{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17362266-1ccb-4722-9658-18293f5c7971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30db8247-2e27-4941-a4f3-8d592cc58822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = 'arxiv_pdfs_cs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39212c82-a2f5-448e-976f-61793f2e4cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_first_n_chars_from_pdfs(folder_path, n):\n",
    "    extracted_texts = []\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    reader = PdfReader(file)\n",
    "                    text = \"\"\n",
    "                    for page in reader.pages:\n",
    "                        page_text = page.extract_text()\n",
    "                        if page_text:\n",
    "                            text += page_text\n",
    "                            if len(text) >= n:\n",
    "                                break\n",
    "                    extracted_texts.append(text[:n])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "    return extracted_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cb53b7-106c-4503-9dc4-2a93f9aa5b67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022221803665161133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1149,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5548526e9a8472facae5c16fcc7217f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(3)\n",
      "Multiple definitions in dictionary at byte 0x7a for key /Subtype\n",
      "Multiple definitions in dictionary at byte 0x1ad for key /Subtype\n",
      "Multiple definitions in dictionary at byte 0x7a for key /Subtype\n",
      "Multiple definitions in dictionary at byte 0x1ad for key /Subtype\n",
      "Multiple definitions in dictionary at byte 0x7a for key /Subtype\n",
      "Multiple definitions in dictionary at byte 0x1ad for key /Subtype\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 4969, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]\n"
     ]
    }
   ],
   "source": [
    "max_sample = 1000\n",
    "begin = 0\n",
    "end = 5000\n",
    "\n",
    "assert begin < end\n",
    "\n",
    "extracted_texts = extract_first_n_chars_from_pdfs(PATH, end)\n",
    "\n",
    "extracted_texts = [text.encode('utf-8', 'ignore').decode('utf-8') for text in extracted_texts]\n",
    "\n",
    "extracted_texts = [x[begin: end] for x in extracted_texts]\n",
    "\n",
    "extracted_texts = [x for x in extracted_texts if len(x) > 50]\n",
    "\n",
    "extracted_texts = extracted_texts[:max_sample]\n",
    "\n",
    "print(len(extracted_texts))\n",
    "print([len(x) for x in extracted_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b973cd-b9fb-4c7f-a568-00835b9db06a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "#\n",
    "# def save_list_as_json(file_path, string_list):\n",
    "#     \"\"\"\n",
    "#     Saves a list of strings as a JSON file.\n",
    "#\n",
    "#     :param file_path: Path where the JSON file will be saved.\n",
    "#     :param string_list: List of strings to be saved in the JSON file.\n",
    "#     \"\"\"\n",
    "#     with open(file_path, 'w', encoding='utf-8') as file:\n",
    "#         json.dump(string_list, file, ensure_ascii=False, indent=4)\n",
    "#\n",
    "# def load_list_from_json(file_path):\n",
    "#     \"\"\"\n",
    "#     Loads a list of strings from a JSON file.\n",
    "#\n",
    "#     :param file_path: Path of the JSON file to be loaded.\n",
    "#     :return: List of strings loaded from the JSON file.\n",
    "#     \"\"\"\n",
    "#     with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#         return json.load(file)\n",
    "#\n",
    "# # Example usage\n",
    "# file_path = \"0_5000.json\"\n",
    "#\n",
    "# # Save the list as a JSON file\n",
    "# # save_list_as_json(file_path, extracted_texts)\n",
    "#\n",
    "# # Load the list back from the JSON file\n",
    "# extracted_texts = load_list_from_json(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ddc000-1f7b-482e-81cc-4e4b8171744e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild Motion Unleashed: Markerless 3D Kinematics\n",
      "and Force Estimation in Cheetahs\n",
      "Zico da Silva1,*, Stacy Shield1, Penny E. Hudson2, Alan M. Wilson3, Fred Nicolls1, and\n",
      "Amir Patel1\n",
      "1University of Cape Town, Department of Electrical Engineering, Cape Town, 7700, South Africa\n",
      "2University of Chichester, Institute of Sport Nursing and Allied Health, Chichester, PO19 6PE, United Kingdom\n",
      "3The Royal Veterinary College, Structure and Motion Laboratory, London, NW1 0TU, United Kingdom\n",
      "*zicods7@gmail.com\n",
      "ABSTRACT\n",
      "The complex dynamics of animal manoeuvrability in the wild is extremely challenging to study. The cheetah ( Acinonyx jubatus )\n",
      "is a perfect example: despite great interest in its unmatched speed and manoeuvrability, obtaining complete whole-body motion\n",
      "data from these animals remains an unsolved problem. This is especially difficult in wild cheetahs, where it is essential that the\n",
      "methods used are remote and do not constrain the animal‚Äôs motion. In this work, we use data obtained from cheetahs in the wild\n",
      "to present a trajectory optimisation approach for estimating the 3D kinematics and joint torques of subjects remotely. We call\n",
      "this approach kinetic full trajectory estimation (K-FTE) . We validate the method on a dataset comprising synchronised video\n",
      "and force plate data. We are able to reconstruct the 3D kinematics with an average reprojection error of 17.69 pixels (62.94 %\n",
      "PCK using the nose-to-eye(s) length segment as a threshold), while the estimates produce an average root-mean-square\n",
      "error of 171.3 N (‚âà17.16%of peak force during stride) for the estimated ground reaction force when compared against the\n",
      "force plate data. While the joint torques cannot be directly validated against ground truth data, as no such data is available for\n",
      "cheetahs, the estimated torques agree with previous studies of quadrupeds in controlled settings. These results will enable\n",
      "deeper insight into the study of animal locomotion in a more natural environment for both biologists and roboticists.\n",
      "Introduction\n",
      "High-speed manoeuvrability is the \"final frontier\" in the study of legged locomotion. While constant-speed gait has been studied\n",
      "extensively, the dynamics and control of these transient movements are still sparsely investigated. This could be attributed to\n",
      "the complex dynamics manoeuvring entails, which require whole-body motion and force data to quantify. This data can be\n",
      "gathered in a lab setting1but does not reflect the natural locomotor conditions or animal motivations experienced in the field.\n",
      "Rapid manoeuvres are important to understand, however. From a biomechanics perspective, they push animals to perform at\n",
      "their mechanical limits, revealing what they are capable of in the most extreme circumstances. They are also interesting to the\n",
      "robotics field, as understanding this category of motion will be crucial for the development of more agile robotic systems that\n",
      "better match the capabilities of animals2.\n",
      "The cheetah ( Acinonyx jubatus ) is the perfect model for studying quadruped dynamics as it is not only the fastest terrestrial\n",
      "animal, but also one of the most manoeuvrable. In fact, a study which used GPS-IMU collars to investigate the behaviour of\n",
      "wild cheetahs revealed that it is the ability to rapidly accelerate that is most critical to their hunting success3. Tracking collars\n",
      "are, however, only able to treat the animal as one lumped rigid body and are thus unable to provide information about leg, spine\n",
      "or tail kinematics or joint loading.\n",
      "By contrast, vision-based pose estimation methods provide a means for non-invasive full-body kinematic and kinetic\n",
      "estimation (‚Äúdynamic‚Äù estimation). In human research, this technique has been adopted to obtain 3D pose estimates from a\n",
      "single camera, i.e. monocular 3D pose estimation4, 5, focusing on full-body kinematics. While data-driven models or purely\n",
      "kinematic formulations are widely applied in research of human locomotion, there have been efforts to incorporate a more\n",
      "complete physics-based model6, 7, which often is formulated as a non-linear program (NLP) to solve for both the kinematic and\n",
      "kinetic parameters.\n",
      "These models provide a strong prior on the motion, making it a popular choice for potentially ambiguous pose detection\n",
      "from a single camera setup. The internal and external torques and forces are a natural byproduct of modelling the kinetics\n",
      "together with the kinematics. Some researchers have used this to explicitly analyse joint torques produced by humans while\n",
      "performing different activities8, 9. In conjunction, optimal-control-based approaches have been used to fit a human model to\n",
      "corresponding kinematic data to obtain joint torques and contact forces10, 11.\n",
      "For all the work done on humans, there is little to show for markerless dynamic motion estimation of animals in the wild.arXiv:2312.05879v1  [cs.CV]  10 Dec 2023That said, animal 3D pose estimation (without explicit modelling of physics), for both multi-view camera and monocular\n",
      "systems, have been well establ\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Nuvo: Neural UV Mapping for Unruly 3D Representations\n",
      "Pratul P. Srinivasan Stephan J. Garbin Dor Verbin Jonathan T. Barron Ben Mildenhall\n",
      "Google Research\n",
      "xatlasNuvo (our model)\n",
      "Nuvo(a) Meshes Extracted from Zip-NeRF(c) Zip-NeRF Volume Density Field\n",
      "(b) Meshes Generated by DreamFusion\n",
      "Nuvoxatlas\"a ghost eating a hamburger\"\n",
      "Figure 1. Nuvo is a technique for UV mapping geometry produced by state-of-the-art 3D reconstruction and generation models such\n",
      "as Neural Radiance Fields (NeRFs) [18]. When applied to such geometry, existing UV mapping algorithms like xatlas [38] produce\n",
      "fragmented texture atlases (as shown by the chart boundaries marked in orange) that are unusable for tasks like appearance editing. Nuvo\n",
      "produces high-quality editable UV mappings for these 3D models, and is robust to challenging input geometry such as (a) meshes extracted\n",
      "from trained NeRF models and (b) meshes generated by text-to-3D models such as DreamFusion [23]. Nuvo can even operate directly on\n",
      "(c) NeRF volumetric density fields without requiring a triangulated mesh.\n",
      "Abstract\n",
      "Existing UV mapping algorithms are designed to oper-\n",
      "ate on well-behaved meshes, instead of the geometry rep-\n",
      "resentations produced by state-of-the-art 3D reconstruction\n",
      "and generation techniques. As such, applying these meth-\n",
      "ods to the volume densities recovered by neural radiance\n",
      "fields and related techniques (or meshes triangulated from\n",
      "such fields) results in texture atlases that are too fragmented\n",
      "to be useful for tasks such as view synthesis or appearance\n",
      "editing. We present a UV mapping method designed to op-\n",
      "erate on geometry produced by 3D reconstruction and gen-\n",
      "eration techniques. Instead of computing a mapping defined\n",
      "on a mesh‚Äôs vertices, our method Nuvo uses a neural field to\n",
      "represent a continuous UV mapping, and optimizes it to be\n",
      "a valid and well-behaved mapping for just the set of visiblepoints, i.e. only points that affect the scene‚Äôs appearance.\n",
      "We show that our model is robust to the challenges posed\n",
      "by ill-behaved geometry, and that it produces editable UV\n",
      "mappings that can represent detailed appearance.\n",
      "1. Introduction\n",
      "Surface parameterization (‚ÄúUV mapping‚Äù) is the process of\n",
      "flattening a 3D surface onto a plane, and it is a core compo-\n",
      "nent of 3D content creation pipelines that enables represent-\n",
      "ing and editing detailed appearance on surface geometry.\n",
      "For complex, real-world meshes, this usually necessitates\n",
      "finding a sequence of cuts such that distortion of the map-\n",
      "ping can be minimal. If those cuts result in multiple discon-\n",
      "nected components that get packaged into one texture, this\n",
      "is commonly referred to as a ‚Äútexture atlas‚Äù.arXiv:2312.05283v1  [cs.CV]  11 Dec 2023Existing UV mapping algorithms are generally designed\n",
      "to work with well-behaved meshes, such as those created\n",
      "by specialized 3D artists. However, an increasing amount\n",
      "of 3D content does not fall into this category: State-of-\n",
      "the-art methods for reconstructing and generating 3D rep-\n",
      "resentations from images or text are based on Neural Ra-\n",
      "diance Fields (NeRFs), which represent geometry as volu-\n",
      "metric fields instead of meshes [18]. Level sets of volume\n",
      "density are generally not smooth, and triangulating these\n",
      "level sets using techniques such as marching cubes [16] pro-\n",
      "duces meshes with multiple connected components, holes\n",
      "that connect to internal ‚Äúhidden‚Äù geometry, and many small\n",
      "‚Äúbumpy‚Äù triangles. More formally, such meshes are typi-\n",
      "cally not manifold or locally smooth, and frequently con-\n",
      "tain a large number of connected components. Existing\n",
      "UV mapping methods either cannot operate on such meshes\n",
      "or produce heavily fragmented UV atlases that complicate\n",
      "downstream applications. For instance, appearance editing\n",
      "in texture space becomes difficult, and optimization by dif-\n",
      "ferentiable rendering is complicated by discontinuities in\n",
      "the surface parameterization which could cause instabilities\n",
      "or necessitate the use of very large textures representations.\n",
      "We present an approach, which we call Nuvo, that ad-\n",
      "dresses these issues by using neural fields to directly opti-\n",
      "mize a UV mapping that satisfies the myriad requirements\n",
      "of a well-behaved surface parameterization. Our method\n",
      "simply requires a representation of scene geometry that al-\n",
      "lows for sampling visible 3D points, and we optimize Nuvo\n",
      "from scratch for each scene by minimizing a set of losses\n",
      "that encourage Nuvo to represent a well-behaved mapping\n",
      "for observed points. Because our method uses point sam-\n",
      "pling on the surface as its fundamental operation, it can\n",
      "be applied to any implicit surface representation, as well\n",
      "as polygonal meshes, without strong limitations on mani-\n",
      "foldness, connectivity, or smoothness. For instance, Nuvo\n",
      "can generate texture atlases directly from NeRF‚Äôs volume\n",
      "density representation of geometry and it can be applied to\n",
      "extracted meshes while remaining agnostic to the connec-\n",
      "tivity of the underlying mesh. Because Nuvo‚Äôs UV map-\n",
      "ping representation is not tied to any underlying mesh, it\n",
      "does \n",
      "----------------------------------------------------------------------------------------------------\n",
      "arXiv:2312.05884v1  [cs.IT]  10 Dec 20231\n",
      "A General Analytical Framework for the Resolution\n",
      "of Near-Field Beamforming\n",
      "Chenguang Rao, Zhiguo Ding, Fellow, IEEE , Octavia A. Dobre, Fellow, IEEE , and Xuchu Dai\n",
      "Abstract ‚ÄîThe resolution is an important performance metric\n",
      "of near-Ô¨Åeld communication networks. In particular, the re solu-\n",
      "tion of near Ô¨Åeld beamforming measures how effectively user s\n",
      "can be distinguished in the distance-angle domain, which is one\n",
      "of the most signiÔ¨Åcant features of near-Ô¨Åeld communication s. In a\n",
      "comparison, conventional far-Ô¨Åeld beamforming can distin guish\n",
      "users in the angle domain only, which means that near-Ô¨Åeld\n",
      "communication yields the full utilization of user spatial r esources\n",
      "to improve spectrum efÔ¨Åciency. In the literature of near-Ô¨Åe ld\n",
      "communications, there have been a few studies on whether\n",
      "the resolution of near-Ô¨Åeld beamforming is perfect. Howeve r,\n",
      "each of the existing results suffers its own limitations, e. g.,\n",
      "each is accurate for special cases only, and cannot precisel y\n",
      "and comprehensively characterize the resolution. In this l etter,\n",
      "a general analytical framework is developed to evaluate the\n",
      "resolution of near-Ô¨Åeld beamforming. Based on this derived\n",
      "expression, the impacts of parameters on the resolution are\n",
      "investigated, which can shed light on the design of the near-\n",
      "Ô¨Åeld communications, including the designs of beamforming and\n",
      "multiple access tequniques.\n",
      "Index Terms ‚ÄîResolution of near-Ô¨Åeld communication, uniform\n",
      "linar array, uniform planar array.\n",
      "I. I NTRODUCTION\n",
      "Recently, there have been an increasing number of studies\n",
      "on near-Ô¨Åeld communications [1]‚Äì[3]. One of the most signiÔ¨Å -\n",
      "cant studies is about the resolution of near-Ô¨Åeld beamformi ng,\n",
      "which is a performance metric to measure the effectiveness\n",
      "of distinguishing different users, an important feature of near-\n",
      "Ô¨Åeld communications. In traditional far-Ô¨Åeld communicati ons,\n",
      "the distinction among different users relies on angular dif fer-\n",
      "ences only. However, in near-Ô¨Åeld communications, thanks t o\n",
      "the characteristics of the used spherical wave channel mode l,\n",
      "the differences in users‚Äô distances can also be used for user\n",
      "distinction [4], [5]. When the resolution is perfect, the us ers\n",
      "in different locations can be perfectly distinguished, suc h\n",
      "that user spatial resources can be fully utilized to improve\n",
      "spectrum efÔ¨Åciency. In [6], the resolution was expressed vi a\n",
      "the Fresnel functions, and was proved to be perfect when the\n",
      "number of base station antennas approaches inÔ¨Ånity. Based\n",
      "on this property of resolution, the authors introduced the\n",
      "location based multiple access (LDMA) scheme to improve\n",
      "the spectral efÔ¨Åciency and fully utilize the location infor mation\n",
      "of users. However, in [7], the author pointed out that unless\n",
      "users are close to the base station, the resolution of near-Ô¨Å eld\n",
      "The work is supported by the National Natural Science Founda tion of China\n",
      "(No. 61971391).\n",
      "C. Rao and X. Dai are with the CAS Key Laboratory of Wireless-\n",
      "Optical Communications, University of Science and Technol ogy of China,\n",
      "No.96 Jinzhai Road, Hefei, Anhui Province, 230026, P. R. Chi na. (e-mail:\n",
      "rcg1839@mail.ustc.edu.cn; daixc@ustc.edu.cn).\n",
      "Z. Ding is with Department of Electrical Engineering and Com puter Sci-\n",
      "ence, Khalifa University, Abu Dhabi, UAE. (e-mail: zhiguo. ding@ku.ac.ae).\n",
      "O. A. Dobre is with the Department of Electrical and Computer Engi-\n",
      "neering, Memorial University, St. John‚Äôs, NL A1B 3X5, Canad a. (e-mail:\n",
      "odobre@mun.ca).beamforming is not perfect. SpeciÔ¨Åcally, if the users‚Äô dist ances\n",
      "to the base station are proportional to the Rayleigh distanc e,\n",
      "the resolution remains poor even if the number of antennas\n",
      "approaches inÔ¨Ånity. Based on this observation, the author i n-\n",
      "troduced the non-orthogonal multiple access (NOMA) scheme\n",
      "for near-Ô¨Åeld communications, which can effectively explo it\n",
      "the imperfect resolution.\n",
      "It is important to point out that the existing studies about t he\n",
      "resolution of near-Ô¨Åeld beamforming have limitations, bei ng\n",
      "accurate only in special cases. Except for these cases, ther e is\n",
      "a lack of an analytical framework to characterize the resolu tion\n",
      "precisely and comprehensively, which motivates our work.\n",
      "In this letter, a general analytical framework is developed\n",
      "to evaluate the resolution of near-Ô¨Åeld beamforming, where\n",
      "the obtained analytical results can be applied to the cases\n",
      "with a uniform planar array (UPA) and a uniform linar\n",
      "array (ULA). In particular, a concise closed-form expressi on\n",
      "for the resolution of near-Ô¨Åeld beamforming is introduced.\n",
      "Compared with the existing results, this expression can be\n",
      "evaluated without involving integration calculations and has\n",
      "a higher accuracy, which can facilitate studies related to\n",
      "near-Ô¨Åeld communications. Based on the derived expression\n",
      "of resolution, the impacts of various parameters are also\n",
      "investigated. SpeciÔ¨Åcally, the conditions for achieving p erfect\n",
      "and imperfect resolution are analyzed in this paper, which\n",
      "provides insights for more stud\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AnomalyDiffusion: Few-Shot Anomaly Image Generation with Diffusion Model\n",
      "Teng Hu1*, Jiangning Zhang2*, Ran Yi1‚Ä†, Yuzhen Du1, Xu Chen2,\n",
      "Liang Liu2, Yabiao Wang2, Chengjie Wang1,2\n",
      "1Shanghai Jiao Tong University2Youtu Lab, Tencent\n",
      "{hu-teng, ranyi, Haaaaaaaaaa }@sjtu.edu.cn;\n",
      "{vtzhang, cxxuchen, leoneliu, caseywang, jasoncjwang }@tencent.com;\n",
      "Abstract\n",
      "Anomaly inspection plays an important role in industrial\n",
      "manufacture. Existing anomaly inspection methods are lim-\n",
      "ited in their performance due to insufficient anomaly data.\n",
      "Although anomaly generation methods have been proposed to\n",
      "augment the anomaly data, they either suffer from poor gener-\n",
      "ation authenticity or inaccurate alignment between the gener-\n",
      "ated anomalies and masks. To address the above problems, we\n",
      "propose AnomalyDiffusion , a novel diffusion-based few-shot\n",
      "anomaly generation model, which utilizes the strong prior\n",
      "information of latent diffusion model learned from large-\n",
      "scale dataset to enhance the generation authenticity under\n",
      "few-shot training data. Firstly, we propose Spatial Anomaly\n",
      "Embedding, which consists of a learnable anomaly embed-\n",
      "ding and a spatial embedding encoded from an anomaly\n",
      "mask, disentangling the anomaly information into anomaly\n",
      "appearance and location information. Moreover, to improve\n",
      "the alignment between the generated anomalies and the\n",
      "anomaly masks, we introduce a novel Adaptive Attention\n",
      "Re-weighting Mechanism. Based on the disparities between\n",
      "the generated anomaly image and normal sample, it dynam-\n",
      "ically guides the model to focus more on the areas with\n",
      "less noticeable generated anomalies, enabling generation of\n",
      "accurately-matched anomalous image-mask pairs. Extensive\n",
      "experiments demonstrate that our model significantly outper-\n",
      "forms the state-of-the-art methods in generation authenticity\n",
      "and diversity, and effectively improves the performance of\n",
      "downstream anomaly inspection tasks. The code and data are\n",
      "available in https://github.com/sjtuplayer/anomalydiffusion.\n",
      "1 Introduction\n",
      "In recent years, industrial anomaly inspection algorithms,\n",
      "i.e.,anomaly detection, localization, and classification, plays\n",
      "a crucial role in industrial manufacture (Duan et al. 2023).\n",
      "However, in real-world industrial production, the anomaly\n",
      "samples are very few, posing a significant challenge for\n",
      "anomaly inspection (Fig. 1-top). To mitigate the issue of few\n",
      "anomaly data, existing anomaly inspection mostly relies on\n",
      "unsupervised learning methods that only use normal sam-\n",
      "ples (Zavrtanik, Kristan, and Sko Àácaj 2021; Li et al. 2021), or\n",
      "few-shot supervised learning methods (Zhang et al. 2023a).\n",
      "Although these methods perform well in anomaly detection,\n",
      "*Equal contributions.\n",
      "‚Ä†Corresponding author.\n",
      "Large Amount of Normal Samples\n",
      " Few Anomalies\n",
      "Normal \n",
      "SamplesAnomaly Generation (Ours)\n",
      "Anomaly \n",
      "DiffusionGenerated\n",
      " Anomalies\n",
      "(d) Ours\n",
      "FactoryUnsupervised\n",
      " Learning\n",
      "Few-shot\n",
      "Supervised \n",
      "LearningPrevious Methods\n",
      "Task1: AD\n",
      "Task2: AL\n",
      "Task3: ACProduce\n",
      "ApplyGood Performance\n",
      "Limited PerformanceGood Performance\n",
      "Good Performance\n",
      "Good Performance Incapable \n",
      "DRAEM\n",
      "ICCV‚Äô21(a)Crop&Paste\n",
      "ICME‚Äô21(b)DFMGAN\n",
      "AAAI‚Äô23(c)\n",
      "Figure 1: Top: Our model generates extensive anomaly data,\n",
      "which supports the downstream Anomaly Detection (AD),\n",
      "Localization (AL) and Classification (AC) tasks, while pre-\n",
      "vious methods mainly rely on unsupervised learning or few-\n",
      "shot supervised learning due to the limited anomaly data;\n",
      "Bottom: Generated anomaly results on hazelnut-crack and\n",
      "capsule-squeeze of our model and existing anomaly gen-\n",
      "eration methods. Our model generates the most authentic\n",
      "anomalies over all the methods.\n",
      "they have limited performance in anomaly localization and\n",
      "cannot handle anomaly classification.\n",
      "To cope with the problem of scarce anomaly samples, re-\n",
      "searchers propose anomaly generation methods to supple-\n",
      "ment the anomaly data, which can be divided into two types:\n",
      "1)The model-free methods randomly crop and paste patches\n",
      "from existing anomalies or anomaly texture dataset onto nor-\n",
      "mal samples (Li et al. 2021; Lin et al. 2021; Zavrtanik, Kris-arXiv:2312.05767v1  [cs.CV]  10 Dec 2023tan, and Sko Àácaj 2021). But such methods exhibit poor au-\n",
      "thenticity in the synthesized data (Fig. 1-bottom-a/b). 2)The\n",
      "GAN-based methods (Zhang et al. 2021; Niu et al. 2020;\n",
      "Duan et al. 2023) utilize Generative Adversarial Networks\n",
      "(GANs) (Goodfellow et al. 2014) to generate anomalies,\n",
      "but most of them require a large amount of anomaly sam-\n",
      "ples for training. The only few-shot generation model DFM-\n",
      "GAN (Duan et al. 2023) employs StyleGAN2 (Karras et al.\n",
      "2020) pretrained on normal samples, and then performs do-\n",
      "main adaption with a few anomaly samples. But the gener-\n",
      "ated anomalies are not accurately aligned with the anomaly\n",
      "masks (Fig. 1-bottom-c). To sum up, the existing anomaly\n",
      "generation methods either fail to generate authentic anoma-\n",
      "lies or accurately-aligned anomalous image-mask pairs by\n",
      "learning from few-shot anomaly data, which limits their im-\n",
      "provement in the downstream anomaly inspection t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Maximum capacity path problem  with loss factors \n",
      "Javad Tayyebi1a, Mihai-Lucian R√Ætan2b and Adrian Marius Deaconu2c \n",
      "1Department of Industrial Engineering, Birjand University of Technology, Industry and Mining Boulevard, Ibn Hesam \n",
      "Square, Birjand, Iran \n",
      "2Department of Mathematics and Computer Science, Transilvania University of Bra»ôov, Iuliu Maniu st. 50, Bra»ôov, \n",
      "Romania \n",
      "javadtayyebi@birjandut.ac.ir, {mihai.ritan, a.deaconu}@unitbv.ro \n",
      "Keywords: Capacity path problems, combinatorial optimization, polynomial algorithms. \n",
      "Abstract: The maximum capacity path problem is to find a path from a source to a sink which has the maximum capacity \n",
      "among all paths. This paper addresses an extension of this problem which considers loss factors. It is called \n",
      "the generalized maximum capacity path problem. The problem is a network flow optimization problem whose \n",
      "network contains capacities as well as loss factors for arcs. The aim of the problem is to find a path from an \n",
      "origin to a destination so as to send a maximum flow along the path considering loss factors and respecting \n",
      "capacity constraints. The paper presents a zero-one formulation of the problem and moreover, it presents two \n",
      "efficient algorithms which solve the problem in polynomial time.\n",
      "1 INTRODUCTION  \n",
      "Combinatorial optimization is a special class of \n",
      "mathematical program that consists of finding an \n",
      "optimal object among a finite set of specific-\n",
      "structured objects. Some most prominent problems of \n",
      "this class are shortest path (SP) problems, maximum \n",
      "reliability path (MRP) problems, and maximum \n",
      "capacity path (MCP) problems. In these problems, the \n",
      "goal is to find an optimal path from an origin to a \n",
      "destination under a special objective function as \n",
      "follows: \n",
      "1. min\n",
      "‡Øâ‚àà‚Ñô‚àëùëô‡Øú‡Øù (‡Øú,‡Øù)‚àà‡Øâ for SP problems  \n",
      "2. max\n",
      "‡Øâ‚àà‚Ñô‚àèùëù‡Øú‡Øù (‡Øú,‡Øù)‚àà‡Øâ for MRP problems  \n",
      "3. max\n",
      "‡Øâ‚àà‚Ñômin\n",
      "‡Øâ‚àà‚Ñôùë¢‡Øú‡Øù  for MCP problems  \n",
      "where ‚Ñô is the set consisting of all paths from the \n",
      "origin to the destination, ùëô‡Øú‡Øù, ùëù‡Øú‡Øù, and ùë¢‡Øú‡Øù denote \n",
      "respectively the length, the reliability, and the \n",
      "capacity of arc (ùëñ,ùëó). Fortunately, these problems are \n",
      "tractable, i.e., there are polynomial-time algorithms to \n",
      "solve them. Specially, shortest path problems can be \n",
      "solved by a Fibonacci-heap implementation of \n",
      "Dijkstra's algorithm in ùëÇ(ùëö + ùëõ ùëôùëúùëî(ùëõ))  if lengths \n",
      " \n",
      "a https://orcid.org/0000-0002-7559-3870 \n",
      "b https://orcid.org/0009-0007-4601-6533 \n",
      "c https://orcid.org/0000-0002-1070-1383 are nonnegative; otherwise, the best-known algorithm \n",
      "is a FIFO implementation of Bellman-Ford algorithm \n",
      "which has a complexity of ùëÇ(ùëöùëõ), where n and m are \n",
      "the number of nodes and arcs, respectively. The \n",
      "maximum reliability path problem can be converted \n",
      "into a shortest path problem by setting ùëô‡Øú‡Øù=\n",
      "‚àíùëôùëúùëî(ùëù ‡Øú‡Øù) for every arc (ùëñ,ùëó). So, it can be solved as \n",
      "well as the SP problem, especially in the case that \n",
      "ùëù‡Øú‡Øù< 1. Moreover, the both MRP and MCP problems \n",
      "can be solved directly by modifying the shortest path \n",
      "algorithms because they enjoy the optimality \n",
      "conditions similar with that of the SP problem (See \n",
      "(Ahuja, 1988) for more details). However, the best-\n",
      "known algorithm for solving the maximum capacity \n",
      "path problem in undirected network is not based on \n",
      "this concept, but it is a recursive algorithm with a \n",
      "linear complexity ùëÇ(ùëö) (Punnen, 1991). \n",
      "As an application of maximum capacity path \n",
      "problems, consider a network that represents \n",
      "connections between routers in the Internet. The \n",
      "capacity of an arc represents the bandwidth of the \n",
      "corresponding connection between two routers, the \n",
      "maximum capacity path problem is to find the path \n",
      "between two Internet nodes that has the maximum \n",
      "possible bandwidth. Besides this well-known \n",
      "network routing problem, MCP is also an important \n",
      "component of the Schulze method for deciding the \n",
      "winner of a multiway election (Schulze, 2011). It is \n",
      "applied to digital compositing (Fernandez, 1998), and \n",
      "metabolic pathway analysis (Ullah, 2009). \n",
      "This paper introduces a novel combinatorial \n",
      "optimization problem, called the generalized \n",
      "maximum capacity path (GMCP) problem. It is a \n",
      "more complex version of the problem of finding the \n",
      "directed path from a given source node s to a given \n",
      "sink node t that has the minimum loss among all \n",
      "directed paths from s to t (Deaconu, 2023). GMCP is \n",
      "defined on a network, which each arc has two \n",
      "attributes: capacity and loss factors. The capacity of \n",
      "an arc means the maximum amount that can flow on \n",
      "the arc. The loss factor of an arc is the flow value \n",
      "arriving at its tail node if 1 unit of flow sends on the \n",
      "arc. The generalized maximum capacity problem is to \n",
      "find a path which is capable of sending maximum \n",
      "flow considering loss factors. This problem is \n",
      "inspired from an extension of maximum flow \n",
      "problems regarding loss factors, called the \n",
      "generalized maximum flow problem [5]. So, its \n",
      "algorithms can be used as subroutines for solving \n",
      "generalized maximum flow problems. On the other \n",
      "hand, the GMCP problem is an extension of MRP and \n",
      "MCP problems because it is convert\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FedASMU: Efficient Asynchronous Federated Learning with Dynamic\n",
      "Staleness-aware Model Update\n",
      "Ji Liu1,‚àó, Juncheng Jia2,‚àó, Tianshi Che3, Chao Huo2, Jiaxiang Ren3, Yang Zhou3,\n",
      "Huaiyu Dai4, Dejing Dou5\n",
      "1Hithink RoyalFlush Information Network Co., Ltd.,2Soochow University,5Boston Consulting Group, China,\n",
      "3Auburn University,4North Carolina State University, United States.\n",
      "To appear in AAAI 2024Abstract\n",
      "As a promising approach to deal with distributed data,\n",
      "Federated Learning (FL) achieves major advancements\n",
      "in recent years. FL enables collaborative model train-\n",
      "ing by exploiting the raw data dispersed in multi-\n",
      "ple edge devices. However, the data is generally non-\n",
      "independent and identically distributed, i.e., statisti-\n",
      "cal heterogeneity, and the edge devices significantly\n",
      "differ in terms of both computation and communica-\n",
      "tion capacity, i.e., system heterogeneity. The statisti-\n",
      "cal heterogeneity leads to severe accuracy degradation\n",
      "while the system heterogeneity significantly prolongs\n",
      "the training process. In order to address the hetero-\n",
      "geneity issue, we propose an Asynchronous Staleness-\n",
      "aware Model Update FL framework, i.e., FedASMU,\n",
      "with two novel methods. First, we propose an asyn-\n",
      "chronous FL system model with a dynamical model\n",
      "aggregation method between updated local models and\n",
      "the global model on the server for superior accuracy\n",
      "and high efficiency. Then, we propose an adaptive\n",
      "local model adjustment method by aggregating the\n",
      "fresh global model with local models on devices to\n",
      "further improve the accuracy. Extensive experimenta-\n",
      "tion with 6 models and 5 public datasets demonstrates\n",
      "that FedASMU significantly outperforms baseline ap-\n",
      "proaches in terms of accuracy (0.60% to 23.90% higher)\n",
      "and efficiency (3.54% to 97.98% faster).\n",
      "1 Introduction\n",
      "In recent years, numerous edge devices have been gen-\n",
      "erating large amounts of distributed data.Due to the\n",
      "implementation of laws and regulations, e.g., General\n",
      "Data Protection Regulation (GDPR) (EU 2018), the\n",
      "traditional training approach, which aggregates the dis-\n",
      "tributed data into a central server or a data center,\n",
      "becomes almost impossible. As a promising approach,\n",
      "Federated Learning (FL) (Kairouz et al. 2021; Liu et al.\n",
      "2022a) enables collaborative model training by transfer-\n",
      "ring gradients or models instead of raw data. FL avoids\n",
      "privacy or security issues incurred by direct raw data\n",
      "transfer while exploiting multiple edge devices to train\n",
      "a global model. FL has been applied in diverse areas,\n",
      "‚àóCorresponding author (jiliuwork@gmail.com and jia-\n",
      "juncheng@suda.edu.cn).such as computer vision (Liu et al. 2020), nature lan-\n",
      "guage processing (Liu et al. 2021), bioinformatics (Chen\n",
      "et al. 2021), and healthcare (Nguyen et al. 2022a).\n",
      "Traditional FL typically exploits a parameter server\n",
      "(server) (Li et al. 2014; Liu et al. 2023a) to coordinate\n",
      "the training process on each device with a synchronous\n",
      "(McMahan et al. 2017; Li et al. 2020; Liu et al. 2023b;\n",
      "Jia et al. 2023) mechanism. The synchronous training\n",
      "process generally consists of multiple rounds and each\n",
      "round contains five steps. First, the server selects a set\n",
      "of devices (Shi et al. 2020). Second, the server broad-\n",
      "casts the global model to the selected devices. Third,\n",
      "local training is carried out with the data in each se-\n",
      "lected device. Fourth, each device uploads the updated\n",
      "model (gradients) to the server. Fifth, the server ag-\n",
      "gregates the uploaded models to generate a new global\n",
      "model when all the selected devices complete the afore-\n",
      "mentioned four steps. Although the synchronous mech-\n",
      "anism is effective and simple to implement, stragglers\n",
      "may significantly prolong the training process (Jiang\n",
      "et al. 2022) with heterogeneous devices (Lai et al. 2021;\n",
      "Yang et al. 2021). Powerful devices may remain idle\n",
      "when the server is waiting for stragglers (Wu et al.\n",
      "2020), incurring significant efficiency degradation.\n",
      "Within the FL paradigm, the devices are typically\n",
      "highly heterogeneous in terms of computation and com-\n",
      "munication capacity (Li, Ota, and Dong 2018; Wu et al.\n",
      "2020; Nishio and Yonetani 2019; Che et al. 2022, 2023b)\n",
      "and data distribution (McMahan et al. 2017; Li et al.\n",
      "2020; Wang et al. 2020; Che et al. 2023a). Some de-\n",
      "vices may complete the local training and update the\n",
      "model within a short time, while some other devices\n",
      "may take a much longer time to finish this process and\n",
      "may fail to upload the model because of modest band-\n",
      "width or high latency, which is denoted by system het-\n",
      "erogeneity. In addition, the data in each device may be\n",
      "non-Independent and Identically Distributed (non-IID)\n",
      "data, which refers to statistical heterogeneity. The sta-\n",
      "tistical heterogeneity can lead to diverse local objectives\n",
      "(Wang et al. 2020) and client drift (Karimireddy et al.\n",
      "2020; Hsu, Qi, and Brown 2019) issues, which degrades\n",
      "the accuracy of the global model in FL.\n",
      "Asynchronous FL (Xu et al. 2021; Wu et al. 2020;\n",
      "Nguyen et al. 2022a) enables the server to aggregate thearXiv:2312.05770v1  [cs.DC]  10 Dec 2023uploaded mode\n",
      "----------------------------------------------------------------------------------------------------\n",
      "arXiv:2312.05885v1  [cs.LG]  10 Dec 2023Adaptive Parameter Selection for Kernel Ridge Regression‚ú©\n",
      "Shao-Bo Lin\n",
      "Center for Intelligent Decision-Making and Machine Learni ng, School of Management, Xi‚Äôan Jiaotong\n",
      "University, Xi‚Äôan 710049, China\n",
      "Abstract\n",
      "This paper focuses on parameter selection issues of kernel ridge r egression (KRR). Due\n",
      "to special spectral properties of KRR, we Ô¨Ånd that delicate subdiv ision of the parameter\n",
      "interval shrinks the diÔ¨Äerence between two successive KRR estima tes. Based on this\n",
      "observation, we develop an early-stopping type parameter select ion strategy for KRR\n",
      "according to the so-called Lepskii-type principle. Theoretical veriÔ¨Å cations are presented\n",
      "in the framework of learning theory to show that KRR equipped with t he proposed\n",
      "parameter selection strategy succeeds in achieving optimal learnin g rates and adapts to\n",
      "diÔ¨Äerent norms, providing a new record of parameter selection for kernel methods.\n",
      "Keywords: Learning theory, kernel ridge regression, parameter selection, Lepskii\n",
      "principle\n",
      "1. Introduction\n",
      "Due to perfect theoretical behaviors in theory [1], kernel ridge r egression (KRR) has\n",
      "been widely used fortheregression purpose. Numerous provablev ariants such as Nystr¬® om\n",
      "regularization [2], distributed KRR [3], localized KRR [4] and boosted KRR [5] have been\n",
      "developed to reduce the computational burden and circumvent th e saturation [6] of KRR.\n",
      "However, theoretical veriÔ¨Åcations on KRR, as well as its variants, are built upon the a-\n",
      "priori regularization parameter selection strategy, which is pract ically infeasible since the\n",
      "a-priori information of the data is generally inaccessible.\n",
      "‚ú©The research was partially supported by the National Key R&D Prog ram of China\n",
      "(No.2020YFA0713900) and the Natural Science Foundation of Chin a [Grant No 62276209]. Email:\n",
      "sblin1983@gmail.com\n",
      "Preprint submitted to Elsevier December 12, 2023Though the uniqueness of the optimal regularization has been prov ed in [7] and the\n",
      "totally stability studied in [8, 9] illustrated that KRR performs stable w ith respect to\n",
      "the regularization parameter, posterior choices of regularization parameter to realize the\n",
      "excellent theoretical behaviors of KRR still remains open. Three ex isting approaches\n",
      "for parameter selection of KRR are the hold-out (HO) [1], discrepan cy-type principle\n",
      "(DP) [10] and Lepskii-type principle (LP) [11, 12]. Numerically, HO requ ires a split of\n",
      "the sample set Dinto training and validation sets; derives a set of KRR estimators via\n",
      "the training set and selects the optimal regularization parameter o n the validation set.\n",
      "Theoretical optimality of HO was provided in [13, Chap.7] for expect ation and [14] for\n",
      "probability. However, therearemainlythreedesignÔ¨ÇawsofHO.AtÔ¨Å rst, thevalidationset\n",
      "is not involved in the training process, resulting in waste of samples an d sub-optimality of\n",
      "HO in practice. Then, HO generally requires that the empirical exces s risk is an accessible\n",
      "unbiased estimate of the population risk, which prohibits the applicat ion of it in deriving\n",
      "parameters for KRR under the reproducing kernel Hilbert space ( RHKS) norm. Finally,\n",
      "as shown in [14], HO is implemented under the assumption that the outp ut is bounded,\n",
      "imposing strong boundedness assumption of the noise.\n",
      "DiÔ¨Äerent from HO that is available for almost all least-square regres sion algorithms,\n",
      "DP and LP are somewhat exclusive to kernel methods. DP, originate d from linear inverse\n",
      "problems [15], devotes to quantifying the Ô¨Åtting error by some comp utable quantities such\n",
      "as the noise of data [10] or complexity of derived estimates [5]. Thoug h it is proved to be\n",
      "powerfulintheliteratureofinverse problems[15], itsperformance isnot, atleastintheory,\n",
      "optimal for learning purpose since the derived learning rates in [10] is sub-optimal. LP\n",
      "(also called as the balancing principle), originally proposed by [16], focu ses on selecting\n",
      "parameter by bounding diÔ¨Äerences of two successive estimates. I t was Ô¨Årstly adopted\n",
      "in [17] for the learning purpose to determine the regularization para meter of KRR and\n",
      "then improved in [11] to encode the capacity information of RKHS and [12] to adapt to\n",
      "diÔ¨Äerent norms. Since LP does not require the split of data, it pract ically performs better\n",
      "than HO [11]. However, there are also two crucial problems concern ing LP. On one hand,\n",
      "LP needs recurrently pairwise comparisons of diÔ¨Äerent KRR estimat es, which inevitablely\n",
      "brings additional computational burden. On the other hand, theo retical results presented\n",
      "2in [11] and [12] are only near optimal in the sense that there is at leas t an additional\n",
      "logarithmic factor in the learning rates of corresponding KRR.\n",
      "This paper aims to design an early-stopping type parameter selectio n strategy based\n",
      "on LP to equip KRR to realize its excellent learning performance in theo ry. Due to\n",
      "the special spectral property of KRR, we present a close relation between diÔ¨Äerences of\n",
      "two successive KRR estimates and the empirical eÔ¨Äective dimension a nd Ô¨Ånd that sub\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Hacking Task Confounder in Meta-Learning\n",
      "Jingyao Wang1,2, Wenwen Qiang2*, Yi Ren2, Zeen Song1,2, Xingzhe Su1,2, Changwen Zheng2\n",
      "1University of Chinese Academy of Sciences, Beijing, China\n",
      "2Institute of Software Chinese Academy of Sciences, Beijing, China\n",
      "{wangjingyao22,suxingzhe18,songzeen22 }@mails.ucas.ac.cn, {renyi,qiangwenwen,changwen }@iscas.ac.cn\n",
      "Abstract\n",
      "Meta-learning enables rapid generalization to new tasks by\n",
      "learning meta-knowledge from a variety of tasks. It is intu-\n",
      "itively assumed that the more tasks a model learns in one\n",
      "training batch, the richer knowledge it acquires, leading to\n",
      "better generalization performance. However, contrary to this\n",
      "intuition, our experiments reveal an unexpected result: adding\n",
      "more tasks within a single batch actually degrades the gen-\n",
      "eralization performance. To explain this unexpected phe-\n",
      "nomenon, we conduct a Structural Causal Model (SCM) for\n",
      "causal analysis. Our investigation uncovers the presence of\n",
      "spurious correlations between task-specific causal factors and\n",
      "labels in meta-learning. Furthermore, the confounding factors\n",
      "differ across different batches. We refer to these confound-\n",
      "ing factors as ‚ÄúTask Confounders‚Äù. Based on this insight, we\n",
      "propose a plug-and-play Meta-learning Causal Representa-\n",
      "tion Learner (MetaCRL) to eliminate task confounders. It en-\n",
      "codes decoupled causal factors from multiple tasks and uti-\n",
      "lizes an invariant-based bi-level optimization mechanism to\n",
      "ensure their causality for meta-learning. Extensive experi-\n",
      "ments on various benchmark datasets demonstrate that our\n",
      "work achieves state-of-the-art (SOTA) performance.\n",
      "Introduction\n",
      "Meta-learning aims to develop algorithms capable of adapt-\n",
      "ing to previously unseen tasks. To achieve this goal, meta-\n",
      "learning methods are trained on a diverse set of tasks,\n",
      "enabling them to learn meta-knowledge that can be ap-\n",
      "plied to new and related tasks. Moreover, meta-learning\n",
      "has been demonstrated to address numerous inherent chal-\n",
      "lenges in deep learning, such as computational bottlenecks\n",
      "and generalization issues (Du et al. 2020; Li et al. 2018).\n",
      "It is widely used in domains like reinforcement learning\n",
      "(Mitchell et al. 2021), computer vision (Mahadevkar et al.\n",
      "2022), and robotics (Schrum et al. 2022).\n",
      "In general, meta-learning can be defined as a bi-level op-\n",
      "timization process. In the inner loop, task-specific parame-\n",
      "ters are independently learned based on meta-parameters. In\n",
      "the outer loop, the meta-parameters are updated by minimiz-\n",
      "ing the average loss across multiple tasks using the learned\n",
      "task-specific parameters. During the meta-training process,\n",
      "*Corresponding author\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "batch size=4 batch size=8444546474849Accuracy on D2\n",
      "303132333435\n",
      "Accuracy on T2\n",
      "5-way 1-shot accuracy on miniImagenet\n",
      "Accuracy on D2\n",
      "Accuracy on T2(a) miniImagenet\n",
      "batch size=32 batch size=64929394959697Accuracy on D2\n",
      "84858687888990\n",
      "Accuracy on T2\n",
      "20-way 1-shot accuracy on Omniglot\n",
      "Accuracy on D2\n",
      "Accuracy on T2 (b) Omniglot\n",
      "batch size=4 batch size=84648505254Accuracy on D2\n",
      "353637383940\n",
      "Accuracy on T2\n",
      "5-way 1-shot accuracy on tieredImagenet\n",
      "Accuracy on D2\n",
      "Accuracy on T2\n",
      "(c) tieredImagenet\n",
      "batch size=4 batch size=8555657585960Accuracy on D2\n",
      "404142434445\n",
      "Accuracy on T2\n",
      "5-way 1-shot accuracy on CIFAR-FS\n",
      "Accuracy on D2\n",
      "Accuracy on T2 (d) CIFAR-FS\n",
      "Figure 1: The empirical results on four benchmark datasets.\n",
      "each batch‚Äôs training set consists of a series of randomly\n",
      "sampled different tasks, with each task containing train-\n",
      "ing samples from various categories. By leveraging shared\n",
      "structures across multiple tasks, the meta-learning model\n",
      "can acquire rich meta-knowledge, leading to great gener-\n",
      "alization and adaptation (Wang, Zhao, and Li 2021; Song\n",
      "et al. 2022). Therefore, a widely adopted hypothesis is that\n",
      "the more tasks the model learns in a single training batch,\n",
      "the richer knowledge it acquires, and consequently, the bet-\n",
      "ter its performance will be (Hospedales et al. 2021; Rivolli\n",
      "et al. 2022). This idea is intuitively reasonable since learning\n",
      "from a broader range of scenarios can help grasp a wealth of\n",
      "knowledge, resembling human cognition.\n",
      "However, our experiments yield conflicting results. We\n",
      "sample two sets of non-overlapping tasks, T1andT2. Within\n",
      "T1, we divide the tasks into a meta-training set D1and a\n",
      "meta-testing set D2, while T2is used solely for separate test-\n",
      "ing without being split. We train MAML (Finn, Abbeel, and\n",
      "Levine 2017) on D1with two different batch size settings,\n",
      "i.e., batch size= Band batch size= 2B. Then we test it on D2\n",
      "andT2. Intuitively, the model with a larger batch size is ex-\n",
      "pected to perform better. Surprisingly, as shown in Figure 1,arXiv:2312.05771v1  [cs.LG]  10 Dec 2023Bùëñ,ùëó\n",
      "AùëóAùëñùëãùëñ\n",
      "ùëãùëóùëåùëñ\n",
      "ùëåùëó(a) data generation mechanism\n",
      "Bùëñ,ùëó\n",
      "AùëóAùëñùëåùëñ\n",
      "ùëåùëóùëãùëñ\n",
      "ùëãùëó\n",
      "(b) meta-learning process in practice\n",
      "Figure 2: The Structural Causal Model (SCM) regarding two\n",
      "tasks œÑiandœÑj, where (Xi, Yi)and(Xj, Yj)are the samples\n",
      "a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "SuperPrimitive: Scene Reconstruction at a Primitive Level\n",
      "Kirill Mazur, Gwangbin Bae, Andrew J. Davison\n",
      "Dyson Robotics Lab, Imperial College London\n",
      "{k.mazur21, g.bae, a.davison }@imperial.ac.uk\n",
      "Abstract\n",
      "Joint camera pose and dense geometry estimation from\n",
      "a set of images or a monocular video remains a challenging\n",
      "problem due to its computational complexity and inherent\n",
      "visual ambiguities. Most dense incremental reconstruction\n",
      "systems operate directly on image pixels and solve for their\n",
      "3D positions using multi-view geometry cues. Such pixel-\n",
      "level approaches suffer from ambiguities or violations of\n",
      "multi-view consistency (e.g. caused by textureless or specu-\n",
      "lar surfaces).\n",
      "We address this issue with a new image representation\n",
      "which we call a SuperPrimitive. SuperPrimitives are ob-\n",
      "tained by splitting images into semantically correlated local\n",
      "regions and enhancing them with estimated surface normal\n",
      "directions, both of which are predicted by state-of-the-art\n",
      "single image neural networks. This provides a local geom-\n",
      "etry estimate per SuperPrimitive, while their relative posi-\n",
      "tions are adjusted based on multi-view observations.\n",
      "We demonstrate the versatility of our new representation\n",
      "by addressing three 3D reconstruction tasks: depth comple-\n",
      "tion, few-view structure from motion, and monocular dense\n",
      "visual odometry.\n",
      "1. Introduction\n",
      "Enriching monocular incremental reconstruction with prior\n",
      "world knowledge is essential for resolving visual ambi-\n",
      "guities. This issue is particularly prevalent in scenarios\n",
      "with scarce data observations available: a notable example\n",
      "would be monocular visual SLAM, where images are being\n",
      "streamed from a camera into the system in real-time.\n",
      "When a monocular vision system encounters a new scene\n",
      "region, it must estimate the region‚Äôs geometry based on a\n",
      "very limited number of observations. Without this, contin-\n",
      "uous camera motion tracking would not be possible. Once\n",
      "the scene region is thoroughly observed, the initial geom-\n",
      "etry estimate should be refined to better explain the multi-\n",
      "view information.\n",
      "This naturally leads to a question: what sort of priors\n",
      "are effective in both providing reliable initial geometry es-\n",
      "timates and supporting multi-view consistency? Geometric\n",
      "[ùëÖ,ùë°]Extracted SuperPrimitiveI!I\"Figure 1. Multi-View Geometry with SuperPrimitives. Super-\n",
      "Primitives are extracted from an input frame by dividing it into im-\n",
      "age segments equipped with estimated surface normal directions\n",
      "(bottom-left). Each SuperPrimitive induces a dense reconstruction\n",
      "within the corresponding image segment up to a-priori unknown\n",
      "scale. Different possible reconstructions are shown in light blue.\n",
      "The scales are then jointly optimised together with a relative cam-\n",
      "era pose to fit multi-view photometric constraints (visualised in\n",
      "green and red). The resulting dense reconstruction of the refer-\n",
      "ence frame is shown in the top.\n",
      "priors generally fall into one of two categories: local and\n",
      "global. Local priors, such as smoothness assumption [30] or\n",
      "surface normal regularisation [50], impose additional con-\n",
      "straints within a small neighbourhood. Global priors, on the\n",
      "other hand, aim to impose constraints on a larger scale, such\n",
      "as depth prediction [2, 11].\n",
      "Our key observation is that some of the geometrical cor-\n",
      "relations are more reliable than the others, and therefore\n",
      "could be safely ‚Äúlocked in‚Äù together within local regions\n",
      "based on a single-view prediction. Points belonging to thearXiv:2312.05889v1  [cs.CV]  10 Dec 2023same rigid body are strongly correlated, making it unnec-\n",
      "essary to determine their depth independently. In contrast,\n",
      "distinct and unrelated objects can be placed arbitrarily in\n",
      "the scene. As the number of objects increases, learning a\n",
      "reliable global prior on their relative positions becomes an\n",
      "increasingly complex problem.\n",
      "In this work, we show that purely local but strong pri-\n",
      "orsare enough to achieve excellent performance across a\n",
      "variety of geometric vision tasks. For that purpose, we in-\n",
      "troduce a novel representation, SuperPrimitives . A Super-\n",
      "Primitive represents a local image segment, coupled with\n",
      "a dense shape estimate which is determined up to a scale\n",
      "factor. The scale factor can be further adjusted based on\n",
      "information observed from other views or additional mea-\n",
      "surements.\n",
      "We show that SuperPrimitives can be efficiently con-\n",
      "structed using a front-end which consists of two single-\n",
      "image neural networks, extracting image segmentation and\n",
      "surface normal prediction. Effectively, our neural front-end\n",
      "predicts whether adjacent pixels belong to the same geo-\n",
      "metrical entity through image segmentation and estimates a\n",
      "surface normal at this point, thereby providing an infinites-\n",
      "imal geometry estimate.\n",
      "We delegate global, scene-level alignment to our stream-\n",
      "lined multi-view, iterative, optimisation-based back-end .\n",
      "The resulting front-end / back-end tandem combines the\n",
      "flexibility of multi-view based optimisation methods with\n",
      "the observation efficiency common in prior-driven systems.\n",
      "O\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Context-Aware Code Generation Framework for Code\n",
      "Repositories: Local, Global, and Third-Party Library\n",
      "Awareness\n",
      "DIANSHU LIAO, School of Computer Information Engineering, Jiangxi Normal University, China\n",
      "SHIDONG PAN, School of Computing, Australian National University & CSIRO‚Äôs Data61, Australia\n",
      "QING HUANG, School of Computer Information Engineering, Jiangxi Normal University, China\n",
      "XIAOXUE REN, School of Software Technology, Zhejiang University, China\n",
      "ZHENCHANG XING, CSIRO‚Äôs Data61 & School of Computing, Australian National University, Australia\n",
      "HUAN JIN, Jiangxi University of Technology, China\n",
      "QINYING LI, Jiangxi University of Technology, China\n",
      "Code generation tools are essential to help developers in the software development process. Existing tools often\n",
      "disconnect with the working context, i.e., the code repository, causing the generated code to be not similar\n",
      "to human developers. In this paper, we propose a novel code generation framework, dubbed ùê¥3-CodGen, to\n",
      "harness information within the code repository to generate code with fewer logical errors, code redundancy,\n",
      "and library-related compatibility issues. We identify three categories of representative information for the\n",
      "code repository: local-aware information from current code file, global-aware information from other code\n",
      "files, and third-party-library information. Results demonstrate that by adopting the ùê¥3-CodGen framework,\n",
      "we successfully extract, fuse, and feed code repository information into the LLM, generating more accurate,\n",
      "efficient, and highly reusable code. The effectiveness of our framework is further underscored by generating\n",
      "code with a higher reuse rate, compared to human developers. This research contributes significantly to the\n",
      "field of code generation, providing developers with a more powerful tool to address the evolving demands in\n",
      "software development in practice.\n",
      "Additional Key Words and Phrases: Code Generation, Code Evolution, Code Repository Knowledge Mining\n",
      "1 INTRODUCTION\n",
      "In the realm of Software Engineering, the advent of Large Language Models (LLMs) has revo-\n",
      "lutionized various tasks, including code generation [ 1‚Äì5]. The automatic generation of code by\n",
      "these models significantly reduces development time and effort [ 6]. Specifically, in the process\n",
      "of evolving software projects, software engineering developers are frequently tasked to add new\n",
      "features and functionality [ 7]. LLMs such as ChatGPT [ 8], GitHub Copilot [ 9], Codex [ 10] are\n",
      "capable of automatically generating code based on the developers‚Äô requirements (e.g., natural\n",
      "language descriptions of functions and function definitions).\n",
      "A significant gap still persists between the code generated by LLMs and that crafted by human\n",
      "developers. Typically, when adding new functionality or features to a specific module, developers\n",
      "already had sufficient knowledge about the current task and the entire code repository. Also,\n",
      "according to a previous study [ 11], developers often expect that code generation tools could be\n",
      "aware of more context/knowledge by using specific frameworks/libraries [ 12]. In addition, they\n",
      "hope the generated code maximum utilizing specific third-party libraries (e.g., invocation of an\n",
      "Authors‚Äô addresses: Dianshu Liao, School of Computer Information Engineering, Jiangxi Normal University, Nanchang,\n",
      "Jiangxi, China, dianshu.liao@jxnu.edu.cn; Shidong Pan, School of Computing, Australian National University & CSIRO‚Äôs\n",
      "Data61, Canberra, Australia, shidong.pan@anu.edu.au; Qing Huang, School of Computer Information Engineering, Jiangxi\n",
      "Normal University, Nanchang, Jiangxi, China, qh@jxnu.edu.cn; Xiaoxue Ren, School of Software Technology, Zhejiang\n",
      "University, Hangzhou, Zhejiang, China, xxren@zju.edu.cn; Zhenchang Xing, CSIRO‚Äôs Data61 & School of Computing,\n",
      "Australian National University, Canberra, Australia, zhenchang.xing@data61.csiro.au; Huan Jin, Jiangxi University of\n",
      "Technology, Nanchang, Jiangxi, China, jinhuan@jxut.edu.cn; Qinying Li, Jiangxi University of Technology, Nanchang,\n",
      "Jiangxi, China, liqinying@jxut.edu.cn.\n",
      ", Vol. 1, No. 1, Article . Publication date: December 2023.arXiv:2312.05772v1  [cs.SE]  10 Dec 20232 Dianshu Liao, Shidong Pan, Qing Huang, Xiaoxue Ren, Zhenchang Xing, Huan Jin, and Qinying Li\n",
      "API in a library) [ 13‚Äì15]. Above all, in contrast to the straightforward LLM-based code generation,\n",
      "developers especially take into account three primary categories of information:\n",
      "1Local Information : This category encompasses information within the current working\n",
      "context, including defined function signatures and variables. It also covers the relative file paths of\n",
      "the module within the project, such as the module‚Äôs Fully Qualified Names (FQNs), like unstruc-\n",
      "tured.documents.html . local information is crucial to ensuring the generated code snippet utilizes\n",
      "accurate variables and operates harmoniously with the other functions in the project.\n",
      "2Global Information : This category involves functions from other code files within the same\n",
      "repository, ac\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Scaling #DNN-Verification Tools with\n",
      "Efficient Bound Propagation and Parallel Computing\n",
      "Luca Marzari*, Gabriele Roncolato and Alessandro Farinelli\n",
      "Department of Computer Science, Univerisity of Verona, Italy\n",
      "Abstract\n",
      "Deep Neural Networks (DNNs) are powerful tools that have shown extraordinary results in many\n",
      "scenarios, ranging from pattern recognition to complex robotic problems. However, their intricate\n",
      "designs and lack of transparency raise safety concerns when applied in real-world applications. In\n",
      "this context, Formal Verification (FV) of DNNs has emerged as a valuable solution to provide provable\n",
      "guarantees on the safety aspect. Nonetheless, the binary answer (i.e., safe orunsafe ) could be not\n",
      "informative enough for direct safety interventions such as safety model ranking or selection. To address\n",
      "this limitation, the FV problem has recently been extended to the counting version, called #DNN-\n",
      "Verification , for the computation of the size of the unsafe regions in a given safety property‚Äôs domain.\n",
      "Still, due to the complexity of the problem, existing solutions struggle to scale on real-world robotic\n",
      "scenarios, where the DNN can be large and complex. To address this limitation, inspired by advances in\n",
      "FV, in this work, we propose a novel strategy based on reachability analysis combined with Symbolic\n",
      "Linear Relaxation and parallel computing to enhance the efficiency of existing exact and approximate FV\n",
      "for DNN counters. The empirical evaluation on standard FV benchmarks and realistic robotic scenarios\n",
      "shows a remarkable improvement in scalability and efficiency, enabling the use of such techniques even\n",
      "for complex robotic applications.\n",
      "Keywords\n",
      "Formal Verification of Deep Neural Network, Safety for Robotics, Parallel Computing\n",
      "1. Introduction\n",
      "In recent years, the use of Deep Neural Networks (DNNs) has increased due to their ability\n",
      "to learn complex patterns from vast amounts of data. In detail, DNNs have emerged as a\n",
      "novel technology revolutionizing various fields ranging from image classification [ 1], robotic\n",
      "manipulation [ 2,3], robotics for medical applications [ 4,5], and even for autonomous navigation\n",
      "[6,7]. As the DNNs become more powerful and pervasive in our applications, the safety aspect\n",
      "has become increasingly prominent. The typical non-linear and non-convex nature of these\n",
      "approximator functions raises two critical concerns: (i) the behavior of these networks is often\n",
      "not comprehensible, leading them to be called \"black boxes\" (ii) slight human-imperceptible\n",
      "changes in the domain of these functions can cause drastic mispredictions that can endanger both\n",
      "the safety aspect of the intelligent agents and the human life in the real-world applications. More\n",
      "AIRO 2023 the 10th Italian Workshop on Artificial Intelligence and Robotics co-located with the 22nd International\n",
      "Conference of the Italian Association for Artificial Intelligence (AI*IA 2023), Rome, Italy\n",
      "*Corresponding author.\n",
      "/envel‚å¢pe-‚å¢penluca.marzari@univr.it (L. Marzari); gabriele.roncolato@studenti.univr.it (G. Roncolato);\n",
      "alessandro.farinelli@univr.it (A. Farinelli)\n",
      "¬©2023 Copyright for this paper by its authors.Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).\n",
      "CEUR\n",
      "Workshop\n",
      "Proceedingshttp://ceur-ws.org\n",
      "ISSN 1613-0073\n",
      "CEUR Workshop Proceedings (CEUR-WS.org)arXiv:2312.05890v1  [cs.AI]  10 Dec 2023specifically, DNNs are vulnerable to the so-called \"adversarial attacks\"[ 8]. To provide the reader\n",
      "with an intuition of what these adversarial inputs are in practice in a robotic scenario, suppose to\n",
      "consider a context where we have a mobile robot trained to navigate in a particular environment.\n",
      "The agent‚Äôs goal is to navigate towards a random target placed in the environment without\n",
      "having access to a map, using only Lidar values to sense the surroundings. In this context,\n",
      "if we train a neural network, for instance, with some Deep Reinforcement Learning (DRL)\n",
      "techniques, it has been shown in [ 9] how, despite empirically achieving a high level of success\n",
      "rate (measured in terms of how many times the agent reaches the goal) and safety (measured in\n",
      "terms of collision rate with obstacles), it is possible to find particular input configurations, that\n",
      "when propagated through the network, lead to suboptimal behaviors, such as the one shown in\n",
      "Fig. 1.\n",
      "(a)\n",
      "(b)\n",
      "Figure 1: Explanatory image of adversarial input in a DRL setup. The robot is trained and is generally able\n",
      "to navigate and reach the yellow target in the environment. FV detects this unsafe input configuration\n",
      "where the agent shows a suboptimal behavior as it is stuck in an infinite alternating loop (a). When an\n",
      "obstacle is added, changing the agent‚Äôs observation, the robot is able to escape from the loop and reach\n",
      "the target (b).\n",
      "To address such an issue, the research field of Formal Verification (FV) of DNNs [ 10], has\n",
      "emerged as a valuable solution to provide formal assurances on the safety aspect of these\n",
      "functions before the actual deployment in real s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Explosive Legged Robotic Hopping: Energy Accumulation and Power\n",
      "Amplification via Pneumatic Augmentation\n",
      "Yifei Chen, Arturo Gamboa-Gonzalez, Michael Wehner, and Xiaobin Xiong\n",
      "Abstract ‚Äî We present a novel pneumatic augmentation to\n",
      "traditional electric motor-actuated legged robot to increase\n",
      "intermittent power density to perform infrequent explosive\n",
      "hopping behaviors. The pneumatic system is composed of a\n",
      "pneumatic pump, a tank, and a pneumatic actuator. The tank\n",
      "is charged up by the pump during regular hopping motion that\n",
      "is created by the electric motors. At any time after reaching\n",
      "a desired air pressure in the tank, a solenoid valve is utilized\n",
      "to rapidly release the air pressure to the pneumatic actuator\n",
      "(piston) which is used in conjunction with the electric motors\n",
      "to perform explosive hopping, increasing maximum hopping\n",
      "height for one or subsequent cycles. We show that, on a custom-\n",
      "designed one-legged hopping robot, without any additional\n",
      "power source and with this novel pneumatic augmentation sys-\n",
      "tem, their associated system identification and optimal control,\n",
      "the robot is able to realize highly explosive hopping with power\n",
      "amplification per cycle by a factor of approximately 5.4 times\n",
      "the power of electric motor actuation alone.\n",
      "I. INTRODUCTION\n",
      "Legged robots, with the ability to make and break ground\n",
      "contact, select contact locations, and modulate gait are able\n",
      "to traverse a broader range of terrains than wheeled or\n",
      "tracked robots. They have shown great potential in search\n",
      "and rescue [1], inspection [2], and exploration in unstructured\n",
      "environments [3]. Although legged robots can have different\n",
      "numbers of legs, joints, and morphologies, their locomotion\n",
      "behaviors are often cyclic, requiring negative work in each\n",
      "cycle of the periodic motion. Taking hopping robots [4] as\n",
      "examples, before accelerating upwards to lift off the ground,\n",
      "the robots must decelerate to a complete stop in the vertical\n",
      "direction in the descending phase by performing negative\n",
      "work on its center of mass.\n",
      "Significant research activities in the literature have been\n",
      "focused on using elastic elements in the system to prevent\n",
      "using actuators to perform negative work, increasing energy\n",
      "efficiency, and reducing the required actuator power in the\n",
      "design. The elastic elements are typically in the form of\n",
      "air springs [4] or mechanical springs [5], [6], [7], [8], [9].\n",
      "The negative work in the descending phase can be stored\n",
      "as spring potential energy and returned to the system in\n",
      "the ascending phase of the cyclic motion. The springs are\n",
      "installed either in series [10], [11], [12] or parallel [13],\n",
      "[14] with the main actuators on the robots; despite this\n",
      "difference, the elastic energy must be stored and released\n",
      "*This work was supported in part by the University of Wisconsin-\n",
      "Madison Office of the Vice Chancellor for Research and Graduate Ed-\n",
      "ucation funded by the Wisconsin Alumni Research Foundation. The\n",
      "authors are with the department of Mechanical Engineering, the Uni-\n",
      "versity of Wisconsin, Madison. Corresponding author: Xiaobin Xiong\n",
      "xiaobin.xiong@wisc.edu . The experiment video can be seen\n",
      "here: https://youtu.be/JObkOIaiOqE\n",
      "Fig. 1. The explosive jumping (right) that is \"warmed up\" by the regular\n",
      "periodic jumping behaviors (left) of the single-legged hopping robot.\n",
      "immediately within one cycle, which prevents the periodic\n",
      "energy accumulation for power amplification to achieve\n",
      "subsequent emergent explosive maneuvers.\n",
      "To address this problem, we propose a design and control\n",
      "framework that augments legged robots with a pneumatic\n",
      "system to accumulate energy during the periods of negative\n",
      "work for storage over multiple cycles. With this system,\n",
      "a pump converts this kinetic energy to potential energy\n",
      "in the form of compressed air pumped to a tank . As an\n",
      "integrated part of the system, no special pumping phase is\n",
      "necessary, as the pump performs its energy conversion during\n",
      "normal locomotion activities. Each cycle pumps additional\n",
      "air, increasing the potential energy in the tank. When the tank\n",
      "has reached a desired pressure (sufficient potential energy),\n",
      "the air can be released, rapidly displacing a pneumatic\n",
      "actuator (converted back to kinetic energy) which is utilized\n",
      "in conjunction with the original actuator to amplify power\n",
      "output for explosive locomotion behaviors.\n",
      "We realize this framework on a single-legged hopping\n",
      "robot that is originally actuated only by electrical motors.\n",
      "We custom-design the pneumatic augmentation system based\n",
      "on the associated physical parameters of the robot. The\n",
      "control of hopping with the pneumatic system is rigorously\n",
      "realized via model-based techniques. With careful system\n",
      "identifications of the pneumatic system, its dynamics can\n",
      "be combined with the canonical rigid-body dynamics model\n",
      "[15] of the robot. We then use a direct collocation method\n",
      "[16], [17], [18] to optimize the trajectories for pneumatically-\n",
      "enhanced (and non-enhanced) hopping behaviors based on a\n",
      "reduced order model. Task space position and for\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "Ensemble Kalman Filtering-Aided Variational\n",
      "Inference for Gaussian Process State-Space Models\n",
      "Zhidi Lin , Yiyong Sun , Feng Yin ,Senior Member, IEEE , and Alexandre Thi ¬¥ery\n",
      "Abstract ‚ÄîGaussian process state-space models (GPSSMs) pro-\n",
      "vide a principled and flexible approach to model latent state\n",
      "dynamics observed through emission models. However, existing\n",
      "variational methods for learning GPSSMs face a substantial\n",
      "challenge in optimizing a large number of parameters, partic-\n",
      "ularly with the introduction of amortized inference networks. To\n",
      "address this challenge, we leverage the ensemble Kalman filter\n",
      "(EnKF), a well-established model-based filtering technique, to\n",
      "approximate the posterior distribution of latent states within the\n",
      "variational inference framework. This approach eliminates the\n",
      "need for inference networks, significantly reducing the number\n",
      "of variational parameters. Moreover, we demonstrate that with\n",
      "the aid of EnKF, the straightforward evaluation of approximated\n",
      "evidence lower bound (ELBO) in the variational inference can\n",
      "be easily obtained through the summation of multiple terms\n",
      "with closed-form solutions. By leveraging automatic differen-\n",
      "tiation tools, we thus can maximize the ELBO and train the\n",
      "GPSSM efficiently. We also extend the proposed method to an\n",
      "online setting and provide comprehensive algorithm analyses\n",
      "and insights. Extensive testing on diverse real and simulated\n",
      "datasets demonstrates that our variational inference algorithms,\n",
      "integrated with EnKF, outperform existing methods in terms of\n",
      "learning and inference performance.\n",
      "Index Terms ‚ÄîGaussian process, state-space model, ensemble\n",
      "Kalman filter, online learning, variational learning and inference.\n",
      "I. I NTRODUCTION\n",
      "STATE-SPACE models (SSMs) are versatile modeling tools\n",
      "used to characterize dynamical patterns in time series\n",
      "data [1]. They have demonstrated successful applications in\n",
      "a wide range of fields, including engineering, statistics, com-\n",
      "puter science, and economics. The primary tasks involved in\n",
      "SSMs are learning and inference [2]. Learning, also known as\n",
      "system identification, focuses on determining optimal model\n",
      "parameters to accurately represent the underlying dynamical\n",
      "system. In contrast, inference aims to estimate latent states of\n",
      "interest based on observed sequential data [1]‚Äì[3].\n",
      "Over the past few decades, numerous learning and inference\n",
      "methods have been developed for SSMs. In cases where the\n",
      "system dynamics are precisely known, various well-established\n",
      "techniques such as the Kalman filter (KF), extended Kalman\n",
      "filter (EKF), ensemble Kalman filter (EnKF) and particle filter\n",
      "(PF) can be employed to infer the latent states [1]. However, in\n",
      "Z. Lin is with the Future Network of Intelligence Institute, and the School\n",
      "of Science & Engineering, The Chinese University of Hong Kong (Shenzhen),\n",
      "Shenzhen 518172, China, and also with the Shenzhen Research Institute of\n",
      "Big Data, Shenzhen 518172, China (email: zhidilin@link.cuhk.edu.cn)\n",
      "Y . Sun and F. Yin are with the School of Science & Engineering, The\n",
      "Chinese University of Hong Kong (Shenzhen), Shenzhen 518172, China\n",
      "(email: yiyongsun@link.cuhk.edu.cn, yinfeng@cuhk.edu.cn). F. Yin is the\n",
      "corresponding author.\n",
      "A. Thi ¬¥ery is with the Department of Statistics & Data Science, National\n",
      "University of Singapore, Singapore 117546 (email: a.h.thiery@nus.edu.sg).complex and uncertain scenarios like model-based reinforce-\n",
      "ment learning [4], [5] and disease epidemic propagation [6],\n",
      "knowing and determining the underlying system dynamics in\n",
      "advance poses tremendous challenges [7]. Thus, the dynamics\n",
      "need to be learned from the observed noisy measurements,\n",
      "leading to the emergence of data-driven state-space models.\n",
      "One class of prominent data-driven state-space models is the\n",
      "Gaussian process state-space model (GPSSM) [8], which uti-\n",
      "lizes Gaussian processes (GPs) as core components to capture\n",
      "the complex dynamics of the underlying system [9].\n",
      "The popularity of GPSSM is largely driven by its inherent\n",
      "appealing properties [8]. First, GPSSM is a probabilistic SSM,\n",
      "offering interpretability and explicit uncertainty calibration for\n",
      "the system dynamics [10]. Second, the nonparametric GP\n",
      "models in GPSSM enable automatic adaptation to problem\n",
      "complexity. Consequently, in practice, GPSSMs often achieve\n",
      "high accuracy in model learning even with limited data [2].\n",
      "Despite the numerous advantageous properties of GPSSMs,\n",
      "the task of learning and inference in GPSSMs remains chal-\n",
      "lenging. Early studies primarily focused on the following two\n",
      "approaches: (1) inferring the latent states through maximum\n",
      "a posteriori (MAP) estimation [10]‚Äì[13], and/or (2) learning\n",
      "GPSSM transition function by assuming the observable latent\n",
      "states [14]‚Äì[16]. However, the MAP estimation is limited to\n",
      "providing a point estimate and often fails to accurately capture\n",
      "the mode of the posterior distribution [3], while assuming\n",
      "observable latent states for learning transition function is often\n",
      "impractical in various applications [17]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Negative Pre-aware for Noisy Cross-modal Matching\n",
      "Xu Zhang1‚Ä†, Hao Li1‚Ä†, Mang Ye2*\n",
      "1School of Computer Science and Engineering, University of Electronic Science and Technology of China\n",
      "2School of Computer Science, Wuhan University\n",
      "{xuzhang.xoe, 18th.leolee, mangye16 }@gmail.com\n",
      "Abstract\n",
      "Cross-modal noise-robust learning is a challenging task since\n",
      "noisy correspondence is hard to recognize and rectify. Due\n",
      "to the cumulative and unavoidable negative impact of unre-\n",
      "solved noise, existing methods cannot maintain a stable per-\n",
      "formance when the noise increases. In this paper, we present a\n",
      "novel Negative Pre-aware Cross-modal (NPC) matching so-\n",
      "lution for large visual-language model fine-tuning on noisy\n",
      "downstream tasks. It is featured in two aspects: (1) For noise\n",
      "recognition and resistance, previous methods usually directly\n",
      "filter out a noise subset, we propose to estimate the negative\n",
      "impact of each sample. It does not need additional correc-\n",
      "tion mechanisms that may predict unreliable correction re-\n",
      "sults, leading to self-reinforcing error. We assign a confidence\n",
      "weight to each sample according to its negative impact in\n",
      "the training process. This adaptively adjusts the contribution\n",
      "of each sample to avoid noisy accumulation. (2) For main-\n",
      "taining stable performance with increasing noise, we utilize\n",
      "the memorization effect of DNNs by maintaining a memory\n",
      "bank. Specifically, we apply GMM to select high-confident\n",
      "clean samples as the memory entry, where the memory entry\n",
      "is used to estimate the negative impact of each sample. Since\n",
      "clean samples are easier distinguished by GMM with increas-\n",
      "ing noise, the memory bank can still maintain high quality at\n",
      "a high noise ratio. Compared to the correction mechanism fo-\n",
      "cusing on noise samples, memory bank-based estimation is\n",
      "more robust, which makes the model performance stable on\n",
      "noisy datasets. Extensive experiments demonstrate that our\n",
      "method significantly improves matching accuracy and perfor-\n",
      "mance stability at increasing noise ratio. Our approach also\n",
      "surpasses the state-of-the-art methods by a large margin.\n",
      "Introduction\n",
      "Cross-modal matching aims to align different modalities\n",
      "(e.g., text and image) within a common space and pair them\n",
      "based on similarity score. With the explosion of multime-\n",
      "dia data, cross-modal matching has gained traction in both\n",
      "industry and academia, e.g., text-to-image generation (Zhou\n",
      "et al. 2022; Ding et al. 2021), image captioning (Li et al.\n",
      "2019b; Stefanini et al. 2022; Wang et al. 2023), and visual\n",
      "question answering (Lin et al. 2022; Lei et al. 2023).\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "*Corresponding author.\n",
      "‚Ä†These authors contributed equally to this work.\n",
      "Annotations\n",
      "AnnotationsMulti -model \n",
      "co-training\n",
      "Rectify\n",
      "Memory bankSelectNegative aware\n",
      "ùë§Training\n",
      "Retrieval RetrievalExisting solution\n",
      "NPC (Ours)\n",
      "Confidence weight\n",
      "ùëÄùêµClean set\n",
      "Noise setùê∑ùê∂\n",
      "ùê∑ùëÅNoise -rectify methods on Flickr30K.\n",
      "(a) Comparison of existing solution and NPC.CLIP -based methods on COCO5K.\n",
      "(b) Comparison of R@1 at different noise ratio.Figure 1: (a) Existing solution vs NPC. (b) Sensitivity\n",
      "of noise-robust learning methods and CLIP-based methods\n",
      "with increasing noise.\n",
      "These works have achieved promising performance by\n",
      "training on large-scale datasets. However, it is expensive to\n",
      "obtain a well-annotated dataset in practical scenarios. The\n",
      "manual-annotated datasets, e.g., MSCOCO (Lin et al. 2014)\n",
      "and Flickr30K (Young et al. 2014), incorporate a significant\n",
      "number of inaccurate descriptions, namely noise correspon-\n",
      "dence. Unlike noise label in classification tasks, the noise\n",
      "here is mismatched cross-modal pairs which is more dif-\n",
      "ficult to deal with, since involves both visual and textual\n",
      "modeling. Therefore, a series of approaches (Huang et al.\n",
      "2021; Yang et al. 2023; Han et al. 2023) following the noise-\n",
      "rectify paradigm have been developed to counter the nega-\n",
      "tive impact of the noise. These methods typically filter out\n",
      "the noise subset from the original training set. Subsequently,\n",
      "they address the noise issue through label correction (Huang\n",
      "et al. 2021; Yang et al. 2023; Han et al. 2023). Neverthe-\n",
      "less, the inherent flaw of the noise-rectify paradigm can-\n",
      "not maintain the performance stability in the existence of\n",
      "severe noise. As shown in Fig. 1(b), we compare the per-\n",
      "formance of different methods using R@1 metric, includ-\n",
      "ing noise-rectify based approaches (Huang et al. 2021; Yang\n",
      "et al. 2023), the large-scale CLIP-based approaches (Rad-\n",
      "ford et al. 2021; Chun 2023) and our approach. We employ\n",
      "variance ( var) of R@1 at different noise ratio to illustrate\n",
      "the ‚Äúperformance stability‚Äù. Obviously, noise-rectify basedarXiv:2312.05777v1  [cs.CV]  10 Dec 2023methods exhibit unstable performance with a considerably\n",
      "larger variance than ours. Additionally, CLIP-based methods\n",
      "also lack consistent performance with increasing noise, even\n",
      "though CLIP is a powerful pre-trained model. Most existing\n",
      "noise-re\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Diffusion for Natural Image Matting\n",
      "Yihan Hu1, Yiheng Lin1, Wei Wang1, Yao Zhao1, Yunchao Wei1‚Ä†, Humphrey Shi2‚Ä†,\n",
      "1Institute of Information Science, Beijing Jiaotong University,2Georgia Tech & Picsart AI Research (PAIR)\n",
      "https://github.com/YihanHu-2022/DiffMatte\n",
      "ùëãùëá ùëãùë° ùëãùë°‚àí1 ùëã0ùëùùúÉ(ùëãùë°‚àí1|ùëãùë°,ùëê)\n",
      "ùëû(ùëãùë°|ùëãùë°‚àí1)c=ùê∂oncùëéùë°(ùêºùëöùëî,ùëáùëüùëñ)\n",
      "Diffusion\n",
      "DecoderArbitrary\n",
      "Matting \n",
      "EncoderDiffusion\n",
      "DecoderDiffusion\n",
      "DecoderDiffusion\n",
      "DecoderAdd\n",
      "Noise\n",
      "c=ùê∂oncùëéùë°(ùêºùëöùëî,ùëáùëüùëñ)\n",
      "Specific\n",
      "Matting \n",
      "Encoder\n",
      "Tightly -coupled\n",
      "Matting Decoder\n",
      "(a) Previous (b) Ours DiffMatte\n",
      "Figure 1. DiffMatte introduces the diffusion process to solve the natural image matting problem. By iteratively correcting the prediction,\n",
      "our method obtains state-of-the-art matting accuracy. DiffMatte can be embedded into arbitrary matting encoders, which makes its appli-\n",
      "cation scenarios more flexible and versatile.\n",
      "Abstract\n",
      "We aim to leverage diffusion to address the challenging\n",
      "image matting task. However, the presence of high compu-\n",
      "tational overhead and the inconsistency of noise sampling\n",
      "between the training and inference processes pose signif-\n",
      "icant obstacles to achieving this goal. In this paper, we\n",
      "present DiffMatte, a solution designed to effectively over-\n",
      "come these challenges. First, DiffMatte decouples the de-\n",
      "coder from the intricately coupled matting network design,\n",
      "involving only one lightweight decoder in the iterations of\n",
      "the diffusion process. With such a strategy, DiffMatte mit-\n",
      "igates the growth of computational overhead as the num-\n",
      "ber of samples increases. Second, we employ a self-aligned\n",
      "training strategy with uniform time intervals, ensuring a\n",
      "consistent noise sampling between training and inference\n",
      "across the entire time domain. Our DiffMatte is designed\n",
      "with flexibility in mind and can seamlessly integrate into\n",
      "various modern matting architectures. Extensive experi-\n",
      "mental results demonstrate that DiffMatte not only reaches\n",
      "the state-of-the-art level on the Composition-1k test set, sur-\n",
      "‚Ä†Corresponding authors.passing the best methods in the past by 5% and 15% in\n",
      "the SAD metric and MSE metric respectively, but also show\n",
      "stronger generalization ability in other benchmarks.\n",
      "1. Introduction\n",
      "Natural image matting is an important task in computer vi-\n",
      "sion, serving the purpose of isolating foreground objects\n",
      "from their backgrounds. Mathematically, a natural image\n",
      "can be expressed as a linear combination of the foreground\n",
      "F‚ààRH√óW√óC, background B‚ààRH√óW√óC, and the alpha\n",
      "matte Œ±‚ààRH√óW, described as:\n",
      "Ii=Œ±iFi+ (1‚àíŒ±i)Bi, Œ±‚àà[0,1], (1)\n",
      "where i‚àà[0, HW ]represents the index of the pixel in\n",
      "the image, H, W, C denote height, width, and the number\n",
      "of channels (3 for a color image) respectively. Since the\n",
      "foreground color Fi, the background color Bi, and the al-\n",
      "pha value Œ±are left unknown, solving for alpha matte is a\n",
      "highly ill-posed problem. To tackle this, deep neural net-\n",
      "works [31, 55, 75, 80] have been widely applied to extract\n",
      "the foreground using a manually labeled trimap as guidance.arXiv:2312.05915v1  [cs.CV]  10 Dec 2023The main challenge of deep learning-based matting so-\n",
      "lutions is how to understand the high-level context knowl-\n",
      "edge and capture the low-level texture information simul-\n",
      "taneously. However, mainstream approaches often focus\n",
      "on either using pre-trained backbones [13, 60, 83] or well-\n",
      "designed modules [12, 46, 74] to enhance the model‚Äôs uti-\n",
      "lization of context information, ignoring the role played by\n",
      "low-level features. This often leads to failures in cases with\n",
      "high and dense uncertainty.\n",
      "Recently, diffusion probabilistic models [29, 70, 71]\n",
      "have emerged and shown great potential for application and\n",
      "research value with high-fidelity and fine-grained genera-\n",
      "tion [16, 58]. Due to the unique iterative diffusion process,\n",
      "we note that diffusion-generative methods naturally excel in\n",
      "modeling highly complex data distributions and generating\n",
      "realistic texture details. These methods obtain the training\n",
      "samples by adding noise to the clean data, which is used to\n",
      "train the denoising ability of the diffusion model and obtain\n",
      "the prediction results by gradually denoising the signal dur-\n",
      "ing the inference. As shown in Figure ??We believe such\n",
      "an iterative diffusion process of destroying and reconstruct-\n",
      "ing can effectively perceive texture details, which is highly\n",
      "suitable for addressing the matting task.\n",
      "However, to the best of our knowledge, no pioneer art has\n",
      "successfully adapted the diffusion process to matting mod-\n",
      "els. We believe that this is due to two reasons. First, high\n",
      "computational overhead. Existing matting models, in order\n",
      "to take into account the context knowledge and texture fea-\n",
      "ture, usually adopt a tightly coupled UNet-like design while\n",
      "receiving original-sized images in the inference. This diffi-\n",
      "culty will be further exacerbated by the direct introduction\n",
      "of such a matting model into the diffusion process. Second,\n",
      "inconsistent noise sampling between the training and infer-\n",
      "ence processes. During training, diffusion involves con-\n",
      "sistently introduci\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Guiding ChatGPT to Fix Web UI Tests via\n",
      "Explanation-Consistency Checking\n",
      "Zhuolin Xu\n",
      "Concordia University\n",
      "Canada\n",
      "zhuolin.xu@mail.concordia.caYuanzhang Lin\n",
      "Beihang University\n",
      "China\n",
      "linyz2020@gmail.com\n",
      "Qiushi Li\n",
      "Concordia University\n",
      "Canada\n",
      "qiushili2021@gmail.comShin Hwei Tan\n",
      "Concordia University\n",
      "Canada\n",
      "shinhwei.tan@concordia.ca\n",
      "ABSTRACT\n",
      "The rapid evolution of Web UI incurs time and effort in maintaining\n",
      "UI tests. Existing techniques in Web UI test repair focus on finding\n",
      "the target elements on the new web page that match the old ones\n",
      "so that the corresponding broken statements can be repaired. We\n",
      "present the first study that investigates the feasibility of using prior\n",
      "Web UI repair techniques for initial local matching and then using\n",
      "ChatGPT to perform global matching. Our key insight is that given\n",
      "a list of elements matched by prior techniques, ChatGPT can lever-\n",
      "age the language understanding to perform global view matching\n",
      "and use its code generation model for fixing the broken statements.\n",
      "To mitigate hallucination in ChatGPT, we design an explanation\n",
      "validator that checks whether the provided explanation for the\n",
      "matching results is consistent, and provides hints to ChatGPT via a\n",
      "self-correction prompt to further improve its results. Our evalua-\n",
      "tion on a widely used dataset shows that the ChatGPT-enhanced\n",
      "techniques improve the effectiveness of existing Web test repair\n",
      "techniques. Our study also shares several important insights in\n",
      "improving future Web UI test repair techniques.\n",
      "ACM Reference Format:\n",
      "Zhuolin Xu, Yuanzhang Lin, Qiushi Li, and Shin Hwei Tan. 2023. Guiding\n",
      "ChatGPT to Fix Web UI Tests via Explanation-Consistency Checking. In\n",
      "Proceedings of ACM Conference (Conference‚Äô17). ACM, New York, NY, USA,\n",
      "12 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn\n",
      "1 INTRODUCTION\n",
      "When developers change the attributes of user interfaces (UI) of\n",
      "a Web application due to the rapidly changing requirements, the\n",
      "corresponding Web UI tests need to be manually updated for test\n",
      "maintenance. To reduce manual efforts in repairing broken Web UI\n",
      "tests, several automated approaches have been proposed [ 7,26,41].\n",
      "The key step in automated repair of Web UI tests is to modify the\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for components of this work owned by others than ACM\n",
      "must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\n",
      "to post on servers or to redistribute to lists, requires prior specific permission and/or a\n",
      "fee. Request permissions from permissions@acm.org.\n",
      "Conference‚Äô17, July 2017, Washington, DC, USA\n",
      "¬©2023 Association for Computing Machinery.\n",
      "ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00\n",
      "https://doi.org/10.1145/nnnnnnn.nnnnnnnbroken statements containing outdated element locators by match-\n",
      "ing the element ùëíùëúùëôùëëin the old version of a Web application with\n",
      "the element in the new version ùëíùëõùëíùë§[14]. Prior Web UI test repair\n",
      "techniques mostly rely on a set of Document Object Model (DOM)\n",
      "attributes (e.g., identifiers and XPath) [ 7] or visual information [ 41]\n",
      "to determine whether the two elements ùëíùëúùëôùëëandùëíùëõùëíùë§match. These\n",
      "techniques extract and compute the similarity of these information\n",
      "to select the most similar element as the result of the matching.\n",
      "As there can be many attributes of a Web UI element which can\n",
      "be used for matching, these techniques may prioritize certain at-\n",
      "tributes. For example, Water , one of the classical Web UI test repair\n",
      "techniques, performs matching via several steps by using different\n",
      "sets of attributes in each step. First, it searches for elements that\n",
      "are exactly the same by matching five attributes ( id,XPath ,class,\n",
      "linkText ,name ). If the first step fails to find the matching element\n",
      "in the new version that makes the test pass, it then finds similar\n",
      "DOM nodes using other additional attributes. Specifically, it finds\n",
      "the element with the same tagname , and then computes the similar-\n",
      "ity between the element with the same tagname using normalized\n",
      "Levenshtein distance between the XPaths of ùëíùëúùëôùëëandùëíùëõùëíùë§. Then,\n",
      "it further matches using other attributes (e.g., screen position of a\n",
      "DOM node), and computes a similarity score based on the weighted\n",
      "sum of XPath and other attributes where it prioritizes XPath simi-\n",
      "larity based on the heuristic that the XPaths of the nodes ‚Äúshould\n",
      "be very similar across versions‚Äù [ 7]). As the prioritization and the\n",
      "predefined order used for matching these set of attributes are usu-\n",
      "ally based on heuristic made by the tool developers, the matching\n",
      "algorithm may not accurately reflect the evolution of the Web ele-\n",
      "ment , causing inaccuracy in the matching step, and subsequently\n",
      "unable to find the repair for the broken statement. Meanwhile, prior\n",
      "learning-based techniques show promising results in c\n",
      "----------------------------------------------------------------------------------------------------\n",
      "arXiv:2312.05919v1  [cs.LO]  10 Dec 2023ALogical Frameworkwith Infinitary Terms\n",
      "ZHIBOCHEN ,Carnegie MellonUniversity, USA\n",
      "Logicalframeworksaresuccessfulinmodelingproofsystem s.Recently,CoLFextendedthelogicalframework\n",
      "LF to supporthigher-order rational terms that enable adequ ateencoding of circular objects and derivations.\n",
      "In this paper, we propose CoLF/u1D714as an alternative interpretation of CoLF-style signatures where terms are\n",
      "taken tobeall possiblyinÔ¨Ånitary terms that are consistent with a given signature. In particular,we propose\n",
      "the notion of productive B√∂hm trees, a particular kind of typ ed‚ä•-free B√∂hm trees that are closed under\n",
      "hereditary substitution. We show that the productive B√∂hm t rees are capable of meta-encoding their own\n",
      "structure. Overall, we hope to establish CoLF/u1D714as a new formal framework for the encoding of inÔ¨Ånitary\n",
      "regular and non-regular structures.\n",
      "1 INTRODUCTION\n",
      "InÔ¨Ånite objects are representable in the logical framework LF b y indexing a type family with a\n",
      "natural number as its observation depth. For example, in the fo llowing signature, the stream of\n",
      "natural numbers whose Ô¨Årst /u1D458elements can be observed is in compositional bijection with th e\n",
      "canonicaltermsofthe typefamily stream(succ/u1D458zero).\n",
      "nat : type.\n",
      "zero : nat.\n",
      "succ : nat -> nat.\n",
      "stream : nat -> type.\n",
      "unobservable : stream zero.\n",
      "cocons : {k : nat} nat -> stream k -> stream (succ k).\n",
      "The encoding is hard to work with, because the observation dept h of the stream needs to be\n",
      "tracked everywhere a stream is used. CoLF [ Chenand Pfenning 2023 ] is an extension of the log-\n",
      "ical framework LF that supports natural and adequate encodings o f circular objects and circular\n",
      "derivations.Tomaketypecheckingdecidable,CoLFlimitsits termmodeltohigher-orderrational\n",
      "terms. This limitation has the shortcoming that objects with out a regular structure cannot be ad-\n",
      "equatelyrepresented inCoLF.Forexample,thestreamofnatur alnumberswithrepeating 1‚Äôsand\n",
      "2‚Äôs, 1,2,1,2,..., can be encoded in CoLF because it has a regular structure, i.e . the stream can be\n",
      "given by the equation /u1D446=1,2,/u1D446. The stream of natural numbers counting up from 1,1 ,2,3,4,...,\n",
      "cannotbe encodedin CoLFbecauseit doesnot have a regularstruct ure, i.e. the stream cannotbe\n",
      "given by a system of equations. In this paper, we develop a new ty pe theory CoLF/u1D714, which pro-\n",
      "videsanalternativetermmodelforCoLF-stylesignatureswhe retermsaretakentobeallpossibly\n",
      "inÔ¨Ånitary terms.Manymoreinteresting inÔ¨Ånitary objectscanbeenco dedinCoLF/u1D714thanin CoLF.\n",
      "Themain contributions ofthispaper are:\n",
      "‚Ä¢A formulationofinÔ¨Ånitary syntaxtrees (Section 3).\n",
      "‚Ä¢A deÔ¨Ånition ofproductive B√∂hmtreesvia theinÔ¨Ånitary syntaxtre es (Section 4).\n",
      "‚Ä¢Thetypetheoryof CoLF/u1D714,whosetermsare productive B√∂hmtrees(Section 5).\n",
      "‚Ä¢An interpretation of (adapted)Ô¨Ånitary signatures ofCoLFinto C oLF/u1D714(Section6).\n",
      "‚Ä¢A meta-encodingof the productive B√∂hmtreesusing CoLF/u1D714signatures (Section 7).\n",
      "‚Ä¢A casestudy onco-naturalnumbersand co-binarynumbersusing CoLF/u1D714(Section8).\n",
      "2 EXAMPLES OF COLF/u1D714\n",
      "WeillustrateinformallytheinÔ¨ÅnitarytermmodelofCoLF/u1D714,andhowitisdiÔ¨Äerent fromtheratio-\n",
      "nal termmodelofCoLF.\n",
      "1Zhibo Chen\n",
      "2.1 Streams\n",
      "Consider the followingCoLFsignature for deÔ¨Åning streamsof natur al numbers.\n",
      "nat : type.\n",
      "zero : nat.\n",
      "succ : nat -> nat.\n",
      "stream : cotype.\n",
      "cocons : nat -> stream -> stream.\n",
      "InCoLF,theonlytermsare rationalterms ,i.e.termshavingÔ¨Ånitelymanysubtermsuptorenam-\n",
      "ingoffreeandboundvariables.Canonicaltermsoftype streamarerational.Asaconsequence,we\n",
      "canonlyrepresentrationalstreams(streamswithÔ¨Ånitelymanydi stinctrepeatingpatterns)inthe\n",
      "framework. A stream that counts up from a certain natural number or a stream that enumerates\n",
      "all Fibonacci numbers is not a term of type streamin CoLF. However, in CoLF/u1D714, all streams are\n",
      "inÔ¨Ånitarytermsconsistentwiththesignature.Thatis,thecanonic altermsoftype streaminclude\n",
      "allpossible streams, andthere are uncountablymanyofthem.\n",
      "There is a question of whether noncomputable streams are also r epresented in the canonical\n",
      "terms. For example, temperature readings from a measurement d evice can be a stream of natural\n",
      "numbers that is not computable. We choose to leave open the ques tion of computability inten-\n",
      "tionally in the hope that the development of CoLF/u1D714can be used to encode either computable or\n",
      "noncomputableobjects,aslongasthe choiceismade consistently .\n",
      "While the canonical terms of type streamcan be any stream, we may specify the streams we\n",
      "actually care about using predicates. For instance, we can spec ify a stream that counts up from\n",
      "thenaturalnumber nbysayingthatthestream Sisatermoftype streamsuchthat up n Sholds,\n",
      "whereupis the predicate deÔ¨Åned below.\n",
      "up : nat -> stream -> cotype.\n",
      "up/def : {N : nat} {S : stream} up (succ N) S\n",
      "-> up N (cocons N S).\n",
      "A term of type up N S must be a term of the form up/def N (cocons N S/quotesingle.Var) U , where\n",
      "S = cocons N S/quotesingle.Var ,andUis a term of type up (succ N) S/quotesingle.Var .In fact, there is \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Autotuning by Changing Direct ives and Number of Threads  \n",
      "in OpenMP using ppOpen-AT \n",
      "Toma Sakurai \n",
      " Graduate School of Informatics \n",
      "Nagoya University \n",
      "Japan  Satoshi Ohshima \n",
      "Information Technology Center \n",
      "Nagoya University \n",
      "Japan  \n",
      "Takahiro Katagiri \n",
      "Information Technology Center \n",
      "Nagoya University \n",
      "Japan \n",
      "Contact: katagiri@cc.nagoya-u.ac.jp  Toru Nagai \n",
      "Information Technology Center \n",
      "Nagoya University \n",
      "Japan \n",
      "This is a preprint paper ( unrefreed) as of October 6th, 2020.  \n",
      " \n",
      "  \n",
      " \n",
      " \n",
      "Abstract ‚Äî Recently, computers have diversified architectures. \n",
      "To achieve high numerical calculation software performance, \n",
      "it is necessary to tune the software according to the target \n",
      "computer architecture. However, code optimization for each \n",
      "environment is difficult unless it is performed by a specialist \n",
      "who knows computer architectures well. By applying \n",
      "autotuning (AT), the tuning effort can be reduced. Optimized \n",
      "implementation by AT that enhances computer performance \n",
      "can be used even by non-experts. In this research, we propose \n",
      "a technique for AT for programs using open multi-processing \n",
      "(OpenMP). We propose an AT method using an AT language \n",
      "that changes the OpenMP opti mized loop and dynamically \n",
      "changes the number of threads in OpenMP according to \n",
      "computational kernels. Performance evaluation was \n",
      "performed using the Fujitsu PRIMEHPC FX100, which is a \n",
      "K-computer type supercomputer installed at the Information \n",
      "Technology Center, Nagoya University. As a result, we found \n",
      "there was a performance increase of 1.801 times that of the \n",
      "original code in a plasma turbulence analysis.  \n",
      "Keywords‚Äî Autotuning; Loop Transformation; Dynamic \n",
      "Thread Optimization; ppOpen-AT; \n",
      "I. INTRODUCTION  \n",
      "In recent years, mainstream computer architectures have \n",
      "become multi-core central processing unit (CPU) \n",
      "architectures that include hierarchical memory structures \n",
      "and caches. The presence or absence of a graphics \n",
      "processing unit (GPU) varies. Software tuning is important to achieve high numerical computation software \n",
      "performance, but optimization for the computing environment requires specialized knowledge of hardware \n",
      "architectures. It is time-consuming work. In addition, \n",
      "programs tuned specifically for one environment may have \n",
      "poor performance in other environments, requiring further performance tuning. In addition, widely used compiler \n",
      "optimizations are often not useful for software developers for code optimization due to lack of knowledge of the \n",
      "compiler code. \n",
      "Software autotuning (AT) [1], which is one of the code \n",
      "optimization technologies, automates performance tuning \n",
      "for programs. By using this technology, it is possible to achieve high performance with the same program in \n",
      "different environments. It is also possible to improve the \n",
      "performance portability of software. Therefore, in recent \n",
      "years, many numerical calculation software applications using AT have been developed [2][3][4]. In addition, AT \n",
      "frameworks have been proposed for creating numerically tuned software with AT. Typical examples include \n",
      "OpenTuner [5], Xevolver [6], and FIBER [7]. \n",
      "In this study we propose and evaluate the following three \n",
      "contents: \n",
      "1. Propose an AT function for OpenMP directives for an \n",
      "AT language. \n",
      "2. Propose an AT function to dynamically change the \n",
      "number of OpenMP threads. \n",
      "3. Evaluate the efficiency for 1 and 2. \n",
      "This paper is organized as follows. Section II explains \n",
      "the framework of the AT software and the AT languages for \n",
      "the paper. Section III proposes an AT function for \n",
      "exchanging OpenMP directives. Section IV also proposes an AT function to dynamically change the number of \n",
      "OpenMP threads. Section V evaluates the total efficiency \n",
      "for the two new functions. Section VI summarizes related work and finally, Section VII describes the conclusion to \n",
      "this paper.   \n",
      "II. F\n",
      "IBER FRAMEWORK AND AT LANGAGE PPOPEN -AT \n",
      "A. FIBER \n",
      "FIBER (framework of installation, before execution, and \n",
      "run-time optimization layers) [7] is an AT framework for use in numerical calculation software. This framework is a \n",
      "software configuration method that can perform AT at the \n",
      "following three time points (layers). \n",
      "1. Installation: optimization hierarchy when installing a \n",
      "library. \n",
      "2. Before execution: optimization hierarchy whose \n",
      "parameters (problem size, the number of processes for \n",
      "message passing interface (MPI), and number of OpenMP threads) have been determined by the user. \n",
      "3. Run-time: optimization hierarchy when a library is \n",
      "executed. \n",
      "With the above hierarchy, it is possible to increase the \n",
      "number of applications to which AT is applied and improve \n",
      "the accuracy of parameter estimation. \n",
      "FIBER supports the following two functions. \n",
      "1. A function that generates code that performs AT, \n",
      "parameterizes code, and registers parameters by giving \n",
      "instructions to the user's program using a dedicated \n",
      "language. \n",
      "2. Parameter optimization in each hierarchy. \n",
      "AT in FIBER is determined by the basic parameter set, \n",
      "the performance parameter set, and the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "Dig-CSI: A Distributed and Generative Model\n",
      "Assisted CSI Feedback Training Framework\n",
      "Zhilin Du, Haozhen Li, Graduate Student Member, IEEE , Zhenyu Liu, Member, IEEE , Shilong Fan,\n",
      "Xinyu Gu, Member, IEEE , and Lin Zhang, Member, IEEE\n",
      "Abstract ‚ÄîThe advent of deep learning (DL)-based models has\n",
      "significantly advanced Channel State Information (CSI) feed-\n",
      "back mechanisms in wireless communication systems. However,\n",
      "traditional approaches often suffer from high communication\n",
      "overhead and potential privacy risks due to the centralized nature\n",
      "of CSI data processing. To address these challenges, we design\n",
      "a CSI feedback training framework called Dig-CSI, in which\n",
      "the dataset for training the CSI feedback model is produced\n",
      "by the distributed generators uploaded by each user equipment\n",
      "(UE), but not through local data upload. Each UE trains an\n",
      "autoencoder, where the decoder is considered as the distributed\n",
      "generator, with local data to gain reconstruction accuracy and the\n",
      "ability to generate. Experimental results show that Dig-CSI can\n",
      "train a global CSI feedback model with comparable performance\n",
      "to the model trained with classical centralized learning with a\n",
      "much lighter communication overhead.\n",
      "Index Terms ‚ÄîMassive MIMO, Generative Neural Network,\n",
      "CSI Feedback, Distributed System\n",
      "I. I NTRODUCTION\n",
      "IN a massive multiple-input multiple-output system\n",
      "(MIMO) with frequency division duplex (FDD) mode, the\n",
      "base station (BS) requires channel state information (CSI)\n",
      "from user equipment (UE). The transmission of CSI (namely\n",
      "CSI feedback task) includes compression and reconstruction\n",
      "of the CSI matrix to save the wireless channel source. Deep\n",
      "learning (DL) based CSI feedback has achieved remarkable\n",
      "success with many deep neural network (DNN) models pro-\n",
      "posed [1] [2] [3]. These models can obtain high reconstruction\n",
      "accuracy of CSI matrices within a certain area.\n",
      "In a real deployment, the model is trained at a server with\n",
      "a prepared CSI dataset and is then sent to each UE and BS,\n",
      "which is named centralized learning (CL). The construction of\n",
      "the dataset is crucial in CL, which is either through asking each\n",
      "UE to upload the locally produced CSI matrices as depicted\n",
      "in Fig.1(a) or through channel measurement that utilizes\n",
      "specialized equipment to collect CSI matrices. In the former\n",
      "method, the communication overhead between the UE and the\n",
      "server is too heavy and the privacy of the UE is susceptible to\n",
      "leakage while in the latter method, the equipment is expensive\n",
      "and the collection activity is time-consuming and laborious.\n",
      "This work was supported in part by the National Key Research and\n",
      "Development Program under Grant 2022YFF0610303, and in part by the\n",
      "National Natural Science Foundation of China (NSFC) under Grant 62201089.\n",
      "Z. Du, H. Li, Z. Liu, S.Fan, L. Zhang, X. Gu are with the School of\n",
      "Artificial Intelligence, Beijing University of Posts and Telecommunications,\n",
      "Beijing, X. Gu is also with the Purple Mountain Laboratories, Nanjing 211111,\n",
      "China. 100876, China (e-mail: {duzhilin, lihaozhen, lzyu, fanshilong, guxinyu,\n",
      "zhanglin }@bupt.edu.cn).In terms of these flaws of CL for DL-based CSI feedback,\n",
      "Federated Learning (FL) is introduced by [4] and [5] as\n",
      "an improved training method which is depicted in Fig.1(b),\n",
      "where each UE trains its model with local data and uploads\n",
      "it to the server and the server aggregates these models to\n",
      "produces a global model for each UE to continue training.\n",
      "Adopting FL for DL-based CSI feedback alleviates UE from\n",
      "uploading local data to the server, which greatly reduces the\n",
      "communication overhead generated in CL and protects the\n",
      "privacy of UE. However, as FL needs several iterations to\n",
      "converge, the overhead of transmitting the model between a\n",
      "UE and the server rises by times as the iteration increases.\n",
      "Moreover, the FL algorithm FedAvg [6] used in [4] and [5] that\n",
      "merely averages the parameters of each local model encounters\n",
      "a severe problem of client drift [7] that harms the performance\n",
      "of the model when the channel state of each UE obviously\n",
      "differs.\n",
      "In this paper, we propose a novel training framework that\n",
      "involves distributed generative model for CSI feedback (Dig-\n",
      "CSI) which is depicted in Fig.1(c). Dig-CSI absorbs the advan-\n",
      "tage of FL which uploads local models to save communication\n",
      "overhead and make sure the global model can be trained as in\n",
      "CL through a generative local model, which solves the client\n",
      "drift problem in FL. Additionally, the model in Dig-CSI only\n",
      "needs to be uploaded once, therefore significantly reducing\n",
      "the communication overhead in FL. We use the structure of\n",
      "autoencoder to implement the local model and adopt sliced\n",
      "Wasserstein distance introduced in [8] to train the distributed\n",
      "generator. We set a scenario where multiple UEs participate\n",
      "in CSI feedback training and deploy CL, FL, and Dig-CSI on\n",
      "it. Experimental results show that Dig-CSI achieves the least\n",
      "communication overhead and has a comparable performance\n",
      "as CL.\n",
      "II. S YSTEM MODEL\n",
      "Supposing that in an FDD Massive MIMO syst\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PULSAR: Graph based P ositive U nlabeled L earning with Multi S tream A daptive\n",
      "Convolutions for Parkinson‚Äôs Disease R ecognition\n",
      "Md. Zarif Ul Alam1, Md Saiful Islam2, Ehsan Hoque2, M Saifur Rahman1\n",
      "1Bangladesh University of Engineering and Technology, Bangladesh\n",
      "2University of Rochester, United States\n",
      "Abstract\n",
      "Parkinson‚Äôs disease (PD) is a neuro-degenerative disorder that\n",
      "affects movement, speech, and coordination. Timely diag-\n",
      "nosis and treatment can improve the quality of life for PD\n",
      "patients. However, access to clinical diagnosis is limited in\n",
      "low and middle income countries (LMICs). Therefore, de-\n",
      "velopment of automated screening tools for PD can have\n",
      "a huge social impact, particularly in the public health sec-\n",
      "tor. In this paper, we present PULSAR, a novel method to\n",
      "screen for PD from webcam-recorded videos of the finger-\n",
      "tapping task from the Movement Disorder Society - Unified\n",
      "Parkinson‚Äôs Disease Rating Scale (MDS-UPDRS). PULSAR\n",
      "is trained and evaluated on data collected from 382 partici-\n",
      "pants (183 self-reported as PD patients). We used an adap-\n",
      "tive graph convolutional neural network to dynamically learn\n",
      "the spatio temporal graph edges specific to the finger-tapping\n",
      "task. We enhanced this idea with a multi stream adaptive con-\n",
      "volution model to learn features from different modalities of\n",
      "data critical to detect PD, such as relative location of the fin-\n",
      "ger joints, velocity and acceleration of tapping. As the labels\n",
      "of the videos are self-reported, there could be cases of un-\n",
      "diagnosed PD in the non-PD labeled samples. We leveraged\n",
      "the idea of Positive Unlabeled (PU) Learning that does not\n",
      "need labeled negative data. Our experiments show clear ben-\n",
      "efit of modeling the problem in this way. PULSAR achieved\n",
      "80.95% accuracy in validation set and a mean accuracy of\n",
      "71.29% (2.49% standard deviation) in independent test, de-\n",
      "spite being trained with limited amount of data. This is spe-\n",
      "cially promising as labeled data is scarce in health care sector.\n",
      "We hope PULSAR will make PD screening more accessible\n",
      "to everyone. The proposed techniques could be extended for\n",
      "assessment of other movement disorders, such as ataxia, and\n",
      "Huntington‚Äôs disease.\n",
      "Introduction\n",
      "Parkinson‚Äôs disease (PD) is one of the common degenera-\n",
      "tive diseases of the nervous system (Ji et al. 2018). It is\n",
      "characterized by a variety of life-changing motor dysfunc-\n",
      "tion symptoms, including tremor, Bradykinesia (slowness of\n",
      "movement), rigidity (limb stiffness), impaired balance and\n",
      "gait, etc. Over 10 million people worldwide are affected by\n",
      "PD (Wikipedia contributors 2022). In 2016, PD resulted in\n",
      "about 211,000 deaths globally, an increase of 161% since\n",
      "1990. The diagnosis of PD mainly relies on clinical criteria\n",
      "based on the Parkinsonian symptoms (e.g., tremor, Bradyki-\n",
      "nesia), and medical history. However, the clinical diagnostic\n",
      "is challenged by the subjective opinions or experiences ofdifferent medical experts. In addition, it is not accessible to\n",
      "many individuals since the number of neurologists is very\n",
      "limited in some countries (Kissani et al. 2022). Therefore,\n",
      "an efficient and remote automatic PD diagnosis system is\n",
      "valuable for supporting clinicians with more robust diagnos-\n",
      "tic decision-making.\n",
      "With the advancement in computer vision technology,\n",
      "sensing of subtle movement of face and body has become\n",
      "possible, and this has the potential to lead to important medi-\n",
      "cal and physiological implications. However, healthcare data\n",
      "(specially, data from individuals with PD) is hard to ob-\n",
      "tain and the small size of the datasets limits application of\n",
      "state-of-the art machine learning models. Here we introduce\n",
      "PULSAR ‚Äì a graph neural network based deep learning ar-\n",
      "chitecture that can be trained with limited data. In addition,\n",
      "in a dataset that uses patient-reported PD diagnosis as the\n",
      "ground truth, ‚Äúnegative‚Äù data samples remain unreliable ‚Äì\n",
      "many people live with PD without being diagnosed. In con-\n",
      "text of healthcare this is very common. Rather than expect-\n",
      "ing clean data, we focused on dealing with the problem ob-\n",
      "jectively. To the best of our knowledge, we are the first to\n",
      "explore Positive Unlabeled (PU) learning in the context of\n",
      "PD screening, which eliminates the need for reliable ‚Äúneg-\n",
      "ative‚Äù samples. An overview of the PD screening pipeline\n",
      "leveraging PULSAR model is shown in Figure 1. PULSAR\n",
      "has been tested through a comprehensive set of experiments,\n",
      "the results of which support its efficacy. As many movement\n",
      "disorders (e.g., ataxia, Huntington‚Äôs disease) share similar-\n",
      "ity in terms of the tasks used for screening/diagnosis and\n",
      "data collection, our proposed approach could be applied for\n",
      "those diseases, potentially improving access to neurological\n",
      "care. In this regard, the data processing and model training\n",
      "codes and the processed de-identified dataset will be made\n",
      "publicly available upon acceptance of the paper.\n",
      "In summary, we make the following contributions:\n",
      "‚Ä¢ We propose a novel multi stream adaptive convolution\n",
      "model which allows PD scr\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Weakly Supervised Video Individual Counting\n",
      "Xinyan Liu1Guorong Li1*Yuankai Qi2Ziheng Yan1\n",
      "Zhenjun Han1Anton van den Hengel2Ming-Hsuan Yang5Qingming Huang1,3,4\n",
      "1University of Chinese Academy of Science, Beijing, China\n",
      "2Australian Institute for Machine Learning, The University of Adelaide\n",
      "3Key Lab of Intell. Info. Process., Inst. of Comput. Tech., CAS, Beijing, China\n",
      "4Peng Cheng Laboratory, Shenzhen, China,5University of California, Merced\n",
      "{liuxinyan19,yanziheng21 }@mails.ucas.ac.cn, {liguorong, hanzhj, qmhuang }@ucas.ac.cn, qykshr@gmail.com,\n",
      "Anton.vandenHengel@adelaide.edu.au, mhyang@ucmerced.edu\n",
      "Abstract\n",
      "Video Individual Counting (VIC) aims to predict the\n",
      "number of unique individuals in a single video. Existing\n",
      "methods learn representations based on trajectory labels\n",
      "for individuals, which are annotation-expensive. To provide\n",
      "a more realistic reflection of the underlying practical chal-\n",
      "lenge, we introduce a weakly supervised VIC task, wherein\n",
      "trajectory labels are not provided. Instead, two types of la-\n",
      "bels are provided to indicate traffic entering the field of view\n",
      "(inflow) and leaving the field view (outflow). We also pro-\n",
      "pose the first solution as a baseline that formulates the task\n",
      "as a weakly supervised contrastive learning problem under\n",
      "group-level matching. In doing so, we devise an end-to-end\n",
      "trainable soft contrastive loss to drive the network to distin-\n",
      "guish inflow, outflow, and the remaining. To facilitate future\n",
      "study in this direction, we generate annotations from the ex-\n",
      "isting VIC datasets SenseCrowd and CroHD and also build\n",
      "a new dataset, UAVVIC. Extensive results show that our\n",
      "baseline weakly supervised method outperforms supervised\n",
      "methods, and thus, little information is lost in the transition\n",
      "to the more practically relevant weakly supervised task. The\n",
      "code and trained model will be public at CGNet\n",
      "1. Introduction\n",
      "Video Crowd Counting (VCC) has garnered much interest\n",
      "due to its broad range of practical applications, particularly\n",
      "in crowd safety management. This task requires a model\n",
      "to count the number of people in each frame of a video. A\n",
      "limitation of VCC [12, 51, 53] is that it gives an imprecise\n",
      "estimate of the number of unique individuals appearing in\n",
      "a video sequence, as people are counted multiple times if\n",
      "they appear in several frames. To overcome this drawback,\n",
      "*Corresponding author.\n",
      "(a) Annotation of VIC method\n",
      " (b) Annotation of our method\n",
      "Figure 1. Existing VIC method requires a unique label indicat-\n",
      "ing the position of each human in each frame, and these labels\n",
      "are consistent across frames. Weakly supervised VIC only re-\n",
      "quires labels indicating each human position and whether they\n",
      "are an inflow/outflow pedestrian (purple/yellow in (b)) in the cur-\n",
      "rent frame. The transition from individual-level labels to identity-\n",
      "agnostic group-level labels represents a significant reduction in the\n",
      "labeling effort.\n",
      "Video Individual Counting (VIC) was introduced, wherein\n",
      "a method must count the total number of people with unique\n",
      "identities appearing in a video sequence.\n",
      "The apparent approach to crowd counting is to count\n",
      "the people who appear in the first frame and add the num-\n",
      "ber of people who come into the camera‚Äôs field of view in\n",
      "later frames (the inflow). Following this principle, Han et\n",
      "al. [14] devised DRNet, the only existing published method\n",
      "for VIC, identifying repeated observations of individuals\n",
      "across consecutive frames based on their appearance, simul-\n",
      "taneously predicting inflow and outflow. Although the num-\n",
      "ber of outflows does not contribute to the final count, DR-\n",
      "Net finds it helps determine individual associations. Han et\n",
      "al. [14] also explored using conventional multi-object track-\n",
      "ing (MOT) methods [7, 41, 44, 54, 56] to tackle the VIC\n",
      "problem. Unfortunately, it turns out MOT methods suffer\n",
      "from poor accuracy. More notably, DRNet and MOT-based\n",
      "methods require trajectory labels (or similar individual as-\n",
      "1arXiv:2312.05923v1  [cs.CV]  10 Dec 2023sociation labels) to supervise identity association, which is\n",
      "highly annotation-expensive.\n",
      "Our key insight is that counting people in the previous\n",
      "and current frames does not require accurate identity asso-\n",
      "ciations for those appearing in both frames. For example,\n",
      "as long as we can predict individual 15 ‚àº17 as entering in\n",
      "Fig. 1a, even if we arbitrarily associate individuals 0 ‚àº14 in\n",
      "frame ito individuals 0 ‚àº14 in frame i, we can still correctly\n",
      "infer the crowd counts. We can still count crowds if we relax\n",
      "individual-level identity associations to group-level associ-\n",
      "ations and do not require trajectory annotations. Thus, we\n",
      "just need to annotate inflow and outflow people (then we can\n",
      "derive the individual exists in two frames), which reduces\n",
      "annotation costs compared to creating individual pairwise\n",
      "target associations for each observed pedestrian between\n",
      "neighboring frames. We name crowd counting with such\n",
      "annotations as Weakly supervised Video Individual Count-\n",
      "ing (WVIC).\n",
      "To address the WVIC task, we propose a benchmark\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DCIR: Dynamic Consistency Intrinsic Reward for\n",
      "Multi-Agent Reinforcement Learning\n",
      "Kunyang Lin1Yufeng Wang1Peihao Chen1\n",
      "Runhao Zeng2Siyuan Zhou3Mingkui Tan1Chuang Gan4\n",
      "Abstract\n",
      "Learning optimal behavior policy for each agent\n",
      "in multi-agent systems is an essential yet difficult\n",
      "problem. Despite fruitful progress in multi-agent\n",
      "reinforcement learning, the challenge of address-\n",
      "ing the dynamics of whether two agents should ex-\n",
      "hibit consistent behaviors is still under-explored.\n",
      "In this paper, we propose a new approach that\n",
      "enables agents to learn whether their behaviors\n",
      "should be consistent with that of other agents by\n",
      "utilizing intrinsic rewards to learn the optimal pol-\n",
      "icy for each agent. We begin by defining behavior\n",
      "consistency as the divergence in output actions\n",
      "between two agents when provided with the same\n",
      "observation. Subsequently, we introduce dynamic\n",
      "consistency intrinsic reward (DCIR) to stimulate\n",
      "agents to be aware of others‚Äô behaviors and deter-\n",
      "mine whether to be consistent with them. Lastly,\n",
      "we devise a dynamic scale network (DSN) that\n",
      "provides learnable scale factors for the agent at\n",
      "every time step to dynamically ascertain whether\n",
      "to award consistent behavior and the magnitude\n",
      "of rewards. We evaluate DCIR in multiple envi-\n",
      "ronments including Multi-agent Particle, Google\n",
      "Research Football and StarCraft II Micromanage-\n",
      "ment, demonstrating its efficacy.\n",
      "1. Introduction\n",
      "Multi-Agent Reinforcement Learning (MARL) has been\n",
      "evidenced as an important technique in a wide range of\n",
      "practical real-world tasks. These tasks are set in multi-\n",
      "agent systems with the goal of cooperation, such as robotic\n",
      "control (Peng et al., 2021; Kober et al., 2013; Lillicrap\n",
      "et al., 2015), video games (Carroll et al., 2019; Vinyals\n",
      "et al., 2019; Brown & Sandholm, 2019), and autonomous\n",
      "vehicles (Dinneweth et al., 2022; Bhalla et al., 2020). In\n",
      "1South China University of Technology2Shenzhen Univer-\n",
      "sity3The Hong Kong University of Science and Technology\n",
      "4UMass Amherst. Correspondence to: Mingkui Tan <mingkui-\n",
      "tan@scut.edu.cn>.\n",
      "Motivation\n",
      "GoalObservation FieldHumble BehaviorAggressive BehaviorAgent2Agent3Agent1Agent4(a) Task: 4 agents cooperate to reach 4 goalsRewardconsistent with Agent2 Penaltyconsistent with Agent1 and 3 (b) Behaviors of Agent4 rewarded by DCIRFigure 1. (a) In a multi-agent cooperation task, four agents must\n",
      "cooperate to reach four goals simultaneously as soon as possible.\n",
      "In the context that Agent1 andAgent3 take aggressive behavior\n",
      "to directly walk towards the goal they have observed, Agent2 and\n",
      "Agent4 should share consistent humble behavior to explore more\n",
      "targets. (b) Our dynamic consistency intrinsic reward (DCIR)\n",
      "awards Agent4 if it behaves consistently with Agent2 while punish-\n",
      "ing it if it behaves consistently with Agent1 andAgent3 .\n",
      "MARL, each agent is a reinforcement learning system with\n",
      "its own perception and decision-making capabilities. The\n",
      "agents are required to collectively learn and optimize their\n",
      "behavior strategies by interacting with the environment to\n",
      "achieve a common goal.\n",
      "As the number of agents grows from one to multiple, it is\n",
      "challenging for each agent to find its optimal behavior. This\n",
      "is particularly obvious in many real-world scenarios where\n",
      "extrinsic rewards are sparse and delayed, exacerbating the\n",
      "difficulty of MARL. Deducing the reward of each agent is\n",
      "crucial to encourage the agents to organize their behaviors\n",
      "for successful collaboration (Ma et al., 2022). While re-\n",
      "ward shaping (Ng et al., 1999) requires heavy and careful\n",
      "manual work, previous works are striving to cope with this\n",
      "1arXiv:2312.05783v1  [cs.LG]  10 Dec 2023DCIR: Dynamic Consistency Intrinsic Reward for Multi-Agent Reinforcement Learning\n",
      "challenge by assigning intrinsic rewards for each agent (Ma\n",
      "et al., 2022; Du et al., 2019; Jaderberg et al., 2019; Stadie\n",
      "et al., 2015; Iqbal & Sha, 2019b). LIIR (Du et al., 2019)\n",
      "tries to break down the extrinsic reward into individual learn-\n",
      "able intrinsic rewards for each agent. ELIGN (Ma et al.,\n",
      "2022) encourages multi-agent cooperation through learning\n",
      "a shared world model among different agents. However, ex-\n",
      "isting methods fail to address the dynamics of whether two\n",
      "agents should exhibit consistent behaviors, which results\n",
      "in a pitfall in multi-agent reinforcement learning. In this\n",
      "context, consistent behaviors exhibited by two agents denote\n",
      "their tendency to arrive at identical decisions when they are\n",
      "given the same observations. To inspect the existing agents‚Äô\n",
      "ability of dynamic behavior consistency, we conduct a pilot\n",
      "study: to evaluate whether they can behave with adequate\n",
      "consistency (see supplementary for more details). We found\n",
      "that existing methods ( e.g.ELIGN) put up a poor show:\n",
      "when required to behave consistently, only 75% agents com-\n",
      "ply, and even worse in being asked to behave inconsistently\n",
      "(69%). Thus, incentivizing agents to behave with dynamic\n",
      "consistency remains an unresolved issue.\n",
      "To illustrate the necessity of both behavior consistency and\n",
      "inconsistency\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data-Free Hard-Label Robustness Stealing Attack\n",
      "Xiaojian Yuan1, Kejiang Chen*1, Wen Huang1, Jie Zhang2,\n",
      "Weiming Zhang1, Nenghai Yu1\n",
      "1University of Science and Technology of China,2Nanyang Technological University\n",
      "xjyuan@mail.ustc.edu.cn, chenkj@ustc.edu.cn, hw2000@mail.ustc.edu.cn,\n",
      "jiezhang@ntu.edu.sg, zhangwm@ustc.edu.cn, ynh@ustc.edu.cn\n",
      "Abstract\n",
      "The popularity of Machine Learning as a Service (MLaaS)\n",
      "has led to increased concerns about Model Stealing At-\n",
      "tacks (MSA), which aim to craft a clone model by query-\n",
      "ing MLaaS. Currently, most research on MSA assumes that\n",
      "MLaaS can provide soft labels and that the attacker has a\n",
      "proxy dataset with a similar distribution. However, this fails\n",
      "to encapsulate the more practical scenario where only hard la-\n",
      "bels are returned by MLaaS and the data distribution remains\n",
      "elusive. Furthermore, most existing work focuses solely on\n",
      "stealing the model accuracy, neglecting the model robustness,\n",
      "while robustness is essential in security-sensitive scenarios,\n",
      "e.g., face-scan payment. Notably, improving model robust-\n",
      "ness often necessitates the use of expensive techniques such\n",
      "as adversarial training, thereby further making stealing ro-\n",
      "bustness a more lucrative prospect. In response to these iden-\n",
      "tified gaps, we introduce a novel Data-Free Hard-Label Ro-\n",
      "bustness Stealing (DFHL-RS) attack in this paper, which en-\n",
      "ables the stealing of both model accuracy and robustness by\n",
      "simply querying hard labels of the target model without the\n",
      "help of any natural data. Comprehensive experiments demon-\n",
      "strate the effectiveness of our method. The clone model\n",
      "achieves a clean accuracy of 77.86% and a robust accuracy\n",
      "of 39.51% against AutoAttack, which are only 4.71% and\n",
      "8.40% lower than the target model on the CIFAR-10 dataset,\n",
      "significantly exceeding the baselines. Our code is available\n",
      "at:https://github.com/LetheSec/DFHL-RS-Attack .\n",
      "1 Introduction\n",
      "Machine learning as a service (MLaaS) has gained signif-\n",
      "icant popularity due to its ease of deployment and cost-\n",
      "effectiveness, which provides users with pre-trained models\n",
      "and APIs. Unfortunately, MLaaS is susceptible to privacy\n",
      "attacks, with Model Stealing Attacks (MSA) being partic-\n",
      "ularly harmful (Tram `er et al. 2016; Orekondy, Schiele, and\n",
      "Fritz 2019; Jagielski et al. 2020; Yuan et al. 2022; Wang\n",
      "et al. 2022), where an attacker can train a clone model\n",
      "by querying its public API, without accessing its param-\n",
      "eters or training data. This attack not only poses a threat\n",
      "to intellectual property but also compromises the privacy\n",
      "of individuals whose data was used to train the original\n",
      "model. Moreover, the clone model can serve as a surrogate\n",
      "*Corresponding author.\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.model for other black-box attacks, e.g., adversarial examples\n",
      "(AE) (Zhang et al. 2022b), membership inference (Shokri\n",
      "et al. 2017), and model inversion (Yuan et al. 2023).\n",
      "Furthermore, numerous security-sensitive scenarios re-\n",
      "quire deployed models are not only accurate but also robust\n",
      "to various attacks, such as adversarial attacks. To address\n",
      "this issue, MLaaS providers can employ adversarial training\n",
      "(AT) techniques (Madry et al. 2018) to improve the robust-\n",
      "ness of their models (Goodman and Xin 2020; Shafique et al.\n",
      "2020). Despite the target model‚Äôs robustness, most existing\n",
      "MSA are limited to Accuracy Stealing, i.e., reconstructing\n",
      "a model with similar accuracy to the target model, and fail\n",
      "at Robustness Stealing, i.e., acquiring the adversarial robust-\n",
      "ness of the target model while maintaining accuracy. Since\n",
      "the improvement of model robustness requires much more\n",
      "computational resources and extra data (Schmidt et al. 2018;\n",
      "Gowal et al. 2021), robustness stealing will bring greater\n",
      "losses to MLaaS providers. Moreover, if an attacker seeks\n",
      "to train a clone model for transfer-based adversarial attacks\n",
      "against a robust target model, then it becomes crucial to em-\n",
      "ploy robustness stealing to achieve effective attack perfor-\n",
      "mance (Dong et al. 2020; Gao et al. 2020).\n",
      "In addition, most previous MSA require MLaaS to pro-\n",
      "vide prediction logits, i.e., soft labels. However, this require-\n",
      "ment is overly stringent in typical scenarios where MLaaS\n",
      "can only return top-1 prediction, i.e., hard label, for each\n",
      "query. Since models that require robustness are more likely\n",
      "trained on sensitive or private datasets, it is difficult for at-\n",
      "tackers to obtain public data with similar distributions, let\n",
      "alone access to the original data. Hence, the investigation of\n",
      "MSA targeting robustness in a data-free hard-label setting is\n",
      "highly valuable and remains unexplored.\n",
      "To tackle the above issues, we propose Data-Free Hard-\n",
      "Label Robustness Stealing (DFHL-RS) attack, which can\n",
      "effectively steal both the accuracy and robustness of the tar-\n",
      "get model. We first demonstrate that direct use of AT dur-\n",
      "ing MSA is suboptimal and point out the limitations of us-\n",
      "ing Uncertain Example (UE) (Li et al. 2023a) f\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Graph-based Prediction and Planning Policy Network (GP3Net) for scalable\n",
      "self-driving in dynamic environments using Deep Reinforcement Learning\n",
      "Jayabrata Chowdhury1*, Venkataramanan Shivaraman2*, Suresh Sundaram1, P B Sujit2\n",
      "1Indian Institute of Science, Bengaluru2Indian Institute of Science Education and Research, Bhopal\n",
      "jayabratac@iisc.ac.in, vshivaraman18@gmail.com, vssuresh@iisc.ac.in, sujit@iiserb.ac.in\n",
      "Abstract\n",
      "Recent advancements in motion planning for Autonomous\n",
      "Vehicles (A Vs) show great promise in using expert driver\n",
      "behaviors in non-stationary driving environments. However,\n",
      "learning only through expert drivers needs more generaliz-\n",
      "ability to recover from domain shifts and near-failure sce-\n",
      "narios due to the dynamic behavior of traffic participants\n",
      "and weather conditions. A deep Graph-based Prediction and\n",
      "Planning Policy Network (GP3Net) framework is proposed\n",
      "for non-stationary environments that encodes the interactions\n",
      "between traffic participants with contextual information and\n",
      "provides a decision for safe maneuver for A V . A spatio-\n",
      "temporal graph models the interactions between traffic par-\n",
      "ticipants for predicting the future trajectories of those par-\n",
      "ticipants. The predicted trajectories are utilized to generate a\n",
      "future occupancy map around the A V with uncertainties em-\n",
      "bedded to anticipate the evolving non-stationary driving en-\n",
      "vironments. Then the contextual information and future oc-\n",
      "cupancy maps are input to the policy network of the GP3Net\n",
      "framework and trained using Proximal Policy Optimization\n",
      "(PPO) algorithm. The proposed GP3Net performance is eval-\n",
      "uated on standard CARLA benchmarking scenarios with do-\n",
      "main shifts of traffic patterns (urban, highway, and mixed).\n",
      "The results show that the GP3Net outperforms previous state-\n",
      "of-the-art imitation learning-based planning models for dif-\n",
      "ferent towns. Further, in unseen new weather conditions,\n",
      "GP3Net completes the desired route with fewer traffic infrac-\n",
      "tions. Finally, the results emphasize the advantage of includ-\n",
      "ing the prediction module to enhance safety measures in non-\n",
      "stationary environments.\n",
      "Introduction\n",
      "Motion planning for A Vs still has a long way to go due to\n",
      "the complexity of real-world driving environments, ensur-\n",
      "ing the safety and comfort of everyone. The A V must be able\n",
      "to carefully plan its maneuvers in urban and highway envi-\n",
      "ronments with varying traffic dynamics set by cars, bikers,\n",
      "pedestrians, and weather conditions. A typical intersection\n",
      "scenario in an urban environment is shown in Fig.1. Vari-\n",
      "ous traffic participants‚Äô different intentions and final goals\n",
      "(as shown by arrows in Fig.1) make it challenging for A V\n",
      "to safely and comfortably move to its destination. Variable\n",
      "*These authors contributed equally.\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "Figure 1: A typical intersection scenario with traffic lights,\n",
      "pedestrians, and vehicles. The scenario has pedestrians and\n",
      "vehicles moving on the desired path of A V . The figure has\n",
      "colour coded markers to show the context.\n",
      "speeds of different traffic participants also make it difficult\n",
      "for A V to drive safely. A research finding on the United\n",
      "States (Choi 2010) shows that wrong estimation of other\n",
      "traffic participants‚Äô speed is responsible for 8.4%of crit-\n",
      "ical reasons for crashes. Also, another problem of driving\n",
      "in an unstructured environment is that traffic pattern varies\n",
      "with the cooperative/noncooperative behaviors of other traf-\n",
      "fic participants. By utilizing communication channels as de-\n",
      "scribed in (Bazzi et al. 2021; Cui et al. 2022), it becomes\n",
      "possible to determine the intentions and objectives of fellow\n",
      "traffic participants. This information simplifies the process\n",
      "for A Vs to make informed decisions regarding their actions.\n",
      "However, vehicles use different communication protocols,\n",
      "and ensuring reliable real-time communications between all\n",
      "traffic participants is challenging. Hence, another way is to\n",
      "model the interactions of traffic participants through time\n",
      "and predict their future trajectories to understand their be-\n",
      "haviors. An A V can make a safe and efficient decision in a\n",
      "non-stationary environment if it can model the interactions\n",
      "better and predict the future trajectories of other surrounding\n",
      "vehicles. Depending on the future trajectories of others‚Äô, an\n",
      "A V can decide on a safe planning maneuver. Hence, there\n",
      "is a need to develop a motion planning algorithm that can\n",
      "handle non-stationary environments using the intention un-\n",
      "derstanding from the predicted trajectories of other trafficarXiv:2312.05784v1  [cs.AI]  10 Dec 2023participants.\n",
      "Existing state-of-the-art methods can be broadly classi-\n",
      "fied into rule-based, imitation learning-based, and reinforce-\n",
      "ment learning-based works. Recently (Aksjonov and Kyrki\n",
      "2021) uses a rule-based decision-making system for navigat-\n",
      "ing road intersections. However, due to the non-stationary\n",
      "nature of the environment, rules vary for each si\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Language-Conditioned Semantic Search-Based Policy\n",
      "for Robotic Manipulation Tasks\n",
      "Jannik Sheikh\n",
      "Bielefeld University\n",
      "Bielefeld, Germany\n",
      "jsheikh@techfak.uni-bielefeld.deAndrew Melnik\n",
      "Bielefeld University\n",
      "Bielefeld, Germany\n",
      "andrew.melnik.papers@gmail.com\n",
      "Gora Chand Nandi\n",
      "Indian Institute of Information Technology\n",
      "Allahabad, India\n",
      "gcnandi@iiita.ac.inRobert Haschke\n",
      "Bielefeld University\n",
      "Bielefeld, Germany\n",
      "rhaschke@techfak.uni-bielefeld.de\n",
      "Abstract\n",
      "Reinforcement learning and Imitation Learning approaches utilize policy learn-\n",
      "ing strategies that are difficult to generalize well with just a few examples of a\n",
      "task. In this work, we propose a language-conditioned semantic search-based\n",
      "method to produce an online search-based policy from the available demonstration\n",
      "dataset of state-action trajectories. Here we directly acquire actions from the most\n",
      "similar manipulation trajectories found in the dataset. Our approach surpasses\n",
      "the performance of the baselines on the CALVIN benchmark and exhibits strong\n",
      "zero-shot adaptation capabilities. This holds great potential for expanding the\n",
      "use of our online search-based policy approach to tasks typically addressed by\n",
      "Imitation Learning or Reinforcement Learning-based policies. Project webpage:\n",
      "https://j-sheikh.github.io/behavioral-search-policy\n",
      "1 Introduction\n",
      "In recent years, the field of robotics has significantly evolved, with robots becoming more powerful,\n",
      "versatile, and interactive, due to progress in the field of natural language processing, computer vision\n",
      "(Rana et al. 2023), reinforcement learning (Schilling & Melnik 2019, Nguyen & La 2019, Bach et al.\n",
      "2020), and imitation learning (Hussein et al. 2017).\n",
      "Motivation The ability of any agent to interact within an environment seamlessly depends largely\n",
      "on its capacity to collect, process, and understand data that are largely unstructured. This data forms\n",
      "the agent‚Äôs perception and guides its decisions, actions, and reactions. Instead of the traditional\n",
      "approach of complex training of a policy to solve specific tasks, our work explores a framework for\n",
      "solving various robot manipulation tasks by using a semantic search-based approach to generate an\n",
      "online search-based policy , inspired by the work of Malato et al. (2023), Beohar & Melnik (2022),\n",
      "Beohar et al. (2022), Rana et al. (2023).\n",
      "2 Data\n",
      "The CALVIN benchmark (Mees, Hermann, Rosete-Beas & Burgard 2022) contains four different\n",
      "tabletop environments (A, B, C, and D) as seen in Figure 1. Those environments always contain\n",
      "a desk with stationary and movable objects to interact with, whose initial positions vary over the\n",
      "NeurIPS 2023 Workshop on Foundation Models for Decision Making, New OrleansarXiv:2312.05925v1  [cs.RO]  10 Dec 2023Static Camera View Gripper Camera View\n",
      "Env. A\n",
      "Env. B\n",
      "Env. C\n",
      "Env. DFigure 1: Overview of all four different environments in CALVIN. During inference, the Search-\n",
      "Based Policy searches for the most similar state in environments A, B and C with respect to the\n",
      "current state from environment D.\n",
      "environments. A drawer and sliding door can be opened and closed. A button toggles an LED light\n",
      "and a switch operates a light bulb. Further three different-sized, colored, and shaped blocks are\n",
      "somewhere located on the desk. A 7-DoF robot arm with a parallel gripper is used to interact with\n",
      "the environment.\n",
      "The demonstration dataset of the benchmark was obtained from teleoperated \"play\" data, thus\n",
      "consisting of state xiand action aipair trajectories œÑ. Therefore œÑcontains the exact information of\n",
      "how the agent, controlled by a human, got from some initial state x0to a goal state xg, for completing\n",
      "a task. This guarantees that the goal state is reachable from the initial state under the performed\n",
      "actions. This results in a dataset Dplay={œÑ|œÑ={(xi, ai)}n\n",
      "i=0and0‚â§n‚â§64}.\n",
      "The authors labeled less than 1% of the collected data, making it possible to identify trajectories that\n",
      "correspond to specific tasks. By annotating these trajectories, they made it possible to describe any of\n",
      "the trajectories, and thus the corresponding tasks, by natural language instructions.\n",
      "3 Method\n",
      "Instead of training a policy to solve tasks, we used search in the latent space of object shapes (Melnik\n",
      "et al. 2021, Rothgaenger et al. 2023) to identify similar states in a demonstration dataset, and after\n",
      "finding similar representations for a given scene and text task, we clone the corresponding actions\n",
      "to solve the given tasks until the divergence threshold is exceeded between the current state and the\n",
      "selected trajectory.\n",
      "2Model Similarity SearchCopy ActionsCurrent State Current State\n",
      "Dataset DatasetText instruction0.6\n",
      "0.89\n",
      "0.34ScoresFigure 2: Overview of our framework. Given xt, we obtain a binary mask of the object of interest in\n",
      "the static and gripper camera views and then compute sim zsto find the most similar state in dataset\n",
      "trajectories and start cloning the corresponding actions.\n",
      "Masking Since all objects over all the environments are of color, we first experimented with\n",
      "transforming the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Efficient Sparse-Reward Goal-Conditioned Reinforcement\n",
      "Learning with a High Replay Ratio and Regularization\n",
      "Takuya Hiraoka takuya-h1@nec.com\n",
      "NEC Corporation\n",
      "National Institute of Advanced Industrial Science and Technology\n",
      "Abstract\n",
      "Reinforcement learning (RL) methods with a high replay ratio (RR) and regularization have\n",
      "gained interest due to their superior sample efficiency. However, these methods have mainly\n",
      "been developed for dense-reward tasks. In this paper, we aim to extend these RL methods\n",
      "to sparse-reward goal-conditioned tasks. We use Randomized Ensemble Double Q-learning\n",
      "(REDQ) (Chen et al., 2021), an RL method with a high RR and regularization. To apply\n",
      "REDQ to sparse-reward goal-conditioned tasks, we make the following modifications to it:\n",
      "(i) using hindsight experience replay and (ii) bounding target Q-values. We evaluate REDQ\n",
      "with these modifications on 12 sparse-reward goal-conditioned tasks of Robotics (Plappert\n",
      "et al., 2018), and show that it achieves about 2√óbetter sample efficiency than previous\n",
      "state-of-the-art (SoTA) RL methods. Furthermore, we reconsider the necessity of specific\n",
      "components of REDQ and simplify it by removing unnecessary ones. The simplified REDQ\n",
      "with our modifications achieves ‚àº8√óbetter sample efficiency than the SoTA methods in 4\n",
      "Fetch tasks of Robotics.\n",
      "1 Introduction\n",
      "In the reinforcement learning (RL) community, improving the sample efficiency of RL methods has been\n",
      "important. Traditional RL methods have been promising for solving complex control tasks, including dex-\n",
      "terous in-hand manipulation (Andrychowicz et al., 2020), quadrupedal/bipedal locomotion (Lee et al., 2020;\n",
      "Haarnoja et al., 2023), and car/drone racing (Wurman et al., 2022; Kaufmann et al., 2023). However,\n",
      "traditional RL methods are generally data-hungry and require large amounts of training samples to solve\n",
      "tasks (Mendonca et al., 2019). Motivated by this problem, various sample-efficient RL methods have been\n",
      "proposed (Haarnoja et al., 2018; Lillicrap et al., 2015; Schulman et al., 2017; Fujimoto et al., 2018).\n",
      "In recent years, RL methods using a high replay ratio (RR) and regularization have attracted attention as\n",
      "sample-efficient methods (Janner et al., 2019; Chen et al., 2021; Hiraoka et al., 2022; Nikishin et al., 2022;\n",
      "Li et al., 2023a; D‚ÄôOro et al., 2023; Smith et al., 2023b; Sokar et al., 2023; Schwarzer et al., 2023). RR is the\n",
      "ratio of components (e.g., policy and Q-functions) updates to the actual interactions with an environment.\n",
      "A high RR facilitates sufficient training of the components within a few interactions but exacerbates the\n",
      "components‚Äô overfitting. Regularization techniques (e.g., ensemble (Chen et al., 2021) or dropout (Hiraoka\n",
      "et al., 2022)) are employed to prevent the overfitting. The RL methods equipped with them have exhibited\n",
      "high sample efficiency and enabled training agents within mere tens of minutes in real-world tasks, such\n",
      "as quadrupedal robot locomotion (Smith et al., 2022; 2023a) and image-based vehicle driving (Stachowicz\n",
      "et al., 2023).\n",
      "However, these methods have been developed mainly on dense-reward tasks rather than sparse-reward tasks.\n",
      "Many RL tasks require RL methods to learn with a sparse reward due to the difficulty of designing dense\n",
      "rewards (Andrychowicz et al., 2017; Trott et al., 2019; Agrawal, 2022; Knox et al., 2023; Booth et al., 2023).\n",
      "A typical example of such tasks is sparse-reward goal-conditioned tasks (Plappert et al., 2018), where\n",
      "a positive reward is provided only upon successful goal attainment. RL methods that can efficiently learn in\n",
      "these tasks hold substantial value in numerous application scenarios, such as (i) developing versatile agents\n",
      "1arXiv:2312.05787v1  [cs.LG]  10 Dec 20232.5 5.0 7.5 10.0 12.5 15.0\n",
      "environment interactions 1e50.00.20.40.60.81.0IQM (success rate)IQM over 12 tasks\n",
      "REDQ\n",
      "REDQ+HER+BQ\n",
      "Previous SoTA (8*1e5)\n",
      "Previous SoTA (16*1e5)\n",
      "2.5 5.0 7.5 10.0 12.5 15.0\n",
      "environment interactions 1e50.00.20.40.60.81.0success rateHandManipulateBlockRotateZ-v0Figure 1: The task success rate of vanilla REDQ and our modified REDQ (REDQ+HER+BQ). The left-\n",
      "hand side figure shows the interquartile mean (IQM) with a 95% confidence interval (Agarwal et al., 2021)\n",
      "for the success rate over 12Robotics tasks. The right-hand side figure shows the average scores with\n",
      "one standard deviation in the HandManipulateBlockRotateZ task (one of the Robotics tasks). We also\n",
      "present scores from previous SoTA methods with 8¬∑105and 16¬∑105samples (number of environment\n",
      "interactions). For context, 105samples correspond to approximately one hour of real-world experience. The\n",
      "left-hand side figure shows that our modified REDQ achieves approximately 2√óbetter sample efficiency\n",
      "than previous SoTA methods. Examples of policies learnt by our modified REDQ can be found at https:\n",
      "//drive.google.com/file/d/1UHd7JVPCwFLNFhy1QcycQfwU_nll_yII/view?usp=drive_link\n",
      "capable of achieving diverse goals (Vithayathil Varghese & Mahmoud, 2020; Beck et al., 2023), or (ii) con-\n",
      "structing \n",
      "----------------------------------------------------------------------------------------------------\n",
      "The survival of scientific stylization\n",
      "Yuanyuan Shu1and Tianxing Pan1,*\n",
      "1School of Information Management, Nanjing University\n",
      "*Corresponding author. E-mail: pantianxing97@163.com\n",
      "Abstract\n",
      "This study elaborates a text-based metric to quantify the unique position of stylized scientific\n",
      "research, characterized by its innovative integration of diverse knowledge components and poten-\n",
      "tial to pivot established scientific paradigms. Our analysis reveals a concerning decline in stylized\n",
      "research, highlighted by its comparative undervaluation in terms of citation counts and protracted\n",
      "peer-review duration. Despite facing these challenges, the disruptive potential of stylized research\n",
      "remains robust, consistently introducing groundbreaking questions and theories. This paper posits\n",
      "that substantive reforms are necessary to incentivize and recognize the value of stylized research,\n",
      "including optimizations to the peer-review process and the criteria for evaluating scientific impact.\n",
      "Embracing these changes may be imperative to halt the downturn in stylized research and ensure\n",
      "enduring scholarly exploration in endless frontiers.\n",
      "1arXiv:2312.05927v1  [cs.DL]  10 Dec 2023Introduction\n",
      "Stylization, characterized by its role in differentiation and establishing distance from peer works, is\n",
      "extensively explored within cultural spheres such as film, music and artwork [1‚Äì6]. An idiosyncratic\n",
      "style can endow preeminent creators with a strategic edge [6, 7], yet it simultaneously exposes them to\n",
      "potential risks and failure [8]. This dichotomy poses a paradox at both the individual and organization\n",
      "level; nevertheless, there exists a prevailing consensus on the significance of diversity within the cultural\n",
      "sector. Contributions imbued with stylistic innovation are indispensable for the flourishing of the cultural\n",
      "milieu as a whole.\n",
      "Yet, within the purview of scientific exploration, systematized investigation on stylization remains\n",
      "conspicuously sparse, even though such phenomena prevails in spectrum of human creative endeavors.\n",
      "A potential reason for this gap may be that the existing instruments we use to track scientific progress are\n",
      "insufficient. Traditional metrics of research impact, such as citation count, while providing a quantitative\n",
      "measure, often fail to capture the holistic evolution of knowledge within academic fields [9, 10].\n",
      "To address this, researchers have turned to network-based metrics [10‚Äì14] that offer a more sophis-\n",
      "ticated analysis of scientific development by examining changes within citation networks. Among these,\n",
      "‚Äúdisruption‚Äù metric [13] stands out, meticulously charting alterations in citation network to quantify the\n",
      "impact on pre-existing knowledge structures. This retrospective gaze highlights the perpetual forward\n",
      "march of science, wherein today‚Äôs cutting-edge discoveries lay the groundwork for tomorrow‚Äôs funda-\n",
      "mental principles.\n",
      "Building upon this analytical shift, we have constructed a text-based metric, termed ‚Äústylization‚Äù,\n",
      "designed to quantify the extent to which a scholarly work deviates from established paradigms. This\n",
      "measure relies on intrinsic textual information rather than using the delayed citation dynamic as an\n",
      "indirect proxy for a work‚Äôs influence within the scientific canon. Our findings, suggest that highly stylized\n",
      "works establish broad connections yet provoke diverse academic critiques, potentially echoing narratives\n",
      "of scientific stagnation [13‚Äì17].\n",
      "Hypotheses ranging from the ‚Äúburden of knowledge‚Äù [18] to the metaphorical harvesting of ‚Äúlow-\n",
      "hanging fruit‚Äù [19] have been advanced to rationalize this phenomenon. However, in the interstice\n",
      "between the declining visibility of stylized scientific work and the broader deceleration of scientific\n",
      "progress may lay an underappreciated nexus. The momentum of scientific progress hinges upon the\n",
      "2cadre of adept scientists, or more pointedly, the vigor of their exploration [20]. Yet, we have observed\n",
      "that diminishing returns in scientific research may be pressuring researchers to focus on outcomes prag-\n",
      "matically rather than exploring their intellectual interests. Substantial, albeit disparate, evidence high-\n",
      "lights that the competition for priority may negatively impact the research quality, exerts on scientists‚Äô\n",
      "choices and performance [21‚Äì24]. This pragmatic shift, while seemingly efficient to the swift response\n",
      "observed during crises [25], might inadvertently stifle the pursuit of pioneering projects with personal\n",
      "styles, potentially contributing to the overall slowdown in scientific advancement.\n",
      "Results\n",
      "Decline of stylized research over time\n",
      "How does the stylized research manifest within the scientific research landscape, and what are the ob-\n",
      "served trends over time? Addressing this inquiry is pivotal for a nuanced comprehension of the scientific\n",
      "revolution and evolving innovation paradigms. We have commenced this investigation by quantifying\n",
      "the stylization of a paper through neural network embedding, inspired by the prior research [4, 26, \n",
      "----------------------------------------------------------------------------------------------------\n",
      "SimPSI: A Simple Strategy to Preserve Spectral Information\n",
      "in Time Series Data Augmentation\n",
      "Hyun Ryu, Sunjae Yoon, Hee Suk Yoon, Eunseop Yoon, and Chang D. Yoo\n",
      "Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea\n",
      "{ryuhyun1905, sunjae.yoon, hskyoon, esyoon97, cd yoo}@kaist.ac.kr\n",
      "Abstract\n",
      "Data augmentation is a crucial component in training neural\n",
      "networks to overcome the limitation imposed by data size,\n",
      "and several techniques have been studied for time series. Al-\n",
      "though these techniques are effective in certain tasks, they\n",
      "have yet to be generalized to time series benchmarks. We\n",
      "find that current data augmentation techniques ruin the core\n",
      "information contained within the frequency domain. To ad-\n",
      "dress this issue, we propose a simple strategy to preserve\n",
      "spectral information ( SimPSI ) in time series data augmen-\n",
      "tation. SimPSI preserves the spectral information by mix-\n",
      "ing the original and augmented input spectrum weighted by\n",
      "a preservation map, which indicates the importance score\n",
      "of each frequency. Specifically, our experimental contribu-\n",
      "tions are to build three distinct preservation maps: magni-\n",
      "tude spectrum, saliency map, and spectrum-preservative map.\n",
      "We apply SimPSI to various time series data augmenta-\n",
      "tions and evaluate its effectiveness across a wide range of\n",
      "time series benchmarks. Our experimental results support that\n",
      "SimPSI considerably enhances the performance of time se-\n",
      "ries data augmentations by preserving core spectral infor-\n",
      "mation. The source code used in the paper is available at\n",
      "https://github.com/Hyun-Ryu/simpsi.\n",
      "Introduction\n",
      "Time series data, whether univariate or multivariate, plays\n",
      "a crucial role in various domains such as medicine (Lipton\n",
      "et al. 2016), physiology (Jia et al. 2020), and sensory de-\n",
      "vices (Yao et al. 2017). Unfortunately, it is limited to col-\n",
      "lecting data samples under consideration of different types,\n",
      "constraining the performance and capabilities of neural net-\n",
      "works that learn from it. To address this issue, data augmen-\n",
      "tation (Iwana and Uchida 2021; Um et al. 2017) is employed\n",
      "as a simple yet effective solution via artificially increasing\n",
      "the number of samples based on a slight variation or pertur-\n",
      "bation on the original samples.\n",
      "Data augmentation techniques have been extensively\n",
      "studied for time series, incorporating methods such as Jit-\n",
      "tering, Scaling, Magnitude warping, Time warping, Permu-\n",
      "tation (Um et al. 2017), Shifting (Woo et al. 2022), and\n",
      "Dropout (Yang and Hong 2022). These perturbations have\n",
      "been popular choices in the time domain. The data augmen-\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "Figure 1: Dependency on data domain of time series data\n",
      "augmentation techniques. The plot shows the increment of\n",
      "classification accuracy of a baseline model after applying\n",
      "each data augmentation technique, which is evaluated on\n",
      "signal demodulation (Simulation), human activity recogni-\n",
      "tion (HAR), and sleep stage detection (SleepEDF) tasks.\n",
      "tation is also considered in the frequency domain via apply-\n",
      "ing the Fourier transform to time series data. The spectrum\n",
      "is then randomly perturbed before being converted back into\n",
      "the time domain through the inverse Fourier transform. No-\n",
      "table techniques in this category include Frequency mask-\n",
      "ing, Frequency mixing (Chen et al. 2023), and Frequency\n",
      "adding (Zhang et al. 2022).\n",
      "We have discovered that while the aforementioned data\n",
      "augmentation techniques show effectiveness in certain spe-\n",
      "cific tasks (Um et al. 2017), they do not generalize well\n",
      "to time series classification benchmarks. Our experimental\n",
      "evidence in Fig. 1 presents the ungeneralized effectiveness\n",
      "of data augmentation techniques according to the datasets,\n",
      "such as signal demodulation, human activity recognition,\n",
      "and sleep stage detection.1Those techniques, though reliant\n",
      "on randomness, operate under the assumption that the core\n",
      "information within the data is preserved. However, the re-\n",
      "sult suggests that perturbing the original time series data is\n",
      "heuristic and depends on the data domain, which leads to\n",
      "losing essential information necessary to solve the tasks.\n",
      "The observed reduction in performance is attributed to\n",
      "1Detailed information about the tasks and our experimental\n",
      "setup can be found in the Experiments section.arXiv:2312.05790v1  [cs.LG]  10 Dec 2023Figure 2: Visualization of a representative example from the\n",
      "HAR dataset in the time and frequency domain with var-\n",
      "ious time series data augmentation techniques. Each color\n",
      "denotes a channel, and three channels are shown.\n",
      "an implicit bias in the frequency domain introduced by\n",
      "each data augmentation technique. This bias alters the orig-\n",
      "inal data distribution. For example, Jittering adds a consis-\n",
      "tent amount of random noise across all frequencies, often\n",
      "obscuring subtle high-frequency components. Permutation,\n",
      "meanwhile, introduces abrupt changes at the boundaries of\n",
      "each fragment, consistently enhancing high-f\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer\n",
      "Joonwoo Kwon1*, Sooyoung Kim2*, Yuewei Lin5‚Ä†, Shinjae Yoo5‚Ä†, Jiook Cha3,4 ‚Ä†\n",
      "1Department of Applied Bioengineering, Seoul National University\n",
      "2Department of Brain and Cognitive Science, Seoul National University\n",
      "3Department of Psychology, Seoul National University\n",
      "4Artificial Intelligence Graduate School Program, Seoul National University\n",
      "5Brookhaven National Laboratory\n",
      "pioneers, rlatndud0513@snu.ac.kr, ywlin, sjyoo@bnl.gov, cha.jiook@gmail.com\n",
      "Abstract\n",
      "Neural style transfer (NST) has evolved significantly in recent\n",
      "years. Yet, despite its rapid progress and advancement, exist-\n",
      "ing NST methods either struggle to transfer aesthetic infor-\n",
      "mation from a style effectively or suffer from high computa-\n",
      "tional costs and inefficiencies in feature disentanglement due\n",
      "to using pre-trained models. This work proposes a lightweight\n",
      "but effective model, AesFA ‚ÄîAesthetic Feature- Aware NST.\n",
      "The primary idea is to decompose the image via its frequen-\n",
      "cies to better disentangle aesthetic styles from the reference\n",
      "image while training the entire model in an end-to-end man-\n",
      "ner to exclude pre-trained models at inference completely. To\n",
      "improve the network‚Äôs ability to extract more distinct rep-\n",
      "resentations and further enhance the stylization quality, this\n",
      "work introduces a new aesthetic feature: contrastive loss. Ex-\n",
      "tensive experiments and ablations show the approach not only\n",
      "outperforms recent NST methods in terms of stylization qual-\n",
      "ity, but it also achieves faster inference. Codes are available\n",
      "at https://github.com/Sooyyoungg/AesFA.\n",
      "1 Introduction\n",
      "Neural Style Transfer (NST) is an artistic application that\n",
      "transfers the style of one image to another while preserving\n",
      "the original content. Initially introduced by (Gatys, Ecker,\n",
      "and Bethge 2016), this area has gained substantial momen-\n",
      "tum with the advancement of deep neural networks. Despite\n",
      "such progress, a significant chasm persists between authen-\n",
      "tic artwork and synthesized stylizations. Existing NST meth-\n",
      "ods, as shown in Figure 1, struggle to capture essential aes-\n",
      "thetic features, such as tones, brushstrokes, textures, grains,\n",
      "and the local structure from style images, leading to discor-\n",
      "dant colors and irrelevant patterns. Ideally, the goal of using\n",
      "NST is to extract a style from the image and transfer it to\n",
      "content, necessitating representations that capture both im-\n",
      "age semantics and stylistic changes. This work focuses on\n",
      "defining these style representations.\n",
      "In the context of painting, style representations are de-\n",
      "fined by attributes, such as overall color and/or the local\n",
      "structure of brushstrokes. Most NST algorithms define style\n",
      "representations as spatially agnostic features to encode this\n",
      "*These authors contributed equally.\n",
      "‚Ä†Corresponding authors.\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "Figure 1: Top: The Starry Night by Vincent Van Gogh. The\n",
      "shortcomings of the existing method: 1) Styles are not ag-\n",
      "nostic to spatial information, and 2) for ultra-high resolution\n",
      "style transfer, the effectiveness of the encoding networks is\n",
      "deficient, creating undesirable artifacts or suboptimal styl-\n",
      "izations. Bottom: Compared with other NST methods, our\n",
      "method can faithfully transfer styles while ensuring the spa-\n",
      "tial information.\n",
      "information. For example, Gatys et al. (Gatys, Ecker, and\n",
      "Bethge 2016) use gram matrices, while Huang et al. (Huang\n",
      "and Belongie 2017) employ mean and variance alignment\n",
      "to obtain a style representation. Despite their success, they\n",
      "rely solely on summary statistics. Thus, they lack spatial in-\n",
      "formation representation. In fact, style representations are\n",
      "highly correlated to spatial information. For example, Vin-\n",
      "cent van Gogh‚Äôs The Starry Night (Figure 1) has expression-\n",
      "istic yellow stars and a moon that dominate the upper center\n",
      "and right, while dynamic swirls fill the center of the sky.\n",
      "In pondering the style of this painting, its focal point pri-\n",
      "marily resides in the sky rather than the village or cypress\n",
      "trees. Therefore, when transferring The Starry Night ‚Äôs style,\n",
      "the expected style output likely would be the dynamic swirls\n",
      "and expressionistic yellow stars in the sky. From this point\n",
      "of view, spatial information keenly matters in style repre-\n",
      "sentations. However, most NST algorithms fail to recognize\n",
      "such distinct spatial styles due to their spatial-independent\n",
      "style representations, leading to stylizations lacking in spa-\n",
      "tial coherence (refer to the bottom panel in Figure 1).\n",
      "To enhance stylization, we propose a lightweight yet ef-arXiv:2312.05928v1  [cs.CV]  10 Dec 2023fective model that we call, Aesthetic Feature- Aware Arbi-\n",
      "trary NST, or AesFA . AesFA overcomes prior NST lim-\n",
      "itations by encoding style representations while retaining\n",
      "spatial details. To expedite the extraction of aesthetic fea-\n",
      "tures, we decompose the image into two discrete comple-\n",
      "mentary components, i.e., the high- and lo\n",
      "----------------------------------------------------------------------------------------------------\n",
      "IEEE INTERNET OF THINGS JOURNAL, 1\n",
      "Take an Irregular Route: Enhance the Decoder of\n",
      "Time-Series Forecasting Transformer\n",
      "Li Shen, Yuning Wei, Yangzhu Wang and Huaxin Qiu\n",
      "Abstract ‚ÄîWith the development of Internet of Things (IoT)\n",
      "systems, precise long-term forecasting method is requisite for\n",
      "decision makers to evaluate current statuses and formulate future\n",
      "policies. Currently, Transformer and MLP are two paradigms\n",
      "for deep time-series forecasting and the former one is more\n",
      "prevailing in virtue of its exquisite attention mechanism and\n",
      "encoder-decoder architecture. However, data scientists seem to be\n",
      "more willing to dive into the research of encoder, leaving decoder\n",
      "unconcerned. Some researchers even adopt linear projections in\n",
      "lieu of the decoder to reduce the complexity. We argue that both\n",
      "extracting the features of input sequence and seeking the relations\n",
      "of input and prediction sequence, which are respective functions\n",
      "of encoder and decoder, are of paramount significance. Motivated\n",
      "from the success of FPN in CV field, we propose FPPformer\n",
      "to utilize bottom-up and top-down architectures respectively in\n",
      "encoder and decoder to build the full and rational hierarchy.\n",
      "The cutting-edge patch-wise attention is exploited and further\n",
      "developed with the combination, whose format is also different in\n",
      "encoder and decoder, of revamped element-wise attention in this\n",
      "work. Extensive experiments with six state-of-the-art baselines\n",
      "on twelve benchmarks verify the promising performances of\n",
      "FPPformer and the importance of elaborately devising decoder in\n",
      "time-series forecasting Transformer. The source code is released\n",
      "in https://github.com/OrigamiSL/FPPformer.\n",
      "Index Terms ‚ÄîDeep-learning, neural network, time-series fore-\n",
      "casting, Transformer.\n",
      "I. I NTRODUCTION\n",
      "A. Background\n",
      "THE advent of Big Data era has brought immense volume\n",
      "and variety of data in the 21st century, especially in\n",
      "Internet of Things (IoT) systems with tons of sensors [1].\n",
      "Consequently, it necessitates long-term time-series forecasting\n",
      "methods with demanding accuracy and efficiency to assist\n",
      "decision makers and engineers in the appraisal of sensor\n",
      "statuses and future plans. Since traditional forecasting methods\n",
      "based on statistics [2], [3] are no longer sufficient for such so-\n",
      "phisticated situations, more and more data scientists pay their\n",
      "attention to deep time-series forecasting [4]. After decades of\n",
      "development and competition, Time-Series Forecasting MLP\n",
      "(TSFM) [5]‚Äì[7] and Time-Series Forecasting Transformer\n",
      "(TSFT) [8]‚Äì[11] become the mainstream.\n",
      "B. Problems\n",
      "TSFM and TSFT have different pros and cons. TSFM is\n",
      "known for its parsimonious but efficient architecture so that\n",
      "Manuscript received xxxx; revised xxxx. (Corresponding author: Li Shen)\n",
      "Li Shen, Yuning Wei, Yangzhu Wang and Huaxin Qiu are with Beihang\n",
      "University, Beijing, China. (email: shenli@buaa.edu.cn; yuning@buaa.edu.cn;\n",
      "wangyangzhu@buaa.edu.cn; qiuhuaxin@buaa.edu.cn)forecasting models based on TSFM excel in resisting non-\n",
      "stationarity brought by distribution shifts [12] and concept\n",
      "drifts [13]. Conversely, forecasting models based on TSFT\n",
      "own more complicated architecture and better capability of\n",
      "capturing long-term dependencies of time-series at the expense\n",
      "of being more vulnerable to over-fitting problem caused by\n",
      "non-stationarity [5]. Fortunately, pioneers have striven to get\n",
      "around plenty of problems of TSFT. Direct forecasting strategy\n",
      "[14] reduces the time complexity and alleviates the error\n",
      "accumulation problem [15]. RevIN [12] solves the problem of\n",
      "distribution shifts among windows with distinct time spans.\n",
      "The channel-independent [16] forecasting method renders\n",
      "TSFT refraining from extracting vague inter-relationships of\n",
      "different variables. Patch-wise attention mechanism [10], [16]\n",
      "further attenuates the space complexity and brings the capabil-\n",
      "ity of local feature extraction to TSFT. Indeed, recent works\n",
      "have proven that TSFT models [9], [17] can also be stable\n",
      "and robust in forecasting. Evidently, the majority of these\n",
      "enhancement focus on improving the encoder architecture and\n",
      "tackling input sequence features. It cannot be denied that they\n",
      "are very important, but not solely. The connections of input\n",
      "and prediction sequences, manifested by decoder in TSFT, are\n",
      "also of paramount significance, especially for pursuing precise\n",
      "forecasting in IoT. However, its significance is frequently\n",
      "omitted and itself is inadequately explored. Normally, the\n",
      "decoder architectures of existing TSFT models are simply\n",
      "duplicates of their encoder architectures, barring with little\n",
      "indispensable modifications, such like changing self-attentions\n",
      "to cross-attentions [8], [15]. Furthermore, some researchers\n",
      "have gone so far as to substitute decoder in TSFT with simple\n",
      "linear projection [16], [18], which is analogous to TSFM,\n",
      "for the sake of enhancing their efficiency. Now it is time to\n",
      "enhance the decoder of TSFT to fully develop its potential and\n",
      "push its forecasting performances to a new altitude.\n",
      "C. Contributions\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Proceedings of Machine Learning Research 225:1‚Äì22, 2023 Machine Learning for Health (ML4H) 2023\n",
      "Temporal Supervised Contrastive Learning\n",
      "for Modeling Patient Risk Progression\n",
      "Shahriar Noroozizadeh snoroozi@cs.cmu.edu\n",
      "Carnegie Mellon University, Pittsburgh, PA, USA\n",
      "Jeremy C. Weiss jeremy.weiss@nih.gov\n",
      "National Library of Medicine, Bethesda, MD, USA\n",
      "George H. Chen georgechen@cmu.edu\n",
      "Carnegie Mellon University, Pittsburgh, PA, USA\n",
      "Abstract\n",
      "We consider the problem of predicting how the\n",
      "likelihood of an outcome of interest for a pa-\n",
      "tient changes over time as we observe more of\n",
      "the patient‚Äôs data. To solve this problem, we\n",
      "propose a supervised contrastive learning frame-\n",
      "work that learns an embedding representation\n",
      "for each time step of a patient time series. Our\n",
      "framework learns the embedding space to have\n",
      "the following properties: (1) nearby points in\n",
      "the embedding space have similar predicted class\n",
      "probabilities, (2) adjacent time steps of the same\n",
      "time series map to nearby points in the embed-\n",
      "ding space, and (3) time steps with very different\n",
      "raw feature vectors map to far apart regions of\n",
      "the embedding space. To achieve property (3),\n",
      "we employ a nearest neighbor pairing mechanism\n",
      "in the raw feature space. This mechanism also\n",
      "serves as an alternative to ‚Äúdata augmentation‚Äù,\n",
      "a key ingredient of contrastive learning, which\n",
      "lacks a standard procedure that is adequately re-\n",
      "alistic for clinical tabular data, to our knowledge.\n",
      "We demonstrate that our approach outperforms\n",
      "state-of-the-art baselines in predicting mortality\n",
      "ofsepticpatients(MIMIC-IIIdataset)andtrack-\n",
      "ing progression of cognitive impairment (ADNI\n",
      "dataset). Our method also consistently recovers\n",
      "the correct synthetic dataset embedding struc-\n",
      "ture across experiments, a feat not achieved by\n",
      "baselines. Our ablation experiments show the\n",
      "pivotal role of our nearest neighbor pairing.\n",
      "Keywords: contrastive learning, time series\n",
      "analysis, nearest neighbors\n",
      "1. Introduction\n",
      "Modeling disease progression patterns of patients is\n",
      "crucial for developing treatment strategies. Under-\n",
      "standing and learning these patterns from longitudinal\n",
      "tabular data, commonly found in healthcare, can be\n",
      "challenging. These time series often vary in length,\n",
      "exhibit irregular sampling, and have many missing\n",
      "entries. To this end, various methods have emerged\n",
      "in recent years to model such tabular time series data.These methods can broadly be categorized into those\n",
      "that focus only on predicting patient outcomes (e.g.,\n",
      "Choi et al. 2016; Ma et al. 2017; Devlin et al. 2019;\n",
      "Mollura et al. 2021), and those that jointly cluster\n",
      "patients and predict their outcomes (e.g., Lee and Van\n",
      "Der Schaar 2020; Lee et al. 2020; Huang et al. 2021;\n",
      "Carr et al. 2021; Aguiar et al. 2022; Qin et al. 2023).\n",
      "The mentioned approaches have several limitations.\n",
      "Specifically, prediction-focused models often struggle\n",
      "to differentiate patients with differing characteristics\n",
      "but the same outcome. For instance, predicting in-\n",
      "hospital mortality from patient time series may yield\n",
      "the same risk for an elderly patient with liver dysfunc-\n",
      "tion and a young patient with renal failure, despite\n",
      "them needing different treatments. In such a case,\n",
      "coarse prediction labels (e.g., in-hospital mortality\n",
      "which encompass diverse underlying causes) do not\n",
      "encourage prediction-centric models to capture clini-\n",
      "cally relevant details. This is because the model is not\n",
      "required to recognize the semantic differences between\n",
      "these two patients directly to achieve high prediction\n",
      "power. We term this challenge as capturing ‚Äúraw\n",
      "feature heterogeneity‚Äù, where distinguishing patients\n",
      "with identical classification outcomes and contrasting\n",
      "raw features becomes a difficulty.\n",
      "For models that jointly cluster patients and predict\n",
      "their outcomes, these models tend to be less accurate\n",
      "thanmodelssolelyfocusedonprediction. Forexample,\n",
      "in the supervised temporal clustering models by Lee\n",
      "and Van Der Schaar (2020) and Aguiar et al. (2022),\n",
      "a prediction neural network is first initialized, after\n",
      "which a clustering module is then added to approx-\n",
      "imate the encoding representation of the prediction\n",
      "model. This approximation incurs some loss in infor-\n",
      "mation such that using a patient‚Äôs assigned cluster\n",
      "to predict the patient‚Äôs outcome has worse accuracy\n",
      "than using the original prediction network.\n",
      "The supervised temporal clustering models by Lee\n",
      "and Van Der Schaar (2020) and Aguiar et al. (2022)\n",
      "are also learned in a manner that arguably depends\n",
      "too much on user-specified design choices. Specifically\n",
      "¬©2023 S. Noroozizadeh, J.C. Weiss & G.H. Chen.arXiv:2312.05933v1  [cs.LG]  10 Dec 2023Temporal Supervised Contrastive Learning\n",
      "these models employ k-means for initializing clusters,\n",
      "where the user must specify the number of clusters to\n",
      "use. Using a different clustering algorithm or number\n",
      "of clusters could drastically change the results. This\n",
      "situation may demand costly model re-training if a\n",
      "user finds the learned clusters to be hard to interpret,\n",
      "or either too fine or t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Large Multimodal Model Compression via Efficient Pruning and\n",
      "Distillation at AntGroup\n",
      "Maolin Wang‚àó‚Ä†\n",
      "City University of Hong Kong\n",
      "Hong Kong SAR, China\n",
      "morin.wang@my.cityu.edu.hkYao Zhao‚àó\n",
      "AntGroup\n",
      "Hangzhou, China\n",
      "nanxiao.zy@antgroup.comJiajia Liu\n",
      "AntGroup\n",
      "Hangzhou, China\n",
      "lekun.ljj@antgroup.com\n",
      "Jingdong Chen\n",
      "AntGroup\n",
      "Hangzhou, China\n",
      "jingdongchen.cjd@antgroup.comChenyi Zhuang\n",
      "AntGroup\n",
      "Hangzhou, China\n",
      "chenyi.zcy@antgroup.comJinjie Gu\n",
      "AntGroup\n",
      "Hangzhou, China\n",
      "jinjie.gujj@antgroup.com\n",
      "Ruocheng Guo\n",
      "ByteDance Research\n",
      "London, UK\n",
      "rguo.asu@gmail.comXiangyu Zhao\n",
      "City University of Hong Kong\n",
      "Hong Kong SAR, China\n",
      "xianzhao@cityu.edu.hk\n",
      "ABSTRACT\n",
      "The deployment of Large Multimodal Models (LMMs) within AntGroup\n",
      "has significantly advanced multimodal tasks in payment, security,\n",
      "and advertising, notably enhancing advertisement audition tasks in\n",
      "Alipay. However, the deployment of such sizable models introduces\n",
      "challenges, particularly in increased latency and carbon emissions,\n",
      "which are antithetical to the ideals of Green AI. This paper intro-\n",
      "duces a novel multi-stage compression strategy for our proprietary\n",
      "LLM, AntGMM. Our methodology pivots on three main aspects:\n",
      "employing small training sample sizes, addressing multi-level redun-\n",
      "dancy through multi-stage pruning, and introducing an advanced\n",
      "distillation loss design. In our research, we constructed a dataset,\n",
      "the Multimodal Advertisement Audition Dataset (MAAD), from\n",
      "real-world scenarios within Alipay, and conducted experiments to\n",
      "validate the reliability of our proposed strategy. Furthermore, the\n",
      "effectiveness of our strategy is evident in its operational success in\n",
      "Alipay‚Äôs real-world multimodal advertisement audition for three\n",
      "months from September 2023. Notably, our approach achieved a\n",
      "substantial reduction in latency, decreasing it from 700ms to 90ms,\n",
      "while maintaining online performance with only a slight perfor-\n",
      "mance decrease. Moreover, our compressed model is estimated to\n",
      "reduce electricity consumption by approximately 75 million kWh\n",
      "‚àóBoth authors contributed equally to this research.\n",
      "‚Ä†All work performed during internship at AntGroup\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for components of this work owned by others than ACM\n",
      "must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\n",
      "to post on servers or to redistribute to lists, requires prior specific permission and/or a\n",
      "fee. Request permissions from permissions@acm.org.\n",
      "Arxiv Preprint, ,\n",
      "¬©2023 Association for Computing Machinery.\n",
      "ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00\n",
      "https://doi.org/XXXXXXX.XXXXXXXannually compared to the direct deployment of AntGMM, demon-\n",
      "strating our commitment to green AI initiatives. We will publicly\n",
      "release our code and the MAAD dataset after some reviews1.\n",
      "KEYWORDS\n",
      "Large Language Model, Large Multimoda Model, Model Compres-\n",
      "sion, Pruning, Distillation, Efficient Inference\n",
      "ACM Reference Format:\n",
      "Maolin Wang, Yao Zhao, Jiajia Liu, Jingdong Chen, Chenyi Zhuang, Jin-\n",
      "jie Gu, Ruocheng Guo, and Xiangyu Zhao. 2023. Large Multimodal Model\n",
      "Compression via Efficient Pruning and Distillation at AntGroup. In Pro-\n",
      "ceedings of (Arxiv Preprint). ACM, New York, NY, USA, 11 pages. https:\n",
      "//doi.org/XXXXXXX.XXXXXXX\n",
      "1 INTRODUCTION\n",
      "The advent of Large Language Models (LLMs) [ 3,4,36,41] marks a\n",
      "significant milestone in Artificial Intelligence (AI). An even broader\n",
      "paradigm, the Large Multimodal Model (LMM) [ 21,29,45], expands\n",
      "the capabilities of LLMs by incorporating visual signals. LMMs\n",
      "excel not only in handling and generating substantial textual-only\n",
      "tasks, but also demonstrate impressive performance in various\n",
      "multimodal tasks, such as video recommendations [ 43], image un-\n",
      "derstanding [ 1], and dialogue systems [ 6]. Particularly within our\n",
      "AntGroup, a leading technology company specializing in finan-\n",
      "cial services and digital payments, LMMs have achieved significant\n",
      "improvements in multimodal tasks related to video-text comprehen-\n",
      "sion and image-text comprehension in our platform and advertising\n",
      "sectors. Specifically, in the scenarios of short video categorization\n",
      "on Alipay, a platform renowned in China for its extensive finan-\n",
      "cial services and digital payment solutions, we observed a notable\n",
      "4.2%enhancement in the accuracy of primary category classifica-\n",
      "tion. Regarding the multimodal advertisement audition task on the\n",
      "same platform, we recorded a substantial 18.7%increase in attribute\n",
      "recognition accuracy. Furthermore, LMMs have demonstrated a sig-\n",
      "nificant improvement in digital advertising effectiveness, evidenced\n",
      "1https://github.com/MorinW/AntGMM_PruningarXiv:2312.05795v1  [cs.AI]  10 Dec 2023Arxiv Preprint, , Maolin Wang, Yao Zhao, Jiajia Liu, Jingdong Chen, Chenyi Zhuang, Jinjie Gu, Ruocheng Guo, and Xiangyu Zhao\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fine-Tuning or Retrieval?\n",
      "Comparing Knowledge Injection in LLMs\n",
      "Oded Ovadia*‚Ä†, Menachem Brief‚Ä†, Moshik Mishaeli, and Oren Elisha\n",
      "{odedovadia,t-mbrief,mmishaeli,oren.elisha }@microsoft.com\n",
      "Microsoft, Israel\n",
      "Abstract\n",
      "Large language models (LLMs) encapsulate a\n",
      "vast amount of factual information within their\n",
      "pre-trained weights, as evidenced by their abil-\n",
      "ity to answer diverse questions across different\n",
      "domains. However, this knowledge is inherently\n",
      "limited, relying heavily on the characteristics of\n",
      "the training data. Consequently, using external\n",
      "datasets to incorporate new information or re-\n",
      "fine the capabilities of LLMs on previously seen\n",
      "information poses a significant challenge. In\n",
      "this study, we compare two common approaches:\n",
      "fine-tuning and retrieval-augmented generation\n",
      "(RAG). We evaluate both approaches on a vari-\n",
      "ety of knowledge-intensive tasks across different\n",
      "topics. Our findings reveal that while fine-tuning\n",
      "offers some improvement, RAG consistently out-\n",
      "performs it, both for existing knowledge encoun-\n",
      "tered during training and entirely new knowledge.\n",
      "Moreover, we find that LLMs struggle to learn\n",
      "new factual information through fine-tuning, and\n",
      "that exposing them to numerous variations of the\n",
      "same fact during training could alleviate this prob-\n",
      "lem.\n",
      "1. Introduction\n",
      "Large language models (LLMs) are able to capture vast\n",
      "amounts of factual information (Petroni et al., 2019; Cohen\n",
      "et al., 2023; Hu et al., 2023). LLMs exhibit a remarkable\n",
      "level of knowledge in various domains due to their massive\n",
      "pre-training datasets. However, there are two significant\n",
      "limitations to this knowledge. First, it is static and does\n",
      "not update with time. Second, it is non-specific and thus\n",
      "may lack nuanced expertise in particular domains. While\n",
      "these are two different problems, they are deeply related\n",
      "since their solution is the same: enhancing the model‚Äôs\n",
      "knowledge.\n",
      "*Corresponding author.\n",
      "‚Ä†Equal contribution.Recently, the idea of adapting LLMs to particular domains\n",
      "and updating their knowledge has become increasingly com-\n",
      "mon (Yu et al., 2022). Various models have been suggested\n",
      "to improve factual knowledge and capabilities in diverse\n",
      "fields such as healthcare (Singhal et al., 2023a;b; Wu et al.,\n",
      "2023a), finance (Wu et al., 2023b; Yang et al., 2023), and\n",
      "law (Huang et al., 2023; Nguyen, 2023).\n",
      "In this work, we focus on the evaluation of a model‚Äôs knowl-\n",
      "edge and its ability to memorize, understand, and retrieve\n",
      "factual data. We aim to understand the concept of knowl-\n",
      "edge injection (Wang et al., 2020; Chen et al., 2022; Liu\n",
      "et al., 2020; Lauscher et al., 2020). Given some knowledge\n",
      "base in the form of a text corpus, what is the best way to\n",
      "teach a pre-trained model this knowledge?\n",
      "One way to add knowledge to a pre-trained model is through\n",
      "fine-tuning. With fine-tuning, we continue the model‚Äôs train-\n",
      "ing process and adapt it using task-specific data. By expos-\n",
      "ing the model to a specific knowledge base, we expect the\n",
      "model weights to adapt accordingly. This process is meant\n",
      "to optimize the model for targeted applications, enhanc-\n",
      "ing its performance and contextual relevance in specialized\n",
      "domains.\n",
      "Another method to enhance a model‚Äôs knowledge base is\n",
      "through the use of in-context learning (ICL) (Chen et al.,\n",
      "2021; Radford et al., 2019; Min et al., 2021; Lampinen\n",
      "et al., 2022). The main idea behind ICL is to improve the\n",
      "performance of pre-trained LLMs on new tasks by modify-\n",
      "ing the input query to the model without directly changing\n",
      "the weights of the model. One form of ICL is retrieval aug-\n",
      "mented generation (RAG) (Lewis et al., 2020; Neelakantan\n",
      "et al., 2022). RAG uses information retrieval techniques to\n",
      "enable LLMs to obtain relevant information from a knowl-\n",
      "edge source and incorporate it into generated text.\n",
      "This study aims to evaluate the knowledge injection capa-\n",
      "bilities of LLMs through a comparison of fine-tuning and\n",
      "RAG. To illustrate the rationale, let us use an analogy. Con-\n",
      "sider three college students taking a test on a specific topic.\n",
      "All had access to class materials but didn‚Äôt know the topic\n",
      "beforehand. The first student had the textbook only during\n",
      "1arXiv:2312.05934v1  [cs.AI]  10 Dec 2023Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs\n",
      "the test, the second had pre-test access and studied, and the\n",
      "third lost access upon the test announcement. Who would\n",
      "probably perform better?\n",
      "2. Background\n",
      "To assess knowledge injection , we must first understand\n",
      "what knowledge means for LLMs.\n",
      "Knowledge and Language Models Defining knowledge\n",
      "is a complex philosophical task far beyond the scope of this\n",
      "research. However, we can examine what factual knowledge\n",
      "means in the context of language models. If a model knows\n",
      "a fact, it can accurately and consistently answer questions\n",
      "about it. Furthermore, it can reliably distinguish between\n",
      "true and false statements related to this fact. We can then\n",
      "extend this definition to a whole knowledge base, not just a\n",
      "single fact.\n",
      "Mathematically, let Q={qn}N\n",
      "n=1be a set of Nmu\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Multimodality in Online Education : A C omparative Study\n",
      "Preprint ,compiled December 12, 2023\n",
      "Praneeta Immadisetty1‚àó, Pooja Rajesh1, Akshita Gupta1, Anala M R2, Soumya A1, and K. N. Subramanya3\n",
      "1Department of Computer Science, RV College of Engineering\n",
      "2Department of Information Science, RV College of Engineering\n",
      "3RV College of Engineering\n",
      "Abstract\n",
      "The commencement of the decade brought along with it a grave pandemic and in response the movement of\n",
      "education forums predominantly into the online world. With a surge in the usage of online video conferencing\n",
      "platforms and tools to better gauge student understanding, there needs to be a mechanism to assess whether\n",
      "instructors can grasp the extent to which students understand the subject and their response to the educational\n",
      "stimuli. The current systems consider only a single cue with a lack of focus in the educational domain. Thus,\n",
      "there is a necessity for the measurement of an all-encompassing holistic overview of the students‚Äô reaction\n",
      "to the subject matter. This paper highlights the need for a multimodal approach to a ffect recognition and its\n",
      "deployment in the online classroom while considering four cues, posture and gesture, facial, eye tracking and\n",
      "verbal recognition. It compares the various machine learning models available for each cue and provides the\n",
      "most suitable approach given the available dataset and parameters of classroom footage. A multimodal approach\n",
      "derived from weighted majority voting is proposed by combining the most fitting models from this analysis of\n",
      "individual cues based on accuracy, ease of procuring data corpus, sensitivity and any major drawbacks.\n",
      "Keywords Affect Recognition¬∑Custom Dataset¬∑Multimodal Architecture ¬∑Non Verbal Cues¬∑Decision-level Fusion\n",
      "1 I ntroduction\n",
      "Affect Recognition or Emotion Recognition refers to the ability\n",
      "to identify non verbal (NV) cues such as facial expressions, body\n",
      "language, tone of speech and physiological signal interpretation.\n",
      "Emotion recognition becomes an essential parallel form of com-\n",
      "munication apart from the most widely used method of verbal\n",
      "communication. It helps to identify the tone of communication\n",
      "and helps allot context to the individual‚Äôs thought process. In\n",
      "certain situations where true a ffective status is required to be\n",
      "identified, non verbal behaviour is more accurate in comparison\n",
      "to verbal behaviour. In fact, research has found that tone of\n",
      "speech is the most di fficult cue to consciously control, thereby\n",
      "reinforcing the need to assist verbal communication with NV\n",
      "cues for complete context identification and emotion recognition\n",
      "[1]. Verbal cues are vocalised opinions made consciously. Ver-\n",
      "bal cues pose a threat of biassed feedback, whereas extracting\n",
      "analytics from NV cues eliminates this issue. However, to iden-\n",
      "tify emotions based on these NV cues is a complex task. NV\n",
      "cues refer to cues that are involuntary. They need to be analysed\n",
      "before reaching any deterministic value.\n",
      "The aforementioned NV cues however, are not as accurate and\n",
      "could prove to be ambiguous when analysed individually. Since\n",
      "emotions can have a wide range, a single cue may not su ffice\n",
      "for the most cohesive a ffect recognition. For this reason, there\n",
      "is a need to combine multiple modalities for better assessment\n",
      "of human emotions. Employing multiple cues for identifying\n",
      "the emotional state leads to a more robust and realistic output,\n",
      "which is closer to a real-world scenario. The parameters that\n",
      "can contribute to the culmination of NV cues include posture,\n",
      "gesture, eye-tracking, speech recognition, facial recognition.\n",
      "These parameters together comprise the di fferent modalities of\n",
      "Multimodal A ffect Recognition (MAR). Moreover, given their\n",
      "non deterministic and involuntary nature, these cues cannot be\n",
      "modified or hampered with, and must lead to an accurate andunbiased feedback. Seeing emotion recognition from a multi-\n",
      "modal perspective ensures the lack of domination of a singular\n",
      "characteristic that promises a more sensitive reaction to human\n",
      "engagement. In some scenarios, where certain cues cannot be\n",
      "properly identified or used, it becomes essential to combine\n",
      "the outputs from the other cues in a deterministic manner to\n",
      "facilitate the complete understanding of the emotion.\n",
      "There have been several attempts to use emotions as a medium\n",
      "of deeper understanding under various circumstances. This in-\n",
      "cludes a ffect recognition in classroom environments, driving\n",
      "simulations, autonomous cars, analysing visual media appeal,\n",
      "medical diagnosis, etc. Thus, emotion recognition becomes vital\n",
      "in fields where one cue, in most cases, verbal communication, is\n",
      "not su fficient to gather information. These situations include stu-\n",
      "dents of younger age groups who haven‚Äôt fully developed means\n",
      "to communicate their needs, special needs patients and also on-\n",
      "line education. Emotions are a vital source for understanding\n",
      "the extent of students‚Äô engagement in online education. They\n",
      "can be incremental in determining the response of students\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Lagrangian Properties and Control of Soft Robots\n",
      "Modeled with Discrete Cosserat Rods.\n",
      "Lekan Molu, Shaoru Chen, and Audrey Sedal\n",
      "Abstract ‚ÄîThe characteristic ‚Äúin-plane‚Äù bending associated\n",
      "with soft robots‚Äô deformation make them preferred over rigid\n",
      "robots in sophisticated manipulation and movement tasks.\n",
      "Executing such motion strategies to precision in soft deformable\n",
      "robots and structures is however fraught with modeling and\n",
      "control challenges given their infinite degrees-of-freedom.\n",
      "Imposing piecewise constant strains (PCS) across (discretized)\n",
      "Cosserat microsolids on the continuum material however,\n",
      "their dynamics become amenable to tractable mathematical\n",
      "analysis. While this PCS model handles the characteristic\n",
      "difficult-to-model ‚Äúin-plane‚Äù bending well, its Lagrangian\n",
      "properties are not exploited for control in literature neither\n",
      "is there a rigorous study on the dynamic performance of\n",
      "multisection deformable materials for ‚Äúin-plane‚Äù bending\n",
      "that guarantees steady-state convergence. In this sentiment,\n",
      "we first establish the PCS model‚Äôs structural Lagrangian\n",
      "properties. Second, we exploit these for control on various\n",
      "strain goal states. Third, we benchmark our hypotheses against\n",
      "an Octopus-inspired robot arm under different constant tip\n",
      "loads. These induce non-constant ‚Äúin-plane‚Äù deformation and\n",
      "we regulate strain states throughout the continuum in these\n",
      "configurations. Our numerical results establish convergence\n",
      "to desired equilibrium throughout the continuum in all of\n",
      "our tests. Within the bounds here set, we conjecture that\n",
      "our methods can find wide adoption in the control of cable-\n",
      "and fluid-driven multisection soft robotic arms; and may be\n",
      "extensible to the (learning-based) control of deformable agents\n",
      "employed in simulated, mixed, or augmented reality.\n",
      "Supplementary material ‚Äî The codes for reproducing\n",
      "the experiments reported in this paper are available online:\n",
      "https://github.com/robotsorcerer/dcm.\n",
      "I. I NTRODUCTION\n",
      "Soft robots are attracting wide adoption in the automation\n",
      "community owing to their improved bending, torsion, config-\n",
      "urability, and compliance properties. These properties enable\n",
      "customizable solutions for assistive wearable devices [23,\n",
      "1], robot grippers [12], and mobile robots [13]. In-plane\n",
      "bending, as a motion deformation strategy, is a particular\n",
      "advantage that serial soft arms execute better than rigid arms.\n",
      "With this property, soft robot grippers can pick up delicate\n",
      "objects, adopt adept nonlinear motion strategies in complex\n",
      "workspaces e.g. for reaching tasks. In embodied applications\n",
      "such as soft exogloves [16] and exosuits [14], they provide\n",
      "conformal deformation that aids improved walking gaits, and\n",
      "muscle rehabilitation and they conserve energy economy.\n",
      "Lekan Molu and Shaoru Chen are with Microsoft Research NYC.\n",
      "Audrey Sedal is with McGill University‚Äôs Department of Mechani-\n",
      "cal Engineering. Emails: {lekanmolu, shaoruchen }@microsoft.com, au-\n",
      "drey.sedal@mcgill.ca.\n",
      "Fig. 1. Schematic of the configuration of an Octopus robot arm.\n",
      "The piecewise constant strain (PCS) Lagrangian dynamics\n",
      "derived by [18] is a reduced special Euclidean group-\n",
      "3 (SE(3)) model for compliant, serial manipulators. De-\n",
      "rived from Cosserat [6] rod theory, it addresses torsion,\n",
      "in-plane, and out-of-plane (multi-) bending motions. The\n",
      "PCS model outperforms the common piecewise constant\n",
      "curvature (PCC) [17] and the constant curvature variants [8]\n",
      "used outside of finite element modeling methods (FEM) [5].\n",
      "Controllers deployed on the PCS model however ignore the\n",
      "geometric properties of the Lagrangian dynamics [4, 22].\n",
      "This makes the control equations complicated and destroys\n",
      "several properties of the Lagrangian dynamics that are useful\n",
      "for control tasks.\n",
      "In this sentiment, considering the PCS model for soft\n",
      "multisection arms, we first establish the structural properties\n",
      "of their Lagrangian dynamics. We then exploit these for\n",
      "the steady-state convergence analyses in various control\n",
      "proposals (under different operating model parameters) and\n",
      "in different surrounding mediums using the well-established\n",
      "method of Lyapunov analysis. The Octopus robot [11], a\n",
      "muscular hydrostat [9] with distributed deformation through-\n",
      "out its articulated arms, blends the interplay between con-\n",
      "tinuum mechanics and sensorimotor control well. Thus,\n",
      "we consider a single arm of the CyberOctopus [20] (con-arXiv:2312.05937v1  [cs.RO]  10 Dec 2023figuration shown in Fig. 1) to benchmark our controllers\n",
      "on the characteristic difficult-to-model-and-control in-plane\n",
      "bending deformation .\n",
      "The rest of this paper is structured as follows: in ¬ßII, we\n",
      "briefly introduce preliminaries relevant to the contributions\n",
      "machinery we present in ¬ßIII. Multivariable stabilizing feed-\n",
      "back controllers for regulating the tip point and strain states\n",
      "are established in ¬ßIV. We present numerical results in ¬ßV\n",
      "and conclude the paper in ¬ßVI.\n",
      "II. N OTATIONS AND PRELIMINARIES\n",
      "The strain field and strain twist vectors are respectively\n",
      "Œæ‚ààR6andŒ∑‚ààR6. The Lie algebra of S\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "Disentangled Representation Learning for\n",
      "Controllable Person Image Generation\n",
      "Wenju Xu, Chengjiang Long, Yongwei Nie and Guanghui Wang, Senior Member, IEEE .\n",
      "Abstract ‚ÄîIn this paper, we propose a novel framework named\n",
      "DRL-CPG to learn disentangled latent representation for con-\n",
      "trollable person image generation, which can produce realistic\n",
      "person images with desired poses and human attributes ( e.g.\n",
      "pose, head, upper clothes, and pants) provided by various source\n",
      "persons. Unlike the existing works leveraging the semantic masks\n",
      "to obtain the representation of each component, we propose to\n",
      "generate disentangled latent code via a novel attribute encoder\n",
      "with transformers trained in a manner of curriculum learning\n",
      "from a relatively easy step to a gradually hard one. A random\n",
      "component mask-agnostic strategy is introduced to randomly\n",
      "remove component masks from the person segmentation masks,\n",
      "which aims at increasing the difficulty of training and promoting\n",
      "the transformer encoder to recognize the underlying boundaries\n",
      "between each component. This enables the model to transfer\n",
      "both the shape and texture of the components. Furthermore, we\n",
      "propose a novel attribute decoder network to integrate multi-level\n",
      "attributes ( e.g.the structure feature and the attribute representa-\n",
      "tion) with well-designed Dual Adaptive Denormalization (DAD)\n",
      "residual blocks. Extensive experiments strongly demonstrate that\n",
      "the proposed approach is able to transfer both the texture and\n",
      "shape of different human parts and yield realistic results. To\n",
      "our knowledge, we are the first to learn disentangled latent\n",
      "representations with transformers for person image generation.\n",
      "Index Terms ‚ÄîDisentangled representation, Transformer, con-\n",
      "trollable person synthesize.\n",
      "I. I NTRODUCTION\n",
      "Deep generative adversarial network [1], [2] has recently\n",
      "drawn increasing attention due to its impressive performance\n",
      "in image/video synthesis [3], [4], which shows great potential\n",
      "in dealing with MultiMedia applications [5], [6], [7]. For\n",
      "instance, exploring synthesized features has been proven to be\n",
      "an effective way to improve the performance of deep neural\n",
      "networks [8], [9], [10]. Manipulating facial images [11], [12],\n",
      "[13] and translating human faces into anime [14], [15] have\n",
      "become popular in social media applications. More recently,\n",
      "researchers have attempted to synthesize human images that\n",
      "can be controlled by user inputs [16], [17]. We can imag-\n",
      "ine that using synthesized digital humans for broadcasting,\n",
      "advertising, and educating will be promising. However, this\n",
      "is still an open problem that needs more endeavor and will\n",
      "significantly impact multimedia society.\n",
      "W. Xu is with AMAZON, Palo Alto, CA 94301 USA (e-mail:\n",
      "xuwenju@amazon.com).\n",
      "C. Long is with the META Reality Labs, Burlingame, CA, USA. Email:\n",
      "cjfykx@gmail.com.\n",
      "Y . Nie is with the South China University of Technology, Guangzhou,\n",
      "Guangdong, China, Email: nieyongwei@scut.edu.cn.\n",
      "G. Wang is with the Department of Computer Science, Toronto\n",
      "Metropolitan University, 350 Victoria St, Toronto, ON M5B 2K3. Email:\n",
      "wangcs@ryerson.ca.\n",
      "Fig. 1: Given a target pose and source person images with\n",
      "semantic masks, the goal of this paper is to design a uni-\n",
      "fied approach for controllable person image generation and\n",
      "attribute transfer.\n",
      "Controllable person image generation aims to synthesize a\n",
      "person image conditioned on the given pose and attributes at\n",
      "the component-level from source person images with the cor-\n",
      "responding semantic masks, preserving attributes like person\n",
      "identity, cloth color, cloth texture, background etc., as shown\n",
      "in Figure 1. This topic has attracted great attention due to\n",
      "its potentially wide applications in movie composition, image\n",
      "editing, person re-identification, virtual clothes try-on, and so\n",
      "on.\n",
      "ADGAN [18] was proposed as the first work for controllable\n",
      "person attribute editing based on the semantic mask to separate\n",
      "each component. Although it achieves success in controllable\n",
      "image editing, the synthesized images are not realistic. In\n",
      "particular, separation in image level does not guarantee the\n",
      "disentanglement of the encoded attributes. Moreover, editing\n",
      "person attributes by simply replacing the entangled semantic\n",
      "representations tends to create artifacts or unrealistic results.\n",
      "To solve the above issues of previous work, we propose\n",
      "a novel and unified framework, termed as DRL-CPG, for\n",
      "controllable person synthetic image generation. As shown in\n",
      "Figure 2, the framework consists of two major parts, i.e.an\n",
      "attribute encoder with transformers learned to generate disen-\n",
      "tangled representation and an attribute decoder that integrates\n",
      "the structure features and attribute representations for control-\n",
      "lable person image generation. In contrast to ADGAN [18]\n",
      "which encodes each component into latent code directly, we\n",
      "introduce transformers [19] in the attribute encoder to generate\n",
      "an intermediate representation set for each component andarXiv:2312.05798v1  [cs.CV]  10 Dec 20232\n",
      "select the corresponding one a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ASH: Animatable Gaussian Splats for Efficient and Photoreal Human Rendering\n",
      "Haokai Pang1,2 ‚Ä†Heming Zhu1 ‚Ä†Adam Kortylewski1,3Christian Theobalt1,4Marc Habermann1,4B\n",
      "1Max Planck Institute for Informatics, Saarland Informatics Campus\n",
      "2ETH Z ¬®urich3Universit ¬®at Freiburg\n",
      "4Saarbr ¬®ucken Research Center for Visual Computing, Interaction and AI\n",
      "{hpang, hezhu, akortyle, theobalt, mhaberma }@mpi-inf.mpg.de\n",
      "Figure 1. ASH takes an arbitrary 3D skeletal pose and virtual camera view, which can be controlled by the user, as input, and generates a\n",
      "photorealistic rendering of the human in real time. To achieve this, we propose an efficient and animatable Gaussian representation, which\n",
      "is parameterized on the surface of a deformable template mesh.\n",
      "Abstract\n",
      "Real-time rendering of photorealistic and controllable\n",
      "human avatars stands as a cornerstone in Computer Vision\n",
      "and Graphics. While recent advances in neural implicit ren-\n",
      "dering have unlocked unprecedented photorealism for digi-\n",
      "tal avatars, real-time performance has mostly been demon-\n",
      "strated for static scenes only. To address this, we propose\n",
      "ASH, an animatable Gaussian splatting approach for pho-\n",
      "torealistic rendering of dynamic humans in real time. We\n",
      "parameterize the clothed human as animatable 3D Gaus-\n",
      "sians, which can be efficiently splatted into image space\n",
      "to generate the final rendering. However, naively learning\n",
      "the Gaussian parameters in 3D space poses a severe chal-\n",
      "lenge in terms of compute. Instead, we attach the Gaussians\n",
      "onto a deformable character model, and learn their param-\n",
      "eters in 2D texture space, which allows leveraging efficient\n",
      "2D convolutional architectures that easily scale with the re-\n",
      "quired number of Gaussians. We benchmark ASH with com-\n",
      "peting methods on pose-controllable avatars, demonstrat-\n",
      "ing that our method outperforms existing real-time methods\n",
      "by a large margin and shows comparable or even better re-\n",
      "sults than offline methods.\n",
      "‚Ä† Joint first authors.\n",
      "BCorresponding author.\n",
      "Project page: vcai.mpi-inf.mpg.de/projects/ash1. Introduction\n",
      "Generating high-fidelity human renderings is a long-\n",
      "standing problem in the field of Computer Graphics and Vi-\n",
      "sion, with a multitude of real-world applications, such as\n",
      "gaming, film production, and AR/VR. Typically, this pro-\n",
      "cess is a laborious task, requiring complicated hardware se-\n",
      "tups and tremendous efforts from skilled artists. To ease\n",
      "the extensive manual efforts, recent advances, including this\n",
      "work, focus on generating photorealistic and controllable\n",
      "human avatars solely from multi-view videos.\n",
      "Recent works on photorealistic human rendering can\n",
      "be categorized into explicit-based and hybrid methods.\n",
      "Explicit methods represent the human avatar as a de-\n",
      "formable template mesh with learned dynamic textures [13,\n",
      "49]. Although these methods are runtime-efficient and\n",
      "can be seamlessly integrated with the well-established\n",
      "rasterization-based rendering pipeline, the generated ren-\n",
      "dering often falls short in terms of photorealism and level of\n",
      "detail. Hybrid approaches usually attach a neural radiance\n",
      "field (NeRF) [35] onto a (deformable) human model [14, 29,\n",
      "42]. Typically, they evaluate the NeRF in an unposed space\n",
      "to model the detailed appearance of clothed humans, and\n",
      "generate color and density values by querying a coordinate-\n",
      "based MLP per ray sample. Although hybrid methods can\n",
      "deliver superior rendering quality through NeRF‚Äôs capabil-\n",
      "ity to capture delicate appearance details, they are unsuit-\n",
      "1arXiv:2312.05941v1  [cs.CV]  10 Dec 2023able for real-time applications due to the intensive sampling\n",
      "and MLP evaluations required for volume rendering.\n",
      "Recently, 3D Gaussian splatting [22] with its impressive\n",
      "rendering quality and real-time capability, has become a\n",
      "promising alternative to NeRFs, which are parameterized\n",
      "with a coordinate-based MLP. However, it originally is only\n",
      "designed for modeling static scenes, which is in stark con-\n",
      "trast to our problem setting, i.e., modeling dynamic and an-\n",
      "imatable human avatars. Thus, one may ask: Can the ren-\n",
      "dering quality and speed of Gaussian splatting be leveraged\n",
      "to model the skeletal motion-dependent characteristics of\n",
      "clothed humans, and how can pose control be achieved?\n",
      "To answer this, we propose ASH, a real-time approach\n",
      "for generating photorealistic renderings of animatable hu-\n",
      "man avatars. Given a skeletal motion and a virtual camera\n",
      "view, ASH produces photorealistic renderings of clothed\n",
      "humans with motion-dependent details in real time (see\n",
      "Fig. 1). Importantly, during training, ASH only requires\n",
      "multi-view videos for supervision.\n",
      "In more detail, our animatable human avatar is parame-\n",
      "terized using Gaussian splats. However, naively learning a\n",
      "mapping from skeletal pose to Gaussian parameters in 3D\n",
      "is intractable given the limited compute budget when con-\n",
      "straining ourselves to real-time performance. Thus, we pro-\n",
      "pose to attach the Gaussians onto a deformable mesh tem-\n",
      "plate of the human. Given the mesh‚Äôs uv parameterization,\n",
      "it allows learning \n",
      "----------------------------------------------------------------------------------------------------\n",
      "SGNet: Structure Guided Network via Gradient-Frequency Awareness\n",
      "for Depth Map Super-Resolution\n",
      "Zhengxue Wang, Zhiqiang Yan*, Jian Yang*\n",
      "PCA Lab, Nanjing University of Science and Technology, China\n",
      "{zxwang,yanzq,csjyang }@njust.edu.cn\n",
      "Abstract\n",
      "Depth super-resolution (DSR) aims to restore high-resolution\n",
      "(HR) depth from low-resolution (LR) one, where RGB im-\n",
      "age is often used to promote this task. Recent image guided\n",
      "DSR approaches mainly focus on spatial domain to rebuild\n",
      "depth structure. However, since the structure of LR depth is\n",
      "usually blurry, only considering spatial domain is not very\n",
      "sufficient to acquire satisfactory results. In this paper, we pro-\n",
      "pose structure guided network (SGNet), a method that pays\n",
      "more attention to gradient and frequency domains, both of\n",
      "which have the inherent ability to capture high-frequency\n",
      "structure. Specifically, we first introduce the gradient cali-\n",
      "bration module (GCM), which employs the accurate gradient\n",
      "prior of RGB to sharpen the LR depth structure. Then we\n",
      "present the Frequency Awareness Module (FAM) that recur-\n",
      "sively conducts multiple spectrum differencing blocks (SDB),\n",
      "each of which propagates the precise high-frequency com-\n",
      "ponents of RGB into the LR depth. Extensive experimen-\n",
      "tal results on both real and synthetic datasets demonstrate\n",
      "the superiority of our SGNet, reaching the state-of-the-art\n",
      "(see Fig. 1). Codes and pre-trained models are available at\n",
      "https://github.com/yanzq95/SGNet.\n",
      "Introduction\n",
      "Image guided DSR has been widely applied in various fields,\n",
      "such as 3D reconstruction (Yuan et al. 2023a), virtual real-\n",
      "ity (Bonetti, Warnaby, and Quinn 2018), and augmented re-\n",
      "ality (Xiong et al. 2021). However, the blurry structure of\n",
      "LR depth caused by complex imaging environment still im-\n",
      "pedes their performance. For example, Fig. 2 (LR) shows\n",
      "that, the LR depth contain rich low-frequency content but\n",
      "are severely deficient in clear high-frequency structure. Re-\n",
      "cently, many DSR approaches (Yuan et al. 2023a; Shi, Ye,\n",
      "and Du 2022) are proposed to tackle this issue. However,\n",
      "most of them focus only on the spatial domain for recovery,\n",
      "which is not very sufficient to obtain desired results.\n",
      "For one thing , from (c)-(f) of Fig. 2 we discover that, the\n",
      "gradient features of RGB and HR contain highly discrimi-\n",
      "native object structure. Besides, although the degraded LR\n",
      "is terribly blurry, the gradient feature can still delineate its\n",
      "structure clearly. For another thing , from (h)-(j) of Fig. 2\n",
      "*Corresponding authors\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "2.02.53.03.54.04.55.05.56.06.5\n",
      "RGB-D-D Middlebury Lu NYU-v2RMSE (cm)DCTNetSUFT SGNet RSAG\n",
      "FDSR DKNFigure 1: RMSE comparison between our SGNet and exist-\n",
      "ing state-of-the-art methods on four benchmarks ( √ó16).\n",
      "we find that, the spectrum features of RGB and HR reserve\n",
      "not only low-frequency content (central area) but also high-\n",
      "frequency structure (corner area). In contrast, the spectrum\n",
      "feature of LR lacks a large number of high-frequency com-\n",
      "ponents. These evidences indicate that the gradient and spec-\n",
      "trum information can accurately depict the distribution of\n",
      "high-frequency structure. Consequently, motivated by these\n",
      "two observations, in this paper we pay more attention to gra-\n",
      "dient and frequency domains to take advantage of their in-\n",
      "herent properties for clear structure recovery .\n",
      "Gradient domain. We design the gradient calibration\n",
      "module (GCM) to leverage the powerful structure repre-\n",
      "sentation capability of gradient feature. Specifically, RGB\n",
      "and LR are first mapped into gradient domain (Ma et al.\n",
      "2020). Then the accurate RGB gradient prior is employed\n",
      "to calibrate the blurry structure of LR. Besides, we intro-\n",
      "duce a gradient-aware loss to further sharpen the structure\n",
      "via narrowing the distance between the intermediate feature\n",
      "of GCM and that of HR in gradient domain.\n",
      "Frequency domain. We present the Frequency Aware-\n",
      "ness Module (FAM), which recursively conducts multiple\n",
      "spectrum differencing blocks (SDB) to propagate the pre-\n",
      "cise high-frequency components (Yan et al. 2022b) of RGB.\n",
      "Concretely, SDB first maps RGB and LR into the same\n",
      "frequency domain. To explicitly compensate for the absent\n",
      "high-frequency components, i.e., the blank corner area of\n",
      "Fig. 2(j), SDB next employs subtraction between the spec-arXiv:2312.05799v3  [cs.CV]  13 Dec 2023(i) HR_S (g) RGB (j) LR_S (k) RGB_S     LR_S\n",
      " (l) Our_S (h) RGB_S(a) HR (b) LR (c) RGB_G (d) HR_G (e) LR_G (f) Our_GFigure 2: Visualizations of (c)-(f) Gradient features and (h)-(l) Spectrum features, where ‚äñrefers to subtraction.\n",
      "trum feature of RGB and that of LR in Fig. 2(k), which is\n",
      "then merged with the spectrum feature of LR to enhance the\n",
      "structure. Besides, we initiate a frequency-aware loss to fur-\n",
      "ther strengthen the response of FAM in frequency space.\n",
      "Owing to the ingenious designs of GCM and FAM, (f)\n",
      "and (l) of Fig. 2 show that our approach can obtain very\n",
      "sharp and highlighted stru\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Uncertainty Propagation through Trained\n",
      "Deep Neural Networks Using Factor Graphs\n",
      "Angel Daruna, Yunye Gong, Abhinav Rajvanshi, Han-Pang Chiu, Yi Yao\n",
      "{angel.daruna,yunye.gong,abhinav.rajvanshi,han-pang.chiu,yi.yao }@sri.com\n",
      "Center for Vision Technologies\n",
      "SRI International\n",
      "Princeton, NJ\n",
      "Abstract\n",
      "Predictive uncertainty estimation remains a challenging prob-\n",
      "lem precluding the use of deep neural networks as subsys-\n",
      "tems within safety-critical applications. Aleatoric uncertainty\n",
      "is a component of predictive uncertainty that cannot be re-\n",
      "duced through model improvements. Uncertainty propaga-\n",
      "tion seeks to estimate aleatoric uncertainty by propagating\n",
      "input uncertainties to network predictions. Existing uncer-\n",
      "tainty propagation techniques use one-way information flows,\n",
      "propagating uncertainties layer-by-layer or across the entire\n",
      "neural network while relying either on sampling or analyti-\n",
      "cal techniques for propagation. Motivated by the complex in-\n",
      "formation flows within deep neural networks (e.g. skip con-\n",
      "nections), we developed and evaluated a novel approach by\n",
      "posing uncertainty propagation as a non-linear optimization\n",
      "problem using factor graphs. We observed statistically sig-\n",
      "nificant improvements in performance over prior work when\n",
      "using factor graphs across most of our experiments that in-\n",
      "cluded three datasets and two neural network architectures.\n",
      "Our implementation balances the benefits of sampling and\n",
      "analytical propagation techniques, which we believe, is a key\n",
      "factor in achieving performance improvements.\n",
      "Introduction\n",
      "Aleatoric uncertainty estimation of deep neural network pre-\n",
      "dictions is a challenging problem precluding their use within\n",
      "saftey critical applications. Neural networks present a new\n",
      "method for processing physical sensor data, improving over\n",
      "traditional methods in many domains, e.g. inertial odometry\n",
      "(Liu et al. 2020). Despite such advancements, extracting pre-\n",
      "dictive uncertainty estimates from trained neural networks\n",
      "remains a challenge. As a result, incorporating neural net-\n",
      "works within safety-critical applications that combine many\n",
      "predictions and their uncertainties remains an open question.\n",
      "Predictive uncertainty is typically modeled as two separate\n",
      "uncertainties, epistemic and aleatoric uncertainty. Aleatoric\n",
      "uncertainty stems from environmental variations and sen-\n",
      "sor noise; hence, aleatoric uncertainty cannot be reduced\n",
      "through model improvements (Gawlikowski et al. 2023).\n",
      "In this paper, we examine a new technique to estimate the\n",
      "aleatoric uncertainty of a trained deep neural network, using\n",
      "uncertainty propagation. Some prior methods for aleatoric\n",
      "uncertainty estimation augment training procedures, which\n",
      "can improve the prediction performance of a trainable neu-\n",
      "ral network. Examples include Bayesian Deep Learning\n",
      "Figure 1: Our uncertainty propagation approach models\n",
      "deep neural networks using factor graphs to estimate pre-\n",
      "dictive uncertainty caused by data uncertainty.\n",
      "(Kendall and Gal 2017), Ensemble Distribution Distilla-\n",
      "tion (Malinin, Mlodozeniec, and Gales 2019), and Eviden-\n",
      "tial Neural Networks (Sensoy, Kaplan, and Kandemir 2018;\n",
      "Amini et al. 2020). Other prior work has sought to assess\n",
      "the aleatoric uncertainty at inference time for a not-editable\n",
      "trained neural network, known as input uncertainty propaga-\n",
      "tion (Titensky, Jananthan, and Kepner 2018; Monchot et al.\n",
      "2023). In this way, uncertainty propagation techniques can\n",
      "be applied to a trained neural network without augmentation.\n",
      "Existing uncertainty propagation techniques use one-way in-\n",
      "formation flows, either propagating uncertainties layer-by-\n",
      "layer or across the network while relying either on sampling\n",
      "or analytical techniques for propagation.\n",
      "We develop and validate a factor graph formulation for\n",
      "modeling deep neural network uncertainty propagation as\n",
      "a non-linear optimization problem by treating network lay-\n",
      "ers as discrete time steps, layer values as variable nodes,\n",
      "and connections among layers as factors (Figure 1). Factor\n",
      "graphs (Kschischang, Frey, and Loeliger 2001) are a proba-\n",
      "bilistic Bayesian graphical model that factorize a probabil-\n",
      "ity density over a set of factors involving variable nodes.\n",
      "While factor graphs have been widely used for large-scale\n",
      "real-time state estimation, to the best of our knowledge, we\n",
      "are the first to leverage factor graphs for neural network un-\n",
      "certainty estimation. Factor graphs can be used to address\n",
      "several limitations of prior uncertainty propagation works.\n",
      "Distribution Statement ‚ÄòA‚Äô (Approved for Public Release, Distribution Unlimited)arXiv:2312.05946v1  [cs.LG]  10 Dec 2023These limitations include limited information flow when es-\n",
      "timating uncertainty as well as balancing the benefits of\n",
      "sampling from the input uncertainty distribution (Abdelaziz\n",
      "et al. 2015) and analytically propagating network uncertain-\n",
      "ties (Titensky, Jananthan, and Kepner 2018).\n",
      "We evaluated our uncertainty propagation approach\n",
      "against three baselines for classification and regression prob-\n",
      "lems\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Transformer-based Selective Super-Resolution for Efficient Image Refinement\n",
      "Tianyi Zhang1, Kishore Kasichainula2, Yaoxin Zhuo2, Baoxin Li2, Jae-Sun Seo3, Yu Cao1\n",
      "1University of Minnesota\n",
      "2Arizona State University\n",
      "3Cornell Tech\n",
      "zhan9167@umn.edu, {kkasicha, yzhuo6, baoxin.li }@asu.edu, js3528@cornell.edu, yucao@umn.edu\n",
      "Abstract\n",
      "Conventional super-resolution methods suffer from two\n",
      "drawbacks: substantial computational cost in upscaling an en-\n",
      "tire large image, and the introduction of extraneous or po-\n",
      "tentially detrimental information for downstream computer\n",
      "vision tasks during the refinement of the background. To\n",
      "solve these issues, we propose a novel transformer-based al-\n",
      "gorithm, Selective Super-Resolution (SSR), which partitions\n",
      "images into non-overlapping tiles, selects tiles of interest at\n",
      "various scales with a pyramid architecture, and exclusively\n",
      "reconstructs these selected tiles with deep features. Exper-\n",
      "imental results on three datasets demonstrate the efficiency\n",
      "and robust performance of our approach for super-resolution.\n",
      "Compared to the state-of-the-art methods, the FID score is\n",
      "reduced from 26.78 to 10.41 with 40% reduction in computa-\n",
      "tion cost for the BDD100K dataset. The source code is avail-\n",
      "able at https://github.com/destiny301/SSR.\n",
      "Introduction\n",
      "Super-resolution (SR) is a fundamental task aimed at en-\n",
      "hancing image resolution by producing intricate details\n",
      "from low-resolution (LR) images. It supplies high-resolution\n",
      "(HR) images that are pivotal for downstream computer vi-\n",
      "sion tasks, such as object detection and image classifi-\n",
      "cation, with wide-ranging applications in the real world.\n",
      "For instance, in the context of autonomous driving, higher-\n",
      "resolution images facilitate more precise and early object\n",
      "detection, particularly for diminutive objects. Although vari-\n",
      "ous super-resolution methods based on convolutional neural\n",
      "networks (CNNs) have been proposed, which enhance high-\n",
      "frequency information through low-resolution image recon-\n",
      "struction, their efficacy is impeded by a lack of long-range\n",
      "dependency integration.\n",
      "Recently, leveraging transformer-based architectures to\n",
      "capture the extended contextual information, pioneering ef-\n",
      "forts like SwinIR (Liang et al. 2021) and HAT (Chen\n",
      "et al. 2023), have achieved notable advancements in\n",
      "super-resolution. Nevertheless, two key issues persist with\n",
      "these algorithms. Firstly, due to the substantial scale of\n",
      "transformer-based networks, the computational demand be-\n",
      "comes exceedingly high when reconstructing entire images,\n",
      "particularly when input low-resolution image sizes are not\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.\n",
      "Figure 1: The reconstruction of high-frequency background\n",
      "information in conventional SR methods (e.g., HAT) often\n",
      "results in discrepancies in features compared to ground truth\n",
      "high-resolution (HR) images. SSR effectively resolves this\n",
      "issue by exclusively enhancing foreground pixels.\n",
      "small, such as 256 √ó256. Secondly, even in state-of-the-\n",
      "art super-resolution approaches, the refined images fail to\n",
      "match the performance of ground truth HR images for typi-\n",
      "cal downstream tasks. To delve into the cause of this degra-\n",
      "dation, we conduct a comparison between features gener-\n",
      "ated by the Inception model from refined images and orig-\n",
      "inal HR images. This analysis unveils that features derived\n",
      "from background pixels exhibit markedly different details\n",
      "compared to the ground truth feature map, as depicted in\n",
      "Figure 1. This divergence suggests that overemphasizing\n",
      "background pixel details can introduce erroneous informa-\n",
      "tion and impede feature generation for downstream tasks.\n",
      "This paper introduces a novel algorithm, Selective Super-\n",
      "Resolution (SSR), designed to address these challenges.\n",
      "Specifically, leveraging object location information, we par-\n",
      "tition images into non-overlapping tiles and employ a cost-\n",
      "efficient transformer-based network for tile selection. To en-\n",
      "sure comprehensive coverage of objects, a pyramid structure\n",
      "is devised for tile selection across multiple scales. In the fi-\n",
      "nal layer of this selection network, we integrate a Gumbel-arXiv:2312.05803v1  [cs.CV]  10 Dec 2023Softmax layer (Jang, Gu, and Poole 2016) to make hard\n",
      "decisions, subsequently directing positive tiles to an ensu-\n",
      "ing super-resolution (SR) module. This module comprises\n",
      "a convolution layer for shallow feature extraction, trans-\n",
      "former blocks for deep feature extraction and an image\n",
      "reconstruction block. In contrast, negative tiles are recon-\n",
      "structed directly from shallow features. This framework not\n",
      "only reduces computation by extracting deep features solely\n",
      "for positive tiles but also enhances image generation by\n",
      "avoiding excessive background detail addition. To validate\n",
      "the robustness of SSR, alongside common evaluation met-\n",
      "rics, such as Structural Similarity Index Measure (SSIM),\n",
      "Fr¬¥echet Inception Distance (FID), and Kernel Inception\n",
      "Distance (KID), we introduce a novel metric, ins\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Learning Differentiable Particle Filter on the Fly\n",
      "Jiaxi Li‚àó\n",
      "Computer Science Research Centre\n",
      "University of Surrey\n",
      "Guildford, United Kingdom\n",
      "jiaxi.li@surrey.ac.ukXiongjie Chen‚àó\n",
      "Computer Science Research Centre\n",
      "University of Surrey\n",
      "Guildford, United Kingdom\n",
      "xiongjie.chen@surrey.ac.ukYunpeng Li\n",
      "Computer Science Research Centre\n",
      "University of Surrey\n",
      "Guildford, United Kingdom\n",
      "yunpeng.li@surrey.ac.uk\n",
      "Abstract ‚ÄîDifferentiable particle filters are an emerging class\n",
      "of sequential Bayesian inference techniques that use neural\n",
      "networks to construct components in state space models. Existing\n",
      "approaches are mostly based on offline supervised training\n",
      "strategies. This leads to the delay of the model deployment and\n",
      "the obtained filters are susceptible to distribution shift of test-\n",
      "time data. In this paper, we propose an online learning framework\n",
      "for differentiable particle filters so that model parameters can\n",
      "be updated as data arrive. The technical constraint is that\n",
      "there is no known ground truth state information in the online\n",
      "inference setting. We address this by adopting an unsupervised\n",
      "loss to construct the online model updating procedure, which\n",
      "involves a sequence of filtering operations for online maximum\n",
      "likelihood-based parameter estimation. We empirically evaluate\n",
      "the effectiveness of the proposed method, and compare it with\n",
      "supervised learning methods in simulation settings including a\n",
      "multivariate linear Gaussian state-space model and a simulated\n",
      "object tracking experiment.\n",
      "Index Terms ‚Äîdifferentiable particle filters, sequential\n",
      "Bayesian inference, online learning.\n",
      "I. I NTRODUCTION\n",
      "Particle filters, or sequential Monte Carlo (SMC) methods,\n",
      "are a class of simulation-based algorithms designed for solving\n",
      "recursive Bayesian filtering problems in state-space mod-\n",
      "els [1]‚Äì[3]. Although particle filters have been successfully\n",
      "applied in a variety of challenging tasks, including target\n",
      "tracking, econometrics, and fuzzy control [4]‚Äì[6], the design\n",
      "of particle filters‚Äô components relies on practitioners‚Äô domain\n",
      "knowledge and often involves a trial and error approach. To ad-\n",
      "dress this challenge, various parameter estimation techniques\n",
      "have been proposed for particle filters [7], [8]. However, many\n",
      "such methods are restricted to scenarios where the structure or\n",
      "the parameters of the state-space model are partially known.\n",
      "For real-world applications where both the structure and the\n",
      "parameters of the considered state-space model are unknown,\n",
      "differentiable particle filters (DPFs) were proposed to construct\n",
      "the components of particle filters with neural networks and\n",
      "adaptively learn their parameters from data [9]‚Äì[11]. Com-\n",
      "pared with traditional parameter estimation methods developed\n",
      "for particle filters, differentiable particle filters often require\n",
      "less knowledge about the considered state-space model [9],\n",
      "[10], [12]‚Äì[14].\n",
      "Most existing differentiable particle filtering frameworks are\n",
      "trained offline in a supervised approach. In supervised offline\n",
      "* Jiaxi Li and Xiongjie Chen contributed equally to this work.training schemes, ground-truth latent states are required for\n",
      "model training; subsequently, online inference is performed on\n",
      "new data without further updates of the model. This leads to\n",
      "several limitations. For example, in many real-world Bayesian\n",
      "filtering problems, data often arrive in a sequential order and\n",
      "ground-truth latent states can be expensive to obtain or even\n",
      "inaccessible. Moreover, offline training schemes can produce\n",
      "poor filtering results in the testing stage if the distribution of\n",
      "the offline training data differs from the distribution of the\n",
      "online data in testing, a.k.a. distribution shift.\n",
      "Traditional online parameter estimation methods for particle\n",
      "filters are often designed as a nested structure for solving\n",
      "two layers of Bayesian filtering problems to simultaneously\n",
      "track the posterior of model parameters and latent variables.\n",
      "In [15], it was proposed to estimate the parameters of particle\n",
      "filters using Markov chain Monte Carlo (MCMC) sampling.\n",
      "The SMC2algorithm [16] and the nested particle filter [17]\n",
      "leverage a nested filtering framework where two Bayesian\n",
      "filters are running hierarchically to approximate the joint\n",
      "posterior of unknown parameters and latent states, while the\n",
      "nested particle filter is designed as a purely recursive method\n",
      "thus more suitable for online parameter estimation problems.\n",
      "The scope of their applications is limited, since they assume\n",
      "that the structure of the considered state-space model is known.\n",
      "To the best of our knowledge, no existing differentiable\n",
      "particle filters address online training at testing time. Sev-\n",
      "eral differentiable particle filters require ground truth state\n",
      "information in model training, rendering them unsuitable for\n",
      "online training. For example, in [9], [10], [12], [18], dif-\n",
      "ferentiable particle filters are optimised by minimising the\n",
      "distance between the estimated latent states and the ground-\n",
      "truth latent states, e.g. the root mean square er\n",
      "----------------------------------------------------------------------------------------------------\n",
      "HumanCoser: Layered 3D Human Generation via Semantic-Aware\n",
      "Diffusion Model\n",
      "Yi Wang1,‚Ä†, Jian Ma1,‚Ä†, Ruizhi Shao2, Qiao Feng1, Yu-Kun Lai3, Yebin Liu2, Kun Li1,‚àó\n",
      "1Tianjin University, China2Tsinghua University, China\n",
      "3Cardiff University, U.K\n",
      "Figure 1. Our method can generate layered 3D humans guided by text prompts, which are physically-decoupled and structurally consistent.\n",
      "This allows our generated clothing to be reused, exchanging between digital avatars with different identities.\n",
      "Abstract\n",
      "The generation of 3D clothed humans has attracted in-\n",
      "creasing attention in recent years. However, existing work\n",
      "cannot generate layered high-quality 3D humans with con-\n",
      "sistent body structures. As a result, these methods are un-\n",
      "able to arbitrarily and separately change and edit the body\n",
      "and clothing of the human. In this paper, we propose a\n",
      "text-driven layered 3D human generation framework based\n",
      "on a novel physically-decoupled semantic-aware diffusion\n",
      "model. To keep the generated clothing consistent with the\n",
      "target text, we propose a semantic-confidence strategy for\n",
      "clothing that can eliminate the non-clothing content gen-\n",
      "‚Ä†Equal contribution.\n",
      "* Corresponding author.erated by the model. To match the clothing with different\n",
      "body shapes, we propose a SMPL-driven implicit field de-\n",
      "formation network that enables the free transfer and reuse\n",
      "of clothing. Besides, we introduce uniform shape priors\n",
      "based on the SMPL model for body and clothing, respec-\n",
      "tively, which generates more diverse 3D content without be-\n",
      "ing constrained by specific templates. The experimental re-\n",
      "sults demonstrate that the proposed method not only gener-\n",
      "ates 3D humans with consistent body structures but also al-\n",
      "lows free editing in a layered manner. The source code will\n",
      "be made public. The project page is available for research\n",
      "purposes at http://cic.tju.edu.cn/faculty/\n",
      "likun/projects/HumanCoser .\n",
      "1arXiv:2312.05804v1  [cs.CV]  10 Dec 20231. Introduction\n",
      "The generation of 3D humans with changeable clothing\n",
      "plays an important role in movies, games and AR/VR. Ex-\n",
      "isting methods [10, 33, 37, 43, 44, 47] can only generate\n",
      "a single surface with coupled body and clothing, and thus\n",
      "cannot be edited and reused separately. In this paper, we\n",
      "aim to generate high-fidelity layered 3D humans with the\n",
      "ability to change clothes, as shown in Fig. 1.\n",
      "Recently, owing to the high-quality image synthesis ca-\n",
      "pability of pre-trained diffusion models [39], some meth-\n",
      "ods [24, 33, 37] introduce a novel Score Distillation Sam-\n",
      "pling ( SDS ) strategy [39] to self-supervise the 3D human\n",
      "generation process. However, these methods ignore the di-\n",
      "versity and self-occlusion of human shapes, which leads\n",
      "to inconsistencies in generated human structures. Fur-\n",
      "thermore, most data-driven 3D avatar generation meth-\n",
      "ods [6, 11, 14, 18, 46, 53] generate 3D clothed humans in\n",
      "a coupled manner, and as a result, clothing cannot be ex-\n",
      "changed between arbitrary bodies. Overall, the aforemen-\n",
      "tioned methods fail to ensure structural consistency and lack\n",
      "the capability to generate and edit bodies and clothes in a\n",
      "layered and flexible manner.\n",
      "This paper introduces HumanCoser, a novel framework\n",
      "based on a physically decoupled semantic-aware diffu-\n",
      "sion model. It aim to generate high-quality physically-\n",
      "decoupled 3D clothed humans with consistent body struc-\n",
      "ture in a layered manner, guided by text. To achieve ac-\n",
      "curate geometric alignment between decoupled body and\n",
      "clothing, we present a 3D implicit deformation field using\n",
      "SMPL [23] vertex prediction, leveraging SMPL-X [31] as\n",
      "a body proxy for matching with clothing. Additionally, we\n",
      "incorporate a layered shape prior to ensure structural con-\n",
      "sistency in the generation of 3D human bodies and clothes.\n",
      "To enhance details, we introduce a normal prediction net-\n",
      "work for smooth normals, combined with optimized spher-\n",
      "ical harmonic lighting. To ensure semantic consistency\n",
      "with the text, we propose a clothing semantic confidence\n",
      "strategy for 3D implicit fields, employing an implicit 3D\n",
      "semantic-confidence prediction network. This strategy re-\n",
      "moves redundant non-clothing content and enhances robust-\n",
      "ness through the addition of Gaussian noise. Hence, the\n",
      "proposed HumanCoser ensures structural consistency while\n",
      "allowing for variability in body clothing.\n",
      "Our main contributions are summarized as follows:\n",
      "‚Ä¢ We propose a layered 3D human generation framework\n",
      "with a semantic-aware diffusion model. To our best\n",
      "knowledge, this is the first work that is truly physically-\n",
      "decoupled and supports the generation of structurally\n",
      "consistent human bodies and clothing. We also introduce\n",
      "a decoupled shape prior to generate structurally consistent\n",
      "3D content.\n",
      "‚Ä¢ We propose a semantic-confidence strategy for 3D im-\n",
      "plicit fields to improve the semantic consistency of cloth-ing generation. The strategy not only improves the se-\n",
      "mantic consistency of the clothing but is also generaliz-\n",
      "able to the enhancement of 3D semantics for other wear-\n",
      "able outfits of humans.\n",
      "‚Ä¢ We propose\n",
      "----------------------------------------------------------------------------------------------------\n",
      "arXiv:2312.05959v1  [cs.LG]  10 Dec 2023IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, DECEMBER 20 23 1\n",
      "V AE-IF: Deep feature extraction with averaging for\n",
      "unsupervised artifact detection in routine acquired\n",
      "ICU time-series\n",
      "Hollan Haule, Ian Piper, Patricia Jones, Chen Qin, Tsz-Yan M illy Lo, and Javier Escudero, Senior Member, IEEE\n",
      "Abstract ‚ÄîArtifacts are a common problem in physiological\n",
      "time-series data collected from intensive care units (ICU) and\n",
      "other settings. They affect the quality and reliability of c linical\n",
      "research and patient care. Manual annotation of artifacts i s\n",
      "costly and time-consuming, rendering it impractical. Auto mated\n",
      "methods are desired. Here, we propose a novel unsupervised a p-\n",
      "proach to detect artifacts in clinical-standard minute-by -minute\n",
      "resolution ICU data without any prior labeling or signal-sp eciÔ¨Åc\n",
      "knowledge. Our approach combines a variational autoencode r\n",
      "(V AE) and an isolation forest (iForest) model to learn featu res\n",
      "and identify anomalies in different types of vital signs, su ch as\n",
      "blood pressure, heart rate, and intracranial pressure. We e valuate\n",
      "our approach on a real-world ICU dataset and compare it with\n",
      "supervised models based on long short-term memory (LSTM)\n",
      "and XGBoost. We show that our approach achieves comparable\n",
      "sensitivity and generalizes well to an external dataset. We also\n",
      "visualize the latent space learned by the V AE and demonstrat e\n",
      "its ability to disentangle clean and noisy samples. Our appr oach\n",
      "offers a promising solution for cleaning ICU data in clinica l\n",
      "research and practice without the need for any labels whatso ever.\n",
      "Index Terms ‚ÄîUnsupervised learning, Autoencoders, Artifact\n",
      "detection, Intensive care unit data, Isolation forests.\n",
      "I. I NTRODUCTION\n",
      "CONTINUOUS monitoring of vital signs in Intensive Care\n",
      "Units (ICU) is essential for patient management and\n",
      "treatment. These vitals typically include signals such as b lood\n",
      "pressure, heart rate, and temperature. The clinical practi ce in\n",
      "most ICU involves the routine acquisition of these signals\n",
      "at low temporal resolution (minute-by-minute samples). Th is\n",
      "data can become a very useful resource for medical research,\n",
      "as it could advance knowledge about disease processes and\n",
      "patient care [1]. However, extracting useful insights from this\n",
      "data is a big challenge due to artifacts.\n",
      "This research was funded in part by an EPSRC Doctoral Trainin g Part-\n",
      "nership PhD studentship to HH and The Carnegie Trust for the U niversities\n",
      "of Scotland (RIG009251) to JE. For the purpose of open access , the author\n",
      "has applied a Creative Commons Attribution (CC BY) licence t o any Author\n",
      "Accepted Manuscript version arising from this submission.\n",
      "H. Haule and J. Escudero are with the Institute for Imaging, D ata and\n",
      "Communications (IDCOM), School of Engineering, Universit y of Edinburgh,\n",
      "Edinburgh EH9 3FB, U.K. (e-mail: hhaule@ed.ac.uk).\n",
      "T.-Y .M. Lo and I. Piper are with the Centre of Medical Informa tics, Usher\n",
      "Institute, University of Edinburgh, U.K., and also with the Royal Hospital for\n",
      "Children and Young People, Edinburgh, U.K.\n",
      "C. Qin is with Department of Electrical and Electronics Engi neering & I-X,\n",
      "Imperial College London, U.K.\n",
      "P. Jones is with Department of Child Life and Health, Univers ity of\n",
      "Edinburgh, Edinburgh, U.K.\n",
      "Manuscript submitted December 2023.Routine collection of ICU data is done in uncontrolled\n",
      "conditions. The focus is clinical care rather than medical\n",
      "research [2], which often affects data quality. By way of\n",
      "illustration, probe changes and accidental probe displace ment,\n",
      "position changes, and clinical interventions [3] can manif est\n",
      "as ‚Äúspikes‚Äù or ‚ÄúÔ¨Çat-line‚Äù artifacts in the collected data, a mong\n",
      "other forms of artifacts. Therefore, re-purposing this dat a for\n",
      "ofÔ¨Çine clinical research risks getting misleading results if\n",
      "artifacts are not dealt with.\n",
      "The gold standard for dealing with data artifacts is manual\n",
      "annotation by experienced researchers, but this is costly a nd\n",
      "non-scalable [4]. Therefore, developing techniques to hel p\n",
      "automate this task is an active and important area of researc h.\n",
      "There are several approaches for detecting artifacts in div erse\n",
      "types of physiological time series. Some of these approache s\n",
      "include Signal Quality Indices (SQI) [5]‚Äì[9] based on tem-\n",
      "plate matching, frequency-based methods [10], and machine\n",
      "learning (ML) [11]‚Äì[17]. Unsupervised ML techniques are\n",
      "of special interest in this domain because of the scarcity of\n",
      "labeled data. However, existing approaches either are sign al-\n",
      "speciÔ¨Åc or work only on high-temporal resolution, quasi-\n",
      "periodic physiological signals, which leaves a gap for meth ods\n",
      "that work on non-periodic, routinely collected physiologi c data\n",
      "from ICU clinical practice.\n",
      "We aim to develop unsupervised ML methods for auto-\n",
      "mated artifact detection in minute-by-minute ICU time se-\n",
      "ries. Building upon a labeled real-world dataset, we initia lly\n",
      "explore supervised ML techniques known for their reliable\n",
      "performance with labeled data. Then, we introduce a no\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Towards Global, Socio-Economic, and Culturally Aware Recommender\n",
      "Systems\n",
      "Kelley Ann Yohe*a\n",
      "aMacquarie University, Sydney, Australia\n",
      "kelley.yohe@students.mq.edu.au\n",
      "ABSTRACT\n",
      "Recommender systems have gained increasing attention to personalise consumer preferences. While these systems\n",
      "have primarily focused on applications such as advertisement recommendations (e.g., Google), personalized sug-\n",
      "gestions (e.g., Netflix and Spotify), and retail selection (e.g., Amazon), there is potential for these systems to ben-\n",
      "efit from a more global, socio-economic, and culturally aware approach, particularly as companies seek to expand\n",
      "into diverse markets. This paper aims to investigate the potential of a recommender system that considers cul-\n",
      "tural identity and socio-economic factors. We review the most recent developments in recommender systems and\n",
      "explore the impact of cultural identity and socio-economic factors on consumer preferences. We then propose an\n",
      "ontology and approach for incorporating these factors into recommender systems. To illustrate the potential of our\n",
      "approach, we present a scenario in consumer subscription plan selection within the entertainment industry. We ar-\n",
      "gue that existing recommender systems have limited ability to precisely understand user preferences due to a lack\n",
      "of awareness of socio-economic factors and cultural identity. They also fail to update recommendations in response\n",
      "to changing socio-economic conditions. We explore various machine learning models and develop a final artificial\n",
      "neural network model (ANN) that addresses this gap. We evaluate the effectiveness of socio-economic and cul-\n",
      "turally aware recommender systems across four dimensions: Precision, Accuracy, F1, and Recall. We find that a\n",
      "highly tuned ANN model incorporating domain-specific data, select cultural indices and relevant socio-economic\n",
      "factors predicts user preference in subscriptions with an accuracy of 95%, a precision of 94%, a F1 Score of 92%,\n",
      "and a Recall of 90%. Keywords: Recommender systems, personalization, cultural identity, socio-economic factors,\n",
      "user preferences.\n",
      "KEYWORDS\n",
      "Recommender systems, personalization, cultural identity, socio-economic factors, user preferences.\n",
      "1 INTRODUCTION\n",
      "Recommender systems have become an integral part of many consumer-related applications in recent years, pro-\n",
      "viding personalised options to customers28, 81. These systems are primarily used by companies such as Google,\n",
      "Netflix, Amazon, and Spotify to recommend advertisements, media, and products to consumers41, 80. However,\n",
      "these systems have been limited in their ability to incorporate socio-economic and cultural factors that can influ-\n",
      "ence consumer preferences. As companies expand into diverse markets, the need for more culturally aware and\n",
      "socio-economically sensitive recommender systems is becoming increasingly important. In this context, a recom-\n",
      "mender system that considers cultural identity and socio-economic factors have the potential to improve customer\n",
      "satisfaction and increase sales.\n",
      "This paper aims to investigate the potential of a recommender system that considers cultural identity and socio-\n",
      "economic factors13. Accordingly, in this paper, we will discuss the most recent developments in recommender sys-\n",
      "tems and explore the impact of cultural identity and socio-economic factors on consumer preferences. We will pro-\n",
      "pose an ontology and approach for incorporating these factors into recommender systems. Finally, we will presentarXiv:2312.05805v1  [cs.IR]  10 Dec 2023a scenario involving consumer subscription and plan selection in the media entertainment industry to illustrate the\n",
      "potential of our approach.\n",
      "1.1 Recommendations as a Competitive Advantage\n",
      "As technological advancements progress, an increasing amount of data is being generated through human activi-\n",
      "ties, devices, and system processes. The introduction of openly available data has led to an overwhelming number\n",
      "of choices available to users, surpassing their capacity for understanding. To remain competitive and establish a\n",
      "strong relationship with their customers, businesses are required to assist users in sorting through this vast amount\n",
      "of information in order to uncover meaningful preferences40. The ability to accurately identify preferences, provide\n",
      "recommendations, and profit from those recommendations represent a rapidly expanding and highly competitive\n",
      "business opportunity. Indeed, it can be a decisive factor in the success of a business strategy that leverages avail-\n",
      "able customer knowledge to generate revenue, sustain profitability, and achieve a competitive edge.\n",
      "Despite the potential benefits that recommender systems can offer, significant challenges are associated with their\n",
      "design and implementation. One major issue is the lack of global, socio-economic, and cultural awareness in cur-\n",
      "rent recommender systems, which can result in inaccurate recommendations and lost revenue opportunities. For\n",
      "example, many current recommender systems rely hea\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TransGlow: Attention-augmented Transduction\n",
      "model based on Graph Neural Networks for Water\n",
      "Flow Forecasting\n",
      "Naghmeh Shafiee Roudbari, Charalambos Poullis, Zachary Patterson, Ursula Eicker\n",
      "Gina Cody School of Engineering and Computer Science\n",
      "Concordia University\n",
      "Montreal, QC, Canada\n",
      "Abstract ‚ÄîThe hydrometric prediction of water quantity is\n",
      "useful for a variety of applications, including water management,\n",
      "flood forecasting, and flood control. However, the task is difficult\n",
      "due to the dynamic nature and limited data of water systems.\n",
      "Highly interconnected water systems can significantly affect\n",
      "hydrometric forecasting. Consequently, it is crucial to develop\n",
      "models that represent the relationships between other system\n",
      "components. In recent years, numerous hydrological applica-\n",
      "tions have been studied, including streamflow prediction, flood\n",
      "forecasting, and water quality prediction. Existing methods are\n",
      "unable to model the influence of adjacent regions between pairs of\n",
      "variables. In this paper, we propose a spatiotemporal forecasting\n",
      "model that augments the hidden state in Graph Convolution\n",
      "Recurrent Neural Network (GCRN) encoder-decoder using an\n",
      "efficient version of the attention mechanism. The attention\n",
      "layer allows the decoder to access different parts of the input\n",
      "sequence selectively. Since water systems are interconnected and\n",
      "the connectivity information between the stations is implicit, the\n",
      "proposed model leverages a graph learning module to extract a\n",
      "sparse graph adjacency matrix adaptively based on the data.\n",
      "Spatiotemporal forecasting relies on historical data. In some\n",
      "regions, however, historical data may be limited or incomplete,\n",
      "making it difficult to accurately predict future water conditions.\n",
      "Further, we present a new benchmark dataset of water flow\n",
      "from a network of Canadian stations on rivers, streams, and\n",
      "lakes. Experimental results demonstrate that our proposed model\n",
      "TransGlow significantly outperforms baseline methods by a wide\n",
      "margin.\n",
      "Index Terms ‚ÄîEncoder-Decoder, Attention, Graph Neural Net-\n",
      "works, Spatiotemporal forecasting\n",
      "I. I NTRODUCTION\n",
      "Accurate water flow prediction plays a crucial role in flood\n",
      "forecasting and mitigation. By understanding and predicting\n",
      "the dynamics of water flow, authorities can issue timely\n",
      "warnings and implement proactive measures to minimize the\n",
      "impact of floods, protecting human lives and reducing property\n",
      "damage. This proactive approach allows for better emergency\n",
      "response planning and the implementation of effective flood\n",
      "control strategies. Furthermore, water flow prediction is essen-\n",
      "tial for optimal water resource management, fair distribution\n",
      "of water, ensuring sustainable use, and minimizing waste.\n",
      "Water systems are interconnected with interdependencies,\n",
      "which can significantly impact hydrometric prediction. Water\n",
      "levels, flow, and quality changes in one part of the system canhave cascading effects on the other parts. For example, changes\n",
      "in precipitation in one part of a river basin can affect water\n",
      "levels and flows downstream. These dependencies are chal-\n",
      "lenging to understand, as different components can interact in\n",
      "complex ways that rely on various factors. Hence, it is essential\n",
      "to develop models that can capture the relationships between\n",
      "other system components. Spatiotemporal forecasting in water\n",
      "flow prediction involves capturing the complex relationships\n",
      "and patterns of water flow in a given geographical area over\n",
      "time. It takes into account the interconnections of hydrological\n",
      "processes across different locations and time intervals. The\n",
      "concept of spatiotemporal forecasting recognizes that water\n",
      "flow is not only influenced by local conditions but also by the\n",
      "spatial context and interactions within the hydrological system.\n",
      "It considers how changes in one area can propagate and affect\n",
      "water flow patterns in neighboring or downstream locations.\n",
      "Additionally, it takes into account the temporal dynamics, such\n",
      "as seasonality, trends, and short-term variations, that influence\n",
      "water flow.\n",
      "Previous studies in the field of hydrometric prediction can\n",
      "be categorized into distinct research areas. These categories\n",
      "include streamflow forecasting [1], drought prediction [2]‚Äì\n",
      "[4], flood forecasting [5]‚Äì[7], and water quality prediction\n",
      "[8]‚Äì[10]. Previous studies in hydrometric prediction have\n",
      "significantly contributed to the field; however, they are not\n",
      "without limitations. These studies have often relied on limited\n",
      "and fragmented datasets, which can result in uncertainties and\n",
      "reduced accuracy. Additionally, oversimplified assumptions\n",
      "about hydrological processes and the disregard of spatial and\n",
      "temporal variability can reduce the accuracy of the predictions.\n",
      "Furthermore, limited focus on realtime applications poses\n",
      "challenges for the field.\n",
      "To address the mentioned challenges, we propose Trans-\n",
      "Glow, a spatiotemporal forecasting solution based on a trans-\n",
      "ductive model with an augmented decoder hidden state using\n",
      "an efficient attention mechanism. The attention a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FEDERATED LEARNING EMPOWERED BY\n",
      "GENERATIVE CONTENT\n",
      "Rui Ye1, Xinyu Zhu1, Jingyi Chai1, Siheng Chen1,2B, Yanfeng Wang2,1\n",
      "1Shanghai Jiao Tong University,2Shanghai AI Laboratory\n",
      "{yr991129,zhuxinyu,chaijingyi,sihengc,wangyanfeng }@sjtu.edu.cn\n",
      "ABSTRACT\n",
      "Federated learning (FL) enables leveraging distributed private data for model\n",
      "training in a privacy-preserving way. However, data heterogeneity significantly\n",
      "limits the performance of current FL methods. In this paper, we propose a novel\n",
      "FL framework termed FedGC, designed to mitigate data heterogeneity issues by\n",
      "diversifying private data with generative content. FedGC is a simple-to-implement\n",
      "framework as it only introduces a one-shot step of data generation. In data gener-\n",
      "ation, we summarize three crucial and worth-exploring aspects (budget allocation,\n",
      "prompt design, and generation guidance) and propose three solution candidates\n",
      "for each aspect. Specifically, to achieve a better trade-off between data diversity\n",
      "and fidelity for generation guidance, we propose to generate data based on the\n",
      "guidance of prompts and real data simultaneously. The generated data is then\n",
      "merged with private data to facilitate local model training. Such generative data\n",
      "increases the diversity of private data to prevent each client from fitting the poten-\n",
      "tially biased private data, alleviating the issue of data heterogeneity. We conduct\n",
      "a systematic empirical study on FedGC, covering diverse baselines, datasets, sce-\n",
      "narios, and modalities. Interesting findings include (1) FedGC consistently and\n",
      "significantly enhances the performance of FL methods, even when notable dis-\n",
      "parities exist between generative and private data; (2) FedGC achieves both bet-\n",
      "ter performance and privacy-preservation. We wish this work can inspire future\n",
      "works to further explore the potential of enhancing FL with generative content.\n",
      "1 I NTRODUCTION\n",
      "Federated learning (FL) is a privacy-preserving machine learning paradigm that enables multiple\n",
      "clients to collaboratively train a global model without directly sharing their raw data (McMahan\n",
      "et al., 2017; Kairouz et al., 2021). With the increasing concerns about privacy, FL has attracted\n",
      "significant attention and has been applied to diverse real-world fields such as natural language pro-\n",
      "cessing, healthcare, finance, Internet of Things (IoT), and autonomous vehicles (Yang et al., 2019).\n",
      "Data heterogeneity presents a prominent and fundamental challenge in FL, significantly impacting\n",
      "FL‚Äôs overall performance (McMahan et al., 2017; Hsu et al., 2019). This heterogeneity arises in-\n",
      "herently due to the varied environments and preferences in which clients‚Äô datasets are collected.\n",
      "Consequently, it results in biased and divergent local models, posing difficulties in achieving a well-\n",
      "generalized aggregated model capable of effectively addressing diverse data sources.\n",
      "Addressing this issue, many optimization-based works are proposed from diverse perspec-\n",
      "tives (Wang et al., 2021). On the client side, they regularize the distance between local and\n",
      "global model (Li et al., 2020b; Acar et al., 2020), introduce control variates to correct local gra-\n",
      "dients (Karimireddy et al., 2020), align the feature space (Ye et al., 2022; Li et al., 2021). On the\n",
      "server side, they introduce momentum to update global model (Reddi et al., 2020; Hsu et al., 2019),\n",
      "adjust the process of aggregating local models (Wang et al., 2020b; Jhunjhunwala et al., 2022), mod-\n",
      "ify model initialization (Nguyen et al., 2022; Chen et al., 2022). However, the performance of all\n",
      "these methods is still severely limited as data heterogeneity fundamentally exists.\n",
      "In this paper, we propose a new idea of fundamentally mitigating the effects of data heterogeneity\n",
      "with the help of diverse generative content. To realize this idea, we propose a novel framework, Fed-\n",
      "erated Learning with Generative Content (FedGC). In FedGC, each client uses a publicly available\n",
      "generative model conditioned on task-related prompts to generate diverse data, which supplements\n",
      "1arXiv:2312.05807v1  [cs.LG]  10 Dec 2023the originally client-specific (the root of data heterogeneity) data. The supplemented dataset can\n",
      "subsequently facilitate client model training by encouraging the local model to also learn diverse\n",
      "patterns rather than only patterns of its private data. Despite the simplicity, FedGC can significantly\n",
      "mitigate data heterogeneity as generative diverse data introduces informative and general patterns,\n",
      "thus preventing each client from over-fitting its potentially biased private data.\n",
      "Furthermore, FedGC is a flexible framework with multiple potential directions. Considering gener-\n",
      "ation efficiency, data diversity, and data fidelity, we summarize four critical aspects in FedGC, in-\n",
      "cluding budget allocation, prompt design, generation guidance, and training strategy. In each aspect,\n",
      "we propose three representative solutions as candidates. For example, to achieve a better trade-off\n",
      "between diversity and fidelity during generation, we propo\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Aikyam: A Video Conferencing Utility for Deaf and \n",
      "Dumb \n",
      "Kshitij Deshpande  \n",
      "Information Technology  \n",
      "Pune Institute of Computer Technology  \n",
      "Pune, India \n",
      "kshitij.deshpande7@gmail.com  \n",
      "Amaan Naikwadi \n",
      "Information Technology  \n",
      "Pune Institute of Computer Technology  \n",
      "Pune, India \n",
      "amaannaikwadi@gmail.comVarad Mashalkar \n",
      "Information Technology  \n",
      "Pune Institute of Computer Technology  \n",
      "Pune, India \n",
      "varadmash2201@gmail.com \n",
      "Dr. Archana Ghotkar \n",
      "Information Technology  \n",
      "Pune Institute of Computer Technology  \n",
      "Pune, India \n",
      "aaghotkar@pict.edu Kaustubh Mhaisekar \n",
      "Information Technlogy  \n",
      "Pune Institute of Computer Technology  \n",
      "Pune, India \n",
      "kaustubh.m0803@gmail.com \n",
      " \n",
      "Abstract ‚Äî With the advent of the pandemic, the use of video \n",
      "conferencing platforms as a means of communication has greatly \n",
      "increased and with it, so have the remote opportunities. The deaf \n",
      "and dumb have traditionally faced several issues in \n",
      "communication, but now the effect is felt more severely. This paper \n",
      "proposes an all-encompassing video conferencing utility that can \n",
      "be used with existing video conferencing platforms to address \n",
      "these issues. Appropriate semantically correct sentences are \n",
      "generated from the signer‚Äôs gestures which would be interpreted \n",
      "by the system. Along with an audio to emit this sentence, the user‚Äôs \n",
      "feed is also used to annotate the sentence. This can be viewed by \n",
      "all participants, thus aiding smooth communication with all \n",
      "parties involved. This utility utilizes a simple LSTM model for \n",
      "classification of gestures. The sentences are constructed by a t5 \n",
      "based model. In order to achieve the required data flow, a virtual \n",
      "camera is used. \n",
      "Keywords‚Äî Video conferencing, communication, deaf and \n",
      "dumb, utility, gestures, LSTM, t5, virtual camera \n",
      "I. INTRODUCTION  \n",
      "Video Conferencing Platforms (VCPs) have gained \n",
      "popularity in recent times, especially in the wake of the \n",
      "COVID-19 pandemic. While these platforms have made \n",
      "communication easier for most people, they have posed a \n",
      "significant challenge for the deaf and dumb community. As \n",
      "of 2016, 6.3% of the Indian population face significant \n",
      "auditory loss. WHO reports 430 million people worldwide \n",
      "with the need for rehabilitation for hearing loss. Sign \n",
      "Language (SL) is a primary way of communication adopted \n",
      "by the Deaf and Hard of Hearing (DHH) community. \n",
      "Existing VCPs provide limited support to sign language \n",
      "users and require the need of a third person to act as an \n",
      "intermediary. This research proposes a lightweight desktop-\n",
      "based utility named \"Aikyam\" which can detect and interpret \n",
      "people communicating in sign language during a video \n",
      "conference call. It is compatible with popular platforms like \n",
      "Google Meet, Teams etc. Using a computationally \n",
      "lightweight algorithm, Aikyam can identify dynamic signs \n",
      "used in ISL and generate the sentence text for what the user \n",
      "is saying in sign language. \n",
      "The paper targets 2 main aspects of the proposed \n",
      "application in each of the section described. This aspects \n",
      "include the tasks of Sign Language Interpretation and \n",
      "generation of semantic sentences using keywords. The \n",
      "remainder of this paper is structured to cover the following \n",
      "sections. A comprehensive survey of existing methodologies \n",
      "is presented under the literature survey section. The datasets used are discussed in section 3. Section 4 describes the \n",
      "architecture of the utility. The detailed methodology and \n",
      "algorithms used in the utility are explained in section 5. \n",
      "Finally, the sections 6 and 7 discuss the results and \n",
      "conclusion of the research respectively. Section 7 also \n",
      "describes the possible scope in which this research can be \n",
      "expanded. \n",
      "II. LITERATURE SURVEY  \n",
      "Interpretation of SL is a progressive area of research \n",
      "which has evolved in various factors such as methods of data \n",
      "acquisition, data representation and classification algorithms. \n",
      "Recognition of gestures is categorized into recognition of \n",
      "characters and numbers, recognition of words and phrases \n",
      "and interpretation of sentences [3]. Real time interpretation \n",
      "of sign language is observed to be done using various \n",
      "permutations and combinations of data acquisition and \n",
      "classification algorithms. 3D sensors like Microsoft Kinect [1 \n",
      "- 5], data gloves [6 - 10] and image processing and computer \n",
      "vision [11 - 18] are observed to be common ways of tracking \n",
      "the user‚Äôs motion. Xiujuan Chai et al. utilized Kinect sensor \n",
      "to generate a 3D motion trajectory by utilizing the sensor‚Äôs \n",
      "capability to track depth and color. This trajectory was further \n",
      "subjected to linear resampling to account for the variable \n",
      "speed of the signer. In order to predict the sign, Euclidean \n",
      "distance based calculation was performed between the probe \n",
      "trajectory and the existing database of trajectories \n",
      "representing different signs in the Chinese Sign Language \n",
      "[1]. \n",
      "Computer Vision based approaches also follow a similar \n",
      "structure of feature extraction using image processing \n",
      "techniques attached to learning algorithms for classification \n",
      "of\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Neural Speech Embeddings for Speech Synthesis\n",
      "Based on Deep Generative Networks\n",
      "Seo-Hyun Lee\n",
      "Dept. of Brain and Cognitive Engineering\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "seohyunlee@korea.ac.krYoung-Eun Lee\n",
      "Dept. of Brain and Cognitive Engineering\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "yelee@korea.ac.krSoowon Kim\n",
      "Dept. of Artificial Intelligence\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "soowon kim@korea.ac.kr\n",
      "Byung-Kwan Ko\n",
      "Dept. of Artificial Intelligence\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "leaderbk525@korea.ac.krJun-Young Kim\n",
      "Dept. of Artificial Intelligence\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "jykim@korea.ac.krSeong-Whan Lee\n",
      "Dept. of Artificial Intelligence\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "sw.lee@korea.ac.kr\n",
      "Abstract ‚ÄîBrain-to-speech technology represents a fusion of\n",
      "interdisciplinary applications encompassing fields of artificial\n",
      "intelligence, brain-computer interfaces, and speech synthesis.\n",
      "Neural representation learning based intention decoding and\n",
      "speech synthesis directly connects the neural activity to the means\n",
      "of human linguistic communication, which may greatly enhance\n",
      "the naturalness of communication. With the current discoveries\n",
      "on representation learning and the development of the speech\n",
      "synthesis technologies, direct translation of brain signals into\n",
      "speech has shown great promise. Especially, the processed input\n",
      "features and neural speech embeddings which are given to the\n",
      "neural network play a significant role in the overall performance\n",
      "when using deep generative models for speech generation from\n",
      "brain signals. In this paper, we introduce the current brain-to-\n",
      "speech technology with the possibility of speech synthesis from\n",
      "brain signals, which may ultimately facilitate innovation in non-\n",
      "verbal communication. Also, we perform comprehensive analysis\n",
      "on the neural features and neural speech embeddings underlying\n",
      "the neurophysiological activation while performing speech, which\n",
      "may play a significant role in the speech synthesis works.\n",
      "Keywords‚Äìbrain-computer interface, deep neural networks,\n",
      "electroencephalogram, generative adversarial network, imagined\n",
      "speech, speech synthesis;\n",
      "I. INTRODUCTION\n",
      "Recently, there has been a growing interest in the field\n",
      "of brain-computer interfaces (BCIs). BCIs offer a way for\n",
      "humans to interact with external devices or control their\n",
      "surroundings by using brain signals [1]. Among the vari-\n",
      "ous methods used for BCI research, electroencephalography\n",
      "This work was supported by Institute for Information & Communications\n",
      "Technology Planning & Evaluation (IITP) grant funded by the Korea gov-\n",
      "ernment (MSIT) (No.2021-0-02068, Artificial Intelligence Innovation Hub;\n",
      "No. 2019-0-00079, Artificial Intelligence Graduate School Program(Korea\n",
      "University)).(EEG) is notable. EEG involves recording electrical activity by\n",
      "placing electrodes on the scalp without the need for invasive\n",
      "procedures like implanting electrodes. This makes EEG a\n",
      "valuable source of information for applications involving brain\n",
      "signals [2], [3]. BCIs based on EEG have been explored\n",
      "for a wide range of applications [4], including the control\n",
      "of motor functions, communication, and cognitive assessment\n",
      "[5], [6]. Despite the challenge of low signal quality in non-\n",
      "invasive EEG recordings, researchers have explored numerous\n",
      "applications due to the ease of use and practical advantages\n",
      "offered by EEG [7].\n",
      "Brain-to-speech (BTS) is a new stream of intuitive BCI\n",
      "communication which aims to generate audible speech from\n",
      "human brain signals [8]. It provides non-verbal communication\n",
      "facilitated by current domain adaptation and speech synthesis\n",
      "technologies. Neural patterns are transformed into spoken\n",
      "language by directly associating the neural features with\n",
      "human language. In previous studies, the domain adaptation\n",
      "framework established a natural correspondence between the\n",
      "neural features and the speech ground truth [8]. Therefore, au-\n",
      "dible speech could be generated from brain signals of silently\n",
      "imagined speech, demonstrating the potential of brain signal-\n",
      "mediated communication. The preprocessing procedures and\n",
      "the feature embeddings given as an input embedding of\n",
      "the model is known to play a significant role in the BTS\n",
      "performance.\n",
      "In this paper, we will provide an extensive analysis of BTS\n",
      "technology, an innovative field that holds promise for utilizing\n",
      "brain signals to synthesize speech directly. We provide an\n",
      "extensive analysis on the previous BTS work [8], which could\n",
      "contribute in highly improving the overall BTS performance.\n",
      "This advancement could introduce a new era of non-verbal\n",
      "communication, transforming how we interact with the ex-arXiv:2312.05814v1  [cs.AI]  10 Dec 20230 5000 10000 15000-4-2024104\n",
      "5 10 1520\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "5 10 1520\n",
      "40\n",
      "60\n",
      "80\n",
      "1000 5000 10000 15000-4-2024104\n",
      "5 10 1520\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "5 10 1520\n",
      "40\n",
      "60\n",
      "80\n",
      "1000 5000 10000 15000-4-2024104\n",
      "5 10 1520\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "5 10 1520\n",
      "40\n",
      "60\n",
      "80\n",
      "100Ambulance Help me Hello\n",
      "Audio\n",
      "fv\n",
      "(Spoken)\n",
      "fv\n",
      "(Imagined)Fig. 1. Feature embedding for the spoken s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ConSequence: Synthesizing Logically Con strained Sequence s for Electronic\n",
      "Health Record Generation\n",
      "Brandon Theodorou1, Shrusti Jain1, Cao Xiao2, Jimeng Sun1\n",
      "1University of Illinois at Urbana‚ÄìChampaign, Urbana, IL, United States\n",
      "2GE Healthcare, Chicago, IL, United States\n",
      "bpt3@illinois.edu, jimeng@illinois.edu\n",
      "Abstract\n",
      "Generative models can produce synthetic patient records for\n",
      "analytical tasks when real data is unavailable or limited.\n",
      "However, current methods struggle with adhering to domain-\n",
      "specific knowledge and removing invalid data. We present\n",
      "ConSequence , an effective approach to integrating domain\n",
      "knowledge into sequential generative neural network out-\n",
      "puts. Our rule-based formulation includes temporal aggre-\n",
      "gation and antecedent evaluation modules, ensured by an\n",
      "efficient matrix multiplication formulation, to satisfy hard\n",
      "and soft logical constraints across time steps. Existing con-\n",
      "straint methods often fail to guarantee constraint satisfac-\n",
      "tion, lack the ability to handle temporal constraints, and hin-\n",
      "der the learning and computational efficiency of the model.\n",
      "In contrast, our approach efficiently handles all types of\n",
      "constraints with guaranteed logical coherence. We demon-\n",
      "strate ConSequence ‚Äôs effectiveness in generating elec-\n",
      "tronic health records, outperforming competitors in achieving\n",
      "complete temporal and spatial constraint satisfaction with-\n",
      "out compromising runtime performance or generative quality.\n",
      "Specifically, ConSequence successfully prevents all rule\n",
      "violations while improving the model quality in reducing its\n",
      "test perplexity by 5% and incurring less than a 13% slowdown\n",
      "in generation speed compared to an unconstrained model.\n",
      "Introduction\n",
      "Sequential data generation applications are used in various\n",
      "fields, such as healthcare (Choi et al. 2017; Biswal et al.\n",
      "2021; Zhang et al. 2021; Theodorou, Xiao, and Sun 2023),\n",
      "finance (Assefa et al. 2020; Dogariu et al. 2022), natural\n",
      "language processing (Gatt and Krahmer 2018; Dong et al.\n",
      "2022; Reiter and Dale 1997), and computer vision (Tulyakov\n",
      "et al. 2018; Yang, Srivastava, and Mandt 2022; Ho et al.\n",
      "2022). In these applications, generative models demonstrate\n",
      "the capability to produce synthetic data closely resembling\n",
      "real-world datasets. Notably, language models have show-\n",
      "cased remarkable achievements in domains like text genera-\n",
      "tion (Chowdhery et al. 2022; Thoppilan et al. 2022; Brown\n",
      "et al. 2020) and health record generation (Theodorou, Xiao,\n",
      "and Sun 2023), primarily attributed to their adeptness in ac-\n",
      "curate next-token forecasting. Beyond mimicking real data,\n",
      "generative models often require adhering to specific rules\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.and temporal dependencies unique to an application domain.\n",
      "For instance, in medicine, generative models should follow\n",
      "logical constraints such as indications (the reason for using\n",
      "a specific treatment for a disease) and contraindications (the\n",
      "reason that makes a particular treatment inadvisable for that\n",
      "disease) to create realistic sequential data.\n",
      "To support domain-specific applications, generated sam-\n",
      "ples must not only approximate the true underlying data\n",
      "distribution but also encapsulate the relationships and de-\n",
      "pendencies encoded as rules derived from external knowl-\n",
      "edge. Failing to meet these constraints can hinder efficacy\n",
      "and deter adoption. Various current approaches attempt to\n",
      "ensure logical consistency in neural network outputs. These\n",
      "methods encompass strategies such as integrating rule con-\n",
      "straints into the loss function (Xu et al. 2018; Fischer et al.\n",
      "2019), employing post-processing modules designed to rec-\n",
      "tify model output violations (Manhaeve et al. 2018; Ho-\n",
      "ernle et al. 2022; Ahmed et al. 2022), or directly adding\n",
      "model components that ensure the final weights and out-\n",
      "puts align with domain knowledge (Towell and Shavlik\n",
      "1994; Avila Garcez and Zaverucha 1999; Giunchiglia and\n",
      "Lukasiewicz 2021). Despite the existing effort in constraint\n",
      "enforcement, sequential data generation still faces several\n",
      "challenges in aligning with real-world knowledge.\n",
      "‚Ä¢Inadequate treatment of temporal logical constraints .\n",
      "Existing models struggle with temporal constraints, which\n",
      "can be static or evolve across multiple time steps. These\n",
      "constraints are key to enhancing accuracy and reliability in\n",
      "sequential generation models. Yet, no existing models ef-\n",
      "fectively manage these constraints as the information con-\n",
      "ditioning them may not be accessible at each time step.\n",
      "‚Ä¢Efficiency and scalability . Sequential tasks typically en-\n",
      "compass a multitude of time steps and entail a substantial\n",
      "output dimensionality, underscoring the need for a stream-\n",
      "lined approach to facilitate large-scale sequence genera-\n",
      "tion. Current methods can be slow and computationally\n",
      "demanding, impairing real-world generation speed (Bond-\n",
      "Taylor et al. 2021). Thus, an effective solution should not\n",
      "only be asymptotically efficient but also maintain\n",
      "----------------------------------------------------------------------------------------------------\n",
      "V oice Activity Detection (V AD) in Noisy\n",
      "Environments\n",
      "Joshua Ball\n",
      "Johns Hopkins University\n",
      "Department of Electrical and Computer Engineering\n",
      "IEEE #94164957\n",
      "Baltimore, USA\n",
      "jball20@jh.edu\n",
      "Abstract ‚ÄîIn the realm of digital audio processing,\n",
      "Voice Activity Detection (V AD) plays a pivotal role in\n",
      "distinguishing speech from non-speech elements, a task\n",
      "that becomes increasingly complex in noisy environments.\n",
      "This paper details the development and implementation\n",
      "of a V AD system, specifically engineered to maintain high\n",
      "accuracy in the presence of various ambient noises. We\n",
      "introduce a novel algorithm enhanced with a specially\n",
      "designed filtering technique, effectively isolating speech\n",
      "even amidst diverse background sounds. Our compre-\n",
      "hensive testing and validation demonstrate the system‚Äôs\n",
      "robustness, highlighting its capability to discern speech\n",
      "from noise with remarkable precision. The exploration\n",
      "delves into: (1) the core principles underpinning V AD\n",
      "and its crucial role in modern audio processing; (2) the\n",
      "methodologies we employed to filter ambient noise; and\n",
      "(3) a presentation of evidence affirming our system‚Äôs\n",
      "superior performance in noisy conditions. The complete\n",
      "system and supplementary materials are accessible at:\n",
      "github.com/JBall1/V AD-in-Noisy-Environments.\n",
      "Index Terms ‚ÄîVoice Activity Detection, Audio Process-\n",
      "ing, Speech Recognition, Noise Suppression.\n",
      "I. I NTRODUCTION\n",
      "V oice Activity Detection (V AD) stands as a crit-\n",
      "ical component in the domain of digital signal\n",
      "processing, with its essential role in distinguishing\n",
      "between speech and non-speech elements in audio\n",
      "streams. Its applications are far-reaching into our\n",
      "everyday lives, extending into realms of speech\n",
      "recognition systems such as Amazon‚Äôs Alexa and\n",
      "Apple‚Äôs Siri, where it serves as the fundamental\n",
      "gateway for human-machine interaction. Both of\n",
      "these, and the many other applications of V AD, de-\n",
      "mand a high degree of both accuracy and reliabilityfrom V AD algorithms, as the quality of the user\n",
      "experience hinges on their performance.\n",
      "Despite its widespread use, the efficacy of V AD\n",
      "is significantly challenged by the presence of ambi-\n",
      "ent noise, which can obfuscate speech signals and\n",
      "degrade performance. The pursuit of a robust V AD\n",
      "system capable of navigating the complexities of\n",
      "real-world acoustic environments forms the corner-\n",
      "stone of this research. This paper delves into the\n",
      "development and refinement of an advanced V AD\n",
      "system, designed to enhance accuracy in detecting\n",
      "speech across various noisy settings.\n",
      "Central to our discussion are the core principles\n",
      "that underpin V AD technology and its pivotal role in\n",
      "modern audio processing. We detail the methodolo-\n",
      "gies employed for signal feature extraction, filtering\n",
      "and classification, pivotal to the system‚Äôs functional-\n",
      "ity. Furthermore, we provide empirical evidence that\n",
      "substantiates the system‚Äôs superior performance in\n",
      "noisy conditions. In an increasingly interconnected\n",
      "world, where voice commands and communication\n",
      "are integral to our devices and services, the need\n",
      "for robust and precise V AD systems has never been\n",
      "more evident.\n",
      "This paper also considers the broader implications\n",
      "of these advancements. As V AD technologies be-\n",
      "come increasingly embedded in our lives, questions\n",
      "of privacy, security, and user autonomy come to the\n",
      "fore. We address these considerations, advocating\n",
      "for a balanced approach that respects user rights\n",
      "while providing enhanced functionality.arXiv:2312.05815v1  [cs.SD]  10 Dec 2023II. R ELATED WORKS\n",
      "A. Personal VAD:Speaker-Conditioned Voice Activ-\n",
      "ity Detection\n",
      "[5] introduced a pioneering system, ‚ÄùPersonal\n",
      "V AD,‚Äù focusing on speaker-specific voice activity\n",
      "detection at the frame level. The system‚Äôs novelty\n",
      "lies in its capacity to trigger on-device speech\n",
      "recognition systems exclusively for the target user‚Äôs\n",
      "speech, thereby optimizing computational efficiency\n",
      "and battery usage. This targeted detection mecha-\n",
      "nism is particularly vital in scenarios where key-\n",
      "word detectors are impractical. Personal V AD‚Äôs ap-\n",
      "proach involves training a V AD-like neural network\n",
      "conditioned on the target speaker‚Äôs embedding or\n",
      "verification score, enabling it to differentiate be-\n",
      "tween non-speech, target speaker speech, and non-\n",
      "target speaker speech. The team‚Äôs optimized setup\n",
      "resulted in a model with just 130K parameters,\n",
      "outperforming a baseline system combining stan-\n",
      "dard V AD and speaker recognition networks. This\n",
      "advancement in voice activity detection technology\n",
      "represents a significant step towards more efficient\n",
      "and personalized speech recognition systems.\n",
      "B. CNN Self-attention Voice Activity Detector\n",
      "In a significant development within voice activ-\n",
      "ity detection (V AD), [4] proposed a novel single-\n",
      "channel V AD approach using a convolutional neural\n",
      "network (CNN). Their method capitalizes on the\n",
      "spatial information of noisy input spectrums to\n",
      "extract frame-wise embedding sequences, enhanced\n",
      "with a Self-Attention (SA) Encoder to capture con-\n",
      "textual information. Unlike previous m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FAKE ITTILLMAKE IT: FEDERATED LEARNING WITH\n",
      "CONSENSUS -ORIENTED GENERATION\n",
      "Rui Ye1, Yaxin Du1, Zhenyang Ni1, Siheng Chen1,2B, Yanfeng Wang2,1\n",
      "1Shanghai Jiao Tong University,2Shanghai AI Laboratory\n",
      "{yr991129,dorothydu,0107nzy,sihengc,wangyanfeng }@sjtu.edu.cn\n",
      "ABSTRACT\n",
      "In federated learning (FL), data heterogeneity is one key bottleneck that causes\n",
      "model divergence and limits performance. Addressing this, existing methods of-\n",
      "ten regard data heterogeneity as an inherent property and propose to mitigate its\n",
      "adverse effects by correcting models. In this paper, we seek to break this inherent\n",
      "property by generating data to complement the original dataset to fundamentally\n",
      "mitigate heterogeneity level. As a novel attempt from the perspective of data,\n",
      "we propose federated learning with consensus-oriented generation ( FedCOG ).\n",
      "FedCOG consists of two key components at the client side: complementary data\n",
      "generation, which generates data extracted from the shared global model to com-\n",
      "plement the original dataset, and knowledge-distillation-based model training,\n",
      "which distills knowledge from global model to local model based on the generated\n",
      "data to mitigate over-fitting the original heterogeneous dataset. FedCOG has two\n",
      "critical advantages: 1) it can be a plug-and-play module to further improve the\n",
      "performance of most existing FL methods, and 2) it is naturally compatible with\n",
      "standard FL protocols such as Secure Aggregation since it makes no modification\n",
      "in communication process. Extensive experiments on classical and real-world FL\n",
      "datasets show that FedCOG consistently outperforms state-of-the-art methods.\n",
      "1 I NTRODUCTION\n",
      "Federated learning (FL) is an emerging privacy-preserving training paradigm that enables multiple\n",
      "clients to train a global model collaboratively without directly accessing their raw data (McMahan\n",
      "et al., 2017). With the increasing privacy concerns and legislation, FL has attracted much attention\n",
      "from industry and academia (Kairouz et al., 2019; Yang et al., 2019). FL can be widely used in\n",
      "a diverse of real-world applications, including keyboard prediction (Hard et al., 2018; Yang et al.,\n",
      "2018), healthcare (Dayan et al., 2021; Xu et al., 2021), and finance (Long et al., 2020).\n",
      "As one of the most common and critical issues in FL, data heterogeneity fundamentally limits FL‚Äôs\n",
      "practical performance (McMahan et al., 2017) as clients‚Äô datasets could be distinctly different from\n",
      "each other (Li et al., 2020a). To tackle this issue, enormous previous works focus on model-level\n",
      "correction at either the client or server side. At the client side, many methods propose to enhance the\n",
      "consistency among local models through regularization in model space (Li et al., 2020b; Acar et al.,\n",
      "2020) or feature space (Li et al., 2021a; Shi et al., 2022), or local gradient correction (Karimireddy\n",
      "et al., 2020). At the server side, some methods introduce update momentum (Hsu et al., 2019; Reddi\n",
      "et al., 2021), apply knowledge distillation based on public dataset (Lin et al., 2020; Li & Wang,\n",
      "2019), or adjust aggregation manner (Wang et al., 2020b; Li et al., 2020c). However, these previous\n",
      "works regard the data heterogeneity as an inherent property and attempt to mitigate its negative\n",
      "effects via model correction , leaving the training adversely affected throughout the FL process as\n",
      "the inherent heterogeneity persists to cause client drift (Karimireddy et al., 2020).\n",
      "In this paper, we seek an orthogonal approach to address the data heterogeneity issue: correcting\n",
      "the data itself to mitigate the heterogeneity level. To correct the data, our core idea is to generate\n",
      "data from the shared global model as consensus to complement the original data, which contributes\n",
      "to mitigate the effects of data heterogeneity by making all local datasets more homogeneous (e.g.,\n",
      "local categorical distributions are more balanced).\n",
      "Following this spirit of data correction, we propose a new FL algorithm, Federated Learning with\n",
      "Consensus- Oriented Generation, denoted as FedCOG . FedCOG includes two novel components:\n",
      "1arXiv:2312.05966v1  [cs.LG]  10 Dec 2023complementary data generation and knowledge-distillation-based model training. 1) During com-\n",
      "plementary dataset generation, each client generates data that is accurately predicted by global model\n",
      "but incorrectly predicted by local model. In this case, the generated data not only contains consen-\n",
      "sual knowledge in the global model but also serves as an informative dataset complement, mitigating\n",
      "the level of data heterogeneity. 2) During local model training, beside minimizing the conventional\n",
      "task-driven loss on the original dataset, each client distills the knowledge from global model to cur-\n",
      "rent local model based on the generated dataset. Such knowledge distillation contributes to enhance\n",
      "the consensus among local models, which further alleviates the impact of data heterogeneity. Over-\n",
      "all, FedCOG improves the performance by mitigating both data heterogeneity level and its effects.\n",
      "FedCOG has two \n",
      "----------------------------------------------------------------------------------------------------\n",
      "ICTS URF: I MPLICIT CONTINUOUS -TIMESURVIVAL FUNCTIONS\n",
      "WITH NEURAL NETWORKS\n",
      "Chanon Puttanawarut\n",
      "Chakri Naruebodindra Medical Institute\n",
      "Ramathibodi Hospital\n",
      "Mahidol University\n",
      "Samutprakarn, Thailand\n",
      "and\n",
      "Department of Clinical Epidemiology and Biostatistics\n",
      "Faculty of Medicine Ramathibodi Hospital\n",
      "Mahidol University\n",
      "Bangkok, Thailand\n",
      "chanonp@protonmal.comPanu Looareesuwan\n",
      "Department of Clinical Epidemiology and Biostatistics\n",
      "Faculty of Medicine Ramathibodi Hospital\n",
      "Mahidol University\n",
      "Bangkok, Thailand\n",
      "panu.loo@mahidol.edu\n",
      "Romen Samuel Wabina\n",
      "Department of Clinical Epidemiology and Biostatistics\n",
      "Faculty of Medicine Ramathibodi Hospital\n",
      "Mahidol University\n",
      "Bangkok, Thailand\n",
      "romensamuel.wab@mahidol.ac.th\n",
      "Prut Saowaprut\n",
      "Department of Clinical Epidemiology and Biostatistics\n",
      "Faculty of Medicine Ramathibodi Hospital\n",
      "Mahidol University\n",
      "Bangkok, Thailand\n",
      "prut.sao@mahidol.edu\n",
      "ABSTRACT\n",
      "Survival analysis is a widely known method for predicting the likelihood of an event over time.\n",
      "The challenge of dealing with censored samples still remains. Traditional methods, such as the\n",
      "Cox Proportional Hazards (CPH) model, hinge on the limitations due to the strong assumptions of\n",
      "proportional hazards and the predetermined relationships between covariates. The rise of models\n",
      "based on deep neural networks (DNNs) has demonstrated enhanced effectiveness in survival analysis.\n",
      "This research introduces the Implicit Continuous-Time Survival Function (ICTSurF), built on a\n",
      "continuous-time survival model, and constructs survival distribution through implicit representation.\n",
      "As a result, our method is capable of accepting inputs in continuous-time space and producing survival\n",
      "probabilities in continuous-time space, independent of neural network architecture. Comparative\n",
      "assessments with existing methods underscore the high competitiveness of our proposed approach.\n",
      "Our implementation of ICTSurF is available at https://github.com/44REAM/ICTSurF.\n",
      "Keywords Survival Analysis ¬∑Time-to-event ¬∑Deep Learning ¬∑Machine learningarXiv:2312.05818v1  [cs.LG]  10 Dec 2023Implicit Continuous-Time Survival Function\n",
      "1 Introduction\n",
      "Survival analysis, also known as time-to-event analysis, aims at estimating the survival distributions of a specific\n",
      "event and time-of-interests. Typically, the estimation of survival probability involves modeling a relationship between\n",
      "covariates and time-to-event that is typically partially observed; e.g., it may not be possible to observe the event status\n",
      "of the same sample. This presents one of the key challenges in the field of survival analysis.\n",
      "The conventional approaches commonly employed in survival analysis include the Cox Proportional Hazards (CPH)\n",
      "model, as proposed by Cox [6]. Although the CPH model is widely used, it is burdened by a substantial assumption of\n",
      "a consistent proportional hazard throughout the entire lifespan and a predetermined relationship between covariates.\n",
      "Other conventional methods, such as Weibull or Log-Normal distribution, also model a relationship between time and\n",
      "covariates based on a strong parametric assumption.\n",
      "Recently, due to the success of DNN-based models, the majority of research in survival analysis has shifted towards\n",
      "models built on DNNs, demonstrating superior performance compared to traditional approaches. Recent studies have\n",
      "shown that the majority of the survival models are an extension of the conventional CPH model [28]. It calculates the\n",
      "hazard rate at time tin the form of h(t) =h0(t)eg(x), where eg(x)is a relative risk that depends on covariate vector x\n",
      "such that g(¬∑)is estimated by a neural network. Initial investigations of adopting neural networks in survival analysis\n",
      "date back to 1995 when Faraggi-Simon et al. [8] utilized neural networks to predict individual risk events based on the\n",
      "CPH model assumption. However, this pioneering study failed to show the advantages of using such methods over\n",
      "traditional CPH models. The deep learning-based model with CPH assumption was then improved in DeepSurv [13]\n",
      "using modern deep learning techniques, which shows superior performance over the traditional CPH model. However,\n",
      "this deep learning model still follows the proportional hazards assumption. To overcome this, several approaches\n",
      "have been developed using deep learning. Cox-Time [18] calculates the relative risk function as eg(x,t)to model the\n",
      "interaction between xandt. Therefore, Cox-Time is more flexible and robust than DeepSurv since it does not depend\n",
      "on the CPH assumption, but is still based on the partial likelihood function.\n",
      "Existing studies have developed discrete-time survival models that try to overcome the proportional hazards assumption.\n",
      "These models allow the input data at a predefined specific time only. For instance, Deephit [20] uses a discrete-time\n",
      "likelihood that constructs a PMF of event time using softmax as an output layer of the model. This approach can\n",
      "overcome the CPH assumption by learning the PMF directly. Deephit has been designed to deal with competing risks\n",
      "b\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Jumpstarting Surgical Computer Vision\n",
      "Deepak Alapatta,‚àó, Aditya Muralia, Vinkle Srivastava,b, Pietro Mascagnic, AI4SafeChole Consortiumc,d,e,f, Nicolas Padoya,b\n",
      "aICube, University of Strasbourg, CNRS, Strasbourg, France\n",
      "bIHU Strasbourg, Strasbourg, France\n",
      "cFondazione Policlinico Universitario A. Gemelli IRCCS, Rome, Italy\n",
      "dAzienda Ospedaliero-Universitaria Sant‚ÄôAndrea, Rome, Italy\n",
      "eFondazione IRCCS Ca‚Äô Granda Ospedale Maggiore Policlinico, Milan, Italy\n",
      "fMonaldi Hospital, Naples, Italy\n",
      "Purpose: General consensus amongst researchers and industry points to a lack of large, representative annotated datasets as the\n",
      "biggest obstacle to progress in the field of surgical data science. Self-supervised learning represents a solution to part of this\n",
      "problem, removing the reliance on annotations. However, the robustness of current self-supervised learning methods to domain\n",
      "shifts remains unclear, limiting our understanding of its utility for leveraging diverse sources of surgical data.\n",
      "Methods: In this work, we employ self-supervised learning to flexibly leverage diverse surgical datasets, thereby learning task-\n",
      "agnostic representations that can be used for various surgical downstream tasks. Based on this approach, to elucidate the impact\n",
      "of pre-training on downstream task performance, we explore 22 di fferent pre-training dataset combinations by modulating three\n",
      "variables: source hospital, type of surgical procedure, and pre-training scale (number of videos). We then finetune the resulting\n",
      "model initializations on three diverse downstream tasks: namely, phase recognition and critical view of safety in laparoscopic\n",
      "cholecystectomy and phase recognition in laparoscopic hysterectomy.\n",
      "Results: Controlled experimentation highlights sizable boosts in performance across various tasks, datasets, and labeling bud-\n",
      "gets. However, this performance is intricately linked to the composition of the pre-training dataset, robustly proven through\n",
      "several study stages.\n",
      "Conclusion: The composition of pre-training datasets can severely a ffect the e ffectiveness of SSL methods for various\n",
      "downstream tasks and should critically inform future data collection e fforts to scale the application of SSL methodologies.\n",
      "Keywords: Self-Supervised Learning, Transfer Learning, Surgical Computer Vision, Endoscopic Videos, Critical View\n",
      "of Safety, Phase Recognition\n",
      "1. Introduction\n",
      "Over the last decade, developments in data science have\n",
      "had a sweeping e ffect spanning almost all areas of healthcare.\n",
      "While this has catalyzed the development of numerous clin-\n",
      "ically impactful applications in fields such as pathology and\n",
      "radiology, the same cannot be said for surgery [14]. In 2019,\n",
      "a large survey, conducted by the Surgical Data Science Initia-\n",
      "tive [13], primarily attributed this lack of success stories to a\n",
      "lack of representative annotated data [14]. On the other hand,\n",
      "it is also unclear whether available datasets are being well-\n",
      "utilized when not directly specific to the task at hand. For\n",
      "example, a recently conducted survey [6] on participant prac-\n",
      "tices across 80 biomedical image analysis competitions, re-\n",
      "vealed that only 9% of all respondents that used deep learning\n",
      "utilized data outside what was provided for the competition\n",
      "(excluding pre-trained models). A natural explanation may\n",
      "be that available public datasets are often small, specific, and\n",
      "mono-centric [14], making it unclear whether they could be\n",
      "leveraged to improve model performance.\n",
      "‚àóCorresponding author: alapatt@unistra.frIn the broader computer vision domain, one of the most\n",
      "effective strategies for leveraging related datasets is transfer\n",
      "learning. For deep learning models, a neural network is pre-\n",
      "trained on a first dataset and task, then the resulting learned\n",
      "features are used as an initialization, or a ‚Äújumpstart‚Äù, for\n",
      "learning the task of interest on a smaller labeled dataset. This\n",
      "simple approach for visual representation learning has proven\n",
      "almost unreasonably e ffective, contributing significantly to\n",
      "pushing the state of the art for a wide range of tasks including\n",
      "segmentation [11], object detection [12], and activity recog-\n",
      "nition [2]. Since then, this paradigm of pre-training and then\n",
      "fine-tuning has become the de facto standard, with pre-trained\n",
      "initializations for large-scale general computer vision datasets,\n",
      "such as ImageNet [19], now widely available for integration\n",
      "into other work. We take inspiration from these develop-\n",
      "ments, hypothesizing that similar access to more appropriate\n",
      "(see Fig. 1) domain-specific initializations can e ffectively con-\n",
      "solidate disparate datasets in the field and channel them toward\n",
      "widely enabling early prototyping for various clinical appli-\n",
      "cations and, eventually, developing more success stories for\n",
      "surgical data science.\n",
      "One challenge precluding this development is the availabil-\n",
      "ity of diverse large-scale datasets, annotated with many cate-arXiv:2312.05968v1  [cs.CV]  10 Dec 20232\n",
      "Fig. 1: Uniform Manifold Approximation and Projection (UMAP) \n",
      "----------------------------------------------------------------------------------------------------\n",
      "ASVD: Activation-aware Singular Value Decomposition for\n",
      "Compressing Large Language Models\n",
      "Zhihang Yuan* 1Yuzhang Shang* 2Yue Song3Qiang Wu1Yan Yan2Guangyu Sun4\n",
      "Abstract\n",
      "This paper explores a new post-hoc training-free\n",
      "compression paradigm for compressing Large\n",
      "Language Models (LLMs) to facilitate their wider\n",
      "adoption in various computing environments. We\n",
      "delve into the challenges of LLM compression,\n",
      "notably their dependency on extensive training\n",
      "data and computational resources. We propose a\n",
      "training-free approach dubbed Activation-aware\n",
      "Singular Value Decomposition (ASVD) to ad-\n",
      "dress these limitations. ASVD effectively man-\n",
      "ages activation outliers by adjusting the weight\n",
      "matrix based on the activation distribution, im-\n",
      "proving decomposition accuracy and efficiency.\n",
      "Our method also addresses the varying sensitivity\n",
      "of different LLM layers to decomposition, with\n",
      "an iterative calibration process for optimal layer-\n",
      "specific decomposition. Experiments demonstrate\n",
      "that ASVD can compress network by 10%-20%\n",
      "without losing reasoning capacities. Additionally,\n",
      "it can be seamlessly integrated with other LLM\n",
      "compression paradigms, showcasing its flexible\n",
      "compatibility. Code and compressed models are\n",
      "available at ASVD4LLM.\n",
      "1. Introduction\n",
      "Numerous strategies have been proposed to mitigate the\n",
      "memory consumption issues in Large Language Models\n",
      "(LLMs), as surveyed by Zhu et al. [2023]. These meth-\n",
      "ods predominantly fall into two categories: neural network\n",
      "compression and system optimizations. In terms of neural\n",
      "network compression, techniques such as weight quantiza-\n",
      "tion [Dettmers et al., 2022, Shang et al., 2023], network\n",
      "pruning [Frantar & Alistarh, 2023], and knowledge distilla-\n",
      "tion [Agarwal et al., 2023] have been extensively explored.\n",
      "Meanwhile, system optimizations focus on efficient mem-\n",
      "*Equal contribution1Houmo AI2Illinois Institute of Tech-\n",
      "nology3University of Trento4Peking University. Correspon-\n",
      "dence to: Zhihang Yuan <hahnyuan@gmail.com >, Guangyu Sun\n",
      "<gsun@pku.edu.cn >.\n",
      "7.5 10.0 12.5 15.0 17.5 20.0 22.5\n",
      "weight memory cost (GB)45678910perplexity on Wikitext2Less Memory Overhead\n",
      "Better Model\n",
      "PerformanceLLaMA-2-13b (FP16)\n",
      "LLaMA-2-13b (INT8)\n",
      "LLaMA-2-13b (INT6)ASVD (FP16)\n",
      "ASVD (INT8)\n",
      "ASVD (INT6)Figure 1. Our post-training LLM decomposition method is or-\n",
      "thogonal to existing LLM compression techniques , enabling it\n",
      "to function as a versatile and plug-and-play solution for prevalent\n",
      "compression paradigms, including popular quantization methods.\n",
      "ory management, with cache mechanisms like FlashAtten-\n",
      "tion [Dao et al., 2022] and PagedAttention [Kwon et al.,\n",
      "2023]. Distinct from these approaches, the paradigm of low-\n",
      "rank decomposition is less explored but promising. This\n",
      "technique involves approximating the weight matrices in\n",
      "neural networks with matrices of lower rank, effectively\n",
      "reducing the model size. Given the massive number of\n",
      "parameters in LLMs, low-rank decomposition offers signifi-\n",
      "cant potential for memory reduction. Despite its potential,\n",
      "it remains a relatively underutilized approach in the field of\n",
      "LLM compression. Furthermore, low-rank decomposition is\n",
      "complementary to existing LLM compression techniques by\n",
      "further compressing quantized or pruned models, enhancing\n",
      "overall efficiency [Cheng et al., 2017, Deng et al., 2020].\n",
      "From the perspective of network compression, traditional\n",
      "low-rank decomposition methods typically adhere to a\n",
      "straightforward process: initially training the original model\n",
      "and subsequently fine-tuning the decomposed model [Jader-\n",
      "berg et al., 2014, Khodak et al., 2021, Wang et al., 2021,\n",
      "Hsu et al., 2022]. While this approach is effective, it is\n",
      "resource-intensive and requires the entire training dataset\n",
      "and substantial computational power for end-to-end back-\n",
      "propagation. Applying this method to Large Language Mod-\n",
      "els (LLMs) would encounter major challenges. Firstly, the\n",
      "training data for LLMs may not always be readily available,\n",
      "often restricted by privacy and commercial considerations.\n",
      "Secondly, the training process for these models is notori-\n",
      "ously expensive, both in terms of time and computational\n",
      "1arXiv:2312.05821v1  [cs.CL]  10 Dec 2023ASVD: Activation-aware Singular Value Decomposition for Compressing Large Language Models\n",
      "resources. Given these constraints, the concept of ‚Äútraining-\n",
      "free‚Äù compression emerges as a more viable approach for\n",
      "LLMs [Zhu et al., 2023]. This approach includes methods\n",
      "like LLM post-training quantization[Dettmers et al., 2022,\n",
      "Yuan et al., 2023] and LLM post-training pruning [Frantar\n",
      "& Alistarh, 2023], which compress LLMs without the need\n",
      "for extensive retraining. These training-free methods offer a\n",
      "more practical solution for efficiently compressing LLMs.\n",
      "To realize low-rank post-training decomposition in\n",
      "LLMs , we conduct an extensive analysis of the baseline\n",
      "methods for LLM decomposition. We first observe that\n",
      "straightforward application of existing low-rank decomposi-\n",
      "tion techniques, which typically necessitate training, proves\n",
      "ineffective f\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ACTIVATING FREQUENCY AND VIT FOR 3D POINT CLOUD QUALITY ASSESSMENT\n",
      "WITHOUT REFERENCE\n",
      "Oussama Messai *, Abdelouahid Bentamou *, Abbass Zein-Eddine *, Yann Gavet *\n",
      "* Mines Saint-Etienne, Univ Lyon, CNRS, UMR 5307 LGF, Centre SPIN, F - 42023 Saint-Etienne France\n",
      "ABSTRACT\n",
      "Deep learning-based quality assessments have signifi-\n",
      "cantly enhanced perceptual multimedia quality assessment,\n",
      "however it is still in the early stages for 3D visual data\n",
      "such as 3D point clouds (PCs). Due to the high volume\n",
      "of 3D-PCs, such quantities are frequently compressed for\n",
      "transmission and viewing, which may affect perceived qual-\n",
      "ity. Therefore, we propose no-reference quality metric of\n",
      "a given 3D-PC. Comparing to existing methods that mostly\n",
      "focus on geometry or color aspects, we propose integrating\n",
      "frequency magnitudes as indicator of spatial degradation pat-\n",
      "terns caused by the compression. To map the input attributes\n",
      "to quality score, we use a light-weight hybrid deep model;\n",
      "combined of Deformable Convolutional Network (DCN) and\n",
      "Vision Transformers (ViT). Experiments are carried out on\n",
      "ICIP20 [1], PointXR [2] dataset, and a new big dataset called\n",
      "BASICS [3]. The results show that our approach outper-\n",
      "forms state-of-the-art NR-PCQA measures and even some\n",
      "FR-PCQA on PointXR. The implementation code can be\n",
      "found at: https://github.com/o-messai/3D-PCQA\n",
      "Index Terms ‚ÄîNo-reference 3D point cloud quality as-\n",
      "sessment, Vision Transformer (ViT), deep learning.\n",
      "1. INTRODUCTION\n",
      "3D Point clouds (3D-PCs) provide the shape information\n",
      "of 3D objects and can be quickly captured by 3D scanners;\n",
      "which are becoming accessible even in our mobile devices\n",
      "(e.g., tablets, smartphones, etc). Recently, 3D-PC has been an\n",
      "active research field, closely tied to applications such as aug-\n",
      "mented reality, drones, self-driving vehicles, and 3D video\n",
      "games [4, 5]. However, because of the large number of points\n",
      "cloud required to describe the object, this type of 3D data re-\n",
      "quires a large amount of memory storage, and demands high\n",
      "computation for transmitting and display. Therefore, im-\n",
      "plementing compression procedures to the 3D-PCs becomes\n",
      "necessary, which can have an impact on its visual quality.\n",
      "However, to ensure that the compression procedure is reli-\n",
      "able, the perceptual quality rate is measured. Subjective and\n",
      "objective studies could be used to get Point Cloud Quality\n",
      "Assessment (PCQA). The former involves human interven-\n",
      "tion, whereas the latter is based on computational algorithms\n",
      "that anticipate perceptual quality. The PCQA metrics are\n",
      "often used to evaluate the perceptual correctness of the codedpoint cloud in relation to a certain compression rate. In order\n",
      "to develop sophisticated quality measurements that forecast\n",
      "the perceived impact of a given PC, it is important to validate\n",
      "the metric output with a subjective evaluation, namely human\n",
      "visual quality assessment. It is mostly expressed in terms\n",
      "of Mean Opinion Score (MOS) or Difference Mean Opinion\n",
      "Score (DMOS) [6, 7]. Objective quality measurements are\n",
      "classified into three types based on the availability of the ref-\n",
      "erence PC: full-reference (FR), reduced-reference (RR), and\n",
      "no-reference (NR). However, subjective human ratings can be\n",
      "time consuming and expensive, and a pristine reference is not\n",
      "always accessible. Therefore, researchers are increasingly\n",
      "relying on NR objective measurements due to the broad ben-\n",
      "efits they give. As a result, most current PCQA approaches\n",
      "are devoted to NR-PCQA in order to meet the criteria of most\n",
      "modern applications. Furthermore, the PCQA metrics can be\n",
      "divided into three categories: point-based metrics, feature-\n",
      "based metrics, and projection-based metrics. In Point-based\n",
      "metrics such as Point-to-Point (Po2Po) [8, 9], Point-to-Plane\n",
      "(Po2Pl) [10]. These metrics work by calculating the geomet-\n",
      "ric/color distance between the reference PC and its distorted\n",
      "variant. In feature-based metrics, geometry and associated\n",
      "properties are extracted at the point level in a global or local\n",
      "way. For instance, a metric called Geotex [11], which uses\n",
      "Local Binary Pattern (LBP) as descriptors, while in metric\n",
      "[12], both geometry and color data have been used as fea-\n",
      "tures. Finally, in projection-based measurements, the points\n",
      "are projected into 2D grids at certain view points/degrees, and\n",
      "2D quality measures are applied to these views. For instance,\n",
      "in metric [13], the authors used point cloud rendering to gen-\n",
      "erate views (2D images), which were then fed into a deep\n",
      "convolutional neural network (CNN) to provide perceptual\n",
      "quality scores.\n",
      "In the following, we briefly address the recent suggested\n",
      "NR-PCQA metrics: In metric [14], low-level details such\n",
      "as geometric distance, local curvature, and brightness val-\n",
      "ues were retrieved from the 3D-PC. The latter inputs were\n",
      "then mapped to a quality score using a deep CNN. Moreover\n",
      "in metric [15], the PCs were transformed from 3D space\n",
      "into domains of quality-related geometry and color features.\n",
      "Then, using 3D natural scene statistics and entrop\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TOWARD OPEN-ENDED EMBODIED TASKS SOLVING\n",
      "Wei Wang\n",
      "Western University\n",
      "Canada\n",
      "wwang828@uwo.caDongqi Han\n",
      "Microsoft Research Asia\n",
      "China\n",
      "dongqihan@microsoft.com\n",
      "Xufang Luo\n",
      "Microsoft Research Asia\n",
      "China\n",
      "xufang.luo@microsoft.comYifei Shen\n",
      "Microsoft Research Asia\n",
      "China\n",
      "yifeishen@microsoft.com\n",
      "Charles Ling\n",
      "Western University\n",
      "Canada\n",
      "charles.ling@uwo.caBoyu Wang\n",
      "Western University\n",
      "Canada\n",
      "bwang@csd.uwo.caDongsheng Li\n",
      "Microsoft Research Asia\n",
      "China\n",
      "dongsli@microsoft.com\n",
      "ABSTRACT\n",
      "Empowering embodied agents, such as robots, with Artificial Intelligence (AI) has\n",
      "become increasingly important in recent years. A major challenge is task open-\n",
      "endedness. In practice, robots often need to perform tasks with novel goals that\n",
      "are multifaceted, dynamic, lack a definitive \"end-state\", and were not encountered\n",
      "during training. To tackle this problem, this paper introduces Diffusion for Open-\n",
      "ended Goals (DOG), a novel framework designed to enable embodied AI to plan\n",
      "and act flexibly and dynamically for open-ended task goals. DOG synergizes the\n",
      "generative prowess of diffusion models with state-of-the-art, training-free guid-\n",
      "ance techniques to adaptively perform online planning and control. Our evalua-\n",
      "tions demonstrate that DOG can handle various kinds of novel task goals not seen\n",
      "during training, in both maze navigation and robot control problems. Our work\n",
      "sheds light on enhancing embodied AI‚Äôs adaptability and competency in tackling\n",
      "open-ended goals.\n",
      "1 I NTRODUCTION\n",
      "Our FrameworkOffline Experience\n",
      "without\n",
      "Goal-Condition\n",
      "Handle\n",
      "Open-ended Goals\n",
      "Training-freeAchieve Desired State\n",
      "Desired\n",
      "StateStartMovement Control\n",
      "(speed)\n",
      "Zero-shot T ransfer\n",
      "(to new environment)\n",
      "No longer passable!Language Guided\n",
      "\"Open the\n",
      "door wide\"\n",
      "Figure 1: Open-Ended Goals. Our framework leverages diverse offline trajectories to master condi-\n",
      "tional goal planning and execution. Key highlights include: (1) Achieve desired state as in traditional\n",
      "goal-conditioned reinforcement learning, (2) Beyond (1), introducing process-level control such as\n",
      "manipulating speed, (3) Adapt to new situations without prior training, by changing its behavior,\n",
      "like avoiding certain areas, and (4) Understand and follow instructions given in natural language to\n",
      "modify its actions.\n",
      "Correspondence: dongqihan@microsoft.com; bwang@csd.uwo.ca.\n",
      "1arXiv:2312.05822v1  [cs.AI]  10 Dec 2023Task solving for open-ended goals (Fig. 1) in embodied artificial intelligence (AI) (Jin & Zhang,\n",
      "2020) represent a cornerstone in the pursuit of creating machines that can assist humans in real-world\n",
      "(Taylor et al., 2016). Unlike traditional AI that operates in virtual realms or specific, constrained\n",
      "settings (Silver et al., 2016), embodied AI is situated in the physical world‚Äîthink robots, drones,\n",
      "or self-driving cars. Here, the utility is not merely in solving a specific problem but in the system‚Äôs\n",
      "ability to perform a broad range of tasks, enabling everything from advanced automation to assistive\n",
      "technologies for the disabled, much like humans and animals do.\n",
      "Yet, this endeavor presents a myriad of challenges. Real-world tasks with open-ended goals are\n",
      "highly diverse and often cannot be described by a single variable or a single type of variables.\n",
      "For example, an embodied agent tasked with \"assisting in household chores\" would require the\n",
      "capabilities to perform various tasks, from vacuuming to cooking, while adapting to new challenges\n",
      "and human preferences over time. These goals are almost impossible to fully cover in learning. The\n",
      "inherent complexity and variability of such goals necessitate a significant advancement in decision-\n",
      "making capacity.\n",
      "To create embodied AI that can flexibly handle open-ended goals, both the knowledge about the\n",
      "world and skills of motor actions need to be equipped. Only until recent times, a handful of works\n",
      "(Driess et al., 2023; Dai et al., 2023) started the attempts for ambition by leveraging the real-world\n",
      "knowledge from pre-trained vision (Rombach et al., 2022) and/or language (Brown et al., 2020)\n",
      "foundation models. On the other hand, Stooke et al. (2021); Bauer et al. (2023) endeavors to perform\n",
      "large-scale multi-task training in a game world so that the agent can quickly adapt to novel tasks.\n",
      "These works are worthy of recognition on the path to embodied AI that can truly tackle open-ended\n",
      "tasks. Nonetheless, these studies are still trapped by the conventional goal-as-an-input paradigm\n",
      "(Fig. 2 Left), and thus the flexibility of goals is limited (e.g., if a robot is trained to go anywhere in\n",
      "the world, after training it cannot be asked to keep away from somewhere.).\n",
      "In the presence of these challenges, we propose a novel framework for solving embodied planning\n",
      "and control for open-ended goals. This work is a trial to approach the ultimate embodied AI that can\n",
      "assist people with diverse tasks such as healthcare, driving, and housework, though further endeavor\n",
      "is, of course, still largely demanded. Here, we empower embodied AI with the recent advance of\n",
      "diffusion models (Ho et \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Learning the Causal Structure of Networked Dynamical Systems\n",
      "under Latent Nodes and Structured Noise\n",
      "Augusto Santos1,*, Diogo Rente2, Rui Seabra2, Jos ¬¥e M. F. Moura2,\n",
      "1Instituto de Telecomunicac ¬∏ Àúoes-IT, Lisbon, Portugal\n",
      "2Department of Electrical and Computer Engineering at Carnegie Mellon University, Pittsburgh, PA, USA\n",
      "augusto.santos@lx.it.pt, drobertd@andrew.cmu.edu, rvilarpo@andrew.cmu.edu, moura@andrew.cmu.edu.\n",
      "Abstract\n",
      "This paper considers learning the hidden causal network of\n",
      "a linear networked dynamical system (NDS) from the time\n",
      "series data at some of its nodes ‚Äì partial observability. The\n",
      "dynamics of the NDS are driven by colored noise that gen-\n",
      "erates spurious associations across pairs of nodes, rendering\n",
      "the problem much harder. To address the challenge of noise\n",
      "correlation and partial observability, we assign to each pair of\n",
      "nodes a feature vector computed from the time series data of\n",
      "observed nodes. The feature embedding is engineered to yield\n",
      "structural consistency: there exists an affine hyperplane that\n",
      "consistently partitions the set of features, separating the fea-\n",
      "ture vectors corresponding to connected pairs of nodes from\n",
      "those corresponding to disconnected pairs. The causal infer-\n",
      "ence problem is thus addressed via clustering the designed\n",
      "features. We demonstrate with simple baseline supervised\n",
      "methods the competitive performance of the proposed causal\n",
      "inference mechanism under broad connectivity regimes and\n",
      "noise correlation levels, including a real world network. Fur-\n",
      "ther, we devise novel technical guarantees of structural con-\n",
      "sistency for linear NDS under the considered regime.\n",
      "Introduction\n",
      "Complex Networked Dynamical Systems (NDS) are\n",
      "causally structured: the state of each unit or node evolves\n",
      "over time due to peer-to-peer interactions or local informa-\n",
      "tion exchange (Barrat, Barth ¬¥elemy, and Vespignani 2008).\n",
      "Examples include: brain activity (Huang and Ding 2016;\n",
      "Li¬¥egeois et al. 2020); Gene Regulatory Networks (Aalto\n",
      "et al. 2020; Casadiego et al. 2017); or pandemics (Ganesh,\n",
      "Massouli ¬¥e, and Towsley 2005; Wan et al. 2014). Under-\n",
      "standing the underlying connectivity pattern in these appli-\n",
      "cations is fundamental to forecast the long term behavior of\n",
      "the NDS as, for example, predicting the onset of critical-\n",
      "ity (Eroglu et al. 2020) or neurological crises (Douw et al.\n",
      "2010); ascertaining whether a strain of virus persists or dies\n",
      "out in the long run (Lahmanovich and James 1976); or for\n",
      "the proper design of control or mitigation measures (Ren\n",
      "et al. 2019) in a pandemics.\n",
      "In all these applications, usually, only the time series data\n",
      "of some of the nodes are readily available while the underly-\n",
      "ing causal structure linking the nodes lurks underneath. The\n",
      "*Corresponding author.\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.main goal of causal inference or structure identification is to\n",
      "map out the underlying causal architecture of a complex sys-\n",
      "tem, i.e., to enable consistent inference of the latent network\n",
      "structure from the observed data.\n",
      "For the most part, causal inference is addressed in two\n",
      "phases: i) Estimation phase ‚Äî a scalar value is assigned\n",
      "to each pair of nodes as a proxy to the pair‚Äôs coupling\n",
      "strength or affinity (e.g., mutual information); ii) Classifica-\n",
      "tion phase ‚Äî a thresholding or hypothesis testing is applied\n",
      "to the estimated couplings to draw the network, consistently.\n",
      "Reference (Machado et al. 2023) departed from this ap-\n",
      "proach and addressed the framework of partial observability\n",
      "(with diagonal or uncorrelated noise), under a novel feature\n",
      "based paradigm. Instead of a scalar-based estimation for the\n",
      "pairs‚Äô affinity, a feature vector is assigned to each pair of\n",
      "nodes, and structure is recovered by leveraging certain iden-\n",
      "tifiability properties of the engineered features in a higher-\n",
      "dimensional space (instead of thresholding). Desirable char-\n",
      "acteristics of this feature-based approach include: i) Sepa-\n",
      "rability ‚Äîthere exists a manifold that separates the features\n",
      "of connected pairs from those of disconnected pairs; ii) Sta-\n",
      "bility ‚Äîthis separation manifold should not be too sensitive\n",
      "to differences in the regimes of connectivity, observability\n",
      "and noise correlation of the underlying complex system; and\n",
      "iii)Locality ‚Äîthe feature of each pair can be computed from\n",
      "the time series of each pair (or neighboring pairs thereof).\n",
      "Separability is a necessary property to consistently cluster\n",
      "the features, i.e., for structure inference; stability renders su-\n",
      "pervised ML tools (e.g., SVM) amenable to generalization;\n",
      "andlocality of the features is crucial for large-scale systems\n",
      "where only a subset of nodes can be feasibly observable.\n",
      "However, in most applications, the underlying excitation\n",
      "noise exhibits nontrivial correlation structure. Depending on\n",
      "the regime of observation or noise structure, information\n",
      "about the main object of inference may be fundamentally\n",
      "lost (Barbier et al. 2023). The level of\n",
      "----------------------------------------------------------------------------------------------------\n",
      "R2Human: Real-Time 3D Human Appearance Rendering from a Single Image\n",
      "Qiao Feng1,‚Ä†, Yuanwang Yang1,‚Ä†, Yu-Kun Lai2, Kun Li1,‚àó\n",
      "1Tianjin University, China2Cardiff University, United Kingdom\n",
      "(a) (b) (c) (d) (e) (f) (g) (h)\n",
      "Figure 1. Given a single RGB image, R2Human can generate photorealistic 3D human appearance in real-time. We utilize the input (a) to\n",
      "render close views (b) and zoomed in (c). The results of pitch angle changes are shown in (d-e), while (f-h) demonstrate the outcomes of\n",
      "divergent views.\n",
      "Abstract\n",
      "Reconstructing 3D human appearance from a single im-\n",
      "age is crucial for achieving holographic communication\n",
      "and immersive social experiences. However, this re-\n",
      "mains a challenge for existing methods, which typically rely\n",
      "on multi-camera setups or are limited to offline operations.\n",
      "In this paper, we propose R2Human, the first approach for\n",
      "real-time inference and rendering of photorealistic 3D hu-\n",
      "man appearance from a single image. The core of our ap-\n",
      "proach is to combine the strengths of implicit texture fields\n",
      "and explicit neural rendering with our novel representa-\n",
      "tion, namely Z-map. Based on this, we present an end-to-\n",
      "end network that performs high-fidelity color reconstruc-\n",
      "tion of visible areas and provides reliable color inference\n",
      "for occluded regions. To further enhance the 3D percep-\n",
      "tion ability of our network, we leverage the Fourier occu-\n",
      "pancy field to reconstruct a detailed 3D geometry, which\n",
      "serves as a prior for the texture field generation and pro-\n",
      "vides a sampling surface in the rendering stage. Experi-\n",
      "ments show that our end-to-end method achieves state-of-\n",
      "the-art performance on both synthetic data and challenging\n",
      "real-world images and even outperforms many offline meth-\n",
      "‚Ä†Equal contribution.\n",
      "* Corresponding author.ods. The project page is available for research purposes\n",
      "athttp://cic.tju.edu.cn/faculty/likun/\n",
      "projects/R2Human .\n",
      "1. Introduction\n",
      "The rapid evolution of digital technology has notably im-\n",
      "pacted computer graphics and computer vision, particularly\n",
      "in 3D human appearance reconstruction. This advancement\n",
      "not only enhances visual experiences but also paves the way\n",
      "for practical applications in AR/VR, enabling interactive\n",
      "platforms like holographic communication and immersive\n",
      "social experiences. However, existing methods heavily rely\n",
      "on multi-camera setups [15, 19, 20, 31] or are constrained\n",
      "to offline operations [1, 7, 16], leaving real-time 3D human\n",
      "rendering from a single image as an unresolved challenge.\n",
      "In this paper, we aim to render the photorealistic 3D human\n",
      "appearance in real-time from a single image, as shown in\n",
      "Fig. 1.\n",
      "Research in human novel view synthesis has explored\n",
      "various methodologies, which can be roughly classified into\n",
      "two categories. The first category of methods [2, 19, 31] is\n",
      "founded on flow-based neural rendering, which warps the\n",
      "feature map from the input images to the target view and\n",
      "then produces high-quality novel view results with convo-\n",
      "1arXiv:2312.05826v1  [cs.CV]  10 Dec 2023lutional neural networks (CNNs). However, the network‚Äôs\n",
      "predictions for occluded regions in the input image usually\n",
      "exhibit significant randomness due to the lack of 3D struc-\n",
      "ture understanding, making it challenging to obtain consis-\n",
      "tently accurate results. To deal with this, these methods re-\n",
      "quire multi-view input images to cover the rendering area\n",
      "as comprehensively as possible. Consequently, generating\n",
      "photorealistic renderings from only one image becomes dif-\n",
      "ficult for them.\n",
      "Another category of methods aims to recover a 3D con-\n",
      "sistent appearance for the human body. PIFu [16] recov-\n",
      "ers the 3D human geometry and appearance from a sin-\n",
      "gle human image using an occupancy field and a texture\n",
      "field, respectively. However, the rendered images are of low\n",
      "quality and the process is time-consuming. Its follow-up\n",
      "work [1] disentangles lighting from texture and redesigns\n",
      "the loss functions, resulting in improved visual quality. On\n",
      "the other hand, works utilizing the Neural Radiance Fields\n",
      "(NeRF) [7, 13, 15, 20] predict the density and radiance\n",
      "throughout the 3D space for rendering images by integrat-\n",
      "ing along camera rays. However, NeRF-based methods of-\n",
      "ten struggle with single-view inputs. While approaches\n",
      "above vary in human appearance representations, they share\n",
      "a common paradigm: they estimate geometry and color for\n",
      "discrete sampled points independently. This makes it dif-\n",
      "ficult for the models to discern relationships between the\n",
      "sampled points, resulting in relatively lower quality in the\n",
      "synthesized novel view images. Additionally, these meth-\n",
      "ods require dense spatial sampling, which results in high\n",
      "computational costs and makes it challenging to balance\n",
      "real-time performance with rendering quality.\n",
      "In this paper, we introduce R2Human , a real-time frame-\n",
      "work for rendering human appearance, which uniquely\n",
      "combines flow-based rendering techniques with an implicit\n",
      "3D human geometry representation to synthesize novel\n",
      "view images. Our method only requires a single i\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FM-G-CAM: A H OLISTIC APPROACH FOR EXPLAINABLE AIIN\n",
      "COMPUTER VISION\n",
      "Ravidu Suien Rammuni Silva1, Jordan J. Bird2\n",
      "Department of Computer Science\n",
      "Nottingham Trent University\n",
      "Nottingham, Nottinghamshire, United Kingdom\n",
      "1ravidu.rammunisilva2022@my.ntu.ac.uk,2jordan.bird@ntu.ac.uk\n",
      "ABSTRACT\n",
      "Explainability is an aspect of modern AI that is vital for impact and usability in the real world. The\n",
      "main objective of this paper is to emphasise the need to understand the predictions of Computer\n",
      "Vision models, specifically Convolutional Neural Network (CNN) based models. Existing methods\n",
      "of explaining CNN predictions are mostly based on Gradient-weighted Class Activation Maps (Grad-\n",
      "CAM) and solely focus on a single target class. We show that from the point of the target class\n",
      "selection, we make an assumption on the prediction process, hence neglecting a large portion of the\n",
      "predictor CNN model‚Äôs thinking process. In this paper, we present an exhaustive methodology called\n",
      "Fused Multi-class Gradient-weighted Class Activation Map (FM-G-CAM) that considers multiple top\n",
      "predicted classes, which provides a holistic explanation of the predictor CNN‚Äôs thinking rationale. We\n",
      "also provide a detailed and comprehensive mathematical and algorithmic description of our method.\n",
      "Furthermore, along with a concise comparison of existing methods, we compare FM-G-CAM with\n",
      "Grad-CAM, highlighting its benefits through real-world practical use cases. Finally, we present an\n",
      "open-source Python library with FM-G-CAM implementation to conveniently generate saliency maps\n",
      "for CNN-based model predictions.\n",
      "Keywords Explainable AI ¬∑Computer Vision ¬∑Image Classification\n",
      "1 Introduction\n",
      "Explainability is an aspect of Artificial Intelligence (AI) that is gaining prominence today. Explainable AI (XAI)\n",
      "enables humans to more comprehensively understand model predictions as opposed to black box approaches, which\n",
      "is of paramount importance for the use of such technologies in the real world[ 1,2,3]. Among many other fields,\n",
      "computer vision is a field that often benefits from XAI, in part due to its visual nature [ 4,5,2]. In the field of\n",
      "Computer Vision, both Convolutional Neural Networks (CNNs) and Transformer-based models are widely used for\n",
      "image classification[6, 7, 8]. It is worth noting that several transformer-based approaches use convolutional layers.\n",
      "Despite the strengths of CNNs, they are often considered a black-box approach [ 9], that is, their predictions are\n",
      "difficult to analyse and interpret. In critical situations where machine learning models are used in the real world, the\n",
      "process that leads to a certain decision may be just as important as the ability of the model itself. The Gradient Class\n",
      "Activation Mapping (Grad-CAM) approach[ 10] was proposed to visually display the convolutional processes in an\n",
      "easy-to-understand manner. The Grad-CAM algorithm generates a saliency map that explains the areas of a given image\n",
      "that are most important for a classification prediction.\n",
      "The Grad-CAM saliency map is based on the activations that the CNN model produces when making a prediction\n",
      "and the gradients of them with respect to them. Based on this foundational theory, more advanced studies have been\n",
      "published that introduce improved techniques, such as the use of the second derivative of the resulting activations with\n",
      "respect to the final prediction[ 11]. However, all of these studies only consider a single class when they produce their\n",
      "saliency maps. This is commonly the top predicted class. In this study, we argue that, except for binary classification,\n",
      "this does not represent the complete rationale of the model for making a given prediction; the class with the highestarXiv:2312.05975v1  [cs.CV]  10 Dec 2023A Holistic Approach for Explainable AI in Computer Vision Silva and Bird\n",
      "probability is shown, regardless of the context of other prediction values. This is mainly because it generates the\n",
      "saliency map on a class that may or may not even be the desired one. The saliency map is thus highly dependent on\n",
      "the model output with the highest probability. The difference in the top-1 and top-5 accuracy rates of models [ 6,12]\n",
      "trained on ImageNet [13] argues that even the most accurate models are not always able to predict the correct class as\n",
      "the top prediction. In this study, we present FM-G-CAM, an approach to generate saliency maps considering multiple\n",
      "predicted classes, providing a holistic visual explanation on the CNN predictions.\n",
      "Figure 1: FM-G-CAM for general image classification tasks against Grad-CAM\n",
      "In this paper, we propose a novel approach to produce a saliency map that could provide a unified approach to the\n",
      "visualisation of multiple class predictions; an example of the proposed approach can be observed in Figure 1. Our\n",
      "approach can be configured to consider any number of top classes to consider when generating the saliency map.\n",
      "The paper begins with a comparison of the existing methods to explain CNN predictions. Then, our new approach,\n",
      "FM-G-CAM an\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sparse Multitask Learning for Efficient Neural\n",
      "Representation of Motor Imagery and Execution\n",
      "Hye-Bin Shin\n",
      "Dept. of Brain and Cognitive Engineering\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "hbshin@korea.ac.krKang Yin\n",
      "Dept. of Artificial Intelligence\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "charles kang@korea.ac.krSeong-Whan Lee\n",
      "Dept. of Artificial Intelligence\n",
      "Korea University\n",
      "Seoul, Republic of Korea\n",
      "sw.lee@korea.ac.kr\n",
      "Abstract ‚ÄîIn the quest for efficient neural network models for\n",
      "neural data interpretation and user intent classification in brain-\n",
      "computer interfaces (BCIs), learning meaningful sparse represen-\n",
      "tations of the underlying neural subspaces is crucial. The present\n",
      "study introduces a sparse multitask learning framework for\n",
      "motor imagery (MI) and motor execution (ME) tasks, inspired by\n",
      "the natural partitioning of associated neural subspaces observed\n",
      "in the human brain. Given a dual-task CNN model for MI-ME\n",
      "classification, we apply a saliency-based sparsification approach\n",
      "to prune superfluous connections and reinforce those that show\n",
      "high importance in both tasks. Through our approach, we seek to\n",
      "elucidate the distinct and common neural ensembles associated\n",
      "with each task, employing principled sparsification techniques\n",
      "to eliminate redundant connections and boost the fidelity of\n",
      "neural signal decoding. Our results indicate that this tailored\n",
      "sparsity can mitigate the overfitting problem and improve the test\n",
      "performance with small amount of data, suggesting a viable path\n",
      "forward for computationally efficient and robust BCI systems.\n",
      "Keywords‚Äìbrain‚Äìcomputer interface, network pruning, sparse\n",
      "multitask learning;\n",
      "I. INTRODUCTION\n",
      "The neural processes underlying imagination, observation,\n",
      "and execution of movements share a profound and enigmatic\n",
      "connection. Neuroscientific studies have consistently demon-\n",
      "strated that these processes engage overlapping neural circuits,\n",
      "suggesting a shared neural subspace [1]‚Äì[3]. This revelation\n",
      "has significant implications for EEG-based brain-computer\n",
      "interfaces (BCIs) leveraging motor imagery (MI) and motor\n",
      "execution (ME) paradigms [4]‚Äì[6]. Despite the success of\n",
      "machine learning algorithms in uncovering meaningful and\n",
      "discriminative features from EEG data [7]‚Äì[9], deep learning\n",
      "has gained popularity in the EEG-BCI domain due to its ability\n",
      "to provide end-to-end learning solutions [10], [11]. However,\n",
      "state-of-the-art deep learning models trained offline on a fixed\n",
      "EEG dataset show severe overfitting due to the limited amount\n",
      "This work was supported by the Institute of Information & Communica-\n",
      "tions Technology Planning & Evaluation (IITP) grant, funded by the Ko-\n",
      "rea government (MSIT) (No. 2019-0-00079, Artificial Intelligence Graduate\n",
      "School Program (Korea University); No.2021-0-02068, Artificial Intelligence\n",
      "Innovation Hub) and the National Research Foundation of Korea (NRF)\n",
      "grant funded by the MSIT (No.2022-2-00975, MetaSkin: Developing Next-\n",
      "generation Neurohaptic Interface Techonology that enables Communication\n",
      "and Control in Metaverse by Skin Touch.of training samples, coupled with the high-dimensional nature\n",
      "of multi-channel EEG data [10].\n",
      "To enhance generalization in deep learning models for\n",
      "BCI, various strategies have been employed, from multi-\n",
      "domain learning, which leverages insights gained from mul-\n",
      "tiple subjects data, to multi-modal and multi-view learning\n",
      "approaches that integrate diverse physiological signals and\n",
      "feature representations, thereby enriching the model‚Äôs un-\n",
      "derstanding and representational power [12]‚Äì[16]. Multi-task\n",
      "learning, on the other hand, remains relatively underexplored\n",
      "in the EEG-BCI domain and and presents a unique opportunity\n",
      "to address the challenge of model generalization, especially\n",
      "given its recent success in other domains, e.g., training large\n",
      "language models [17]. In the context of motor-related BCI\n",
      "paradigms, a multitask setup is particularly pertinent as it\n",
      "can exploit the duality of task imagination and execution\n",
      "inherent in their design, e.g., motor imagery/execution [15]\n",
      "and imagined/overt speech [18], [19]. Given the neuroscientific\n",
      "evidence for shared neural substrates underlying these tasks,\n",
      "multitask learning can potentially uncover the commonalities\n",
      "and learn shared representation across these related tasks.\n",
      "In this study, we construct a multitask CNN model for MI\n",
      "and ME classification and apply sparse training technique to\n",
      "distill the network to its most informative parameters while\n",
      "pruning away those that are not helpful for either task [20]‚Äì\n",
      "[22]. This sparse multitask learning approach can mitigate\n",
      "model overfitting and improve generalization performance by\n",
      "learning shared representations across different tasks. The\n",
      "integration of different pruning and sparse training methods\n",
      "is largely unexplored in BCI, but it can potentially help to\n",
      "create efficient and compact models suitable for real-time\n",
      "applications [23]‚Äì[26]. Our contribution is twofold:\n",
      "‚Ä¢We demonstrate how multitask learning can be effectively\n",
      "appli\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A Representative Study on Human Detection\n",
      "of Artificially Generated Media Across Countries\n",
      "Joel Frank\n",
      "Ruhr-Universit√§t Bochum\n",
      "joel.frank@rub.deFranziska Herbert\n",
      "Ruhr-Universit√§t Bochum\n",
      "franziska.herbert@rub.deJonas Ricker\n",
      "Ruhr-Universit√§t Bochum\n",
      "jonas.ricker@rub.deLea Sch√∂nherr\n",
      "CISPA\n",
      "schoenherr@cispa.de\n",
      "Thorsten Eisenhofer\n",
      "TU Berlin\n",
      "thorsten.eisenhofer@tu-berlin.deAsja Fischer\n",
      "Ruhr-Universit√§t Bochum\n",
      "asja.fischer@rub.deMarkus D√ºrmuth\n",
      "Leibniz Universit√§t Hannover\n",
      "markus.duermuth@itsec.uni-hannover.deThorsten Holz\n",
      "CISPA\n",
      "holz@cispa.de\n",
      "Abstract ‚ÄîAI-generated media has become a threat to our digital\n",
      "society as we know it. Forgeries can be created automatically\n",
      "and on a large scale based on publicly available technologies.\n",
      "Recognizing this challenge, academics and practitioners have\n",
      "proposed a multitude of automatic detection strategies to detect\n",
      "such artificial media. However, in contrast to these technological\n",
      "advances, the human perception of generated media has not\n",
      "been thoroughly studied yet.\n",
      "In this paper, we aim to close this research gap. We\n",
      "conduct the first comprehensive survey on people‚Äôs ability\n",
      "to detect generated media, spanning three countries (USA,\n",
      "Germany, and China), with 3,002 participants covering audio,\n",
      "image, and text media. Our results indicate that state-of-the-\n",
      "art forgeries are almost indistinguishable from ‚Äúreal‚Äù media,\n",
      "with the majority of participants simply guessing when asked\n",
      "to rate them as human- or machine-generated. In addition,\n",
      "AI-generated media is rated as more likely to be human-\n",
      "generated across all media types and all countries. To further\n",
      "understand which factors influence people‚Äôs ability to detect AI-\n",
      "generated media, we include personal variables, chosen based\n",
      "on a literature review in the domains of deepfake and fake news\n",
      "research. In a regression analysis, we found that generalized\n",
      "trust, cognitive reflection, and self-reported familiarity with\n",
      "deepfakes significantly influence participants‚Äô decisions across\n",
      "all media categories.\n",
      "1. Introduction\n",
      "In his 2015 book, the historian Yuval Noah Harari\n",
      "wrote: ‚ÄúIn the past, censorship worked by blocking the flow\n",
      "of information. In the 21st century, censorship works by\n",
      "flooding people with irrelevant information.‚Äù [1]. While in the\n",
      "original context the quote referred to fake news , the content\n",
      "of the quote is more relevant than ever. Deep generative\n",
      "modeling has enabled the unbounded creation of fake media\n",
      "at scale. While it has been used for harmless endeavors\n",
      "like putting Jim Carrey into the movie Shining [2], there\n",
      "are also more destructive examples like phishing $243,000\n",
      "from a UK company by imitating their CEO‚Äôs voice [3] orinfluencing political events [4]‚Äì[7]. A prominent example\n",
      "being a fake video of Ukraine‚Äôs president Zelenskyy telling\n",
      "his forces to surrender [8]. These fakes have resulted in a\n",
      "flurry of techniques to automatically detect AI-generated\n",
      "media [9]‚Äì[22]. However, there is little research on how\n",
      "convincing AI-generated media is to human observers. Prior\n",
      "works [23]‚Äì[28] often only consider one type of media\n",
      "(usually images) and often rely on small sample sizes or\n",
      "convenience samples.\n",
      "In this work, we establish the first cross-country and\n",
      "cross-media baseline the detection of media generated with\n",
      "state-of-the-art methods. In our preregistered study, we\n",
      "examine three different countries (USA, Germany, and China)\n",
      "under three different conditions (audio, image, and text),\n",
      "with a total number of participation of n= 3,002. The\n",
      "primary goal of the surveys is to answer the following three\n",
      "research questions: i) Can people identify state-of-the-art\n",
      "generated media? ii) Which demographic factors influence\n",
      "the identification accuracy? iii) Which cognitive factors affect\n",
      "the identification accuracy?\n",
      "In our survey, participants are asked to rate a set of\n",
      "human- and machine-generated media on how believable\n",
      "they are. Most importantly, we find that most AI-generated\n",
      "samples are already so convincing that the majority of\n",
      "participants cannot accurately distinguish them from human-\n",
      "generated content. More specifically, the average detection\n",
      "accuracy of participants is below 50% for images and never\n",
      "exceeds 60% for the other media types. Moreover, we\n",
      "find that participants in all countries believed that most\n",
      "of the samples we showed to them were human-generated,\n",
      "compared to the 50/50ground truth.\n",
      "To evaluate which variables might improve or worsen\n",
      "people‚Äôs ability to detect AI-generated media, we performed\n",
      "a literature review of prior work in the domains of deepfake\n",
      "and fake news research. This review enabled us to identify\n",
      "multiple personal variables that might influence the decision\n",
      "of participants, such as cognitive reasoning [29], media\n",
      "literacy [24] or political orientation [30]. We included these\n",
      "variables in our survey. In a regression analysis, we found\n",
      "that generalized trust, motivated System 2 reasoning, and self-arXiv:2312.05976v1  [cs.CR]  10 Dec 2023reported familiarity with deepfakes significantly influenced\n",
      "peo\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "EM Based p-norm-like Constraint RLS\n",
      "Algorithm for Sparse System Identification\n",
      "Shuyang Jiang and Kung Yao, Life Fellow, IEEE\n",
      "Abstract\n",
      "In this paper, the recursive least squares (RLS) algorithm is considered in the sparse system identifi-\n",
      "cation setting. The cost function of RLS algorithm is regularized by a p-norm-like ( 0‚â§p‚â§1) constraint\n",
      "of the estimated system parameters. In order to minimize the regularized cost function, we transform it\n",
      "into a penalized maximum likelihood (ML) problem, which is solved by the expectation-maximization\n",
      "(EM) algorithm. With the introduction of a thresholding operator, the update equation of the tap-weight\n",
      "vector is derived. We also exploit the underlying sparsity to implement the proposed algorithm in a\n",
      "low computational complexity fashion. Numerical simulations demonstrate the superiority of the new\n",
      "algorithm over conventional sparse RLS algorithms, as well as regular RLS algorithm.\n",
      "Index Terms\n",
      "Adaptive filters, expectation-maximization algorithm, p-norm-like constraint, recursive least squares,\n",
      "sparsity.\n",
      "I. I NTRODUCTION\n",
      "Adaptive filtering algorithms, such as least mean squares (LMS) and recursive least squares (RLS)\n",
      "algorithms [1], are widely used in estimation problems where data arrive sequentially. In communication,\n",
      "a wide range of signals of interest is sparse in a certain representation. For example, the multipath wireless\n",
      "channel contains only a few large coefficients among many negligible ones [2]. However, neither LMS\n",
      "nor RLS exploits the underlying sparseness in order to improve the quality of estimation.\n",
      "Recently, many LMS-based new algorithms [5]-[11] have been proposed for sparse sytem identi-\n",
      "fication. These adaptive algorithms utilize the results from the least absolute shrinkage and selection\n",
      "operator (LASSO) [3] and compressive sensing literature [4], and incorporate the sparsity-promoting\n",
      "norm regularization into the cost function. The first of this kind of algorithms was given in [5]. The\n",
      "‚Ñìp(0< p‚â§1) norm of the weight vector is employed as the regularization penalty. Subsequently, ‚Ñì1\n",
      "The authors are with the Department of Electrical and Computer Engineering, University of California at Los Angeles, Los\n",
      "Angeles, CA 90095 USA (E-mail: shuyangjiang@ucla.edu;yao@ee.ucla.edu).\n",
      "December 12, 2023 DRAFTarXiv:2312.05829v1  [cs.IT]  10 Dec 20232\n",
      "norm [6], reweighted ‚Ñì1norm [7], ‚Ñì0norm [8], p-norm-like [9], ‚Ñìp-norm [10, 11] are also utilized to\n",
      "obtain a series of norm constraint LMS algorithms, which constitute an important family of sparse LMS\n",
      "algorithms during the last few years. All of these algorithms have increased convergence speed and\n",
      "decreased steady-state mean square error (MSE) compared with traditional LMS algorithm.\n",
      "RLS based adaptive algorithms are another important class of adaptive algorithms. Hence, some RLS-\n",
      "based sparse algorithms have been proposed. Angelosante et al. [12] propose time-weighted and time-and-\n",
      "norm-weighted LASSO approaches for recursive estimation of sparse signals. Then an online coordinate\n",
      "descent algorithm is used to obtain the solution of the ‚Ñì1-norm penalized least-squares cost function.\n",
      "Eksioglu uses a reweighted ‚Ñì1norm and a sparsity-related convex function as the regularization term\n",
      "of RLS algorithm in [13] and [14], respectively. By using the results from subgradient calculus, the\n",
      "ensuing algorithms ‚Ñì1-WRLS and convex regularized-RLS (CR-RLS) are derived, which have a form\n",
      "similar to conventional RLS. In [15], a recursive ‚Ñì1-regularized least squares (SPARLS) algorithm is\n",
      "introduced, which is based on an expectation-maximization (EM) type algorithm presented in [16]. Also\n",
      "based on EM algorithm, [17] addresses the problem of in-network distributed estimation of sparse system\n",
      "by using ‚Ñì1and‚Ñì0norm, and derive several distributed sparse RLS algorithms. In [18], a family of low-\n",
      "complexity RLS adaptive filters with different penalties is proposed based on dichotomous coordinate\n",
      "descent (DCD) iterations. Two zero-attracting RLS algorithms [19], ZA-RLS-I and ZA-RLS-II, are derived\n",
      "by employing an adaptively weighted ‚Ñì2-norm constraint of the parameter vector to the cost function of\n",
      "conventional RLS. Compared with LMS-based sparse algorithms, RLS-based sparse algorithms have a\n",
      "faster convergence speed and more accurate system estimates.\n",
      "In this paper, inspired by the research work on norm constraint LMS and the fact that p-norm-like with\n",
      "0‚â§p‚â§1provides an effective mathematical measure of sparsity [4], we add a p-norm-like constraint\n",
      "to the cost function of classic RLS algorithm. Then in a manner alike to the approach in SPARLS [15],\n",
      "we adopt a maximum likelihood (ML) framework and use the EM algorithm to get the update equation\n",
      "of estimated system parameters. The new algorithm is called EM- lp-like-RLS algorithm. Moreover, with\n",
      "slight modification, the proposed algorithm can operate with low computational requirement. From the\n",
      "numerical simulations, we see that the proposed algorithm exhibits better estimation performance than\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FERMILAB-CONF-23-0813-CSAID-PPD 1\n",
      "Neural Architecture Codesign for Fast Bragg Peak Analysis\n",
      "Luke McDermott1, Jason Weitz1, Dmitri Demler1,\n",
      "Daniel Cummings2, Nhan Tran3,4, Javier Duarte1\n",
      "1University of California, San Diego,2Intel Labs,\n",
      "3Fermi National Accelerator Laboratory,4Northwestern University\n",
      "lmcdermo@ucsd.edu, jdweitz@ucsd.edu, ddemler@ucsd.edu,\n",
      "daniel.j.cummings@intel.com, ntan@fnal.gov, jduarte@ucsd.edu\n",
      "Abstract\n",
      "We develop an automated pipeline to streamline neural ar-\n",
      "chitecture codesign for fast, real-time Bragg peak analysis in\n",
      "high-energy diffraction microscopy. Traditional approaches,\n",
      "notably pseudo-V oigt fitting, demand significant computa-\n",
      "tional resources, prompting interest in deep learning mod-\n",
      "els for more efficient solutions. Our method employs neu-\n",
      "ral architecture search and AutoML to enhance these models,\n",
      "including hardware costs, leading to the discovery of more\n",
      "hardware-efficient neural architectures. Our results match the\n",
      "performance, while achieving a 13 √óreduction in bit opera-\n",
      "tions compared to the previous state-of-the-art. We show fur-\n",
      "ther speedup through model compression techniques such as\n",
      "quantization-aware-training and neural network pruning. Ad-\n",
      "ditionally, our hierarchical search space provides greater flex-\n",
      "ibility in optimization, which can easily extend to other tasks\n",
      "and domains.\n",
      "Introduction\n",
      "With the rapid advance of machine learning tools, material\n",
      "science researchers have significantly enhanced their exper-\n",
      "imental methodologies and analysis. Particularly, locating\n",
      "diffraction peak positions for X-ray diffraction-based mi-\n",
      "croscopy proposes an interesting challenge. Common meth-\n",
      "ods require large inference costs, thus sparking work in\n",
      "building lightweight deep learning models as approxima-\n",
      "tors. Liu et al. (2022) laid the foundation for this work,\n",
      "training a transformer-like CNN on pseudo-V oigt fitting pre-\n",
      "dictions (Bhakar, Taxak, and Rai 2023), using a diffrac-\n",
      "tion scan from an undeformed bi-crystal gold sample (Shade\n",
      "et al. 2016). This work has extensively been used, combined\n",
      "with Liu et al. (2021), to integrate BraggNN with remote\n",
      "data centers for faster model retraining and deployment,\n",
      "enhancing real-time data analysis. Furthermore, Levental\n",
      "et al. (2023) heavily optimized how the model is compiled\n",
      "and deployed in hardware, providing a significant speed up\n",
      "in their framework. OpenHLS compiles BraggNN into a\n",
      "low-latency, register-transfer level format, which increases\n",
      "model throughput. While these methods lay the foundation\n",
      "for hardware optimization in high-energy diffraction mi-\n",
      "croscopy (Park et al. 2017), there is considerable room for\n",
      "improvement in the design of the neural architecture.\n",
      "Copyright ¬© 2024, Association for the Advancement of Artificial\n",
      "Intelligence (www.aaai.org). All rights reserved.Our pipeline incorporates neural architecture search\n",
      "(NAS) (Elsken, Metzen, and Hutter 2019), hyperparame-\n",
      "ter optimization (HPO), and model compression techniques,\n",
      "including pruning (Blalock et al. 2020) and quantization-\n",
      "aware training (Weng 2021). Deep learning models are op-\n",
      "timized over a hierarchical search space, selecting high-\n",
      "performing lightweight models with evolutionary strate-\n",
      "gies. This automated pipeline streamlines neural architec-\n",
      "ture codesign (NAC) from model to hardware optimization.\n",
      "We demonstrate state-of-the-art performance for psuedo-\n",
      "V oigt fitting estimation over previous work, while requiring\n",
      "13√óless bit operations (BOPs) (Baskin et al. 2021) than Liu\n",
      "et al. (2022) for inference.\n",
      "Our methodology employs a modular approach, based on\n",
      "open-source packages, allowing for flexible and dynamic\n",
      "construction. This adaptability facilitates the integration or\n",
      "alteration of network components, allowing for bespoke\n",
      "search spaces on new tasks. We believe in democratizing\n",
      "edge AI for ML practitioners in science domains, especially\n",
      "on specialized hardware such as field-programmable gate ar-\n",
      "rays (FPGAs). To carry out this mission, our open-source\n",
      "pipeline will be released in the camera-ready version.\n",
      "Related Work\n",
      "Neural Architecture Search Background. NAS aims to\n",
      "optimize the structure of neural networks for specific tasks\n",
      "and objectives. This includes searching over network sizes\n",
      "or even constructing completely different model classes.\n",
      "There are three critical components: search space, search\n",
      "strategy, and architecture evaluation . The search space de-\n",
      "termines the potential architectures that can be sampled (Ren\n",
      "et al. 2021). While a narrow search space can be heavily\n",
      "biased, a large one is extremely difficult to properly ex-\n",
      "plore, necessitating a delicate balance. This space is ex-\n",
      "plored by sampling architectures and evaluating them across\n",
      "our objectives. Instead of evaluating high-cost objectives,\n",
      "such as network performance, researchers often use a proxy\n",
      "for such objectives like partial training or even zero-cost\n",
      "methods (Abdelfattah et al. 2021). After validating, the\n",
      "search strategy will update its beliefs and sample again.\n",
      "Various stra\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "A Decoupled Spatio-Temporal Framework for\n",
      "Skeleton-based Action Segmentation\n",
      "Yun-Heng Li, Zhong-Yu Li, Shanghua Gao, Qilong Wang, Qibin Hou, Member, IEEE ,\n",
      "Ming-Ming Cheng, Senior Member, IEEE\n",
      "Abstract ‚ÄîEffectively modeling discriminative spatio-temporal information is essential for segmenting activities in long action se-\n",
      "quences. However, we observe that existing methods are limited in weak spatio-temporal modeling capability due to two forms of\n",
      "decoupled modeling: (i) cascaded interaction couples spatial and temporal modeling, which over-smooths motion modeling over the\n",
      "long sequence, and (ii) joint-shared temporal modeling adopts shared weights to model each joint, ignoring the distinct motion patterns\n",
      "of different joints. In this paper, we present a Decoupled Spatio- Temporal Framework ( DeST ) to address the above issues. Firstly, we\n",
      "decouple the cascaded spatio-temporal interaction to avoid stacking multiple spatio-temporal blocks, while achieving sufficient spatio-\n",
      "temporal interaction. Specifically, DeST performs once unified spatial modeling and divides the spatial features into different groups of\n",
      "sub-features, which then adaptively interact with temporal features from different layers. Since the different sub-features contain distinct\n",
      "spatial semantics, the model could learn better interaction patterns at each layer. Meanwhile, inspired by the fact that different joints\n",
      "move at different speeds, we propose joint-decoupled temporal modeling, which employs independent trainable weights to capture\n",
      "distinctive temporal features of each joint. On four large-scale benchmarks of different scenes, DeST significantly outperforms current\n",
      "state-of-the-art methods with less computational complexity.\n",
      "Index Terms ‚ÄîSkeleton-based action segmentation, decoupled spatio-temporal interaction, joint-decoupled temporal modeling\n",
      "‚ú¶\n",
      "1 I NTRODUCTION\n",
      "TEMPORAL action segmentation (TAS), which aims at clas-\n",
      "sifying each video frame, is critical for various practical\n",
      "applications, such as surveillance [1], [2], assisted rehabilita-\n",
      "tion [3], [4], interactive robotics [5], [6] and virtual reality [7], [8].\n",
      "Current works on action segmentation can be divided into RGB\n",
      "video-based methods and skeleton-based methods. RGB video-\n",
      "based approaches adopt two stages to model spatial and temporal\n",
      "information, respectively, where high computational costs are\n",
      "required to capture the pixel-level appearance information. In\n",
      "contrast, skeleton-based action segmentation utilizes one stage for\n",
      "unified spatial and temporal modeling and is more efficient as the\n",
      "skeleton acquired by motion capture systems already represents\n",
      "motion information. Moreover, skeleton data is more robust to\n",
      "appearance variation and environmental noises, e.g., scene and\n",
      "illumination changes [9], [10], [11]. Based on the skeleton data,\n",
      "previous works [12], [13], [14], [15], [16], [17], [18], [19] have\n",
      "achieved great progress in identifying short action clips.\n",
      "Despite the remarkable progress, segmenting all actions in a\n",
      "long skeleton sequence is still extremely challenging. Existing\n",
      "temporal action segmentation methods [20], [21], [22], [23] gen-\n",
      "erally employ spatial and temporal graph convolution networks\n",
      "(GCNs) to model the spatial and temporal dependencies among\n",
      "joints and perform spatio-temporal interaction to extract motion\n",
      "features, as illustrated in Fig. 1(a). However, we observe that these\n",
      "GCNs-based approaches are limited to weak spatio-temporal\n",
      "‚Ä¢Y.-H. Li, Z.-Y. Li, S. Gao, Q. Hou, and M.-M. Cheng are with VCIP , School\n",
      "of Computer Science, Nankai University, Tianjin 300350, China. E-\n",
      "mail:({yunhengli; lizhongyu }@mail.nankai.edu.cn) (Corresponding au-\n",
      "thor: Q. Hou)\n",
      "‚Ä¢Q. Wang is with the College of Intelligence and Computing, Tianjin\n",
      "University, Tianjin 300350, China.\n",
      "‚Ä¢This work was supported in part by the Supercomputing Center of Nankai\n",
      "University.\n",
      "‚Ä¢Our code is available at: https://github.com/lyhisme/DeST.\n",
      "......Skeleton Data\n",
      "Cascaded\n",
      "InteractionSpatial\n",
      "Temporal\n",
      "Spatial\n",
      "Temporal\n",
      "Temporal\n",
      "(a) Existing MethodsSkeleton Data\n",
      "Unified Spatial\n",
      "Temporal\n",
      "Decoupled\n",
      "Interaction\n",
      "Temporal\n",
      "Decoupled\n",
      "Interaction\n",
      "(b) DeST (Ours)\n",
      "Fig. 1. Comparison of existing and our proposed methods for spatio-\n",
      "temporal modeling in the skeleton-based action segmentation. (a)\n",
      "Existing methods employ coupled spatial and temporal modeling for\n",
      "cascaded interaction. (b) In contrast, the proposed DeST decouples\n",
      "the cascaded spatial-temporal interaction by adopting unified spatial\n",
      "modeling to extract different groups of spatial sub-features, which adap-\n",
      "tively interact with temporal features from different layers, respectively.\n",
      "modeling capability for long skeleton sequences due to two\n",
      "forms of coupled modeling, i.e.,(i) cascaded interaction pattern\n",
      "and (ii) joint-shared temporal modeling. Specifically, identifying\n",
      "complex actions needs to extract discriminative spatio-temporal\n",
      "representations by interacting with spatial and temporal informa-\n",
      "tion of joints. Nevertheless, to perform multiple spa\n",
      "----------------------------------------------------------------------------------------------------\n",
      "NovaCOMET: Open Commonsense Foundation Models with Symbolic\n",
      "Knowledge Distillation\n",
      "Peter West‚Ä†‚Ä°Ronan Le Bras‚Ä°Taylor Sorensen‚Ä†‚Ä°\n",
      "Bill Yuchen Lin‚Ä°Liwei Jiang‚Ä†‚Ä°Ximing Lu‚Ä†‚Ä°Khyathi Chandu‚Ä°\n",
      "Jack Hessel‚Ä°Ashutosh Baheti‚Ä°Chandra Bhagavatula‚Ä°Yejin Choi‚Ä†‚Ä°\n",
      "‚Ä†Paul G. Allen School of Computer Science & Engineering, University of Washington\n",
      "‚Ä°Allen Institute for Artificial Intelligence\n",
      "pawest@cs.washington.edu\n",
      "Abstract\n",
      "We present NOVACOMET , an open common-\n",
      "sense knowledge model, that combines the\n",
      "best aspects of knowledge models and general\n",
      "task models. Compared to previous knowledge\n",
      "models, NOVACOMET allows open-format re-\n",
      "lations enabling direct application to reason-\n",
      "ing tasks; compared to general task models\n",
      "like Flan-T5, NOVACOMET explicitly centers\n",
      "knowledge, enabling superior performance for\n",
      "commonsense reasoning.\n",
      "NOVACOMET leverages the knowledge of\n",
      "opaque proprietary models to create an open\n",
      "knowledge pipeline. First, knowledge is sym-\n",
      "bolically distilled into NOVATOMIC , a publicly-\n",
      "released1discrete knowledge graph which can\n",
      "be audited, critiqued, and filtered. Next, we\n",
      "train NOVACOMET onNOVATOMIC by fine-\n",
      "tuning an open-source pretrained model. NO-\n",
      "VACOMET uses an open-format training ob-\n",
      "jective, replacing the fixed relation sets of past\n",
      "knowledge models, enabling arbitrary struc-\n",
      "tures within the data to serve as inputs or out-\n",
      "puts.\n",
      "The resulting generation model, optionally aug-\n",
      "mented with human annotation, matches or ex-\n",
      "ceeds comparable open task models like Flan-\n",
      "T5 on a range of commonsense generation\n",
      "tasks. NOVACOMET serves as a counterex-\n",
      "ample to the contemporary focus on instruction\n",
      "tuning only, demonstrating a distinct advantage\n",
      "to explicitly modeling commonsense knowl-\n",
      "edge as well.\n",
      "1 Introduction\n",
      "We present NOVACOMET , an open commonsense\n",
      "knowledge model combining the advantages of\n",
      "both knowledge models and general task models.\n",
      "NOVACOMET models commonsense knowledge\n",
      "with an open format, allowing it to be applied\n",
      "to general reasoning tasks in contrast to previous\n",
      "knowledge models. Compared to simply training\n",
      "1Our resources are available at novacomet.dev\n",
      "NovaCOMET\n",
      "NovATOMICClosed LLM\n",
      "Going to School [MASK] [MASK]What should you bring? Lunch, textbooks, stationary[MASK] Who is there besides Eliza? Parents, refereesEliza is playing in a school soccer game\n",
      "Caption: Knowledge is distilled from strong LLMs such as gpt-3 turbo, which allows auditable transfer of knowledge that prevents issues like data contamination (CITE) that may plague opaque proprietary models. The Ô¨Ånal trained model learns to Ô¨Åll in any part of the knowledge ‚Äî beyond simply answering a query[orange], NovaCOMET can e.g. predict what context[green] would make a query[orange] + inference[purple] likely. \n",
      "Open Data\n",
      "Open Model\n",
      "Open Format\n",
      "Figure 1: We leverage opaque-but-powerful proprietary\n",
      "LLMs into an open commonsense pipeline by: (i) creat-\n",
      "ing an auditable knowledge base NOVATOMIC that gives\n",
      "fine-grained control over included knowledge, (ii) en-\n",
      "suring the generated knowledge uses a higher-coverage\n",
      "open-format with natural-language queries as relations\n",
      "and flexible mask-filling to allow for more open com-\n",
      "monsense use-cases, (iii) demonstrating the effective-\n",
      "ness of (i) and (ii) via NOVACOMET ‚Äôs superior perfor-\n",
      "mance on a number of tasks, under both automatic and\n",
      "human evaluations.\n",
      "models to be open task solvers (e.g. instruction tun-\n",
      "ing) we find that explicitly modeling knowledge in\n",
      "NOVACOMET also provides a distinct advantage,\n",
      "with NOVACOMET showing similar or superior\n",
      "performance to comparable open task models on a\n",
      "range of commonsense reasoning benchmarks.\n",
      "ForNOVACOMET , we leverage opaque, pro-\n",
      "prietary models like ChatGPT or GPT-4 (Ouyang\n",
      "et al., 2022; OpenAI, 2023) as the knowledge\n",
      "source in an open commonsense pipeline (Figure 1).\n",
      "Such models have demonstrated remarkable com-\n",
      "monsense ability (Bubeck et al., 2023; Bian et al.,\n",
      "2023) yet, closed and opaque, their direct useful-\n",
      "ness for studying commonsense is limited. Without\n",
      "information about training or direct access to the\n",
      "model, it is impossible to study where reported\n",
      "gains come from‚Äîe.g. the extent of test set con-\n",
      "tamination with benchmarks.\n",
      "In our work, we use these models first to gener-arXiv:2312.05979v1  [cs.CL]  10 Dec 2023ate an open knowledge base ( NOVATOMIC , ¬ß2.1),\n",
      "which can be analyzed, improved, and verified\n",
      "against test set contamination. Next, we train an\n",
      "open commonsense model ( NOVACOMET , ¬ß2.3)\n",
      "on this knowledge: the underlying data and code\n",
      "will be released along with the model for the study\n",
      "of commonsense. This allows future testing of\n",
      "NOVACOMET (and of other models based on NO-\n",
      "VATOMIC ) to analyze the training set‚Äîessentially\n",
      "allowing us to distill information from a base LLM\n",
      "into an auditable format.\n",
      "In training NOVACOMET , we also use an open\n",
      "format: compared to previous knowledge models\n",
      "which use a fixed relation set and training order\n",
      "(head + relation ‚Üítail) we use natural language\n",
      "queries as relations, and allow masked generation\n",
      "of all as\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PHYSICS -AWARE MULTIFIDELITY BAYESIAN OPTIMIZATION :A\n",
      "GENERALIZED FORMULATION\n",
      "Francesco Di Fiore\n",
      "Politecnico di Torino\n",
      "francesco.difiore@polito.itLaura Mainini\n",
      "Imperial College London\n",
      "Politecnico di Torino\n",
      "Massachusetts Institute of Technology\n",
      "l.mainini@imperial.ac.uk\n",
      "ABSTRACT\n",
      "The adoption of high-fidelity models for many-query optimization problems is majorly limited by the\n",
      "significant computational cost required for their evaluation at every query. Multifidelity Bayesian\n",
      "methods (MFBO) allow to include costly high-fidelity responses for a sub-selection of queries only,\n",
      "and use fast lower-fidelity models to accelerate the optimization process. State-of-the-art methods rely\n",
      "on a purely data-driven search and do not include explicit information about the physical context. This\n",
      "paper acknowledges that prior knowledge about the physical domains of engineering problems can be\n",
      "leveraged to accelerate these data-driven searches, and proposes a generalized formulation for MFBO\n",
      "to embed a form of domain awareness during the optimization procedure. In particular, we formalize\n",
      "a bias as a multifidelity acquisition function that captures the physical structure of the domain. This\n",
      "permits to partially alleviate the data-driven search from learning the domain properties on-the-fly,\n",
      "and sensitively enhances the management of multiple sources of information. The method allows to\n",
      "efficiently include high-fidelity simulations to guide the optimization search while containing the\n",
      "overall computational expense. Our physics-aware multifidelity Bayesian optimization is presented\n",
      "and illustrated for two classes of optimization problems frequently met in science and engineering,\n",
      "namely design optimization and health monitoring problems.\n",
      "1 Introduction\n",
      "Optimization problems are ubiquitous in science and engineering applications [ 1]. Those also include the support to\n",
      "engineering tasks that are in increasing demand to meet sustainability goals such as the identification of the best design\n",
      "configurations to maximize the performance and minimize the environmental impact of novel engineering solutions, and\n",
      "the detection and identification of damages or faults to monitor the health condition of complex systems to maximize\n",
      "their useful life and minimize waste of resources.\n",
      "Over the last decades, the increase of computing power and the advances in computational modelling capabilities made\n",
      "available computer-based models for the accurate analysis and simulation of complex physical systems. This is the case\n",
      "of computational schemes for the numerical solution of governing partial differential equations as computational fluid\n",
      "dynamic solvers to represent viscous fluids, and finite element methods for the analysis of mechanical structures, heath\n",
      "transfer and electromagnetic phenomena. In principle, this computer-based representations can provide a remarkable\n",
      "contribution to enhance the search and identification task in simulation-based optimization. Unfortunately, the extensive\n",
      "adoption of these high-fidelity models during the optimization procedure is hampered by the significant computational\n",
      "cost and time required for their evaluation, potentially in the order of months for a single evaluation on high performance\n",
      "computing platforms. This issue becomes more challenging for many-query optimization problems where the demand\n",
      "for model evaluations grows exponentially with the number of parameters to optimize.\n",
      "The use of low-fidelity models constitutes a popular approach to reduce the computational resources associated with\n",
      "the solution of optimization problems. Low-fidelity representations introduce assumptions about the physics and/or\n",
      "approximate the solution of the governing equations, and relief the computational expenditure for the evaluation of\n",
      "the response of the system. On one hand, the use of low-fidelity models allows to efficiently acquire and exploit aarXiv:2312.05831v1  [cs.LG]  10 Dec 2023massive amount of information; on the other hand, their adoption results in a reduction of the overall time required for\n",
      "optimization. However, the main drawback of this strategy is enclosed in the simplified modeling approach which might\n",
      "not be adequate to capture complex physical phenomena that characterize many advanced technological applications,\n",
      "providing inaccurate responses that potentially lead to the suboptimal identification of solutions.\n",
      "Multifidelity methods offer the opportunity to efficiently include high-fidelity models during the optimization procedure,\n",
      "combining information elicited from a library of models hierarchically ordered accordingly to the accuracy of the\n",
      "response and associated expense of the computations [ 2,3,4,5]. These methodologies use fast low-fidelity models\n",
      "to speedup the search procedure, and refine the solution identified through of a principled selection of high-fidelity\n",
      "information. The goal is to accelerate the identification of optimal solutions while managing a trade-off between\n",
      "accuracy and computational \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Accurate Differential Operators for Hybrid\n",
      "Neural Fields\n",
      "Aditya Chetan, Guandao Yang, Zichen Wang,\n",
      "Steve Marschner, and Bharath Hariharan\n",
      "Cornell Univeristy\n",
      "achetan@cs.cornell.edu, {gy46, zw336}@cornell.edu,\n",
      "{srm, bharathh}@cs.cornell.edu\n",
      "https://justachetan.github.io/hnf-derivatives/\n",
      "Abstract. Neural fields have become widely used in various fields, from\n",
      "shape representation to neural rendering, and for solving partial differen-\n",
      "tial equations (PDEs). With the advent of hybrid neural field representa-\n",
      "tions like Instant NGP that leverage small MLPs and explicit represen-\n",
      "tations, these models train quickly and can fit large scenes. Yet in many\n",
      "applications like rendering and simulation, hybrid neural fields can cause\n",
      "noticeable and unreasonable artifacts. This is because they do not yield\n",
      "accurate spatial derivatives needed for these downstream applications.\n",
      "In this work, we propose two ways to circumvent these challenges. Our\n",
      "first approach is a post hoc operator that uses local polynomial-fitting to\n",
      "obtain more accurate derivatives from pre-trained hybrid neural fields.\n",
      "Additionally, we also propose a self-supervised fine-tuning approach that\n",
      "refines the neural field to yield accurate derivatives directly while pre-\n",
      "serving the initial signal. We show the application of our method on\n",
      "rendering, collision simulation, and solving PDEs. We observe that us-\n",
      "ing our approach yields more accurate derivatives, reducing artifacts and\n",
      "leading to more accurate simulations in downstream applications.\n",
      "Keywords: Hybrid Neural Fields, Polynomial-fitting\n",
      "1 Introduction\n",
      "Neural fields are neural networks that take spatial coordinates as input and\n",
      "approximate spatial functions such as images [35], signed distance fields [29], and\n",
      "radiance fields [23]. With the recent development of hybridneural fields, which\n",
      "modulate the neural network using features from a feature grid, these neural\n",
      "fields can now be trained quickly [26,32,6] and can approximate large-scale 3D\n",
      "structures such as entire cities [42,38,31,37].\n",
      "At first glance, these hybrid neural fields accurately represent large, complex\n",
      "spatial signals. However, a closer look reveals several artifacts in the derivatives\n",
      "oftherepresentedsignal(computedwithautomaticdifferentiation,asisstandard\n",
      "practice). For example, Figure 1 shows the erroneous derivatives obtained from\n",
      "a grid-based neural field trained to represent the signed distance field (SDF)arXiv:2312.05984v1  [cs.CV]  10 Dec 20232 Chetan et al.\n",
      "Fig.1:Noisy gradients in hybrid neural fields . Normal maps of Blub the\n",
      "fish[36] (inset), using gradients queried from its hybrid neural SDF using au-\n",
      "tomatic differentiation (AD) and our approach. Naively using AD gradients as\n",
      "surface normals leads to noisy artifacts, that are alleviated by our method.\n",
      "of a 3D shape. These errors cause significant artifacts when the neural fields\n",
      "are used in established rendering [37] or simulation pipelines [7] which heavily\n",
      "rely on accurate derivatives. If hybrid neural fields are to succeed as a general\n",
      "representation for spatial signals in a variety of applications, we need to address\n",
      "and mitigate such artifacts.\n",
      "What causes these artifacts in the derivative? The key problem is that neural\n",
      "fields are trained to approximate the signalitself ‚Äì there is no guarantee on the\n",
      "quality of approximation of the signal derivatives. Furthermore, since the hy-\n",
      "brid neural fields are usually designed and trained to reproduce high-frequency\n",
      "details, they have high-frequency components and are thus liable to have high-\n",
      "frequency noise (albeit of low magnitude). Taking derivatives directly will am-\n",
      "plify these high-frequency signals resulting in significant noise (Section 3.1). To\n",
      "obtain a better differential operator, we need to remove this high-frequency noise\n",
      "before computing the derivative.\n",
      "In this paper, we propose a new approach to compute accurate derivatives on\n",
      "pre-trained hybrid neural fields. Our approach takes inspiration from classical\n",
      "signal processing where derivative computation is typically done on a smoothed\n",
      "version of the signal to avoid amplifying high-frequency noise. Our key idea is\n",
      "to replace direct derivatives of the neural field with derivatives of a locallow-\n",
      "degree polynomial approximation:‚àÇ\n",
      "‚àÇxFŒò(x)‚âà‚àÇ\n",
      "‚àÇxPd\n",
      "i=0aixi,where parameters\n",
      "aiareobtainedbyleast-squareoptimizationofasetoflabelsrandomlygenerated\n",
      "from a neighborhood N(x). These low-order polynomials are easy to optimize\n",
      "efficiently and effectively remove high-frequency noise.\n",
      "While this approach yields accurate derivatives for off-the-shelf neural fields,\n",
      "it requires that downstream pipelines be changed to use our new derivative op-\n",
      "erator. To avoid altering downstream pipelines, we need an alternative approach\n",
      "that updates the neural field itself to remove the error in autodiff derivatives. We\n",
      "address this need with a second approach that fine-tunes the pre-trained neural\n",
      "field in a self-supervised manner, using the accurate derivatives from the firstAccurate Differential O\n",
      "----------------------------------------------------------------------------------------------------\n",
      "IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS\n",
      "Spatial-wise Dynamic Distillation for MLP-like\n",
      "Efficient Visual Fault Detection of Freight Trains\n",
      "Y ang Zhang, Huilin Pan, Mingying Li, An Wang, Y ang Zhou, and Hongliang Ren\n",
      "Abstract ‚ÄîDespite the successful application of convo-\n",
      "lutional neural networks (CNNs) in object detection tasks,\n",
      "their efficiency in detecting faults from freight train im-\n",
      "ages remains inadequate for implementation in real-world\n",
      "engineering scenarios. Existing modeling shortcomings\n",
      "of spatial invariance and pooling layers in conventional\n",
      "CNNs often ignore the neglect of crucial global information,\n",
      "resulting in error localization for fault objection tasks of\n",
      "freight trains. To solve these problems, we design a spatial-\n",
      "wise dynamic distillation framework based on multi-layer\n",
      "perceptron (MLP) for visual fault detection of freight trains.\n",
      "We initially present the axial shift strategy, which allows the\n",
      "MLP-like architecture to overcome the challenge of spatial\n",
      "invariance and effectively incorporate both local and global\n",
      "cues. We propose a dynamic distillation method without a\n",
      "pre-training teacher, including a dynamic teacher mecha-\n",
      "nism that can effectively eliminate the semantic discrep-\n",
      "ancy with the student model. Such an approach mines more\n",
      "abundant details from lower-level feature appearances and\n",
      "higher-level label semantics as the extra supervision sig-\n",
      "nal, which utilizes efficient instance embedding to model\n",
      "the global spatial and semantic information. In addition, the\n",
      "proposed dynamic teacher can jointly train with students to\n",
      "further enhance the distillation efficiency. Extensive exper-\n",
      "iments executed on six typical fault datasets reveal that our\n",
      "approach outperforms the current state-of-the-art detectors\n",
      "and achieves the highest accuracy with real-time detection\n",
      "at a lower computational cost.\n",
      "Index Terms ‚ÄîDynamic distillation, Multi-layer percep-\n",
      "tron, Fault detection, Freight train images.\n",
      "I. INTRODUCTION\n",
      "VISUAL fault detection of the train braking system is a\n",
      "crucial task to ensure the safe operation of the railway. In\n",
      "the domain of visual fault detection, machine learning-based\n",
      "detectors [1], [2] are gradually supplanting manual detection,\n",
      "which can eliminate human subjectivity while accomplishing\n",
      "greater accuracy and efficiency. As a branch of machine learn-\n",
      "ing, deep learning techniques, especially convolutional neural\n",
      "This work was supported in part by the State Key Laboratory of Novel\n",
      "Software Technology (Grant KFKT2022B38), Hubei Key Laboratory of\n",
      "Modern Manufacturing Quality Engineering (Grant KFJJ-2022014) and\n",
      "the Ph.D. early development program of Hubei University of Technology\n",
      "(Grant XJ2021003801). (Corresponding author: Huilin Pan).\n",
      "Y . Zhang, H. Pan, M. Li, and Y . Zhou are with the School\n",
      "of Mechanical Engineering, Hubei University of Technology, Wuhan\n",
      "430068, China (e-mail: yzhangcst@hbut.edu.cn; hlp@hbut.edu.cn;\n",
      "102200036@hbut.edu.cn; z-g99@hbut.edu.cn).\n",
      "H. Pan, A. Wang and H. Ren are with the Department of Elec-\n",
      "tronic Engineering, The Chinese University of Hong Kong, Hong\n",
      "Kong, China (e-mail: huilinpan@cuhk.edu.hk; wa09@link.cuhk.edu.hk;\n",
      "hlren@ieee.org).\n",
      "Y . Zhang is also with the National Key Laboratory for Novel Soft-\n",
      "ware Technology, Nanjing University, Nanjing 210023, China. (e-mail:\n",
      "yzhangcst@smail.nju.edu.cn)\n",
      "(a)\n",
      " (b)\n",
      " (c)\n",
      " (d)\n",
      "Fig. 1. Visualization results of activation maps from various detectors.\n",
      "(a) Ground truth annotations (blue) for each fault image. (b) CNN-based\n",
      "teacher-student distillation detector. (c) CNN-based self-distillation de-\n",
      "tector. (d) Our proposed MLP-like self dynamic distillation detector. The\n",
      "intensity of the feature response increases from blue to red. As the\n",
      "activation maps exemplify, our method can more accurately capture the\n",
      "region of interest due to the efficient encoding mechanism.\n",
      "networks (CNNs), have significantly boosted the performance\n",
      "of image recognition tasks. The CNNs typically emphasize\n",
      "local features through convolutional operations and pooling,\n",
      "which may disregard the broader context and correlation be-\n",
      "tween faulty parts and the background. As shown in Fig. 1(a),\n",
      "the intricate distributions and volume variations among fault\n",
      "elements and train bodies face challenges for CNN-based\n",
      "methods, specifically due to inherent spatial invariance, result-\n",
      "ing in less accurate identification of fault regions. Therefore,\n",
      "capturing global cues and modeling spatial cues are the most\n",
      "critical issues for visual fault detection of freight trains.\n",
      "Recently, multi-layer perceptrons (MLP) based methods and\n",
      "residual connections have emerged as a new trend in visual\n",
      "recognition tasks. Without using CNNs and self-attention\n",
      "mechanism, MLP-mixer [3] uses matrix transpose and self-\n",
      "attention mechanism to demonstrate that pure MLP architec-\n",
      "ture can also achieve competitive results in image classifica-\n",
      "tion. Meanwhile, ResMLP [4] simplifies the token mixture\n",
      "MLP into a single fully connected layer and utilizes residual\n",
      "connections to create a m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Delaunay Triangulations in the Hilbert Metric\n",
      "Auguste H. Gezalyan /envel‚å¢pe/h‚å¢me\n",
      "Department of Computer Science, University of Maryland, College Park, USA\n",
      "Soo H. Kim /envel‚å¢pe/h‚å¢me\n",
      "Wellesley College, Wellesley, MA\n",
      "Carlos Lopez /envel‚å¢pe/h‚å¢me\n",
      "Montgomery Blair High School, Silver Spring, MD\n",
      "Daniel Skora /envel‚å¢pe/h‚å¢me\n",
      "Indiana University Boolmington, Bloomington, IN\n",
      "Zofia Stefankovic /envel‚å¢pe/h‚å¢me\n",
      "Stony Brook University, Stony Brook, NY\n",
      "David M. Mount /envel‚å¢pe/h‚å¢me\n",
      "Department of Computer Science, University of Maryland, College Park, USA\n",
      "Abstract\n",
      "The Hilbert metric is a distance function defined for points lying within the interior of a convex body.\n",
      "It arises in the analysis and processing of convex bodies, machine learning, and quantum information\n",
      "theory. In this paper, we show how to adapt the Euclidean Delaunay triangulation to the Hilbert\n",
      "geometry defined by a convex polygon in the plane. We analyze the geometric properties of the\n",
      "Hilbert Delaunay triangulation, which has some notable differences with respect to the Euclidean\n",
      "case, including the fact that the triangulation does not necessarily cover the convex hull of the point\n",
      "set. We also introduce the notion of a Hilbert ball at infinity, which is a Hilbert metric ball centered\n",
      "on the boundary of the convex polygon. We present a simple randomized incremental algorithm that\n",
      "computes the Hilbert Delaunay triangulation for a set of npoints in the Hilbert geometry defined\n",
      "by a convex m-gon. The algorithm runs in O(n(logn+log3m))expected time. In addition we\n",
      "introduce the notion of the Hilbert hull of a set of points, which we define to be the region covered\n",
      "by their Hilbert Delaunay triangulation. We present an algorithm for computing the Hilbert hull in\n",
      "timeO(nhlog2m), wherehis the number of points on the hull‚Äôs boundary.\n",
      "2012 ACM Subject Classification Theory of computation ‚ÜíComputational geometry\n",
      "Keywords and phrases Delaunay Triangulations, Hilbert metric, convexity, randomized algorithms\n",
      "1 Introduction\n",
      "David Hilbert introduced the Hilbert metric in 1895 [15]. Given any convex body ‚Ñ¶in\n",
      "d-dimensional space, the Hilbert metric defines a distance between any pair of points in\n",
      "the interior of ‚Ñ¶(see Section 2 for definitions). The Hilbert metric has a number of useful\n",
      "properties. It is invariant under projective transformations, and straight lines are geodesics.\n",
      "When ‚Ñ¶is a Euclidean ball, it realizes the Cayley-Klein model of hyperbolic geometry. When\n",
      "‚Ñ¶is a simplex, it provides a natural metric over discrete probability distributions (see, Nielsen\n",
      "and Sun [20,21]). An excellent resource on Hilbert geometries is the handbook of Hilbert\n",
      "geometry by Papadopoulos and Troyanov [22].\n",
      "The Hilbert geometry provides new insights into classical questions from convexity\n",
      "theory. Efficient approximation of convex bodies has a wide range of applications, including\n",
      "approximate nearest neighbor searching both in Euclidean space [6] and more general\n",
      "metrics [1], optimal construction of Œµ-kernels [4], solving the closest vector problem approxi-\n",
      "mately [11,12,18,24], and computing approximating polytopes with low combinatorial\n",
      "complexity [3,5]. These works all share one thing in common‚Äîthey approximate a convex\n",
      "body by covering it with elements that behave much like metric balls. These coveringarXiv:2312.05987v1  [cs.CG]  10 Dec 20232 Delaunay Triangulations in the Hilbert Metric\n",
      "elements go under various names: Macbeath regions, Macbeath ellipsoids, Dikin ellipsoids,\n",
      "and(2,Œµ)-covers. Vernicos and Walsh showed that these shapes are, up to a constant scaling\n",
      "factor, equivalent to Hilbert balls [2,26]. In addition, the Hilbert metric behaves nicely in\n",
      "the context flag approximability of convex polytopes as studied by Vernicos and Walsh [27].\n",
      "Other applications of the Hilbert metric include machine learning [20], quantum infor-\n",
      "mation theory [23], real analysis [17], and optimal mass transport [9]. Despite its obvious\n",
      "appeals, only recently has there been any work on developing classical computational geome-\n",
      "try algorithms that operate in the Hilbert metric. Nielsen and Shao characterized balls in\n",
      "the Hilbert metric defined by a convex polygon with msides [19]. Hilbert balls are convex\n",
      "polygons bounded by 2msides. Nielsen and Shao showed that Hilbert balls can be computed\n",
      "inO(m)time, and they developed dynamic software for generating them. Gezalyan and\n",
      "Mount presented an O(mnlogn)time algorithm for computing the Voronoi diagram of n\n",
      "point sites in the Hilbert polygonal metric [13] (see Figure 1(a) and (b)). They showed that\n",
      "the diagram has worst-case combinatorial complexity of O(mn). Bumpus et al.[8] further\n",
      "analyzed the properties of balls in the Hilbert metric and presented software for computing\n",
      "Hilbert Voronoi diagrams.\n",
      "‚Ñ¶\n",
      "‚Ñ¶\n",
      "‚Ñ¶\n",
      "Figure 1 (a) A convex polygon ‚Ñ¶and sites, (b) the Voronoi diagram, and (c) the Delaunay\n",
      "triangulation.\n",
      "In this paper, we present an algorithm for computing the Delaunay triangulation of\n",
      "a setPofnpoint sites in the Hilbert geometry defined by an m-side\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Evidence-based Interpretable Open-domain Fact-checking\n",
      "with Large Language Models\n",
      "Tan Xin andZou Bowei andAw Ai Ti\n",
      "Institute for Infocomm Research (I2R), A*STAR\n",
      "{tan_xin,zou_bowei,aaiti}@i2r.a-star.edu.sg\n",
      "Abstract\n",
      "Universal fact-checking systems for real-world\n",
      "claims face significant challenges in gather-\n",
      "ing valid and sufficient real-time evidence and\n",
      "making reasoned decisions. In this work,\n",
      "we introduce the Open-domain Explainable\n",
      "Fact -checking (OE-Fact) system for claim-\n",
      "checking in real-world scenarios. The OE-Fact\n",
      "system can leverage powerful understanding\n",
      "and reasoning capabilities of large language\n",
      "models (LLMs) to validate claims and gener-\n",
      "ate causal explanations for fact-checking de-\n",
      "cisions. To adapt the traditional three-module\n",
      "fact-checking framework to the open domain\n",
      "setting, we first retrieve claim-related informa-\n",
      "tion as relevant evidence from open websites.\n",
      "After that, we retain the evidence relevant to\n",
      "the claim through LLM and similarity calcula-\n",
      "tion for subsequent verification. We evaluate\n",
      "the performance of our adapted three-module\n",
      "OE-Fact system on the Fact Extraction and\n",
      "Verification (FEVER) dataset. Experimental\n",
      "results show that our OE-Fact system outper-\n",
      "forms general fact-checking baseline systems\n",
      "in both closed- and open-domain scenarios, en-\n",
      "suring stable and accurate verdicts while pro-\n",
      "viding concise and convincing real-time expla-\n",
      "nations for fact-checking decisions.\n",
      "1 Introduction\n",
      "In an era of rapid proliferation of non-factual data,\n",
      "inaccurate and misleading content poses signifi-\n",
      "cant challenges to humanity, preventing people\n",
      "from making informed decisions and eroding trust\n",
      "in online resources. The vast spread of misin-\n",
      "formation highlights the importance of automatic\n",
      "fact-checking tasks in natural language processing\n",
      "(NLP) and calls for the emergence of robust and\n",
      "effective fact-checking systems.\n",
      "Existing effective fact-checking models (Nie\n",
      "et al., 2019; Zhong et al., 2020; DeHaven and\n",
      "Scott, 2023; Soleimani et al., 2020; Jiang et al.,\n",
      "2021; Pradeep et al., 2021a,b) usually adopt a three-\n",
      "module pipeline to verify the authenticity of a givenclaim. Firstly, the document retrieval module re-\n",
      "trieves claim-related documents from a database\n",
      "prepared in advance. Secondly, the sentence selec-\n",
      "tion module is harnessed to predict evidence for a\n",
      "claim by scoring and ranking the sentences from\n",
      "retrieved documents. Lastly, the claim classifica-\n",
      "tion module is used to verify the claim‚Äôs authen-\n",
      "ticity based on the predicted evidence. Although\n",
      "the traditional three-module framework effectively\n",
      "improves claim-checking by training three mod-\n",
      "ules in database-centric scenarios, it remains chal-\n",
      "lenging in open-domain real-world scenario claim-\n",
      "checking, which requires more valid and sufficient\n",
      "real-time evidence.\n",
      "Unlike database-centric scenarios, open-domain\n",
      "fact-checking tasks are more challenging due to the\n",
      "complexity and continuous evolution of real-world\n",
      "claims. In this situation, the claim-checking system\n",
      "needs to first understand the claims entered by users\n",
      "in informal language, then retrieve evolving real-\n",
      "time claim-related evidence from multiple sources,\n",
      "and then select claim-relevant evidence from large\n",
      "amounts of candidate evidence to reach reliable\n",
      "and reasoned verdicts.\n",
      "To achieve such a fact-checking system that fo-\n",
      "cuses on real-world claims, we propose an Open-\n",
      "domain Explainable Fact-checking system (OE-\n",
      "Fact). To cater to the nature of real-world claim-\n",
      "checking, we take advantage of the understanding\n",
      "and reasoning capabilities of large language mod-\n",
      "els (LLMs) to build an LLM-based fact-checking\n",
      "system that generates reliable judgments and rea-\n",
      "sonable explanations for a given claim. Specifically,\n",
      "we adopt the traditional three-module pipeline in\n",
      "OE-Fact and adjust the three modules to adapt to\n",
      "the open-domain scenario: First, we employ an\n",
      "evidence retrieval module to retrieve claim-related\n",
      "information from open websites as candidate evi-\n",
      "dence. Afterward, we deploy an evidence selection\n",
      "module to filter the evidence most related to the\n",
      "claim (top-5) through LLM and semantic similarity.arXiv:2312.05834v1  [cs.CL]  10 Dec 2023Finally, a verdict generation module is designed to\n",
      "generate predictive labels and real-time decision\n",
      "explanations of claims based on preserved claim-\n",
      "relevant evidence.\n",
      "The main contribution of this work is three-fold:\n",
      "‚Ä¢We contribute the fact-checking system OE-\n",
      "Fact, which fills the gap in real-world claim-\n",
      "checking within the open-domain setting.\n",
      "‚Ä¢The experimental results on Fact Extraction\n",
      "and VERification (FEVER) dataset (Thorne\n",
      "et al., 2018) highlight the effectiveness of\n",
      "LLMs in generating stable and accurate judg-\n",
      "ments in fact-checking tasks.\n",
      "‚Ä¢The real-time fact-checking decision explana-\n",
      "tion generated by our LLM-based OE-Fact\n",
      "system guarantees the verdict‚Äôs transparency\n",
      "and enhances the explanation‚Äôs overall coher-\n",
      "ence and plausibility.\n",
      "2 Related Work\n",
      "2.1 Traditional Fact-checking\n",
      "Fact-checking is an important task in the field of\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Natural Interaction Modalities f or Human -CPS Interaction i n Construction Progress \n",
      "Monitoring  \n",
      "Srijeet Halder1, Kereshmeh Afsari2, and Alireza Shojaei3 \n",
      "1Assistant Professor ,, Department of Sustainable Technology and the Built Environment, Appalachian State \n",
      "University, Boone, NC, United States. Email: halders1@appstate.edu . Corresponding author.  \n",
      "2Assistant Professor, Myers Lawson School of Construction, Virginia Tech, Blacksburg, VA, United States.  Email: \n",
      "keresh@vt.edu.  \n",
      "3Assistant Professor, Myers Lawson School of Construction, Virginia Tech, Blacksburg, VA, United States. Email: \n",
      "shojaei@vt.edu.  \n",
      "ABSTRACT  \n",
      "This article explores natural interaction modalities \n",
      "for human -cyber -physical systems (CPS) interaction in \n",
      "construction. CPS has been applied in construction for \n",
      "many purposes with the promise of improving  the safety \n",
      "and productivity  of construction operations . However, \n",
      "there is little research on human -CPS interaction in \n",
      "construction. This study proposes two methodologies for \n",
      "human- CPS interactions for construction progress \n",
      "monitoring ‚Äì a) hand gesture interaction using transfer \n",
      "learning, and b) voice comm and interaction using natural \n",
      "language processing.  User studies with thirty -two users \n",
      "validated the generalizability of the proposed methodologies . The proposed hand gesture recognition \n",
      "method achieved higher accuracy  (99.69% vs 87.72%) \n",
      "and speed (36.05ms vs 578.91ms) than the proposed \n",
      "voice command recognition method, though users performed the progress monitoring task more correctly \n",
      "with voice commands  than hand gesture s (88% vs \n",
      "66.1%). The main contribution of the study is the \n",
      "development of an ML pipeli ne and computational \n",
      "framework to recognize hand gestures and voice \n",
      "commands without the need for a large training dataset \n",
      "for human -CPS interaction.  \n",
      "INTRODUCTION  \n",
      "Cyber -Physical System (CPS) is an integrated \n",
      "network of cyber and physical components like Building \n",
      "Information Modelling (BIM), robots, artificial \n",
      "intelligence (AI), etc. Construction 4.0, which is the \n",
      "industry- wide push for automation in the construction  \n",
      "industry, promotes the use of CPS in construction for \n",
      "many applications [1] . Use of CPS has been proposed for \n",
      "many applications in the architecture, engineering, \n",
      "construction, and operations (AECO) industry, such as \n",
      "progress monitoring [2], safety monitoring [3], \n",
      "temporary structures monitoring [4], crane operations \n",
      "[5], structural health monitoring [6] ,  smart city \n",
      "management [7], facility management [8], etc. In a \n",
      "previous study, the author proposed a robotic CPS \n",
      "framework for construction progress monitoring [9]. \n",
      "Construction progress monitoring is a crucial process in \n",
      "construction that ensures that the construction is progressing in a manner consistent with the original \n",
      "plans [10]. Using robotic CPS can improve the \n",
      "productivity and safety of the progress monitoring \n",
      "process by partially automating the process with robots \n",
      "[2]. \n",
      "However, traditionally the interaction between \n",
      "humans and CPS are operationalized with traditional \n",
      "interfaces such as keyboards, mouse, and touchscreens \n",
      "[11], which may not be suitable for use in the \n",
      "construction environment. In this context, voice command interaction and hand gesture recognition have emerged as promising alternative modalities for human -\n",
      "CPS interaction [12,13] . Hand gesture recognition \n",
      "technology allows users to interact with CPS systems using natural hand movements [12] . This technology has \n",
      "been applied in various domains such as gaming, healthcare, and robotics, but its potential in the construction industry remains largely unexplored. Hand \n",
      "signaling is frequently used among construction workers \n",
      "to communicate from a di stance [14]. Therefore, \n",
      "construction workers are already familiar with hand \n",
      "gesture -based communication, which can be leveraged \n",
      "to facilitate hand gesture -based interactions between \n",
      "humans and CPS. On the other hand, voice -based \n",
      "systems have seen increased attention in the past few \n",
      "years with the advent of many voice -based hardware and \n",
      "software like Google Home, Alexa, Siri, etc. [15] . These \n",
      "voice -based systems were found to provide an intuitive \n",
      "method of information access and improve productivity \n",
      "by past researchers [15]. Voice and hand gestures are \n",
      "also key components of human- to-human \n",
      "communication [16]. These interactions , which utilize \n",
      "human language and human behavior in the interaction with computer systems , are called natural interactions \n",
      "[17]. They are designed to reuse the existing skills of the \n",
      "users in terms of speech and hand movements which reduces the corresponding cognitive load of the interactions [17]. Therefore, these two interaction \n",
      "modalities are studied in this research.  \n",
      "Previous research on hand gesture -based interaction \n",
      "between humans and computer systems has largely used \n",
      "motion sensors [12] . Recently, with advancements in \n",
      "computer vision techniques, researchers have used \n",
      "vision -\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fault tree reliability analysis via squarefree polynomials\n",
      "Milan Lopuha ¬®a-Zwakenberg\n",
      "University of Twente, Enschede, the Netherlands\n",
      "m.a.lopuhaa@utwente.nl\n",
      "Keywords: Fault trees, reliability analysis, polynomial algebra\n",
      "Abstract: Fault tree (FT) analysis is a prominent risk assessment method in industrial systems. Unreliability is one of\n",
      "the key safety metrics in quantitative FT analysis. Existing algorithms for unreliability analysis are based\n",
      "on binary decision diagrams, for which it is hard to give time complexity guarantees beyond a worst-case\n",
      "exponential bound. In this paper, we present a novel method to calculate FT unreliability based on algebras\n",
      "of squarefree polynomials and prove its validity. We furthermore prove that time complexity is low when the\n",
      "number of multiparent nodes is limited. Experiments show that our method is competitive with the state-of-\n",
      "the-art and outperforms it for FTs with few multiparent nodes.\n",
      "1 Introduction\n",
      "Fault trees . Fault trees (FTs) form a prominent risk\n",
      "assessment method to categorize safety risks on in-\n",
      "dustrial systems. A FT is a hierarchical graphical\n",
      "model that shows how failures may propagate and\n",
      "lead to system failure. Because of its flexibility and\n",
      "rigor, FT analysis is incorporated in many risk assess-\n",
      "ment methods employed in industry, including Fault-\n",
      "Tree+ (IsoTree, 2023) and TopEvent FTA (Reliotech,\n",
      "2023).\n",
      "A FT is a directed acyclic graph (not necessarily a\n",
      "tree) whose root represents system failure. The leaves\n",
      "are called basic events (BEs) and represent atomic\n",
      "failure events. Intermediate nodes are AND/OR-\n",
      "gates, whose activation depends on that of their chil-\n",
      "dren; the system as a whole fails when the root is ac-\n",
      "tivated. An example is given in Fig. 1.\n",
      "Quantitative analysis . Besides a qualitative analy-\n",
      "sis of what sets of events cause overall system fail-\n",
      "ure, FTs also play an important role in quantitative\n",
      "risk analysis , which seeks to express the safety of the\n",
      "system in terms of safety metrics, such as the total\n",
      "expected downtime, availability, etc. An important\n",
      "safety metric is (un)reliability , which, given the fail-\n",
      "ure probability of each BE, calculates the probability\n",
      "of system failure. As the size of FTs can grow into the\n",
      "hundreds of nodes (Ruijters et al., 2019), calculating\n",
      "the unreliability efficiently is crucial for giving safety\n",
      "and availability guarantees.\n",
      "There exist two main approaches to calculating\n",
      "unreliability (Ruijters and Stoelinga, 2015). The first\n",
      "Left engine fails Right engine fails\n",
      "Right rotor fails Left rotor fails No fuelAND\n",
      "OR\n",
      "BEAircraft failsFigure 1: A fault tree for a small aircraft. The aircraft fails\n",
      "if both its engines fail; each engine fails if either its rotor\n",
      "fails or it has no fuel (the plane has a single fuel tank).\n",
      "approach works bottom-up, recursively calculating\n",
      "the failure probability of each gate. This algorithm is\n",
      "fast (linear time complexity), but only works as long\n",
      "as the FT is actually a tree. However, nodes with mul-\n",
      "tiple parents (DAG-like FTs) are necessary to model\n",
      "more intricate systems. For such FTs, as we show in\n",
      "this paper, calculating unreliability is NP-hard. The\n",
      "main approach for such FTs is based on translating\n",
      "the FT into a binary decision diagram (BDD) and per-\n",
      "forming a bottom-up analysis on the BDD. This BDD\n",
      "is of worst-case exponential size, though heuristics\n",
      "exist. The BDD corresponding to an FT depends on\n",
      "a linear ordering of the BEs, with different orderings\n",
      "yielding BDDs of wildly varying size; although any\n",
      "single one of them can be used to calculate unrelia-\n",
      "bility, finding the optimal BE ordering is an NP-hard\n",
      "problem in itself. As a result, it is hard to give guar-\n",
      "antees on the runtime of this unreliability calculation\n",
      "algorithm in terms of properties of the FT.arXiv:2312.05836v1  [cs.DS]  10 Dec 2023Contributions. In this paper, we present a radical\n",
      "new way for calculating unreliability for general FTs.\n",
      "The bottom-up algorithm does not work for DAG-like\n",
      "FTs, since it does not recognize multiple copies of the\n",
      "same node in the calculation, leading to double count-\n",
      "ing. In our approach we amend this by keeping track\n",
      "of nodes with multiple parents, as these may occur\n",
      "twice in the same calculation. Then, instead of propa-\n",
      "gating failure probabilities as real numbers, we prop-\n",
      "agate squarefree polynomials whose variables repre-\n",
      "sent the failure probabilities of nodes with multiple\n",
      "parents; keeping these formal variables allows us to\n",
      "detect and account for double counting. Furthermore,\n",
      "to keep complexity down we replace formal variables\n",
      "with real numbers whenever we are able. At the root\n",
      "all formal variables have been substituted away, yield-\n",
      "ing the unreliability as a real number.\n",
      "This approach has as advantage over BDD-based\n",
      "algorithms that we are able to give upper bounds to\n",
      "computational complexity. Most of the complexity\n",
      "comes from the fact that we do arithmetic with poly-\n",
      "nomials rather than real numbers. However, if the\n",
      "number of multiparent nodes is limited, these poly-\n",
      "nomi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A Note on the Convergence of Denoising Diffusion Proba-\n",
      "bilistic Models\n",
      "Sokhna Diarra Mbacke sokhna-diarra.mbacke.1@ulaval.ca\n",
      "Universit√© Laval, Canada\n",
      "Omar Rivasplata o.rivasplata@ucl.ac.uk\n",
      "University College London, UK\n",
      "Abstract\n",
      "Diffusion models are one of the most important families of deep generative models. In this\n",
      "note, we derive a quantitative upper bound on the Wasserstein distance between the data-\n",
      "generating distribution and the distribution learned by a diffusion model. Unlike previous\n",
      "works in this field, our result does not make assumptions on the learned score function.\n",
      "Moreover, our bound holds for arbitrary data-generating distributions on bounded instance\n",
      "spaces, even those without a density w.r.t. the Lebesgue measure, and the upper bound does\n",
      "not suffer from exponential dependencies. Our main result builds upon the recent work of\n",
      "Mbacke et al. (2023) and our proofs are elementary.\n",
      "1 Introduction\n",
      "The goal of a generative model is to learn a probability distribution on an instance space, such that samples\n",
      "from this distribution resemble samples from a given target distribution. Along with generative adversarial\n",
      "networks (Goodfellow et al., 2014) and variational autoencoders (VAEs) (Kingma & Welling, 2014; Rezende\n",
      "et al., 2014), diffusion models (Sohl-Dickstein et al., 2015; Song & Ermon, 2019; Ho et al., 2020) are one of the\n",
      "most prominent families of deep generative models. They have exhibited impressive empirical performance in\n",
      "image (Dhariwal & Nichol, 2021; Ho et al., 2022) and audio (Chen et al., 2021; Popov et al., 2021) generation,\n",
      "as well as other areas (Zhou et al., 2021; Sasaki et al., 2021; Li et al., 2022; Trabucco et al., 2023).\n",
      "There are two main approaches to diffusion models: denoising diffusion probabilistic models (DDPMs) (Sohl-\n",
      "Dickstein et al., 2015; Ho et al., 2020) and score-based generative models (Song & Ermon, 2019) (SGMs).\n",
      "The former kind, DDPMs, progressively transform samples from the target distribution into noise through\n",
      "a forward process, and learn a backward process that reverses the transformation and is used to generate\n",
      "new samples. On the other hand, SGMs use score matching techniques (Hyv√§rinen & Dayan, 2005; Vincent,\n",
      "2011) to learn an approximation of the score function of the data-generating distribution, then generate new\n",
      "samples using Langevin dynamics. Since for real-world distributions the score function might not exist, Song\n",
      "& Ermon (2019) propose adding different noise levels to the training samples to cover the whole instance\n",
      "space, and train a neural network to simultaneously learn the score function for all noise levels.\n",
      "Although DDPMs and SGMs might seem like different approaches at first, Ho et al. (2020) showed that\n",
      "DDPMs implicitly learn an approximation of the score function and the sampling process resembles Langevin\n",
      "dynamics. Furthermore, Song et al. (2021b) derived a unifying view of both techniques using stochastic\n",
      "differential equations (SDEs). The SGM of Song & Ermon (2019) can be seen as a discretization of the\n",
      "Brownian motion, and the DDPM of Ho et al. (2020) as a discretization of an Ornstein‚ÄìUhlenbeck process.\n",
      "Hence, both DDPMs and SGMs are usually referred to as SGMs in the literature. This explains why the\n",
      "previous works studying the theoretical properties of diffusion models utilize the score-based formulation,\n",
      "which requires assumptions on the performance of the learned score function. In this work, we take a\n",
      "different approach and apply techniques developed by Mbacke et al. (2023) for VAEs to DDPMs, which can\n",
      "be seen as hierarchical VAEs with fixed encoders (Luo, 2022). This approach allows us to derive quantitative\n",
      "1arXiv:2312.05989v1  [cs.LG]  10 Dec 2023Wasserstein distance upper bounds with no assumptions on the data-generating distribution, no assumptions\n",
      "on the learned score function, and elementary proofs that do not require the SDE toolbox. Moreover, our\n",
      "bounds do not suffer from any costly discretization step, such as the one in De Bortoli (2022), since we\n",
      "consider the forward and backward processes as being discrete-time from the beginning, instead of seeing\n",
      "them as discretizations of continuous-time processes.\n",
      "1.1 Related Works\n",
      "There has been a growing body of work aiming to establish theoretical results on the convergence of SGMs\n",
      "(Block et al., 2020; De Bortoli et al., 2021; Song et al., 2021a; Lee et al., 2022; De Bortoli, 2022; Kwon et al.,\n",
      "2022; Lee et al., 2023; Chen et al., 2023; Li et al., 2023), but these works either rely on strong assumptions\n",
      "on the data-generating distribution, derive non quantitative upper bounds, or suffer from exponential depen-\n",
      "dencies on some of the parameters. We manage to avoid all three of these pitfalls. The bounds of Lee et al.\n",
      "(2022) rely on very strong assumptions on the data-generating distribution such as log-Sobolev inequalities\n",
      "which are not realistic for real-life data distributions. Furthermore, Song et al. (2021a); Chen et al. (2023);\n",
      "Lee et al. (2023) establish upper b\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Topological Data Analysis for Neural Network Analysis:\n",
      "A Comprehensive Survey\n",
      "Rub¬¥ en Ballester ruben.ballester@ub.edu\n",
      "Carles Casacuberta carles.casacuberta@ub.edu\n",
      "Departament de Matem` atiques i Inform` atica\n",
      "Universitat de Barcelona\n",
      "Gran Via de les Corts Catalanes, 585, 08007 Barcelona, Catalonia, Spain\n",
      "Sergio Escalera sescalera@ub.edu\n",
      "Departament de Matem` atiques i Inform` atica\n",
      "Universitat de Barcelona\n",
      "Gran Via de les Corts Catalanes, 585, 08007 Barcelona, Catalonia, Spain\n",
      "Computer Vision Center\n",
      "Edifici O, Campus UAB, 08193 Bellaterra, Catalonia, Spain\n",
      "Abstract\n",
      "This survey provides a comprehensive exploration of applications of Topological Data Anal-\n",
      "ysis (TDA) within neural network analysis. Using TDA tools such as persistent homology\n",
      "and Mapper, we delve into the intricate structures and behaviors of neural networks and\n",
      "their datasets. We discuss different strategies to obtain topological information from data\n",
      "and neural networks by means of TDA. Additionally, we review how topological informa-\n",
      "tion can be leveraged to analyze properties of neural networks, such as their generalization\n",
      "capacity or expressivity. We explore practical implications of deep learning, specifically\n",
      "focusing on areas like adversarial detection and model selection. Our survey organizes the\n",
      "examined works into four broad domains: 1. Characterization of neural network architec-\n",
      "tures; 2. Analysis of decision regions and boundaries; 3. Study of internal representations,\n",
      "activations, and parameters; 4. Exploration of training dynamics and loss functions. Within\n",
      "each category, we discuss several articles, offering background information to aid in under-\n",
      "standing the various methodologies. We conclude with a synthesis of key insights gained\n",
      "from our study, accompanied by a discussion of challenges and potential advancements in\n",
      "the field.\n",
      "Keywords: Topological data analysis, persistent homology, Mapper, deep learning, neu-\n",
      "ral networks, topological machine learning\n",
      "1 Introduction\n",
      "Over the past few years, deep learning has consolidated its position as the most successful\n",
      "branch of artificial intelligence. With the continuous growth in computational capacity,\n",
      "neural networks have expanded in size and complexity, enabling them to effectively tackle\n",
      "increasingly challenging problems. However, their increased capacity has made it more\n",
      "challenging to comprehend essential properties of the networks such as their interpretabil-\n",
      "ity, generalization ability, or suitability for specific problems. From both theoretical and\n",
      "practical standpoints, this is undesirable, especially in critical contexts where AI decisions\n",
      "¬©2023 Rub¬¥ en Ballester and Carles Casacuberta and Sergio Escalera.\n",
      "License: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/ .arXiv:2312.05840v1  [cs.LG]  10 Dec 2023TDA for Neural Network Analysis\n",
      "could lead to catastrophic consequences, such as medical diagnosis (Yang et al., 2021) or\n",
      "autonomous driving (W¬® aschle et al., 2022), among others.\n",
      "Topological Data Analysis (TDA) has emerged as a subfield of algebraic topology that\n",
      "offers a framework for gaining insights into the shape of data in a broad sense. Topological\n",
      "data analysis has found application across a wide array of experimental science disciplines,\n",
      "spanning from biomedicine (Skaf and Laubenbacher, 2022) to finance (Gidea and Katz,\n",
      "2018), among numerous others. One of its most prolific areas of application is machine\n",
      "learning, particularly in the domain of deep learning. A basic introduction to topological\n",
      "machine learning can be found in Hensel et al. (2021). Topological data analysis, specifically\n",
      "homology, persistent homology and Mapper, has been used to analyze various aspects of\n",
      "neural networks. Broadly, these aspects can be categorized in the following four groups:\n",
      "1. Structure of the neural network; 2. Input and output spaces; 3. Internal representations\n",
      "and activations; 4. Training dynamics and loss functions.\n",
      "Figure 1 visually delineates these four categories. The first category involves examining\n",
      "unweighted graphs associated with neural networks and their properties, such as depth, layer\n",
      "widths, and graph topology, among others. The second category encompasses the analysis\n",
      "of neural network input and output spaces, including decision regions and boundaries for\n",
      "classification problems, as well as the study of latent spaces for generative models. The\n",
      "third category, which currently holds the largest number of contributions in the literature,\n",
      "focuses on the analysis of hidden and output neurons in a broad sense. Lastly, the fourth\n",
      "category involves the analysis of neural network training procedures, including the study of\n",
      "loss functions.\n",
      "Many components studied within the preceding categories play a pivotal role in under-\n",
      "standing some of the fundamental traits of deep learning, such as interpretability or the\n",
      "generalization capacity of neural networks. Moreover, these elements inherently exhibit\n",
      "geometrical and topological characteristics, rendering th\n",
      "----------------------------------------------------------------------------------------------------\n",
      "VEC-TIONARIES FOR EXTRACTING LATENT MESSAGE FEATURES \n",
      "  1  Constructing Vec-tionaries to Extract Latent Message Features from Texts:  A Case Study of Moral Appeals Version: December 10, 2023 *This version has not undergone peer review*   Zening Duan1, Anqi Shao2, Yicheng Hu3, Heysung Lee1, Xining Liao1,  Yoo Ji Suh1, Jisoo Kim1, Kai-Cheng Yang4, Kaiping Chen2, Sijia Yang1 1 School of Journalism and Mass Communication, University of Wisconsin-Madison 2 Department of Life Sciences Communication, University of Wisconsin-Madison 3 Department of Chemical and Biological Engineering, University of Wisconsin-Madison 4 Network Science Institute, Northeastern University    Author Note Zening Duan (https://orcid.org/0000-0001-7369-657X) is a doctoral student in the School of Journalism and Mass Communication at University of Wisconsin-Madison.  Anqi Shao (https://orcid.org/0000-0002-4051-2276) is a doctoral candidate from the Department of Life Sciences Communication, University of Wisconsin-Madison.  Yicheng Hu (https://orcid.org/0000-0001-9790-736X) is a senior research specialist at the Dow Chemical Company. He obtained his Ph.D. in Chemical Engineering from University of Wisconsin-Madison. VEC-TIONARIES FOR EXTRACTING LATENT MESSAGE FEATURES \n",
      "  2 Heysung Lee (https://orcid.org/0000-0003-3306-9939) is a Ph.D. candidate at the School of Journalism and Mass Communication, the University of Wisconsin-Madison. Xining Liao (https://orcid.org/0000-0001-7501-8967) is a Ph.D. candidate in the School of Journalism and Mass Communication at the University of Wisconsin-Madison. Yoo Ji Suh (https://orcid.org/0000-0003-1224-8524) is a Ph.D. student at the School of Journalism and Mass Communication, University of Wisconsin-Madison. Jisoo Kim (https://orcid.org/0009-0009-5149-2846) is a Ph.D. Candidate at the School of Journalism and Mass Communication at the University of Wisconsin-Madison. Kai-Cheng Yang (Ph.D., Indiana University; https://orcid.org/0000-0003-4627-9273) is a postdoctoral research associate at Network Science Institute, Northeastern University. Kaiping Chen (Ph.D., Stanford University; https://orcid.org/0000-0002-5864-5333) is an assistant professor in computational communication at the Department of Life Sciences Communication, University of Wisconsin‚ÄìMadison. Sijia Yang (Ph.D., University of Pennsylvania; https://orcid.org/0000-0003-4209-9881) is an assistant professor in the School of Journalism and Mass Communication at the University of Wisconsin-Madison. We have no known conflict of interest to disclose.  Correspondence concerning this article should be addressed to Sijia Yang, University of Wisconsin-Madison, 5160 Vilas Hall, 821 University Avenue, Madison, WI 53706, United States. Email: syang84@wisc.edu   VEC-TIONARIES FOR EXTRACTING LATENT MESSAGE FEATURES \n",
      "  3  Abstract While communication research frequently studies latent message features like moral appeals, their quantification remains a challenge. Conventional human coding struggles with scalability and intercoder reliability. While dictionary-based methods are cost-effective and computationally efficient, they often lack contextual sensitivity and are limited by the vocabularies developed for the original applications. In this paper, we present a novel approach to construct vec-tionary measurement tools that boost validated dictionaries with word embeddings through nonlinear optimization. By harnessing semantic relationships encoded by embeddings, vec-tionaries improve the measurement of latent message features by expanding the applicability of original vocabularies to other contexts. Vec-tionaries can also help extract semantic information from texts, especially those in short format, beyond the original vocabulary of a dictionary. Importantly, a vec-tionary can produce additional metrics to capture the valence and ambivalence of a latent feature beyond its strength in texts. Using moral appeals in COVID-19-related tweets as a case study, we illustrate the steps to construct the moral foundations vec-tionary, showcasing its ability to process posts missed by dictionary methods and to produce measurements better aligned with crowdsourced human assessments. Furthermore, additional metrics from the moral foundations vec-tionary unveiled unique insights that facilitated predicting outcomes such as message retransmission.   Keywords: Computational text analysis, message features, moral appeals, word embedding, optimalization, crowdsourcingVEC-TIONARIES FOR EXTRACTING LATENT MESSAGE FEATURES \n",
      "  4  Communication researchers are often interested in studying latent message features within texts, such as emotional appeals, language sophistication, and more recently, moral appeals (Graham et al., 2013; Brady et al., 2017; Weber et al., 2018; Zhou et al., 2022). However, quantifying latent message features presents a significant challenge. For example, human coding cannot easily scale up to process ‚Äúbig data,‚Äù or in some cases, is suboptimal to alternative\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MUTUAL ENHANCEMENT OF LARGE AND SMALL LANGUAGE\n",
      "MODELS WITH CROSS -SILOKNOWLEDGE TRANSFER\n",
      "Yongheng Deng, Ziqing Qiao, Ju Ren, Yaoxue Zhang\n",
      "Department of Computer Science and Technology, BNRist\n",
      "Tsinghua University\n",
      "Beijing, China\n",
      "{dyh19,qiaozq20}@mails.tsinghua.edu.cn\n",
      "{renju, zhangyx}@tsinghua.edu.cnYang Liu\n",
      "Institute for AI Industry Research (AIR)\n",
      "Tsinghua University\n",
      "Beijing, China\n",
      "liuy03@air.tsinghua.edu.cn\n",
      "ABSTRACT\n",
      "While large language models (LLMs) are empowered with broad knowledge, their task-specific\n",
      "performance is often suboptimal. It necessitates fine-tuning LLMs with task-specific data, but such\n",
      "data may be inaccessible due to privacy concerns. In this paper, we propose a novel approach to\n",
      "enhance LLMs with smaller language models (SLMs) that are trained on clients using their private\n",
      "task-specific data. To enable mutual enhancement between LLMs and SLMs, we propose CROSS LM,\n",
      "where the SLMs promote the LLM to generate task-specific high-quality data, and both the LLM\n",
      "and SLMs are enhanced with the generated data. We evaluate CROSS LMusing publicly accessible\n",
      "language models across a range of benchmark tasks. The results demonstrate that CROSS LM\n",
      "significantly enhances the task-specific performance of SLMs on clients and the LLM on the cloud\n",
      "server simultaneously while preserving the LLM‚Äôs generalization capability.\n",
      "Keywords Language Models, Collaborative Learning, Cross-Silo, Knowledge Transfer\n",
      "1 Introduction\n",
      "Recent large language models (LLMs) have achieved significant success [ 1,2], sparking a profound revolution in\n",
      "natural language processing (NLP). Today‚Äôs LLMs are trained on massive corpora from a broad variety of sources,\n",
      "empowering them with diverse and comprehensive linguistic knowledge. However, when pre-trained LLMs are applied\n",
      "to a specific domain for targeted tasks, their performance often proves considerably less satisfactory (see Fig. 1).\n",
      "Therefore, pre-trained LLMs necessitate further training with domain-specific data to enhance their performance in\n",
      "specialized tasks [3, 4].\n",
      "Domain-specific data typically originates from specific users, companies, or organizations within a particular field. For\n",
      "example, in the financial sector, banks and investment firms produce transaction records, market reports, and financial\n",
      "statements, which are valuable for tasks such as risk assessment and financial analysis. In the medical domain, hospitals\n",
      "and healthcare providers generate patient medical records and clinical trial data, which are helpful for tasks such as\n",
      "patient diagnosis and medical research. However, this data is usually privacy-sensitive. As user privacy awareness\n",
      "is increasing and legal regulations regarding data governance are becoming more stringent [ 5], the collection and\n",
      "utilization of private domain data face significant obstacles. This poses a formidable challenge in further enhancing the\n",
      "performance of LLMs for specific tasks. In this evolving landscape, there is a growing need for innovative approaches\n",
      "that enable the development of domain-specific LLM solutions without exposing private domain data.\n",
      "Federated learning (FL) [ 6], which harnesses collaborative model training across decentralized data sources without\n",
      "exposing raw private data, provides a viable solution to address these challenges. However, applying FL directly to\n",
      "LLM training encounters obstacles in terms of both resource and proprietary constraints. On the one hand, the training\n",
      "of LLMs is computationally and memory-intensive due to their substantial parameter size, which can be prohibitive\n",
      "for some resource-constrained FL participants. Furthermore, transferring these extensive parameters to the server forarXiv:2312.05842v1  [cs.AI]  10 Dec 2023SST-2 AG News IMDb Yahoo! Answers020406080100Accuracy (%)Pre-trained GPT2-Large Well-trained Bert-Base Finetuned GPT2-LargeFigure 1: The performance of pre-trained GPT2-Large on specific tasks. The performance of pre-trained GPT2-Large is\n",
      "much degraded relative to a smaller task-specifically trained Bert-Base model. The performance gap can be filled by\n",
      "fine-tuning GPT2-Large with task-specific data.\n",
      "aggregation also incurs significant communication overhead. On the other hand, many LLMs are non-public, which\n",
      "cannot be directly accessed or shared with clients for fine-tuning due to proprietary constraints or privacy concerns.\n",
      "To address the aforementioned challenges, prior arts proposed federated parameter-efficient fine-tuning approaches [ 7,\n",
      "8,9]. These approaches freeze most of the weights of pre-trained LLMs and only update a small portion of LLM\n",
      "parameters on clients. Only the updated parameters on clients are transferred to the server for aggregation. Although\n",
      "this approach reduces the resource overhead compared to full-model training, it still imposes significant resource\n",
      "requirements, as it needs to accommodate the full model on each client, which can be demanding. For example,\n",
      "the GPT-3 model [ 10] boasts a massive 175 billion parameters, necessitating 350GB of G\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Modifying RL Policies with Imagined Actions: How Predictable Policies Can\n",
      "Enable Users to Perform Novel Tasks\n",
      "Isaac Sheidlower, Reuben Aronson, Elaine Short\n",
      "Tufts University, Department of Computer Science\n",
      "{isaac.sheidlower, reuben.aronson, elaine.short }@tufts.edu\n",
      "Abstract\n",
      "It is crucial that users are empowered to use the functionalities\n",
      "of a robot to creatively solve problems on the fly. A user who\n",
      "has access to a Reinforcement Learning (RL) based robot\n",
      "may want to use the robot‚Äôs autonomy and their knowledge\n",
      "of its behavior to complete new tasks. One way is for the user\n",
      "to take control of some of the robot‚Äôs action space through\n",
      "teleoperation while the RL policy simultaneously controls the\n",
      "rest. However, an out-of-the-box RL policy may not readily\n",
      "facilitate this. For example, a user‚Äôs control may bring the\n",
      "robot into a failure state from the policy‚Äôs perspective, caus-\n",
      "ing it to act in a way the user is not familiar with, hindering\n",
      "the success of the user‚Äôs desired task. In this work, we formal-\n",
      "ize this problem and present Imaginary Out-of-Distribution\n",
      "Actions, IODA, an initial algorithm for addressing that prob-\n",
      "lem and empowering user‚Äôs to leverage their expectation of a\n",
      "robot‚Äôs behavior to accomplish new tasks.\n",
      "Introduction\n",
      "As robots are increasingly in the hands of users, it is nec-\n",
      "essary to ensure that these users are empowered to use\n",
      "the robot and its functionality to accomplish the tasks they\n",
      "want. Ideally, one can deploy a robot with an exhaustive li-\n",
      "brary of Reinforcement Learning (RL) policies that can au-\n",
      "tonomously perform any task the user wishes. However, this\n",
      "approach is impractical as users may wish to seamlessly use\n",
      "the robot for a task or in an environment that was not fore-\n",
      "seen by the designers of the robot. In reality, the user will be\n",
      "provided with a limited set of policies and a means of con-\n",
      "trolling the robot, such as teleoperation. Given this, there is a\n",
      "need for methods that enable users to take advantage of these\n",
      "two types of control to perform new and emergent tasks.\n",
      "Consider the following illustrative example. Sally fre-\n",
      "quently uses her assistive robot arm to perform tasks around\n",
      "the house. Sally has used the robot arm‚Äôs pick-and-place RL\n",
      "policy to move cups full of liquid many times. She knows\n",
      "how the robot will pick up the cup and steadily move it\n",
      "to a specified location. Now Sally wants to use the same\n",
      "functionality to water her flowers. To do this, she starts the\n",
      "autonomous policy and during execution rotates the robot‚Äôs\n",
      "wrist to pour the water over her basin and water her flowers\n",
      "as the robot moves along it‚Äôs path. Although in this example\n",
      "the interaction led to the desired result, an RL policy ‚Äúas-is‚Äù\n",
      "may not facilitate this. For instance, if the RL policy wastrained on a reward function such that if it spills liquid, it\n",
      "should stop moving along its path until the cup is upright.\n",
      "In this case, Sally may accidentally pour all her water onto\n",
      "one flower, since the robot did not continue along its path as\n",
      "she had expected. Similar problems exist in the autonomous\n",
      "driving domain, such as driving intentionally on the side-\n",
      "walk or hitting an obstacle.\n",
      "These examples demonstrate potential problems of\n",
      "naively using an RL policy while the user controls part of the\n",
      "robots behavior. Since the user may have only seen success-\n",
      "ful examples of task execution, they may not know that their\n",
      "control signal can cause failure with respect to the robot‚Äôs\n",
      "reward function, causing it to behave unexpectedly. Further-\n",
      "more, that unexpected behavior may impede the user‚Äôs abil-\n",
      "ity to perform novel tasks or result in task failure from the\n",
      "user‚Äôs perspective. This problem setting also allows the user\n",
      "to bring the policy ‚Äúout-of-distribution,‚Äù which may result in\n",
      "undesirable behavior. There is a need to both better under-\n",
      "stand this type of interaction from a user‚Äôs point of view and\n",
      "develop algorithms that act on RL policies to better facilitate\n",
      "the user completing their task. Our key insight is that whilst\n",
      "the user has partial control, the robot should act in a way\n",
      "similar to the behavior the user has seen before and is famil-\n",
      "iar with, allowing the user to leverage their prior knowledge\n",
      "about the robot‚Äôs behavior to adapt it to new tasks.\n",
      "In this paper, we formalize the aforementioned problem\n",
      "setting and present Imaginary Out-of-Distribution Actions\n",
      "(IODA), an algorithm that modifies the state passed into\n",
      "an RL policy by projecting its current state to a previous\n",
      "state the user has seen: despite the robot‚Äôs current real state,\n",
      "it chooses actions based on an imagined state. IODA only\n",
      "modifies the state when the user brings the state out-of-\n",
      "distribution (OOD) with respect to states the user is familiar\n",
      "with/has seen before. IODA uses an OOD detector to deter-\n",
      "mine when to modify the state, and then a projection func-\n",
      "tion to determine the nearest state the user is familiar with to\n",
      "project on to. We study IODA in simulation and then discuss\n",
      "our future work studying how IODA can facilitate re\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Super -rays grouping scheme and novel coding \n",
      "architecture for computational time reduction of \n",
      "graph -based Light Field coding  \n",
      " \n",
      "Nguyen Gia Bach  1, Chanh Minh Tran  1, Nguyen Duc Tho 1, Phan Xuan Tan 2,*, and Eiji Kamioka  1 \n",
      "1 Graduate School of Engineering and Science, Shibaura Institute of Technology, Tokyo 135 -8548, Japan ; Email: \n",
      "nb23505 @shibaura -it.ac.jp (N.G.B.); nb20502@shibaura -it.ac.jp (C.M.T.); nb20501@shibaura -it.ac.jp (T.N.D.);  \n",
      "kamioka@shibaura -it.ac.jp (E.K.)  \n",
      "2 Department of Information and Communications Engineering, Shibaura Institute of Technology,  Tokyo 135 -8548, \n",
      "Japan ;  \n",
      "*Correspondence: tanpx@shibaura -it.ac.jp . \n",
      " \n",
      " \n",
      " \n",
      "Abstract‚ÄîGraph -based Light Field coding using the concept \n",
      "of super -rays is powerful to exploit signal redundancy along \n",
      "irregular shapes and achieves good energy compaction, \n",
      "compared to rectangular block -based approaches. However, \n",
      "its main limitation lies in the high time complexity for e igen-\n",
      "decomposition of each super -ray local graph, a high number \n",
      "of which can be found in a Light Field when segmented into \n",
      "super -rays. This paper examines a grouping scheme for \n",
      "super -rays in order to reduce the number of eigen -\n",
      "decomposition times, and prop oses a novel coding \n",
      "architecture to handle the signal residual data arising for \n",
      "each super -ray group, as a tradeoff  to achieve lower \n",
      "computation al time. Experimental results have shown to \n",
      "reduce a considerable amount of decoding time for Light \n",
      "Field scenes, despite having a slight increase in the coding \n",
      "bitrates when compared with the original non -grouping \n",
      "super -ray -based approach. The proposal also remains to \n",
      "have competitive performance in Rate Distortion in \n",
      "comparison to HEVC -based and JPEG Pleno -based  \n",
      "methods.  \n",
      " \n",
      "Keywords ‚Äîlight field; compression; super -ray; over -\n",
      "segmentation; graph transform; eigen -decomposition  \n",
      " \n",
      "I. INTRODUCTION  \n",
      "Light Field (Light Field) devices have recently been \n",
      "gaining popularity over traditional cameras for capturing \n",
      "light rays emitted by a 3D point from different orientations \n",
      "[1], hence providing a rich description of the 3D scene with \n",
      "a variety of potential applications in computer vision tasks \n",
      "like semantic segmentation [2], depth estimation and re -\n",
      "focusing [3], 3D reconstruct ion [4], video stabilization [5], \n",
      "and so on. This, however, comes with the cost of \n",
      "containing high dimensional data with redundancy in both \n",
      "spatial and angular dimensions, raising challenges in \n",
      "storage capacity and transmission [6].  \n",
      "Such redundancies or correlations can be visualized in a \n",
      "multi -view representation of a Light Field, illustrated in \n",
      "Fig. 1. Spatial correlation refers to the relation between the \n",
      "intensity values of nearby pixels in a single view. If the \n",
      "intensity values o f two neighboring pixels are highly similar, they have a strong spatial correlation. Angular \n",
      "correlation refers to the relation between the light \n",
      "intensities of corresponding pixels from different views. If \n",
      "the intensities from different angles are highly similar, they \n",
      "have a strong angular correlation. The spatio -angular \n",
      "correlation has shown to be well exploited by signal \n",
      "transform -based  methods [7], in which continuously \n",
      "similar signals with high redundancy are translated into \n",
      "energy coefficients with compaction in frequency domain. \n",
      "High energy compaction enables efficient compression \n",
      "performance.  \n",
      " \n",
      "Figure 1.  Multiview representation of a 4D Light Field \n",
      "scene L(u, v, s,  t), with  spatial domain (u, v), and angular \n",
      "domain (s,  t). (Left side) Example of a  Light Field scene \n",
      "Friends [8]. (Right side) Example of spatial correlation  and \n",
      "angular correlation for a given pixel position in all views \n",
      "(selected in  green)  \n",
      "This paper considers the use of graph -based  transform \n",
      "to exploit the  correlations in Light Field data. Graphs are \n",
      "useful to describe irregular image structures, adhering \n",
      "closely to texture boundaries. Thus,  the image can be \n",
      "partitioned into variable -shape blocks containing  mostly \n",
      "uniform pixel intensities. In contrast to the conventional \n",
      "rectangular blocks with variable -size used in standardized \n",
      "solutions (i.e:  HEVC [9]), this is more likely to contain \n",
      "non-uniform intensities or  different statistical properties. \n",
      "As a result, better energy compaction  can be achieved for \n",
      "varying -sized blocks than rectangular blocks after  \n",
      "transforming into frequency domain.  \n",
      "To carry out this operation, Graph Fourier transform \n",
      "(GFT) [10] and  other variants [11 ‚Äì 14] are natural tools \n",
      "used for adaptive transforms of  irregular image structures, \n",
      "such as piecewise smooth images. A comprehensive \n",
      "survey on GFT can be found in [15]. GFT operation on \n",
      "each graph requires computing its basis functions \n",
      "(Laplacian eigenvectors)  to decompose signals residing on \n",
      "a graph onto these basis functions.  During this process, the \n",
      "Laplacian graph is diagonalized into eigenvalues and \n",
      "eigenvectors matri ces, also known as eigen -\n",
      "decomposition.  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "mir_ref : A Representation Evaluation Framework for\n",
      "Music Information Retrieval Tasks\n",
      "Christos Plachouras Pablo Alonso-Jim√©nez Dmitry Bogdanov\n",
      "Music Technology Group, Universitat Pompeu Fabra, Barcelona, Spain\n",
      "cplachouras@nyu.edu, pablo.alonso@upf.edu, dmitry.bogdanov@upf.edu\n",
      "Abstract\n",
      "Music Information Retrieval (MIR) research is increasingly leveraging represen-\n",
      "tation learning to obtain more compact, powerful music audio representations\n",
      "for various downstream MIR tasks. However, current representation evaluation\n",
      "methods are fragmented due to discrepancies in audio and label preprocessing,\n",
      "downstream model and metric implementations, data availability, and computa-\n",
      "tional resources, often leading to inconsistent and limited results. In this work, we\n",
      "introduce mir_ref ,1an MIR Representation Evaluation Framework focused on\n",
      "seamless, transparent, local-first experiment orchestration to support representation\n",
      "development. It features implementations of a variety of components such as MIR\n",
      "datasets, tasks, embedding models, and tools for result analysis and visualization,\n",
      "while facilitating the implementation of custom components. To demonstrate its\n",
      "utility, we use it to conduct an extensive evaluation of several embedding models\n",
      "across various tasks and datasets, including evaluating their robustness to various\n",
      "audio perturbations and the ease of extracting relevant information from them.\n",
      "1 Evaluating Music Representations\n",
      "In the last decade, representation learning has attracted much interest in Music Information Retrieval\n",
      "(MIR), the field concerned with extracting, analyzing, and understanding information from music\n",
      "data. Time and frequency domain representations of audio are very information-dense, making it\n",
      "difficult and expensive to build end-to-end pipelines for solving MIR tasks. Additionally, their size\n",
      "and accompanying copyright restrictions make sharing, handling, and transferring music datasets\n",
      "challenging. Deep representations have shown promise as a generalized, compact, and efficient\n",
      "input feature relevant to many MIR tasks that circumvents these challenges. Many different music\n",
      "representation learning approaches have been undertaken, starting with the use of Deep Belief\n",
      "Networks in an unsupervised manner [ 21,17,12]. More popularly, classification approaches based\n",
      "on tags followed [ 34,23,10,28,38,37], as well as some based on editorial metadata [ 27,22].\n",
      "Correspondence has also been exploited, such as with tags [ 13,14], editorial metadata [ 4,30],\n",
      "playlists [ 15,3], language [ 25,24,18], and video [ 11]. A lot of interest has also fallen on self-\n",
      "supervised [31, 9, 40] and music-generation-based approaches [7].\n",
      "Evaluation of music audio representations so far remains fragmented. This is in part attributable to\n",
      "challenges present in MIR like data unavailability and implementation complexity [ 26], but, ultimately,\n",
      "there are no clear guidelines about how various components of a representation learning system should\n",
      "be implemented. Tools such as mirdata [5] and mir_eval [29] have encouraged consistency and\n",
      "transparency by standardizing dataset and metric implementations respectively. Practically, however,\n",
      "representation evaluation comes with many more components that need appropriate experimentation\n",
      "and transparent implementation. Table 1 demonstrates implementation choices by several works in\n",
      "the evaluation of their respective representation models in downstream classification tasks. Model\n",
      "1mir_ref is available at https://github.com/chrispla/mir_ref\n",
      "37th Conference on Neural Information Processing Systems (NeurIPS 2023), ML for Audio WorkshoparXiv:2312.05994v2  [cs.SD]  12 Dec 2023sizes and optimization details vary significantly, and even preprocessing and prediction strategies are\n",
      "not consistent. In some cases, important implementation details are only present in the accompanying\n",
      "code, making them harder to find, or are missing from both the paper and code.\n",
      "Table 1: Downstream implementation details (selected). Downstream code and hyperparameter\n",
      "optimization (HPO) study open availability is indicated. Model output can be aggregated (aggr.) at\n",
      "the representation (repr.) or prediction (pred.) level. ?indicates implementation detail is missing.\n",
      "model optimization output\n",
      "code type layer(s) HPO initial lr wd aggr.\n",
      "EffNet-Discogs MLP 512 1e‚àí31e‚àí5pred.\n",
      "MusiCNN ‚úì SVM NA NA NA pred.\n",
      "OpenL3 MLP 512-128 ‚úì 1e{‚àí5,..,‚àí3}1e{‚àí5,..,‚àí3}pred.\n",
      "NeuralFP LC NA ? ? ?\n",
      "CLMR ‚úì LC NA 3e‚àí41e‚àí6repr.\n",
      "MERT ‚úì MLP 512 ‚úì 1e{‚àí4,..,‚àí2}? repr.\n",
      "COALA ‚úì MLP 256 1e‚àí31e‚àí4repr.\n",
      "JukeMIR ‚úì LC/MLP NA/512 ‚úì 1e{‚àí5,..,‚àí3}1e{‚àí3,..,0}repr.\n",
      "MuLaP ‚úì MLP 512 1e‚àí31e‚àí2pred.\n",
      "Additionally, setting up evaluation experiments is tedious. Getting access to and handling several large\n",
      "datasets is challenging, and ensuring adequate experimentation on downstream pipeline components\n",
      "and parameters is time-consuming and, often, computationally infeasible. As a result, a limited set of\n",
      "datasets and tasks is usually investigated in the original representation m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "InteractDiffusion: Interaction Control in Text-to-Image Diffusion Models\n",
      "Jiun Tian Hoe1Xudong Jiang1Chee Seng Chan2Yap-Peng Tan1Weipeng Hu1\n",
      "1Nanyang Technological University, Singapore2Universiti Malaya, Malaysia\n",
      "jiuntian001@e.ntu.edu.sg {exdjiang,eyptan,weipeng.hu }@ntu.edu.sg cs.chan@um.edu.my\n",
      "GLIGENStable DiffusionLayout InputInteraction InputInteractDiffusion\n",
      "Caption: a personis holdinga bag, another person is talkingon a cell phoneCaption: a personis feedinga cat\n",
      "Generated ImageGenerated ImageGenerated Image\n",
      "personanother person\n",
      "personfeedingpersoncell phone\n",
      "catanother personpersontalkingholding\n",
      "bagbagcell phone\n",
      "cat\n",
      "Figure 1. Generated samples of size 512x512. Stable Diffusion conditions on text caption only, while GLIGEN conditions on extra layout\n",
      "input. Our proposed InteractDiffusion conditions on extra interaction label and its location shown by the shaded area.\n",
      "Abstract\n",
      "Large-scale text-to-image (T2I) diffusion models have\n",
      "showcased incredible capabilities in generating coherent\n",
      "images based on textual descriptions, enabling vast ap-\n",
      "plications in content generation. While recent advance-\n",
      "ments have introduced control over factors such as object\n",
      "localization, posture, and image contours, a crucial gap\n",
      "remains in our ability to control the interactions between\n",
      "objects in the generated content. Well-controlling inter-\n",
      "actions in generated images could yield meaningful appli-\n",
      "cations, such as creating realistic scenes with interacting\n",
      "characters. In this work, we study the problems of condi-\n",
      "tioning T2I diffusion models with Human-Object Interac-\n",
      "tion (HOI) information, consisting of a triplet label (per-\n",
      "son, action, object) and corresponding bounding boxes. We\n",
      "propose a pluggable interaction control model, called In-teractDiffusion that extends existing pre-trained T2I diffu-\n",
      "sion models to enable them being better conditioned on in-\n",
      "teractions. Specifically, we tokenize the HOI information\n",
      "and learn their relationships via interaction embeddings.\n",
      "A conditioning self-attention layer is trained to map HOI\n",
      "tokens to visual tokens, thereby conditioning the visual to-\n",
      "kens better in existing T2I diffusion models. Our model\n",
      "attains the ability to control the interaction and location\n",
      "on existing T2I diffusion models, which outperforms exist-\n",
      "ing baselines by a large margin in HOI detection score, as\n",
      "well as fidelity in FID and KID. Project page: https:\n",
      "//jiuntian.github.io/interactdiffusion .\n",
      "1. Introduction\n",
      "The advent of diffusion generative models recently opens\n",
      "up new creative task opportunities. While diffusion mod-\n",
      "1arXiv:2312.05849v1  [cs.CV]  10 Dec 2023els could generate diverse high quality images that re-\n",
      "construct the original data distributions, it is important to\n",
      "control the content generated. Numerous literatures have\n",
      "since extensively studied how to control the image gener-\n",
      "ation of the diffusion models via e.g. class [7, 31], text\n",
      "[19, 21, 22, 24], image (including edge, line, scribble and\n",
      "skeleton) [1, 13, 30] and layout [1, 5, 15, 28, 32]. However,\n",
      "these are insufficient to effectively express the nuanced in-\n",
      "tentions and desired outcomes, especially the interactions\n",
      "between objects. Our work introduces another important\n",
      "control in image generation: interaction .\n",
      "Interaction refers to a reciprocal action between two en-\n",
      "tities or individuals. Without a doubt, interaction is an inte-\n",
      "gral part of describing our daily activities. However, we find\n",
      "that existing diffusion models work well on static images\n",
      "such as paintings or scenic photos but face great challenges\n",
      "in generating images involving interactions. For instance,\n",
      "GLIGEN [15] adds layout as a condition to help specify the\n",
      "location of objects, but controlling the relationship or inter-\n",
      "action between the objects remains an open difficult prob-\n",
      "lem, as shown in Fig. 1. Control at the interaction level in\n",
      "text-to-image (T2I) diffusion models has countless applica-\n",
      "tions, e.g. e-commerce, gaming, interactive storytelling etc.\n",
      "This paper studies the problem of interaction-\n",
      "conditioned image generation, i.e. how to specify the\n",
      "interaction in the image generation process. It faces three\n",
      "main challenges:\n",
      "a)Interaction representation : How to represent interac-\n",
      "tion information in a meaningful token representation.\n",
      "b)Intricate interaction relationship : The relationship\n",
      "among objects with interaction is complex, and gener-\n",
      "ating coherent images remains a great challenge.\n",
      "c)Integrating conditions into existing models : Current\n",
      "T2I diffusion models excel in image generation quality\n",
      "but lack interaction control. A pluggable module that\n",
      "can be seamlessly integrated into them is imperative.\n",
      "To address the aforementioned issues, we propose an in-\n",
      "teraction control model called InteractDiffusion as a plug-\n",
      "gable module to existing T2I diffusion model as illustrated\n",
      "in Fig. 2, aiming to impose interaction control. First, to pro-\n",
      "vide conditioning information to the diffusion model, we\n",
      "treat each interacting pair as a HOI triplet and transform\n",
      "its in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "From Correspondences to Pose:\n",
      "Non-minimal Certifiably Optimal Relative Pose without Disambiguation\n",
      "Javier Tirado-Gar ¬¥ƒ±n Javier Civera\n",
      "I3A, University of Zaragoza\n",
      "{j.tiradog,jcivera }@unizar.es\n",
      "Abstract\n",
      "Estimating the relative camera pose from n‚â•5corre-\n",
      "spondences between two calibrated views is a fundamen-\n",
      "tal task in computer vision. This process typically involves\n",
      "two stages: 1) estimating the essential matrix between the\n",
      "views, and 2) disambiguating among the four candidate rel-\n",
      "ative poses that satisfy the epipolar geometry. In this pa-\n",
      "per, we demonstrate a novel approach that, for the first\n",
      "time, bypasses the second stage. Specifically, we show\n",
      "that it is possible to directly estimate the correct relative\n",
      "camera pose from correspondences without needing a post-\n",
      "processing step to enforce the cheirality constraint on the\n",
      "correspondences. Building on recent advances in certifi-\n",
      "able non-minimal optimization, we frame the relative pose\n",
      "estimation as a Quadratically Constrained Quadratic Pro-\n",
      "gram (QCQP). By applying the appropriate constraints, we\n",
      "ensure the estimation of a camera pose that corresponds\n",
      "to a valid 3D geometry and that is globally optimal when\n",
      "certified. We validate our method through exhaustive syn-\n",
      "thetic and real-world experiments, confirming the efficacy,\n",
      "efficiency and accuracy of the proposed approach. Code is\n",
      "available at https://github.com/javrtg/C2P .\n",
      "1. Introduction\n",
      "Finding the relative pose between two calibrated views is\n",
      "crucial in many computer vision applications. This task is\n",
      "particularly relevant, among others, in Structure from Mo-\n",
      "tion (SfM) [44, 53], and Simultaneous Localization And\n",
      "Mapping (SLAM) [13, 46, 47]. In SfM, it serves to geo-\n",
      "metrically verify the correspondences as well as to provide\n",
      "pairwise constraints for pose averaging schemes [27, 40]. In\n",
      "SLAM, besides correspondence verification, it is also used\n",
      "for bootstrapping the odometry of the camera and comput-\n",
      "ing an initial estimate of the 3D map.\n",
      "The relative pose problem has five observable degrees\n",
      "of freedom: three for the relative rotation between the\n",
      "cameras, and two for the direction of the relative transla-\n",
      "I0\n",
      "I1approximate\n",
      "solver\n",
      "glob. optim.\n",
      "solver\n",
      "pure rot. checkE\n",
      " E‚ãÜ\n",
      "certif.\n",
      "C2P\n",
      "(ours)\n",
      "disambiguation\n",
      "is pure rot.?\n",
      "is pure rot.? + + E‚ãÜ\n",
      "certif.Figure 1. Relative pose directly from matches, without addi-\n",
      "tional steps for disambiguation and pure rotation checks. Tra-\n",
      "ditionally, estimating the relative pose involves two steps: 1) Es-\n",
      "timating the essential matrix Eusing an approximate or globally-\n",
      "optimal solver, and 2) disambiguating the unique geometrically\n",
      "valid pose among four candidate relative poses, with an additional\n",
      "step to determine if the motion is purely rotational. In this paper,\n",
      "we introduce C2P, a globally-optimal and certifiable approach that,\n",
      "for the first time, solves the relative pose problem in a single step.\n",
      "tion. The standard approach for its computation [29] be-\n",
      "gins by considering a set of npixel correspondences be-\n",
      "tween the two images. These correspondences can be es-\n",
      "tablished through matching the descriptors of keypoints ex-\n",
      "tracted from the images [1, 16, 41, 43], or more recently by\n",
      "estimating a (semi)dense 2D mapping between the views\n",
      "[17, 58, 61]. The pose is then computed by minimizing\n",
      "epipolar errors [29], requiring at least five correspondences.\n",
      "Solvers that handle n= 5correspondences are termed min-\n",
      "imal [48, 54] and those able to handle all the correspon-\n",
      "dences are called non-minimal [10, 69].\n",
      "This paper focuses on non-minimal solvers. In a practi-\n",
      "cal setup in which input correspondences may contain out-\n",
      "liers, these solvers are essential within RANSAC [19, 49]\n",
      "and Graduated Non-Convexity (GNC) [66]. In RANSAC,\n",
      "non-minimal solvers are used to improve the accuracy of\n",
      "theso-far-best and final models (initially computed with\n",
      "minimal solvers) thanks to noise cancellation of the inliers\n",
      "[49]. In GNC, globally-optimal non-minimal solvers serve\n",
      "as fundamental building blocks to robustly solve a weighted\n",
      "instance of the problem in an iterative fashion.\n",
      "Since the seminal paper by Longuet-Higgins [42] in\n",
      "1arXiv:2312.05995v1  [cs.CV]  10 Dec 20231981, computing this non-minimal estimate of the rela-\n",
      "tive pose, involves two key steps: 1) estimating the es-\n",
      "sential matrix ‚Äîwhich models the epipolar geometry of the\n",
      "problem‚Äîvia an approximate (minimal or local optimiza-\n",
      "tion) method, or a certifiably globally-optimal method, and\n",
      "2) disambiguating the true relative pose from those satisfy-\n",
      "ing the same epipolar geometry. This ambiguity arises from\n",
      "ignoring the cheirality constraints which enforce a valid 3D\n",
      "geometry (mainly that the 3D points observed in the image\n",
      "must be in front of the camera), resulting in a additional\n",
      "overhead that scales with the number of points.\n",
      "In this paper, we demonstrate that this two-step ap-\n",
      "proach, gold standard for more than 40 years, is not a must,\n",
      "and present a method that, for the first time directly esti-\n",
      "mates the relative pose without requiri\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Composite Survival Analysis: Learning with Auxiliary Aggregated\n",
      "Baselines and Survival Scores\n",
      "Chris Solomou *\n",
      "University of York\n",
      "Abstract\n",
      "Survival Analysis (SA) constitutes the default\n",
      "method for time-to-event modeling due to\n",
      "its ability to estimate event probabilities of\n",
      "sparsely occurring events over time. In this\n",
      "work, we show how to improve the training\n",
      "and inference of SA models by decoupling\n",
      "their full expression into (1) an aggregated\n",
      "baseline hazard, which captures the overall\n",
      "behavior of a given population, and (2) inde-\n",
      "pendently distributed survival scores, which\n",
      "model idiosyncratic probabilistic dynamics of\n",
      "its given members, in a fully parametric set-\n",
      "ting. The proposed inference method is shown\n",
      "to dynamically handle right-censored obser-\n",
      "vation horizons, and to achieve competitive\n",
      "performance when compared to other state-\n",
      "of-the-art methods in a variety of real-world\n",
      "datasets, including computationally inefficient\n",
      "Deep Learning-based SA methods and models\n",
      "that require MCMC for inference. Neverthe-\n",
      "less, our method achieves robust results from\n",
      "the outset, while not being subjected to fine-\n",
      "tuning or hyperparameter optimization.\n",
      "1 Introduction\n",
      "Survival Analysis is a statistical method used to predict\n",
      "the time until a specific event of interest occurs within\n",
      "a predefined period. Some of its applications include\n",
      "clinical trials, digital marketing, financial forecasting,\n",
      "engineering and manufacturing. Although these do-\n",
      "mains differ significantly, the underlying purpose of\n",
      "Survival Analysis remains the same, with the event\n",
      "being adjusted to fit the specific domain. Across all\n",
      "applications of Survival Analysis, the objective is to\n",
      "determine the distribution of survival times, which\n",
      "* Preliminary work. This work is not supported by any\n",
      "organization.represents significant events such as patient mortality\n",
      "(clinical trials), conversion of a new customer (digital\n",
      "marketing) or failure of a machine (manufacturing).\n",
      "One of the most prominent challenges in Survival Anal-\n",
      "ysis is that over the predetermined period of a study,\n",
      "participants may leave the study early due to a different\n",
      "event than the one of interest. Nonetheless, for many\n",
      "of the participants, that event can occur at a later time,\n",
      "after the study has concluded. This phenomenon rep-\n",
      "resents ‚Äôright-censoring‚Äô and is commonly encountered\n",
      "in various applications of Survival Analysis.\n",
      "Related Work The idiosyncrasies of the event proba-\n",
      "bilities changing with time, and participants leaving or\n",
      "outrunning the duration of the study, make common\n",
      "classifiers ineffective in Survival Analysis. Common\n",
      "solutions for estimating the survival probabilities over\n",
      "time include methods that take into account specific\n",
      "characteristics of the population (covariates); while oth-\n",
      "ers focus specifically on the time-to-event relationship.\n",
      "There is a rich history of non-parametric models ap-\n",
      "plied to survival analysis with the most popular being\n",
      "the Kaplan Meier estimator, developed by Kaplan and\n",
      "Meier [1958], which is a non-parametric method for\n",
      "modelling the survival function as the population of\n",
      "the study changes with time. We direct the reader\n",
      "to Fong and Lehmann [2022] for more resources ofarXiv:2312.05854v1  [cs.LG]  10 Dec 2023Composite Survival Analysis\n",
      "non-parametric methods applied to Survival Analysis.\n",
      "Traditional parametric methods include modelling the\n",
      "survival times using the Exponential, Gamma, Weibull\n",
      "distribution etc. These methods require a distribu-\n",
      "tional assumption, and it‚Äôs difficult to account for the\n",
      "covariates of a study with the few parameters that\n",
      "govern them. Although when their assumptions are\n",
      "met they can handle all types of censored data, and\n",
      "as demonstrated by Efron [1977] and Oakes [1977] a\n",
      "parametric model yields more efficient estimates than\n",
      "semi-parametric models.\n",
      "Survival models that utilize covariates include para-\n",
      "metric distributions Accelerated Life Models, and Pro-\n",
      "portional Hazard Models. The Cox [1972] proportional\n",
      "hazards model, constitutes the most popular model in\n",
      "survival analysis since no assumption is required about\n",
      "the probability distribution of the survival times. It is\n",
      "comprisedfromanon-parametricpart(baselinehazard)\n",
      "and a parametric part that utilizes the population‚Äôs\n",
      "covariates for modelling the hazard rate over time.\n",
      "Machine Learning algorithms have also found success\n",
      "in Survival Analysis. This includes Survival Support\n",
      "Vector Machines (P√∂lsterl et al. [2015, 2016]), an exten-\n",
      "sion of the standard SVM - Boser et al. [1992], applied\n",
      "to right-censored time-to-event data. Survival SVM\n",
      "can effectively model non-linear relationships between\n",
      "features and survival outcomes by utilizing the kernel\n",
      "trick. The kernel function transforms the input features\n",
      "into high-dimensional feature spaces and separating hy-\n",
      "perplane determines survival (or otherwise).\n",
      "Another prevalent method for survival analysis is Ran-\n",
      "dom Survival Forest by Ishwaran et al. [2008] an ex-\n",
      "tension of Breiman [2001]. In RSF each tree is grown\n",
      "by randomly sele\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The SyGuS Language Standard Version 2.1\n",
      "Saswat Padhi Elizabeth Polgreen Mukund Raghothaman\n",
      "Andrew Reynolds Abhishek Udupa\n",
      "Sunday 8thAugust, 2021\n",
      "1 Introduction\n",
      "We present a language to specify instances of the syntax-guided synthesis (SyGuS) problem. An instance\n",
      "of a SyGuS problem specifies:\n",
      "1.The vocabularies, theories and the base types that are used to specify (a) semantic constraints on\n",
      "the function to be synthesized, and (b) the definition of the function to be synthesized itself. We\n",
      "refer to these as the inputandoutputlogics respectively.\n",
      "2. A finite set of typed functions f1,...,fnthat are to be synthesized.\n",
      "3.The syntactic constraints on each function fi,i‚àà[1,n]to be synthesized. The syntactic constraints\n",
      "are specified using context-free grammars Giwhich describe the syntactic structure of candidate\n",
      "solution for each of these functions. The grammar may only involve function symbols and sorts from\n",
      "the specified output logic.\n",
      "4.Thesemanticconstraintsandassumptionsthatdescribethebehaviorofthefunctionstobesynthesized.\n",
      "Constraints are given as quantifier-free formulas œÜand assumptions are given as quantifier-free\n",
      "formulasŒ±in the input logic, and may refer to the functions-to-synthesize as well as universally\n",
      "quantified variables v1,...,vm.\n",
      "The objective then is to find definitions ei(in the form of expression bodies) for each function fisuch that\n",
      "(a) the expression body belongs to the grammar Githat is used to syntactically constrain solutions for fi,\n",
      "and (b) the constraint ‚àÄv1,...,vm.Œ±=‚áíœÜis valid in the background theory under the assumption that\n",
      "functionsf1,...,fnare interpreted as functions returning e1,...,en. Note that each eiis an expression\n",
      "containing a fixed set of free variables which represent the argument list of the function fi.\n",
      "Overview of This Document This document defines the SyGuS format version 2.1, which is intended\n",
      "to be used as the standard input and output language for solvers targeting the syntax-guided synthesis\n",
      "problem. The language borrows many concepts and language constructs from the standard format for\n",
      "Satisfiability Modulo Theories (SMT) solvers, the SMT-LIB standard (version 2.6) [3].\n",
      "Outline In the remainder of this section, we cover differences of the SyGuS format described in this\n",
      "document with previous revisions [ 5,1,2] and cover the necessary preliminaries. Then, Section 2 gives the\n",
      "concrete syntax for commands in the SyGuS input language. Section 3 documents the well-formedness\n",
      "and the semantics of input commands. Section 4 documents the expected output of synthesis solvers\n",
      "in response to these commands. Section 5 describes formally the notion of a SyGuS logic and how it\n",
      "restricts the set of commands that are allowed in an input. Section 6 formalizes what constitutes a correct\n",
      "response to a SyGuS input. Finally, Section 9 provides examples of possible inputs in the SyGuS language\n",
      "and solvers responses to them.\n",
      "1.1 Differences from Previous Versions\n",
      "In this section, we cover the differences in this format with respect to the one described in the previous\n",
      "version of the SyGuS format [5], and its extensions [1, 2].\n",
      "1arXiv:2312.06001v1  [cs.PL]  10 Dec 20231.1.1 Changes from SyGuS 1.0 to SyGuS 2.0\n",
      "1.The syntax for providing grammars inside the synth-fun command now requires that non-terminal\n",
      "symbols are declared upfront in a predeclaration , see Section 3.4 for details.\n",
      "2.The keyword Start, which denoted the starting (non-terminal) symbol of grammars in the previous\n",
      "standard, has been removed. Instead, the first symbol listed in the grammar is assumed to be the\n",
      "starting symbol.\n",
      "3.Terms that occur as the right hand side of production rules in SyGuS grammars are now required\n",
      "to be binder-free. In particular, this means that let-terms are now disallowed within grammars.\n",
      "Accordingly, the keywords InputVariable and LocalVariable , which were used to specify input\n",
      "and local variables in grammars respectively, have been removed since the former is equivalent to\n",
      "Variable and the latter has no affect on the grammar.\n",
      "4.The datatype keyword Enumand related syntactic features have been removed. The standard\n",
      "SMT-LIB 2.6 commands for declaring datatypes are now adopted, see Section 3.5 for details.\n",
      "5.The set-options command has been renamed set-option to correlate to the existing SMT-LIB\n",
      "version 2.6 command.\n",
      "6.The syntax for terms and sorts now coincides with the corresponding syntax for terms and sorts\n",
      "from SMT-LIB versions 2.0 and later. There are three notable changes with respect to the previous\n",
      "SyGuS format that come as a result of this change. First, negative integer and real constants must\n",
      "be written with unary negation, that is, the integer constant negative one must be written (- 1),\n",
      "whereas previously it could be written -1. Second, the syntax for bit-vectors sorts (BitVec n) is\n",
      "now written (_ BitVec n) . Third, all let-bindings do notannotate the type of the variable being\n",
      "bound. Previously, a let-term was written (let ((x T t)) ...) where Tindicates the type of t.\n",
      "Now, it \n",
      "----------------------------------------------------------------------------------------------------\n",
      "NeVRF: Neural Video-based Radiance Fields for Long-duration Sequences\n",
      "Minye Wu Tinne Tuytelaars\n",
      "KU Leuven\n",
      "{minye.wu, tinne.tuytelaars }@esat.kuleuven.be\n",
      "Abstract\n",
      "Adopting Neural Radiance Fields (NeRF) to long-\n",
      "duration dynamic sequences has been challenging. Ex-\n",
      "isting methods struggle to balance between quality and\n",
      "storage size and encounter difficulties with complex scene\n",
      "changes such as topological changes and large motions.\n",
      "To tackle these issues, we propose a novel neural video-\n",
      "based radiance fields (NeVRF) representation. NeVRF\n",
      "marries neural radiance field with image-based rendering\n",
      "to support photo-realistic novel view synthesis on long-\n",
      "duration dynamic inward-looking scenes. We introduce\n",
      "a novel multi-view radiance blending approach to predict\n",
      "radiance directly from multi-view videos. By incorporat-\n",
      "ing continual learning techniques, NeVRF can efficiently\n",
      "reconstruct frames from sequential data without revisit-\n",
      "ing previous frames, enabling long-duration free-viewpoint\n",
      "video. Furthermore, with a tailored compression approach,\n",
      "NeVRF can compactly represent dynamic scenes, making\n",
      "dynamic radiance fields more practical in real-world sce-\n",
      "narios. Our extensive experiments demonstrate the effec-\n",
      "tiveness of NeVRF in enabling long-duration sequence ren-\n",
      "dering, sequential data reconstruction, and compact data\n",
      "storage.\n",
      "1. Introduction\n",
      "Neural Radiance Field (NeRF) [30] has facilitated a series\n",
      "of breakthroughs in novel view synthesis, enriching the con-\n",
      "tents for virtual reality, telecommunications, etc. Among\n",
      "them is photo-realistic free-viewpoint video (FVV). How-\n",
      "ever, generating dynamic radiance fields in practical set-\n",
      "tings remains challenging due to their storage requirements\n",
      "and the complexity of processing streaming input data.\n",
      "Recent advances have improved NeRF content gen-\n",
      "eration in many ways, such as accelerating the training\n",
      "speed [9, 44], rendering speed [14, 33, 39], and reduc-\n",
      "ing the storage in a compact representation [5, 46]. These\n",
      "methods mainly focus on static scenes. Some methods in-\n",
      "troduce space deformation [20, 34, 37] to handle dynamic\n",
      "scenes. They disentangle motion and canonical space from\n",
      "tn\n",
      "Sequential Video DataContinual Learnin g\n",
      "NeVRF\n",
      "Video Timeline\n",
      "Figure 1. Our method introduces a neural video-based radiance\n",
      "field representation for dynamic scenes achieving photo-realistic\n",
      "novel view synthesis with small storage (around 1.32MB per-\n",
      "frame) in sequential input setting. NeVRF can continuously re-\n",
      "construct a sequence without revisiting previous data, making it\n",
      "suitable for long-duration sequences.\n",
      "sequences to achieve fast training speed with sparse views\n",
      "and further speed up by leveraging an explicit grid repre-\n",
      "sentation [20]. However, the decreased number of views\n",
      "can impair performance in scenes with large motion, and\n",
      "limits their ability to handle topological changes due to the\n",
      "use of canonical space. MLPs [37, 53] and space-time latent\n",
      "codes [18] are used to capture motion information. While\n",
      "they achieve relatively compact storage, they have large\n",
      "computational complexity and their performance is con-\n",
      "strained by the network capacity, which makes it challeng-\n",
      "ing to deal with long-duration or large motion sequences. In\n",
      "another line of work, grid-based methods usually require a\n",
      "large memory [20], making the transmission and storage of\n",
      "NeRF content challenging.\n",
      "Furthermore, previous approaches require all sequence\n",
      "data to be available throughout the entire training process\n",
      "to enable i.i.d. sampling of rays for assembling training\n",
      "batches. This becomes unfeasible for long-duration or end-\n",
      "less sequences owing to the substantial surge in memory\n",
      "consumption and the indeterminate length of data. Dynamic\n",
      "scene data is naturally sequential and ordered by time, but\n",
      "so far this property has not been exploited for more efficient\n",
      "FVV generation.\n",
      "In this paper, we present a novel Neural Video-based Ra-\n",
      "diance Field (NeVRF) representation to tackle the issuesarXiv:2312.05855v1  [cs.CV]  10 Dec 2023and challenges of long-duration sequences with sequential\n",
      "input, as illustrated in Figure 1. NeVRF directly infers the\n",
      "radiance fields from the inward-looking input videos frame-\n",
      "per-frame. At the core is a Multi-view Radiance Blend-\n",
      "ing approach that predicts colors from multi-view frame\n",
      "images. Specifically, we deploy a shared lightweight fea-\n",
      "ture encoder to extract local context and semantic cues\n",
      "from multi-view frame images. Another network learns to\n",
      "predict views‚Äô visibility and blending weights for sample\n",
      "points along rays, avoiding traditional high-cost visibility\n",
      "calculations. The density fields are represented using ex-\n",
      "plicit volumetric grids, enabling it to be decoupled from the\n",
      "appearance rendering process. This separative design en-\n",
      "ables both high-quality rendering and efficient storage com-\n",
      "pression. Our representation leverages off-the-shelf video\n",
      "codecs and our proposed density fields compression algo-\n",
      "rithm to achieve compact storage.\n",
      "We also introduce a tailored conti\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Large Language Models on Lexical Semantic Change Detection:\n",
      "An Evaluation\n",
      "Ruiyu Wang*\n",
      "University of Toronto\n",
      "rywang@cs.toronto.eduMatthew Choi*\n",
      "University of Toronto\n",
      "mattchoi@cs.toronto.edu\n",
      "Abstract\n",
      "Lexical Semantic Change Detection stands out\n",
      "as one of the few areas where Large Language\n",
      "Models (LLMs) have not been extensively in-\n",
      "volved. Traditional methods like PPMI, and\n",
      "SGNS remain prevalent in research, alongside\n",
      "newer BERT-based approaches. Despite the\n",
      "comprehensive coverage of various natural lan-\n",
      "guage processing domains by LLMs, there is a\n",
      "notable scarcity of literature concerning their\n",
      "application in this specific realm. In this work,\n",
      "we seek to bridge this gap by introducing LLMs\n",
      "into the domain of Lexical Semantic Change\n",
      "Detection. Our work presents novel prompting\n",
      "solutions and a comprehensive evaluation that\n",
      "spans all three generations of language models,\n",
      "contributing to the exploration of LLMs in this\n",
      "research area.\n",
      "1 Introduction\n",
      "Languages are evolving. A perpetual flux of\n",
      "changes occurs, driven by an array of factors en-\n",
      "compassing cultural, social, technological, and of-\n",
      "ten, undiscovered influences. In this ever-shifting\n",
      "linguistic landscape, words shed unused senses\n",
      "while concurrently acquiring new meanings. Lan-\n",
      "guages engage in a reciprocal exchange, borrowing\n",
      "senses from one another, and simultaneously ex-\n",
      "erting influence. This intricate web of linguistic\n",
      "evolution necessitates an automatic approach to\n",
      "comprehend and assess the fluidity of languages.\n",
      "Automation becomes the key to navigating and in-\n",
      "terpreting the dynamic currents of linguistic trans-\n",
      "formation.\n",
      "However, the development of advanced compu-\n",
      "tational methods for Diachronic Lexical Seman-\n",
      "tic Change (LSC) has been a blank slate for re-\n",
      "searchers. Since the 2010s, traditional embed-\n",
      "ding methods like PPMI, SVD, and SGNS have\n",
      "shown significant statistical correlation with hu-\n",
      "man annotators and produced promising results in\n",
      "*These authors contributed equally to this work.detecting shifts in word meaning (Kulkarni et al.,\n",
      "2014; Hamilton et al., 2018; Schlechtweg et al.,\n",
      "2019). As a result, previous works often lean to-\n",
      "wards using existing tools to uncover new mean-\n",
      "ing shifts rather than exploring novel algorithms\n",
      "to enhance them. Additionally, frequency-based\n",
      "algorithms typically depend on large corpora (Tah-\n",
      "masebi et al., 2019). Their performance on rela-\n",
      "tively low-resource datasets remains a challenge,\n",
      "and an efficient solution for this has yet to be dis-\n",
      "covered.\n",
      "Since its introduction by Vaswani et al. (2017),\n",
      "models based on the Transformer architecture have\n",
      "become the latest trend. Contextualized word em-\n",
      "beddings generated by BERT (Devlin et al., 2019)\n",
      "have provided a solid foundation for various down-\n",
      "stream language tasks. Moreover, recently, Large\n",
      "Language Models (LLMs) have showcased remark-\n",
      "able capabilities in logical thinking and solving\n",
      "language tasks based on instructions (Bubeck et al.,\n",
      "2023; Zhao et al., 2023; OpenAI, 2023a; Rozi√®re\n",
      "et al., 2023). This has inspired researchers to em-\n",
      "brace LLMs for a modern approach to a series of\n",
      "lexical semantic tasks and explore their ability to\n",
      "understand natural language meanings.\n",
      "In this study1, we conducted a series of tasks to\n",
      "assess the suitability of LLMs for LSC detection for\n",
      "TempoWiC (Loureiro et al., 2022), a low-resource\n",
      "annotated tweet dataset. Our key findings are out-\n",
      "lined as follows:\n",
      "1.We reassess the performance of traditional\n",
      "methods (i.e., PPMI, SGNS, SVD) in address-\n",
      "ing diachronic LSC on a low-resource dataset.\n",
      "2.We introduce a simple yet innovative gener-\n",
      "ative approach for diachronic LSC detection.\n",
      "This method achieves promising results with-\n",
      "out requiring fine-tuning on pre-trained mod-\n",
      "els.\n",
      "1Access the GitHub repository through this link .arXiv:2312.06002v1  [cs.CL]  10 Dec 20233.We conduct comprehensive evaluations for\n",
      "LLMs, BERT-based methods, and traditional\n",
      "methods at both the corpus level and instance\n",
      "level, offering insights into their respective\n",
      "capabilities in diachronic LSC detection.\n",
      "2 Related Works\n",
      "Traditional Methods We define traditional sense\n",
      "modeling methods as those that do not rely on\n",
      "pre-trained models and prior knowledge. These\n",
      "mainly include count-based vector representations\n",
      "andpredictive vector representations. Count-\n",
      "based representations are computed based on word\n",
      "co-occurrence frequencies, with Positive Point-\n",
      "wise Mutual Information (PPMI) being a popu-\n",
      "lar method. Predictive vector representations typ-\n",
      "ically involve word2vec (Mikolov et al., 2013)\n",
      "variants, such as the skip-gram with negative-\n",
      "sampling (SGNS) training method, which previ-\n",
      "ously achieved state-of-the-art results on various\n",
      "tasks.\n",
      "However, traditional methods have notable lim-\n",
      "itations. Firstly, due to their one-to-one relation-\n",
      "ship between words and vectors, these methods\n",
      "are inherently incapable of classifying colexifica-\n",
      "tion. Secondly, as all traditional models operate at\n",
      "the corpus level, they struggle to classify instance-\n",
      "level meaning changes,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A Video is Worth 256 Bases: Spatial-Temporal Expectation-Maximization\n",
      "Inversion for Zero-Shot Video Editing\n",
      "Maomao Li1, Yu Li2, Tianyu Yang2, Yunfei Liu2, Dongxu Yue3, Zhihui Lin4, and Dong Xu1\n",
      "1The University of Hong Kong2International Digital Economy Academy (IDEA)\n",
      "3Peking University4Tsinghua University\n",
      "Input video\n",
      "STEMTF with DDIM\n",
      "DDIMFZ with DDIM\n",
      "Reconstruction: A man is playing tennis. Editing #1:  Spider-Manis playing tennis.Editing #2:  ‚Ä¶ in Van Gogh Starry Night style.\n",
      "TF with STEMFZ with STEM\n",
      "Figure 1. We propose STEM inversion as an alternative approach to zero-shot video editing, which offers several advantages over the\n",
      "commonly employed DDIM inversion technique. STEM inversion achieves superior temporal consistency in video reconstruction while\n",
      "preserving intricate details. Moreover, it seamlessly integrates with contemporary video editing methods, such as TokenFlow (TF) [9] and\n",
      "FateZero (FZ) [30], enhancing their editing capabilities. Best viewed with zoom-in.\n",
      "Abstract\n",
      "This paper presents a video inversion approach for zero-\n",
      "shot video editing, which aims to model the input video\n",
      "with low-rank representation during the inversion process.\n",
      "The existing video editing methods usually apply the typ-\n",
      "ical 2D DDIM inversion or na ¬®ƒ±ve spatial-temporal DDIM\n",
      "inversion before editing, which leverages time-varying rep-\n",
      "resentation for each frame to derive noisy latent. Unlike\n",
      "most existing approaches, we propose a Spatial-Temporal\n",
      "Expectation-Maximization (STEM) inversion, which for-\n",
      "mulates the dense video feature under an expectation-\n",
      "maximization manner and iteratively estimates a more com-\n",
      "pact basis set to represent the whole video. Each frame\n",
      "applies the fixed and global representation for inversion,\n",
      "which is more friendly for temporal consistency during re-\n",
      "construction and editing. Extensive qualitative and quan-\n",
      "titative experiments demonstrate that our STEM inversion\n",
      "can achieve consistent improvement on two state-of-the-art\n",
      "video editing methods. Project page: https://stem-\n",
      "inv.github.io/page/ .1. Introduction\n",
      "Recent years have witnessed a surge of interest in using\n",
      "diffusion models [13,40] for text-to-image (T2I) generation.\n",
      "There are fruitful endeavours that have been pursued, such\n",
      "as DALLE-2 [33], Imagen [37], and Stable Diffusion [35].\n",
      "Following this line, a group of methods finetune the general\n",
      "T2I model [35] for personalization usage [5,8,22,36,47,50].\n",
      "In view of amazing results in the image domain, it is nat-\n",
      "ural to leverage a pre-trained large-scale T2I model [35]\n",
      "for video editing. However, frame-wise editing inevitably\n",
      "brings an unacceptable flickering effect. Thus, how to ef-\n",
      "fectively model 3D correspondence in a 2D model poses\n",
      "the main obstacle in the current video editing task.\n",
      "There are three schools of research for diffusion-based\n",
      "text-driven video editing. 1) Finetune or train addition\n",
      "modules [11, 25] for the image diffusion model on mas-\n",
      "sive videos to learn video motion prior. 2) Tune the im-\n",
      "age model on each video to be edited to capture the tem-\n",
      "poral consistency in the input video. 3) Design frame-\n",
      "wise attention mechanisms to capture temporal cues, such\n",
      "as FateZero [30], Pix2Video [3], and TokenFlow [9]. The\n",
      "1arXiv:2312.05856v1  [cs.CV]  10 Dec 2023last setting requires no training and reaches impressive re-\n",
      "sults, which is more convenient for users and communities\n",
      "to use. Therefore, we focus on the third setting in this paper.\n",
      "Although DDIM inversion struggles for precise recon-\n",
      "struction when classifier-free guidance [14] is applied, most\n",
      "of the existing zero-shot video editing approaches only fo-\n",
      "cus on making an improvement on the editing process itself\n",
      "to eliminate the limited editing ability brought by inaccurate\n",
      "inversion and reconstruction. For example, Pix2Video [3]\n",
      "and TokenFlow [9] use the typical DDIM image inversion\n",
      "to invert a video without any temporal modeling. Tune-A-\n",
      "Video [46] and FateZero [30] adopt a na ¬®ƒ±ve spatial-temporal\n",
      "DDIM inversion, which inflates the 2D UNet of the Stable\n",
      "Diffusion to incorporate multiple frames for each frame in-\n",
      "version. To achieve acceptable complexity, each frame only\n",
      "explores the spatial-temporal context of two frames in total,\n",
      "providing rough temporal modeling.\n",
      "In contrast to previous methods, this paper aims at\n",
      "an accurate inversion for better reconstruction and edit-\n",
      "ing ability. Specifically, we propose an efficient video\n",
      "inversion method, dubbed Spatial- Temporal Expectation-\n",
      "Maximization (STEM) inversion. Instead of regarding all\n",
      "pixels in a video as the reconstruction bases [24], we lever-\n",
      "age the EM [4] algorithm to find a more compact basis set\n",
      "(e.g., 256 bases). Here, we treat the low-rank bases as the\n",
      "parameter to learn and the responsibility of each base as the\n",
      "latent variables in the EM algorithm. During each iteration,\n",
      "the E step in the proposed STEM inversion tries to calcu-\n",
      "late the expectation of latent variables (responsibility) while\n",
      "the M step updates the parameters (bases). The algorithm\n",
      "would ach\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Multiplier Optimization via E-Graph Rewriting\n",
      "Andy Wanna1, Samuel Coward1,2, Theo Drane2, George A. Constantinides1and Milo Àás D. Ercegovac3\n",
      "1Imperial College London,2Intel Corporation,3University of California, Los Angeles\n",
      "Email: {andy.wanna20, s.coward21, g.constantinides }@imperial.ac.uk, theo.drane@intel.com, milos@cs.ucla.edu\n",
      "Abstract ‚ÄîMultiplier circuits account for significant resource\n",
      "usage in datapath-dominated circuit designs, and RTL designers\n",
      "continue to build bespoke hand-crafted multiplication arrays for\n",
      "their particular application. The construction of an optimized\n",
      "multiplier presents trade-offs between pre-processing to generate\n",
      "a smaller array and array reduction. A data structure known as\n",
      "an e-graph has recently been applied to datapath optimization,\n",
      "where the e-graph‚Äôs ability to efficiently explore trade-offs has\n",
      "been shown to be crucial. We propose an e-graph based rewriting\n",
      "framework to construct optimized multiplier circuits. Such a\n",
      "framework can express alternative multiplier representations and\n",
      "generate customized circuit designs. We demonstrate that the\n",
      "proposed tool, which we call OptiMult, can reduce the latency\n",
      "of a squarer by up to 46% and reduce the latency of a standard\n",
      "multiplier by up to 9% when compared against logic synthesis\n",
      "instantiated components.\n",
      "Index Terms ‚ÄîMultiplier, Datapath, E-graph\n",
      "I. I NTRODUCTION\n",
      "Multiplication circuits consist of three stages: array creation,\n",
      "array reduction and a final carry-propagate adder. We re-\n",
      "consider these boundaries, blurring the line between array\n",
      "reduction and carry-propagation. The most common array\n",
      "creation approaches deploy AND arrays or Booth encoding at\n",
      "various radices [1], [2]. Array reduction is typically achieved\n",
      "via compressor cells that sum columns of bits [1], [3], or\n",
      "reduce nrows to mrows, where m < n . Commonly used\n",
      "reduction schemes are the Wallace tree [4] and Dadda tree [5].\n",
      "High-level and logic synthesis tools automatically replace\n",
      "a‚àóbin source code with optimized components, but rely on\n",
      "fixed architectures and logic synthesis gate-level optimization.\n",
      "Automated techniques for compressor tree synthesis have\n",
      "explored both heuristic based search methods and integer\n",
      "linear programming [6], [7].\n",
      "We propose an automated rewriting framework helping RTL\n",
      "designers to explore bespoke multiplier implementations. The\n",
      "framework is based on the e(quivalence)-graph data struc-\n",
      "ture that efficiently explores equivalent designs by cluster-\n",
      "ing equivalent sub-expressions into e(quivalence)-classes. This\n",
      "clustering into e-classes captures the notion that there are\n",
      "many equivalent implementations of a given sub-graph in a\n",
      "dataflow graph. The e-graph is grown via constructive rewrite\n",
      "application, meaning that the left-hand side of the rewrite is\n",
      "retained rather than replaced. E-graphs have recently been\n",
      "successfully applied to datapath optimization [8]‚Äì[10].\n",
      "Typical e-graph optimization tools explore a single e-graph,\n",
      "however this is not scalable for many applications. Prior\n",
      "work has proposed sketch-guided equality saturation [11],\n",
      "where intermediate sketches enable e-graph contraction andre-initialization. We modify such an approach by encoding\n",
      "intermediate e-graph optimization phases in a sequence of cost\n",
      "models. We have developed a multiplication circuit optimizer,\n",
      "OptiMult, based on the extensible e-graph library, egg [12],\n",
      "targeting minimal latency circuits. This paper contains the\n",
      "following novel contributions:\n",
      "‚Ä¢application of e-graphs to gate-level component design,\n",
      "‚Ä¢a multi-level and iterative e-graph optimization method,\n",
      "‚Ä¢a dual representation of AND arrays enabling the appli-\n",
      "cation of column-wise and row-wise optimizations,\n",
      "‚Ä¢expression of multiplier optimizations as a set of local\n",
      "equivalence-preserving rewrites.\n",
      "II. M ETHODOLOGY\n",
      "The approach is separated into three key contributions.\n",
      "First we describe the representations that make multiplier\n",
      "design amenable to rewriting. Next we describe how multiplier\n",
      "optimization can be decomposed into a collection of local\n",
      "equivalence preserving rewrites. Lastly, we address scalability,\n",
      "taking inspiration from compilers [13], and separating opti-\n",
      "mization into a set of passes.\n",
      "A. Multiplier Representation\n",
      "In this work an input multiplier expressed as a simple ‚àó\n",
      "operator, is initially mapped to an AND array. The AND array\n",
      "is represented as an e-graph, where each node is either an\n",
      "operator connected by edges to its children or a variable/con-\n",
      "stant. The internal representation supports the basic logical\n",
      "operators, addition of bits and several specialized operators.\n",
      "Therow operator is equivalent to a concatenation of its\n",
      "children. The sum operator computes the addition of rows,\n",
      "where each row may represent a multi-bit number. Figure 1\n",
      "depicts these different representations in both an e-graph and\n",
      "as an array for a 2-bit multiplier, {p1, p0}‚àó{q1, q0}, where pi\n",
      "andqiare single bits. The rewrites described in Section II-B\n",
      "encode the transitions between these two representations and\n",
      "highlight \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Finding Concept Representations\n",
      "in Neural Networks with Self-Organizing Maps\n",
      "Mathieu d‚ÄôAquin\n",
      "mathieu.daquin@loria.fr\n",
      "LORIA, Universit√© de Lorraine/CNRS/INRIA\n",
      "Nancy, France\n",
      "ABSTRACT\n",
      "In sufficiently complex tasks, it is expected that as a side effect of\n",
      "learning to solve a problem, a neural network will learn relevant\n",
      "abstractions of the representation of that problem. This has been\n",
      "confirmed in particular in machine vision where a number of works\n",
      "showed that correlations could be found between the activations of\n",
      "specific units (neurons) in a neural network and the visual concepts\n",
      "(textures, colors, objects) present in the image. Here, we explore the\n",
      "use of self-organizing maps as a way to both visually and computa-\n",
      "tionally inspect how activation vectors of whole layers of neural\n",
      "networks correspond to neural representations of abstract concepts\n",
      "such as ‚Äòfemale person‚Äô or ‚Äòrealist painter‚Äô. We experiment with\n",
      "multiple measures applied to those maps to assess the level of rep-\n",
      "resentation of a concept in a network‚Äôs layer. We show that, among\n",
      "the measures tested, the relative entropy of the activation map for\n",
      "a concept compared to the map for the whole data is a suitable\n",
      "candidate and can be used as part of a methodology to identify\n",
      "and locate the neural representation of a concept, visualize it, and\n",
      "understand its importance in solving the prediction task at hand.\n",
      "CCS CONCEPTS\n",
      "‚Ä¢Computing methodologies ‚ÜíArtificial intelligence ;Neural\n",
      "networks ;Knowledge representation and reasoning .\n",
      "KEYWORDS\n",
      "Neural networks, conceptual representation, neuro-symbolic AI\n",
      "ACM Reference Format:\n",
      "Mathieu d‚ÄôAquin. 2023. Finding Concept Representations in Neural Net-\n",
      "works with Self-Organizing Maps. In Knowledge Capture Conference 2023\n",
      "(K-CAP ‚Äô23), December 5‚Äì7, 2023, Pensacola, FL, USA. ACM, New York, NY,\n",
      "USA, 8 pages. https://doi.org/10.1145/3587259.3627551\n",
      "1 INTRODUCTION\n",
      "It has now been clearly established that neural networks represent\n",
      "an effective, popular, and highly applicable approach to data-centric\n",
      "artificial intelligence, but that one of their key disadvantages is their\n",
      "interpretability [ 11]. They lack transparency in the sense that, even\n",
      "if one can inspect their inner working, a meaningful understanding\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for components of this work owned by others than the\n",
      "author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\n",
      "republish, to post on servers or to redistribute to lists, requires prior specific permission\n",
      "and/or a fee. Request permissions from permissions@acm.org.\n",
      "K-CAP ‚Äô23, December 5‚Äì7, 2023, Pensacola, FL, USA\n",
      "¬©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n",
      "ACM ISBN 979-8-4007-0141-2/23/12. . . $15.00\n",
      "https://doi.org/10.1145/3587259.3627551of the relation between the (sometimes extremely large) vectors of\n",
      "weights and activations in the network and the conclusion being\n",
      "made is rarely achievable. However, some form of implicit repre-\n",
      "sentation of abstract notions, conceptual knowledge, is expected to\n",
      "exist within those vectors to support the task at hand [ 2]. For ex-\n",
      "ample, in a previous work [ 9], we could see that there was a strong\n",
      "relationship between the results of neural networks and the pres-\n",
      "ence concepts extracted from a knowledge graph in the input data,\n",
      "showing, for example, that a network appeared to rely on knowl-\n",
      "edge of the country of origin or artistic movement of a painter to\n",
      "predict whether their work was exposed in major museums.\n",
      "In this paper, we aim to explore a methodology to identify and\n",
      "locate the representation of conceptual knowledge directly within\n",
      "a neural network‚Äôs layers, to find for example whether the concepts\n",
      "of ‚ÄòItalian painters‚Äô or ‚Äôsurealist painters‚Äô are actually present in\n",
      "the activation vectors of the network. In other words, we aim to\n",
      "propose a way to inspect those vectors so that they can be visually\n",
      "and computationally assessed and compared when presented with\n",
      "input data exemplifying different concepts. This can help to under-\n",
      "stand the importance, direct or indirect, of certain concepts in the\n",
      "decision and where the representation of those concepts might be\n",
      "located in the network. This is helpful in order to not only make\n",
      "the neural network more interpretable and communicable, but also\n",
      "to potentially identify biases in the data and in the way the network\n",
      "exploits the data. Indeed, in such cases, we can see biases as the\n",
      "use of information that should not be relevant to make a decision.\n",
      "By identifying a supposedly irrelevant concept that is implicitly\n",
      "represented in a neural network and how close the representation\n",
      "of such a concept is to the decision taken (i.e., to the output layer),\n",
      "we can therefore get an idea of the level at\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Noname manuscript No.\n",
      "(will be inserted by the editor)\n",
      "Software issues report for bug fixing process: An empirical study\n",
      "of machine-learning libraries.\n",
      "Ajibode Adekunle ¬∑Yunwei Dong‚àó¬∑Hongji Yang\n",
      "Received: date / Accepted: date\n",
      "Abstract Issue resolution and bug-fixing processes are essential in the development of machine-\n",
      "learning libraries, similar to software development, to ensure well-optimized functions. Understand-\n",
      "ing the issue resolution and bug-fixing process of machine-learning libraries can help developers\n",
      "identify areas for improvement and optimize their strategies for issue resolution and bug-fixing.\n",
      "However, detailed studies on this topic are lacking. Therefore, we investigated the effectiveness of is-\n",
      "sue resolution for bug-fixing processes in six machine-learning libraries: Tensorflow, Keras, Theano,\n",
      "Pytorch, Caffe, and Scikit-learn. We addressed seven research questions (RQs) using 16,921 issues\n",
      "extracted from the GitHub repository via the GitHub Rest API. We employed several quanti-\n",
      "tative methods of data analysis, including correlation, OLS regression, percentage and frequency\n",
      "count, and heatmap to analyze the RQs. We found the following through our empirical investiga-\n",
      "tion: (1) The most common categories of issues that arise in machine-learning libraries are bugs,\n",
      "documentation, optimization, crashes, enhancement, new feature requests, build/CI, support, and\n",
      "performance. (2) Effective strategies for addressing these problems include fixing critical bugs, op-\n",
      "timizing performance, and improving documentation. (3) These categorized issues are related to\n",
      "testing and runtime and are common among all six machine-learning libraries. (4) Monitoring the\n",
      "total number of comments on issues can provide insights into the duration of the issues. (5) It is\n",
      "crucial to strike a balance between prioritizing critical issues and addressing other issues in a timely\n",
      "manner. Therefore, this study concludes that efficient issue-tracking processes, effective commu-\n",
      "nication, and collaboration are vital for effective resolution of issues and bug fixing processes in\n",
      "machine-learning libraries.\n",
      "Keywords machine-learning library, ¬∑issue-report, ¬∑bug-fixing process, ¬∑regression analysis, ¬∑\n",
      "bug-fixing metrics\n",
      "‚àóCorresponding author\n",
      "Ajibode Adekunle Akinjobi\n",
      "School of Software, Northwestern Polytechnical University, Xi‚Äôan, 710072, China\n",
      "E-mail: damajibode@gmail.com\n",
      "Yunwei Dong\n",
      "School of Computer Science, Northwestern Polytechnical University, Xi‚Äôan 710072, China\n",
      "E-mail: yunweidong@nwpu.edu.cn\n",
      "Hongji Yang\n",
      "School of Computing and Mathematical Sciences, Leicester University, Leicester, UK\n",
      "E-mail: hongji.yang@leicester.ac.ukarXiv:2312.06005v1  [cs.SE]  10 Dec 20232 Ajibode Adekunle et al.\n",
      "1 Introduction\n",
      "Software development and maintenance are critical activities of the modern software industry.\n",
      "Software systems must be developed, maintained, and updated to meet the evolution requirements\n",
      "of users and businesses goals. However, software development and maintenance are not without\n",
      "challenges, one of which is the issue of software bugs (Saha et al., 2015).\n",
      "Similarly, machine-learning libraries are also developed and maintained like other software, and\n",
      "have become increasingly popular in recent years as a way to simplify the development of machine-\n",
      "learning applications. These libraries provide pre-built algorithms and functions that can be easily\n",
      "integrated into software applications. However, like any software system, machine-learning libraries\n",
      "are not immune to bugs and issues (Nguyen et al., 2019).\n",
      "To address the issue of bugs and general issues in machine-learning libraries, it is essential to\n",
      "have an effective issues resolution and bug fixing process (Thung et al., 2012). An issues report\n",
      "is an important component of the bug fixing process (Guo et al., 2011, Goyal and Sardana, 2019,\n",
      "Zhang et al., 2015). It provides a comprehensive overview of the issues and bugs in the software\n",
      "system, enabling developers to prioritize and fix them.\n",
      "These issues are reported in different repositories, such as GitHub, in a form of tickets or issues,\n",
      "which typically include a description of the problem, steps to reproduce the issue, and any relevant\n",
      "code or data. Users can also add comments and discuss possible solutions or workarounds.\n",
      "GitHub is an online platform used for collaborative software development and version control,\n",
      "currently holds the distinction of being the largest host of open-source software in the world. In\n",
      "the year 2018, the platform saw the creation of approximately one third of its total 96 million\n",
      "repositories, indicating the platform‚Äôs continued growth and significance as a resource for open-\n",
      "source software development (Brisson et al., 2020).\n",
      "Bug fixing process refers to the steps taken to identify and resolve software defects, with the goal\n",
      "of improving the quality and reliability of the software. This process involve activities such as bug\n",
      "detection, analysis, isolation, and correction, and may be influenced by \n",
      "----------------------------------------------------------------------------------------------------\n",
      "M. d‚ÄôAquin / TaBIIC\n",
      "TaBIIC: Taxonomy Building through\n",
      "Iterative and Interactive Clustering\n",
      "Mathieu D‚ÄôAQUINa,1,\n",
      "aK Team, LORIA CNRS/INRIA/Universit ¬¥e de Lorraine, Nancy, France\n",
      "ORCiD ID: Mathieu d‚ÄôAquin https://orcid.org/0000-0001-7276-4702\n",
      "Abstract. Building taxonomies is often a significant part of building an ontology,\n",
      "and many attempts have been made to automate the creation of such taxonomies\n",
      "from relevant data. The idea in such approaches is either that relevant definitions\n",
      "of the intension of concepts can be extracted as patterns in the data (e.g. in formal\n",
      "concept analysis) or that their extension can be built from grouping data objects\n",
      "based on similarity (clustering). In both cases, the process leads to an automatically\n",
      "constructed structure, which can either be too coarse and lacking in definition, or\n",
      "too fined-grained and detailed, therefore requiring to be refined into the desired\n",
      "taxonomy. In this paper, we explore a method that takes inspiration from both ap-\n",
      "proaches in an iterative and interactive process, so that refinement and definition of\n",
      "the concepts in the taxonomy occur at the time of identifying those concepts in the\n",
      "data. We show that this method is applicable on a variety of data sources and leads\n",
      "to taxonomies that can be more directly integrated into ontologies.\n",
      "Keywords. Applications and Methods, bottom-up ontology construction, taxonomies\n",
      "1. Introduction\n",
      "Taxonomies are an integral part of ontologies, whether they represent an aspect of\n",
      "highly axiomatized ontologies in OWL [13], or simpler concept structures such as those\n",
      "constructed using SKOS [14]. While ontology building methodologies (see, for exam-\n",
      "ple, [9,19,20]) focus on identifying and defining core concepts, understanding how to\n",
      "hierarchically divide such concepts is often not trivial and is not as well covered by those\n",
      "methodologies. In addition, when the aim is to use such a taxonomy to classify entities\n",
      "into the corresponding categories from existing data, it is important to ensure that the\n",
      "definitions of concepts and subconcepts align well with the attributes and groups that\n",
      "exist in the data, as well as with what is meaningful in the domain.\n",
      "For these reasons, some of the tools aiming to support ontology building have fo-\n",
      "cused on (semi)automatic ways to construct such taxonomies in a bottom-up manner,\n",
      "that is, from existing data. We describe such works in more detail in the following sec-\n",
      "tion, focusing on approaches taking structured data as input (i.e., ignoring the many ap-\n",
      "proaches building taxonomies from text). In summary, however, depending on the spe-\n",
      "cific technique applied, those approaches suffer from a number of drawbacks that signifi-\n",
      "cantly limit their applicability. Some, for example, are constrained to using only nominal\n",
      "1Corresponding Author: Mathieu d‚ÄôAquin, e-mail: mathieu.daquin@loria.frarXiv:2312.05866v1  [cs.AI]  10 Dec 2023M. d‚ÄôAquin / TaBIIC\n",
      "data as input and come up with very large and complex hierarchies that require to be\n",
      "pruned. Others rely on grouping data objects together, coming up with flat structures, or\n",
      "hierarchies and definitions that are difficult to reconnect with intensional definitions of\n",
      "concepts.\n",
      "Taking inspiration from these techniques, we explore here the use of an iterative\n",
      "and interactive method for building taxonomies from data. The idea is to enable the user\n",
      "to edit and label subconcepts in the taxonomy as they are being created, therefore, en-\n",
      "suring that what is created is aligned with both the domain and the data. We describe\n",
      "the principles and implementation of a tool called TaBIIC (Taxonomy Building through\n",
      "Interactive and Iterative Clustering) and show how it applies to a variety of data inputs\n",
      "to create taxonomies that match the user‚Äôs view of the domain, are ready (compatible in\n",
      "format and structure) for integration in ontologies, and are aligned with the source data.\n",
      "In the following (Section 3) we consider common approaches to building tax-\n",
      "onomies from structured data. The form of structured data and of the taxonomies created\n",
      "can vary from one approach to the other, even if similarities exist. Therefore, we first\n",
      "introduce some notation and elements of vocabulary in relation to datasets and concept\n",
      "taxonomies (inspired by formal concept analysis and description logics) that can be used\n",
      "as a shared framework to describe existing work.\n",
      "2. Preliminaries\n",
      "As mentioned above, we consider the semiautomatic construction of taxonomies from\n",
      "structured data. Although structured data can come in a wide variety of shapes and for-\n",
      "mats, we restrict ourselves to a common and widely available one: data tables or data\n",
      "frames.\n",
      "Definition 1 (Dataset) A dataset D = (O,A)is defined as a set of objects O (lines),\n",
      "described through a list of attributes A (columns). Each object o ‚ààO is described as a\n",
      "vector of size |A|of values for each attribute a ‚ààA.\n",
      "At this stage, the definition of datasets is relatively unconstrained. In particular, there\n",
      "is no restriction on the types of the\n",
      "----------------------------------------------------------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Guardians of Trust: Navigating Data Security in AIOps through Vendor \n",
      "Partnerships \n",
      "Subhadip, Kumar* \n",
      "Western Governors University, skuma19@wgu.edu \n",
      "Artificial Intelligence for IT Operations (AIOps) is a rapidly growing field that applies artificial intelligence and machine learning to \n",
      "automate and optimize IT operations. AIOps vendors provide services that ingest end-to-end logs, traces, and metrics to offer a full stack \n",
      "observability of IT systems. However, these data sources may contain sensitive information such as internal IP addresses, hostnames, \n",
      "HTTP headers, SQLs, method/argument return values, URLs, personal identifiable information (PII), or confidential business data. \n",
      "Therefore, data security is a crucial concern when working with AIOps vendors. In this article, we will discuss the security features offered \n",
      "by different vendors and how we can adopt best practices to ensure data protection and privacy. \n",
      "Additional Keywords and Phrases:  AIOps, Cyber Security, AI Security  \n",
      "1 INTRODUCTION \n",
      "AIOps, or Artificial Intelligence for IT Operations, is a new approach that leverages machine learning and automation to \n",
      "enhance the observability and reliability of complex software systems. Observability is the ability to monitor and \n",
      "understand the internal state of a system or application based on the external outputs, such as logs, metrics, and traces. \n",
      "Several vendors offer full stack observability, monitor security vulnerabilities, automations, actionable alerts, and \n",
      "insights. These vendors ingest customers‚Äô logs, traces and metrices to produce actionable insights and recommendations \n",
      "that help SREs, and developers achieve full stack observability and improve the quality and efficiency of their software \n",
      "delivery. Security is a big concern when these vendors ingest customer data such as logs, metrices and traces as they \n",
      "consist sensitive information such as IP addresses, client details and their personal information‚Äôs even confidential \n",
      "business data. Also, when this data is in transit or at rest, vendors ensure that the data is protected from being exposed. \n",
      "Security is always a joint responsibility that requires the participation and contribution of all stakeholders to create a safe \n",
      "and secure environment for everyone. In this article, we will discuss about different AIOps vendors and their security \n",
      "features. However, AIOps also poses some security challenges, such as data privacy, access control, and compliance. \n",
      "Therefore, it is important to choose an AIOps vendor that can provide robust and reliable security solutions. Different \n",
      "AIOps vendors have different standards and approaches to meet security standards. In this article, we will discuss in \n",
      "detail about those security measures and how a customer can leverage them and develop a best practice. \n",
      "We will also discuss about how the vendors ingest customer data, encryption in transit and in rest from customers‚Äô \n",
      "system to vendor, in product communications, masking of sensitive information‚Äôs and PII. Will also discuss how to \n",
      "protect the data using RBAC (Role based access control) and masking to ensure minimum exposure in case of a data \n",
      "breach. \n",
      " \n",
      " \n",
      "* Place the footnote text for the author (if applicable) here.  2 2 TYPE OF DATA COLLECTED \n",
      " \n",
      "AIOps can help IT teams monitor, analyze, and troubleshoot complex systems, as well as improve service quality and \n",
      "customer satisfaction. However, AIOps also involves collecting and processing logs, metrics and traces which contains a \n",
      "large amount of sensitive data, such as client IP addresses, HTTP headers, HTTP post parameters, URL query parameters, \n",
      "SQL bind variables, SQL statements, personally identifiable information (PII), and more. This data can reveal a lot of \n",
      "information about the users, their behavior, their preferences, and their identity. If this data is not protected properly, it can \n",
      "lead to a serious data breach, which can have legal, financial, and reputational consequences for both the IT service provider \n",
      "and the users. Therefore, it is essential to implement appropriate security measures to protect the data at every stage of its \n",
      "lifecycle, from capture, to transit, to storage, to display. \n",
      "3 DATA COLLECTION AGENT BY VENDOR AND AGENT SECURITY \n",
      "3.1 DATA COLLECTION AGENT BY VENDOR \n",
      "Most of the vendors deploy a single agent to collect data from remote sources and forward that to vendor‚Äôs instance.  \n",
      "Some examples include: \n",
      "- Splunk has three types of forwarders aka agent ‚Äì Universal forwarder, heavy forwarder, and light forwarder \n",
      "[1]. Out of that universal forwarder is the most popular one. Universal forwarder handles all kinds of data ‚Äì \n",
      "starting from Microsoft Windows event logs, webserver logs, change logs, archive files etc. \n",
      "- Dynatrace uses OneAgent ‚Äì a single agent per host that collects all relevant metrics along with 100% of your \n",
      "application-delivery chain. \n",
      "- AppDynamics uses different agents by application type ‚Äì Java/.Net/Python/SAP are f\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Fast Internet Computer Consensus\n",
      "Massimo Albarello\n",
      "malbarello@student.ethz.ch\n",
      "ETH Zurich\n",
      "SwitzerlandJakub Sliwinski\n",
      "jsliwinski@ethz.ch\n",
      "ETH Zurich\n",
      "Switzerland\n",
      "Yann Vonlanthen‚àó\n",
      "yvonlanthen@ethz.ch\n",
      "ETH Zurich\n",
      "SwitzerlandRoger Wattenhofer\n",
      "wattenhofer@ethz.ch\n",
      "ETH Zurich\n",
      "Switzerland\n",
      "Abstract\n",
      "This paper presents the first rotating leader state machine\n",
      "replication (SMR) protocol that allows transactions to be\n",
      "confirmed in just a single round-trip time in the Byzantine\n",
      "fault tolerance (BFT) setting. Based on minimal alterations\n",
      "to the Internet Computer Consensus (ICC) protocol and with\n",
      "negligible communication overhead, we introduce a novel\n",
      "dual mode mechanism that enables optimal block finalization\n",
      "latency in the fast path. Crucially, the modes of operation are\n",
      "integrated, such that even if the fast path is not effective, no\n",
      "penalties are incurred. Moreover, our algorithm maintains\n",
      "the core attributes of the original ICC protocol, including\n",
      "optimistic responsiveness and rotating leaders without the\n",
      "necessity for a view-change protocol.\n",
      "We prove the correctness of our Fast Internet Computer\n",
      "Consensus (FICC) protocol and provide an open-source im-\n",
      "plementation of it. Both the FICC and original ICC protocol\n",
      "are compared in a globally distributed wide-area network.\n",
      "Our evaluation reveals that the FICC protocol achieves re-\n",
      "duced latency compared to the ICC protocol, without re-\n",
      "quiring additional security assumptions. Furthermore, by\n",
      "increasing the number of replicas to ùëõ=5ùëì+1, we exhibit\n",
      "that latency improvements close to the theoretical maxi-\n",
      "mum of 33% are attainable. We conclude by highlighting the\n",
      "network topology as a significant factor in evaluating and\n",
      "comparing the latency of consensus algorithms.\n",
      "CCS Concepts: ‚Ä¢Security and privacy ‚ÜíDistributed\n",
      "systems security ;‚Ä¢Applied computing ‚ÜíSecure online\n",
      "transactions .\n",
      "Keywords: state machine replication, consensus, byzantine\n",
      "fault tolerance, blockchain, fast path\n",
      "1 Introduction\n",
      "Byzantine fault tolerance (BFT) is a class of protocols that\n",
      "provide guarantees in the presence of arbitrary faults, such\n",
      "as a powerful adversary controlling both a share of partici-\n",
      "pants and the network scheduling [ 42]. BFT protocols can\n",
      "be applied whenever a fixed (also called permissioned) set\n",
      "of untrusted parties desires to reach an agreement.\n",
      "‚àóCorresponding Author.Popularized by Bitcoin [ 49], Ethereum [ 15] and other dig-\n",
      "ital currencies, protocols that tolerate an open set of partic-\n",
      "ipants have emerged. This has not lessened interest in the\n",
      "permissioned setting, however, as their approaches are often\n",
      "based on advancements from permissioned counterparts (see\n",
      "Ethereum‚Äôs Casper [16] and Algorand [33] for instance).\n",
      "The practicality of these systems has been shown in the\n",
      "context of finance and digital art [ 22,44,50,58], but other\n",
      "promising applications such as file storage, social media,\n",
      "governance, and democracy have emerged [ 29,31,57,59].\n",
      "In essence, BFT protocols can be applied whenever multiple\n",
      "parties desire to perform some computation, without trusting\n",
      "any set of participants fully.\n",
      "These decentralized systems are not unlike a decentralized\n",
      "world computer, enabling anyone to run Turing-complete\n",
      "programs. Various such world computers exist today [ 10,15,\n",
      "28,31], with varying trade-offs regarding performance, secu-\n",
      "rity, and inclusiveness. At each system‚Äôs core, lays an order-\n",
      "ing protocol assuring that resource accesses are consistent\n",
      "across all participants (called replicas), thus guaranteeing\n",
      "deterministic and secure execution of the computation.\n",
      "Byzantine agreement (BA) protocols typically provide con-\n",
      "sensus on a single decision, while state machine replication\n",
      "protocols (SMR) focus on making efficient use of this costly\n",
      "primitive. In practice, the most widely used SMR protocols\n",
      "(such as Bitcoin [ 49], Ethereum [ 15], and Algorand [ 33])\n",
      "make use of an elected leader to propose a batch of trans-\n",
      "actions, called a block. A total order across leaders is then\n",
      "obtained by chaining blocks.\n",
      "There are a few considerations that are especially crucial\n",
      "to such leader-based protocols. Firstly, leaders can misbehave\n",
      "and propose conflicting blocks. While this can be detected,\n",
      "the resulting change of the leader (called view-change in the\n",
      "literature) leads to notoriously high complexity. Honest, but\n",
      "slow leaders are just as problematic, as they cannot easily be\n",
      "called out, but can stall the effective throughput nonetheless\n",
      "[21].\n",
      "Moreover, relying on a single leader leads to uneven load,\n",
      "both in terms of computation and communication [ 23]. Fi-\n",
      "nally, leaders can sometimes extract value from their control\n",
      "of the block creation. On the Ethereum blockchain for ex-\n",
      "ample, miner-extractable value (MEV) is a major source ofarXiv:2312.05869v1  [cs.DC]  10 Dec 2023M. Albarello, J. Sliwinski, Y. Vonlanthen, R. Wattenhofer\n",
      "Figure 1. The FICC protocol can terminate after just two\n",
      "communication steps. Existing rotating leader SMR protocols\n",
      "require at least three communication steps.\n",
      "income for replicas \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "A Practical Survey on Emerging Threats from\n",
      "AI-driven V oice Attacks: How Vulnerable are\n",
      "Commercial V oice Control Systems?\n",
      "Yuanda Wang, Qiben Yan, Nikolay Ivanov, and Xun Chen\n",
      "Abstract ‚ÄîThe emergence of Artificial Intelligence (AI)-driven\n",
      "audio attacks has revealed new security vulnerabilities in voice\n",
      "control systems. While researchers have introduced a multitude\n",
      "of attack strategies targeting voice control systems (VCS), the\n",
      "continual advancements of VCS have diminished the impact\n",
      "of many such attacks. Recognizing this dynamic landscape,\n",
      "our study endeavors to comprehensively assess the resilience of\n",
      "commercial voice control systems against a spectrum of malicious\n",
      "audio attacks. Through extensive experimentation, we evaluate\n",
      "six prominent attack techniques across a collection of voice\n",
      "control interfaces and devices. Contrary to prevailing narratives,\n",
      "our results suggest that commercial voice control systems exhibit\n",
      "enhanced resistance to existing threats. Particularly, our research\n",
      "highlights the ineffectiveness of white-box attacks in black-box\n",
      "scenarios. Furthermore, the adversaries encounter substantial\n",
      "obstacles in obtaining precise gradient estimations during query-\n",
      "based interactions with commercial systems, such as Apple Siri\n",
      "and Samsung Bixby. Meanwhile, we find that current defense\n",
      "strategies are not completely immune to advanced attacks.\n",
      "Our findings contribute valuable insights for enhancing defense\n",
      "mechanisms in VCS. Through this survey, we aim to raise\n",
      "awareness within the academic community about the security\n",
      "concerns of VCS and advocate for continued research in this\n",
      "crucial area.\n",
      "Index Terms ‚ÄîVoice control system, Speech recognition,\n",
      "Speaker verification, Adversarial examples\n",
      "I. I NTRODUCTION\n",
      "V oice control systems (VCS) have transformed the way\n",
      "users interact with computers by enabling interactions through\n",
      "natural language and voice commands. Conventionally, users\n",
      "can transmit speech audio to online automatic speech recog-\n",
      "nition (ASR) service platforms, which in turn offer the cor-\n",
      "responding text translations. Meanwhile, the development of\n",
      "deep learning has greatly advanced VCS technology, leading\n",
      "to more accurate speech recognition and natural language\n",
      "processing. As a result, the global VCS market is projected to\n",
      "reach a staggering 95.41 billion dollars by 2030 [1], indicating\n",
      "the immense potential and demand for this technology. To opti-\n",
      "mize user experience and improve efficiency, VCS technology\n",
      "has been integrated into a wide variety of applications, such\n",
      "as smart devices, Internet of Things (IoT), and automobile\n",
      "systems. By allowing users to access information and control\n",
      "devices more conveniently, VCS offers an intuitive and seam-\n",
      "less human-computer interaction solution.\n",
      "However, existing research has revealed that AI models,\n",
      "particularly those based on deep neural network (DNN) archi-\n",
      "tectures, are susceptible to a range of attacks. The vulnerability\n",
      "in DNNs has subsequently extended to AI-based VCS. Toinvestigate the robustness of VCS, it is imperative to have a\n",
      "thorough understanding the impacts of the diverse attacks and\n",
      "their respective defenses in real-world scenarios. In this work,\n",
      "we identify four major research gaps that hinder the execution\n",
      "of successful practical attacks on commercial VCS.\n",
      "Gap 1: Generic Black-box Attacks. Most adversarial attacks\n",
      "adopt a white-box setup, which leverages gradient descent\n",
      "optimization to generate adversarial examples (AEs). This\n",
      "implies that adversaries require complete knowledge of the\n",
      "models within the VCS. However, this assumption may not\n",
      "hold in real-world scenarios. Commercial VCS platforms, such\n",
      "as Apple Siri [2], Google Assistant [3], Amazon Alexa [4],\n",
      "and Samsung Bixby [5], are black-box systems, where the\n",
      "attackers could only access the final output for a given input.\n",
      "To address the challenges of black-box attacks, recent stud-\n",
      "ies have suggested that adversaries might optimize their AEs\n",
      "by querying the VCS to obtain an estimated gradient. However,\n",
      "this query-based gradient estimation approach has significant\n",
      "overheads. First, accurate gradient estimation demands a large\n",
      "number of queries ( ‚â•1000 ); thus, querying the VCS to\n",
      "craft effective AEs becomes costly. Second, to prevent abuse,\n",
      "API services tend to restrict excessive queries from a single\n",
      "user, adding another layer of complexity to the query-based\n",
      "gradient estimation process. Meanwhile, executing such black-\n",
      "box attacks still requires prior knowledge such as the device\n",
      "model and its API, which is sometimes unobtainable in real-\n",
      "world scenarios.\n",
      "Gap 2: Physical Adversarial Audio Transmission. The\n",
      "generation of AEs often overlooks the complexities of physical\n",
      "world signal transmission, rendering them frequently ineffec-\n",
      "tive in real-world settings during airborne transmission. On\n",
      "one hand, these perturbations experience energy loss during\n",
      "transmission, which reduces the attack‚Äôs success rate. On\n",
      "the other hand, AEs are susceptible to signal distortions in\n",
      "complex envi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "This work appears as a full paper in IEEE Conference on Computer Communications (INFOCOM) 2024.\n",
      "Optimization for the Metaverse over Mobile Edge\n",
      "Computing with Play to Earn\n",
      "Chang Liu1, Terence Jie Chua1, Jun Zhao2\n",
      "1Graduate College, Nanyang Technological University, Singapore\n",
      "2School of Computer Science & Engineering, Nanyang Technological University, Singapore\n",
      "E-mail: {liuc0063@e.ntu.edu.sg, terencej001@e.ntu.edu.sg, junzhao@ntu.edu.sg }\n",
      "Abstract ‚ÄîThe concept of the Metaverse has garnered growing\n",
      "interest from both academic and industry circles. The decen-\n",
      "tralization of both the integrity and security of digital items has\n",
      "spurred the popularity of play-to-earn (P2E) games, where players\n",
      "are entitled to earn and own digital assets which they may trade\n",
      "for physical-world currencies. However, these computationally-\n",
      "intensive games are hardly playable on resource-limited mobile\n",
      "devices and the computational tasks have to be offloaded to\n",
      "an edge server. Through mobile edge computing (MEC), users\n",
      "can upload data to the Metaverse Service Provider (MSP) edge\n",
      "servers for computing. Nevertheless, there is a trade-off between\n",
      "user-perceived in-game latency and user visual experience. The\n",
      "downlink transmission of lower-resolution videos lowers user-\n",
      "perceived latency while lowering the visual fidelity and conse-\n",
      "quently, earnings of users. In this paper, we design a method to\n",
      "enhance the Metaverse-based mobile augmented reality (MAR)\n",
      "in-game user experience. Specifically, we formulate and solve a\n",
      "multi-objective optimization problem. Given the inherent NP-\n",
      "hardness of the problem, we present a low-complexity algorithm\n",
      "to address it, mitigating the trade-off between delay and earnings.\n",
      "The experiment results show that our method can effectively bal-\n",
      "ance the user-perceived latency and profitability, thus improving\n",
      "the performance of Metaverse-based MAR systems.\n",
      "Index Terms ‚ÄîMetaverse, mobile edge computing, play-to-earn ,\n",
      "latency, wireless networks.\n",
      "I. I NTRODUCTION\n",
      "The Metaverse is a virtual environment on public blockchain\n",
      "technology where users create, share, and own digital assets,\n",
      "interacting through virtual avatars. Each world within the\n",
      "Metaverse has its own digital currency, facilitating economic\n",
      "activities like in-game purchases and virtual land acquisition.\n",
      "These digital tokens hold significant value, motivating peo-\n",
      "ple to play games to earn them [1]. With a growing trend\n",
      "towards digital activities and gaming [2], the combination of\n",
      "better games, AR/VR advancements, and the desire for asset\n",
      "ownership drives users to participate in play-to-earn (P2E)\n",
      "games within the Metaverse. This ownership of digital assets\n",
      "and tokens opens up opportunities for virtual world economies\n",
      "and trade [3].\n",
      "The Metaverse and its extended reality applications such\n",
      "as P2E present computation-intensive challenges for game\n",
      "graphics and gameplay [4], especially on current mobile\n",
      "device computing hardware with limited resources. To ensure\n",
      "a seamless real-to-world experience for users, scenes delivered\n",
      "by VR devices must have a minimal delay (within 20ms)\n",
      "and demand high bitrates up to Gbps for synchronization [5].\n",
      "To address this limitation, the convergence of MEC with the\n",
      "Metaverse gives rise to a new generation of MEC-empoweredMetaverse [6]. This integration prioritizes enhancing real-\n",
      "time performance in virtual reality systems, system mobility,\n",
      "and ultra-reliability, leveraging the capabilities of B5G or 6G\n",
      "technologies.\n",
      "In the Metaverse system integrated with MEC, efficient\n",
      "communication is crucial for a seamless virtual world ex-\n",
      "perience. However, high-resolution graphics and large data\n",
      "transmission can lead to increased latency, affecting players‚Äô\n",
      "interactions and experiences in P2E games. Minimizing la-\n",
      "tency is vital to ensure player satisfaction and profitability.\n",
      "Lowering video resolution can reduce data size and latency, but\n",
      "it compromises graphic quality, impacting gameplay and token\n",
      "earnings. Balancing resolution and token earnings becomes a\n",
      "trade-off. Additionally, optimizing user-server association is\n",
      "necessary to address workload imbalance among edge servers,\n",
      "which can cause service latency issues. Developing an effec-\n",
      "tive user-server association strategy is essential for enhancing\n",
      "Metaverse service performance and reducing latency.\n",
      "In this paper, we identify a problem where MSP edge\n",
      "servers have limited resources for computation and commu-\n",
      "nication, limiting their ability to support a rapidly growing\n",
      "player base. In the absence of resource allocation regulation,\n",
      "players will always expect the best possible game environment\n",
      "in terms of quality and connectivity. However, this may not be\n",
      "feasible for a resource-limited MSP edge server. We present\n",
      "a framework for optimizing communication and computation\n",
      "that strikes a balance between the delay experienced by\n",
      "players and their in-game token earnings. This scheme aids the\n",
      "MSP in controlling transmission data and the association of\n",
      "players with MSP edge servers, while also \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "GenDepth: Generalizing Monocular Depth\n",
      "Estimation for Arbitrary Camera Parameters via\n",
      "Ground Plane Embedding\n",
      "Karlo Koledi ¬¥c, Luka Petrovi ¬¥c, Ivan Petrovi ¬¥c, Ivan Markovi ¬¥c1.\n",
      "Abstract ‚ÄîLearning-based monocular depth estimation leverages geometric priors present in the training data to enable metric depth\n",
      "perception from a single image, a traditionally ill-posed problem. However, these priors are often specific to a particular domain, leading\n",
      "to limited generalization performance on unseen data. Apart from the well studied environmental domain gap, monocular depth\n",
      "estimation is also sensitive to the domain gap induced by varying camera parameters, an aspect that is often overlooked in current\n",
      "state-of-the-art approaches. This issue is particularly evident in autonomous driving scenarios, where datasets are typically collected\n",
      "with a single vehicle-camera setup, leading to a bias in the training data due to a fixed perspective geometry. In this paper, we\n",
      "challenge this trend and introduce GenDepth, a novel model capable of performing metric depth estimation for arbitrary vehicle-camera\n",
      "setups. To address the lack of data with sufficiently diverse camera parameters, we first create a bespoke synthetic dataset collected\n",
      "with different vehicle-camera systems. Then, we design GenDepth to simultaneously optimize two objectives: (i) equivariance to the\n",
      "camera parameter variations on synthetic data, (ii) transferring the learned equivariance to real-world environmental features using a\n",
      "single real-world dataset with a fixed vehicle-camera system. To achieve this, we propose a novel embedding of camera parameters as\n",
      "the ground plane depth and present a novel architecture that integrates these embeddings with adversarial domain alignment. We\n",
      "validate GenDepth on several autonomous driving datasets, demonstrating its state-of-the-art generalization capability for different\n",
      "vehicle-camera systems.\n",
      "Index Terms ‚ÄîMonocular depth estimation, Domain generalization, Sim2real adaptation, Camera parameters, Autonomous driving,\n",
      "Ground plane\n",
      "‚ú¶\n",
      "1 I NTRODUCTION\n",
      "ACCURATE 3D perception is one of the fundamental\n",
      "challenges in computer vision, with numerous ap-\n",
      "plications in fields such as robotics, virtual reality and\n",
      "autonomous driving. Due to the depth ambiguity of the\n",
      "monocular camera systems, traditional approaches, includ-\n",
      "ing Structure-from-Motion or Visual SLAM, estimate 3D\n",
      "structure via subsequent correspondence matching and tri-\n",
      "angulation. However, these solutions are prone to errors\n",
      "in challenging conditions such as occlusions or textureless\n",
      "regions and also require a complicated setup with multi-\n",
      "sensor calibration.\n",
      "To remedy these issues, learning-based Monocular\n",
      "Depth Estimation (MDE) models use a large amount of\n",
      "data to directly regress per-pixel depth from a single image,\n",
      "usually by exploiting learnable semantic and geometric\n",
      "cues, such as the size of known objects or their position on\n",
      "the ground plane. These models are consequently heavily\n",
      "reliant upon environments and objects present in the train-\n",
      "ing data. Given that, supervised methods [1], [2], [3], [4],\n",
      "[5], [6], [7], [8], [9], which require expensive and rigorously\n",
      "obtainable ground-truth data, are often limited to a narrow\n",
      "distribution of environments, thereby adversely affecting\n",
      "the generalization performance. On the other hand, self-\n",
      "supervised methods [10], [11], [12], [13], [14], [15], [16],\n",
      "1Authors are with University of Zagreb Faculty of Electrical Engineering\n",
      "and Computing, Laboratory for Autonomous Systems and Mobile Robotics,\n",
      "Zagreb, Croatia {name.surname@fer.hr }.\n",
      "This research has been funded by the H2020 project AIFORS under Grant\n",
      "Agreement No 952275.[17] offer a promising alternative, by constructing a su-\n",
      "pervision signal via view synthesis of nearby frames. This\n",
      "alleviates the issue of ground-truth data acquisition and\n",
      "enables scalable deployment across diverse environments\n",
      "and scenarios.\n",
      "Self-supervised learning simplifies the gathering of data\n",
      "in various environments. However, the impact of different\n",
      "extrinsic and intrinsic camera parameters is frequently over-\n",
      "looked during testing. This issue is particularly evident in\n",
      "autonomous driving scenarios. In such cases, datasets are\n",
      "often collected with a single vehicle-camera setup, resulting\n",
      "in all images being captured from the same view relative to\n",
      "the ground plane. Models naturally overfit to this perspec-\n",
      "tive geometry bias in the training data and exhibit critical\n",
      "performance degradation when inferring depth for images\n",
      "captured with different vehicle-camera setups [19].\n",
      "The generation of synthetic data with diverse camera\n",
      "parameters, along with embedding of camera extrinsics [20],\n",
      "intrinsics [21] or focal length [22], has been proposed to\n",
      "solve this issue. However, these methods do not provide\n",
      "solutions that are applicable to a real-world scenario with\n",
      "an arbitrary vehicle-camera setup. Another line of work\n",
      "focuses on relative depth estimation [23], [24], [25], [26], [27],\n",
      "[28], [29], [\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Class-Aware Pruning for Efficient Neural Networks\n",
      "Mengnan Jiang1, Jingcun Wang1, Amro Eldebiky2, Xunzhao Yin3, Cheng Zhuo3, Ing-Chao Lin4, Grace Li Zhang1\n",
      "1TU Darmstadt,2TU Munich,3Zhejiang University4National Cheng Kung University\n",
      "Email: {mengnan.jiang, jingcun.wang, grace.zhang }@tu-darmstadt.de, amro.eldebiky@tum.de,\n",
      "xzyin1@zju.edu.cn, czhuo@zju.edu.cn, iclin@mail.ncku.edu.tw\n",
      "Abstract ‚Äî Deep neural networks (DNNs) have demonstrated\n",
      "remarkable success in various fields. However, the large number\n",
      "of floating-point operations (FLOPs) in DNNs poses challenges for\n",
      "their deployment in resource-constrained applications, e.g., edge\n",
      "devices. To address the problem, pruning has been introduced\n",
      "to reduce the computational cost in executing DNNs. Previous\n",
      "pruning strategies are based on weight values, gradient values\n",
      "and activation outputs. Different from previous pruning solutions,\n",
      "in this paper, we propose a class-aware pruning technique to\n",
      "compress DNNs, which provides a novel perspective to reduce\n",
      "the computational cost of DNNs. In each iteration, the neural\n",
      "network training is modified to facilitate the class-aware pruning.\n",
      "Afterwards, the importance of filters with respect to the number\n",
      "of classes is evaluated. The filters that are only important for\n",
      "a few number of classes are removed. The neural network is\n",
      "then retrained to compensate for the incurred accuracy loss. The\n",
      "pruning iterations end until no filter can be removed anymore,\n",
      "indicating that the remaining filters are very important for many\n",
      "classes. This pruning technique outperforms previous pruning\n",
      "solutions in terms of accuracy, pruning ratio and the reduction\n",
      "of FLOPs. Experimental results confirm that this class-aware\n",
      "pruning technique can significantly reduce the number of weights\n",
      "and FLOPs, while maintaining a high inference accuracy.\n",
      "I. Introduction\n",
      "Deep neural networks (DNNs) have achieved significant\n",
      "success in various fields, e.g., computer vision [1], and natural\n",
      "language processing [2]. However, their significant success\n",
      "comes with an increasing number of parameters and multiply-\n",
      "accumulate (MAC) operations as well as floating-point op-\n",
      "erations (FLOPs). For instance, ResNet-50, a widely used\n",
      "convolutional neural network for image classification, contains\n",
      "25.6 million parameters and requires approximately 4.1 billion\n",
      "MAC operations and thus 8.2 billion FLOPs to process an\n",
      "RGB image with 224 √ó224 pixels. The huge number of MAC\n",
      "operations and FLOPs prevents the application of DNNs in\n",
      "resource-constrained platforms, e.g., edge devices.\n",
      "To reduce the computational cost of DNNs, various tech-\n",
      "niques, e.g., pruning [3][4], quantization [5][6], and knowledge\n",
      "distillation [7][8], have been proposed at the software level.\n",
      "Pruning refers to the removal of unnecessary weights in DNNs\n",
      "according to a specific criterion. According to the granularity\n",
      "of pruning, it can be categorized into unstructured pruning and\n",
      "structured pruning. Unstructured pruning removes individual\n",
      "weights without considering their structures. For example,\n",
      "in [9], weights with small absolute values are pruned. [10]\n",
      "proposes a weight pruning technique that removes weights\n",
      "based on the product of weight values and their gradients. [11]\n",
      "adjusts the neural network training to punish the number of\n",
      "non-zero parameters, so that more weights can be reduced to\n",
      "zero after training. [12] iteratively prunes the weights that havelow products of the their values, gradients, and the second-\n",
      "order gradients.\n",
      "Unstructured pruning can achieve a high pruning rate.\n",
      "However, the weight matrix after unstructured pruning tends\n",
      "to be irregular, which is not efficient for digital hardware. To\n",
      "address this challenge, structured pruning has been introduced\n",
      "to prune groups of weights, such as filters [13], layers [14],\n",
      "or weight blocks, e.g., residual blocks in ResNet [15][16].\n",
      "Among structured pruning, filter-wise pruning is a widely\n",
      "used pruning technique since it provides a relatively fine\n",
      "granularity for compressing DNNs. To prune filters, criteria\n",
      "such as weights [17][18], activation outputs [19][20], gradients\n",
      "[21], and specific parameters [22] are usually used to guide\n",
      "the pruning process. For example, [23] remove the weight\n",
      "of filters based on their absolute values. [24] calculates the\n",
      "average percentage of zero activation outputs of filters and\n",
      "removes those filters that generate activation outputs with a\n",
      "large percentage of zeros. [25] prunes filters based on both\n",
      "activation outputs and their gradients.\n",
      "In this paper, we propose a class-aware pruning technique to\n",
      "compress DNNs. In this technique, we evaluate the importance\n",
      "of each filter with respect to the number of classes. By\n",
      "removing filters that are important for only a few classes,\n",
      "the number of FLOPs in DNNs can be reduced significantly\n",
      "while still maintaining high inference accuracy. The main\n",
      "contributions of this work are summarized as follows:\n",
      "‚Ä¢This paper proposes a class perspective to prune filters.\n",
      "Instead of using the values of weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1\n",
      "Exploiting Representation Bias for Data Distillation\n",
      "in Abstractive Text Summarization\n",
      "Yash Kumar Atri1, Vikram Goyal1, Tanmoy Chakraborty2\n",
      "1IIIT-Delhi, New Delhi, India;2IIT Delhi, New Delhi, India\n",
      "{yashk,vikram }@iiitd.ac.in; tanchak@iitd.ac.in\n",
      "Abstract ‚ÄîAbstractive text summarization is surging with the\n",
      "number of training samples to cater to the needs of the deep\n",
      "learning models. These models tend to exploit the training data\n",
      "representations to attain superior performance by improving\n",
      "the quantitative element of the resultant summary. However,\n",
      "increasing the size of the training set may not always be the ideal\n",
      "solution to maximize the performance, and therefore, a need to\n",
      "revisit the quality of training samples and the learning protocol\n",
      "of deep learning models is a must. In this paper, we aim to\n",
      "discretize the vector space of the abstractive text summarization\n",
      "models to understand the characteristics learned between the\n",
      "input embedding space and the models‚Äô encoder space. We show\n",
      "that deep models fail to capture the diversity of the input space.\n",
      "Further, the distribution of data points on the encoder space\n",
      "indicates that an unchecked increase in the training samples\n",
      "does not add value; rather, a tear-down of data samples is highly\n",
      "needed to make the models focus on variability and faithfulness.\n",
      "We employ clustering techniques to learn the diversity of a\n",
      "model‚Äôs sample space and how data points are mapped from the\n",
      "embedding space to the encoder space and vice versa. Further,\n",
      "we devise a metric to filter out redundant data points to make\n",
      "the model more robust and less data hungry. We benchmark\n",
      "our proposed method using quantitative metrics, such as Rouge,\n",
      "and qualitative metrics, such as BERTScore, FEQA and Pyramid\n",
      "score. We also quantify the reasons that inhibit the models from\n",
      "learning the diversity from the varied input samples.\n",
      "Impact Statement ‚ÄîIn the realm of abstractive text summa-\n",
      "rization, the surge in training data for deep learning models\n",
      "promises superior quantitative summary performance. However,\n",
      "blindly increasing the dataset size does not consistently yield\n",
      "optimal results. This necessitates a reevaluation of training\n",
      "sample quality and learning strategies. Our study dissects the\n",
      "vector space of abstractive text summarization models, revealing\n",
      "that deep models struggle to capture input space diversity.\n",
      "Furthermore, excessive training data fails to provide substantial\n",
      "value. We employ clustering techniques to understand sample\n",
      "space diversity and devise a metric to filter redundant data,\n",
      "enhancing model robustness while reducing data dependency.\n",
      "Benchmarking against quantitative and qualitative metrics cor-\n",
      "roborates our approach. This research not only identifies critical\n",
      "model limitations but also offers a pragmatic solution, ushering in\n",
      "an era of more effective, data-efficient summarization techniques.\n",
      "Index Terms ‚ÄîAbstractive summarization, Data distillation,\n",
      "Representation bias, Text summarization\n",
      "I. I NTRODUCTION\n",
      "Over the past years, summarization systems have evolved\n",
      "from traditional graph-based approaches [1], [2], [3], [4] to\n",
      "machine learning and deep learning based systems [5], [6]. The\n",
      "recent advancements in attention-based architectures [7] have\n",
      "further pushed the performance at the cost of large labelleddatasets. Despite the huge success, these systems often fail to\n",
      "maintain consistency in performance across multiple datasets\n",
      "[8]. This inconsistency is observed primarily in the qualitative\n",
      "parameters like generalizability, faithfulness and coherence.\n",
      "The factors like the diversity of users, community theme, and\n",
      "moderation can be accounted for quality degradation arising\n",
      "from scrapping crowdsourcing platforms. Intuitively, the diver-\n",
      "sity and variability should help the model generalize better;\n",
      "however, the skewed representation of the training samples\n",
      "abstains the systems from learning variable representations\n",
      "(Table I).\n",
      "Deep learning based abstractive text summarization models\n",
      "exploit the schematic representations in the training data to\n",
      "capture the relationship between the source and the target.\n",
      "However, for a given dataset, a large portion of the training\n",
      "sample follows a similar structure in terms of style and feature\n",
      "representation making the systems learn it as an essential\n",
      "representation while ignoring the other variable samples as\n",
      "noise. This imbalance of features in the corpus leads to\n",
      "representation bias where the majority features get importance\n",
      "while minority features are considered outliers. This skewed\n",
      "representation of samples in the training data incapacitates the\n",
      "model from understanding the varied representation across the\n",
      "input space, making it learn over a saturated sample leading\n",
      "to degraded performance. The models trained on these skewed\n",
      "data generate repetitive, templatic and unfaithful [9], [10], [11]\n",
      "summaries.\n",
      "Representation bias is studied widely for binary and multi-\n",
      "class classification tasks but is often not given importance for\n",
      "language generation\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Proceedings of the XCSP3Competition 2023\n",
      "Gilles Audemard\n",
      "Christophe Lecoutre\n",
      "Emmanuel Lonca\n",
      "CRIL\n",
      "University of Artois & CNRS\n",
      "France\n",
      "August 30, 2023\n",
      "(Revised‚àóon December 10, 2023)arXiv:2312.05877v1  [cs.AI]  10 Dec 20232\n",
      "This document represents the proceedings of the XCSP3Competition 2023. The website\n",
      "containing all detailed results of this international competition is available at:\n",
      "https://www.cril.univ-artois.fr/XCSP23\n",
      "The organization of this 2023 competition involved the following tasks:\n",
      "‚Ä¢adjusting general details (dates, tracks, . . .) by G. Audemard, C. Lecoutre and E. Lonca\n",
      "‚Ä¢selecting instances (problems, models and data) by C. Lecoutre\n",
      "‚Ä¢receiving, testing and executing solvers on CRIL cluster by E. Lonca\n",
      "‚Ä¢validating solvers and rankings by C. Lecoutre and E. Lonca\n",
      "‚Ä¢developping the 2023 website dedicated to results by G. Audemard\n",
      "Important : for reproducing the experiments and results, it is important to use the set of\n",
      "XCSP3instances used in the competition. These instances can be found in this archive. Some\n",
      "(usually minor) differences may exist when compiling the models presented in this document\n",
      "and those that can be found in this archive.\n",
      "Revision (‚àó) of December 2023: some models in this document have been simplified while\n",
      "using new possibilities offered by Version 2.2 of PyCSP3. As mentioned above, note that in\n",
      "order to reproduce results and/or to make fair new comparisons with respect to solvers engaged\n",
      "in the 2023 competition, you have to use the very same set of XCSP3instances, as in the 2023\n",
      "competition.Contents\n",
      "1 About the Selection of Problems in 2023 5\n",
      "2 Problems and Models 9\n",
      "2.1 CSP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
      "2.1.1 Another Magic Square . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
      "2.1.2 Antimagic Square . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n",
      "2.1.3 Binary Puzzle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
      "2.1.4 Calvin Puzzle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n",
      "2.1.5 Coloring . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n",
      "2.1.6 Covering Array . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n",
      "2.1.7 Dominoes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n",
      "2.1.8 Fischer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n",
      "2.1.9 Magic Square . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.1.10 Nonogram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.1.11 Non Transitive Dice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n",
      "2.1.12 Peg Solitaire . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n",
      "2.1.13 Primes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n",
      "2.1.14 Pythagorean Triples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n",
      "2.1.15 Slant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n",
      "2.1.16 Soccer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n",
      "2.1.17 Square Packing Suite . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n",
      "2.1.18 Word Design (for DNA Computing on Surfaces) . . . . . . . . . . . . . 25\n",
      "2.2 COP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n",
      "2.2.1 Aircraft Assembly Line . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n",
      "2.2.2 Beer Jugs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n",
      "2.2.3 Benzenoide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n",
      "2.2.4 Carpet Cutting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n",
      "2.2.5 Generalised Balanced Academic Curriculum Problem (GBACP) . . . . 37\n",
      "2.2.6 Generalized MKP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n",
      "2.2.7 HC Pizza . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
      "2.2.8 Hoist Scheduling Problem (HSP) . . . . . . . . . . . . . . . . . . . . . . 41\n",
      "2.2.9 Kidney Exchange . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n",
      "2.2.10 K-Median Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n",
      "2.2.11 Large Scale Scheduling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n",
      "2.2.12 Progressive Party . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n",
      "2.2.13 Pigment Sequencing Problem (PSP) . . . . . . . . . . . . . . . . . . . . 49\n",
      "2.2.14 Resource Investment Problem (RIP) . . . . . . . . . . . . . . . . . . . . 51\n",
      "2.2.15 Rule Mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n",
      "2.2.16 Sonet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\n",
      "2.2.17 Single-Row Facility Layout Problem (SRFLP) . . . . . . . . . . . . . . . 54\n",
      "34 CONTENTS\n",
      "2.2.18 TSPTW . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n",
      "3 Solvers 57\n",
      "ACE . . . . . . . . .\n",
      "----------------------------------------------------------------------------------------------------\n",
      "PSCR: Patches Sampling-based Contrastive\n",
      "Regression for AIGC Image Quality Assessment\n",
      "Jiquan Yuan, Xinyan Cao, Linjing Cao,\n",
      "Jinlong Lin, and Xixin Cao‚ãÜ\n",
      "School of Software & Microelectronics, Peking University, Beijing, China\n",
      "Abstract. In recent years, Artificial Intelligence Generated Content\n",
      "(AIGC) has gained widespread attention beyond the computer science\n",
      "community. Due to various issues arising from continuous creation of AI-\n",
      "generated images (AIGI), AIGC image quality assessment (AIGCIQA),\n",
      "which aims to evaluate the quality of AIGIs from human perception per-\n",
      "spectives, has emerged as a novel topic in the field of computer vision.\n",
      "However, most existing AIGCIQA methods directly regress predicted\n",
      "scores from a single generated image, overlooking the inherent differences\n",
      "among AIGIs and scores. Additionally, operations like resizing and crop-\n",
      "ping may cause global geometric distortions and information loss, thus\n",
      "limiting the performance of models. To address these issues, we propose\n",
      "a patches sampling-based contrastive regression (PSCR) framework. We\n",
      "suggest introducing a contrastive regression framework to leverage dif-\n",
      "ferences among various generated images for learning a better represen-\n",
      "tation space. In this space, differences and score rankings among images\n",
      "can be measured by their relative scores. By selecting exemplar AIGIs as\n",
      "references, we also overcome the limitations of previous models that could\n",
      "not utilize reference images on the no-reference image databases. To avoid\n",
      "geometric distortions and information loss in image inputs, we further\n",
      "propose a patches sampling strategy. To demonstrate the effectiveness\n",
      "of our proposed PSCR framework, we conduct extensive experiments on\n",
      "three mainstream AIGCIQA databases including AGIQA-1K, AGIQA-\n",
      "3K and AIGCIQA2023. The results show significant improvements in\n",
      "model performance with the introduction of our proposed PSCR frame-\n",
      "work. Code will be available at https://github.com/jiquan123/PSCR .\n",
      "Keywords: AIGC, AIGCIQA, contrastive regression framework, patches\n",
      "sampling strategy\n",
      "1 Introduction\n",
      "In recent years, Artificial Intelligence Generated Content (AIGC) has garnered\n",
      "extensive attention beyond the field of computer science. AIGC, created by ad-\n",
      "vanced Generative AI (GAI) technologies rather than human authors, can au-\n",
      "tomatically produce large volumes of content in a short time. Its core concept\n",
      "‚ãÜCorresponding author. Email: cxx@ss.pku.edu.cnarXiv:2312.05897v1  [cs.CV]  10 Dec 20232 J. Yuan, X. Cao, L. Cao, J. Lin, X. Cao\n",
      "(a)\n",
      " (b)\n",
      " (c)\n",
      "Fig. 1: Most IQA methods employ a direct regression approach to obtain pre-\n",
      "dicted scores such as (a) and (b). The image preprocessing methods they use,\n",
      "such as resizing, cropping, and non-overlapping patches sampling, often lead to\n",
      "geometric distortion and information loss. Our proposed patches sampling-based\n",
      "contrastive regression framework (c) initially captures overlapping image patches\n",
      "using a sliding window to avoid information loss, and simultaneously learns a\n",
      "better representation space by leveraging differences among various images. The\n",
      "red box section within the image represents the image information utilized.\n",
      "involves using AI generative models to automatically create various types of\n",
      "content such as text, images, audio, and video, based on given themes, key-\n",
      "words, formats, and styles, etc.AIGC is widely applicable in fields like media,\n",
      "education, entertainment, marketing, and scientific research, etc., offering users\n",
      "high-quality, efficient, and highly personalized content services.\n",
      "Due to various issues arising from continuous creation of AI-generated im-\n",
      "ages (AIGI), AIGC image quality assessment (AIGCIQA), which aims to eval-\n",
      "uate the quality of AI-generated images from human perception perspectives,\n",
      "has emerged as a novel topic in the field of computer vision. Compared to com-\n",
      "mon image content, AIGIs often suffer from unique distortions [24, 33], such as\n",
      "unrealistic structures, irregular textures and shapes, and AI artifacts, etc., mak-\n",
      "ing AIGCIQA more challenging. Unlike traditional image classification or object\n",
      "detection tasks, which mainly focus on classifying and segmenting objects in im-\n",
      "ages, AIGCIQA requires models to predict fine-grained scores from a multitude\n",
      "of AIGIs. Considering the variations in AIGIs and scores, the key to address-\n",
      "ing this issue lies in enabling models to learn the differences among AIGIs and\n",
      "regress predicted scores based on these differences.\n",
      "Over the past few years, significant efforts have been made to advance the\n",
      "development of AIGCIQA, such as the establishment of dedicated databases likeTitle Suppressed Due to Excessive Length 3\n",
      "AGIQA-1K [33], AGIQA-3K [10], AIGCIQA2023 [24], and PKU-I2IQA [30], etc.\n",
      "However, we identify two main deficiencies in current research on AIGCIQA:\n",
      "First, most of them [7, 10, 21, 22, 24, 25, 30, 33] treat AIGCIQA as a regression\n",
      "problem, where models directly regress predicted scores from individual AIGIs,\n",
      "overlooking the inherent diffe\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Thinking Assistants : LLM-Based Conversational Assistants that Help Users\n",
      "Think By Asking rather than Answering\n",
      "SOYA PARK and CHINMAY KULKARNI, Emory University, USA\n",
      "Understand intentProbing: Understand user‚Äôs interest e.g.Answering: Offer tailored response to research-related questions e.g. \n",
      "Content\n",
      "Follow-up questionsIf enough understanding of users:   Recommend the professors‚Äô relevant papers OR   Give Wise Feedback on user‚Äôs researchIf matching information provided by the professor:   Respond the information Otherwise:   If the question is relevant to research: Say ‚ÄúWe don‚Äôt know what [the professor thinks about this]‚Äù  & Offer answers by querying GPT   Otherwise: Turn conversation back to research-relatedAsk  More clarifying questions about their research interest/goal or approach to get a full picture of their research\n",
      "![User message]\n",
      "! I‚Äôm interested in LLM chatbot for reflection\n",
      "! What is Prof. Golbeck advising style?Ask  If they want to know how their research aligns with the professor If there is any terminology they want to know more about\n",
      "Fig. 1. Gradschool.chat is a thinking assistant that helps prospective graduate students reflect on research interests. Based on\n",
      "the user‚Äôs question, the assistant chooses between a ‚Äòprobing‚Äô mode, understanding user interests and prompting reflection, and an\n",
      "‚Äòanswering‚Äô mode that offers with relevant information. Most conversational turns end with a encouraging follow-up question.\n",
      "We introduce the concept of thinking assistants , an approach that encourages users to engage in deep reflection and critical thinking\n",
      "through brainstorming and thought-provoking queries. We instantiate one such thinking assistant, Gradschool.chat , as a virtual\n",
      "assistant tailored to assist prospective graduate students. We posit that thinking assistants are particularly relevant to situations like\n",
      "applying to graduate school, a phase often characterized by the challenges of academic preparation and the development of a unique\n",
      "research identity. In such situations, students often lack direct mentorship from professors, or may feel hesitant to approach faculty\n",
      "with their queries, making thinking assistants particularly useful.\n",
      "Leveraging a Large Language Model (LLM), Gradschool.chat is a demonstration system built as a thinking assistants for working\n",
      "with specific professors in the field of human-computer interaction (HCI). It was designed through training on information specific\n",
      "to these professors and a validation processes in collaboration with these academics. This technical report delineates the system‚Äôs\n",
      "architecture and offers a preliminary analysis of our deployment study. Additionally, this report covers the spectrum of questions posed\n",
      "to our chatbots by users. The system recorded 223 conversations, with participants responding positively to approximately 65% of\n",
      "responses. Our findings indicate that users who discuss and brainstorm their research interests with Gradschool.chat engage more\n",
      "deeply, often interacting with the chatbot twice as long compared to those who only pose questions about professors. We also find\n",
      "that participants who use the system as an informational or predictive agent, seeking definitive answers such as a direct ‚Äôyes‚Äô or ‚Äôno‚Äô\n",
      "to queries like ‚ÄúDo I have a chance of getting into the university?‚Äù find the thinking assistants‚Äôs reflective conversations unsatisfactory.\n",
      "1 INTRODUCTION\n",
      "Many of life‚Äôs most important decisions are challenging because they inherently require a degree of self-discovery in the absence of\n",
      "direct and readily accessible guidance. For instance, in career transitions, individuals must navigate through a maze of choices and\n",
      "Authors‚Äô address: Soya Park, soya.park@emory.edu; Chinmay Kulkarni, chinmay.kulkarni@emory.edu, Emory University, USA.\n",
      "¬©2023 Copyright held by the owner/author(s)\n",
      "This is the author‚Äôs version of the work.\n",
      "1arXiv:2312.06024v1  [cs.HC]  10 Dec 20232 Soya Park and Chinmay Kulkarni\n",
      "opportunities, such that many choices can be reasonable, depending on one‚Äôs goals. Navigating these choices is challenging as an\n",
      "individual: choosing a new career path or pivoting to a different industry involves not only assessing one‚Äôs skills and interests but also\n",
      "understanding the nuances of new fields, often without any mentorship.\n",
      "This paper introduces the idea of a thinking assistant that combines expertise-based guidance with scaffolding for self-reflection.\n",
      "We introduce Gradschool.chat , a set of thinking assistants designed to support prospective graduate students as they navigate the\n",
      "complexities of graduate applications. For many prospective graduate students, the journey to and through graduate school, marked\n",
      "by the need for critical decision-making and self-discovery, can be overwhelming, especially in the absence of direct, readily accessible\n",
      "guidance from more senior academics. The primary agent that comprises Gradschool.chat aids prospective graduate students by\n",
      "engaging users through targeted questioning, fostering deeper thou\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in extracted_texts[:100]:\n",
    "    print(text)\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1027419d-dbf7-44ca-bbbe-761be2e45baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# def calculate_total_perplexity(logits, target_token_ids):\n",
    "#     shifted_logits = logits[:-1, :]\n",
    "#     shifted_targets = target_token_ids[1:]\n",
    "#     average_loss = F.cross_entropy(shifted_logits, shifted_targets, reduction='mean')\n",
    "\n",
    "#     perplexity = torch.exp(average_loss).item()\n",
    "\n",
    "#     return perplexity\n",
    "\n",
    "def calculate_log_sum(logits, target_token_ids):\n",
    "    shifted_logits = logits[:-1, :]\n",
    "    shifted_targets = target_token_ids[1:]\n",
    "    \n",
    "    log_probs = F.log_softmax(shifted_logits, dim=-1)\n",
    "    \n",
    "    target_log_probs = -log_probs.gather(1, shifted_targets.unsqueeze(1)).squeeze()\n",
    "    # print(target_log_probs)\n",
    "    \n",
    "    # perplexity = torch.exp(-sum_log_prob).item()\n",
    "    log_sum = torch.sum(target_log_probs, dim=-1)\n",
    "    # print(perplexity_sum)\n",
    "\n",
    "    # return perplexity\n",
    "    return log_sum.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398f38c-0bb9-495e-b441-7ea0843d51bc",
   "metadata": {},
   "source": [
    "## RWKV-5 1.5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dd07c3c-bdb3-4c36-bff8-acbc7923c280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py38_cu118/wkv_cuda/build.ninja...\n",
      "Building extension module wkv_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module wkv_cuda...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    }
   ],
   "source": [
    "os.environ['RWKV_JIT_ON'] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '1'\n",
    "\n",
    "from rwkv.model import RWKV\n",
    "from rwkv.utils import PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696a73f7-8e30-49f2-8589-c231923e19d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 1 RESCALE_LAYER 6\n",
      "\n",
      "Loading ./models/models--BlinkDL--rwkv-5-world/snapshots/54a28319ff63b17f933975a58ab66010ba534fc0/RWKV-5-World-1B5-v2-20231025-ctx4096.pth ...\n",
      "Model detected: v5.2\n",
      "Strategy: (total 24+1=25 layers)\n",
      "* cuda [float16, float16], store 25 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  65536  2048 \n",
      "blocks.0.ln1.weight               f16   cuda:0   2048       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   2048       \n",
      "blocks.0.ln2.weight               f16   cuda:0   2048       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   2048       \n",
      "blocks.0.att.time_mix_g           f16   cuda:0   2048       \n",
      "blocks.0.att.time_decay           f32   cuda:0     32    64 \n",
      "blocks.0.att.time_first           f32   cuda:0     32    64 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   2048  2048 \n",
      "blocks.0.att.key.weight           f16   cuda:0   2048  2048 \n",
      "blocks.0.att.value.weight         f16   cuda:0   2048  2048 \n",
      "blocks.0.att.output.weight        f16   cuda:0   2048  2048 \n",
      "blocks.0.att.gate.weight          f16   cuda:0   2048  2048 \n",
      "blocks.0.att.ln_x.weight          f32   cuda:0   2048       \n",
      "blocks.0.att.ln_x.bias            f32   cuda:0   2048       \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   2048       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   2048       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   2048  7168 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   2048  2048 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0   7168  2048 \n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.23.ln1.weight              f16   cuda:0   2048       \n",
      "blocks.23.ln1.bias                f16   cuda:0   2048       \n",
      "blocks.23.ln2.weight              f16   cuda:0   2048       \n",
      "blocks.23.ln2.bias                f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_k          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_v          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_r          f16   cuda:0   2048       \n",
      "blocks.23.att.time_mix_g          f16   cuda:0   2048       \n",
      "blocks.23.att.time_decay          f32   cuda:0     32    64 \n",
      "blocks.23.att.time_first          f32   cuda:0     32    64 \n",
      "blocks.23.att.receptance.weight   f16   cuda:0   2048  2048 \n",
      "blocks.23.att.key.weight          f16   cuda:0   2048  2048 \n",
      "blocks.23.att.value.weight        f16   cuda:0   2048  2048 \n",
      "blocks.23.att.output.weight       f16   cuda:0   2048  2048 \n",
      "blocks.23.att.gate.weight         f16   cuda:0   2048  2048 \n",
      "blocks.23.att.ln_x.weight         f32   cuda:0   2048       \n",
      "blocks.23.att.ln_x.bias           f32   cuda:0   2048       \n",
      "blocks.23.ffn.time_mix_k          f16   cuda:0   2048       \n",
      "blocks.23.ffn.time_mix_r          f16   cuda:0   2048       \n",
      "blocks.23.ffn.key.weight          f16   cuda:0   2048  7168 \n",
      "blocks.23.ffn.receptance.weight   f16   cuda:0   2048  2048 \n",
      "blocks.23.ffn.value.weight        f16   cuda:0   7168  2048 \n",
      "ln_out.weight                     f16   cuda:0   2048       \n",
      "ln_out.bias                       f16   cuda:0   2048       \n",
      "head.weight                       f16   cuda:0   2048 65536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py38_cu118/rwkv5/build.ninja...\n",
      "Building extension module rwkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module rwkv5...\n"
     ]
    }
   ],
   "source": [
    "rwkv5_1b5_path = r'./models/models--BlinkDL--rwkv-5-world/snapshots/54a28319ff63b17f933975a58ab66010ba534fc0/RWKV-5-World-1B5-v2-20231025-ctx4096.pth'\n",
    "\n",
    "rwkv5_1b5 = RWKV(model=rwkv5_1b5_path, strategy='cuda fp16')\n",
    "pipeline = PIPELINE(rwkv5_1b5, r\"rwkv_vocab_v20230424\")\n",
    "rwkv_tokenizer = pipeline.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431047af-a6bb-4cd7-bd91-d3a9e354e166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05390bc-11be-4bb9-9827-6d171bac5b7e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011543512344360352,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a7cc2eb97245658fbf402fc72ba358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/rwkv/model.py:957: UserWarning: operator() profile_node %318 : int = prim::profile_ivalue(%316)\n",
      " does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  r, k, v, g, xxx, ss = self.v5_2_before(x, sx, s, ln_w, ln_b, lx_w, lx_b, k_mix, v_mix, r_mix, g_mix, t_decay, t_first, kw, vw, rw, gw, ow, kmx, krx, kmy, kry, vmx, vrx, vmy, vry, rmx, rrx, rmy, rry, gmx, grx, gmy, gry, omx, orx, omy, ory)\n",
      "/tmp/ipykernel_11145/24350323.py:14: UserWarning: seq-494 length > 4096\n",
      "  warnings.warn(f'seq-{idx} length > {max_length}')\n"
     ]
    }
   ],
   "source": [
    "rwkv_test_data = []\n",
    "rwkv_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_seq = rwkv_tokenizer.encode(sample)\n",
    "\n",
    "        if len(input_seq) > max_length:\n",
    "            # print(f'length > {max_length}')\n",
    "            overlong_seq += 1\n",
    "            warnings.warn(f'seq-{idx} length > {max_length}')\n",
    "            # input_seq = input_seq[:max_length]\n",
    "\n",
    "        logit = rwkv5_1b5.forward(input_seq, None, full_output=True)[0]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, torch.tensor(input_seq).cuda())\n",
    "\n",
    "        rwkv_token_length_list.append(len(input_seq))\n",
    "        rwkv_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e45040-aba8-4cae-8ac7-9ffc1bff9dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2716.632776611328\n",
      "avg tokens: 1194.052\n",
      "overlong_seq: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'log probability sum: {sum(rwkv_test_data) / len(rwkv_test_data)}')\n",
    "print(f'avg tokens: {sum(rwkv_token_length_list) / len(rwkv_token_length_list)}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23cc8a1a-d2e0-49c1-a6b4-c314afe1f2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del rwkv5_1b5\n",
    "del pipeline, rwkv_tokenizer, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af7c39-a166-4c36-bd54-f17584dbf2fe",
   "metadata": {},
   "source": [
    "## Qwen 1.8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6094ba0-e7df-4e11-8b8f-8f07c11b318d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006068229675292969,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9f02d053a3440ca1dfafeeee87e121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "qwen_path = r'./models/models--Qwen--Qwen-1_8B/snapshots/fa6e214ccbbc6a55235c26ef406355b6bfdf5eed/'\n",
    "\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_path, trust_remote_code=True)\n",
    "\n",
    "# use bf16\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B\", device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "# use fp16\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B\", device_map=\"auto\", trust_remote_code=True, fp16=True).eval()\n",
    "# use cpu only\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-1_8B\", device_map=\"cpu\", trust_remote_code=True).eval()\n",
    "# use auto mode, automatically select precision based on the device.\n",
    "qwen_1b8 = AutoModelForCausalLM.from_pretrained(qwen_path, device_map=\"auto\", trust_remote_code=True).eval()\n",
    "\n",
    "# Specify hyperparameters for generation. But if you use transformers>=4.32.0, there is no need to do this.\n",
    "# model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-1_8B\", trust_remote_code=True)\n",
    "\n",
    "# inputs = tokenizer('ËíôÂè§ÂõΩÁöÑÈ¶ñÈÉΩÊòØ‰πåÂÖ∞Â∑¥ÊâòÔºàUlaanbaatarÔºâ\\nÂÜ∞Â≤õÁöÑÈ¶ñÈÉΩÊòØÈõ∑ÂÖãÈõÖÊú™ÂÖãÔºàReykjavikÔºâ\\nÂüÉÂ°û‰øÑÊØî‰∫öÁöÑÈ¶ñÈÉΩÊòØ', return_tensors='pt')\n",
    "# inputs = inputs.to(model.device)\n",
    "# pred = model.generate(**inputs)\n",
    "# print(tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))\n",
    "# # ËíôÂè§ÂõΩÁöÑÈ¶ñÈÉΩÊòØ‰πåÂÖ∞Â∑¥ÊâòÔºàUlaanbaatarÔºâ\\nÂÜ∞Â≤õÁöÑÈ¶ñÈÉΩÊòØÈõ∑ÂÖãÈõÖÊú™ÂÖãÔºàReykjavikÔºâ\\nÂüÉÂ°û‰øÑÊØî‰∫öÁöÑÈ¶ñÈÉΩÊòØ‰∫öÁöÑÊñØ‰∫öË¥ùÂ∑¥ÔºàAddis AbabaÔºâ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d485da66-feb6-436d-bd9b-902e9cda4cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08b13eb9-7c88-40e3-8cc1-8dddf092d014",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008640289306640625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55cd79acb774e6083a5523f60accf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qwen_test_data = []\n",
    "qwen_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        inputs = qwen_tokenizer(sample, return_tensors='pt')\n",
    "        inputs = inputs.to(qwen_1b8.device)\n",
    "\n",
    "        seq_length = inputs['input_ids'].shape[-1]\n",
    "\n",
    "        if seq_length > max_length:\n",
    "            # print(f'length > {max_length}')\n",
    "            # inputs = qwen_tokenizer(sample, return_tensors='pt', truncation=True)\n",
    "            overlong_seq += 1\n",
    "            warnings.warn(f'seq-{idx} length > {max_length}')\n",
    "\n",
    "        logit = qwen_1b8.forward(**inputs).logits[0, :, :]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, inputs['input_ids'].squeeze(0))\n",
    "\n",
    "        qwen_token_length_list.append(seq_length)\n",
    "        qwen_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a2a226-e29f-40ce-ac21-0cbf61e7959d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2999.704\n",
      "avg tokens: 1179.163\n",
      "overlong_seq: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'log probability sum: {sum(qwen_test_data) / len(qwen_test_data)}')\n",
    "print(f'avg tokens: {sum(qwen_token_length_list) / len(qwen_token_length_list)}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7339f42e-19e3-43db-acff-55a0c4ac613f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del qwen_1b8, inputs, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22d975-d0a3-40ec-af1c-ab4b12da5a0a",
   "metadata": {},
   "source": [
    "## Falcon 1.3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00e3e28-9269-49cd-bf93-da976168e52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "falcon_path = r\"./models/models--tiiuae--falcon-rw-1b/snapshots/e4b9872bb803165eb22f0a867d4e6a64d34fce19/\"\n",
    "\n",
    "falcon_tokenizer = AutoTokenizer.from_pretrained(falcon_path)\n",
    "falcon_1b3 = AutoModelForCausalLM.from_pretrained(falcon_path, device_map=\"auto\", trust_remote_code=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f49529f-53e1-47f8-9f7a-be6a37a2cdd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "truncation_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c378bce-40a2-403a-9117-0ef0a55ef5e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008498430252075195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f16d4e3cd7e440480d8d1823b1cc39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 1024). Running this sequence through the model will result in indexing errors\n",
      "/tmp/ipykernel_11145/1899047759.py:20: UserWarning: seq-409 length 5220 > truncation_length(2048) truncated\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n",
      "/tmp/ipykernel_11145/1899047759.py:20: UserWarning: seq-494 length 8666 > truncation_length(2048) truncated\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n"
     ]
    }
   ],
   "source": [
    "falcon_test_data = []\n",
    "falcon_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        inputs = falcon_tokenizer(sample, return_tensors='pt')\n",
    "        inputs = inputs.to(falcon_1b3.device)\n",
    "\n",
    "        seq_length = inputs['input_ids'].shape[-1]\n",
    "        \n",
    "        if seq_length > max_length:\n",
    "            overlong_seq += 1\n",
    "            # warnings.warn(f'seq-{idx} length {seq_length} > max_length({max_length})')\n",
    "        if seq_length > truncation_length:\n",
    "            inputs = falcon_tokenizer(sample, return_tensors='pt', max_length=truncation_length, truncation=True)\n",
    "            inputs = inputs.to(falcon_1b3.device)\n",
    "            warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n",
    "            # print(inputs['input_ids'].shape[-1])\n",
    "\n",
    "        logit = falcon_1b3.forward(**inputs).logits[0, :, :]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, inputs['input_ids'].squeeze(0))\n",
    "\n",
    "        falcon_token_length_list.append(seq_length)\n",
    "        falcon_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "201837db-deb3-4b28-8610-7f3e7cdc6ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 3042.29790625\n",
      "avg tokens: 1229.174\n",
      "overlong_seq: 6\n"
     ]
    }
   ],
   "source": [
    "falcon_1b3_log_sum = sum(falcon_test_data) / len(falcon_test_data)\n",
    "falcon_1b3_avg_length = sum(falcon_token_length_list) / len(falcon_token_length_list)\n",
    "print(f'log probability sum: {falcon_1b3_log_sum}')\n",
    "print(f'avg tokens: {falcon_1b3_avg_length}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7df43be-f092-485e-bc3a-557675107dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del falcon_1b3, inputs, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b675613-3510-4b8c-96d7-4eeea0e184fd",
   "metadata": {},
   "source": [
    "## Mamba 1.4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae5e563b-a4f7-4d30-a7c1-fcc0c05feb33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "mamba_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "mamba_1b4 = MambaLMHeadModel.from_pretrained(\"state-spaces/mamba-1.4b\", device=device, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10b7e299-2bf6-4e64-a1f8-87fc49266bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9ee6656-d411-4d00-9d22-bef9d6777c1b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00906682014465332,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8b632be2da4be4990898dc73666e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11145/4273580554.py:16: UserWarning: seq-409 length 2517 > truncation_length(2048)\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length})')\n",
      "/tmp/ipykernel_11145/4273580554.py:16: UserWarning: seq-484 length 2706 > truncation_length(2048)\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length})')\n",
      "/tmp/ipykernel_11145/4273580554.py:16: UserWarning: seq-494 length 6119 > truncation_length(2048)\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length})')\n",
      "/tmp/ipykernel_11145/4273580554.py:16: UserWarning: seq-708 length 2360 > truncation_length(2048)\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length})')\n"
     ]
    }
   ],
   "source": [
    "mamba_test_data = []\n",
    "mamba_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        inputs = mamba_tokenizer(sample, return_tensors=\"pt\").input_ids.to(device=device)\n",
    "\n",
    "        seq_length = inputs.shape[-1]\n",
    "\n",
    "        if seq_length > max_length:\n",
    "            # print(f'length > {max_length}')\n",
    "            overlong_seq += 1\n",
    "            warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length})')\n",
    "\n",
    "        mamba_output = mamba_1b4.forward(inputs)\n",
    "        logit = mamba_output.logits[0, :, :]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, inputs[0])\n",
    "\n",
    "        mamba_token_length_list.append(seq_length)\n",
    "        mamba_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a4478ad-724c-4527-9963-27309f03e45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2859.632\n",
      "avg tokens: 1203.145\n",
      "overlong_seq: 4\n"
     ]
    }
   ],
   "source": [
    "mamba_1b4_log_sum = sum(mamba_test_data) / len(mamba_test_data)\n",
    "mamba_1b4_avg_length = sum(mamba_token_length_list) / len(mamba_token_length_list)\n",
    "print(f'log probability sum: {mamba_1b4_log_sum}')\n",
    "print(f'avg tokens: {mamba_1b4_avg_length}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d2711ff-6c84-4b05-881e-b83101d34722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del mamba_1b4, inputs, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e651d78-4d54-4fbc-b361-25b0184b9578",
   "metadata": {},
   "source": [
    "## Mamba 2.8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84442a0d-5aac-49a1-93be-637b1a0485e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "mamba_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "mamba_2b8 = MambaLMHeadModel.from_pretrained(\"state-spaces/mamba-2.8b\", device=device, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "246cb22d-5709-433f-a60d-6d179c8611dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "truncation_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b522805a-7135-4830-a0e8-8524d53d6b04",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009051322937011719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cf347b71fe49efb01319948adc276e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11145/4042484439.py:19: UserWarning: seq-494 length 6119 > truncation_length(2048) truncated\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n"
     ]
    }
   ],
   "source": [
    "mamba_test_data = []\n",
    "mamba_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        inputs = mamba_tokenizer(sample, return_tensors=\"pt\").input_ids.to(device=device)\n",
    "\n",
    "        seq_length = inputs.shape[-1]\n",
    "\n",
    "        if seq_length > max_length:\n",
    "            # print(f'length > {max_length}')\n",
    "            overlong_seq += 1\n",
    "            # warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length})')\n",
    "        if seq_length > truncation_length:\n",
    "            inputs = mamba_tokenizer(sample, return_tensors=\"pt\", max_length=4096, truncation=True).input_ids.to(device=device)\n",
    "            warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n",
    "\n",
    "        mamba_output = mamba_2b8.forward(inputs)\n",
    "        logit = mamba_output.logits[0, :, :]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, inputs[0])\n",
    "\n",
    "        mamba_token_length_list.append(seq_length)\n",
    "        mamba_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12612a2b-7400-4c30-a263-86a0c7afa03b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2728.718\n",
      "avg tokens: 1203.145\n",
      "overlong_seq: 4\n"
     ]
    }
   ],
   "source": [
    "mamba_2b8_log_sum = sum(mamba_test_data) / len(mamba_test_data)\n",
    "mamba_2b8_avg_length = sum(mamba_token_length_list) / len(mamba_token_length_list)\n",
    "print(f'log probability sum: {mamba_2b8_log_sum}')\n",
    "print(f'avg tokens: {mamba_2b8_avg_length}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76e82adb-03c7-4862-a2f4-231b1551c53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del mamba_2b8, inputs, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd4048c-1506-47ab-872f-6abb9c8f3253",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RWKV-5 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7161bf5f-02b6-4a0c-bf3a-213f9686af80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['RWKV_JIT_ON'] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '1'\n",
    "\n",
    "from rwkv.model import RWKV\n",
    "from rwkv.utils import PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51ee17d9-c0be-4d06-a054-4941c06343c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 1 RESCALE_LAYER 6\n",
      "\n",
      "Loading ./models/models--BlinkDL--rwkv-5-world/snapshots/54a28319ff63b17f933975a58ab66010ba534fc0/RWKV-5-World-3B-v2-20231113-ctx4096.pth ...\n",
      "Model detected: v5.2\n",
      "Strategy: (total 32+1=33 layers)\n",
      "* cuda [float16, float16], store 33 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 25-cuda-float16-float16 26-cuda-float16-float16 27-cuda-float16-float16 28-cuda-float16-float16 29-cuda-float16-float16 30-cuda-float16-float16 31-cuda-float16-float16 32-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  65536  2560 \n",
      "blocks.0.ln1.weight               f16   cuda:0   2560       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   2560       \n",
      "blocks.0.ln2.weight               f16   cuda:0   2560       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_g           f16   cuda:0   2560       \n",
      "blocks.0.att.time_decay           f32   cuda:0     40    64 \n",
      "blocks.0.att.time_first           f32   cuda:0     40    64 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   2560  2560 \n",
      "blocks.0.att.key.weight           f16   cuda:0   2560  2560 \n",
      "blocks.0.att.value.weight         f16   cuda:0   2560  2560 \n",
      "blocks.0.att.output.weight        f16   cuda:0   2560  2560 \n",
      "blocks.0.att.gate.weight          f16   cuda:0   2560  2560 \n",
      "blocks.0.att.ln_x.weight          f32   cuda:0   2560       \n",
      "blocks.0.att.ln_x.bias            f32   cuda:0   2560       \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   2560       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   2560       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   2560  8960 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   2560  2560 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0   8960  2560 \n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.31.ln1.weight              f16   cuda:0   2560       \n",
      "blocks.31.ln1.bias                f16   cuda:0   2560       \n",
      "blocks.31.ln2.weight              f16   cuda:0   2560       \n",
      "blocks.31.ln2.bias                f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_k          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_v          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_r          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_g          f16   cuda:0   2560       \n",
      "blocks.31.att.time_decay          f32   cuda:0     40    64 \n",
      "blocks.31.att.time_first          f32   cuda:0     40    64 \n",
      "blocks.31.att.receptance.weight   f16   cuda:0   2560  2560 \n",
      "blocks.31.att.key.weight          f16   cuda:0   2560  2560 \n",
      "blocks.31.att.value.weight        f16   cuda:0   2560  2560 \n",
      "blocks.31.att.output.weight       f16   cuda:0   2560  2560 \n",
      "blocks.31.att.gate.weight         f16   cuda:0   2560  2560 \n",
      "blocks.31.att.ln_x.weight         f32   cuda:0   2560       \n",
      "blocks.31.att.ln_x.bias           f32   cuda:0   2560       \n",
      "blocks.31.ffn.time_mix_k          f16   cuda:0   2560       \n",
      "blocks.31.ffn.time_mix_r          f16   cuda:0   2560       \n",
      "blocks.31.ffn.key.weight          f16   cuda:0   2560  8960 \n",
      "blocks.31.ffn.receptance.weight   f16   cuda:0   2560  2560 \n",
      "blocks.31.ffn.value.weight        f16   cuda:0   8960  2560 \n",
      "ln_out.weight                     f16   cuda:0   2560       \n",
      "ln_out.bias                       f16   cuda:0   2560       \n",
      "head.weight                       f16   cuda:0   2560 65536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module rwkv5, skipping build step...\n",
      "Loading extension module rwkv5...\n"
     ]
    }
   ],
   "source": [
    "rwkv5_3b_path = r'./models/models--BlinkDL--rwkv-5-world/snapshots/54a28319ff63b17f933975a58ab66010ba534fc0/RWKV-5-World-3B-v2-20231113-ctx4096.pth'\n",
    "\n",
    "rwkv5_3b = RWKV(model=rwkv5_3b_path, strategy='cuda fp16')\n",
    "pipeline = PIPELINE(rwkv5_3b, r\"rwkv_vocab_v20230424\")\n",
    "rwkv_tokenizer = pipeline.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9231f238-eb15-481d-a789-1ca0dc8527cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6a8d3fb-12a8-4d6f-a98f-90107bbf0a68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009706497192382812,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43afc786d0a14e58bc048448d2dbd178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11145/2951203530.py:14: UserWarning: seq-494 length > 4096\n",
      "  warnings.warn(f'seq-{idx} length > {max_length}')\n"
     ]
    }
   ],
   "source": [
    "rwkv_test_data = []\n",
    "rwkv_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_seq = rwkv_tokenizer.encode(sample)\n",
    "\n",
    "        if len(input_seq) > max_length:\n",
    "            # print(f'length > {max_length}')\n",
    "            overlong_seq += 1\n",
    "            warnings.warn(f'seq-{idx} length > {max_length}')\n",
    "            # input_seq = input_seq[:max_length]\n",
    "\n",
    "        logit = rwkv5_3b.forward(input_seq, None, full_output=True)[0]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, torch.tensor(input_seq).cuda())\n",
    "\n",
    "        rwkv_token_length_list.append(len(input_seq))\n",
    "        rwkv_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61c4c944-cdc3-4693-bbf9-eaf6f06df2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2585.3745444335937\n",
      "avg tokens: 1194.052\n",
      "overlong_seq: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'log probability sum: {sum(rwkv_test_data) / len(rwkv_test_data)}')\n",
    "print(f'avg tokens: {sum(rwkv_token_length_list) / len(rwkv_token_length_list)}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce045440-2683-4a7a-9841-f9c8ff1a32c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del rwkv5_3b\n",
    "del pipeline, rwkv_tokenizer, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d000b-9b45-40c9-826d-86c84fd7361e",
   "metadata": {},
   "source": [
    "## StableLM-3B-4E1T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86fd2db3-ab44-421d-9c69-89264c13aec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "stable_lm_3b_path = r\"./models/models--stabilityai--stablelm-3b-4e1t/snapshots/c6554ba60f40a8252d2a43e38e55ee2e3a645813/\"\n",
    "\n",
    "stable_lm_tokenizer = AutoTokenizer.from_pretrained(stable_lm_3b_path)\n",
    "stable_lm_3b = AutoModelForCausalLM.from_pretrained(stable_lm_3b_path, device_map=\"auto\", trust_remote_code=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59159b23-1d17-4781-9f87-7dcbb9306e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 4096\n",
    "truncation_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5663d8c3-25a8-46bd-ac01-790579443df4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015801429748535156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7493214f0f047f580d31cd4bffeeb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11145/3890670133.py:20: UserWarning: seq-494 length 6119 > truncation_length(4096) truncated\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n"
     ]
    }
   ],
   "source": [
    "stablelm_test_data = []\n",
    "stablelm_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        inputs = stable_lm_tokenizer(sample, return_tensors='pt')\n",
    "        inputs = inputs.to(stable_lm_3b.device)\n",
    "\n",
    "        seq_length = inputs['input_ids'].shape[-1]\n",
    "        \n",
    "        if seq_length > max_length:\n",
    "            overlong_seq += 1\n",
    "            # warnings.warn(f'seq-{idx} length {seq_length} > max_length({max_length})')\n",
    "        if seq_length > truncation_length:\n",
    "            inputs = stable_lm_tokenizer(sample, return_tensors='pt', max_length=truncation_length, truncation=True)\n",
    "            inputs = inputs.to(stable_lm_3b.device)\n",
    "            warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n",
    "            # print(inputs['input_ids'].shape[-1])\n",
    "\n",
    "        logit = stable_lm_3b.forward(**inputs).logits[0, :, :]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, inputs['input_ids'].squeeze(0))\n",
    "\n",
    "        stablelm_token_length_list.append(seq_length)\n",
    "        stablelm_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "385834d7-f39c-45ec-b8c1-646f7c8a8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2529.696282836914\n",
      "avg tokens: 1203.145\n",
      "overlong_seq: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'log probability sum: {sum(stablelm_test_data) / len(stablelm_test_data)}')\n",
    "print(f'avg tokens: {sum(stablelm_token_length_list) / len(stablelm_token_length_list)}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3f6d574-e20d-46f9-9b19-59a839a3cc89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del stable_lm_3b\n",
    "del stable_lm_tokenizer, logit, inputs\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21686786-db4f-4ef0-b909-53bf74ff37ea",
   "metadata": {},
   "source": [
    "## Phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "006ce54c-fed2-4184-b8a1-b8b3b3ac71f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006051778793334961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2ba6804a574db0a304cd82563fe046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "phi2_path = r\"./models/models--microsoft--phi-2/snapshots/d3186761bf5c4409f7679359284066c25ab668ee/\"\n",
    "\n",
    "phi2_tokenizer = AutoTokenizer.from_pretrained(phi2_path)\n",
    "phi2 = AutoModelForCausalLM.from_pretrained(phi2_path, device_map=\"auto\", trust_remote_code=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29c96ccc-6ebe-4370-bc28-8cf43d723308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_length = 2048\n",
    "truncation_length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "610b504f-5b87-49c9-b2fa-d02f54fd1d03",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007810115814208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c9a5bc798040b197365367d271c1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5185 > 2048). Running this sequence through the model will result in indexing errors\n",
      "/tmp/ipykernel_11145/4033256481.py:22: UserWarning: seq-409 length 5185 > truncation_length(2048) truncated\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n",
      "/tmp/ipykernel_11145/4033256481.py:22: UserWarning: seq-494 length 8666 > truncation_length(2048) truncated\n",
      "  warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n"
     ]
    }
   ],
   "source": [
    "phi_test_data = []\n",
    "phi_token_length_list = []\n",
    "overlong_seq = 0\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        inputs = phi2_tokenizer(sample, return_tensors='pt')\n",
    "        inputs = inputs.to(phi2.device)\n",
    "\n",
    "        seq_length = inputs['input_ids'].shape[-1]\n",
    "\n",
    "        if seq_length > max_length:\n",
    "            # print(f'length > {max_length}')\n",
    "            # inputs = qwen_tokenizer(sample, return_tensors='pt', truncation=True)\n",
    "            overlong_seq += 1\n",
    "            # warnings.warn(f'seq-{idx} length > {max_length}')\n",
    "        if seq_length > truncation_length:\n",
    "            inputs = phi2_tokenizer(sample, return_tensors='pt', max_length=truncation_length, truncation=True)\n",
    "            inputs = inputs.to(phi2.device)\n",
    "            warnings.warn(f'seq-{idx} length {seq_length} > truncation_length({max_length}) truncated')\n",
    "            # print(inputs['input_ids'].shape[-1])\n",
    "\n",
    "        logit = phi2.forward(**inputs).logits[0, :, :]\n",
    "\n",
    "        log_sum = calculate_log_sum(logit, inputs['input_ids'].squeeze(0))\n",
    "\n",
    "        phi_token_length_list.append(seq_length)\n",
    "        phi_test_data.append(log_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f41c191c-c4de-4a67-900e-c4943b43f046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability sum: 2851.696897216797\n",
      "avg tokens: 1227.742\n",
      "overlong_seq: 6\n"
     ]
    }
   ],
   "source": [
    "print(f'log probability sum: {sum(phi_test_data) / len(phi_test_data)}')\n",
    "print(f'avg tokens: {sum(phi_token_length_list) / len(phi_token_length_list)}')\n",
    "print(f'overlong_seq: {overlong_seq}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91b8c6ff-0bbb-4e68-83d2-613c3bfaa9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del phi2\n",
    "del phi2_tokenizer, logit, inputs\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b8b730-5c09-4c50-841c-ef869591d769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
