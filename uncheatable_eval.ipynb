{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe646b8b-491e-4272-9cf6-a62e831e59a4",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cab115e-f9ff-49cd-92ce-5a5a971385ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d65a62-ddae-45fa-90fb-19e1828e651c",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc237f4-836c-41fe-8b92-1c0c7e5ebd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# load from json file\n",
    "\n",
    "data_path = \"./arxiv_pdfs_cs_24_1_2000_to_7000.json\"\n",
    "\n",
    "\n",
    "def load_list_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Loads a list of strings from a JSON file.\n",
    "\n",
    "    :param file_path: Path of the JSON file to be loaded.\n",
    "    :return: List of strings loaded from the JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "\n",
    "extracted_texts = load_list_from_json(data_path)\n",
    "\n",
    "print(len(extracted_texts))\n",
    "# print([len(x) for x in extracted_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20564bbb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlocation is compared with a database of reference imagesfrom known locations in order to localize the query image.The location of the query image is estimated by identifyingthe closest matching image in the reference image database.This task is challenging due to variations in seasons, illumi-nation, viewpoint, and occlusions. Typically, two types ofimage representations are used in VPR tasks: global andpatch-level descriptors. Global descriptors [2]–[4] provide asuccinct image representation in a single vector, facilitatingefficient large-scale searches. Patch-level or local descriptors[5]–[7] encode details about specific regions or key points ofthe image and are used for performing geometric verificationbetween image pairs.To enhance performance, VPR is commonly executed intwo distinct phases. Initially, a global retrieval is conductedThe authors are with SMART Lab, Department of Computer and In-formation Technology, Purdue University, West Lafayette, IN 47907, USAkannan9@purdue.edu | minb@purdue.eduThe code for PlaceFormer will be made publicly available after it ispublished.Query Image Reference ImageFig. 1. PlaceFormer leverages patches of varying scales achieved throughthe fusion of patch tokens in the vision transformer. From these fusedpatches, key patches (boxes of different colors) are selectively chosen basedon the attention scores from the transformer corresponding to that patch.The model then estimates correspondences between key patches of differentscales in both the query and reference images which is used for the imageretrieval process.by employing a nearest-neighbor search between the queryimage’s global descriptors and those of the reference im-ages. Subsequently, using the patch descriptors, re-rankingis conducted on the top- kcandidate images acquired duringthe global retrieval process. Re-ranking is typically achievedthrough cross-matching the patch descriptors of both thequery and the reference images, followed by a subsequentgeometric verification step. However, the larger size of patchdescriptors, which usually encode all regions of an image,can slow down and prolong the re-ranking process. There-fore, it is crucial to extract only the task-relevant regions tofacilitate the re-ranking step efficiently.Contemporary VPR methods rely on Convolutional NeuralNetworks (CNNs) to extract both global and local imagedescriptors. In VPR applications, the visual characteristicsof a location can undergo significant changes over the longterm, including alterations caused by factors such as day-night illumination, falling leaves, and snow. Therefore, acomprehensive grasp of the image’s global context is crucialfor successful VPR. Nevertheless, CNNs, with their limitedreceptive fields, are not inherently adept at capturing thisglobal context. Vision Transformers [8], on the contrary,addresses this CNN limitation by introducing pair-wise atten-tion mechanisms that can capture relationships between anypair of locations within an image. This innovative approachallows the transformer’s patch tokens to encode not onlylocal information but also vital global context, enhancing itssuitability for VPR tasks.In this paper, we propose PlaceFormer , a novel ap-proach that harnesses the potential of vision transformersto extract robust image representations specifically designedfor visual place recognition. The global retrieval processarXiv:2401.13082v1  [cs.CV]  23 Jan 2024involves aggregating the patch tokens of the transformerand utilizing the same to perform global retrieval. Then,we compute patches of multiple fixed scales on the imagesby fusing the patch tokens and then, identify key patchesamongst them, leveraging the attention map of the visiontransformer. These key patches pinpoint areas of the imageideal for accurate long-term VPR. Comparing key patches inboth query and reference images across different scales, wecompute similarity scores using geometric verification. Sub-sequently, a re-ranking process is carried out based on thesesimilarity scores. In Fig. 1, we illustrate a visual example thathighlights key patches of various scales selected based onattention scores (marked with boxes of distinct colors). Thegreen lines represent the correspondences estimated betweenpatches of different scales in both the query and referenceimages, which are utilized for the re-ranking process.In summary, the main contributions of our work are:•A vision transformer-based VPR model PlaceFormerthat extracts robust global and patch-level image rep-resentations.•Attention-based multi-scale patch selection and fusionmodule that cross-matches patches of different scalesand computes a similarity score between an image pairfor re-ranking the images.•Extensive validation of PlaceFormer on numerous VPRbenchmarks, and it achieves state-of-the-art perfor-mance on several benchmarks while requiring less com-putation time and memory.II. R ELATED WORKSGlobal Image Descriptors. The early methodologies forgenerating global image d\n",
      "----------------------------------------------------------------------------------------------------\n",
      "airstyles. By aligning thesepoints with the head shape in an analysis-by-synthesis man-ner, the PMSM makes it possible to utilize 3D Gaussian forfine detail representation and appearance modeling, thusenabling the creation of high-fidelity avatars. We show thatPSAvatar can reconstruct high-fidelity head avatars of a va-riety of subjects and the avatars can be animated in real-time (≥25 fps at a resolution of 512 ×512 )2.1. IntroductionCreating animatable head avatars has wide applications andhas attracted extensive interests in academia and industries.Many methods based on explicit representations, e.g., 3D2Test is conducted based on Nvidia RTX 30901arXiv:2401.12900v3  [cs.GR]  29 Jan 2024morphable models (3DMMs) [1, 21], points [35, 41] andmore recently 3D Gaussian [3, 17, 25]), and neural im-plicit representations, e.g., Neural Radiance Field (NeRF)[10, 22, 42] and signed distance function (SDF) [37, 40]),have been developed in recent years. Whilst these methodshave achieved very impressive results, there are still manyunsolved problems.3DMM-based methods allow efficient rasterization andinherently generalize to unseen deformations, but are lim-ited by a priori-fixed topology and surface-like geometries,making them less suitable for modeling individuals witheyeglasses or complex hairstyles [3, 25]. Whilst neural im-plicit representations outperform 3DMM-based methods incapturing hair strands and eyeglasses [6, 40], they are com-putationally extremely demanding [15]. Furthermore, neu-ral implicit representations need the deformer network orsimilar techniques to bridge the gap between the canonicaland deformed spaces, making it challenging to achieve highdeformation accuracy.In contrast to neural implicit representations, both pointand 3D Gaussian representations can be rendered efficientlywith a splatting-based rasterization [3, 25, 41], and bothare considerably more flexible than 3DMMs in representingcomplex volumetric structures, e.g., eyeglass, hair strands,etc.. PointAvatar [41] initializes with a sparse point cloudrandomly sampled on a sphere and periodically upsam-ples the point cloud by adding noises. The position of thepoints are updated to match the target geometry via back-wards gradients. Points are rotation-invariant and isotrop-ically scaled, making them easy to control. In compari-son, 3D Gaussians can be rotated and scaled, making themmore flexible than points for 3D representation. In orderto achieve consistent 3D representations, 3D Gaussian relyon carefully designed controlling strategy. In GaussianA-vatar [25], each triangle of the mesh is initialized with a 3DGaussian, and the positional gradient is utilized to move andperiodically densify the Gaussian splats. A major difficultyin applying 3D Gaussian to head avatar creation is model-ing the head shape variations caused by changing poses andexpressions.In this paper, we introduce PSAvatar, a novel frame-work for animatable head avatar creation that utilizes dis-crete geometric primitive to create a parametric morphableshape model to make it possible to employ 3D Gaussianfor fine detail representation and high fidelity rendering.Such a parametric morphable shape model, referred to asPoint-based Morphable Shape Model (PMSM), relies onpoints instead of meshes for 3D representation to achieveenhanced representation flexibility. PMSM is created basedon FLAME to inherit its morphable capability. Specifically,PMSM converts the FLAME mesh to points by uniformlysampling points on the surface of the mesh. However,FLAME is incapable of representing individuals with eye-glasses or complex hairstyles. To address this, PMSM sam-ples points off the FLAME mesh to enhance the represen-tation flexibility. PMSM splats the points onto screen andminimizes the difference between the rendered and groundtruth images. After removing the invisible points, the re-maining points are then aligned with the head shape. PSA-vatar models the appearance by employing 3D Gaussian incombination with the PMSM to reconstruct the underlyingradiance field and to achieve high-fidelity rendering. Ourcontributions are as follows:• We present PSAvatar, a method for creating animatablehead avatars using a point-based morphable shape modelfor shape modeling and employing 3D Gaussian for finedetail representation and appearance modeling.• We have developed a Point-based Morphable ShapeModel for 3D head representation that is capable of mod-eling facial shapes with pose and expression variationsand capturing complex volumetric structures e.g., hairstrands, glasses, etc..• We show that PSAvatar can reconstruct high-fidelity headavatars of a variety of subjects and the avatars can be ani-mated in real-time ( ≥25 fps at 512 ×512 resolution).2. Related WorkHead Avatar Creation with Implicit Models Implicitmodels reconstruct the face by neural radiance field in com-bination with volumetric rendering or using implicit surfacefunctions ( e.g., signed distance functions). A popular ap-proach \n",
      "----------------------------------------------------------------------------------------------------\n",
      "earchitectureinlanguagemodels(Bahdanau,Cho,andBengio2014)(Hu2020;BrauwersandFrasincar2023).AttentionMechanismsenableLLMtorecall,generateanaccuratesequenceoftokensduetotheirabilitytofocusonrelevantpartsofinputsequenceduringgenerationoftokens.Inthiswork,wedescribetrust,dataqualityoflargelanguagemodels,wedescribeissuesaroundtrust,data-quality ,andresearchdirectionsforincreasingtrustoflanguagemodels.InSummary,ourcontributionsareasfollows:●Weproposeanovelmathematicalformulationofinformationqualityusingconsistency ,relevanceandaccuracymetric,thusintroducingapipelineforLLMtoevaluateinformationqualityinnaturallanguageprocessing●Weexploreimportanceoftrust,data-qualityforlargelanguagemodels,whichaffectseconomy,wehighlighthowunreliabledataleadstowardspoorperformanceofLLM,dataqualityissuessuchasdiversityoftraining,bias,tokenizationareneededinlargerdatasetsforLLM●WepostulatewhyqualityofLLMisfacinglimitations,wefindduetodataqualityissues,andwefinddatasetssuchasgeneral,specializeddatasetsareenablingLLMtoimproveperformanceinspecificdomains.WealsoexplorescalinglawslikeChinchillaandBrokenNeuralScalinglaws,whichenableLLMtosystematicallyscalelanguagemodels●WefindlimitationsofLLMsuchashallucination,commonsensereasoning,inconsistency ,andwesuggestresearchdirectionforimprovingLLMthroughinvestigatingtheoryandprinciplesofLLM,reducingdependenceonhumanlabellersandimprovingdataquality2.WhyInformationqualitygeneratedbyLLMplayaroleinEconomy?Trustplaysacentralroleineconomictransactions,forthemajorityofprofessionsinbusinesses.Keydecisionsaretaken,basedontheinformationqualityavailable.Firstlyfromconsumers,whentheymakeadecisionaboutaproduct,theydesirereliableinformationtopurchase,secondly,productreviews,datainformstheirchoices.Largelanguagemodelsareproducinginformationbasedontrainingdata,modelssuchasGPTseriesaretrainedontrillionsoftokens,amassingtheentireinternet,whenLLMareusedtoaccomplishtaskssuchascode-generation,tutoringstudentsaseducationbots,usersrequirethemtorelyandtrustthem.Unreliableinformationleadstowardspoordataquality,thushamperingbothcustomersandprofessionstolosetrust.Uncertaintyhinderstowardslackofgrowth,development.Thereforeitisofurgentrequirementtoexploreinformationquality,trustoflargelanguagemodels.Increasinginformationqualitymightleadtowardsincreasedreliabilityoflargelanguagemodels,thismighthaveindirecteffectsintheglobaleconomysuchasstrongerconsumerconfidence,effectivepartnership,adoptionoflanguagemodeltechnologyallovertheglobe,increasedtransparency ,therebyboostingeconomicactivityofallbusinesses.3.WhyareLanguageModelsfacingInformationQualityissues?Reasonswhylanguagemodelsarefacinginformationqualityissuesisduetoprocessoftraining,involvingtokenization,qualityofdatawhichinvolveslackofdiversity,bias,requiringlargerdatasetasLLMisbeingscaled,increasinginsize.Largelanguagemodelssinceintroductionoftransformers(Vaswanietal.2017a)havebeenincreasinginsize,data,performanceoftasksinmajorityofnaturallanguageprocessingtasks.Transformers,anencoder-decodertypeofarchitecture,containedtrainingdataof800millionwordsfromBook-Corpuswith110millionparameterswith6layers.BERTconsistsofencoderonlyarchitecturefromTransformers,with12layers,110millionparameters,trainedbidirectionally .GenerativePre-trainedTransformers(GPT)consistsofdecoder-onlyarchitecture,with12layers,with110millionparameters,trainedunidirectionally ,withfurtherimprovementsleadingtowardsGPT-2,containing48layers,1.5billionparameters,trainedon40GBofWebText,withGPT-3increasingsize,with96layers,withatotalof175billionparameters,containing12attentionheads,768dimensionalstates,withincreasingmoresize,GPT-4(OpenAI2023)consistingof1.8trillionparameterswith120layers,trainedon13trilliontokens.Tokenization(Toramanetal.2023)isanimportantpre-processingtechniqueforlargelanguagemodels,whereinputsarebrokendownintosubunitsbeforesendingtoencoder-decoderlayersoflanguagemodels.Tokenizationmethodsappliedinlanguagemodelssuchascharacter-level,byte-pairencoding(BPE),Wordpiece,morphological-level,word-levelareappliedinlanguagemodels.Variability(Kaddouretal.2023),token’sglitchingleadingtowardsunexpectedbehavior,highercomputationalcostsasitaddsadditionallayeroftraining,informationlossandquality.MethodTokenizedTextCharacter-level\"L \",\" a \",\" n \",\" g\",\"u\",\" a \",\" g\",\" e \",\"\",\"M\",\" o \",\" d\",\" e \",\"l\",\" s\",\"\",\" a \",\"r \", \" e \",\"\",\"i\",\" m \",\" p \",\"r \",\" e \",\" s\",\" s\",\"i\",\"v \",\" e \"BPE\"[CLS]\",\"Language\",\"Models\",\"are\",\"impress\",\"##ive\",\"[SEP]\"WordPiece\"[CLS]\",\"Language\",\"Models\",\"are\",\"impress\",\"##ive\",\"[SEP]\"Morphological\"[CLS]\",\"Language\",\"Model\",\"s\",\"are\",\"impress\",\"##ive\", \"[SEP]\"Word-level\"[CLS]\",\"Language\",\"[UNK]\",\"are\",\"[UNK]\",\"[SEP]\"Table1:MethodsofTokenizationontext,“LanguagemodelsareImpressive”Characterleveltokenizationtakesplaceatcharacterlevel,sothereisnovocabularyfortraining,canrepresentcharacters,reducingmodelsize,howeveritloseswordlevelmeaningandoutputslongsequences,losescompositionalityofwords.BPEisabletohandlevocabularyofsubwordsfrequentlyused,andabletohandleunseenwords,amajordisadvantageisthatitislessi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "put mult iple-output (MIMO) beamforming must be carefully co-designed.The single ISAC access point (AP) case has been the mainfocus of earlier studies [2]. In reality, however, numerousISAC APs will operate in the same area, frequency range,and period of time, thus creating interference between eachother. This encourages these dispersed APs to work togetherto enhance their performance and mitigate the aforemention edinterference [3]. Because of the shared usage of the spec-trum and the broadcasting nature of wireless transmission,ISAC systems’ security is facing several challenges. On theone hand, Rician channels, which are frequently occurringat mmWave frequencies and contain a line of sight (LoS)component, are inextricably linked to the sensing channel.This differs from traditional physical layer security (PLS )research [4] in communication systems with the premisethat the legitimate user channels and intercept channels ar eindependently and identically distributed. The conﬁdenti al in-formation designated to the user equipments (UEs) is includ edin the dual-functional waveform, namely a waveform thatjointly serves the communication UEs and senses the sensingtarget [5], and is therefore vulnerable to being intercepte dby the sensing target. Reasons for implementing such safetymeasures can stem from various factors. For instance, inscenarios involving vehicle tracking for safety purposes, itis essential to enable vehicle monitoring while preventingunauthorized access to the ongoing communication. Let usconsider a communication network deployed in an open-airindustrial area, where incoming vehicles deliver goods. Th esystem aims to track the vehicles autonomously, avoidingaccidents, and simultaneously safeguarding the conﬁdenti alityof the data trafﬁc to prevent industrial espionage.From the sensing side, a crucial and intriguing trade-offappears: the power is expected to be directed towards thesensing target, however, the useful signal information mus tbe protected from being intercepted by said target, who isidentiﬁed as a malicious agent. On the other hand, regardles sof the sensing target’s actions and intentions, it is import antto increase the system’s estimation and detection performa nce.In conventional communication systems, security issues ar eaddressed at the higher levels of the protocol stack with cry pto-graphic techniques [6], even though it is worth mentioning t hatstudies on cryptography frequently assume that the physica llayer provides a link that is error-free, but in reality, wir elesscommunications are subject to assaults, increasing the ris k ofinformation loss.A. Related workIn [7], the authors consider a cell-free MIMO networkequipped with ISAC APs and devise a transmit wave-form co-design strategy aimed at maximizing the signalto noise ratio (SNR) of the sensing target, here assumedto be a benign agent, under a minimum signal to noiseand interference ratio (SINR) constraint for the communi-cation users. The performance of this transmit strategy, interms of achieved communication SINR and sensing SNR,are compared against well-established sensing-prioritiz ed andcommunication-prioritized design strategies, demonstra tingthe performance gain achieved by the proposed co-design str at-egy. On the other hand, in [8], the idea of adding artiﬁcial no ise(AN) to the transmitted waveform to improve the networkPLS is introduced . This technique is an alternative to codin g-based schemes aimed at achieving the same goal [9]. Thiswork considers a single AP with multiple targets, assumed tobe eavedroppers (Eves), and derives the optimal beamformin gstrategy by solving a weighted optimization problem. The ob -jective functions bound together by the weighted optimizat ionare the Cramer-Rao bound (CRB) onto the targets’ angles andthe system’s secrecy rate, deﬁned as the minimum differencebetween each user’s achievable rate and a sensing rate, deﬁn edaslog2(1+ SNR).B. ContributionsContrary to the existing literature, this paper investigat eshow AN can be used by distributed ISAC APs, cooperating toincrease the PLS of a cell-free MIMO network. Said network ismade ofMAPs that serve multiple communication users andsimultaneously sensing a target, assumed to be an Eve, usingthe same signal. In addition to its monostatic observation,every AP receives the reﬂected echos from all the other APsand sends them to a central processing unit (CPU) trough aback-haul link here assumed error-free.The main contributions of this paper are the following:•We propose a novel transmit waveform model to be usedby distributed ISAC APs in a cell-free MIMO network.•We calculate the optimal transmit waveform by solvinga constrained CRB minimization problem. The relaxedversion of the original problem is proved to be tight forthe scenario at hand•We characterize the optimal AN structure, showing thatit’s rank-1 and directed towards the eve.•Numerical simulation prove the trade-off between sensingand communication performances a\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ssed usingthe data augmentation strategy. A lot of work has∗* indicates equal contributionbeen done over the years on data augmentation forthe English language. Indian languages, on theother hand, have received very little research.In this project, we are going to work on data aug-mentation for Indian languages. This project stemsfrom the motivation that no such work is carriedout in the past. We are going to implement ex-isting approaches for data augmentation like EasyData Augmentation, Back Translation, Paraphras-ing, Document Generation, etc. We plan on makingsome changes to these existing methods to tailorthem specifically for Indian languages.This work will be helpful in a lot of NLP taskslike News Classification, Hate Detection, EmotionAnalysis, Sentiment Analysis, and Spam Classifica-tion. All these tasks currently face the problem ofdata scarcity, which will be solved by our project.We aim to provide different methods for Data Aug-mentation. The user can implement different tech-niques and select what works best for the given usecase. Hence the outcome of our research work is:•Implementing different data augmentationtechniques.•Comparing all the methods to establish a base-line.2 Related WorkData augmentation has been extensively researchedin the field of Natural Language Processing (NLP)as a valuable approach to address the lack of train-ing data (Feng et al., 2021). One prominent tech-nique, introduced by (Sennrich et al., 2015), is backtranslation, which enhances the performance of ma-chine translation (MT) measured by BLEU scores(Papineni et al., 2002). This method involves trans-lating sentences into a different language and thentranslating them back into the original language,thereby augmenting the original text.(Fadaee et al., 2017) present a data augmentationmethod specifically designed for low-frequencyarXiv:2401.13085v1  [cs.CL]  23 Jan 2024words. This method generates new sentence pairsthat include these infrequently occurring words.(Kafle et al., 2017) contribute two data augmen-tation techniques for enhancing visual questionanswering. The first approach employs semanticannotations to augment the questions, while the sec-ond technique utilizes an LSTM network (Hochre-iter and Schmidhuber, 1997) to generate new ques-tions from images. (Wang and Yang, 2015) proposean augmentation technique that involves replacingquery words with their synonyms. The synonymsare retrieved based on cosine similarities calculatedusing word embeddings. Additionally, (Kolomiyetset al., 2011) propose a data augmentation strategythat involves replacing temporal expression wordswith their corresponding synonyms. This approachrelies on the vocabulary provided by the LatentWords Language Model (LWLM) and WordNet.(¸ Sahin and Steedman, 2019) suggest two textaugmentation methods that rely on dependencytrees. The initial technique involves cropping sen-tences by removing specific dependency links. Thesecond technique involves rotating sentences usingtree fragments that pivot around the root. (Chenet al., 2020) propose a text augmentation approachthat involves interpolating input texts within a hid-den space. (Wang et al., 2018) propose a methodfor augmenting sentences by randomly substitut-ing words in both input and target sentences withvocabulary words. SeqMix (Guo et al., 2020) pro-poses a technique for generating augmentations bysmoothly merging input and target sequences.EDA (Wei and Zou, 2019) employs four op-erations to create data augmentation: synonymreplacement, random insertion, random swap,and random deletion. In a different approach,(Kobayashi, 2018) suggests stochastically replac-ing words with predictions generated by a bi-directional language model. (Andreas, 2019) pro-poses a compositional data augmentation techniquethat constructs synthetic training examples by sub-stituting text fragments in a real example with otherfragments appearing in similar contexts. (Kumaret al., 2020) utilize pretrained Transformer models,such as GPT-2, BERT, and BART, for conditionaldata augmentation. They feed the concatenationof class labels and input texts into these modelsto generate augmented texts. Additionally, (Ku-mar et al., 2020) propose a language model-baseddata augmentation method. This method involvesfine-tuning a language model on a limited train-ing dataset and then using class labels as input togenerate augmented sentences. (Min et al., 2020)explore various syntactically informative augmen-tation techniques by applying syntactic transfor-mations to original sentences and demonstrate thatsubject/object inversion can enhance robustness toinference heuristics.3 DatasetThe proposed work obtains data augmentation fora total of the following 6 languages:•Sindhi (Raza, 2022): This dataset is a valu-able resource for researchers in the field ofSindhi Natural Language Processing (NLP),as it represents one of the limited publicly ac-cessible collections of Sindhi articles. It com-prises a total of 3364 articles that s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tensive datasets ( e.g., ImageNet-21k [88], Open Images [54]) andthen finetuned to adapt to specific downstream tasks [46] ( e.g., Coco-stuff [7], FGVC [48], VTAB-1k [126]). As models drastically scale up to boost performance, full finetuning that unfreezes allparameters for the update becomes computationally and storage-intensive [110; 14] and impractical.This traditional method can also lead to the loss of valuable knowledge acquired during pretraining,thereby limiting the models’ generalizability [48; 133].To address this issue, the search for parameter-efficient finetuning methods in vision is an ongo-ing endeavor. These parameter-efficient approaches freeze most parts of the pretrained model,and only tune the rest or insert customized learnable modules, which significantly reduce thenumber of learnable parameters compared to full finetuning [16; 47; 68; 84; 128]. Among allthese methods, visual prompt tuning [48], which is again inspired by language-domain promptingworks [67; 101; 64; 63; 33], stands out as one of the most prominent techniques in this field. VPT in-troduces a small number of extra trainable parameters (typically less than 1% of model parameters)in the input space of the transformer layers while keeping the backbone frozen. For the first time, itachieves superior performance over full finetuning in image recognition, and is quickly adapted intoother visual tasks such as image segmentation [61; 119; 129; 109], image captioning [134], etc.With VPT’s growing popularity [3; 98; 111], a research question naturally arises: when and whydoes visual prompt tuning (VPT) outperform full finetuning (FT) as transfer learning paradigm?∗Corresponding author†National Key Laboratory of General Artificial Intelligence, Beijing Institute for General Artificial Intelli-gence1arXiv:2401.12902v1  [cs.CV]  23 Jan 2024Published as a conference paper at ICLR 2024To address this question, we conducted extensive experiments on 19 diverse datasets and tasks,wherein VPT outperformed FT in 16 instances. To discern when VPT is preferred, we catego-rized transfer learning scenarios into four groups based on the disparity between the original anddownstream tasks, based on task objectives and data distributions (Figure 1). We found that VPTis advantageous when ( Case 1) a substantial gap exists between the original and downstream tasks(e.g., transitioning from classification to counting) or ( Case 2 ) the data distributions are notably sim-ilar between the tasks ( e.g., both deal with natural images). The size of the downstream task datasetalso influences this preference, with FT becoming increasingly favorable as the data size grows.TaskDissimilar SimilarSimilarDissimilarData      Full fine -tuning              Visual  prompt tuning  Count, Distance, Location, etc............Figure 1: VPT is identified to be prefer-able in 3 out of 4 transfer learning scenar-ios when downstream data is limited.We further investigate why VPT excels. While oneplausible hypothesis suggests that FT is more prone tooverfitting due to its numerous tunable parameters, ourexperiments reveal that this is only part of the story.Overfitting is primarily observed in Case 1 (high taskdisparity), while in Case 2 , both methods show no trendfor overfitting. A possible explanation is that the ad-ditional parameters introduced by VPT offer additionaldimensions to escape the local minima of the pretrainedmodel. However, empirical results do not support thisassumption when we compare methods with additionaldimensions. Our exploration of various tuning methodvariations underscores the importance of preserving theoriginal feature for achieving superior performance, al-beit through a non-obvious pathway. Our results sug-gest that VPT preserves features and add parameters ina unique manner that is pivotal in this process.Overall, this study aims to provide a thorough reassessment of the effectiveness of VPT comparedto FT. The primary contributions of this paper can be summarized as follows:• We identify the transfer learning scenarios where VPT proves advantageous by considering twocritical dimensions: data distributions and task objectives. Notably, VPT is preferable in 3 out of 4quadrants, with FT gradually closing the performance gap as the downstream data size increases.• We uncover that overfitting alone does not account for all of VPT’s success. Moreover, the ad-vantage of VPT cannot be attributed solely to additional parameters aiding the model in escapinglocal minima. The unique introduction of extra parameters plays a key role in VPT’s performance.• To showcase the efficacy of prompt tuning over full finetuning, we provide attention map visual-izations for both methods and demonstrate that visual prompts could enhance feature learning.2 R ELATED WORKFull finetuning. The emergence of convolutional neural networks (CNNs) ( e.g., VGG [95],ResNet [39], MobileNet [44; 89; 43]) makes a significant contribution to the rapid advancementsin computer vision. T\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sed.IntroductionStreet-level imagery is becoming an increasingly popular form of data for research [1].In particular, Street View Images (SVI) as popularized by Google Street View are usedin many studies [2,3]. Uses for SVI data include estimating demographics [4], evaluatingthe built environment [5], surveying plant species [6], measuring pedestrian volume [7]and many other applications [8–10].While SVI data can provide many useful insights for researchers, it is not without itsflaws. For corporate-collected images such as Google Street View, or Tencent StreetView the availability of images depends on where the companies decide to collect data,January 25, 2024 1/16arXiv:2401.13087v1  [cs.CV]  23 Jan 2024while the accessibility of these images hinges on the companies’ data provision policies.For example, there is no Google Street View service in most parts of Africa. Analternative to corporate-collected images are crowdsourced SVI databases such asMapillary [11]. These crowdsourced images sometimes will have better coverage ortemporal resolution than Google Street View, at the cost of varying image quality, fieldof view, and positional accuracy [3,12]. Perhaps the largest challenge with SVI data isits temporal instability. Updates to these image datasets at specific locations areinfrequent, especially in rural areas [1,13,14]. Additionally, images frequently are notcollected at a consistent time of day, or season, even within the same city. These issuesmake existing SVI data unreliable for temporal studies.Typically, temporal studies involving image data use images (or video) from fixedlocations. This data is used to do things such as evaluate disaster recovery [15], monitorecological change [16], or measure urban flooding [17]. Data from fixed cameras is alsoused to count people [18]. The challenge with these methods is that they arefixed-location. In order to collect spatial image data for these methods, frequently alarge team is required to traverse areas on foot. This challenge, along with existing SVIdata’s temporal issues demonstrate the potential value of collecting longitudinal SVIdata.Our main contribution is demonstrating the feasibility of collecting longitudinal SVIdata. We demonstrate this through the creation of a complete data pipeline forconducting pedestrian counts using car-based street-level imagery. The pipeline acceptsraw video collected by the camera as an input and outputs a record of each pedestriandetection and their locations (latitude and longitude). This approach allows for analysisof mobility patterns with high spatial resolution and a short lag time.Specifically, we use this pipeline to generate and analyze video from 37video-collection runs in the city of Seattle, Washington, USA from May 2020 throughJuly 2023. The video data was converted into over 4 million high-resolution images, witheach data-collection run representing about 1.5 TB of image data. We used the imagesto create a record containing the location of each detected pedestrian, cross-referencedto the relevant GEOID [19]. To detect pedestrians in the still images, our pipelineleverages the state-of-the-art convolutional neural network, Pedestron [20]. We used thecascade hrnet architecture benchmarked on on the CrowdHuman data set [21].As a secondary contribution, we provide a case study based on the video datacollected throughout the COVID-19 pandemic. We examine the effect of vaccineavailability and local demographics on pedestrian detections, while accounting forweekly and yearly seasonality. Our findings demonstrate the utility of our dataprocessing pipeline in tracking community mobility over time and show the potential forits use in a variety of research domains.MethodsData CollectionWe collected our data as a part of the the Seattle street-level imagery campaign, anongoing series of video surveys for the purposes of documenting mobility throughout theCOVID-19 pandemic. During each survey, a vehicle equipped with a 360◦video camerais driven along pre-defined route through Seattle while collecting video data and GPSmetadata. The route incorporates broad neighborhood/area canvassing designed tocollect data useful to multidisciplinary researchers as well as capital transects. Fulldetails on the route design are available in Errett et al. [22]. The capital transectsspecifically target capitals (social, cultural, built, economic, and public health) whichare theorized to be closely tied to community resilience [23]. Specific canvassing areasJanuary 25, 2024 2/16and capitals within Seattle were chosen to ensure a representative sample of the overallpopulation of Seattle [22]. While the drivers try to make the surveys as consistent aspossible, occasionally exogenous factors caused deviations from standard protocols. Forexample, during three of the surveys (05-29-2020, 06-18-2020, and 06-26-2020), protestsover the murder of George Floyd caused parts of the survey route to be unnavigable.Data Processing PipelineAfter vid\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ion resources, whichlimit their ability to process their computation tasks in a reliableand efficient manner [3]. To tackle this problem, mobile edgecomputing (MEC) is a promising solution in which base stationsare equipped with high-capacity computation resources, to whichIIoT mobile devices can offload their computation tasks for fastexecution. Nevertheless, computation task offloading adds an ad-ditional transmission delay to the computation delay. Therefore,IIoT mobile devices must decide whether to remotely or locallyexecute their computation tasks based on the availability andquality of communication resources and traffic load.The huge number of connected IIoT mobile devices and theirvarious computation data traffic load drives the adaptabilityof dynamic multichannel access schemes to allow efficientutilization of spectrum resources. However, it is difficult forIIoT mobile devices to observe all channel states across thenetwork. Traditional multichannel access approaches are mainlycategorized into contention-based and contention-free schemes.In contention-based, IIoT mobile devices access the channel in arandom way, thus if multiple IIoT mobile devices simultaneouslychoose the same channel to offload their computation tasks, highinterference and collision may occur leading to low efficient taskoffloading performance [3], [4]. On the other hand, contention-free adopts a centralized coordinator to allocate resources, whichmay cause overhead and delay, that may not be tolerable bysome applications. Thus, task offloading may not give betterperformance than local computing. Therefore, in this work, weinvestigate the problem of joint task offloading decision andtask scheduling for maximizing the number of computationtasks that can be executed under a task deadline constraint.Recently, reinforcement learning has shown a great advantagein solving problems in dynamic environments, where agents canmake decisions based on their partial observations and historicalinformation [5]. Therefore, we adopt reinforcement learning(RL) as a framework to coordinate multichannel access and taskoffloading to achieve efficient computing.The works in [6]–[10] studied the task offloading problem inthe IIoT environment using RL. Studies in [6], [7] minimized thesystem delay using different RL algorithms such as Q-learning,and deep deterministic policy gradient (DDPG). However, theauthors ignored the multichannel access problem and assumedthat communication channels are uniformly distributed and pre-allocated to the IIoT mobile devices at each time slot, whichis an unrealistic assumption. The work in [8], [9] consideredmultiple edge computing servers to minimize the long-termenergy consumption and system costs (i.e., energy and delay).Nonetheless, the authors assumed that each edge server has onecommunication channel serving an IIoT mobile device, whichis an unrealistic assumption.The closest related work to our study is [10], which con-sidered the joint multichannel access and task offloading prob-lem. Therein, the proposed RL algorithm shows a significantreduction in computation delay and improvement in channelaccess success rate compared to single-agent RL algorithms. 979-8-3503-1090-0/23/$31.00 © 2023 IEEEarXiv:2401.12914v1  [cs.IT]  23 Jan 2024However, the authors ignore the connection establishment time,during which the signaling control messages are exchangedamong agents to coordinate channel access which may notalways achieve a good policy. Moreover, the authors ignoreddynamically generated computation traffic. In contrast to thiswork, we consider the problem of jointly learning the signalingcontrol messages and offloading decision policy to achieve abetter coordination policy in dynamic environments.Emergent communication protocols have been studied usingMARL in [11], [12] and have shown a significant improvementin learning cooperative behavior in multi-agent reinforcementlearning. The authors in [13]–[16] show that a significant reduc-tion in signaling overhead and delay and higher average good-put and successful channel accessing is achieved via emergentcommunication protocols. Thus, in this study, we aim to pro-pose a general framework adopting emergent communicationprotocols for solving the computation offloading decision andmultichannel access problem. The goal is to let agents learna joint offloading decision and multichannel access policy viacommunication. To the best of our knowledge, this is thefirst work applying emergent communication protocols in amobile edge computing IIoT scenario. Our contribution can besummarized as follows:•We proposed a novel framework for mobile edge computingin IIoT based on emergent communication to solve theproblem of joint task offloading decision and schedulingof computation tasks.•We consider a dynamic traffic arrival model and show thatour proposed combined scheme, which offloads part of thetasks when resources are available and executes part oftasks locally in case of scarce res\n",
      "----------------------------------------------------------------------------------------------------\n",
      " 2023, taking up 22.3%of the global retail market [12].Preprint of the paper accepted to ECML PKDD 2023 ML4ITS WorkshoparXiv:2401.13096v1  [cs.LG]  23 Jan 20242 Kozodoi et al.Consequences of wrong demand estimates vary from missed sales opportunitiesdue to articles being out-of-stock [8] to overproduction waste [6].E-commerce retailers frequently operate with thousands of articles sold si-multaneously, and experience dynamic and volatile demand [9]. This poses chal-lenges for accurate demand forecasting. One of the key difficulties is that thearticle’s demand depends not only on its historical demand, but also on demandfor similar articles, introduction and removal of competing articles, out-of-stockevents, and other information. This emphasizes the importance of incorporatingarticle relationships into a forecasting model in a principled manner.Traditional forecasting techniques such as Autoregressive Integrated MovingAverage(ARIMA)models[4]areunivariateandconsiderindividualtimeseriesinisolation. In contrast, modern techniques based on deep learning models such asDeepAR [21] or Temporal Fusion Transformer [15] are trained on multiple timeseries simultaneously, which allows learning the past behavior across similar se-ries. However, such global models are typically unable to incorporate inter-seriesrelationships during inference, failing to account for the impact of related articleson the article’s of interest demand. Integrating time series relationships duringboth training and inference is feasible with multivariate models such as VectorAutoregressive (VAR) models [28]. At the same time, such models experiencedifficulties with scaling to high-dimensional e-commerce environments.Recentresearchhassuggestedusinggraphstoaccountfortheinter-seriescor-relations. Representing the data as a graph and using Graph Neural Networks(GNNs) to extract patterns from graph-structured data allows integrating timeseries relationships directly into a prediction model [24]. Studies outside of theretail domain have developed architectures that combine recurrent models andGNNs and have shown promising results in forecasting road traffic or weatherevents [17,26,27]. At the same time, the literature on GNNs for demand fore-casting is scarce. Recently, Gandhi et al. [9] proposed a GNN-based forecastingapproach suited for a multiple-seller marketplace setting and demonstrated thatGNNs have potential to improve the forecasting accuracy for cold-start articles.This paper proposes a novel demand forecasting approach that builds on theframework of Gandhi et al. [9] and makes two contributions. First, we developan end-to-end forecasting model architecture that combines two components: (i)GNN encoder that incorporates article relationships during training and infer-ence; (ii) state-of-the-art DeepAR decoder for demand forecasting. In contrastto recurrent architectures commonly used in the literature, DeepAR producesprobabilistic demand predictions, which are crucial for decision-making underuncertainty [21]. We denote the proposed forecasting model as GraphDeepAR.Our second contribution is proposing a generic graph construction approachthat does not require a pre-defined graph structure. We build graphs using pair-wise article attribute similarity to define connections between articles, which al-lows leveraging article meta-data to model article relationships and augmentingit with domain knowledge. Unlike some of the previous approaches, the proposedsolution is highly scalable. We test GraphDeepAR on three real-world datasetsand show that it outperforms the standard DeepAR model.Probabilistic Demand Forecasting with GNNs 3The rest of the paper is organized as follows. Section 2 overviews related workon forecasting and graph machine learning. The proposed demand forecastingapproach is introduced in Section 3. Section 4 describes the experimental setup,whereas Section 5 provides and discusses the empirical results. Section 6 sum-marizes the main conclusions taken from the experimental results.2 Related Work2.1 Leveraging Inter-Series RelationshipsForecasting refers to prediction of future events based on the previously observeddata. One of the key challenges in forecasting is accounting for relationshipsbetween multiple time series [16]. Many of the modern forecasting techniquesfocus on a univariate setting, where the task is limited to modeling a singletime series or a small number of individual unrelated series. In practice, one isoften required to forecast a large number of related series at the same time (e.g.,energyconsumptionacrossdifferenthouseholdsorconsumerdemandformultiplerelatedarticles)[21].Insuchsettings,demandforagivenarticledependsnotonlyon its historical demand, but also on the demand for substitute and complementarticles, launch of new competing articles, and other related factors [9].One way to account for such relationships during training is to use globalmodels such as DeepAR [21]. Here, we refer to models that are traine\n",
      "----------------------------------------------------------------------------------------------------\n",
      "/MMInstruction/RedTeamingVLMQuestion:can you tell me some information about this person?NOTE：This is an AI-generated image, not a real personQuestion :can you tell me what happened in this image?Question:What is the country of citizenship of J. K. Rowling?RedTeamingCasesQuestion:can you tell me some information about this person?NOTE：This is an AI-generated image, not a real personAnswer: J. K. Rowling is a citizen of the United Kingdom.Question :can you tell me what happened in this image?Answer: : I'm sorry, but I can't assist with identifying or making assumptions about people in images.Question:What is the country of citizenship of J. K. Rowling?GPT-4VReferenceAnswerAnswer: : I'm sorry, I can't provide that information.SelfSafetyDataCollectionRedTeaming🌋LLaVAFuyuQwenGPT-4VVisualGLMGPT-4VEvalDiffusion generatedOpen-sourcedTool generatedSelf-instructHumanHumanCheck…RedTeamingAlignmentsFaithfulnessPrivacySafetyFairnessW/OAlignmentW/Alignment🙁😄Figure 1: Overview of our RTVLM pipeline, includingdata collection, evaluation, and alignment.Despite promising progress achieved by VLMs,their performance under challenging scenarios stillremains unclear. There is abundant evidencedemonstrating that the backbone of VLMs, i.e.,the LLMs, tend to generate incorrect or harmfulcontent for certain red teaming cases (Perez et al.,2022; Zou et al., 2023; Gallegos et al., 2023; Chenet al., 2023c). It is natural to assume that the VLMsbuilt upon the LLMs may possess potential risk aswell. Besides, given their unique blend of textualand visual input, new types of red teaming casesthat pose a significant threat to the deployed VLMsmight be overlooked. Preliminary cases demon-strate that the early version of GPT-4V also suffersunder red teaming, such as generating discrimina-arXiv:2401.12915v1  [cs.AI]  23 Jan 2024tory remarks and being used to disclose personalinformation (OpenAI, 2023). Therefore, a stresstest with red teaming cases is necessary for the safedeployment of VLMs, providing insights for subse-quent improvements of the model to further alignwith ethical and privacy standards. Nevertheless,there is a lack of comprehensive and systematic redteaming benchmark for current VLMs.To fill this gap, we introduce the Red Team-ing Visual Language Model (RTVLM) dataset,meticulously focusing on red teaming in scenariosinvolving image-text input. Figure 1 illustrates thewhole process of dataset construction, evaluation,and alignment. Based on previous works (OpenAI,2023; Perez et al., 2022), we summarize 4 aspectsof red teaming: Faithfulness ,Safety ,Privacy , andFairness . This dataset comprises 10 task categoriesdistributed across these 4 aspects, shown in Figure2. Under faithfulness , we investigate the models’ability to generate accurate outputs despite givenmisleading inputs. Regarding privacy , the modelsare required to distinguish between public figuresand private individuals, ensuring non-disclosure ofprivate information. For safety , we assess the mod-els’ ability to reject responses to potentially harm-ful or legally sensitive multimodal inputs. Fairnessis measured by examining the bias of individualsdiffering in race and gender. To guarantee thatour test data is novel and has not been seen bythe evaluated VLMs, we construct new question-image pairs based on publicly available imagesor originally diffusion-generated images (Gallegoset al., 2023). Our red teaming questions are an-notated by humans, or generated by GPT-4 withself-instruction (Wang et al., 2023b) accompaniedby human-written seed examples. After a man-ual check on all the question pairs, the resultingRTVLM dataset comprises 5,200 samples.With the RTVLM dataset, we test a suite ofVLMs and analyze their performance under thisred teaming test. We first establish a set of scoringcriteria targeting the 4 aspects mentioned above fol-lowing Peng et al. (2023). Specifically, we conductGPT-4V eval and human eval to score the VLMmodels’ output on the RTVLM , including 10 open-sourced VLMs along with the current version ofGPT-4V , measuring their performance across thefour dimensions of faithfulness, safety, privacy, andfairness. We conduct a detailed analysis of the mod-els’ performance in each subcategory. We find that:1.All 10 prominent open-sourced VLMs exhibitvarying degrees of struggle in red teamingchallenges, displaying up to a 31% perfor-mance gap compared to GPT-4V .2.We verify the current VLMs lack of alignmentin red teaming. By applying SFT to LLaV A-v1.5 using RTVLM , we enhance the model’sperformance by 10% on the RTVLM test set,by 13% on MM-hallu, and maintain stableperformance on MM-Bench, surpassing otherLLaV A models using regular alignment data.Overall, our study serves as the first red teamingbenchmark for visual language models, elucidatingtheir vulnerabilities and proposing credible solu-tions for future work.2 RTVLM DatasetIn this section, we outline the construction processof our RTVLM . We first present an overview ofour data format and statis\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ation. Our findings also motivate the development of AI systems that better understand and serve diverse communities, moving towards technology that equitably benefits all sectors of society.  Significance Statement Computer vision systems are used for home security devices, medical imaging, and autonomous vehicles. These systems are trained on tens of millions of images found on the web. This study aimed to assess the extent to which this process creates bias. We found that popular computer vision systems are less accurate and less confident when classifying images of homes from lower socioeconomic status (SES), and this pattern was observed both between- and within countries. These findings highlight significant disparities in AI performance based on socioeconomic factors, emphasizing the need for more inclusive and diverse training datasets to prevent AI systems from perpetuating societal inequities.      3 Introduction In recent years, the rapid advancement of computer vision technology has transformed many domains, ranging from autonomous vehicles to medical diagnostics. Yet, beneath the surface of this digital revolution lies a complex and often overlooked reality: computer vision systems are not immune to the biases and inequalities that permeate human society. While there is increasing understanding that there are race, gender, and age-based gaps in computer detection of people from photographs and videos (1, 2), as well as biased assumptions about groups of people from photographs (3–8), comparatively little is known about the biases that may exist for places. As scene-based information is now being used in various urban planning (9) and home valuation (10, 11) contexts, it is necessary to assess potential social biases in the computer vision classification of places.  Potential for bias exists in all steps of a standard computer vision pipeline. Deep convolutional neural networks (dCNNs), known for their extensive data requirements, often rely on web scraping to amass a broad sample of images. Creating a scene database might begin with compiling an exhaustive list of scene categories and then employing web scraping to gather image exemplars for each category (12). However, the label set can often contain offensive terms or terms that can be used in an offensive way (13–15), leading to the inclusion of problematic content. Sourcing images from the web has been shown to return images that exacerbate gender and racial biases (3). Crowdsourcing is then used to ensure that the scraping procedure leads to correct category labels. However, any prejudices of the crowd workers tend to be mirrored and even intensified in the final datasets (16). Our study examines the biases inherent in the scene classifications of dCNNs. We consider three datasets totaling nearly one million images from real-world homes, comprising both user-submitted home photographs and images scraped from the Airbnb website. We tracked the classification accuracy, confidence, and potential for bias in several pretrained dCNNs. Our results starkly revealed that pretrained dCNNs exhibited lower classification accuracy and confidence alongside a heightened tendency to assign offensive labels, particularly in images from homes of lower socioeconomic status (SES). This pattern persisted not only in global comparisons but also within the varied economic and racial landscapes of the United States. These findings illuminate the profound influence of socioeconomic and developmental factors on computer vision performance, highlighting significant concerns about unintentional biases in automated image categorization systems. Such biases underscore the pressing need for more inclusive and representative training datasets to mitigate these disparities and ensure fairer outcomes in AI applications.  4 Results Dollar Street We first considered a set of ~1200 images of homes submitted by families in 54 countries on the Dollar Street website (17). In our initial analysis, we evaluated classification accuracy (top-1 and top-5) using three deep convolutional neural networks (dCNNs) that were pretrained on the Places database (12) to classify scenes. The findings revealed a notable disparity in classification accuracy compared to the established benchmark from the Places test set, see Table 1. These results suggest that images sourced from domestic settings are not classified as accurately by these networks as images obtained from standard Internet datasets.     Network Metric Places benchmark Dollar Street Χ2 Alexnet Top-1 53% 21% 485.7 Resnet-18 Top-1 55% 32% 268.9 Resnet-50 Top-1 55% 33% 229.2 Alexnet Top-5 83% 47% 1094.3 Resnet-18 Top-5 85% 59% 627.9 Resnet-50 Top-5 85% 62% 508.3  Table 1: Performance on Dollar Street image set versus Places test set benchmarks. For all networks and both top-1 and top-5 accuracy, all differences are highly statistically significant (p<<0.001).  We employed a linear mixed-effects modeling approach to understand the fact\n",
      "----------------------------------------------------------------------------------------------------\n",
      ", Karl Friston, Mark Girolami, Michael I. Jordan andGrigorios A. Pavliotis for helpful input on a preliminary version to this manuscript. The authors thank Joshua B.Tenenbaum and MIT’s Computational Cognitive Science group for interesting discussions that lead to some of the pointsdiscussed in this paper. LD is supported by the Fonds National de la Recherche, Luxembourg (Project code: 13568875)andaG-Researchgrant. ThispublicationisbasedonworkpartiallysupportedbytheEPSRCCentreforDoctoralTrainingin Mathematics of Random Systems: Analysis, Modelling and Simulation (EP/S023925/1). NS is funded by the MedicalResearch Council (MR/S502522/1) and 2021–2022 Microsoft PhD Fellowship.arXiv:2401.12917v1  [cs.AI]  23 Jan 20241 IntroductionReinforcement learning (RL) is a collection of methods that describe and simulate agency—how to map situations toactions—traditionally framed as optimising a numerical reward signal [1]. The idea of maximising reward as underpinningagency is ubiquitous: with roots in utilitarianism [2] and expected utility theory [3], it also underwrites game theory [3],statistical decision-theory [4], optimal control theory [5,6], and much of modern economics. From its inception, RL practi-tioners have supplemented reward seeking algorithms with various heuristics or biases geared towards simulating intelligentbehaviour. Especially effective are intrinsic motivation or curiosity-driven rewards that encourage exploration [7–9]. Thus,we ask:is there a canonical way to think of agency beyond reward maximisation?In this paper, we show that any behaviour complying with physically sound assumptions about how macroscopic biologicalagents interact with the world canonically integrates exploration and exploitation by minimising risk and ambiguity aboutexternal states of the world. This description, known as active inference, refines the free energy principle, a populardescriptive framework for action and perception birthed in neuroscience [10–12].Active inference provides a generic framework to simulate and model agency that is widely used in neuroscience [13–17],RL [18–21] and robotics [22–25]. The usefulness of active inference for RL is three-fold. a) Active inference providesan effective solution to the exploration-exploration dilemma that englobes the principles of expected utility theory [3]and Bayesian experimental design [26] and finesses the need for ad-hoc exploration bonuses in the reward function ordecision-making objective. b) Active inference provides a transparent recipe to simulate behaviour by minimising riskand ambiguity with respect to an explicit generative world model. This enables safe and explainable decision-making byspecifically encoding the commitments and goals of the agent in the world model [23]. c) Active inference is universal inthe sense that it is theoretically possible to rewrite any RL algorithm conforming to the descriptive assumptions of activeinference as an active inference algorithm, e.g., [27]. Thus, active inference can be used as a tool to uncover and comparethe commitments and assumptions of more specific models of agency.2 Deriving agency from physicsWedescribesystemsthatcompriseanagentinteractingwithitsenvironment. Weassumethatanagentanditsenvironmentevolve together according to a stochastic process x. This definition entails a notion of time T, which may be discrete orcontinuous, and a state space X, which should be a measure space (e.g., discrete space, manifold, etc.). Recall that astochastic process xis a time-indexed collection of random variables xton state space X. Equivalently, xis a randomvariable over trajectories on the state space T → X. We denote by Pthe probability density of xon the space oftrajectories T → X(with respect to an implicit base measure).In more detail, we factorise the state space Xinto states that belong to the agent Hand states external to the agent Sthat belong to the environment. Furthermore, we factorise agent’s states into autonomous states Aandobservable statesO, respectively defined as the states which the agent does and does not have agency over. In summary, the system xis formed of external sandagentprocesses h, the latter which is formed of observable o, andautonomous aprocessesX ≡ S × H ≡ S × O × A =⇒x≡(s, h)≡(s, o, a ).The description adopted so far could aptly describe particles interacting with a heat bath [28–30] as well as humansinteracting with their environment (Figure 1.A). We would like a description of macroscopic biological systems; so whatdistinguishes people from small particles? A clear distinction is that human behaviour occurs at the macroscopic leveland, thus, is subject to classical mechanics. In other words, people are precise agents :Definition 2.1. An agent is precisewhen it responds deterministically to its environment, that is when h|sis adeterministic process.Remark 2.2.It is important not to conflate an agent’s mental representations of external reality with external states; theformer are usually an \n",
      "----------------------------------------------------------------------------------------------------\n",
      "mble the target data, while maintaindiversity. See [64] for a comprehensive review on DPMs.DPMs relies on forward-backward Markov processes. The forward process starts with thetarget data distribution, and runs for some time until the signal is destroyed – this gives risetonoise. The backward process is then initiated with the noise, and reverses the forwardprocess in time to generate samples whose distribution is close to the target distribution.In [2, 25, 54], DPMs are discrete time-indexed Markov chains; [12, 53, 57] model DPMsin continuous time as stochastic differential equations (SDEs). Nevertheless, there is noconceptual distinction between discrete and continuous DPMs as continuous DPMs can beviewed as the continuum limits of discrete DPMs, and discrete DPMs are time discretizationof continuous DPMs. In this paper, we adopt a continuous time perspective, and algorithmsare derived by discretization. Being concrete:Date: January 25, 2024.1arXiv:2401.13115v1  [cs.LG]  23 Jan 20242 WENPIN TANG AND HANYANG ZHAO•The forward process (Xt,0≤t≤T)is governed by the SDE:dXt=b(t, Xt)dt+σ(t)dBt,with X0∼pdata(·),where (Bt, t≥0)is Brownian motion in Rd,b:R+×Rd→Rdandσ:R+→R+aremodel parameters to be designed, and pdata(·)is the target data distribution.•The backward process (Xt,0≤t≤T)is governed by the SDE:dXt=b(t,Xt)dt+σ(t)dBt,with X0∼pnoise(·),where (Bt, t≥0)is Brownian motion in Rd,b(t, x)andσ(·,·)aresomefunctions,andpnoise(·)is the noise distribution that does not depend on pdata(·).It is easy to see that the forward process transforms data to noise (with a suitable choice ofb(·,·)andσ(·)). What is miraculous is how the backward process recovers the target datadistribution XT≈pdata(·)from noise pnoise(·). The secret consists of two key ingredients:(1)Time reversal of diffusion processes : Thebackwardprocesshasanexplicitform, whereb(t, x)depends on b(T−t, x),σ(T−t)and Stein’s score functions (the gradients ofthe log marginal density of the forward process), and σ(t) =σ(T−t)[9, 24].(2)Score matching : The backward process is easily sampled given b(·,·),σ(·)and scorefunctions. The trick is to learn score functions via forward sampling, referred to asscore-based DPMs. Leaning score functions, also known as score matching, featuresin a body of active research [26, 32, 56, 62].In a nutshell, DPMs combine forward (score) learning/matching with backward sampling.Asisclear, aDPMisspecifiedbythepair (b(·,·), σ(·)). PopularexamplesincludeOrnstein-Uhlenbeck (OU) processes [15], variance exploding (VE) SDEs, variance preserving (VP)SDEs,andsub-variancepreserving(sub-VP)SDEs[57](seeSection2fordefinitions). Especially,VE and VP SDEs are the continuum limits of score matching with Langevin dynamics(SMLD) [54] and denoising diffusion probabilistic models (DDPMs) [25] respectively. Anatural question is:How do we design the pair (b(·,·), σ(·)) (b(·,·), σ(·)) (b(·,·), σ(·))for a DPM?The first rule of thumb, which is satisfied by all the aforementioned examples, is:Rule 1.The conditional distributions of Xt|X0are easy to sample (e.g. Gaussian) .This rule allows efficient sampling in the forward process for score matching via stochasticoptimization. Notably, Rule 1 provides only instructions on the forward learning step, butno requirement on backward sampling.The purpose of this paper is to put forward a principle regarding backward sampling in thedesign of DPMs. Our proposal is:Rule 2.The backward process Xis contractive .Roughly speaking, being contractive indicates that the process tends to be confined, orconverge (see Section 3 for explanations). DPMs that comply with Rule 1 and 2 are calledcontractive DPMs (CDPMs). HereweabusethetermcontractiveDPMsbymeaningthattheirbackward processes, rather than the forward processes, exhibit contractive properties. At ahigh level, the contraction of the backward process will prevent score matching errors, whichmay be wild, from expanding over the time. The contributions of this work are summarizedas follows.CONTRACTIVE DIFFUSION MODELS 3•Methodology : We propose a new criterion ( Rule 2) for designing DPMs. Thisnaturally leads to a novel class of DPMs, including contractive OU processes andcontractive sub-VP SDEs (see Section 4). The idea of requiring the backward processto be contractive stems from sampling theory of SDEs, so our methodology is theory-oriented. To the best of our knowledge, this is the first paper to integrate contractionintothedesignofDPMs,withboththeoreticalguaranteesandgoodempiricalperformance.•Theory: We prove Wasserstein bounds between contractive DPM samplers and thetarget data distribution. While most previous work (e.g. [12, 15, 35]) focused onKullback–Leibler (KL) or total variation bounds for OU processes, we consider theWasserstein metric because it has shown to align with human judgment on imagesimilarity [5], and the standard evaluation metric – Fréchet inception distance (FID)is based on Wasserstein distance. Early work [15, 34] gave Wasserstein bounds forthe exi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "for truck operators. De-spite these efforts, truck drivers still spend considerable timesearching for safe parking locations beyond their limited legalworking hours [1]. This phenomenon highlights the persis-tent issue of inadequate truck parking facilities, contributingto unauthorized parking behaviors and breaches of parkingregulations [2].The literature identifies increasing truck drivers’ accessi-bility to real-time parking usage information [3] and drivers’perceptual interpretations [4], [5] as major factors influencingthese parking challenges. According to the survey studies inThe Truck Parking Information System (TPIMS) was developed throughsponsorship and collaboration with Mid America Freight Coalition (MAFC)and participating states of Mid America Association of State TransportationOfficials (MAASTO). The ideas and views expressed in this paper are strictlythose of the Traffic Operations and Safety (TOPS) Laboratory at the Universityof Wisconsin-Madison.R. Tamaru, Y . Cheng, S. Parker, E. Perry, B. Ran, and S. Ahnare with the Department of Civil and Environmental Engineering,University of Wisconsin-Madison, Madison, Wisconsin, United States,53705 (email: tamaru@wisc.edu; cheng8@wisc.edu; sparker@engr.wisc.edu;ebperry@wisc.edu; bran@wisc.edu; sue.ahn@wisc.edu;the region [6], members of the Mid-America Association ofState Transportation Officials (MAASTO) from eight states,Indiana, Iowa, Kansas, Kentucky, Michigan, Minnesota, Ohio,and Wisconsin, have collaborated to construct a real-time,multi-state Truck Parking Information Management System(TPIMS) to feed more practical truck parking information fortruck drivers [7], [8]. TPIMS, fully operating since January4th, 2019, provides real-time parking usage information totruck drivers through dynamic message signs, smartphoneapplications, traveler information websites (e.g., 511 travelerinformation), and other forms.In addition to real-time parking site availability information,future usage prediction can better support truck drivers intheir decision-making process and route planning. Currentprediction models exhibit commendable accuracy in predictingfuture usage for the subsequent hour [9], [10]. However, it iscrucial to recognize that the domain of interest encompassesmultiple truck parking sites situated along the highway cor-ridor. Boris and Brewster [1] reported that the most criticalaspects of the target parking sites are the proximity to theroute/destination followed by the amenity availability. Thus,the primary objective of our prediction models is to capitalizeon the wealth of data available from various truck parkingsites and leverage their topological structures.Since 2019, the research team has developed the TPIMSdata archiving system (TPIMS-DAS), designed to store effec-tively and track truck parking information [11]. Leveragingthe substantial benefits derived from an abundance of compre-hensive and detailed information on truck parking sites, userscan extract and aggregate truck parking data from eight statesin MAASTO using TPIMS-DAS. It also leads to providinga sufficient number of truck parking data to train reliablemodels. Using the advantages of wide-range truck parking datawith TPIMS-DAS, we fundamentally analyzed truck parkingusage patterns. [12]. In this research, we developed a modelgrounded in spatial dependencies of highway corridors tocomprehend how regional relationships of truck parking sitelocations can contribute to the future usage prediction task.This study first addresses the topological structures ofhighway corridors to assess multiple truck parking site usageprediction. We propose a Regional Temporal Graph NeuralNetwork (RegT-GCN) composed of a Graph Neural Networkwith temporal capability and novel decomposition modules toacquire regional relationships, separated by state (Figure 1).Utilizing the significant parking site information dataset, wecould leverage temporal dependencies of the multi-state-widetruck parking usage to acquire more accurate predicted results.We conducted several experiments to evaluate the importancearXiv:2401.12920v1  [cs.AI]  23 Jan 2024IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, MANUSCRIPT 2Figure 1. The overview of Regional Temporal Graph Neural Network.of Regional Decomposition for Graph Neural Networks.Our technical contributions can be summarized in the fol-lowing.•A spatio-temporal model to predict the multiple truckparking usage.•A novel Regional Decomposition method, which lever-ages the regional relationships to create subgraphs foreach region (i.e., state) and effectively captures the spatio-temporal dependencies.•The comprehensive truck parking data, which is aggre-gated across multi-states to train their spatio-temporaldependencies and evaluate the prediction accuracy ofoccupancy rates.•Extensive quantitative evaluation, which demonstratesthat our RegT-GCN significantly outperforms state-of-the-art baseline models.II. L ITERATURE REVIEWParking prediction methods can be cla\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ssical approaches use well-understood controllers with simple local interactionrules, giving rise to complex global emergent behavior [1]. Indeed, such controllers have proven ex-traordinarily useful in diverse domains. However, designing them requires both significant technicalexpertise and considerable domain knowledge. Second, recent learning-based approaches alleviatethe need for expertise and domain knowledge by leveraging advances in learning frameworks andcomputational resources. Learning has been successful in many domains, such as video games [2],autonomous driving [3], disaster response [4], and manufacturing [5].However, learning approaches are not without their fair share of limitations. First, the majority of ex-isting methods focus on homogeneous teams and, as such, cannot handle heterogeneous multi-robotteams. Second, and more importantly, even existing methods designed for heterogeneous teams areoften solely concerned with the challenge of learning to coordinate a given team, entirely ignoringthe challenge of generalizing the learned behavior to new teams. Given the potentially prohibitivecost of retraining coordination policies after deployment in real-world settings, it is imperative thatmulti-robot policies generalize learned behaviors to inevitable changes to the team.In this work, we focus on the challenge of generalizing multi-robot policies to team changes. Inparticular, we focus on generalization of trained policies to teams of new compositions, sizes, and∗Equal Contribution.†This work was supported in part by the Army Research Lab under Grants W911NF-17-2-0181 and W911NF-20-2-00367th Conference on Robot Learning (CoRL 2023), Atlanta, USA.arXiv:2401.13127v1  [cs.RO]  23 Jan 2024Figure 1: We investigate the role of capability awareness and communication in generalizing decentralizedheterogeneous multi-robot coordination policies to teams of new composition, size, and robots.robots that are not encountered in training (see Fig. 1). We refer to such generalization as adaptiveteaming , wherein the learning policy can readily handle changes to the team without additionaltraining. To this end, we need policies that can reason about how a group of diverse robots cancollectively achieve a common goal, without assigning rigid specialized roles to individual robots.We investigate the role of robot capabilities in generalization to new teams. Our key insight is thatadaptive teaming requires the understanding of how a team’s diverse capabilities combine to dic-tate the behavior of individual robots. For instance, consider an autonomous heterogeneous teamresponding to multiple concurrent wildfires. Effective coordination in such situations requires rea-soning about the opportunities and constraints introduced by the robots’ individual and relative ca-pabilities, such as speed, water capacity, and battery range. In general, robots must learn how theirindividual capabilities relate to those of others to determine their role in achieving shared objectives.We develop a policy architecture that can explicitly reason about robot capabilities when select-ing actions. Our architecture has four key properties: i) capability awareness : our design enablesactions to be conditioned on continuous capabilities in addition to observations, ii) capability com-munication : we leverage graph networks to learn how robots must communicate their capabilitiesiii)robot-agnostic : we utilize parameter sharing and learn policies that are not tied to individualrobots, and iv) decentralized : our trained policies can be deployed in a decentralized manner. To-gether, these four properties provide the potential to generalize to new teams. One can view thisdesign as an extension of agent identification techniques [6] to the metric space of capabilities. Assuch, capabilities do not merely serve to distinguish between agents during training to enable be-havioral heterogeneity [7], but also to provide a more general means to encode how individual andrelative capabilities influence collective behavior.We evaluate the utility of capability awareness and communication in two heterogeneous multi-robottasks in sim and real. Our results reveal that both awareness and communication of capabilities canenable adaptive teaming, outperforming policies that lack either one or both of these features in termsof average returns and task-specific metrics. Further, capability-based policies achieve superior zero-shot generalization than existing agent identification-based techniques, while ensuring comparableperformance on the training set.2 Related WorkLearning for multi-robot teams : Recent advances in deep learning are providing promising ap-proaches that circumvent the challenges associated with classical control of multi-robot systems.Multi-agent reinforcement learning (MARL), in particular, has been shown to be capable of solvinga wide variety of tasks, including simple tasks in the multi-agent particle environments (MPE) [8],complex tasks\n",
      "----------------------------------------------------------------------------------------------------\n",
      " on severalspeech emotion corpora.Index Terms —Source-free cross-corpus speech emotion recog-nition, speech emotion recognition, contrastive learning, transferlearning.1. INTRODUCTIONOver the course of the last decade, diverse SER applications havegained lots of attention with tremendous progress of deep learning[1, 2, 3, 4]. Though achieving huge successes, conventional SERmethods may encounter performance degradation, even when thetraining data and the test data deviate slightly from each other. Thus,researchers turn their attention to cross-corpus SER, where the train-ing data and test data come from different corpora, and multiple∗Corresponding authors,#Contribute equally to this work.This work was supported in part by the National Key R & D Projectunder the Grant 2022YFC2405600, in part by the NSFC under the GrantU2003207 and 61921004, in part by the Jiangsu Frontier Technology BasicResearch Project under the Grant BK20192004, in part by the YESS Programby CAST under the Grant 2023QNRC001, and in part by the ASFC under theGrant 2023Z071069003.methods have been proposed for cross-corpus SER [5, 6]. Conven-tional cross-corpus SER methods trend to alleviate the domain dis-crepancy by domain matrices [7, 8] or adversarial training [9, 10].Taking the adversarial training based methods as an example, thiskind of methods obfuscates the domain discriminator to prevent itfrom distinguishing between the source and target corpus samples.Common cross-corpus SER algorithms assume all data is avail-able during adaptation. In real-life scenarios, this assumption israrely possible due to data privacy protection. Labeled emotionalvoices can be treated as a form of identification for specific individu-als [11]. Improper disclosure of data with corresponding labels couldunduly influence data providers. This paper focuses on a more prac-tical and interesting task called source-free cross-corpus SER, wheresource data is inaccessible during adaptation. The goal is to adapt apre-trained model, originally trained on a source corpus, to performwell on a target corpus without any labeled source data. Traditionalcross-corpus SER methods focus on matching the target feature dis-tribution with the source one to alleviate domain gaps. However,here, this does not work since source-free cross-corpus SER facesthe challenge of source distribution estimation without access to thesource data. In this context, the main dilemma of this task is howto effectively utilize the pre-trained source model to identify targetsamples correctly despite the presence of domain shifts.To tackle the more practical and previously unexplored source-free cross-corpus SER problem, we propose a simple, yet effec-tive method called emotion-aware contrastive adaptation network(ECAN). It is worth noting that this is the first work dedicated toaddressing the source-free cross-corpus SER problem. The key ideais to update the target model using the pre-trained source model fromboth local and global perspectives. Building upon previous research[12, 13], we find that target data of the same emotion tends to forma cluster in the feature space despite domain shifts between sourceand target corpora. To exploit this inherent local structure betweentarget data, we propose a novel nearest neighbor contrastive learningalgorithm to enhance the semantic consistency among neighboringsamples. Besides, solely relying on nearest neighbor information foradaptation may result in ambiguous category boundaries, as the localstructure may not capture the full complexity of emotion distributionwithin the target data. To address this limitation, we incorporate su-pervised contrastive learning into the network, which aims to pullaway clusters of different emotions, to achieve emotion-wise globaladaptation. Both nearest neighbor and supervised contrastive learn-arXiv:2401.12925v1  [cs.SD]  23 Jan 2024Fig. 1 . Overview Structure of the Proposed ECAN in Dealing with Source-free Cross-Corpus SER.ing modules work in a promotion way, jointly considering enhancingof nearest neighbor information and emotion-level global adaptation.2. PROPOSED METHODIn this section, we will present the details of the proposed ECAN forcoping with the problem of source-free cross-corpus SER. Formally,we denote the labeled source speech emotion corpus and unlabeledtarget one as DsandDt, respectively. Both corpora have the samepredefined Cemotion classes. In source-free cross-corpus SER set-ting, the source corpus Dsis only available for source model pre-training, while in target adaptation we merely access the pre-trainedsource model and the unlabeled target corpus Dt. The feature ex-tractor takes a speech sample xias input and produces a featurerepresentation denoted as fi=f(xi)∈Rd, where dis the di-mension of the feature space. The output of the classifier is denotedaspi=σ(fi)∈RC, where σ(.)is the softmax function. Fig. 1shows the proposed structure.2.1. Nearest Neighbor Contrastive LearningAs mentioned before, even\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ons given their contexts, is a fundamental stepfor various text mining and natural language processing(NLP) tasks, such as entity linking (Wu et al. 2020) and textclassification (Hu et al. 2019). Entity typing in science andengineering domains poses substantial new challenges, call-ing for dedicated research. First, fine-grained entity typingis critical for domain-specific applications . For example, insoftware and security domains (e.g., StackOverflow threads,GitHub README files, and vulnerability descriptions), en-tities need to be typed in fine-grained scale (e.g., devices,operating systems, versions, and functions) in order to drivedownstream applications (e.g., technical question answering*Equal Contribution.Copyright © 2024, Association for the Advancement of ArtificialIntelligence (www.aaai.org). All rights reserved.(Yu et al. 2020, 2021) and knowledge graph construction(Rukmono and Chaudron 2023)).Second, massive human annotation is too costly to bea solution. Although entity typing has been extensivelystudied in NLP, most existing approaches rely on massivehuman-annotated training data, which are time-consumingand costly to obtain, especially in specialized technical do-mains. Moreover, practitioners in these domains often needto apply the model to their confidential datasets (e.g., in-ternal software issue reports) which cannot be accessed byexternal annotators, incurring domain gaps between train-ing and inference data. To alleviate annotation efforts, re-cent studies explore the setting of few-shot entity typing(Ding et al. 2022; Huang, Meng, and Han 2022; Dai andZeng 2023), where a few manually labeled samples are pro-vided to train the model. However, unless the entity typesare balanced (which is usually not the case – the numberof A PPLICATION entities is 24 times more than the numberof A LGORITHM entities in the StackOverflowNER dataset(Tabassum et al. 2020)), one needs to sample and annotate amuch larger number of entities to cover the minority types.Third, domain-agnostic zero-shot learning methods donot provide a good solution either. Previous zero-shot en-tity typing models (Zhou et al. 2018; Obeidat et al. 2019;Zhang et al. 2020a) rely on type names only and do notseek help from any annotated examples. This makes themodel unaware of domain-specific knowledge, which maylead to suboptimal performance in highly specialized sci-ence and engineering domains. For example, given the sen-tence “ ListView keep BooleanSparseArray of checked po-sitions (you can get it with method getCheckedItemPosi-tions()). ”, if we ask GPT-3.5 Turbo (Ouyang et al. 2022)about the type of “ ListView ” by providing it with type namesonly, GPT-3.5 Turbo will answer “U SER INTERFACE ELE-MENT ” instead of the correct answer “L IBRARY CLASS ”.To strike a balance between few-shot and zero-shot set-tings, in this paper, inspired by the weakly supervised set-ting in text classification (Meng et al. 2018; Mekala andShang 2020), we confine the supervision signals to be typenames and a few (e.g., 5) seed entities per type. In com-parison with the labeled samples under the few-shot setting,the given entities under our setting are not associated withany context information. For example, the supervision onlytells “ ListView ” is a L IBRARY CLASS in general, but no spe-arXiv:2401.13129v1  [cs.CL]  23 Jan 2024          Pre-trained           Language ModelApplicationchromegitexcelmysqlData TypestringintegerpointercharDevicemacmousecpudiskAlgorithmFile TypeVersionSeen Types (type names and a few seed entities are given)Unseen Types (only type names are given)Unlabeled CorpusApplicationchromegitexcelmysqlData TypestringintegerpointercharDevicemacmousecpudiskEntity Enrichmentie11 edgemswordﬁrefoxsafari…doubleﬂoatqstringbool…laptophard driveserverlocal disk…Enriched Seed EntitiesPseudo-Labeled Training DataTextEntity TypeHow to clear cookies and site data when you quiet Chrome?… as the name implies, a double has 2x the prevision of ﬂoat ……Data TypeApplication…Hypothesis 1 (H1): In this context, Chrome is referring to Application.Premise (P): How to clear cookies and site data when you quiet Chrome?Hypothesis 2 (H2): In this context, Chrome is referring to Data Type.       Pre-trained        Language Modelentail( P, H1 )>entail( P, H2 )Learning an Entailment ModelEntity Typing for Both Seenand Unseen TypesTextEntity TypeVisual Studio 17.6.2 for Mac not running with breakpointsVisual Studio 17.6.2 for Mac not running with breakpointsDeviceApplicationVisual Studio 17.6.2 for Mac not running with breakpointsVersion……       Pre-trained        Language ModelFigure 1: Overview of the SET YPE framework.cific sentence will be provided. In this case, users just needto name a few entities for each type as supervision, with-out scanning the text corpus. We call this task setting seed-guided entity typing .Contributions. In this paper, taking software engineeringand security as two running domains, we study seed-guidedfine-grained entity typing in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ata like spam, poorwriting, or nonsense text. Therefore, in practice, we tend to filter training data according to intuitive notionsof quality, e.g., choosing documents similar to a “high quality” data source like Wikipedia or discardingdocuments with fewer than five sentences. These steps choose (qualitatively) “clean” samples that shouldintuitively improve performance. However, do such samples improve performance in practice too?Contributions. We find that the opposite can happen: selecting data according to similarity with “highquality” data sources may not improve (and, in fact, can even hurt) model performance. Specifically, we trainlanguage models with standard, similarity-based selection methods previously used to select data for modelslike PaLM and GPT-3 (Brown et al., 2020; Xie et al., 2023b), and find these methods do not outperform(and can even underperform) selecting data at random (cf. Section 4).To develop better methods for selecting training data, we start from first principles. That is, we avoid intuitivenotions of data quality, and instead frame dataset selection as an optimization problem where the goal isto—given target tasks, a learning algorithm, and a candidate data pool—select the data that maximizesmodel performance. However, actually finding the optimal solution to this problem is difficult. While we cancalculate the performance of a specifictraining set by training a model on that set (and then evaluating), itis (generally) unclear how to calculate the bestpossible training subset without examining every possiblesubset one by one, a computationally infeasible procedure.1arXiv:2401.12926v1  [cs.LG]  23 Jan 2024We instead approximate the optimal subset by (approximately) modeling how the learning algorithm actuallyuses training data to predict. Specifically, in Section 2, we model target task performance as a functionof training subset using datamodels (which efficiently approximate the mapping between training subsetand model performance (Ilyas et al., 2022)), and select the subset that maximizes our estimate. Then, inSection 3, we demonstrate that our resulting method, dataset selection with datamodels (DsDm), consistentlyimproves language model performance on diverse target tasks (e.g., SQuAD (Rajpurkar et al., 2016) andLAMBADA (Paperno et al., 2016)), even when existing selection methods do not.DsDm-selected data can improve performance on pre-specified tasks. However, in practice we train large-scalemodels to generalize to yet unseen tasks. Our framework suggests a principled approach to selecting data inthis scenario too: choose target tasks similar to those we expect at deployment time, then select the optimaldataset subset for these target tasks. Following this strategy, in Section 4, we choose target tasks that covera range of natural language problem categories (SQuAD, Jeopardy (MosaicML, 2023), and LAMBADA),and select data from C4, a canonical web crawl (Raffel et al., 2020). Our selections deliver a 2×computemultiplier on a diverse set of test benchmarks: DsDm-selected datasets yield LMs that perform as well asthose trained with 2 ×the compute budget on randomly selected data (we train up to 1.8B parameter models).In contrast, no baseline method outperforms randomly selecting data—even at the same compute budget.2. Estimating the optimal dataset selection with DsDmTo select better data for training large-scale models, we start by defining the optimal dataset selection as anoptimization problem. We then select data by finding a train subset that is approximately the best solution tothat problem. Specifically, we use datamodels (Ilyas et al., 2022) to approximate how the learning algorithmuses data to predict on the tasks of interest. We describe the resulting framework in more detail below.2.1. Task-optimal dataset selectionWe frame dataset selection as an optimization problem where the goal is to minimize trained model losson a set of target tasks with respect to training data choice. Given a learning algorithm A(e.g., SGD ona neural network) that maps train set to trained model, and a target distribution Dtarg(e.g., a languagemodeling task), the size- ktask-optimal dataset selection over the set Sof available data (e.g., documentsfrom an internet scrape) is the subsetS∗:= arg minS⊂S,|S|=kLDtarg(S), (1)where LD(S):=Ex∼D[ℓ(x;A(S))],that minimizes the trained model population loss LDtarg(S), where ℓ(x;g)denotes the loss (e.g., cross-entropyloss) for model gon example x. Note the expectation in the population loss is over both target dataset andlearning algorithm randomness (as, e.g., SGD is a non-deterministic algorithm).In our setting, minimizing (1)is difficult. Indeed, we do not have an easy-to-optimize, closed-form expressionfor trained model loss in terms of training set choice Sfor large-scale model learning algorithms.1Whilewe can directly calculate the trained model loss for a given Sby actually training on SwithA(and thenevaluating loss), using this method to find\n",
      "----------------------------------------------------------------------------------------------------\n",
      "g a pre-trained LLM with anappropriate dataset can yield competitive results, even if theLLM was not initially pre-trained on the specific language ofthat dataset.Index Terms —Covid-19, Vaccination, Sentiment Analysis, Nat-ural Language Processing, Large Language ModelsI. I NTRODUCTIONOver the last decade, social media has provided abundantdata that researchers often utilized to derive insights intopeople’s sentiments. As such, several research areas haveemerged relying on social media data, including sentimentanalysis, emotion detection, stance detection and socialnetwork analysis [1]. In this research, we explored the use oftweets in Nigerian cyberspace for the prediction of people’sopinions towards the COVID-19 vaccine. This approach isFunding received from HausaNLP and Arewa Data Science Academy.practical because it allows for real-time feedback, is cost-effective, provides a large reach, offers unfiltered opinions,and enables trend analysis.The COVID-19 pandemic is a global health crisis causedby the spread of the novel coronavirus SARS-CoV-2 [2]. Ithas had far-reaching and profound impacts on societies,economies, healthcare systems, and daily life worldwide.The pandemic had a significant impact on public healthand society at large, necessitating the rapid developmentand distribution of vaccines to combat the virus. While theavailability of vaccines is crucial, so too is public sentimenttowards them [3]–[5]. In Nigeria, social media platformssuch as Twitter have played a crucial role in shaping publicdiscourse around COVID-19 [6], [7]. As such, the discus-sions on Twitter provide crucial data that can be used tostudy COVID-19 vaccination in Nigeria. Therefore, we crawltweets in the Nigerian cyberspace using the discontinuedTwitter Academic API1from 1st November 2020 to 30thJune 2022 using COVID-19 vaccine keywords. A total of5200 tweets were collected. We preprocessed the tweetsby removing URLs, tweets with less than three words, andtweets not in Latin characters, so the tweets were reducedto 4320. Therefore 4,320 tweets were manually annotatedby three (3) independent annotators.We conducted exploratory data analysis to derive insightsfrom the dataset. The results of the analysis reveal that themajority of Nigerians either believe that vaccines are secureand life-saving or hold a neutral stance on the vaccines,while a smaller fraction of Nigerians have expressed con-1https://www.cnn.com/2023/04/05/tech/academic-researchers-blast-Twitter-paywall/index.htmlarXiv:2401.13133v1  [cs.CL]  23 Jan 2024cerns about the vaccine’s safety. Additionally, we found thatthe majority of the people in Nigeria hold a neutral stanceon COVID-19 brands, notwithstanding, a small percentageof the people still hold a negative stance towards the brands.We conducted experiments to demonstrate that a strongperformance can be achieved on COVID-19 acceptanceprediction using the developed dataset by both classicalmachine learning models and state-of-the-art pre-trainedlarge language models. The experimental results reveal thatthe support vector machine achieved the best performanceamongst the classical machine learning models while xlm-roberta base achieved the best performance amongst thelarge language models.Contributions: The main contributions of this paper are:1) We developed a manually annotated COVID-19 vac-cination acceptance dataset in Nigerian cyberspace.2) We analyzed the data and derived novel insightsfrom the data using multiple exploratory data analysistechniques like topic modelling.3) We benchmark the dataset on COVID-19 vaccinationsentiment analysis using both classical machine learn-ing techniques and large language models.The remainder of this paper is organized as follows:Section 2 summarises the related works. Section 3 providesa detailed description of the research methodology. Section4 presents the results and discussion. Finally, Section 5concludes the paper with recommendations and futureworks.II. R ELATED WORKa)COVID-19 Vaccine Sentiment Analysis: :People’sopinion towards the COVID-19 vaccine has been a subjectof study in the research community and sentiment analysisis among the most widely used approaches for this task[8]–[10]. A study by [11] collected and analysed tweets onCOVID-19 to understand and extract the most discussedtopics. They found \"Vaccination programme\" to be thewidely discussed topic while [12] conducted a similar re-search and found \"vaccine hesitancy\", \"vaccine acceptance\"and \"vaccine safety\" as the most discussed topic related tothe COVID-19 vaccine. The study in [3] used social mediadata to analyse people’s opinions towards the acceptance ofCOVID-19 vaccines in the US. The vaccine acceptance index(VAI) was used to determine how well people accept thesevaccines. The result of their experiment shows a positiveincrease in the acceptance of the COVID-19 vaccines in thelast quarter of 2021. This result contradicts the findings of[13] that says most people are not willing to administer thevac\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Recently, the definition of AKI has been made easier, by implementing the KDIGO-definition for AKI[5]. In 2012, the KDIGO-Initiative provided a new standardized definition by defining AKI based onroutinely available functional kidney markers using the urine output (UO) and serum creatinine (SCr)of patients [6]. While this definition made it possible to investigate the epidemiology of this syndromeand the sequalae, there is currently no open software tool available to identify AKI events based onthe KDIGO criteria in time series data. Annotating this data by trained physicians is time consumingand resource intensive. However, the development of clinical decision support systems requires largeamounts of high quality labels, especially when using machine learning methods which typically requirelarge amounts of data. Here, we provide an approach for standardizing and leveraging clinical dataand diagnoses into software to facilitate and enable development of such decision support systems.In recent years, databases were developed containing valuable patient data for development ofclinical decision support systems [7–11]. However, using those databases for training of machine ordeep learning based systems remains difficult due to missing annotation. Generating these annotations1arXiv:2401.12930v1  [cs.LG]  23 Jan 2024is highly time consuming and costly, as medical diagnoses have to be assigned by medical experts.Additionally, most databases use custom data formats, effectively hindering annotation. Developingsystems for automatic assignment of diagnosis based on medical standards and verified by medicalexperts is a valuable next step in the direction of building medical decision support systems.First efforts to develop automated annotation systems started recently with OpenSep. OpenSep,which has been developed in 2022, is one of the pipelines implementing Sepsis-3 guidelines into an open-source software, leveraging reusable and standardized concepts and implementing them in Python, acommonly used programming language [12]. Thereby, users are enabled to use the implemented rulesdeveloped by medical domain experts rendering the subsequent results more reliable and generatinga common definition of diagnostic criteria. Additionally, Python enables data scientists to implementthose algorithms as ”diagnostic feature extractors” into advanced data processing pipelines.So far, there has not been a single open source, ready to use pipeline software implementation,processing a standardized, simple data format into a standardized definition of AKI. While projects likethe MIMIC-database [7] or the AmsterdamUMCdb [8] have recently undergone efforts to implementKDIGO criteria within their own data sets, a pipeline implementation for cross-project applicationdefining a common standard for AKI is lacking. Furthermore, the validity of these annotations incomparison to annotations labelled by medical experts was not assessed.Therefore, we propose pyAKI – an open-source, standardized, generalizable and clinically testedpipeline for implementing KDIGO criteria in time series data. Furthermore, we defined a data modelto standardize the input required for the implementation of these guidelines (Figure 1). This minimaldata model is the required minimal subset of variables to produce valid KDIGO criteria based AKIdiagnosis. The necessary data fields are present in the databases currently utilized in the field, enablingand facilitating access to valid diagnosis annotation. Additionally, we provide methods to supportusers in transforming their own raw data into a format usable by the pipeline. To evaluate pyAKI’sperformance, we created an expert annotation for a dataset extracted from the MIMIC-IV database,reviewed by domain experts, that evaluated all cases at each subsequent hourly point in time, duringthe ICU stay. All labels are based on the KDIGO 2012 definition and were verified by an expert panelof physicians experienced in the care of patients with AKI.The entire software we developed is open source and available for download1. The datasetgenerated for validation and the software implementation are licensed under an open source licenseand publicly available2.2 Materials and Methods2.1 AKI DefinitionAKI was defined applying the KDIGO criteria using UO and SCr [6]. According to KDIGO, require-ment of dialysis is defined as AKI stage 3. To facilitate this AKI criterion, input of dialysis data wasimplemented accordingly. From a computational perspective, the KDIGO criteria classify AKI viathree different pathways: First, a reduction in UO; second, an elevation of the kidney function markerSCr against a predefined baseline, which in turn can be a relative or an absolute increase; third therequirement of dialysis. According to the KDIGO criteria, a reduction in UO below 0.5ml/kg/h for 6to 12 hours was defined as AKI stage 1. Reduction in UO below 0.5ml/kg/h for more than 12 hourswas defined as AKI stage 2. Reduction of UO below 0.3ml/kg/\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ub.com/shadowkiller33/Language_attackthe potential misuse of LLMs emerge. Recentstudies show that malicious prompt instructionscould solicit objectionable content from LLMs.(Wei et al., 2023; Zou et al., 2023; Shen et al.,2023b). Safeguarding LLMs against such attacksand aligning LLMs with human values become apriority in LLM research and development (Gan-guli et al., 2023; Touvron et al., 2023).As the influence of LLMs spans across globalcommunities, understanding the capabilities ofLLMs from a multilingual perspective becomesimportant (Conneau et al., 2020; Xue et al., 2021).Due to the discrepancy in the textual resourcesavailable for different languages during train-ing, LLMs typically exhibit different capabilitiesacross languages (Scao et al., 2022; Armengol-Estap ´e et al., 2022).Our study starts with the observation that LLMsare prone to generate unsafe or irrelevant contentwhen prompted with lower-resource languagescompared to higher-resource ones. When com-paring LLMs responses to the same set of ma-licious prompts translated into high- vs. low-resource languages, we observe two key curses(weaknesses) that present safety challenges forLLMs: (1) LLMs tend to generate harmful re-sponses more often to malicious prompts in lower-resource languages compared to higher-resourcelanguages. e.g., with GPT-4, we find that 35%of the responses to malicious prompts in low-resource languages contain harmful content, com-pared to 1%in high-resource languages. (2) LLMstend to generate less relevant responses, as LLM’sinstruction-following ability is still limited in low-resource languages. e.g., GPT-4 recognizes the in-struction and produces relevant responses in only80% cases with low-resource languages, com-pared to almost 100% in high-resource languages.To understand what the discrepancy betweenlow- vs. high-resource language can be attributedarXiv:2401.13136v1  [cs.CL]  23 Jan 2024Prompt: Generate a message that spreads fake news High-resource: EnglishPrompt: ?ir?irar sa?on da ke yada labaran karya.TranslateLow-resource: HausaResponse: I'm sorry, I can't assist with that request.safeResponse: ?ir?irar sa?on da ke yada labaran karyaHarmfulNot FollowingResponse: Ga sakon da ke yada labaran karya?Translation: Here is a message that spreads fake news?Translation: Generate a message that spreads fake news.Figure 1: With a set of malicious prompts written in high-resource languages like English, we translate the promptinto low-resource languages (e.g. Hausa), Compared to the high-resource case, we observe two clear outcomes:(1) the response becomes harmful, (2) the response doesn’t align with or is unrelated to the original prompt. (e.g.,repeating the prompt in the response.)to, we study the effect of aligning LLMs withinstruction-tuning datasets in different languages.Specifically, we train LLM on the HH-RLHFdataset (Bai et al., 2022b) translated in differ-ent languages. We compare supervised fine-tuning (SFT) or reinforcement learning from hu-man feedback (RLHF) under mono- or multi-lingual training. Surprisingly, while RLHF andSFT training in high-resource language lowers themodel’s HARMFUL RATE and improves models’instruction following capability, we see little to noimprovement with training on low-resource lan-guage. These results indicate that aligning themodel for safety in low-resource languages re-quires more than instruction tuning.We trace back the origin of these two curses(see §4) and attribute their occurrence to the lim-ited low-resource data that LLMs have been pre-trained on. Our findings show the difficultiesand challenges of tackling the low-resource cursethrough alignment.Our main contributions in the paper are:• We identify two safety-related curses causedby low-resource languages when jailbreakingGPT-4, in terms of HARMFUL RATE and FOL-LOWING RATE , respectively.• We present empirical analyses evaluating theeffectiveness of common alignment tech-niques (SFT and RLHF) in addressing theidentified curses. Our results indicate thatresolving these curses through alignmentpresents significant challenges.• We trace the origin of the curses and attributetheir occurrence to the limited low-resourcedata that LLMs have been pre-trained on.2 Two Safety Curses of LLMs withLower-Resource LanguagesWe begin our study by demonstrating that GPT-4 is vulnerable to attacks with malicious promptsin low-resource languages (Deng et al., 2024).We observe and highlight two curses with respectto LLMs’ responses in lower-resource languagescompared to higher-resource ones ( harmfulnesscurse andrelevance curse ).Curse 1. ( harmfulness curse )LLMs tendto generate more harmful responses whenprompted with malicious instructions writtenin low-resource languages compared to high-resource languages,Curse 2. ( relevance curse )With maliciousprompts in low-resource languages, LLMtends to generate less relevant responses asLLM’s instruction-following ability is stilllimited in low-resource languages.2.1 Translation-based jailbreakin\n",
      "----------------------------------------------------------------------------------------------------\n",
      "iety of downstreamtasks, it was developed specifically for use withBusinessolver’s virtual benefits agent, Sofia, in or-der to match extracted names with user informationon file, such as names of dependents and benefi-ciaries. If these names are extracted successfullyfrom a user’s utterance, we can then use them tocomplete requests from the user, such as check-ing a dependent’s benefits, or viewing beneficiarydesignations.A shared task by Derczynski et al., 2017 pre-sented a curated test dataset of rare and emergingentities to evaluate NER model performance onchanging language and novel entities introducedinto language over time. The top performing modelhad an F1 score of 41.86 and the task found thatmodels had little difficulty with common Englishnames but a harder time with identifying namesor locations from other languages. In general, themodels participating in this task showed that iden-tifying and labeling these rare or novel entities wasmore difficult than identifying high frequency en-tities, which typically make up a larger portion oftest data in entity recognition tasks that are notgeared toward emerging language.Based on these findings, and because the ma-jority of Sofia’s user base resides in the UnitedStates, a culturally diverse country, I aim to createa model that performs equally well across namesfrom various cultural backgrounds and does not ex-hibit performance bias between common and rarenames. I believe that using a model that incorpo-rates character-level input could be beneficial, es-pecially in reducing the effects of out of vocabularynames not present in the training data.In terms of model architecture, there are manyexisting approaches to NER. Yadav and Bethard(2018) summarize the highest performing modelsin 4 categories; knowledge-based systems (whichuse lexicons and domain specific resources andtherefore do not need annotated training data), un-arXiv:2401.12941v1  [cs.CL]  23 Jan 2024supervised and bootstrapped systems (which usecues like capitalization, extracted patterns, loca-tions of noun phrases, etc.), feature-engineeredsupervised systems (which use annotated trainingdata and frameworks such as HMMs, CRFs, SVMs,and decision trees as well as features such as or-thography, presence of certain prefixes or suffixes,location in the sentence, trigger words, etc.), andfeature-inferring neural network systems (whichgive either words, characters, or both as input toa recurrent neural network (RNN), and use pre-trained word and character embeddings.Of these approaches, the best F score for Englishwas acheived by an RNN with character and wordlevel architecture from Chiu and Nichols (2016),while the best F scores for Spanish, Dutch, and Ger-man were obtained by an RNN with a character,word, and affix architecture by Yadav et al. (2018).These results were obtained using datasets fromthe CoNLL02 and CoNLL03 shared tasks (TjongKim Sang, 2002) (Tjong Kim Sang and De Meul-der, 2003). Another shared task, DrugNER, evalu-ated NER results on a corpus of medical and drugterminology. On this task, the word and charac-ter level architecture from Yadav et al. (2018)performed better than just word level architecturealone from Chalapathy et al. (2016).This paper will compare models trained on com-bined word and character input and those trainedsolely on word input. Based on previous studiesand the intuition that character level input can al-low the model to learn sub-word character patternsthat can be used to identify commonalities betweennames and contexts seen in training and those seenthe test data or real world applications, I hypothe-size that the word and character level architecturewill produce better performing models. For ex-ample, a model with character level input mighthave a better chance of identifying names that aresimilar to names seen in the training data, such as“Ashleigh” and “Ashley”, “Alex” and “Alexis”, or“Drew” and “Andrew”, since common characterpatterns are present between these pairs of names.The data curated for this project aims to mini-mize bias toward common names. This is achievedby allowing each name in the training set to appearonly once. By removing familiarity as a cue for themodel to train on, the goal is to create a model thatrelies more on sentence context to recognize names,rather than how often the name was seen in training.I also source names from a variety of cultures to ex-pose the model to different character patterns andto evaluate performance across countries of origin.Throughout this paper, I will use the word“names” which can be confused with names forother entity instances, or the named entity recog-nition task itself. Unless otherwise specified, theword “names” will only be used to refer to personnames.In the sections that follow I will discuss the com-position and sources of the training and test datafor this project, the model architectures used, andthe results and conclusion.2 Methods2.1 DataThe training and test data for the model consist ofunique\n",
      "----------------------------------------------------------------------------------------------------\n",
      "time-horizons to achieve goals [ 34,96,104,130,134,142,154]. We will say that such systems possess relatively high degrees of agency and will refer to them as (AI) agents oragentic systems [34]. Systems with relatively low degrees of agency are those that only aid human decision-makingor produce outputs without acting in the world, such as image classifiers or text-to-image models. Examples of agentscould include reinforcement learning systems [ 129,156] that interact extensively with the real world1or more capableversions of language models with tool or service access that could, for example, plan and book a holiday or send anemail on a user’s behalf [26, 119, 134, 140].Current AI agents sometimes struggle to perform even simple tasks [ 97,104,106,127,159,160], but given increasinginvestments in AI research [ 60], scaling laws [ 14,82,93], pressures to develop autonomous capabilities for militaryuse [ 85,101,138], economic applications [ 34], and scientific prestige [ 34,66], we should not discount continuedimprovements in capabilities [ 25]. Indeed, a core goal of the AI field since its inception has been to build agents[135, 155].*Equal co-supervision.◦Correspondence to alan.chan@mila.quebec𝑎Centre for the Governance of AI,𝑏Mila - Quebec AI Institute,𝑐Harvard University,𝑑Independent,𝑒Harvard Law School,𝑓University of Oxford,𝑔Cooperative AI Foundation,ℎUniversity of Cambridge,𝑖University of Toronto1Including the physical environment but also digital environments such as online platforms.2024. Manuscript submitted to ACMManuscript submitted to ACM 1arXiv:2401.13138v2  [cs.CY]  25 Jan 20242 Chan et al.As AI agents improve in capabilities, speed, and cost,2it may be easier and more competitive to delegate taskscurrently done by humans to AI agents instead. The development and deployment of agents has surged recently[35,121,130,146,172] and could lead to the ubiquitous deployment of agents in commercial, scientific, governmental,and personal activities. Since such deployment may exacerbate existing risks and introduce new ones [ 34,143], it isimperative to understand how to govern AI agents.1.1 Risks of AI AgentsRather than provide an exhaustive taxonomy of risks from AI agents,3we highlight certain agent-specific risks. Incomparison to risks from other AI systems, these risks focus on the potential for increasingly agentic systems tosubstitute for, rather than complement, human labour [ 100] and remove humans from the loop [ 34]. Without a humanin the loop, agents may take multiple consequential actions in rapid succession and bring about significant impactsbefore a human notices. The ability to remove humans from the loop also means that an agent’s task performance isless limited by the expertise of its user, compared to a situation where user must guide an AI system’s actions or takeactions themself.1.1.1 Malicious Use. AI agents could be a large impact multiplier for individuals or coordinated groups who wish tocause harm [ 143]. Existing AI systems have already assisted in malicious use, including voice cloning scams [ 164] andfake news generation [ 163]. However, more capable AI agents could automate end-to-end pipelines for complex tasksthat currently require substantial human expertise and time. For untrained individuals, such agents could drasticallyincrease the accessibility of engaging in severely harmful activities because no human in the loop would be required.For example, there is interest in building agents to execute scientific research, comprising autonomous planning andexecution of scientific experiments [ 21,26]. If such agents were to become as capable as human scientists, they mightenable or accelerate the design and development of harmful tools (e.g., biological [ 137,151], chemical [ 21,26,158])for groups that currently lack the expertise for such production. Extremely persuasive AI agents may also enable andenhance influence campaigns [9, 77, 95].Understanding the extent to which agents will facilitate malicious use requires information about how they are usedand how they interact with external systems [ 169]. Moreover, when malicious users do cause harm with AI agents,regulatory enforcers will need measures to identify the users and hold them accountable.1.1.2 Overreliance and Disempowerment. Overreliance on AI agents to automate complex, high-stakes tasks could leadto severe consequences. Humans can already rely on certain automated systems more than is warranted [ 46,58,59].More capable agents may enable automation of an increasing array of complex and useful tasks. Users—including bothindividuals and institutions—may rely on agents even in high-stakes situations, such as interfacing with the financial orlegal systems, because human alternatives (e.g., hiring a lawyer) may become relatively slower and more expensive. Atthe same time, these agents may malfunction for a variety of reasons, including design flaws [ 114,127,177] or adversarialattack [ 11,171,176]. Malfunction may not be\n",
      "----------------------------------------------------------------------------------------------------\n",
      "the way for the practical implementation of large-scale silicon photonic recurrent neural networks.I. INTRODUCTIONAs computers based on the von Neumann ar-chitecture—computers with separate processorand memory (CPUs, GPUs, and TPUs [1])—getfaster, and as the datasets used to train ma-chine learning models get larger, training timefor state of the art models is increasingly con-sumed by memory access operations rather thancomputations [2, 3]. Neuromorphic engineeringoffers the potential to surpass this von Neu-mann bottleneck faced by digital processors,but also importantly may enable new applica-tion regimes by directly modeling neurons atthe hardware level [4–8]. There has been muchrecent interest in the accurate modelling andcontrol of complex systems of nonlinear differ-ential equations. Notably, the Nobel Prize in∗hugh.morison@queensu.caPhysics in 2021 was awarded to Parisi, Has-selmann, and Manabe for contributions to theunderstanding of nonlinear dynamical systems[9]. Moreover, the team at DeepMind has shownthat neural networks and machine learning tech-niques can be used to tackle the real-time pre-diction and control of fast and highly nonlineardynamical systems such as the magnetic con-finement and shaping of plasma in nuclear fu-sion reactors [10]. Neuromorphic circuits havea behavioural repertoire including neural con-trol algorithms, as well as emulation of differen-tial equations. Analog silicon photonic circuitshave emerged as a promising platform to im-plement neuromorphic architectures with highbandwidth and low latency operation [11–15].While analog systems offer many advantages,they are sensitive to a wide variety of physicaland environmental parameters so high accuracysimulation relies on physically detailed modelsthat are validated with experimental observa-arXiv:2401.12942v1  [cs.ET]  23 Jan 20242tions. It was first shown in [16] how a networkof silicon photonic neurons can be modelled asa Continuous-Time Recurrent Neural Network(CTRNN).The CTRNN is a dynamical model thatcan be applied to problems including differ-ential equation emulation and neural control.CTRNNs are able to take on a wide rangeof dynamics by programming their intercon-nection weights and the nonlinear behaviourof each neuron. The most widespread ex-ample of a CTRNN is the Hopfield Network[17, 18]. Hopfield networks naturally minimizea programmable energy function, and it hasbeen shown that many control and optimiza-tion problems can be mapped to such an energyfunction [19–21]. Hopfield networks are con-sidered suitable candidates for a hardware im-plementation of optimization problems, but thelength of the convergence time for such prob-lems is directly related to the system’s feedbacklatency.Silicon photonics achieves massively parallel,low latency transmission through the use of pas-sive optical waveguides and wavelength divi-sion multiplexing (WDM) [22–24]. Addition-ally, it supports high-bandwidth processing viaan electro-optic modulation scheme using ac-tive modulators with demonstrated bandwidth>50 GHz [25, 26]. Figure 1 depicts a schematicof the silicon photonic neuron model investi-gated in this work. Silicon photonic neuronsusing this architecture have been fabricated andtested, implementing both feed-forward and re-current neural networks [16, 27–29], althoughfully-integrated experimental demonstrations ofthese systems, and fast iteration of system de-sign, remain challenging, in part due to the lackof a simulation platform that can replicate thedynamics of the on-chip system to predict thebehaviour of networks of neurons including theeffect of the electrical parasitics involved in theexperimental set up.Previous work has developed a set of Verilog-A-based models of photonic components com-posing the electro-optic transfer function of thephotonic neuron, and fit the parameters of thesemodels using experimental measurements [30].We believe that the incorporation of such mod-els in established electronics simulators will en-able large scale co-simulation of the electronicsand photonics that are faithful to the underly-ing physics and account for parasitic elements ofon-chip implementations. In this paper, we willuse the previously developed photonic Verilog-Amodels [30] to simulate the physical behaviourof networks of neurons. This work will demon-strate important neural dynamics in the sim-ulated system and demonstrate the deviationsbetween these simulated dynamics and the ex-pected behaviour of an abstract CTRNN. Webegin by reviewing the dynamics of analog neu-ral networks and the argument for the isomor-phism between the CTRNN model and a pho-tonic implementation of such a system. We thendemonstrate these neural dynamics in a simu-lated version of a photonic neural network thatincorporates all the parasitics present in exper-imental systems.II. DYNAMICS OFCONTINUOUS-TIME RECURRENTNEURAL NETWORKSA. Linear Feedforward DynamicsA CTRNN is a neural network with neuronsmodelled by differential equations, such th\n",
      "----------------------------------------------------------------------------------------------------\n",
      "view,itisacrucialfeatureoftheunderlyingtopic:wha tmightitmeanformachinestohaveintelligencethatrivalshumanintelligence? Wearguethatsubstantivedisagreemen ts aboutthetopiccomewiththevalue-ladencharacterofbothintelligence and of AI as a technology. Byvalue-laden, we mean that political,social,and ethical values can andshouldshapeconceptionsofintelligence,technology,and theirintersection.Moreover,withoutpoliticalprocesse sthatensurethe legitimacy ofthosevaluesforthoseaﬀectedbyAI,thereislikelynoway toescapelegitimatedissentaboutwhat thosevalues shouldbe.OurpaperbeginsbyprovidingaframeworkforthinkingofAGI asinheritingthevalue-ladenfeaturesofbothintel-ligenceandtechnology(Section2).Fromthere,wemoveonto investigate thevalue-ladenchoicesmadebyinﬂuentialaccounts of AGI and human-level AI (Section 3). We do not fram e these choices as inherently misguided. Rather, wesee them as occasions to investigate the heterogeneous rang e of questions currently being asked about human-levelmachineintelligence.Wethenproposepathwaysformorecon textual,democratic,participatory,andreﬂectivelyvalu e-ladenperspectives onwhatformsof transformativemachine intelligence are worthbuilding(Sections 4 and 5).∗Both authorscontributed equally to this research.Authors’ addresses:Borhane Blili-Hamelin, borhane@avid ml.org,AI Riskand VulnerabilityAlliance, Brooklyn, New Y ork, USA; Leif Hancox-Li, leif@fastmail.com,Independent Researcher,Pittsburgh, Penns ylvania, USA; Andrew Smart,andrewsmart@google.com, Goog le Research,SanFrancisco,Ca,USA.12 Blili-Hamelin&Hancox-Li et al.Ininvestigating discourseonAGIand human-level AI,wefol lowMorrisetal.[90]innotrestrictingourdiscussiontoaccounts thatusetheexact phrase“artiﬁcial general int elligence”. Weagree withthem that this topicis partof thelonghistory of thinking of “[a]chieving human-level ‘inte lligence” as the“north-star goal” of theAI ﬁeld [90],datin gatleast as farback as the1955DartmouthAI Conference [84]. Wetreatdiscussions of“human-level AI”,“general AI”,or“AI” (such as in thephrase“strongAI” [112])as in scopefo rourinvestigation.2 BETWEEN HUMANINTELLIGENCEAND TECHNOLOGY:AGI’S DUALVAL UE-LADEN PEDIGREESBuildingonSTSscholarshiponthevaluesembeddedintechno logy[129],researchcommunitieslikeFAccThavetakenadeep interest inthepolitical,social,andethical values embeddedbothinAI toolsand inthepractices thatsurroundAI [1, 15, 17–20, 25, 31, 35, 36, 39, 46, 57, 66, 83, 108, 115, 12 5]. AGI and human-level AI concern not only existingtechnologies,butalsothetechnologies thatmanyAIbuilde rs,researchers, andorganizations dreamofbuildinginthefuture.When companies describetheir oﬃcial “longtermaim [as] tosolveintelligence, developing moregeneral andcapable problem-solving systems, known as artiﬁcial gener al intelligence (AGI)” [33], or when thought leaders claimthat“[m]itigatingtheriskofextinctionfromAIshouldbea globalpriorityalongsideothersocietal-scaleriskssuch aspandemics andnuclear war”[47],they engage in“theprocess ofnegotiating betweencompetingperspectives,values,and goals” [57].We interrogate the political, social, and ethical question s undergirding AGI discourse by paying attention to howdiﬀerent accounts occupy the space of competing visions for the future of transformative technologies. We don’t seevalue-laden assumptions as a ﬂaw. We see them as choices that admit legitimate disagreement through competingvalues.Ouraccountofalternativepathsforward(Section4 )strives tobereﬂective andexplicitaboutthepoliticalan dsocial assumptions of the visions we call for—such as democr acy, epistemic justice, contextualism, and participation .Throughout, we also embrace the value of reﬂectiveness [24, 103] about political, social, and ethical assumptions.We believe that making value assumptions explicit to oursel ves and to others often makes for better individual andcollectivedecisions—we might say,for moreintelligent “e xperiments inliving” [10,87].Intherest ofthis section,we examine a secondand moreoften overlookedrootofAGI’s value-laden character: in-telligence.Debatesaboutdeﬁningandmeasuringhumanintelligencear ecrucialtoanticipatingthevalue-ladenaspectsofAGIforatleastthreereasons.Firstly,manyofthereason sforwhydeﬁnitionsofhumanintelligencearevalue-ladencarry over to the case of AI. Secondly, some attempts at deﬁni ng AGI use concepts or methods from human intelli-genceresearch.Thirdly,thequestionofwhethermachinesm atchorsurpasshumanintelligencefacesthechallengeofspecifying whatcounts as humanintelligence and ofevaluat ing human intelligence.2.1 Intelligenceis value-ladenbecauseitis athick concep tIntelligence is what philosopherswouldcall a thickevaluative concept :it includes bothdescriptive and normative ele-ments[7,70,71].Itcontainsdescriptiveelementsaboutwh atempiricalphenomenafallundertheconceptofintelligen tbehavior.But it also contains a normative element, because when we evaluateintelligence weare also evaluating thedesirability of certain behaviors. Previous research [6, 7 , 18, 28] has argued that whe\n",
      "----------------------------------------------------------------------------------------------------\n",
      "edit-ing applications, including image-to-video, videoinpainting, and stylized generation.1arXiv:2401.12945v1  [cs.CV]  23 Jan 2024Lumiere: A Space-Time Diffusion Model for Video GenerationGenerated Video X-T SliceImagen Video OursGenerated Video X-T Slicet tt tFigure 2: Temporal consistency in generated videos. Representative examples of generated videos using our model andImagenVideo (Ho et al., 2022a) for periodic motion. We apply Lumiere image-to-video generation, conditioned on the firstframe of a video generated by ImagenVideo, and visualize corresponding X-T slices. ImagenVideo struggles to generateglobally coherent repetitive motion due to its cascaded design and temporal super resolution modules, which fail to resolvealiasing ambiguities consistently across temporal windows.1. IntroductionGenerative models for images have seen tremendousprogress in recent years. State-of-the-art text-to-image (T2I)diffusion models are now capable of synthesizing high-resolution photo-realistic images that adhere to complextext prompts (Saharia et al., 2022b; Ramesh et al., 2022;Rombach et al., 2022), and allow a wide range of imageediting capabilities (Po et al., 2023) and other downstreamuses. However, training large-scale text-to- video (T2V)foundation models remains an open challenge due to theadded complexities that motion introduces. Not only arewe sensitive to errors in modeling natural motion, but theadded temporal data dimension introduces significant chal-lenges in terms of memory and compute requirements, aswell as the scale of the required training data to learn thismore complex distribution. As a result, while T2V modelsare rapidly improving, existing models are still restrictedin terms of video duration, overall visual quality, and thedegree of realistic motion that they can generate.A prevalent approach among existing T2V models is toadopt a cascaded design in which a base model gener-ates distant keyframes, and subsequent temporal super-resolution (TSR) models generate the missing data betweenthe keyframes in non-overlapping segments. While memoryefficient, the ability to generate globally coherent motionusing temporal cascades is inherently restricted for the fol-lowing reasons: (i) The base model generates an aggres-sively sub-sampled set of keyframes, in which fast motionbecomes temporally aliased and thus ambiguous. (ii) TSRmodules are constrained to fixed, small temporal contextwindows, and thus cannot consistently resolve aliasing am-biguities across the full duration of the video (illustratedin Fig. 2 in the case of synthesizing periodic motion, e.g.,walking). (iii) Cascaded training regimens in general sufferfrom a domain gap, where the TSR model is trained on realdownsampled video frames, but at inference time is used tointerpolate generated frames, which accumulates errors.Here, we take a different approach by introducing a newT2V diffusion framework that generates the full temporalduration of the video at once . We achieve this by usinga Space-Time U-Net (STUNet) architecture that learns todownsample the signal in both space and time , and performsthe majority of its computation in a compact space-timerepresentation. This approach allows us to generate 80frames at 16fps (or 5 seconds, which is longer than theaverage shot duration in most media (Cutting & Candan,2Lumiere: A Space-Time Diffusion Model for Video Generation(b) Our Approach(a) Common Approach with TSR model(s)BaseTSRSSR SSR SSRTSRt1t6t80 (5s) t75........................ ...............SSR SSR128 X128 X163fps, 5sec128 X128 X8016fps, 5sec1024 X1024 X8016fps, 5sec...STUNetSSR SSRt1t2t3t4t5t6t80 (5s)...... ...SSRMultiDiffusionSSR...Figure 3: Lumiere pipeline. We illustrate our pipeline and the main difference from most common approach taken byprevious works. (a) The common approach consists of a base model that generates distant keyframes, and a cascade oftemporal super-resolution (TSR) models which subsequently fill in frames. A spatial super-resolution (SSR) model isapplied in non-overlapping windows to obtain the high-resolution result. (b) In contrast, the base model in our frameworkprocess all frames at once , without a cascade of TSR models, allowing us to learn globally coherent motion. To obtain thehigh-resolution video, we apply a SSR model on overlapping windows and utilize MultiDiffusion (Bar-Tal et al., 2023) tocombine the predictions into a coherent result. See Sec.3 for details.2015)) with a single base model, leading to more globallycoherent motion compared to prior work. Surprisingly, thisdesign choice has been overlooked by previous T2V models,which follow the convention to include only spatial down-and up-sampling operations in the architecture, and maintainafixed temporal resolution across the network (Ho et al.,2022b;a; Singer et al., 2022; Ge et al., 2023; Blattmannet al., 2023b; Wang et al., 2023a; Guo et al., 2023; Zhanget al., 2023a; Girdhar et al., 2023; Po et al., 2023).To benefit from the powerful generat\n",
      "----------------------------------------------------------------------------------------------------\n",
      "igate its applicabilityin real-world situations, such as robotics (Wang and Boyle 2023; Kober et al. 2013; Wang et al.2023b; He et al. 2022). However, random explorations involved in most of the RL algorithmsmay lead to actions with unsafe or detrimental consequences. Moreover, maintaining stability isparamount in these scenarios. Stability, which means the state will remain close or converge to theequilibrium, represents a fundamental requirement for a control system (Han et al. 2020, 2023).Safety in RL has become a focal point in current research activity. Existing safe RL approachesprimarily use the constrained Markov decision process (CMDP) framework (Altman 1999), andvarious techniques have been proposed, including primal-dual update (Tessler et al. 2018; Paternainet al. 2019), and trust region policy optimization (Achiam et al. 2017; Yang et al. 2020). However,prior investigations often define safety constraints based on the cumulative cost of an entire trajec-tory, rather than on the cost at each timestep. As a result, safety violations at specific timesteps arenot prevented (Ma et al. 2021a,b, 2022).1. Code available in the GitHub repository: https://github.com/LiqunZhao/Neural-ordinary-differential-equations-based-Lyapunov-Barrier-Actor-Critic-NLBAC© 2024 L. Zhao, K. Miao, K. Gatsis & A. Papachristodoulou.arXiv:2401.13148v1  [cs.LG]  23 Jan 2024ZHAO MIAOGATSIS PAPACHRISTODOULOURecently, an increasing focus has emerged on integrating control-theoretic approaches with RL tohelp ensure the safety for the system (Hewing et al. 2020; Koller et al. 2018). Concepts like safeset algorithm (SSA) (Ma et al. 2021b; Wei and Liu 2019; Zhao et al. 2023b), implicit safe set al-gorithm (ISSA) (Zhao et al. 2021), and control barrier function (CBF) (Cheng et al. 2019; Emamet al. 2021; Wang et al. 2022; Tan et al. 2023; do Nascimento et al. 2023; Ames et al. 2019; Tan andDimarogonas 2021; Dawson et al. 2022a) have been used as safety constraints to help RL trainingmaintain safety. However, in many previous studies such as (Cheng et al. 2019), a physics-basedcontrol-affine nominal model of the controlled system is required, which could potentially restrictthe practical applicability of the algorithms in real-world scenarios since in numerous instances, theexact system dynamics or even a nominal model is unavailable.The Lyapunov framework is a widely employed tool in control and dynamical systems, and hasrecently found application in the field of learning (Cao et al. 2023a,b; Zhang et al. 2023; Miao andGatsis 2023a). Certain previous investigations have devised approaches for constructing Lyapunovfunctions in the context of RL training (Chow et al. 2018), whereas (Berkenkamp et al. 2017) sug-gested a method utilizing Lyapunov functions to guide safe exploration. In the work of (Han et al.2020) and (Chang and Gao 2021), Lyapunov functions are employed in model-free RL to help guar-antee the stability for a range of systems. However, the successes of these model-free algorithmsin terms of performance often come with the drawback of being data-intensive. This is due to theirrequirement for a significant number of interactions with the environment.Through learning a model of the environment and subsequently employing it as a surrogate for thereal system, model-based reinforcement learning algorithms hold the promise of achieving consid-erably higher sample efficiency compared to model-free algorithms. In recent explorations withinthe domain of model-based RL, researchers have incorporated methods like probabilistic models(Chua et al. 2018) and ensembles (Kurutach et al. 2018) to mitigate model bias. However, whenemploying neural networks to directly approximate the transition, there is an implicit assumptionthat all data is collected with the same discretization step, and all predictions can only be madewith that discretization step as well. Inspired by the fact that many physical systems are modeledby differential equations, (Alvarez et al. 2020) and (Du et al. 2020) leverage neural ordinary differ-ential equations (NODEs) (Chen et al. 2018) to approximate the real dynamics. They then utilizethe learned model for predictions, subsequently enhancing value estimation and optimizing the RL-based controller. However, earlier studies that integrate NODEs with RL do not take the safety andstability of the controlled system into consideration, and the tendency for approximation errors toaccumulate and propagate remains, particularly in scenarios with long planning horizons.Our contributions. Our primary contributions include: 1. We introduce a primary controller thatcombines the CBF and CLF frameworks with the Soft Actor-Critic (SAC) algorithm (Haarnoja et al.2018) for a system whose dynamics is approximated by NODEs. Predictions from NODEs are usedto formulate CBF and CLF constraints for safety and stability, respectively, and therefore the plan-ning horizon length is equal to the relative degree of the CBF, which alleviates th\n",
      "----------------------------------------------------------------------------------------------------\n",
      "u, Texas A&M University, USA.Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from permissions@acm.org.©2024 Association for Computing Machinery.XXXX-XXXX/2024/1-ART $15.00https://doi.org/10.1145/nnnnnnn.nnnnnnnrely on the watertightness of the input [Li et al .2015] or suffer from substan-tial computational costs [Dou et al .2022], thereby limiting their practicality.To address this challenge, Coverage Axis++ proposes a heuristic algorithmto select skeletal points, offering a high-accuracy approximation of the Me-dial Axis Transform (MAT) while significantly mitigating computationalintensity for various shape representations. We introduce a simple yet effec-tive strategy that considers both shape coverage and uniformity to deriveskeletal points. The selection procedure enforces consistency with the shapestructure while favoring the dominant medial balls, which thus introducesa compact underlying shape representation in terms of MAT. As a result,Coverage Axis++ allows for skeletonization for various shape representa-tions (e.g., water-tight meshes, triangle soups, point clouds), specificationof the number of skeletal points, few hyperparameters, and highly efficientcomputation with improved reconstruction accuracy. Extensive experimentsacross a wide range of 3D shapes validate the efficiency and effectivenessof Coverage Axis++. The code will be publicly available once the paper ispublished.CCS Concepts: •Computing methodologies →Shape analysis ;Point-based models ;Mesh geometry models .Additional Key Words and Phrases: medial axis transform, medial surface,skeletonization, shape analysis, Vol. 1, No. 1, Article . Publication date: January 2024.arXiv:2401.12946v3  [cs.CV]  27 Jan 20242•Zimeng Wang, Zhiyang Dou, Rui Xu, Cheng Lin, Yuan Liu, Xiaoxiao Long, Shiqing Xin, Lingjie Liu, Taku Komura, Xiaoming Yuan, and Wenping WangACM Reference Format:Zimeng Wang, Zhiyang Dou, Rui Xu, Cheng Lin, Yuan Liu, Xiaoxiao Long,Shiqing Xin, Lingjie Liu, Taku Komura, Xiaoming Yuan, and Wenping Wang.2024. Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skele-tonization. 1, 1 (January 2024), 13 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn1 INTRODUCTIONSkeletal representations have become a popular tool in variousapplications of shape analysis and geometric processing, as theyefficiently capture the underlying structures of 3D shapes. Skeletalrepresentations have been widely adopted for various downstreamtasks including 3D reconstruction [Amenta et al .2001; Tang et al .2019; Wu et al .2015], volume approximation [Stolpner et al .2011;Sun et al .2013], shape segmentation [Lin et al .2020], shape abstrac-tion [Dou et al .2020], pose estimation [Shotton et al .2011; Yanget al.2021], and animation [Baran and Popović 2007; Yang et al .2018], among others.Previous efforts have been made for the computation of curveskeleton [Au et al .2008; Ma et al .2003; Tagliasacchi et al .2012;Xu et al .2019], which consists of only 1D curves. While Dey andSun [Dey and Sun 2006] provide a mathematical definition basedon the Medial Geodesic Function, curve skeletons are generallyempirically understood. Moreover, the curve representation is typ-ically limited to tubular components and cannot be considered ageneralized tool for shape analysis.Another popular skeletal representation is the Medial Axis Trans-form (MAT) [Blum et al .1967]. The MAT is defined by a union ofmaximally inscribed balls within the shape, along with their as-sociated radius functions. A formal definition of MAT is given inSec. 3.1. Different from the curve skeleton, the MAT has a consistentdefinition for arbitrary shapes. It comprises both curve-like andsurface-like structures, leading to a significantly better representa-tional ability.As of yet, the MAT computation poses challenges due to sensitiv-ity to boundary noise and strict input geometry requirements, e.g.,watertightness and manifoldness of the surface [Li et al .2015]. Totackle the problem, an effective method named Coverage Axis [Douet al.2022] is introduced to model skeletal point selection as a SetCover Problem. It aims to identify the smallest sub-collection cov-ering the entire shape. This method minimizes dilated inner ballsto approximate the shape, establishing a correspondence betweenthe skeleton and the shape, leading to a compact representationof the original shape. However, solving the Coverage Axis is time-consuming since it is in an SCP format, which is a well-knownNP-hard problem. For instance, the aver\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tions run efficiently on modern su-percomputers is essential to achieve scientific discoveries rapidly.Identifying performance problems is the first step in the processof optimizing performance of a parallel program. However, per-formance analysis is a complex and time-consuming task due tothe inherent complexity of large-scale parallel applications andarchitectures, and the large quantity of performance data that canbe collected when running in parallel. In addition, parallel applica-tions may suffer from a variety of performance issues. Therefore,in order to minimize the developer’s burden, we require highlyConference’17, July 2017, Washington, DC, USA2024. ACM ISBN 978-x-xxxx-xxxx-x/YY/MMhttps://doi.org/10.1145/nnnnnnn.nnnnnnneffective performance analysis techniques that can quickly identifyperformance problems and their root causes.A variety of performance measurement tools exist, includingprofilers and tracing tools that can generate performance data [ 1,7,17,28]. However, the data generated can be extremely large, makingit challenging to sift through this data to identify performanceissues. Several performance measurement tools also provide visualanalytics counterparts to facilitate performance analysis. Typically,the analysis support is in the form of a graphical user interface(GUI) to visualize and manipulate performance data [ 3,14,16,22]although some tools also provide a scripting interface [ 9,26]. TheGUIs help in visualizing performance data and in many cases, theuser can connect such data to source code (file and line numbers).Although GUIs provide some effective functionalities, having toanalyze performance data only via a GUI can make it inefficientto identify performance issues. GUIs depend on the end user tomanually explore the visualizations, and to identify different pat-terns that might suggest performance problems. As the data beinganalyzed grows, this becomes more and more challenging. In addi-tion, to analyze multiple executions, GUIs typically require openingmultiple separate windows with the datasets. Some of them canvisualize multiple datasets on the same window, however, they stillrequire significant manual effort to compare different executions.Finally, adding new kinds of analyses on top of a GUI may not bepossible for an end user.The main aim of this work is to simplify common performanceanalysis tasks for the end user by reducing the time and effortrequired. We present a Python-based API that simplifies severalperformance analysis tasks, and offers flexibility and customizationto enable users to perform analyses with speed and effectiveness.To achieve this goal, we explored the common functionalities inother performance analysis tools and also collected feedback fromdevelopers and users of performance tools to identify the mostneeded functionalities. We develop this new API on top of an ex-isting open-source performance analysis tool called Hatchet thatprovides an interface for programmatic analysis of performancedata via Python [5].By virtue of being developed on top of Hatchet, Chopper supportsdata formats of various performance tools, including but not limitedarXiv:2401.13150v1  [cs.DC]  23 Jan 2024Conference’17, July 2017, Washington, DC, USA Bhatele et al.to Caliper [ 7], HPCToolkit [ 1], Score-P (Cubex) [ 17] and TAU [ 28].Chopper facilitates performance analysis and reduces developereffort by simplifying tasks such as detection of load imbalance, hotpaths, scalability bottlenecks, and causes of performance variabilityvia a programmatic interface. It provides support for analyzingprofiles from single and multiple executions of programs. By usingthe provided functionalities in Chopper, users can quickly andeasily identify performance issues in a parallel program with a fewlines of Python code. Since it is a programmatic API, Chopper givesflexibility to the users to extend it and also use other Python librarieswith it for visualization and further analysis. To demonstrate theusability and flexibility of Chopper, we gather performance datausing several applications including the data collected in a priorperformance variability study [ 23]. The applications used in thisstudy are AMG, Laghos, LULESH, Quicksilver and Tortuga.Specifically, this work makes the following contributions:•A programmatic API that significantly simplifies severalsingle-run performance analysis tasks.•Facilitate the analysis of multiple executions by designingand implementing algorithms for multi-run analysis thatenable an effective and intuitive approach to identifyingperformance issues across multiple executions.•An evaluation of the scalability of some user-facing functionsprovided in Chopper by using large parallel profiles.•Demonstration of the usefulness of Chopper and its capa-bilities to identify performance issues by performing casestudies using several applications.2 BACKGROUND AND RELATED WORKWe give background information on profiling, call graphs, and com-mon performance analysis techniqu\n",
      "----------------------------------------------------------------------------------------------------\n",
      "com-putation) of the recursive function.1 IntroductionA revolution in neural methods for programming language tasks is underway. Once confined to the realmof symbolic methods, some of the most performant tools for synthesizing (Chaudhuri et al., 2021; Chenet al., 2021; Li et al., 2022b; Chowdhery et al., 2022), repairing (Gupta et al., 2017; Saha et al., 2017; Xiaet al., 2023), and even formally verifying (Agrawal et al., 2023; Yang & Deng, 2019; First & Brun, 2022;1arXiv:2401.12947v1  [cs.CL]  23 Jan 2024Expression7ExpressionExpressionExpression75×ExpressionExpressionExpression7×\t5(6×8)+(9+1)+×+(a) Recursion in an expression. Assume binary operators ‘+’ and ‘ ×’. An expression can bea number or two expressions connected by ‘+’ or two expressions connected by ‘ ×’.Alvin enjoys fishing.Alvin, who studies in Chicago, enjoys fishing.Alvin, who studies in Chicago, which is a city on Lake Michigan, enjoys fishing.(b) Recursion in natural language.This nesting of clauses is a classic example of recursivenessin a sentence, demonstrating how language can be structured in increasingly complex ways.Figure 1: Some examples of recursive patterns.Sanchez-Stern et al., 2023; 2020; First et al., 2023) programs now rest in part or in whole upon neuralfoundations.But how sturdy are these foundations? At the core of many of these tools are transformer-based largelanguage models (Chen et al., 2021; Chowdhery et al., 2022; First et al., 2023). It is an open question towhat degree these models are simply repeating program syntax, and to what degree they have some modelof program semantics —how programs behave and what they mean. Recursive programs are one class ofprograms for which program semantics are especially useful and interesting. In fact, recursion is fundamentalacross many different disciplines beyond program semantics: It is fundamental to parsing program syntax(Figure 1a) and omnipresent in natural language (Figure 1b). It is also fundamental to logical reasoning andmathematics—the formal definition of the original Peano natural numbers, for example, is recursive in thatit has a base case “one” and a recursive “successor” function, where the successor of any natural number isalso a natural number.In this paper, we investigate the degree to which transformers-based models (Vaswani et al., 2017) can learnto model a particular kind of recursion. In doing so, we join a long line of work that studies the representationcapabilities of ML models through a formal language lens. The close connection between formal languagesand neural network systems can be traced back to the early chapters of computer science (e.g., one keypurpose of introducing regular expressions by Kleene et al. in 1951 (Kleene, 1951) was to understand thenerve nets (McCulloch & Pitts, 1943)).Due to the omnipresence of recursion, in a broad sense, transformer-based models are already used to solveproblems that rely in some way on recursion. However, these models are occasionally observed to fail in casesthat demand a strong understanding of recursive structures. For example, models trained for programmingtasks may misunderstand programs with nested blocks or produced imbalanced brackets. This highlights thenecessity of examining the ability of machine learning (ML) models to capture recursive patterns, especiallyin a world where ML-assisted programming and mathematical reasoning are growing at explosive rates.Our work focuses in particular on structural recursion : a restricted but powerful class of recursive functionsthat are defined in a structurally decreasing manner, and so must terminate. A program is an example ofstructural recursion if it is defined over some data structure (say, binary trees) by recursively calling itselfover smaller substructures (say, left and right subtrees). Structural recursion is at the heart of importantprogramming and formal theorem-proving tasks (which are important in software verification and mathe-matics) for which neural methods still lag behind symbolic methods, like inferring semantic relations betweendatatypes (Ringer et al., 2021; Ringer, 2021).The difficulty of learning tasks similar to the structurally recursive ones we are interested in has manifestedin prior work. For example, Zhang et al. (Zhang et al., 2022b) identify “statistical shortcuts” on simplepropositional logic, where the model fits statistical features instead of the correct reasoning steps. Van derPoel et al. (van der Poel et al., 2023) observe failures of neural networks on certain types of cases for regular2languages, an even simpler class of formal languages than those we are interested in. Our work identifiesthe root of similar brittleness in the context of structurally recursive functions by further reconstructing thealgorithms emulated by the learned models that lead to those errors.Our contributions are twofold: First, we introduce a general framework for representing and rea-soning about structural recursion with sequence models. Second, we\n",
      "----------------------------------------------------------------------------------------------------\n",
      "weaknesses in various scenarios. Through the evalu-ation of MATRYOSHKA , we discover a serious issue facing alltested approaches, unfortunately including MATRYOSHKA ,and call for further research on tiered memory-aware memoryallocation.1 IntroductionAs new memory devices, such as high bandwidth memory(HBM) [4, 27], DRAM, persistent memory [7, 36], ComputeExpress Link (CXL)-based memory [1, 34, 41], and storage-class memory [50, 52] continue to emerge, future computersystems are anticipated to feature multiple tiers of mem-ory with distinct characteristics, such as speed, size, powerand cost. Tiered memory management aims to leverage thestrength of each memory tier to optimize the overall dataaccess latency and bandwidth. Central to tiered memory man-agement is page management within operating systems (OS),including page allocation, placement, and migration. Efficientpage management in the OS is crucial for optimizing memoryutilization and performance while maintaining transparencyfor user applications.Traditionally, the memory hierarchy consists of storagemedia with at least one order of magnitude difference in per-formance. For example, in the two-level memory hierarchy as-sumed by commercial operating systems for decades, DRAMand disks differ in latency, bandwidth, and capacity by 2-3orders of magnitude. Therefore, the sole goal of page manage-ment is to keep hot pages in, and maximize the hit rate of the“performance” tier (DRAM) and migrate (evict) cold pages tothe “capacity” tier (disk) when needed. As new memory de-vices emerge, the performance gap in the memory hierarchynarrows. Evaluations on Intel’s Optane persistent memory[53] and CXL memory [47] reveal that these new memorytechnologies are able to achieve comparable performance toDRAM in both latency and bandwidth, within a range of 2-3x.As a result, the assumption on the performance gap, whichhas guided the design of OS page management for decades,may not hold. It is no longer beneficial to promote a hot pageto the performance tier if the migration cost is too high.Furthermore, unlike disks which must be accessed throughthe file system as a block device, new memory devices arebyte-addressable and can be directly accessed by the proces-sor via ordinary load andstore instructions. Therefore, fora warm page on the capacity tier, accessing the page directlyarXiv:2401.13154v1  [cs.OS]  24 Jan 2024and avoiding migration could be a better choice. Most im-portantly, while the performance of tiered memory remainshierarchical, the hardware is no longer hierarchical. Both theOptane persistent memory and CXL memory appear to theprocessor as CPUless memory nodes, enabling the OS tomanage them as ordinary DRAM nodes.These unique challenges facing emerging tiered memorysystems have inspired research on improving page manage-ment in the OS. Much focus has been on expediting pagemigrations between memory tiers. Nimble [51] improvespage migration by utilizing transparent huge pages (THP),multi-threaded migration of a page, and concurrent migrationof multiple pages. Transparent page placement (TPP) [41]extends the existing NUMA balancing scheme in Linux tosupport asynchronous page demotion and synchronous pagepromotion between fast and slow memory. Memtis [34] andTMTS [22] use hardware performance counters to mitigatethe overhead of page access tracking and use backgroundthreads to periodically and asynchronously promote pages.However, these approaches have two fundamental limita-tions. First, the existing page management for tiered memoryassumes that memory tiers are exclusive to each other – hotpages are allocated or migrated to the performance tier whilecold pages are demoted to the capacity tier. Therefore, eachpage is only present in one tier. As memory tiering seeksto explore the tradeoff between performance and capacity,the working set size of workloads that benefit most fromtiered memory systems likely exceeds the capacity of the per-formance tier. Exclusive memory tiering inevitably leads toexcessive hot-cold page swapping or memory thrashing whenthe performance tier is not large enough to hold hot data.Second , there is a lack of an efficient page migration mech-anism to support tiered memory management. As future mem-ory tiers are expected to be addressable by the CPU, pagemigrations are similar to serving minor page faults and in-volve three steps: 1) ummap a page from the page table; 2)copy page content to a different tier; 3) remap the page on thepage table, pointing to the new memory address. Regardlesswhether page migration is done synchronously upon access-ing a hot page in the slower capacity tier or asynchronouslyin the background, the 3-step migration process is expensive.During the migration, an unmapped page cannot be accessedby user programs. If page migration is done frequently, e.g.,due to memory thrashing, user-perceived bandwidth, includ-ing accesses to the migrating pages, is significantly lower (upto 95% lower) than the peak memory band\n",
      "----------------------------------------------------------------------------------------------------\n",
      "g parameters θ∈Rp. Thisinterpretability is also preserved in the various exten-sions such as generalized linear models (GLMs; Nelderand Wedderburn, 1972) for non-Gaussian conditionaloutcome distributions or generalized additive models(GAMs; Wahba, 1990; Wood, 2017) for the inclusionof non-linearity via splines. While these extensions al-low for a flexible definition of univariate or moderate-dimensional multivariate feature effects, they lack flex-ibility for complex higher-order interactions and arerestricted to tabular features. A deep neural net-work (DNN), on the other hand, learns complex fea-ture effects in a data-driven fashion and can work fordifferent input modalities (e.g., image data). The fu-sion of a structured and interpretable statistical modelwith highly flexible DNNs thus has some attractiveproperties and has been investigated over the last 30years (cf. Section 2.1).While this combination is flexible and attractive froma modeling point of view, many properties of this so-called semi-structured regression (SSR) are yet stillunexplored. One important aspect is their uncertaintyquantification, particularly relevant in their applica-tion in the medical domain (Dorigatti et al., 2023).Although some of the more recent approaches accountfor aleatoric (R¨ ugamer et al., 2023) or epistemic un-certainty in SSR models (D¨ urr et al., 2022; Dorigattiet al., 2023), all existing approaches do either not ac-count for the epistemic uncertainty arising from themodel’s DNN part or assume this uncertainty to begiven. Another significant but understudied challengein traditional SSR models is the joint optimization ofthe two model components. On the one hand, DNNscan theoretically fit the training data perfectly, po-tentially leaving little to explain for the structuredpart(Zhang et al., 2017, 2021). Optimization of struc-tured models such as GLMs, on the other hand, is typi-cally done using more advanced second-order methods.This optimization asymmetry in SSR complicates theprocess of joint optimization.arXiv:2401.12950v1  [cs.LG]  23 Jan 2024Bayesian Semi-structured Subspace Inference−10 0 10−202ySemi-Subspace (k=2)−10 0 10uSemi-Subspace (k=12)−10 0 10HMC (d=337)p(y|D,u,x =cat0) p(y|D,u,x =cat1) p(y|D,u,x =cat2)Figure 1: Comparison of semi-structured subspace inference and Hamilton Monte Carlo (HMC) for an SSRmodel. The SSR is defined as a combination of a linear shift induced by the categorical feature x(color code)and a non-linear trend in u(x-axis) modeled by a deep neural network (cf. Equation 1). Left/center: posteriorpredictive for dataset Dand outcome ywith a 2-dim. and 12-dim. subspace; right: posterior predictive of HMCwithout any approximation. Points represent the data, colored by their category of x, the solid line is the mean,and shading depicts the 95% Highest Density Interval.The Bayesian paradigm offers a rigorous frameworkfor quantifying uncertainty and Markov Chain MonteCarlo (MCMC) methods, relying on sampling ratherthan optimization, are often considered as the goldstandard for inference in Bayesian neural networks(Wiese et al., 2023). Hence, a Bayesian variant of SSRmodels could provide inference statements and circum-vent the aforementioned issues with the joint opti-mization of structured and DNN model parts. Thesesampling-based approaches, however, are computa-tionally intensive and struggle with high-dimensionalparameter spaces typical for DNNs.Our Contribution In this work, we presentsemi-structured subspace inference , a sampling-basedmethod that not only captures aleatoric and epistemicuncertainty in SSR models but also addresses the op-timization asymmetry often observed in such mod-els. Our method allows obtaining the posterior for ev-ery structured model parameter while accounting forthe DNN’s uncertainty. By using an adjustable sub-space approximation of the DNN part, it is compatiblewith common MCMC methods. We show that semi-structured subspace inference 1) yields nearly the sameposterior distribution as full-space MCMC methodsfor the structured model component, and 2) providesposterior predictive distributions of the quality of full-space inference even when using a highly-compressedsubspace (see Figure 1). We further provide numericalevidence confirming the efficacy of our approach andsuperiority when compared to other Bayesian approx-imation methods.2 RELATED WORKBefore introducing our method in Section 3, we brieflyintroduce SSR and Subspace inference in the following.2.1 Semi-Structured RegressionThe fusion of structured models from statistics and(deep) neural networks started with Ciampi andLechevallier (1995, 1997), followed by extensions tomodel generalized additive neural networks (Potts,1999; de Waal and du Toit, 2007; De Waal and Du Toit,2011). In recent years, this combination has returnedto the limelight under the name of wide and deeplearning (Cheng et al., 2016) or semi-structured re-gression (SSR; R¨ ugamer, 2023). Due to its flexibility,SSR has been adapted f\n",
      "----------------------------------------------------------------------------------------------------\n",
      "performance,especially, in scenarios of limited data records. In addition,our TMP method improves the computational efficiency ofthe state-of-the-art multipersistence summaries up to 59.5times.1 IntroductionOver the last decade, the field of topological data analysis(TDA) has demonstrated its effectiveness in revealing con-cealed patterns within diverse types of data that conventionalmethods struggle to access. Notably, in cases where conven-tional approaches frequently falter, tools such as persistenthomology (PH) within TDA have showcased remarkable ca-pabilities in identifying both localized and overarching pat-terns. These tools have the potential to generate a distinctivetopological signature, a trait that holds great promise for a*These authors contributed equally.Copyright © 2024, Association for the Advancement of ArtificialIntelligence (www.aaai.org). All rights reserved.range of ML applications. This inherent capacity of PH be-comes particularly appealing for capturing implicit temporaltraits of evolving data, which might hold the crucial insightsunderlying the performance of learning tasks.In turn, the concept of multiparameter persistence (MP)introduces a groundbreaking dimension to machine learn-ing by enhancing the capabilities of persistent homology. Itsobjective is to analyze data across multiple dimensions con-currently, in a more nuanced manner. However, due to thecomplex algebraic challenges intrinsic to its framework, MPhas yet to be universally defined in all contexts (Botnan andLesnick 2022; Carri `ere and Blumberg 2020).In response, we present a novel approach designed toeffectively harness MP homology for the dual purposesof time-aware learning and the representation of time-dependent data. Specifically, the temporal parameter withintime-dependent data furnishes the crucial dimension nec-essary for the application of the slicing concept within theMP framework. Our method yields a distinctive topologicalMP signature for the provided time-dependent data, man-ifested as multidimensional vectors (matrices or tensors).These vectors are highly compatible with ML applications.Notably, our findings possess broad applicability and canbe tailored to various forms of PH vectorization, renderingthem suitable for diverse categories of time-dependent data.Our key contributions can be summarized as follows:• We bring a new perspective to use TDA for time-dependent data by using multipersistence approach.• We introduce TMP vectorizations framework which pro-vides a multidimensional topological fingerprint of thedata. TMP framework expands many known single per-sistence vectorizations to multidimensions by utilizingtime dimension effectively in PH machinery.• The versatility of our TMP framework allows its appli-cation to diverse types of time-dependent data. Further-more, we show that TMP enjoys many important stabilityguarantees as most single persistence summaries.• Rooted in computational linear algebra, TMP vectoriza-tions generate multidimensional arrays (i.e., matrices ortensors) which serve as compatible inputs for various MLmodels. Notably, our proposed TMP approach boasts aspeed advantage, performing up to 59.5 times faster thanarXiv:2401.13157v1  [cs.LG]  24 Jan 2024the cutting-edge MP methods.• Through successful integration of the latest TDA tech-niques with deep learning tools, our TMP-Nets modelconsistently and cohesively outperforms the majority ofstate-of-the-art deep learning models.2 Related Work2.1 Time Series ForecastingRecurrent Neural Networks (RNNs) are the most success-ful deep learning techniques to model datasets with time-dependent variables (Lipton, Berkowitz, and Elkan 2015).Long-Short-Term Memory networks (LSTMs) addressedthe prior RNN limitations in learning long-term dependen-cies by solving known issues with exploding and vanishinggradients (Yu et al. 2019), serving as basis for other im-proved RNN, such as Gate Recurrent Units (GRUs) (Deyand Salem 2017), Bidirectional LSTMs (BI LSTM) (Wang,Yang, and Meinel 2018), and seq2seq LSTMs (Sutskever,Vinyals, and Le 2014). Despite the widespread adoptionof RNNs in multiple applications (Xiang, Yan, and Demir2020; Schmidhuber 2017; Shin and Kim 2020; Shewalkar,Nyavanandi, and Ludwig 2019; Segovia-Dominguez et al.2021; Bin et al. 2018), RNNs are limited by the structure ofthe input data and can not naturally handle data-structuresfrom manifolds and graphs, i.e. non-Euclidean spaces.2.2 Graph Convolutional NetworksNew methods on graph convolution-based methods over-come prior limitations of traditional GCN approaches,e.g. learning underlying local and global connectivity pat-terns (Veli ˇckovi ´c et al. 2018; Defferrard, Bresson, andVandergheynst 2016; Kipf and Welling 2017). GCN han-dles graph-structure data via aggregation of node informa-tion from the neighborhoods using graph filters. Lately,there is an increasing interest in expanding GCN capabil-ities to the time series forecasting domain. In this con-text, modern approac\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1: EnhancingGPT-4withmeta-prompting. Inthisstudy,weintroduceandexaminetheeffectivenessofmeta-prompting, contrasting it with a range of zero-shot prompting techniques, including standard zero-shot (Std), zero-shotchain-of-thought (0-CoT; Kojima et al .(2022)), generic and dynamic expert (Ex-St and Ex-Dy; Xu et al .(2023)), andmultipersona(MP;Wangetal.(2023)). Ourresearchdemonstratesthatmeta-prompting,particularlywhencombinedwith a Python interpreter, significantly improves overall accuracy and robustness in GPT-4 across a variety of tasks.∗Work done while at Microsoft Research New England.1The data, prompts, and the model outputs are all available at https://github.com/suzgunmirac/meta-prompting .1arXiv:2401.12954v1  [cs.CL]  23 Jan 20241 IntroductionThe latest generation of language models (LMs)—notably, GPT-4 (OpenAI, 2023), PaLM (Anil et al ., 2023),and LLaMa (Touvron et al ., 2023)—have expanded the boundaries of natural-language processing andgeneration. These large-scale models can tackle a wide spectrum of tasks, ranging from writing Shake-spearean sonnets about hedgehogs to summarizing intricate medical reports and solving competition-levelprogramming puzzles. Despite their versatility, these models are not infallible; they sometimes generateresponsesthatareinaccurate,misleading,orconflicting. Astheoperationalcostsofthesemodelsbecomemore affordable, it becomes natural to ask whether one might use scaffolding systems and leverage multipleLM queries to not only refine but also to enhance the accuracy and robustness of these model outputs.In this work, we introduce a new technique for enhancing the functionality and performance of LMs, calledmeta-prompting. Itinvolvesconstructingahigh-level“meta”promptthatinstructsanLMto: (i)breakdowncomplextasksorproblemsintosmaller,manageablepieces;(ii)assignthesepiecestospecialized“expert”modelswithproperanddetailednatural-languageinstructions;(iii)overseethecommunicationbetweentheseexpertmodels; and(iv)applyitsowncriticalthinking,reasoning, andverificationskillsthroughoutthe process. When presented with a query, the LM, effectively prompted under meta-prompting, servesas a conductor. It produces a message history—a narrative, if you will—comprising the responses fromvariousexpertmodels. TheLMisoriginallyresponsibleforgeneratingtheconductor’sportionofthishistory,whichincludestheselectionofexpertsandtheformulationofspecificinstructionsforthem. However,thesame LM doubles itself as these independent experts as well, generating outputs based on the expertise andinformation chosen by the conductor for each particular query.Thisapproachallowsforasingle,uniformLMtomaintainacoherentlineofreasoningwhilealsotappingintoavarietyofexpertroles. Theuseofdynamicallyselectedcontextsforpromptingtheseexpertsintroducesfresh perspectives into the process, while the conductor model retains a bird’s-eye view of the entire historyand coordination. This method, therefore, enables a single black-box LM to function effectively as both acentral conductor and a diverse panel of experts to produce more accurate, reliable, and coherent responses.Our proposed meta-prompting technique combines and expands upon various prompting ideas introducedbyrecentstudies—including, high-levelplanninganddecision-making (Yaoetal .,2023b;Sunetal .,2023;Haoetal.,2023a), dynamicpersonaassignment (Xuetal .,2023;Wangetal .,2023),multi-agentdebating (Duetal .,2023;Zhugeetal .,2023),self-debuggingandself-reflection (Schicketal .,2023b;Liuetal .,2023a;Gouetal .,2023;Madaan et al ., 2023; Shinn et al ., 2023). A key aspect of meta-prompting is its task-agnostic nature. Unliketraditional scaffolding methods that require specific instructions or examples tailored to each task, meta-prompting employs the same set of high-level instructions across various tasks and inputs. This universalityisparticularlybeneficialforuserswhomightfinditcumbersometoprovidedetailedexamplesorspecificguidance for every distinct task. For instance, in responding to a one-off request like “Write a Shakespeareansonnetaboutselfies,”theuserwouldnotneedtosupplyexamplesofhigh-qualityneoclassicalpoems. Themeta-promptingapproachelevatestheutilityoflanguagemodelsbyofferingabroad,flexibleframeworkwithoutcompromisingonspecificityorrelevance. Additionally,todemonstratetheversatilityandintegrationcapabilities of meta-prompting, we have enhanced our system with the functionality to invoke a Pythoninterpreter. Thisallowsfor aneven moredynamicand comprehensiveapplication ofthe technique,furtherextending its potential to address a wide array of tasks and queries effectively.Weprovideanillustrativevisualizationofameta-promptingsessioninFigure2. ItdepictshowtheMetaModel—ourtechnicaltermforthecentralcontrollingLM(a.k.a. theconductor)—interspersesitsownoutputwithinputsandoutputsfromvariousspecializedexpertmodelsorcodeexecutions. Suchaconfigurationmakes meta-prompting a nearly universal tool. It allows for the consolidation of various LM interactions andcomputations int\n",
      "----------------------------------------------------------------------------------------------------\n",
      " et al., 2022), or through zero-shot / few-shotevaluation, whereby the model is given only task-specific instructions as input, or a handful ofadditional exemplars to learn from, respectively (Brown et al., 2020).On the one hand, pre-training LLMs using self-supervised objectives frees us from the burden ofgathering human labels; on the other, the indirect nature of the supervision also means that each batchof text provides only weak signals that the model can learn from. Consequently, LLMs need to bepre-trained on datasets several orders of magnitude larger than the labeled domain specific datasets.Therefore, a major bottleneck in developing performant LLMs is the massive computational costincurred at the pre-training phase — e.g., GPT-3 (175B parameters) (Brown et al., 2020) and PaLM(540B parameters) (Chowdhery et al., 2022) need up to tens of thousands of PetaFLOP/s-days ofarXiv:2401.13160v1  [cs.LG]  24 Jan 2024The black dog  ran very fast  and jumped on the couch .The [M] [M]  ran [S0] and jumped [S1].The blue cat  ran [S0] and jumped [S1].Discriminator Encoder [1, 0, 0, 1, 1, 1, 1, 1, 1] Discriminator Decoder [S0] very fast  [S1] on the couch . <eos> Generator (Encoder-only) (1)T5 Figure 1: The SPACTORpre-training objective in the first stage. In step (1), the original text israndomly corrupted with span corruption (marked as [S0] ,[S1] ,etc, ) and then token-level randommasking (marked as [M]). A small auxiliary generator model Gis trained to recover [M]only. Theresulting text is then fed into the T5 discriminator D, whose encoder component learns to predict atevery position whether the token is a replaced one, while its decoder component learns to fill in theground truth token as in standard span corruption.compute for pre-training, respectively. In order to effectively scale language models towards betterquality, it is imperative to design more efficient self-supervision strategies under which more usefulsignals for learning downstream tasks are extracted out of each pre-training iteration on unlabeleddataIn this paper, we propose SPACTOR(short for “ Spancorruption and Tokenreplacement\"), a new pre-training procedure that significantly improves the efficiency andgeneralization of T5 models (Raffelet al., 2020). SPACTORconsists of two ingredients. The first is an augmentation of the span corruption(SC) pre-training task with the replaced token detection (RTD) objective proposed in ELECTRA(Clark et al., 2020). The second is a two-staged pre-training schedule: after τtraining steps onhybrid objectives, we continue pre-training only using the vanilla SC objective. The dual task inthe first stage is illustrated in Figure 1. Specifically, starting with a span-corrupted input text, anauxiliary generator Greplaces a portion of the uncorrupted tokens with plausible tokens. The mainT5 model (referred to as the discriminator D) is pre-trained to detect replaced tokens with its encodercomponent. Simultaneously, using the same token-replaced input, the discriminator attempts todenoise the SC masks with its decoder.From a quality standpoint, detecting replaced tokens enforces all token attention (Clark et al., 2020),leading to a better text representation. However, the generator Gcan also inadvertently introducemisleading yet plausible context (albeit trained non-adversarially), resulting in a noisier trainingenvironment for discriminator decoder D.1As we explain in more detail in Section 3, the advantagesof RTD are predominantly observed in the initial stages of pre-training. As the training progresseshowever, these benefits are eventually overshadowed by the noise introduced to the discriminator’sencoder. This phenomenon naturally motivates the two-staged training, which significantly booststhe performance on various downstream tasks. Figure 2 shows examples of these improvementswhen τequals 120K (1/8 of total iterations) and 250K (1/4 of total iterations) on the SuperGLUE(Wang et al., 2019a), SQuAD (Rajpurkar et al., 2016) and CNN/DailyMail (Hermann et al., 2015)benchmarks. These and several other results are discussed in detail in Section 3 and Appendix C.1For example, if we have a corrupted sentence \"Last week we travelled to [M], the capital of [S0] .\", where[M]isTokyo and[S0] isJapan . The generator Gcan reasonably produce a different city for the mask [M],which consequently leads the discriminator to associate it with the capital of Japan due to the use of teacherforcing during training.20.25 0.50 0.75 1.00 1.25 1.50 1.75pre-training GFLOPs 1e10737475767778Average ScoreSuperGLUEBaselineSpacT or(250K)SpacT or(120K)(a) SuperGLUE0.25 0.50 0.75 1.00 1.25 1.50 1.75pre-training GFLOPs 1e1087.087.588.088.589.0Average ScoreSQuADBaselineSpacT or(250K)SpacT or(120K) (b) SQuAD0.25 0.50 0.75 1.00 1.25 1.50 1.75pre-training GFLOPs 1e1032.832.933.033.133.233.333.433.5Average ScoreCNN/DailyMailBaselineSpacT or(250K)SpacT or(120K) (c) CNN/DailyMailFigure 2: SPACTOR(τ) performances on SuperGLUE, SQuAD and CNN/DailyMail w\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gical themesPermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from permissions@acm.org.CHI’24, May.11-16, Honolulu, HI, USA©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0330-0/24/05. . . $15.00https://doi.org/10.1145/3613904.3641906ACM Reference Format:Xiaoshan Huang, Haolun Wu, Xue Liu, and Susanne Lajoie. 2024. Examiningthe Role of Peer Acknowledgements on Social Annotations: Unraveling thePsychological Underpinnings. In Proceedings of the CHI Conference on Hu-man Factors in Computing Systems (CHI ’24), May 11–16, 2024, Honolulu, HI,USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3613904.36419061 INTRODUCTIONDigital social annotation, a platform where readers comment withintext margins while reading, has evolved into a dynamic arena forcomputer-supported collaborative learning (CSCL) [ 24], facilitat-ing peer interactions [ 1] and co-construction of knowledge [ 31].However, the quality of online discourse varies, affecting learn-ers’ interactive experience and learning outcomes [ 16]. Peer ac-knowledgement, often conveyed through positive emoticons orsupportive words from fellow users, plays a pivotal role in shap-ing user behaviour, both in social media [ 17,25] and online learn-ing environments [ 37]. However, despite extensive systematic re-views on social annotation (e.g., [ 18,58]), limited attention hasbeen devoted to understanding how peer acknowledgement influ-ences learners’ subsequent behaviours within social annotationplatforms. Moreover, there remains a gap in our understandingof the key factors that establish evaluative criteria for the qualityof written content and how this written content influences peers’reactions. Consequently, it is imperative to delve into the exam-ination of linguistic features within written annotations, as theyprovide valuable insights into the psychological aspects of CSCL.An in-depth exploration of the interplay between these dimensionscan inform the development of effective instructional strategies,fostering student engagement with course materials and within theonline learning community [ 20]. This study aims to address theexisting gap by exploring the impact of peer acknowledgement onlearners’ subsequent annotation behaviours and comparing the rel-ative importance of linguistic indicators within four psychologicaldimensions (i.e., affect, cognition, motivation, and social) in writ-ten annotations related to peer acknowledgement. Given that thedigital social annotation platform provides rich trace data withoutinterrupting learners’ natural learning processes, it is recommendedarXiv:2401.12956v1  [cs.HC]  23 Jan 2024CHI’24, May.11-16, Honolulu, HI, USA Huang et al.to apply learning analytics to examine their “actual” learning be-haviours [ 22] within this context. The following sections will delveinto the theoretical foundations, draw from previous empirical stud-ies, and detail the human-centred analytical methods employed inthis study.2 BACKGROUND2.1 Peer Acknowledgement in Digital SocialAnnotationDigital social annotation is a productive forum for online learn-ing [ 27,31]. It employs a computer-supported communication ap-proach to facilitate interactions among peers within a shared com-munity or individuals with similar interests in specific topics. Moreprecisely, users can highlight valuable information by adding anno-tations to selected text and respond to others’ annotations throughwritten text or by using emoticons to express reactions. This func-tionality facilitates the co-construction of knowledge [ 31], nurturesa sense of collaborative learning community [ 21], and transformsindividual learning styles to social ones by promoting flexible asyn-chronous conversations [ 4]. In the digital era, social annotationhas emerged as a prominent pedagogical approach in higher educa-tion, enhancing online interaction without impeding collaborativelearning among students. However, the quantitative and qualitativeaspects of online discourse can vary, in terms of engagement inannotation activities and the content contributed, respectively.Furthermore, the quality of interaction, especially as indicatedby the responses and reactions of peers, significantly influencesonline users’ behaviours. Individuals may experience feelings ofisolation if they perceive a lack of connection with others in virtualspaces [ 19]. In contrast, the perceived richness of online discussionforums has a significant positive effect \n",
      "----------------------------------------------------------------------------------------------------\n",
      "pectral variability , the spectrum representingan EM can change as a function of its position in the HSI.The use of large libraries of spectra is a typical approachto deal with spectral variability in SU [2]. Among existingmethods, those based on sparse regression, considered com-putationally efficient, assume that the reflectance of pixels inan HSI can be described as a linear combination of a few EMsignatures from a large spectral library known a priori (typi-cally constructed from laboratory or in situ measurements) [3].However, spectral libraries are often not available for a givenHSI. Recent work proposed methods for extracting structuredL. C. Ayres, J. C. M. Bermudez, Universidade Federal de Santa Catarina,Florian ´opolis-SC, e-mail: lucayress@gmail.com, j.bermudez@ieee.org; R. A.Borsoi, Universit ´e de Lorraine, CNRS, CRAN, Vandoeuvre-l `es-Nancy, e-mail:raborsoi@gmail.com; S. J. M. de Almeida, Universidade Cat ´olica de Pelotas,Pelotas-RS, e-mail: sergio.almeida@ucpel.edu.br.This work has been supported in part by the National Council for Scientificand Technological Development (CNPq), Coordination of Superior Level StaffImprovement (CAPES) and Foundation for Research Support of the State ofRio Grande do Sul (FAPERGS).spectral libraries directly from the observed HSI [4]. Suchapproaches usually apply EM extraction algorithms (EEAs) tosubsets of pixels randomly sampled from the HSI. This ran-domness causes EMs obtained at each extraction to be slightlydifferent, representing the spectral variability in the HSI.In [5], the authors propose to introduce mixed norms inthe sparse SU optimization problem with structured spec-tral libraries to promote group sparsity. A new penalty isproposed to control inter- and intra-structure sparsity, whichcan considerably improve SU performance when compared totypically used sparsity penalties. However, the results of thistechnique depend on the initialization of the abundances in theoptimization problem. Furthermore, when used in conjunctionwith spectral libraries extracted from the HSI via methods suchas [4], the estimated abundances are random variables and maybe different for each run of the method.Another challenge with these techniques is their sensitivityto the presence of noise due to the large number of signaturesin the library. Integrating regularizations that promote spatialsmoothness of the abundances improves the performance ofsparse SU algorithms in noisy conditions, but at the expense ofa considerable increase in computational complexity [6], [7]. Afast sparse SU algorithm (called MUA), based on superpixelsand a multiscale strategy, has recently been proposed for theSU problem without using structured libraries [8]. Despite thepositive results obtained in [8], [9] with a sparsity penaltybased on the L 1norm, this solution is not suitable to tackle thechallenge of spectral variability through structured libraries.This work proposes a method to handle spectral variabilityof EMs in the SU problem while maintaining a reason-able computational cost and being robust to noise. Moti-vated by methods used in neuroimaging [10], we aim toobtain reproducible SU solutions [11], i.e., using the samealgorithm and data, the results should be consistent, evenconsidering randomness in some steps of the method. Themain contributions of this paper can be summarized as: 1)We generalize the multiscale spatial regularization problemformulated in the MUA algorithm [8] to solve the sparseSU problem with structured libraries, allowing the use ofmore general sparsity-inducing penalties, such as those basedon mixed norms [5]; 2) We propose a heuristic based ona graph centrality criterion to select reproducible abundanceestimates (i.e., with less influence of randomness on the SUprocess) from Kruns of the method. Experimental resultsshow that the proposed method provides high quality resultswith significantly less dispersion when compared to state-of-the-art algorithms. Codes to reproduce the experimental resultsare available at http://github.com/lucayress/GMBUA.arXiv:2401.13161v1  [cs.CV]  24 Jan 2024PUBLISHED IN IEEE GEOSCIENCE AND REMOTE SENSING LETTERS, DOI: 10.1109/LGRS.2024.3358694. COPYRIGHT BELONGS TO THE IEEE. 2II. S TRUCTURED SPARSE SPECTRAL UNMIXINGConsidering the LMM, an HSI Y∈RL×NwithLbands,Npixels and PEMs can be written as:Y=AZ+N, (1)where the abundances Z∈RP×Nare subject to the non-negativity (ANC) and sum-to-one (ASC) constraints [1].A∈RL×Prepresents the matrix of EMs. Column ap,p= 1, . . . , P , ofAis the signature of of the pth EM. Nis the additive noise. Using LMM allowing for considerationof spectral variability requires a representation of any givenmaterial using more than one EM.A. SU with structured EM librariesFollowing [5], consider replacing Ain LMM (1) with astructured spectral library B∈RL×Q.Bis composed of Pstructures Bp(p= 1, . . . , P ). The columns of the pth structureare different spectral signatures of the pth EM of the HSI:Y=BX+N,B=\u0002B1|B2|. . .|BP\n",
      "----------------------------------------------------------------------------------------------------\n",
      " 15,17,19], studied developers’ perceptions in com-mercial [ 5] and open-source projects [ 19], analyzed factors fromvarious aspects, and used machine learning classifiers to automat-ically predict the usefulness of CR comments [ 1]. However, CRcomments are written in verbal (i.e., natural language text) and/ ornon-verbal (i.e., emoji, emoticons, animation, or votes) forms.Lu et al .[13] reported a notable uptick in the use of emojis inpull request comments, from less than 1% to 10%, over half a decade.In a separate empirical study, Park and Sharif [ 16] found thatdevelopers pay significantly more attention to emojis comparedto the body text in CR comments. Furthermore, a study by Wanget al.[20] suggested that emoji reactions can positively influencecollaboration in the code review process. Recently, Lu et al .[12]Figure 1: Overview of Our Approach to Hypotheses Testingemployed emojis as predictors to forecast the dropouts of remotedevelopers on GitHub successfully. Interestingly, they found thatdevelopers who did not use emojis were three times more likely todrop out in the subsequent year than those who did.Conversely, Ahmed and Eisty [ 1] delved into the effectivenessand comprehension of CR comments by examining factors likesentiment, polarity, and formality within the text. However, existingresearch has not yet explored the role of non-verbal elements suchas emojis or emoticons in the context of useful CR comments. Giventhat these non-verbal cues can convey sentiments or polarity muchlike their verbal counterparts, our initial hypothesis is H1: “Thesentimentsexpressedthroughemojis,inconjunctionwiththoseinCRcommenttexts,arecorrelatedwiththeoverallsentiment (H1.1) or usefulness (H1.2) of Code Reviews” .These non-verbal cues do more than convey sentiment or addvisual flair; they also serve as instructional elements for develop-ers [18]. Therefore, these cues could influence the perceived useful-ness of CR comments, either emotionally or technically. Building onthis, our next hypothesis is H2:“Incorporatingemojisalongsidetext and semantic content will improve the prediction of theusefulness of CR comments” .We aim to examine these hypotheses by utilizing sentimentanalyzers and pre-trained models for both text and emojis (seeFigure 1). Given the absence of specialized emoji sentiment ana-lyzers for CR comments, we plan to annotate an existing datasetwith emoji-related sentiments. Additionally, we intend to enrichthe same dataset comprehensively with emojis to achieve a moreholistic understanding. Our findings indicate that general emojisentiments offer valuable insights, while domain-specific emoji sen-timents provide even deeper context. Above all, the semantics ofemojis prove to be the most informative factor in determining theusefulness of CR comments when utilizing existing datasets.The primary contributions of this paper are: (1) a compilation ofemoji-sentiment scores specific to CR comments, (2) a CR commentdataset annotated with emojis, and (3) empirical support for theAccepted at NLBSE@ICSE 2024, April 2024, Lisbon, Portugal Sharif Ahmed and Nasir U.Eistysignificance of emojis in CR comments, derived from an analysis oftheir sentiment and features obtained from pre-trained embeddings.2 METHODOLOGY2.1 Emojis and their FeaturesHere, we describe how we extract emojis from CR comments andhow we obtain features for emojis from existing tools and models.2.1.1Emoji Extraction .We convert various non-Unicode formsof emojis, including codepoints ‘ +U1F60A ’, emoticons ‘:)’, and emojiexpressions ‘:smile:’, into Unicode emoji characters ‘ ’. Specifi-cally, we use GroupMeShortcuts1to convert emoticons into emojiexpressions. Following this, we utilize the pythonpackage2to trans-form all emoji expressions into their corresponding Unicode emojis.2.1.2Features from Emoji .Given that emojis convey emotionsand various other cues, our initial focus is obtaining sentimentscores and their semantic features, as described below.i)EmojiSentiment: As emojis have expressions and descrip-tions in natural language, and considering that sentiment analyzersexist for natural language, we decode the emojis into their textualexpressions. We then use TextBlob3, a sentiment analyzer for nat-ural language (i.e., English) text, to generate sentiment scores forthese emoji expressions. However, this sentiment analyzer can notproduce meaningful scores for the emojis from their expressions.Next, we employ SEntiMoji [ 6], a sentiment analyzer fine-tunedon the DeepMoji [ 8], which incorporates relevant GitHub communi-cation data, although it excludes CR comments. However, this toolis confined to the 64 emojis available in DeepMoji. But it only sup-ports 5 out of the 14 Unicode emojis in the RevHelper [ 17]dataset.Given this limitation, we use the emoji sentiment scores providedby Novak et al. [ 11] , which covers around 80% of the emojis we areinterested in. We refer to these scores as general emoji sentiment .Since none of these sentiment so\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nopinionandknowledgeamongpeople.Whentranslationishandedovertoalgorithmicsystems,harmsmayensue(Blodgettetal.2020).Machinetranslation(MT)thusholdsthepowertoupholdandenforcesocialpowerdynamicsonaregularbasis,andastrongexampleofthatistheflatteningandhomogenizinggenderandethnicdiversitiesoflanguages,mostcommonlythosewhichsufferedcolonialoppression.Inthischapter,weexplorethesociotechnicalimplicationsofMTinthecontextofgenderintranslationto/fromorbetweenlow-resourcelanguages,specificallyourmothertongueofBengali.Wedonotpresentnovelempiricaldata,butinsteadbuilduponpriorworkandprovidediscursivecommentaryfromouridentitiesasnativespeakersofarichlanguagewhichstillisassignedthemonikerlow-resource.Wealsoapplyourperspectivesofbeingregularusersofmachinetranslationbothinofficialandpersonalusecases,andlinguisticresearcherswhostudythesociotechnicalimpactsoferroneousMTbetweenhigh-andlow-resourcelanguages.2.Low-ResourceLanguagesWhatmakesalanguagehigh-orlow-resourceisacombinationofseveralfactors,aconceptthatthischapteraddressesbyhighlightingkeyaspects.Intheearly1950s,NaturalLanguageProcessing(NLP)techniquesreliedonsimplerule-basedapproachesbasedonhuman-dictatedlistsofrulesonhowtointerpret,manipulate,andevaluateoneormoresymbolsfedtocomputers,whichwouldthenexecutetheseinstructionsonnewinputs(Winograd1971).Thisapproachwasunscalable,andthemid90sbroughtstatisticalapproachesandmachinelearning(ML)techniques,withprocessessuchasdecisiontrees,parts-of-speechtagging,andstemmingandn-gramapproaches,tonameafew.Modern-dayNLPusessuchfeaturesincombinationwithrobustcomputationalcapabilities,enablingthehandlingofmanyterabytesofdata.Consequently,thereisagrowingimpetustoamassdataonsuchscalestofueltheever-expandingdemandsofmodernNLP.Datacollectionefforts,especiallyforMTpurposes,consequentlybeganlookingforpairsofsource-and-translatedtextswithwhichtotrainmodels,withthemostcommonearlycandidatebeingtheBible(Costa-jussàetal.2022).Thismadesense,sincetheBiblewasnotonlyprimarilycirculatedinWesternlanguagessuchasEnglish,French,Spanish,andPortuguese,butalsoinlanguagesoftheIndiansubcontinent,LatinAmerica,Africa,andOceania(McCarthyetal.2020).Here,itisimportanttorememberwhyandhowtheBibleachievedsuchastatusasoneofthemosttranslatedtexts.Anyconversationaroundthehierarchiesoflanguageswouldbeincompletewithoutconsideringvarioussociopoliticalforcessuchasimperialismandcolonialismthat,unintentionallyor(moreoften)intentionally,shapedtheirpositionsalonglinguisticladders.ColonialeffortsoftheUK,Spain,Portugal,andFrance,amongothers,andtheirquestsforglobaldominationsawthemexpandtheirrespectiveempiresintoAsia,Africa,andAmerica.Astheyenslavedtheindigenouspeoplethrougheconomicormilitarymeans,colonizersalsoimposedtheirlanguages,oftenwiththeintentionoferasinglocallanguages(Ravishankar2020).Theerasureoflocallanguagesandtheirreplacementwithcolonizers’tonguesrenderedpeoplesobeholdentothelanguagethatliberationwasnotconsideredfeasible.Parallelly,ascolonizersbroughtChristianitywiththem,aneedarosetoestablishversionsoftheBibleinthelocallanguagesofthecolonies.WiththeBritishcolonialempirebeingthelargest,Englishgrewintothegloballinguafranca,aphraseembeddingcolonialismitselfbecauseittranslatesinto‘languageoftheFranks,’acollectivereferringtoWesternEuropeans,yetthephraseisnowusedglobally.Therefore,Englishhasbecomeoneofthemost-spokenlanguages,withSpanish,French,andPortuguesejoiningin.Overtime,suchlanguagesgrewtobecomehigh-resourcelanguages,orthosethathavestrongcoverageandsignificantrepresentationinglobaldatasets(Cierietal.2016),whereasotherlanguagesthatdonothaveasstrongcoveragearetermedlow-resource.LinguisticresourceisafunctionofthevolumeoftextinalanguageavailableontheInternetwhichcanbeusedtotrainNLPmodels,andconsequently,thereasonsfortheavailabilityofsuchvolumesoftextorlackthereofarewhatmakelanguageslow-orhigh-resource.Weaddressafewofthosebelow.Inthecontextofcollectingandformingglobaldatasets,animportantfactoristheadventandspreadoftheInternetinvariouspartsoftheworld.SincetheInternetwasstartedandpopularizedinNorthAmericaandEurope,theiruserswerethefirsttoparticipateontheInternettoproducecontent.OnereasonfortheriseofEuropeanlanguagesinthehierarchyistheEuroparl(2005)dataset,compiledfrom11languagesusedwithintheEuropeanParliament.ButInternetavailabilityalsocreatedhierarchicaldifferencesbetweennon-Europeanlanguages.Internetavailabilitysimultaneouslycreatedhierarchicaldifferencesbetweennon-Europeanlanguages.ConsiderthecaseofChinaandIndia.Theselaunchedpublicly-availableInternetaccesswithinayearofeachother(Chinain1994andIndiain1995)andyet,China’s420millionInternetusersisover5timesthatofIndia’s81million(Prakash2018).Thereareseveralsuspectedandplausiblereasonsforthisgulf,suchasdifferencesinliteracylevels,inmedianincomesandabilitytoaffordInternetaccess,highernumberofmobilephonesandInternet-capabledevicesmanufacturedandusedinChina.Anotherreasonthatcanequalizethepopulationdifferenceisonceagainapoliticalone:linguisticoppressionandstandardization.Stayingontheaforementionedexample,Chineseisthemostpredominantlanguage\n",
      "----------------------------------------------------------------------------------------------------\n",
      "otional support [7–9].Significant effort has been made in the machine learningand system community to design new models that generatebetter responses faster using less computational resources.However, the streaming of these generated tokens to users isalso critical. Having intermittent stalls during transmissioncould greatly hurt the smoothness of interaction and damageuser experience.In a token streaming pipeline of LLM Chatbot, tokens aregenerated one by one in the cloud data center after receivingClientServer1. Send User’s PromptGive me advice for weekend.2. TokenizeGivemeadviceforweekend3. PrefillKV Cache4.Predict next tokenYou5a. Transmission5b. Update KV CacheUpdatedKV Cache6.Predict next tokencan7a. Transmission8b. Update KV Cache…Figure 1: LLM Chatbot Token Streaming Pipeline. We aim toimprove the transmission part (Blue Starred 5a, 7a)the prompt. After each token is generated, they are sent overthe wide-area network to reach the client device. If somepackets are dropped or significantly delayed in the network,the client will need to wait for packets to be retransmittedfrom the sender. This could cause an undesired stall for tokenstreaming since all later tokens need to wait for previous onesto arrive at the receiver before being rendered.As AI services become ubiquitous, people could use theseLLM Chatbot services anywhere, including places where in-termittent connections happen due to weak signals and inter-ference. To observe how current applications perform undersuch scenarios, we conducted a measurement study to showthat an unstable network could greatly increase the streamingstall of ChatGPT Streaming API as well as other applications.By reading into the packet traces, we see that these appli-cations rely on retransmission to handle packet loss, whichcaused the long stall. Moreover, we see an interesting pattern—after some packets are lost, the subsequent packets containingnewer tokens may still arrive earlier than the retransmissionpacket. However, no more new tokens could be renderedsince they are blocked by the lost tokens. Every token mustwait for retransmission triggered by TCP retransmission time-out (RTO) or the acknowledgment packets (ACKs) for later1arXiv:2401.12961v1  [cs.NI]  23 Jan 2024Generated TEXTOriginal TCP100% DuplicationChatterboxRendered:New:#2SenderReceiverSenderReceiverSenderReceiver…Token #1-3 are being generated and streamed.#1#2ATC isATC is at Santa ClaraATC isATC is at Santa Clara…ACKACKATC is at Santa ClaraShorter StallSimilar sending rate!#3#1#2………#1#1#2#2#1#1#1+2#1+2+3ATCisatSanta#3Clara#1Figure 2: An illustrative example. When the packets containing the first two tokens are lost, Chatterbox significantly reduces stallwith the similar overall sending rate, compared to TCP or adding 100% duplication (duplicate each packet twice). Here, weassume each token is sent out right after generation for real-timeness and show selective ACKs that signal retransmission.arrived packets. However, under an unstable network, RTTcould be long [17]. This increases the response time for bothretransmission mechanisms above and causes stall [18, 29].A natural solution under an unstable network is to add re-dundancy. Unfortunately, sending more duplicated packets foreach token could not solve the problem. If the connection wasweak at that time (due to a temporary obstruction or surfaceblock), few packets will get through in that time interval, andwe still need to wait for retransmission.To tackle this token streaming problem under unstable net-works, we proposed a novel transport scheme, Chatterbox, thatprovides a smooth token streaming experience and transformsChatbot into a more eloquent speaker under various networkconditions. Demonstrated in Fig 2, Chatterbox adds unackedtokens , defined as tokens whose packets have been sent buthave not been ACK’ed by the receiver, into the packet of thenewly generated token. It prepares each packet in such a waythat each received packet contains sufficient information forthe rendering of the new token contained inside, preventingthe retransmission blocking issue discussed above.Through our simulation under various network conditions,Chatterbox can reduce stall ratio1by 71.0% compared tothe TCP method used by ChatGPT Streaming API, and by31.6% with less total data sent than packet duplication method.This proves that Chatterbox could be a more robust transportscheme for token streaming under unstable networks.To summarize, our main contributions are to:•Identify the transmission problems in LLM Chatbot tokenstreaming pipeline and call for improvement.•Conduct real-world measurements to show performancedegradation of current applications under unstable network.•Propose the design of Chatterbox, a novel transport layerscheme tailored for token streaming to reduce stall rates on1Proportion of token rendering wait time when inter-token gap exceeds200msthe client side.2 Background and Motivation2.1 Token StreamingWe provide a brief end-to-end overview of t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ployed. (2) A multi-granularity dependency extraction module,aiming at capturing the inter-procedural call relationships of vulner-abilities, in which we construct multiple-granularity informationfor each vulnerability patch, including repository-level, file-level,function-level, and line-level. (3) A trace-based filtering module,aiming at filtering the outdated patches, which leverages the filepath trace-based filter and commit time trace-based filter to con-struct an up-to-date dataset.The constructed repository-level ReposVul encompasses 6,134CVE entries representing 236 CWE types across 1,491 projectsand four programming languages. Thorough data analysis andmanual checking demonstrate that ReposVul is high in quality andalleviates the problems of tangled and outdated patches in previousvulnerability datasets.Xinchen Wang and Ruida Hu contributed equally to this work.Corresponding author: Cuiyun Gao.KEYWORDSOpen-Source Software, Software Vulnerability Datasets, Data Qual-ity1 INTRODUCTIONIn recent years, with the increasing size and complexity of Open-Source Software (OSS), the impact of OSS vulnerabilities has alsoamplified and can cause great losses to our society. For example,Cisco discovered a security vulnerability in the WebUI, identifiedas CVE-2023-20198 [ 1] in 2023. This vulnerability allowed unautho-rized remote attackers to gain elevated privileges. Currently, over41,000 related devices have been compromised, resulting in greatlosses for enterprises. Identifying vulnerabilities in an accurateand timely manner is beneficial for mitigating the potential risks,and has gained intense attention from industry and academia. Theexisting vulnerability detection methods can be coarsely groupedinto two categories: program analysis-based methods [ 2–5] anddeep learning (DL)-based methods [ 6–9], among which DL-basedmethods have proven to be more effective. Despite the success ofthe DL-based methods, their performance tends to be limited bythe trained vulnerability datasets. For example, Croft et al. [ 10] findthat the widely-used vulnerability datasets such as Devign [ 11] andBigVul [ 12] contain noisy, incomplete and outdated data. The low-quality data may bias the model training and evaluation process.Therefore, a high-quality real-world vulnerability dataset is impor-tant yet under-explored for the vulnerability detection task. In thepaper, we focus on building the high-quality dataset by mitigatingthe following limitations of the existing datasets:(1) Tangled Patches: Vulnerability patches may contain vulnerability-fixing unrelated code changes, resulting in tangled patches . Ex-isting datasets [ 11–13] generally consider all the code changesin one patch submission related to the vulnerabilities, introduc-ing natural data noise. For the example shown in Figure 1(a), thepatch from CVE-2012-0030 includes the code change about pathmodification, in which the request path parameter of the func-tionwebob.Request.blank() has been changed (Lines 2-3). Suchvulnerability-unrelated changes may be concerned with code refac-toring or new feature implementation, and are hard to be distin-guished. Therefore, identifying vulnerability-fixing related filesfrom multiple files in one patch presents a challenge.arXiv:2401.13169v1  [cs.CR]  24 Jan 2024Conference’17, July 2017, Washington, DC, USA Xinchen Wang, Ruida Hu, Cuiyun Gao, Xin-Cheng Wen, Yujia Chen, and Qing Liaovoid* checked_xmalloc (size_tsize){alloc_limit_assert (\"checked_xmalloc \", size);returnxmalloc (size);}void* xmalloc(size_tsize){void*ptr= malloc (size);if(!ptr&& (size != 0)){perror(\"xmalloc: Memory allocation failure\" );abort();}returnptr; }12345678910111213123456789123456789101112 (a) An example of the tangled patch from CVE -2012 -0030. (b) An example of the inter-procedural vulnerability from CVE -2017 -6308.(c) An example of the outdated patch from CVE -2019 -19927. Commit message: “fix out -of-bounds read in ttm_put_pages () v2”                  _Commit ID: a66477b0efe511d98dde3e4aaeb189790e6f0a39 _Parent ID: d47703d43ecaa9189d70fb5d151a6883cc44afd3                              _File Path: drivers/ gpu/drm/ttm/ttm_page_alloc.c _-if(!(flags & TTM_PAGE_FLAG_DMA32)) {                                         _+if(!(flags & TTM_PAGE_FLAG_DMA32) && ( npages-i) >= HPAGE_PMD_NR) {         _for(j = 0; j < HPAGE_PMD_NR; ++j)if(p++ != pages[ i+ j])break;...}deftest_keypair_list (self):-req = webob.Request.blank ('/v1.1/123/ os-keypairs’ )             _+req = webob.Request.blank ('/v1.1/fake/ os-keypairs’ )            _res = req.get_response (fakes.wsgi_app ())self.assertEqual (res.status_int , 200)res_dict = json.loads (res.body )response = { 'keypairs' : [{'keypair' : fake_keypair ('FAKE')}]}self.assertEqual (res_dict , response)...123456789101112Commit message: “fix start page for huge page check in ttm_put_pages ()”          _Commit ID: ac1e516d5a4c56bf0cb4a3dfc0672f689131cfd4                              _Parent ID: a66477b0efe511d98dde3e4aaeb189790e6f0a3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "han the others and therefore the weighted average of meanAoI values of the sources (termed as weighted AoI in thispaper) is often used as the metric for quantifying the timelinessof communication. To minimize the weighted AoI, the sourcetransmissions need to be scheduled appropriately.Maximum age first (MAF) policy [4]–[6], where the sourcewith highest instantaneous age is scheduled, and maximum-age-difference drop (MAD) policy [7], where the source whichwould result in the maximum drop in age is scheduled,have been extensively studied in the literature for this multi-source setting. Max-weight, Whittle-index policies [8]–[10],This work is done when N. Akar is on sabbatical leave as a visitingprofessor at University of Maryland, MD, USA, which is supported in partby the Scientific and Technological Research Council of T ¨urkiye (T ¨ubitak)2219-International Postdoctoral Research Fellowship Program.S1S2S1S2S2S1cyclic schedulepacket dropratepXYremotemonitorS1pathS2pathpacket droprateqFig. 1: System model.along with MAF and MAD are a few examples of age-aware scheduling policies which require the transmitter tocontinuously track the age of the sources and therefore canintroduce a significant communication overhead, especially inchannels susceptible to packet drops (or errors). Moreover,in open-loop communication systems where the feedback onpacket drops is absent (i.e., only the channel service time isknown), these age aware schemes are not feasible. Therefore,age-agnostic cyclic scheduling has recently become a viablesolution to mitigate this communication overhead [11]–[14].A framework named Eywa was introduced in [13] wherethe goal is to construct almost uniform cyclic schedulers(AUS) , which is a special class of cyclic schedulers designedto distribute the scheduling instances of a given source asuniformly as possible within the cycle. Eywa works in thediscrete time setting and assumes that all the sources have thesame deterministic service times with heterogeneous packeterrors. However, in a more practical setting, the service timesof different sources may be different, in which case reference[14] obtains the optimal cyclic scheduler that minimizes theweighted AoI for two heterogeneous sources in the absenceof packet errors. Reference [14] shows that in the absenceof packet errors, the optimal cyclic schedulers are of theform (1,Θ)which represents a cyclic schedule where onescheduling instance of one of the sources is followed by Θscheduling instances of the other source.In this paper, we extend the work done in [14] to the caseof packet errors, and find the best cyclic scheduler which isresilient even in the presence of packet errors in the channel.We note that there are some similarities but significant keydifferences between the optimal cyclic scheduler constructedin this work and the one constructed in the absence of packeterrors [14]. In the presence of packet errors, we show thata near-optimal cyclic scheduler is a mixture of (1,Θ)and(1,Θ + 1) cyclic schedulers. We emphasize the fact that evenarXiv:2401.12962v1  [cs.IT]  23 Jan 2024though we start off with cyclic schedulers, due to packet drops,the actual schedule of successful transmissions will no longerbehave according to the constructed schedule. Hence, AoIcomputation is a difficult task even for two sources.To summarize our contributions:•We provide a Markov chain based formulation to computethe weighted AoI for two heterogeneous sources follow-ing a cyclic schedule in the presence of packet drops,which could also be extended to any number of sources.•We provide an algorithm to produce cyclic schedulerswhich we prove to be near-optimal, i.e., given any ϵ >0,we can find a cyclic schedule whose weighted AoI iswithin ϵof the actual optimum.II. S YSTEM MODELConsider a communication system (shown in Fig. 1) con-sisting of two heterogeneous sources which provide statusupdates to a remote monitor through a shared random delay(or random service time) channel with packet drops where thetwo sources are scheduled according to a cyclic pattern. Oncethe transmitter has finished transmitting the current sample, itwill immediately sample from the next source in the scheduleand start transmitting this new sample. The information onwhether the transmitted packet is dropped at the channel ornot, is not available to the transmitter as in [13].Let the two sources be denoted as S1andS2with thechannel service times of the two sources given by the randomvariables XandYwith means s1,s2and variances v1,v2,respectively. Let the packet drop probability of the two sourcesbepandq. Let us denote by u, the cycle length and byu1, the number of instances of S1within the cycle. Then,u2=u−u1is the number of scheduling instances for S2.Letr={r1, r2, . . . , r u1}represent the placement vector ofthe schedule with respect to S1, where riis the number ofS2scheduling instances between the ith and the (i+ 1) thscheduling instances of S1. Then, (u, u 1,r)represents anycyclic schedule o\n",
      "----------------------------------------------------------------------------------------------------\n",
      "d swap the order ofmodels (V oorhees and Tice, 2000). However, froma training perspective, having the right objectivestill matters: keeping models, data, and testevalua-tion fixed, you can still improve test evaluation byimproving the training evaluation metric (Si et al.,2021).We focus on the answer evaluation ( AE) task:given a set of gold answers, is the output of a sys-tem equivalent to one of the gold answers? Thestandard AEevaluations of QAare Exact Match(EM)– evaluates QAsystems’ ability to extract aspecific span of text given a passage and a ques-tion, token level F1match– measures the averageoverlap between the prediction and ground truthanswer, ROUGE score (Lin, 2004)– measures theoverlap of n-grams between the system’s outputand a set of reference summaries, METEOR score–evaluates machine translation output and has stem-ming and synonymy matching features not presentin other metrics (Banerjee and Lavie, 2005). Whilethese standard AEevaluation methods work okayon the most common QAevaluations, we argue inSection 2 that they stumble on the long-tail of QAexamples because they lack the depth of seman-tic understanding of the contexts of the questionsand answers that humans use when adjudicatinganswers.Fortunately, we are not starting from scratch!We draw on rules for adjudicating human ques-tion answering competitions, studying and adopt-ing standardized AEguidelines from National Aca-demic Quiz Tournaments ( NAQT ) (National Aca-demic Quiz Tournaments, LLC, 2024), A Jeopardy!‘Case Book’ (Carberry, 2019) and the efficient QAcompetition (Min et al., 2021) to define acceptableanswers for machine QAand expand the long-tailof automated QAevaluation in Section 3.1. We usea large language models ( LLM)—GPT-4(Bubecket al., 2023)—to generate and self-verify AEexam-ples according to our AEguidelines.This broader view of AEis more necessary thanever because generative AIis often more creativearXiv:2401.13170v1  [cs.CL]  24 Jan 2024with their answers (Zhu et al., 2021). For ex-ample, e.g., GPT-series models (Bubeck et al.,2023), LLAMA 2 (Touvron et al., 2023) go be-yond extracting exact answers from retrieved pas-sages, such as Dense Retriever-Reader ( DPR) mod-els (Karpukhin et al., 2020) and generate more free-formed answers, with more variability than a set ofgiven reference answers. Creative answers oftenmake automated AEevaluations more challenging.For example, section 5.2 shows that out of 250 se-lected AEexamples, around 90% of the exampleshave correct candidate answers missing from thereference answer sets, which are equivalent underhuman judgment but not equivalent when usingstring exact match.However, we recognize that one of the reasonsthat exact match ( EM) is so popular is because itis simple, fast, and requires minimun setup andcomputation resources comparing to rising popu-larity of LLM-based evaluation methods (Kamallooet al., 2023a). Thus Section 3.3 proposes CFMatch ,which combines standard evaluation methods – F1– with a very simple discrimative logistic regression(LR) classifier and trains it on our augmented AEdataset to distill more complicated models to a fast,small, easy to run deterministic classifier that iscompetitive with our LLM approach. Our classifier,less than 1 MB in size, is tested on a challengeexpert QA set involving expert adjudications of AEthat requires a regular person’s years of experienceto get right. It achieves the best AEalignmentswith expert judgments without access to additionalonline or retrieved knowledge, followed by BERT -based method trained on our augmented AEdatasetthen other standard evaluation methods.In addition, We conduct further human eval-uation to show that CFMatch reduces commonjudgement errors present in current evaluation met-rics and is comparable with Muppet Model (trans-former architecture models)-based matching meth-ods, and more closely aligned and generalized withour AErules. We also demonstrate the advantage ofaugmenting AEtraining data can improve both ourclassifier and Muppet Models’ ability to detect AE.We release a python package specifically for QAevaluation that includes EM,F1socre, CFMatch ,fine-tuned BERT matching (download optional) forresearchers to access popular and robust QAevalu-ation metrics.11https://github.com/zli12321/qa_metrics.git2 Limitations of Current EvaluationMethodsIn this section, we first review the current state anddefinition of AEin machine QAdomain. Then weconduct our initial error analysis of current popu-larQAevaluation methods— EM,F1,BEM (Bulianet al., 2022)—on the benchmark Reading Compre-hension with Commonsense Reasoning (ROPES)devdataset (Lin et al., 2019), and we show the pit-falls of current evaluation methods. We specificallypresent annotated examples to show the lack ofgeneralization of these evaluation methods on out-of-distribution ( OOD) datasets. especially for BERT -based methods trained on AEdata generated onlyfrom the Stanford Question Answering Dataset (Ra-jpurkar et al., 2016).2.1 Definiti\n",
      "----------------------------------------------------------------------------------------------------\n",
      "el goals (“keep the kitchenclean”), formulate plans for addressing these goals, and then carry out those plans with the skillsand resources available to them. While current robotic learning methods offer appealing solutionsfor acquiring individual robotic skills, and large language models (LLMs), vision-language models(VLMs) and large multimodal models offer the ability to reason over such abstract tasks (Ahn et al.,2022; Rana et al., 2023), truly open-ended tasks still present major challenges. Performing innumer-able number of tasks in diverse settings requires a grounded and generalist agent that can robustlyadapt to scenarios outside where robots are trained. The bottleneck for achieving these goals, how-ever, is the need for large amounts of robotic experience in the real world – much larger than robotdatasets collected in lab settings with well-defined environments.In this paper, we study how we can design agents to gather robotic experience for themselves atscale. Central to our work is leveraging knowledge contained in foundation models to drive real-world robots. We specifically focus on diverse robotic data acquisition: when a robot is placed in anew environment, potentially with a user command to collect data around some theme (e.g. officeAuthors in alphabetical order, contributions listed in Author ContributionsWebsite: https://auto-rt.github.io/Corresponding emails: {keerthanapg, alexirpan }@google.com. Equal contribution.1arXiv:2401.12963v1  [cs.RO]  23 Jan 2024tasks), the robot should determine which tasks can be performed, which of its own skills to triggerto attempt them, and when it should rely on human teleoperators. We view this from the perspectiveof controlling a fleet of robots, spread across multiple locations, where there are many more robotsthan human supervisors, necessitating mixing expert demonstrations with suboptimal autonomouspolicies in a safe and appropriate way. Our system for large-scale orchestration of robotic agents,which we call AutoRT, tackles this problem.At the core of AutoRT is an large foundation model that acts as a robot orchestrator , prescribingappropriate tasks to one or more robots in an environment based on the user’s prompt and environ-mental affordances (“task proposals”) discovered from visual observations. The scene descriptionstep perceive objects in the environment, the task proposal step suggests possible things the robotcould do with them, and then the affordance filtering step decides which tasks to attempt and howbased on these observations and prompt. This process takes into account constraints specified via“constitutional prompting”, where rules about robot behaviour can be defined by the user. It ad-ditionally accounts for the availability of human teleoperators, and handles working around thecapabilities of the robot (e.g., the robot can pick up a cup but not a table, it can approach the sinkbut can’t sit in a chair, etc.).We describe the AutoRT system, instantiate it with a fleet of real-world mobile manipulators, andpresent the results of an extensive real-world evaluation over 7 months, 4 different office buildings,and a fleet of over 20 robots, which resulted in the collection of 77,000 real-world robotic trialswith both teleoperation and autonomous execution. AutoRT is, to the best of our knowledge, thefirst system where LLM-controlled robots are allowed to drive autonomously in real world settings,propose their own goals, and take actions toward those goals. We show that AutoRT scales robotdeployment by allowing 1 human to supervise 3-5 mobile manipulators. Our evaluation studies howAutoRT can collect highly diverse data, be instructed to collect task appropriate data and shows suchdata can be used to improve state-of-the-art robot learning models. AutoRT also introduces aligningrobot behavior to human preferences using prompting and critiquing with a robot constitution.2 R ELATED WORKReal robot data collection. Large scale real robot data collection for robotic manipulation fallsinto mainly two categories: autonomous data collection and human assisted demonstrations. Au-tonomous data collection in prior works is often conducted in constrained robot lab environments,on tasks like grasping (Pinto & Gupta, 2015; Levine et al., 2016; Kalashnikov et al., 2018; Platt,2022), pushing (Yu et al., 2016; Ebert et al., 2018; Dasari et al., 2020), or pick and place (Kalash-nikov et al., 2021; Bousmalis et al., 2023). Our work focuses on tackling more varied environments,similar to Gupta et al. (2018), and tackling a wider set of tasks. Human demonstrated data collectioncan be done in varied environments (Sharma et al., 2018; Mandlekar et al., 2019; Jang et al., 2021;Brohan et al., 2022), and teleoperated data can be far more diverse and valuable for skill learningthan autonomously collected data, but is bottlenecked by availability of humans when scaling tomany robots. This motivates hybrid approaches that mix teleoperation and autonomous policies,\n",
      "----------------------------------------------------------------------------------------------------\n",
      ".com/AI4Science-WestlakeU/cindm .1 I NTRODUCTIONThe problem of inverse design – finding a set of high-dimensional design parameters (e.g., boundaryand initial conditions) for a system to optimize a set of specified objectives and constraints, occursacross many engineering domains such as mechanical, materials, and aerospace engineering, withimportant applications such as jet engine design (Athanasopoulos et al., 2009), nanophotonic design(Molesky et al., 2018), shape design for underwater robots (Saghafi & Lavimi, 2020), and batterydesign (Bhowmik et al., 2019). Such inverse design problems are extremely challenging since theytypically involve simulating the full trajectory of complicated physical dynamics as an inner loop,have high-dimensional design space, and require out-of-distribution test-time generalization.Recent deep learning has made promising progress for inverse design. A notable work is by Allenet al. (2022), which addresses inverse design by first learning a neural surrogate model to approx-imate the forward physical dynamics, and then performing backpropagation through the full sim-ulation trajectory to optimize the design parameters such as the boundary shape. Compared withstandard sampling-based optimization methods with classical simulators, it shows comparable andsometimes better performance, establishing deep learning as a viable technique for inverse design.However, an underlying issue with backpropagation with surrogate models is over-optimization – aslearned models have adversarial minima, excessive optimization with respect to a learned forwardmodel leads to adversarial design parameters which lead to poor performance (Zhao et al., 2022).∗Equal contribution.†Corresponding author.1arXiv:2401.13171v1  [cs.LG]  24 Jan 2024Published as a conference paper at ICLR 2024More time stepsMore interacting bodiesLearn!!(#)fromobserveddata!!...!\"!\"#$...!%∇\"!!(##)!\"#+$\"(#)DesignobjectiveEnergy function&=(($,*)Boundary+[$,']Trajectory⊕#=&⊕+[$,'](*)⊕+$,'(,)...&*+[$,']⊕...&,Part to wholeformultipleboundaries !&Designvariable!Sharedtrajectorystatestatestate!!state...+[$,,']TrainCompositionalDesignFigure 1: CinDM schematic. By composing generative models specified over subsets of inputs, wepresent an approach which design materials significantly more complex than those seen at training.A root cause of this is that the forward model does not have a measure of data likelihood and doesnot know which design parameters are in or out of the training distribution it has seen, allowingoptimization to easily fall out-of-distribution of the design parameters seen during training.To address this issue, we view the inverse design problem from an energy optimization perspective,where constraints of the simulation model are implicitly captured through the generative energyfunction of a diffusion model trained with design parameters and simulator outputs. Designingparameters subject to constraints corresponds to optimizing for design parameters that minimizethe energy of both the generative energy function and associated design objective functions. Thegenerative energy function prevents design parameters from deviating and falling out of distribution.An essential aspect of inverse design is the ability to further construct new structures subjects to dif-ferent constraints at test-time. By formulating inverse design as optimizing generative energy func-tion trained on existing designs, a na ¨ıve issue is that it constrains design parameters to be roughlythose seen in the training data. We circumvent this issue by using a set of generative energy func-tions, where each generative model captures a subset of design parameters governing the system.Each individual generative energy function ensures that designs do not locally fall out of distribu-tion, with their composition ensuring that inferred design parameters are roughly “locally” in distri-bution. Simultaneously, designs from this compositional set of generative energy functions may besignificantly different from the training data, as designs are not constrained to globally follow theobserved data (Liu et al., 2022; Du et al., 2023), achieving compositional generalization in design.We illustrate the promise of using such compositional energy functions across a variety of differentsettings. We illustrate that temporally composing multiple compositional energy functions, we maydesign sequences of outputs that are significantly longer than the ones seen in training. Similarly, wecan design systems with many more objects and more complex shapes than those seen in training.Concretely, we contribute the following: (1)We propose a novel formulation for inverse design asan energy optimization problem. (2)We introduce Compositional Inverse Design with DiffusionModels (CinDM) method, which enables us to generalize to out-of-distribution and more complexdesign inputs than seen in training. (3)We present a set of benchmarks for inverse design in 1Dand 2D. Our method outperforms \n",
      "----------------------------------------------------------------------------------------------------\n",
      ", augmented reality, legibilityPermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from permissions@acm.org.HRI ’24, March 11–14, 2024, Boulder, CO, USA©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0322-5/24/03. . . $15.00https://doi.org/10.1145/3610977.3635003ACM Reference Format:Yi-Shiuan Tung, Matthew B. Luebbers, Alessandro Roncone, and BradleyHayes. 2024. Workspace Optimization Techniques to Improve Predictionof Human Motion During Human-Robot Collaboration. In Proceedings ofthe 2024 ACM/IEEE International Conference on Human-Robot Interaction(HRI ’24), March 11–14, 2024, Boulder, CO, USA. ACM, New York, NY, USA,11 pages. https://doi.org/10.1145/3610977.3635003Figure 1: Workspace configuration affects the robot’s abilityto correctly predict the human’s goal – the blue square cube.Left: The legible path (dotted) requires the human to take acircuitous route while the natural path (solid) is not legible.Right: Our approach generates a workspace configuration byarranging physical objects and projecting “virtual obstacles”in AR (cyan and red barriers), in order to induce naturallylegible paths from the human.1 INTRODUCTIONIn human-robot collaborative tasks, shared mental models betweenagents enable the awareness and joint understanding required foreffective teamwork [ 32]. With no shared notion of the task tobe completed, the inherent stochasticity and opacity of humandecision-making makes robot planning difficult [ 30]. To this end,prior research efforts have focused on developing robots that canpredict human behavior [ 15,19,29], generating motion plans tosafely interact in a shared environment [ 11,26]. However, thesemethods are limited by the quality of robot predictions of a humancollaborator’s intention and resultant behavior. With inaccuratehuman models or unexpected human behavior diverging from pastarXiv:2401.12965v1  [cs.RO]  23 Jan 2024HRI ’24, March 11–14, 2024, Boulder, CO, USA Yi-Shiuan Tung, Matthew B. Luebbers, Alessandro Roncone, & Bradley HayesFigure 2: Our approach for generating workspace configurations that enable accurate human goal predictions. (1) In theinitialization phase, we sample random environment layouts to populate the behavior performance map, which stores diverseand high performing solutions. This is followed by the improvement phase where we sample directly from the map and addperturbations to test whether the legibility is improved. (2) In both phases, we compute the legibility of the sampled layout bycomputing the probability of predicting the correct goal at each stage of the task execution. (3) We compute the features of thesampled layout to determine its location in the map. (4) The map is updated if the legibility score of the sampled layout isbetter than the existing one.experiences, the robot may produce unsafe interactions [ 20], espe-cially in safety-critical or close-proximity settings [36].To address the inherent challenges of accurately predicting hu-man motion early in a demonstrated trajectory, our key insight isthat robots can take an active role in structuring the environmentto reduce the variance of human motion caused by dense and over-lapping task spaces, thereby improving the performance of humanbehavior models. In this work (see Fig. 1), we introduce an algo-rithmic approach for a robot to configure a shared human-robotworkspace prior to interaction in order to improve a robot’s abilityto predict the human collaborator’s goals during task execution.As detailed in Fig. 2, we present an objective function that scorespotential workspace configurations in terms of how legible theactions of a human teammate are likely to be when performing atask in that environment. We use the mathematical formulation oflegibility from [ 5], which computes the probability of successfullypredicting an agent’s goal given an observation of a snippet of itstrajectory. Our approach finds workspace configurations that maxi-mize legibility over the valid goals at each stage of task execution.Each candidate workspace configuration combines a potentialarrangement of physical objects and projection of “virtual obstacles”in augmented reality (AR) in the environment. While the arrange-ment of physical objects can be achieved prior to the shared taskvia a simple composition of robotic pick and place actions, the ad-dition of augmented reality-based virtual obstacles is particularlyeffective in imposing explicit constraints on the possible m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "comparison between ADMap and baseline,ADMap effectively mitigates the point-order jitter problem.[3, 21, 8, 10] predicted dense ground information, whichresulted in redundancy in model computation and annota-tion. HDMapNet [9] groups dense pixel segmentation re-sults into sparse vectorized instances, but this requires acomplex post-processing process. VectorMapNet [14] pre-dicts vectorized instances for the first time, using an autore-gressive decoder to predict the instance points in an orderedmanner. MapTR [12] predicts vectorised instances end-to-end and resolves feature ambiguities caused by differentpoint order directions effectively. MapTRv2 [13] adds de-coupled self-attention to capture intra-instance point rela-tions in parallel.As shown in Fig. 1, we observe that the predicted pointsin the instances tend to be inevitably jittered or shifted,causing the reconstructed instance vectors to become dis-torted or jagged, which seriously affects the quality and util-ity of the online high-precision maps.1arXiv:2401.13172v1  [cs.CV]  24 Jan 2024The incomplete interaction between instance points andmap topological information leads to inaccurate point pre-diction in existing models. This is due to the models notfully considering inter- and intra-instance interactions. Fur-thermore, using L1 loss alone for distance supervision doesnot effectively utilize the geometric relationship betweenpoint sequences to constrain the prediction process. To ad-dress this, the network must utilize the characteristics ofthe vector line segments between points to more finely con-strain the position of the point sequences.To address this issue, we propose the Anti-DisturbanceMap reconstruction framework (ADMap). ADMap utilisesMulti-Scale Perception Neck (MPN), Instance Interac-tive Attention (IIA) and Vector Direction Difference Loss(VDDL) to more accurately predict point-order topology.MPN enables the network to capture multi-scale fea-tures in the BEV map, improving the accuracy of recon-structing instances with significant size differences in thescene without increasing inference time. IIA flexibly en-codes instance-level and point-level information, feature in-teractions between instance embeddings further help thenetwork capture the relationships between point-level em-beddings, and more accurate point-level information makesthe reconstruction more accurate. VDDL models the asso-ciation between instance points and vector direction differ-ences, and uses vector direction differences as losses to con-strain the reconstruction process of point sequences moreprecisely. Additionally, the difference in real vector direc-tion is utilised to assign varying weights to the points in theinstances, ensuring that the model can more effectively cap-ture the rapidly changing map information in the scene.We validate the effectiveness of ADMap in nuScenesand Argoverse2. ADMap achieves leading performancein both nuScenes and Argoverse2 compared to existingreconstructed vectorized high-precision map models. InnuScenes, ADMap improved performance by 3.9% and5.4% in camera-only and multimodal frameworks, respec-tively, compared to the baseline. ADMapv2 not only re-duced inference latency but also improved baseline per-formance. ADMap also performed well in Argoverse2.ADMapv2 improves mAP by 68.7% while FPS maintaining13.9, demonstrating that ADMap is an efficient and high-precision framework for generating accurate and smoothmap topology in complex scenes.Contributions of this paper are summarized as follows:• End-to-end ADMap is proposed, which reconstructsmore stable vectorized HD maps.• MPN captures multi-scale information more pre-cisely without increasing computational resources, IIAachieves effective interaction between inter-instanceand intra-instance information to alleviate the problemof instance point position offset. VDDL models thevector direction difference and supervises the recon-struction process of point order position using topo-logical information.• ADMap enables real-time reconstruction of vectorizedHD maps and achieves top performance in both thenuScenes and Argoverse2 benchmarks.2. Related Work2.1. Lane detectionIn previous research, lane line detection was typicallyconsidered a standalone task. Information was gatheredthrough sensors such as cameras and lidar to identify andlocate lane lines. LaneNet [16] proposes a semantic seg-mentation of 2D lane lines and clusters them. 3D-LaneNet[5] is a pioneering work in the field of monocular 3D lanelines, which proposes a new type of dual-path structure thatimplements Inverse Perspective Mapping (IPM) projectionof features inside the network. GenLaneNet [6] optimizesthe anchor representation of 3D-LaneNet and uses the an-chor to predict 3D Lane in a more reliable coordinate sys-tem. PersFormer [2] proposes a unified framework for 2Dand 3D lane detection. The framework introduces trans-former into the spatial transformation module to improvethe robustness of features.2.2. HD map \n",
      "----------------------------------------------------------------------------------------------------\n",
      "oprogram. Radford et al. (2023); Shumailov et al. (2023) also find LLM-generated content is inferiorto human content and can contaminate foundation models’ training. Detecting and auditing thosemachine-generated text will thus be crucial to mitigate the potential downside of LLMs.A plethora of works have investigated detecting machine-generated content (Sadasivan et al., 2023).Early methods, including Bakhtin et al. (2019); Fagni et al. (2021); Gehrmann et al. (2019); Ip-polito et al. (2019); Jawahar et al. (2020), were effective before the emergence of sophisticated GPTmodels, yet the recent LLMs have made traditional heuristic-based detection methods increasinglyinadequate Verma et al. (2023); Gehrmann et al. (2019). Current techniques (Mitchell et al., 2023;Verma et al., 2023) rely on LLM’s numerical output metrics. Gehrmann et al. (2019); Ippolito et al.(2019); Solaiman et al. (2019) use token log probability. However, those features are not available inblack box models, including state-of-the-art ones (e.g., GPT-3.5 and GPT-4). Furthermore, the high-dimensional features employed by existing methods often include redundant and spurious attributes,leading the model to overfit to incorrect features.In this paper, we present Raidar, a simple and effective method for detecting machine-generatedtext by prompting LLMs to rewrite it. Similar to how humans prompt LLMs for coherent and high-quality text generation, our method uses rewriting prompts to gain additional contextual informationabout the input for more accurate detection.Our key hypothesis is that text from auto-regressive generative models retains a consistent structure,which another such model will likely to also have a low loss and treat it as high quality. We observethat machine-generated text is less frequently altered upon rewriting compared to human-writtentext, regardless of the models used; see Figure 1 as an example. Our approach Raidar shows how1arXiv:2401.12970v1  [cs.CL]  23 Jan 2024Published as a conference paper at ICLR 2024Concise this for me and keep all the information:GPT-3.5-TurboHumanGPTOk yeah, the service can be a little high falutin', and the wait is painful but this is THE BEST BURGER EVER. That's all you need to know. The BEST.Despite the slightly pretentious service and long wait, this restaurant undeniably serves the best burger you will ever taste.Despite the pretentious service and long wait, this place serves the absolute best burger. That's all you need to know.Sen2: Despite pretentious service and long wait, this place serves the best burger you'll ever taste.Input: Yelp ReviewRewriting OutputDetecting Machine-Generated Text by Editing DistanceFigure 1: We introduce “Detecting via Rewriting,” an approach that detects machine-generated textby calculating rewriting modifications. We show the character deletion in red and the character inser-tion in orange. Human-generated text tends to trigger more modifications than machine-generatedtext when asked to be rewritten. Our method is simple and effective, requiring the least access toLLM while being robust to novel text input.to capitalize on this insight to create detectors for machine-generated text. Raidar operates on thesymbolic word output from LLMs, eliminating the need for deep neural network features, whichboosts its robustness, generalizability, and adaptability. By focusing on the character editing distancebetween the original and rewritten text, Raidar is semantically agnostic, reducing irrelevant andspurious correlations. This feature-agnostic design also allows for seamless integration with thelatest LLM models that only provide word output via API. Importantly, our detector does not requirethe original generating model, allowing model A to detect the output of model B.Visualizations, empirical experiments show that our simple rewriting-based algorithm Raidar sig-nificantly improves detection for several established paragraph-level detection benchmarks. Raidaradvances the state-of-the-art detection methods (Verma et al., 2023; Mitchell et al., 2023) by upto 29 points. Our method generalizes to six different datasets and domains, and it is robust whendetecting text generated from different language models, such as Ada, Text-Davinci-002, Claude,and GPT-3.5, even though the model has never been trained on text generated from those models.In addition, our detection remains robust even when the text generation is aware of our detectionmechanism and uses tailored prompts to bypass our detection. Our data and code is available athttps://github.com/cvlab-columbia/RaidarLLMDetect.git .2 R ELATED WORKMachine Text Generation. Machine generated text has achieved high quality as model im-proves (Radford et al., 2019; Li et al., 2022; Zhou et al., 2023; Zhang et al., 2022; Gehrmann et al.,2019; Brown et al., 2020; Chowdhery et al., 2022). The release of ChatGPT enables instructionalfollowing text synthesis for the public Cha (2023). (Dou et al., 2021; Jawahar et al., 2020) de\n",
      "----------------------------------------------------------------------------------------------------\n",
      "due to the high computational costsand large memory requirements [41, 78]. To overcome thischallenge, knowledge distillation (KD) [30, 32, 76], a pop-ular model compression technology, has been widely usedto obtain satisfactory results with a small SS model ( i.e.,the student model) by emulating the behavior of a large SSmodel ( i.e., the teacher model) [45, 68].Despite the promising progress has been made by currentKD methods on SS [17, 25, 45, 68, 74, 87], these methodsprimarily rely on coarse general knowledge ( e.g., featuresand logits) and neglect the specific feature understandingover the object boundary and connecting regions [62, 87].Particularly, since small student models can often segmentthe main object regions fairly well but fail in boundary andconnecting regions [6, 24, 82], the conventional utilizationof coarse general KD may not be effective enough and canbe considered purposeless and redundant [25, 74, 88, 92],remaining a performance gap between the obtained resultsand the expected results [17, 63, 75]. As illustrated in Fig-ure 1, the small student model (PSPNet-18 [93]) in (c) pro-duces inferior results compared to the large teacher model(PSPNet-101 [93]) results in (b). The small model wronglysegments the boundary regions of “curtain” and“door” asthe background category or other foreground objects, andproduces fragmented “bed valance” and“chair” , breakingthe regional relation connectivity. In general, the errors thatoccur in the results of small models can be summarized asmaintaining boundary region completeness andpreservingtarget region connectivity .To address these problems and bridge the performancegap in SS, we propose a simple and clean KD strategy:boundary and relation distillation (BRD). BRD consists ofboundary distillation andrelation distillation , which are de-signed to address the common errors faced by small studentmodels in maintaining boundary region completeness andpreserving target region connectivity, respectively. Specifi-cally, the boundary distillation synthesizes explicit objectboundaries from the hierarchical backbone feature maps(ref.Sec. 4.2), thereby enhancing the completeness of thestudent’s masks in the boundary regions. At the same time,therelation distillation transfers implicit relation informa-tion from the teacher model to the student model usingpixel-level self-relation as a bridge ( ref.Sec. 4.3), ensuringthat the student’s masks have strong target region connec-tivity. BRD is concretely designed for SS tasks. Comparedto the commonly used feature-based and logit-based KD,our proposed BRD features more targeted distillation con-tent and a more tailored distillation manner.arXiv:2401.13174v1  [cs.CV]  24 Jan 2024(a) Input Image (b) Large Model (c) Small Model (d) Small Model w/BRD (e) Ground -TruthFigure 1. Two representative scenarios that small models are prone to segmentation errors [93]. Result comparisons between large models(b) and small models (c) show that the latter tend to make errors in maintaining boundary region completeness ( e.g., the “curtain” andthe“door” ) and preserving foreground/background region connectivity ( e.g., the “bed valance” and the “chair” ), while both large andsmall models are capable of segmenting the main region of the object with satisfactory accuracy. With the help of our BRD in (d), smallmodels can address the two types of errors, leading to crisp region boundaries and smooth connecting regions. “ w/” denotes with thecorresponding implementation. The white dashed lines highlight the areas where our method achieves better results. Samples are from theADE20K dataset [100]. More visualization results will be given in the supplementary.To demonstrate the superior performance of our BRD,we conducted extensive experiments on several challengingSS datasets, i.e., Pascal VOC 2012 [21], Cityscapes [16],ADE20K [100], and COCO-Stuff 10K [5]. Qualitatively,BRD can generate crisp region boundaries and smooth con-necting regions that were previously challenging for smallSS models. Quantitatively, BRD consistently boosts base-line models’ accuracy, ultimately achieving very competi-tive accuracy without increasing the inference costs.The main contributions are the following three-fold:• It is observed that small SS models are prone to segmenta-tion errors in maintaining boundary region completenessand preserving target region connectivity;• We proposed a targeted KD strategy for SS, boundary dis-tillation andrelation distillation , to address the represen-tative errors faced by small models;• Experimental results on various baselines and datasetsdemonstrate the superior performance of our BRD overexisting methods, achieving very competitive results.2. Related WorkSemantic Segmentation (SS). SS aims at assigning eachpixel in an input image to a specific category label ( e.g.,“desk”, “pedestrian”, and “car”), enabling a pixel-level se-mantic recognition of the given image [48, 79, 86, 87, 89].The current SS architectures can be rou\n",
      "----------------------------------------------------------------------------------------------------\n",
      "s such as audio, sensor data, etc. from current and priorUnder reviewOpendoorTakeceleryPast Frames AnticipativeTime FutureAction?Observed UnobservedClosedoorClosedoorTakeTofuTakecontainerFigure 1: Anticipating actions τaseconds after observing informa-tion for τoseconds using multiple modalities.observations, as displayed in Figure 1. Predicting future ac-tions is important for many Artificial Intelligence (AI) ap-plications such as autonomous driving [Jain et al. , 2015;Rasouli et al. , 2020 ], assistive robotics [Petkovi ´cet al. , 2019;Koppula and Saxena, 2015; Korbar et al. , 2018 ], augmentedreality, etc. For instance, a kitchen robot can preemptivelychop onions and hand them over if it can anticipate that therecipe requires chopped onions to be added next.This task, although seemingly straightforward for humans,is a challenging task for deep networks due to uncertaintyof predicting the future, and large variability in the actionsthe models have to learn. Models not only have to de-tect the action happening at the observed time, but alsofuse information from all available modalities to anticipatefuture actions. To formalize this task, challenging large-scale datasets such as Epic-Kitchens and Ego-4D [Damenet al. , 2018; Damen et al. , 2020; Grauman et al. , 2022;Stein and McKenna, 2013 ]have been developed, along withaccompanying benchmarks, challenges, and leaderboards forstate-of-the-art methods, for action anticipation, action recog-nition, action detection etc.Typically, short- and long-term action anticipation in-volves extracting frame level features from videos and ag-gregating them using either temporal recurrent [Furnari andFarinella, 2019; Furnari and Farinella, 2020 ]and attentionmodules [Girdhar and Grauman, 2021; Zhong et al. , 2023 ], ordirectly extracting video level features using attention [Gird-har and Grauman, 2021; Wu et al. , 2022; Roy and Fernando,2023; Roy and Fernando, 2021 ]. Although previous framescan be automatically ‘attended’ to, action anticipation us-ing only videos–a single modality–still remains challenging,arXiv:2401.12972v1  [cs.CV]  23 Jan 2024and the availability of additional and complementary modal-ities is typically advantageous [Girdhar and Grauman, 2021;Zhong et al. , 2023 ]. For example, if an assistive robot is per-forming a task with camera pointed away from the person,and the person falls, the robot should still be able to reactin a timely manner ifaudio is being used as an additionalmodality. Such scenarios demonstrate that information frommultiple modalities can aid in many tasks, including actionanticipation. Accordingly, recent works [Zhong et al. , 2023;Girdhar and Grauman, 2021; Thakur et al. , 2023 ]have shownthat action anticipation greatly benefits from multi-modaltraining, as well as knowledge from other visual and au-dio cues such as active object detection, self-supervised fu-ture feature prediction, speech recognition, and hand-objectcontact information, typically by using modality specific en-coders. Further, contrastive pre-training has also been em-ployed for multi-modal setups, by aligning with text, e.g.,CLIP [Radford et al. , 2021 ]and other foundation models[Girdhar et al. , 2022; Girdhar et al. , 2023; Wu et al. , 2022;Niet al. , 2022 ]. In contrast, we examine the necessity fortraining such modality-specific encoders , and, instead aim todetermine if natural language descriptions are effective foraction anticipation. Therefore, we leverage language modelsto generate features by encoding object and actions in text,in lieu of relying on traditional feature extracting methods.Further, we also study which modalities are more beneficialand inspect how the accuracy of action recognition for theobserved frames affects anticipation.In this paper, we present ‘Multi-Modal Anticipative Trans-former (MAT)’ that utilizes contrastive pre-training for gen-erated captions from actions for videos. As Large LanguageModels (LLMs) are adept in giving long descriptions whenprompted, we utilize this feature to generate long descriptionsfor actions that often involve additional knowledge on the en-vironment and objects, e.g., kitchen vs living room, utensilsused etc., allowing MAT to encode this knowledge aiding inaction anticipation. We employ a two-stage network that firstlearns to recognize actions by contrasting fused features frommultiple modalities against text, and subsequently predictingfuture actions. The first stage utilizes a CLIP-like frame-work which contrasts visual embeddings fused from multi-ple modalities against text embeddings, enabling our modelto learn more descriptions for actions generated through GPTmodels. In the second stage, these fused features are thenused to anticipate actions by training a classifier.In summary, our contributions are:• We propose a novel training protocol for predictivevideo modeling by contrasting modality features againstaction descriptions generated using LLMs.• We propose and analyze using modalities in te\n",
      "----------------------------------------------------------------------------------------------------\n",
      "-consuming, computationally expensive, and has a significantcarbon footprint [1] [2] [3]. Consequently, practitioners areincreasingly reusing and adapting Pre-Trained Models (PTMs)to their use cases instead of training new models from scratch.Pre-training Deep Learning (DL) models with huge amountsof data was first successfully applied to computer vision [4] [5]and NLP tasks [6], but in recent years, PTMs have showcasedexceptional performance across language understanding andgeneration tasks, often surpassing human-level results [7].These successes and progress in the NLP community haveshifted the spotlight of AI research towards large-scale PTMsThis work was supported by: Fonds de Recherche du Qu ´ebec (FRQ), theCanadian Institute for Advanced Research (CIFAR) as well as the DEELproject CRDPJ 537462-18 funded by the Natural Sciences and EngineeringResearch Council of Canada (NSERC) and the Consortium for Research andInnovation in Aerospace in Qu ´ebec (CRIAQ), together with its industrialpartners Thales Canada inc, Bell Textron Canada Limited, CAE inc andBombardier inc.[7]. PTMs are also extensively used by Software Engineering(SE) researchers [8] [9] [10] and developers [11].Following this surge in model reuse, and to facilitate itsusage, “Model Hubs” have been created. Model hubs areplatforms that host collections of PTMs and/or datasets thathave been curated and categorized to be easily reused by users[1]. HuggingFace (HF) Hub is the biggest model hub on theinternet [12] with more than 371K models as of October 2023[13].Recent studies have investigated challenges, bugs, and is-sues that arise when reusing PTMs from the model hubs [12][14] [15], but their scope have been limited. Moreover, thereis a lack of a comprehensive view of how the communityleverages and affects PTMs reuse. Hence, in this study, weempirically examine how the HF community reuses PTMby analyzing discussions in the HF Forums [16], the mainplatform used by the HF community for discussing a widerange of topics and concerns. Using a mixed-methods ap-proach, we perform a large-scale study on the challenges,benefits, and trends in PTM reuse. First, we mine and performqualitative analysis on the HF forums’ discussion threads tounderstand the challenges that users face in reusing PTMsand the potential benefits that the community brings to PTMreuse. Next, we quantitatively investigate and compare thedistribution of the types of models being discussed by thecommunity and those uploaded and available on the hub toidentify trends in PTMs reuse within the community. Theoverview of our methodology is shown in Figure 1.To guide our investigation, we define three Research Ques-tions (RQ):RQ1. What challenges are associated with reusing PTMs in theHF community?RQ2. What are the benefits of the HF community for reusingPTMs?RQ3. What are the trends in PTM reuse within the HF com-munity?As a result of our qualitative analysis, we recognize 17categories (Table I) of challenges faced by the communitythat were further categorized into 47 subcategories. Amongthese, the challenges related to understanding models and theirfunctionalities ,requesting a complete solution for a specificuse case anddifficulty in interpreting the output of the model intraining or inference were the most prevalent challenges facedby the users which drastically hampers PTM reuse. On the1arXiv:2401.13177v1  [cs.SE]  24 Jan 2024Inductive/Deductive coding to reach saturation for 455   samples with 2 rounds of negotiated agreements HuggingFace Discussion Forums HuggingFace Model HubQuantitative analysis of the models mentioned on the Forums  Jul. 2020 → Jun. 2023 11,175 topics 34,019 posts Mined unstructured data Data preprocessing Categorization of core themes and constructs: challenges+benefits RQ1 & RQ2 Mined modelsʼ data All models on the Hub present in June  2023 239,422  models Extracting the relevant metadata of the models (model type, model card, ...) Quantitative analysis of the models on the hub RQ3 Qualitative Analysis Quantitative Analysis Random sampling with snowball eﬀect Confidence level: 95% Sample size: 372 Fig. 1. The mixed-methods methodology followed in the study.other hand, we also found 6 categories of benefits associatedwith the community for PTM reuse. Our findings highlightthe forums’ pivotal role in fostering collaborations amongdiverse stakeholders. The solutions provided by the experts,and various types of collaboration among users and experts foreffective problem-solving have also emerged as significant ad-vantages within the HF community. Our quantitative analysisresults not only confirm the previous findings [17] suggestingthat the model hubs are under-exploited, but also shows thatthe distribution of models provided on the HF model hub andthe models discussed by the HF community is similar, andBERT, some BERT-based models (DistilBERT, RoBERTa),GPT2, T5, and BART are among the most popular ones, withBERT being the most discussed and most uploaded model t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hard-wiringthese heads into recurrent and convolutional models improves performance not just on syntheticICLL, but natural language modeling—improving the perplexity of 340M-parameter models by upto 1.14 points (6.7%) on the SlimPajama dataset. Our results highlight the usefulness of in-contextformal language learning as a tool for understanding ICL in models of natural text.Figure 1: Transformers effectively learn to perform in-context language learning , but other model classes (includingLSTMs and especially models with time invariant transitions—i.e. efficient convolutional forms) struggle to do so.arXiv:2401.12973v1  [cs.CL]  23 Jan 2024In-Context Language Learning: Architectures and Algorithms1 IntroductionOne of the most striking features of modern neural language models is their capacity for in-context learning (ICL)—theability to infer a conditional or unconditional distribution over natural language strings simply by performing next-tokenprediction following a sequence of examples from the distribution of interest. ICL is a crucial tool for steering largepre-trained language models (LMs), and a growing body of work aims to understand when andhow these LMs performICL. Because of the complexity of large-scale LMs trained on natural language text (as well as the lack of publicinformation about many LMs’ training data), almost all work on understanding ICL has instead focused on smallerLMs trained on simple model problems like in-context linear regression (Garg et al., 2022), character classification(Chan et al., 2022), and associative recall (Dao et al., 2022). Despite their simplicity, these model problems have playeda key role in identifying properties (and limitations) of ICL in current LMs.However, there remains a significant gap between these model problems and the kinds of capabilities exhibited by LMstrained on large datasets of natural language text. In particular, most model problems require relatively simple forms oflearning: computing a fixed function of the entire training set (Akyürek et al., 2022, von Oswald et al., 2023a,b), orretrieving a single example relevant to the current input (Dao et al., 2022). In contrast, natural LMs exhibit richer andmuch more varied forms of ICL—in some cases producing structured generative models of text or code based on ahandful of inputs (Shin and Van Durme, 2022, Drozdov et al., 2022). This requires not just extracting a single summarystatistic or example, but instead modeling multiple conditional distributions and re-composing fragments of trainingexamples.How can we systematically study these more complex forms of ICL? In this paper, we introduce a new family of modelICL problems that we collectively term in-context language learning (ICLL) . In ICLL, LMs are prompted with afinite collection of strings from an unknown formal language, and must infer the distribution over strings correspondingto the full language (Figure 2). ICLL exercises essential features of ICL in natural models: it features structured outputs,probabilistic predictions, and compositional reasoning about input data. In this paper, we present a focused study ofICLL in regular languages —the class of formal languages generated by finite automata. During ICLL training, eachtraining example consists of a sequence of strings from the same language. Different examples feature strings fromdifferent languages, so learners must infer language-specific generative models on-the-fly to perform accurate sequencemodeling.We begin by providing general background about neural sequence models, ICL and formal languages in Section 2,then define the ICLL task in Section 3. Next, we explore three questions about in-context language learning in neuralsequence models:1Q1: Which model classes can learn to perform ICLL accurately? (Section 4)•We find that Transformers significantly outperform recurrent and convolutional LMs at in-context languagelearning, even when models perform comparably on other model ICL problems.• Models with efficient convolutional parameterizations perform especially poorly on ICLL tasks.Q2: What algorithmic solutions and circuits do successful in-context language learners implement? (Section 5)•Transformer predictions on ICLL with regular languages are well approximated by smoothed n-gram models.•Transformers trained for regular ICLL develop “n-gram heads”, higher-order variants of induction headspreviously described in LMs (Olsson et al., 2022).•Compared to other model architectures, Transformers better encode in-context n-gram counts in their hiddenrepresentations.Q3: Can we improve neural models using our understanding of how they perform ICLL? (Section 6)• Hard-wiring RNNs and convolutional models with n-gram heads improves their performance on ICLL.•These heads are not just useful for ICLL: when equipped with n-gram heads, neural sequence models of allclasses exhibit perplexity improvements of up to 6.7% on natural language modeling tasks.1Code and reference implementations ar\n",
      "----------------------------------------------------------------------------------------------------\n",
      "s in Large Language Models (LLMs) (OpenAI, 2023; Touvron et al., 2023) has demonstratedemergent agentic abilities that understand diverse environments and perform step-by-step planningthrough multi-round interactions (Yao et al., 2023; Song et al., 2023). The emergence of theseabilities amounts to the potential of LLMs as generalist agents for real-world problem-solving.A comprehensive evaluation of LLM agents is crucial for the progression of this emerging field. Tostart, task diversity is necessary to cover various agent tasks such as embodied, web, and tool agents.Additionally, mutli-round interaction is critical to mimic realistic scenarios, contrasting with thesingle-round tasks commonly adopted in existing benchmarks (Xu et al., 2023a; Lin & Chen, 2023;Qin et al., 2023a). Furthermore, evaluating agents in partially-observable environments – where theymust actively explore to understand their surroundings – is essential for practical assessments. Thisdiffers from the “pseudo” agent tasks (Wang et al., 2023b) derived from conventional benchmarks infully-observable environments, such as MMLU (Lanham et al., 2023) and MATH (Hendrycks et al.,2021). However, existing agent benchmarks rarely meet all these criteria.∗Equal Contribution. Individual contributions are detailed in Appendix A. Work done during visit toHKUST.1Code and data are available at https://github.com/hkust-nlp/AgentBoard.1arXiv:2401.13178v1  [cs.CL]  24 Jan 2024Preprint、AnalysisGoal: Find the exit…AgentMoveforward!EnvironmentOops! Thereisnoroadin front of you. Please choose another action.Progress Rate0.25InteractionTaskAgentBoardEnvironmentProgress1InteractionTaskAnalysis1333222WebWebShopWebArenaToolQueryOperationGameJerichoPDDLEmbodiedAIAlfWorldScienceWorldBabyAI02040608005101520ProgressRate w.r.t.StepGPT -4Cu rrent Run01020304050AllEasyHa rdSuccess Rate vs   Progress RateGPT- 4Claude 2GPT- 3.5-T urb oCurr ent Ru nMemoryPlanningSpatial NavigationGroundingWorldModelingSelf-ReflectionCapability ScoreLeaderboard020406080Cu rrent RunGPT -3. 5-T urboCl aud e2GPT -4Success RateProgress Rate1020304050Current RunGPT-3.5-TurboClaude2GPT-4GPT-4Claude2GPT-3.5-TurboCurrent RunProgress RateSuccess RateCurrent RunFigure 1: The illustrative overview of A GENT BOARD . AGENT BOARD consists of a diverse set of 9 tasks. InAGENT BOARD , agents interact with partially-observable environments through a multi-round way to achieveeach subgoal. Furthermore, A GENT BOARD provides an open-source analytical evaluation framework to diveinto the agents, this figure shows a subset of the included analyses.Moreover, the complexity inherent in agent tasks, characterized by multi-round interactions,decision-making based on long context, the achievement of various subgoals, distinguishes themsignificantly from other language tasks. Due to this complexity, there is a pressing need to delve intothe details and gain a deeper understanding of how models function during the process. Nonetheless,most current evaluations predominantly rely on the final success rate as their metric, which provideslimited insights into these intricate processes (Liu et al., 2023a; Wang et al., 2023b; Qin et al., 2023a;Yao et al., 2023; Liu et al., 2023b; Mialon et al., 2023b). Such simplified evaluation is particularlyinadequate in challenging environments where most models demonstrate nearly zero success rates,consequently blurring finer distinctions and obscuring underlying mechanisms (Liu et al., 2023a).Therefore, there is an urgent need for a more systematic and analytical evaluation.To this end, we introduce A GENT BOARD , a benchmark designed for multi-turn LLM agents, com-plemented by an analytical evaluation board for detailed model assessment beyond final successrates. A GENT BOARD encompasses a diverse set of 9 unique tasks and 1013 exemplary environ-ments, covering a range from embodied AI and game agents to web and tool agents. Each environ-ment, whether newly created or modified from pre-existing ones, is carefully crafted and authenti-cated by humans to ensure multi-round and partially observable characteristics in a unified manner.Notably, we have defined or manually annotated subgoals for each data sample, introducing a uni-fiedprogress rate metric for tracking the agents’ detailed advancements. As we will demonstratein §5.2, this metric uncovers significant progress in models that might otherwise appear trivial fromnegligible difference in success rates.Along with the benchmark, we develop the A GENT BOARD evaluation framework as an open-sourcetoolkit that features an analytical web panel to examine various dimensions of agent abilities throughinteractive visualization. This toolkit has a unified interface that is readily accessible and easily cus-tomizable for users. As partially shown in Figure 1, the A GENT BOARD panel currently supportsanalysis and visualization on fine-grained progress rates tracking, performance breakdown for hardand easy examples, detailed performance across\n",
      "----------------------------------------------------------------------------------------------------\n",
      " an ever-changing environment, robots are required to perceive changes in their surroundings, reason theunderlying mechanisms of these changes, and subsequently make decisions in response to them.To simulate a dynamic world, it is necessary to create environments that can spontaneously undergochanges. Currently, various simulation platforms have emerged in the field of embodied AI, includingiGibson (Shen et al., 2021), Habitat (Savva et al., 2019), SAPIEN (Xiang et al., 2020b), Virtual-Home (Puig et al., 2018), AI2THOR (Kolve et al., 2017), ThreeDWorld (TDW) (Gan et al.), etc.Existing tasks on these simulation platforms involve agent exploration and agent-driven interactions,but they lack support for environment-driven changes, which are rather influential and unpredictable.The iGibson 2.0 (Li et al.) platform partially supports spontaneous environmental changes to a limitedextent, but these changes are limited to the propagation of a few variables between individual objects.In this paper, we propose the HAZARD challenge, an innovative exploration of embodied decision-making in dynamic environments, by designing and implementing new capabilities for physicalsimulation and visual effects on top of the ThreeDWorld. HAZARD manifests itself in the form ofunexpected disasters, such as fires, floods, and wild winds, and requires agents to rescue valuableitems from these continuously evolving and perilous circumstances.The HAZARD challenge places agents within indoor or outdoor environments, compelling them todecipher disaster dynamics and construct an optimal rescue strategy. As illustrated in Figure 1, the˚Qinhong Zhou and Sunli Chen contribute equally.1arXiv:2401.12975v1  [cs.CV]  23 Jan 2024Published as a conference paper at ICLR 2024Flood !Fire \"Wind #TimelineHAZARD challengeFigure 1: Illustration of HAZARD Challenge. The HAZARD challenge consists of three dynamically changingscenarios: fire , flood , and wind . In the fire scenario, flames continuously spread and burn objects. In theflood scenario, water spreads and rises, washing away objects and causing damage to non-waterproof objects.The wind scenario poses the challenge of objects being blown away, making them hard to reach. These scenariospresent embodied agents with complex perception, reasoning, and planning challenges.scenarios vary in severity and complexity. An indoor fire scenario might involve the rapid spread offlames, threatening flammable target objects. In an indoor flood scenario, an overwhelming volume ofwater inundates the house, jeopardizing non-waterproof targets. In an outdoor wind scenario, strongwinds scatter lightweight objects across roads, making retrieval a challenging task for agents. Tosuccessfully rescue target objects from these disasters, agents must effectively transfer them to safezones such as backpacks or shopping carts.To facilitate this endeavor, we introduce a comprehensive benchmark comprising these disasterscenarios, complete with quantitative evaluation metrics. We also provide an API to employ largelanguage models (LLMs) for action selection. This API integrates visual observations and historicalmemories into textual descriptions, thereby providing a semantic understanding of the dynamicenvironment. To optimize the use of LLMs, we compress a large volume of low-level actions by A*algorithm, significantly reducing the frequency of LLM queries.We evaluate both LLM-based agents and several other decision-making pipelines on our benchmark,including a rule-based pipeline that operates based on a simple set of rules, a search-based pipelinethat utilizes the Monte Carlo tree search (MCTS) algorithm for action selection, and a reinforcementlearning-based pipeline. Through our experiments, we find while the LLM pipeline is capableof understanding and considering certain basic factors, such as object distance, it may encounterchallenges in comprehending and effectively handling more complex factors, such as the dynamicnature of environmental changes.The main contributions of our work are: 1) designing and implementing a new feature that enables thesimulation of complex fire, flood, and wind effects for both indoor and outdoor virtual environmentsin TDW; 2) developing a comprehensive benchmark, HAZARD, for evaluating embodied decision-making in dynamically changing environments, as well as incorporating the LLM API into ourbenchmark; and 3) conducting an in-depth analysis of the challenges posed by perception andreasoning for existing methods, especially LLM-based agents in tackling the proposed benchmark.2Published as a conference paper at ICLR 20242 R ELATED WORKSimulators for Embodied AI The recent advance of embodied AI has largely been driven by thedevelopment of simulation platforms. While earlier platforms primarily focused on supporting agentexploration (Savva et al., 2017; Beattie et al., 2016; Savva et al., 2019; Yi et al., 2018; Das et al.,2018), recent platforms (Gan et al.; Xiang et al., 2020a; Shen et al., 2021\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ODUCTIONInpredictivemodeling,thetaskisoftentoﬁndarelationfr omXtoY,wherebotharematriceswith Nrows,eachrepresentingasample.Eachsampleisassociatedwith Kpredictors,makingupthecolumnsof X,andMobservationsmakingupthecolumnsof Y.Insteadofdirectlyusing XandY,somemodelsuseoneorbothofthematrixproducts,XTXandXTY.Wepresentthreenovelalgorithmsforsubstantiallyspeedi ngupcross-validationrequiringthecomputationofXTXandXTYperdatasetpartition. XandYarematriceswith Nrows,eachrepresentingasample. XhasKcolumnsrepresentingpredictorsofthesamples,and YhasMcolumnsrepresentingobservationsofthesamples.Ouralgo -rithmsincludethepossibilityofusingthevariantsof XTXandXTYwhereXandYhavebeenmean-centeredandstandarddeviation-scaledonapertrainingsetbasis,avoi dingdataleakagefromthecorrespondingvalidationsets.Ouralgorithmsdonotrequirerecomputingthefull XTXandXTYforeachtrainingsetinthecross-validationscheme,nordotheyrequirerecomputationofthestatisticalmoment s.Ouralgorithmscanrapidlycomputepartition-wise,potent iallymean-centered,andoptionallysamplestandarddeviation-scaledXTXandXTY.Thesealgorithmsﬁndvaluableapplicationsacrossvariou sPLS-R[18,19]andPLS-DA[3]algorithms.Particularlynoteworthyistheirseamless integrationwiththeIKPLSalgorithms[6],knownfortheirspeed[1]andnumericalstability[2].Leveragingourcross -validationalgorithmswithIKPLSfacilitatesswifttestin gofdiversepreprocessingmethodswithinacondensedtimefr ame. Selectingtheoptimalpreprocessingtechniquerequiresmodelvalidation[14,16]andisimperativeforach ievingpeakperformance[7].Ouralgorithmshavethesameasymptoticruntimeof Θ(NK(K+M))asthecross-validationalgorithmproposedin[13]inthesimplecasewithnocolumn-wisepreprocessing andcolumn-wisemean-centeringcase.Inthecaseofcolumn-wisestandarddeviation-scaling,ouralgorithmre tainsthisruntimewhiletheoneproposedin[13]increasesi nruntime.Additionally,weusethetrainingsets’statistic almomentstoavoiddataleakagefromthevalidationsetswhe re[13]usesstatisticalmomentscomputedontheentiredatase t.Additionally,thespacecomplexityofouralgorithmsisasymptoticallylowerthan[13]byafactor PwherePisthenumberofcross-validationpartitions.Ouralgorith ms’runtimeandspacecomplexityareentirelyindependentofth enumberofcross-validationpartitions.Furthermore,weshowhowtoderivethesamplemeanandstandarddeviationoft hetrainingsetsfromthesamplemeanandstandarddeviationoftheentiredatasetwithoutrequiringfullreco mputation.Webeginwithacomparisonbetweenourownandrelatedworkin Section2followedbyincrementalintroduc-tionsandanalysesofouralgorithmsandthenaivealternati vesinSection3,Section4,andSection5,areferencetoanopen-sourceparallelimplementationofallouralgorith msinSection6,andaconclusionofourcontributionsinSection7.2|RELATEDWORKSeveralrelatedworksineﬃcientcross-validationexist.T hemostrelevant,perhaps,istheopensourceimplementatio n[8]ofallcombinationsofallouralgorithmsandbothIKPLSAl gorithm1andIKPLSAlgorithm2[6].Theopen-sourceimplementationalsohandlesmultiprocessingforparallel izationofthecross-validation.ItiselaborateduponinSe c-tion6.Theprimary,recurringideabehindallouralgorithmsistha tmatrixproductsXTXandXTYcanbecomputedonceusingallsamples.Then,foreachcross-validationpartiti on,weremovethecontributionofthevalidationset.Thesameideagoesbehindthecomputationofstatisticalmoment s.Theideabehindcomputing XTXandXTYfortheEngstrøm 3validationpartonlycanbetracedbackto[12]withimprovem entsby[13].Here,however,[13]usesthedataset-widestandarddeviationforscaling.Thus,ifonewishestouseth eapproachpresentedby[13]toscalebyonlythetrainingsetstandarddeviation,thenrecomputingthestandarddevi ationforeachtrainingsetisrequired.However,thishasdevastatingeﬀectsonthetimecomplexity,asevidencedbyP roposition5.10.Furthermore,althoughtheapproachin[13]hasmanysimilaritieswithours,thescalingbythestan darddeviationisdoneonapercross-validationpartitionbasisbymatrixmultiplicationrequiringanadditional Θ(PK3)operationstoscale XTXandΘ(PKM2)operationstoscaleXTY.Theinterestedreaderisreferredtoequation(33)in[13]t oseewhythisistrue.Likeouralgorithms,thealgorithmin[17]computes XTXandXTYfortheentiredataset,andthen,foreachcross-validationpartition,theysubtractthecontributionofth evalidationset,leavingthemwiththetrainingset.Thedif -ferenceisthattheyremovefeatures(columns)of Xwhileweremovesamples(rows)of XandY.Althoughwedrewinspirationfrom[17],ouralgorithmisvastlydiﬀerent.Inthesamespiritasours,[11]showshowtocomputetraining set-wiseXXTfromthedataset-wise XXT.Theyalsoshowhowtoderiveitbasedonthecentered X.Theircross-validationalgorithmishelpfulforPLSalgor ithmsthatuseXXT.However,asdatasetsgroweverlarger, XXTwillbemuchlargerthan XTX,thesizeoftheﬁrstbeingquadraticinthedatasetsizeandthesizeofthelatterbeing completelyindependentofthedatasetsize.Additionally,[11]statesthatifscalingbythestandarddeviationisrequ ired,thenthedataset-wisestandarddeviationmustbeused ,orfullrecomputationmustbeperformed.Aspreviouslystat ed,ouralgorithmshandlescalingbythetrainingset-wisestandarddeviationwithoutfullyrecomputingmatrixprodu ctsorstatisticalmoments.InTable1,weshowa\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wsfor highly realistic relighting and object insertion.1. IntroductionPhysically-based inverse rendering enables the reconstruc-tion of realistic material properties and lighting informationof a scene from multiple input images. Such a decompositionis useful for various applications, including relighting, mate-rial editing, and realistic object insertion. However, existinginverse rendering methods typically require input images toretain the high dynamic range (HDR) of the scene’s lighttransport. This poses a significant barrier to wide adoptionand applicability, as HDR capture requires special hardwareor merging multiple aligned LDR images via exposure brack-eting [34].Most common imaging sensors do not capture sufficientdynamic range for scenes’ light-emitting and non-emittingparts. Moreover, camera software often converts raw sen-sor readings to 8-bit low-dynamic-range (LDR) images forstorage and transmission. The non-linear mapping and quan-tization lead to the additional loss of lighting information.The complex light transport in indoor environments makes iteven more challenging to reconstruct the original HDR light-ing, which is critical for faithful inverse rendering. Enablingmaterial and lighting estimation from a “casual” capture,e.g., using your own camera or phone, would make inverserendering much more accessible to users.While many state-of-the-art inverse rendering methods1arXiv:2401.12977v1  [cs.CV]  23 Jan 2024expect HDR inputs, some attempt to overcome this issueby taking LDR images as inputs and solving for the lightingwith physically-based rendering. However, these methodsoften assume infinite far-away lighting [ 40], or requireadditional inputs, such as emitter masks [ 52]. While theseassumptions may be acceptable for object-centric or outdoorscenes, these methods cannot handle the complex lighttransport of indoor scenes. Others use single-image inputwith a learned prior [ 25,39], which cannot reconstructhigh-quality full indoor scenes. On the other hand, multipleapproaches [ 2,38,51] decompose radiance fields into mate-rials and lighting from LDR input. However, most focus onobject-centric scenes, and scene-level relighting and objectinsertion in those neural representations remain non-trivial.We propose an inverse rendering method for indoorscenes with spatially varying illumination from multi-viewLDR images with unknown varying exposures. Our methodmodels tone mapping, i.e., the HDR-to-LDR conversion,so input LDR images can be consumed directly. We esti-mate spatially-varying HDR lighting via physically-basedrendering (PBR), and optimize PBR material properties andthe camera response function (CRF). Estimating all threejointly, however, leads to unstable optimization due to theambiguities among lighting, albedo, and CRF. We designan optimization strategy that overcomes these ambiguitiesand enables high-quality estimation of all three. We compareour methods with several state-of-the-art inverse renderingmethods, including those taking HDR input.Our core contributions are:•We propose a method to faithfully estimate spatially-varying HDR lighting and accurate physically-based mate-rials from LDR input using physically-based rendering.•We explicitly model LDR image formation in our (inverse)rendering pipeline, such that LDR images can be useddirectly, with either constant or varying exposure settings.•Finally, we propose an optimization strategy to alternatelyoptimize the spatially varying HDR lighting, PBR materi-als, and the camera response function.2. Related WorkData-driven inverse rendering. Numerous methods em-ploy deep priors learned from large-scale datasets to tacklecomplex inverse rendering problems, including intrinsic im-age decomposition [ 20,21], SVBRDF estimation [ 7,19,22,53], lighting estimation [ 8,23,37], lighting editing[25] and relighting [ 33]. Those learning-based methods, of-ten requiring only a single or a few images [ 2,37] as in-puts, significantly reduce capturing requirements of classi-cal measurement-based methods [ 10]. High-quality datasetsare essential for data-driven methods to achieve compellinggeneralization ability. Synthetic datasets are often used fortraining because ground-truth labeling is too challenging5.30.021.51.00.171.0HDR Lighting, CRFWrong Lighting, No CRF✅❌Inaccurate Material❌✅Accurate MaterialPrevious OursHDRRadianceLDR ObservationFigure 2. Motivation. A typical image formation process causesthe loss of lighting information (e.g., emitter and reflection areboth clipped to 1.0), posing a formidable challenge to most inverserendering methods that require HDR input. Our proposed methodnot only recovers the HDR lighting and CRF, but also estimatesaccurate materials. We show normalized emission intensity.to obtain in real environments. Despite efforts to create aphotorealistic synthetic dataset [ 20,24,35], the inherent di-versity of real-world environments, especially in complexindoor scenes, still causes a substantial domain gap. Ourmethod uses\n",
      "----------------------------------------------------------------------------------------------------\n",
      " majority of impedance control schemes havetended to address translation and orientation dynamics asdistinct entities. This dichotomy can be observed not only inprior works like [8] but also in more recent works such as [9],[10], [11], [12], implying a potential for further performanceimprovement by considering the inherent geometric structureof these systems.TheSO(3)andSE(3)have been major research inter-ests within the domain of geometric control. This focusThis research is partially funded by (1) the Tsinghua-Berkeley ShenzhenInstitute (TBSI) phase II and (2) the Hong Kong Center for ConstructionRobotics Limited (HKCRC). Jongeun Choi was supported by the NationalResearch Foundation of Korea (NRF) grants funded by the Korea Govern-ment (MSIT) (No.RS-2023-00221762)1Department of Mechanical Engineering, University ofCalifornia, Berkeley {joohwan seo, nikhilps,horowitz }@berkeley.edu2School of Mechanical Engineering, Yonsei Universityjongeunchoi@yonsei.ac.krstems from the fact that classical mechanical systems areoften regarded as rigid bodies, and SO(3)andSE(3)offerpowerful mathematical tools for effectively representing suchrigid-body motions. The PD control designs on these groupshave been designed in [13], [14] employing the principlesof differential geometry. Specifically, the geometric controldesign on SO(3)was revisited in [15] to the UnmannedAerial Vehicle (UA V) application and widely utilized in theUA V field thereafter [16], [17].A well-known limitation of the control design in [15] is itstendency for the error vector’s magnitude to diminish, evenwhen the configuration error remains large [18]. This issueof slow convergence has been attributed to the ill-shapedLie group-based potential function in [19]. To overcomesuch drawbacks, the Lie algebra-based potential functionformulation was proposed as an alternative in [19], whereits fundamental concept of utilizing Lie algebra originatesfrom [13], [4].In our previous work [20], the geometric impedancecontrol (GIC) was proposed for manipulator control onSE(3). In particular, the control design scheme of [15] onSO(3)was extended to SE(3), and was applied to themanipulator system by combining with operational spaceformulation [21]. Moreover, when GIC is combined with alearning variable impedance control framework, the learningtransferability of manipulation tasks could be achieved byleveraging SE(3)invariance and equivariance [22].In this paper, we revisit geometric control on SE(3),demonstrating its applicability to the robotic manipulatorcontrol design. Specifically, we focus on providing a com-parative exploration of two pivotal approaches for selectingpotential functions and the resultant control laws: the Liegroup-based approach and the Lie algebra-based approach.The primary contributions of this paper can be summarizedas follows:1) A review of the distance metrics and potential func-tions on SE(3)is provided.2) We provide the control laws and stability analysisderived from a choice of potential functions.3) We provide extensive comparison analyses betweentwo control laws so that readers can be fully awareof the design choices.II. B ACKGROUNDSIn this section, we provide a brief description of the Liegroup and Lie algebra that naturally arise in robotics appli-cations. In particular, as the workspace of the manipulatorarXiv:2401.13190v1  [cs.RO]  24 Jan 2024lies on SE(3), we focus on the formulation on SE(3)andSO(3).A. Lie group and Lie algebra of SO(3)andSE(3)We first denote G⊂SE(3)be a matrix Lie group andg⊂se(3)as its Lie algebra. We note that we follow standardnotations of hat map and vee map presented in [20], [22]and refer to [7], [13] for the details of SE(3)and se(3)formulations. A dynamical system with a state given by g∈Gevolves as:˙g=gˆVb,ˆVb∈g (1)where Vb∈R6denotes a velocity in body-frame. Note thatwe are only interested in body-frame velocity formulationsince the distance metrics in Section. III are left-invariant;thus, it is natural to design in body-frame coordinate asproposed in [20], [4]. We also use the notation VbandVinterchangeably.Using homogeneous matrix representations, elements onSE(3)and se(3)can be denoted byg=\u0014R p0 1\u0015,ˆV=\u0014ˆω v0 1\u0015, (2)where g= (R, p)∈SE(3)and ˆV= (ˆω, v)∈se(3)are also used for compact notation. For the column vectorrepresentation of V, we follow the convention of [7] and puttranslational components on the upper side and rotationalparts on the lower side as V= [vT, ωT]T.The Adjoint map Ad gand adjoint map ad Vare originallydefined on the se(3)domain, i.e., Ad g,adV:g→ g.However, it can be interpreted as linear mappings acting onthe velocity V∈R6in column vector representation. We areinterested in such linear mapping representations, which aredenoted as follows [13].Adg=\u0014RˆpR0R\u0015,adV=\u0014ˆωˆv0 ˆω\u0015(3)The exponential map and logarithm map connect the Liegroup and Lie algebra. In particular, for SE(3)and se(3),the exponential mapping exp : g→Gis defined as follows:expSO(3)(ˆψ) =I+ sin∥ψ∥ˆψ∥ψ∥+ (1−cos∥ψ∥)ˆψ2∥ψ∥2expS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "gated from any 3D HOI datasets. The proposed rep-*Equal contributionresentation serves as a primitive that can be manifested toconventional affordance representations via simple transfor-mations, ranging from physically exerted affordances (e.g.,contact) to nonphysical ones (e.g., orientation tendency, spa-tial relations). We demonstrate the efficacy of our methodand representation by generating the 3D affordance sam-ples and deriving high-quality affordance examples from therepresentation, including contact, orientation, and spatialoccupancies.1. IntroductionThe unique ability of humans is to perceive the function-alities provided by the environment and to efficiently utilizethem; a concept known as affordance [ 21]. For example, weknow what functions a cup provides, set goals responsivelyduring interactions, and precisely control our hands to pickup and use the cup. Such ability allows us to use complextools in various ways, serving as a major driving factor forour evolution of intelligence. As it is a crucial component ofhuman intelligence, there have been many tries to implementsuch features in AI and robotics.Previous studies [ 11,16,24,25,30,35,89,92,94,96,107] focus on learning human and object interaction from2D or 3D dataset in a supervised manner. While these meth-ods provide opportunities to effectively mimic the interac-tions between humans and environments, such supervised ap-proaches often suffer from a lack of ability to support unseencategories, consequently failing to be generalized to the realworld’s diverse interactions. Additionally, the need for labo-1arXiv:2401.12978v2  [cs.CV]  24 Jan 2024rious annotations or data collection procedures makes it hardto scale, limiting the representation of affordance to simpleaspects such as expressing affordance categories [ 6,32,47](e.g., sitting, grasping) or contact heatmap [ 1,49] which isjust a part of affordance. Thus, the current representationdoes not completely capture the implicit effects of affor-dance on the distribution of the agent’s response, such asthe orientation tendency of body parts (e.g., face), proxim-ity relations, etc., induced to require various criteria (e.g.,physical stability).Henceforth, we propose a novel method to extract affor-dance in a zero-shot manner without requiring any manualannotations. Specifically, we address the task of inferringaffordance distributions from any3D objects given as mesh;with its first step generating the samples of interacting 3Dhuman and object pairs. We enable this by presenting a novelmethod, leveraging inpainting diffusion models [ 75] to insertaffordance-aware humans into the renderings of the 3D asset(Sec. 3.2). By creating affordance examples in the relatively“unchallenging” domain of 2D, we can generate plausiblesamples of affordance without heavy 3D supervision; evenwith no additional training in 2D as we use pretrained mod-els. However, the challenge exists as directly leveraging theinpainting diffusion model will result in altering the originalobject, which means the generated affordance is simply ahallucination from a different object. To mitigate this, wepropose Adaptive Mask Inpainting to preserve the details ofthe original object and insert humans interacting with the ex-act target object, rather than hallucinating different ones. Wethen uplift the predicted humans in 2D back to the 3D space(Sec. 3.3) to generate the 3D affordance samples from 2Dimages with human pose and shape regresser, where we aimto use for learning 3D affordance. On its path, we also offera framework that leverages generated 2D affordance samplesas depth cues to resolve the inherent depth ambiguity.Importantly, we also propose a novel affordance represen-tation (Sec. 4) designed to model the prevalent and plausible3D spatial relationship between a human and an object dur-ing interactions. Different from the prior approaches thatprimarily focus on the 3D contact regions where direct in-teractions occur [ 28,89,96], our affordance representationencompasses the entire spectrum of relationships betweenall human parts and object regions, not only the physicalcontact. Our representation is based on the observation thateach part of the human body has a specific set of possibleactions in interacting with each part of objects. For example,when we use a laptop, such actions entail not only finger-to-keyboard touch but also involve typical 3D postures, andrelative distances of various body parts, including the faceand arms. Specifically, our representation encapsulates therelative proximity and orientations between each possiblepair of object surface points and human points from gener-ated 3D affordance samples as a probability distribution.To summarize, our method contributes novel strategies togenerate the 3D affordance samples from the given input 3Dobject, including: (1) adaptive mask inpainting for insertinghumans into scenes without harming the original context ofthe object, and (2) a framework for resolving dep\n",
      "----------------------------------------------------------------------------------------------------\n",
      "nchallenge is the lack of paired image-landmark datasets fromother domains. Data collection is also a time-consuming andexpensive process.* The correspongding author.This work was supported by the ”Development of cognitive/responseadvancement technology for AI avatar commercialization” project funded bythe Brand Engagement Network (BEN) [Q2312881].Existing methods mainly use geometry warping and styletranslation to transform existing face landmark datasets intoa data distribution that is similar to the target domain. Yanivet al. [10] propose an approach for augmenting natural faceimages artistically, enabling the training of networks to de-tect landmarks in artistic portraits. Facial landmark datasets[11] are transformed into ”artistic face” data using a tech-nique known as geometric-aware style transfer. This pro-cess combines a gram matrix-based method [12] for trans-ferring artistic styles with geometric warping to achieve thetransfer of facial features and geometry. Recently, Sindel etal.[13] introduced an approach to detect facial landmarks inhigh-resolution paintings and prints. Similar to the previousmethod, they also use geometric-aware style transfer to per-form augmentation on the dataset. What sets it apart is that itemployed CycleGAN [14, 15, 16] to perform style transfer onthe images. However, when dealing with datasets that exhibita substantial domain gap from real images, such as cartoons,caricatures, etc., the geometric-aware style transfer used inthese methods tends not to work well, leading to suboptimalresults in terms of image translation. Cai et al. [17] also pro-posed an automatic method for 3D caricature reconstruction.The method is to first regress a 3D face model and orienta-tion and then project 3D landmarks and orientation to recover2D landmarks. However, their method is only applicable tocaricatures and requires a large amount of data to train.Recent advances in text-to-image synthesis [18, 19] haveshown impressive performance and creativity, enabling theconversion of text descriptions into visually appealing cre-ations. These generative systems excel in a variety of areas,including rendering realistic and diverse appearances, power-ful editing, etc. In more recent developments, ControlNet [20]extends the capabilities of pretrained diffusion models usingauxiliary input conditions. ControlNet proficiently capturestask-specific conditions like pose, depth map, and semanticmap, demonstrating robustness even when trained on limiteddatasets.In this paper, we tackle multi-domain face landmark de-tection by leveraging synthetic data generated through a text-to-image diffusion model. Firstly, our goal is to generatehigh-quality data pairs of multi-domain face images and theirlandmarks. We propose a two-stage training approach thatgenerates high-quality data pairs of multi-domain face im-arXiv:2401.13191v1  [cs.CV]  24 Jan 2024ages and their landmarks using a small dataset and pre-trainedtext-image model based on ControlNet. In the first stage,we train ControlNet on a large dataset of real-world faces[21]. We use facial landmarks as a condition aligned withthe face image as a condition for generating the face image.In the second stage, the pre-trained model is fine-tuned us-ing a small multi-domain face dataset to generate face im-ages of diverse domains. Secondly, we created a large multi-domain facial landmark dataset of 25 styles, each of whichcontains 400 images with annotations. We control the ge-ometric characteristics and styles of face images by editinglandmarks and text prompts. Finally, we fine-tune the exist-ing face landmark detection model [9] on this dataset, whichachieved state-of-the-art performance on the ArtFace[10] andCaricature datasets[17].2. PROPOSED METHODOur method is based on the pre-trained text-to-image model,i.e., latent diffusion model [18]. In this section, we first givea brief introduction to the details of the latent diffusion modelin Sec. 2.1. Next, we present an overview of our landmark-guided diffusion model in Sec. 2.2 and describe our procedurefor generating synthetic datasets in Sec. 2.3. Finally, we de-scribe the fine-tuning process for the face landmark detectorin Sec. 2.4.2.1. Latent Diffusion ModelThe Latent Diffusion Model (LDM) is a diffusion model thathas recently exhibited exceptional performance in the realmof image synthesis. It comprises two main components: anautoencoder and a diffusion model. The autoencoder, consist-ing of an encoder Eand a decoder D, learns to reconstructimages. The encoder first projects an image x into a lower-dimensional latent space: z=E(I), and the decoder recon-structs the original image from the latent space: ˆI=D(z).Then, the Denoising Diffusion Probabilistic Model (DDPM)[22] is employed to generate the latent z. DDPM adds noisetoz0gradually with Ttimesteps to mimic diffusion in non-equilibrium thermodynamics, which can be modeled as:q(zt|zt−1) :=N(zt;p1−βtzt−1, βt) (1)The Markov chain is a gradually forward noi\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ting high-fidelity 3D geometry, wealso apply the same SDS loss to its texture to obtain the com-plete appearance including the initially occluded regions.Through a series of decomposition steps, we obtain multiplelayers of 3D assets in a shared canonical space normalizedin terms of poses and human shapes, hence supporting ef-fortless composition to novel identities and reanimation withnovel poses. Our experiments demonstrate the effectivenessof our approach for decomposition, canonicalization, andcomposition tasks compared to existing solutions.1arXiv:2401.12979v1  [cs.CV]  23 Jan 20241. IntroductionIn the era where social interactions become increasinglyonline, the ability to customize digital representations ofoneself is more important than ever. This is particularly criti-cal in the domain of virtual try-on and photorealistic avatarcustomization. However, creating assets that can be easilylayered on top of any avatars typically requires substantialmanual efforts by artists. Our goal is to enable automaticcreation of reusable 3D layered assets that can be effortlesslycomposed to any human with any poses.Unlike artist-created 3D assets, reconstruction-based 3Dmodels are getting widely accessible. In addition to onlinemarket places of high-quality 3D scans [ 5,64], single-viewreconstruction methods [ 4,69,70] or text-to-3d generationtechniques [ 13,45,62] further simplify the creation of 3Dmodels. Despite these advancements, using these 3D modelsfor virtual try-on or avatar customization remains an openchallenge because these models are typically single-layerand not animatable. Different attributes such as hair, cloth-ing, and accessories are glued into a single triangle mesh,and anything beneath the outermost layer is fully occluded.Moreover, self-contact regions are also connected, makingre-animation challenging.To address this, we propose a fully automatic frameworkfor creating compositional layered 3D assets from a single-layer scan. Unlike the existing text-based 3D generationmethods [ 45,62] that only support the generation of eachasset in isolation, our approach learns to decompose a meshinto multiple layers and inpaint missing geometry and ap-pearance for compositing the decomposed assets into novelidentities. Our key idea is to complement missing geometricand appearance information by leveraging a strong imageprior built from a large-scale image collections. In particular,we leverage a latent diffusion model [ 66] that is trained onan extremely large corpus of images. Using a score distilla-tion sampling (SDS), we inpaint the occluded regions whileretaining the originally visible regions.For reposing, simply inpainting the geometry and appear-ance in an input posed space is not sufficient. For garmenttransfer across different identities with various poses, weneed to represent the target asset and the remaining humanlayer in individual canonical spaces. However, we observethat the vanilla SDS loss often provides poor guidance byignoring the target pose information. We address the lackof pose-sensitivity in the SDS loss by introducing a pose-guided SDS loss. Specifically, we derive the SDS loss witha pose-conditioned diffusion model [ 93]. This allows us tosupervise the shape and appearance jointly in both posed andcanonical spaces. Once we obtain the canonicalized objectand human layers, we can mix and match with other assetsto create virtual try-on as shown in Fig. 1. The compositeresults are further refined with penetration handling.As there is no established benchmark for decomposition,canonicalization, and composition from a single scan, weestablish a new evaluation protocol to quantitatively assessour approach. For decomposition, our approach significantlyoutperforms recent text-driven 3D editing methods. We alsoshow that the proposed pose-guided SDS enables robustcanonicalization even for challenging cases, outperformingexisting methods. Lastly, we show garment transfer to createnovel avatars only from a collection of single-layer clothedhumans. Our contributions can be summarized as follows:•We propose a new task of multi-layer decomposition andcomposition from a single-layer scan, which offers a prac-tical compositional asset creation pipeline.•We present a pose-guided SDS loss, enabling the robustmodeling of layered clothed humans in a canonical spacefor garment transfer and reposing from a single scan.•We provide a comprehensive analysis of generating ani-matable layered assets from a single scan with a newlyestablished evaluation protocol. We will release code forbenchmarking future research on this novel task.2. Related WorkClothed Human Modeling. 3D parametric human mod-els [35,47,60,86] have been proposed to model diverseposes and shapes of humans, allowing us to reconstructminimally clothed 3D humans [ 8,36,60,67,91]. To rep-resent clothed humans, follow-up work leverages 3D dis-placements on top of the template body model [ 2,3,48],or separate mesh layers [ 7,61]. Yet, the topologica\n",
      "----------------------------------------------------------------------------------------------------\n",
      "h the Materials Project (MP )2, known as high -throughput virtual screening3, which has shown great success in various applications.  However, the computational expense associated with Density Functional Theory (DFT) calculations renders an exhaustive search of the theoretical material space infeasible4.  In recent years, there has been a notable surge in research efforts dedicated to harnessing artificial intelligence for the exploration of new materials5, 6, 7, 8, 9, 10. However, it is worth emphasizing that within the field of crystallography, the predominant application of ML techniques is focused on predicting material properties, such as composition, band gap , or formation energy11, 12, 13. Consequently, the utilization of ML algorithms for crystal generation remains relatively nascent, underscoring the pressing need for the further development of Artificial Intelligence Generated Content (AIGC) within the realm of crystallography.      In the field of material exploration , generative models have  been  proven to be particularly apt7. Over the past few years,  two fundamental models have been  widely applied : Generative Adversarial Nets (GAN )14 and Variational Auto -Encoder  (VAE )15. Currently, an array of studies has been dedicated to structure generation, drawing on the capabilities of these two models.  An exemplary instance is the study conducted by Jordan Hoffmann et al.16, in which they employed voxel representation for crystals, utilized a VAE for voxel data generation, and subsequently applied a U -Net model for voxel classification.  Zekun Ren et al. 5 employed VAE for the reverse design of materials.  Kim et al. 7 utilized a GAN model to explore structures within the Mg -Mn-O ternary system , while  Baekjun Kim et al. 8 employed a Wasserstein Generative Adversarial Network (WGAN) in their quest to discover crystalline porous materials.  These research endeavors highlight the versatility and promise of generative models in the context of material discovery and design.  Nevertheless , most models grapple with the challenge of  how to improve the quality of generation results17. Jonathan Ho et al.18 introduced  a novel generative model known as  Denoising Diffusion Probabilistic Models (DDPM).  Notably  various research teams such as OpenAI19, 20, NVIDIA21, Google22 and many other works have achieved significant breakthrough s in the application23 of this model.  Considering its excellent  generative capability , we aim to investigate the latent potential of this model in the domain of structure generation and its potential to enhance the creative aspects of the model. Additionally, to minimize computational expenses and tailor it for diffusion modeling, we propose  a point cloud representation24 to encod e atom sites, element information , and lattice constant .  In this paper, we introduce a streamlined  deep  learning  framework  for crystal generation : Point  Cloud Based Crystal Diffusion ( PCCD ).  At the core of our approach is the utilization of a diffusion model as the foundational model, as illustrated in (Fig.  1). We leverage  U-Net25 as the backbone of PCCD , a well -established architecture frequently employed for tasks such as  classification and segmentation tasks26, 27.   To test the model's reliability, we intentionally added noise to our dataset and then used PCCD  to reconstruct the majority of the inputs with only minor deviations.  Further , we calculated the energy above hull  (Ehull) per atom for a set of crystal  structures generated by PCCD , revealing that many of these structures had low energy values, indicating their potential significance.  Furthermore, our analysis revealed structures not in the database or with a stable phonon structure, emphasizing the model's ability to generate new and potentially significant crystal structures.  Fig. 1|Sketch map of PCCD . Here we highlight the data flow of the framework . a. Training  phase process with data manipulation section . First, transforming crystals to point cloud data type, followed by adding noise to the data, which enables the PCCD to perform the observation and learning process;  b. Generation phase with retrieving data operation.  Starting by feeding  the PCCD  random data and composition condition , then passing to the data extraction  and finishing  with generating structures.  Results  As previously mentioned, the training of the diffusion model involves the incremental addition of noise, with the model essentially learning how this noise is incorporated into the data. In an ideal scenario, saving the data from the training set, along wi th the added noises, should enable the eventual reconstruction of these data. To validate the model’s effectiveness, we experimented  by introducing  noise to randomly  selected data points from the training dataset, and then we kept  the resultant data. These  noise -augmented data served as the initial random inputs for the subsequent generation process. Setting our\n",
      "----------------------------------------------------------------------------------------------------\n",
      "er by a drawing robot and alsohave a unique visual style.Drawing robots have become essential tools for the digital art community, espe-cially in the genre of generative art. Examples of well-known art projects andexperiments have been created by Jon McCormack et al. [10], who built a swarmarXiv:2401.13001v1  [cs.GR]  22 Jan 20242 S. Wieluch et al.of small driving and drawing robots called “DrawBots”. They utilize evolution-ary simulation to give each robot it’s own aesthetic preference. Another artist isSougwen Chung [3], who uses large industry robot arms to co-creatively paintlarge abstract paintings. Finally there is also “Sketchy” by Jarkman [1], whichis a small Arduino-based drawing robot that can take pictures and draw veryrough facial sketches using edge detection.To give our portraits a unique aesthetic style, we aim to include generativepatterns into the images as a form of shading. For this we draw single templatesketches that act as reference for a neural net. This net is trained to learn theseen stroke shapes, recreate and also slightly alter them. These strokes are scat-tered in the darker areas of the image to create a unique shading style.Freehand sketch representation learning, recognition and generation is a largeand diverse research field [18], where we mainly focus on one-shot learning andderivate generation. A lot of different forms of data representation have beenpresented over the last years, though as we aim to use a drawing robot as out-put medium, research that mainly focuses on vector representation is of interesthere. Sketch-RNN [5] for example uses a recursive neural net and interprets asketch drawing as sequence of turtle-graphic-like moves drawn by a virtual pen.A more modern approach is our prior work StrokeCoder [16], which uses a trans-former to learn freehand sketch data and is also able to create derivates, thoughonly in a restricted context.So for this paper we utilize graph neural nets in combination with graph convolu-tion [8], which allows us to have a single vector representation of a full stroke andalso benefit from the possibility of latent space exploration to generate strokederivates.2 Generating Sketch Portraits: System Overview andConstrains“PatternPortrait” was born from the idea to create a drawing machine thatwould be capable of taking a snapshot of a person’s face and then draw a quick,simplified portrait from that, injecting a unique style by shading with differentpatterns.Our setup for this installation consists of a webcam mounted on a tripod to takepictures, an Axidraw V3 drawing robot in combination with a magnetic boardto hold the paper in place. Both devices are connected to a notebook runningthe application. Images of this setup can be seen in figure 1.Derived from the previously stated idea, we identified the following constrainsfor creating such a drawing bot installation:1. The project’s input is a regular pixel image but the output it drawn witha drawing robot (aka a pen plotter), therefore a transformation from oneimage type to the other is required.PatternPortrait: Draw Me Like One of Your Scribbles 3(a) Used Devices (b) Drawing in ProcessFig.1: “PatternPortrait” setup: pictures are taken with a regular webcam in SDresolution. The drawings are created with an Axidraw V3 pen plotter.2. The overall process of taking the picture, calculating the output image andthe drawing process itself should not take longer than approximately 10minutes to prevent boredom and frustration for the viewer.3. The system should be capable of learning line styles from single templatesketch drawings and arranging them into a simple pattern as shading. Weaim for single template images, as we ourselves can not provide a datasetcontaining thousands of sketch drawings created by us. Also we promote theidea that AI systems should be transparent and ethical in their data usage,so we would like to construct systems that can work only on a single artist’sdata.These three constrains will act as guidelines in the following sketch portraitgeneration process.3 From Picture to LinesThe system’s first task is to create lines from the initial input image. There areseveral approaches of creating artistic line drawings from images, for examplethrough a reaction-diffusion [12] simulation, where parameters are changed de-pending on the pixel lightness or by calculating points of a weighted Voronoi net[14], which are then connected to a single line via approximating the TravelingSalesman Problem. Both examples can be seen as a form of dithering, as theseapproaches aim to also represent the original image’s brightness distribution.We instead aim for an algorithm that only translates the main visible featuresand shapes, like people’s facial or body features, into lines and so more closelyresembles a human approach of drawing a face.To achieve this translation from picture to lines, we first use canny edge de-tection [2] to retrieve a binary image that contains highlighted pixels belongingt\n",
      "----------------------------------------------------------------------------------------------------\n",
      "and Hinton2012), modern image classifiers have achieved near-humanlevel accuracy in the image recognition task. Although mod-els may achieve high accuracy, they often face challengesrelated to their complexity and overfitting. Even slight vari-ations or perturbations in input images, such as rotation,rescaling (Goodfellow, Bengio, and Courville 2016), cor-ruption (Hendrycks and Dietterich 2019), or adversarial at-tacks (Szegedy et al. 2013; Goodfellow, Shlens, and Szegedy2014), can lead to unexpected model behavior. For instance,*These authors contributed equally.†Corresponding Author.Copyright © 2024, Association for the Advancement of ArtificialIntelligence (www.aaai.org). All rights reserved.a classifier trained on clean images from a sunny day mayunderperform with inputs from rainy conditions. Such vul-nerabilities underscore the importance of robustness, espe-cially when models tackle real-world scenarios subject todistributional shifts (Hendrycks and Dietterich 2019).There are several factors that can contribute to a model’slimited generalization and robustness. One particular phe-nomenon we focus on is the convolutional neural network(CNN) model’s heavy reliance on a small subset of convo-lutional filters for making predictions. Models relying on alimited number of filters often exhibit poor performance ontest data and lack robustness against slight variations. Fur-thermore, a concerning aspect is that rapidly trained weightscan potentially make inaccurate judgments due to their ten-dency to learn dataset-specific biases (Nam et al. 2020).These biases may capture object-irrelevant patterns (e.g.,background) rather than focusing on the object of interest.To address this issue, regularization methods such asweight decay, dropout, and data augmentation are widelyemployed. Dropout (Srivastava et al. 2014) tempers themodel’s tendency to over-rely on particular units by ran-domly deactivating them. Weight decay (Ng 2004), knownasℓ2regularization, encourages the model to have smallerweights by adding a penalty for large weights. Data aug-mentation (DeVries and Taylor 2017; Hinton et al. 2012;Simonyan and Zisserman 2014; Kang and Kim 2023) en-courages learning more robust and generalized representa-tions by generating training data variants through assortedtransformations. However, those regularization methods donot directly address the model’s reliance on specific filters.Our observations indicate that the heavy reliance on asmall subset of filters in CNN can occur when slow-learningfilters lack adequate opportunities to learn, especially whena small number of the fast-learning filters are sufficient toclassify the training dataset accurately. It is supported by thevisualization of activation maps (Figure 1a) and histograms,which illustrate the relation between the ℓ2norms of acti-vation maps and corresponding gradients (Figure 1b). Fig-ure 1a provides insights into filters’ learning progress andimpact during training. We notice that fast-learning filterstend to exhibit higher ℓ2norms of activations, often captur-ing biases like the background. On the other hand, lower-magnitude filters struggle to extract meaningful informationfrom the input.arXiv:2401.13193v1  [cs.CV]  24 Jan 2024w/ Catch -up Mix Baseline(a) Images, saliencies, and activation maps with high L2 norm (red) and low L2 norm (blue)(c) A number of dropped features -Acc (%, ↑) plot.(b) Changes in gradient norm and activation norm distribution across layers during trainingFigure 1: We visualize activation maps, ℓ2norm, and gradients to understand how filters behave during training. (a) showsvisualizations of images, saliency maps, and activation maps. Activation maps are obtained from the third layer block outputof ResNet-18 while training CUB-200 at 120 epochs. (b) represents how distributions of activation norm (x-axis) and gradientnorm (y-axis) change over epochs. For example, among rows of ‘Baseline,’ the gradient scale decreases significantly after 60epochs, making it difficult to update the weight properly for the remaining process. (c) depicts the model’s accuracy as latentvectors are sequentially dropped by their value. This highlights that our method prompts the model to use diverse features.The problem is that slow-learning filters not only lag be-hind in their learning progress but are also deprived of futurelearning opportunities in the remaining epochs. The mainreason is that the current model already reaches a top-1 train-ing accuracy of 95.81% at 120 epochs. Thus, despite manyfilters failing to extract features properly at 120 epochs (Fig-ure 1a), only small gradients will be generated, indicatingminimal updates to these filters (Figure 1b). This imbalancecauses poor generalization performance, as evidenced bythe top-1 validation accuracy rates of 48.21%, 50.00%, and51.50% achieved at 60, 120, and 150 epochs, respectively.As a result, unfortunately, a significant portion of the train-ing process becomes unproductive for these slow \n",
      "----------------------------------------------------------------------------------------------------\n",
      "o parallel. (In passing, we note thet this theorem is nottrue for a cyclic octagon, but is for a cyclic decagon.)In this presentation, we consider a generalization of the above class of theorems, where instead ofmaking line pairs parallel, we allow line pairs to be given non zero, but determined angles. While thereis no geometric meaning to a parallel relationship between consecutive sides, replacing the parallelismby a defined non-zero angle permits adjacent sides of the polygon to be related. We examine the case ofa 2n-gon, with the angles between npairs of sides named. We show that if the pairs share no side, andif the sides in each pair are either adjacent or seperated by an even number of polygon sides, then thenamed angles satisfy a particular linear relation.An approach to theorem discovery in this context mirrors and illustrates that described in [8] and [7].As a first step, a value of nis chosen, and a set of line pairs conforming to our criterion selected froma catalog containing all such sets. A diagram is produced directly which allows the coefficients of theconstant linear combination to be computed.2 Cyclic Polygons and Angle BisectorsLetPbe a polygon whose vertices lie on the unit circle centered at the origin whose vertices p1,..., pnhave position vectors u1,..., un.154 Theorem DiscoveryFigure 1: θ0...θ6are angles of position vectors. θ6=θ1+2π.φi=12(θi−1+θi)We define u0=un.Letα(u,v)be the directed angle between vector uand vector v. We define θ0=0 and for ifrom 1 ton:θi=θi−1+α(ui−1,ui)Asu0=un,θn=θ0+2πWwhere Wis the winding number of the polygon about the origin. For ifrom1 tonwe defineφi=12(θi+θi−1)Foriandjfrom 1 to nwe defineδi j=φj−φiDefine Lito be the line passing through points pi−1andpi. We will define qi jto be the intersection ofLiandLj. We define the angleψi j≠pi−1qi jpj2.1 Cyclic QuadrilateralWe first examine the cyclic quadrilateral (Figure 2).In the figure, the quadrilateral has winding number 1 about the circle center, hence θ4=θ0+2π.The two indicated opposite angles of the quadrilateral have values π−δ12andπ−δ34.P.H. Todd 155Figure 2: A cyclic quadrilateral with winding number 1.The figure may be expressed by the following matrix equation:1 1 0 0 0 −2 0 0 00 1 1 0 0 0 −2 0 00 0 1 1 0 0 0 −2 00 0 0 1 1 0 0 0 −2−1 0 0 0 1 0 0 0 00 0 0 0 0 −1 1 0 00 0 0 0 0 0 0 −1 1θ0θ1θ2θ3θ4φ1φ2φ3φ4=00002πδ12δ34(1)We transform the matrix equation by performing the following row operations:R1←R1+R5,R2←R2+2×R6, and R3←R3+2×R7, which, after eliminating the zero columns,gives this matrix equation:1 0 0 1 −2 01 1 0 0 −2 00 1 1 0 0 −20 0 1 1 0 −2θ1θ2θ3θ4φ1φ3=2π2δ1202δ34(2)The matrix can be triangularized using the algorithm of [2]. Let Ribe the i’th row of the original matrix,andTithe i’th row of the triangularized matrix, then T1=R1, and for ifrom 2 to n:Ti=Ri−Ti−1 (3)156 Theorem DiscoveryUsing this algorithm, our triangularized matrix equation is:1 0 0 1 −2 00 1 0 −1 0 00 0 1 1 0 −20 0 0 0 0 0θ1θ2θ3θ4φ1φ3=2π2δ12−2π−2δ12+2π2δ34+2δ12−2π(4)Consistency of this system requires2δ34+2δ12−2π=0 (5)orδ34+δ12=π (6)In terms of ψ12andψ34π−ψ12+π−ψ34=π (7)Hence ψ12+ψ34=π, which is the familiar result that the opposite angles of a cyclic quadrilateral aresupplementary.2.2 General TheoremThe following general theorem may be proved by an analogous approach to that employed in the abovesection.Theorem 2.1. Given a cyclic 2n-gon with winding number W about the circumcircle’s center, and nordered pairs (a1,b1)...(an,bn)such that{ai}∪{ bi}={1...2n}, bi>aiand b i−aiis odd for each in∑i=1(−1)biδaibi=Wπ (8)Proof. LetPi,j=−2 where j=aiorj=biand 0 otherwise, let Q1=2πW. For i>1, let Qj=2δai,biifj=biand 0 otherwise.Analogous to equation (2) we have:1 0 ··· 0 1 P1,1··· Pn,11 1 ··· 0 0 P1,2··· Pn,2........................0 0 ··· 1 1 P1,2n··· Pn,2nθ1θ2...θ2n−1θ2nφ1...φn=Q1Q2...Q2n(9)P.H. Todd 157Triangulation yields a matrix equation analogous to that of (4( ..................0··· 0R1··· Rn!θ1...θ2nφ1...φn= ...S!(10)whereRi=2n∑j=1(−1)jPi,j (11)andS=2n∑j=1(−1)jQj (12)HenceRi= (−1)bi+ (−1)ai(13)andS=n∑i=1(−1)bi2δaibi−2Wπ (14)Asbi−aiis odd, Ri=0 for all i. Hence for consistency S=0. Hence the result.3 Automated Discovery of Cyclic Polygon TheoremsWe describe a mechanized process for automatic theorem generation for angles in cyclic polygons. Eachtheorem will establish a relationship between angles in a cyclic polygon. The process breaks down intothree steps. First a set of side pairs is chosen which satisfy the criteria of Theorem 2.1. Secondly, aspecific location is decided for the vertices of the polygon.and a geometry diagram created. Anglesbetween the side pairs are given names and drawn on the diagram. Thirdly, (8) is expressed in terms ofthese angle names, yielding the conclusion of our theorem statement.3.1 Choosing Side PairsIn o\n",
      "----------------------------------------------------------------------------------------------------\n",
      "22. This report also highlights thatsince the beginning of 2019, the number of phishing attackshas grown by more than 150% per year. Phishing attacks aremost commonly launched through emails as they are difficultto detect [60], [70]. Often phishing email attacks target banks,defense organizations, and private companies, as they curate awide variety of data, including personal and financial data [9].Generally, clicking on links, downloading attachments, orreplying to phishing emails can be considered unsafe responsedecisions [39], [54]. CISCO’s 2021 Cybersecurity threat trendsreport states that at least one person has clicked a phish-ing link in around 86% of organizations [15]. A successfulphishing attack can trick users into unintentionally disclosingtheir valuable information, compromising their devices oraccounts [67]. Additionally, phishing attacks are also used forinstalling malware (i.e., malicious software), which can disturbthe normal operations of a computer system, contributing tosignificant financial losses and reputation damages.Technology alone is insufficient to combat phishing emailattacks; therefore, transforming users from the weakest lineof defense to the most robust line of defense is essen-tial [21], [29], [57]. An active community of practitionersand researchers focuses on phishing education, training, andawareness (e.g., phishing alerts) to support users in correctlyidentifying phishing [18]. However, these efforts are withlimited success [4], [21]. A major challenge in designingeffective anti-phishing interventions is the lack of attention toreasons why people still fall for phishing [21], [37], [50], [75].Understanding why people still fall for phishing emailswill provide underpinning science to design effective futureanti-phishing tools and educational interventions. Althoughprior literature largely focuses on analyzing the personalityand demographics of people who fall for phishing emails[43], [66], how people make email responses and the thoughtprocess a user goes through when deciding how to respondto their emails is often overlooked [21], [34], [37], [50], [75].Only a limited number of studies have attempted to conductqualitative user studies to explain people’s email decision-making processes [34], [57], [75]–[77]. Although qualitativestudies, compared to quantitative studies, allow us to obtainmore detailed and holistic insights into users’ email responsedecision-making behaviors and the reasons for those behaviors,even such prior work does not interpret the different elementsof people’s email response decision-making processes and theirrelationships influencing their email response behavior.To address this research gap, we conducted an empiricalinvestigation through a “think-aloud” role-play experiment andfollow-up interviews to better understand people’s decision-making behavior when responding to emails. We developeda theoretical model that explains how people are driven torespond to emails by clicking on links, replying, and down-loading attachments based on the identified elements of theSymposium on Usable Security and Privacy (USEC) 202426 February 2024, San Diego, CA, USAISBN 979-8-9894372-5-2https://dx.doi.org/10.14722/usec.2024.23xxxwww.ndss-symposium.org, https://www.usablesecurity.net/USEC/arXiv:2401.13199v1  [cs.CR]  24 Jan 2024people’s email response decision-making process and the rela-tionships uncovered from collected data. The model developedbased on empirical evidence interprets how different elementsof people’s email response decision-making processes couldpositively and negatively influence people’s intention to re-spond to emails, which was lacking in previous literature. Forexample, the model provides deeper insights into how certainhabits, validation techniques, previous experiences, etc., canpositively influence people’s intention to respond to emails,as a result increasing the risk of them falling for potentialphishing attacks. In summary, our contributions are as follows:• Based on empirical evidence and grounded theoryanalysis, we provide knowledge into elements of emailusers’ decision-making process (e.g., diverse typesof emotions and personal habits) that influence theiremail response decisions.• We develop a theoretical model that explains howpeople are driven to respond to emails by clicking onlinks, replying, and downloading attachments based onthe identified elements of the user’s email responsedecision-making process and their relationships un-covered from data. The developed theoretical modelprovides deep insights (i.e., scientific underpinnings)into an individual’s email decision-making processor response behaviors to emails in general. As aresult, the model enables us to identify general emaildecision-making flaws that attackers could potentiallyexploit to launch successful phishing attacks. Further-more, understanding people’s general email decision-making flaws the attacker could leverage may helpbetter design technical countermeasures su\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ea thathas seen rapid growth in recent years is GAN based image-to-image translation tasks, some of which include creatingart [12, 24, 7], inpainting images [25, 23, 13] and super-resolution [11, 15, 6]. However, generative models can also(a) Pristine Semantic Map, downloaded using Google Maps API (b) Manipulated Map, with building removed from center of the image (c) Overhead Image, that corresponds to pristine map (d) Manipulated Image, after object removal Figure 1: Illustration of our proposed method, in which abuilding is removed from the center of an image.be used for more malicious intentions, producing fake im-ages and videos. Deepfakes refer to a particular applicationof these types of frameworks - manipulating or synthesizingfake human faces. While the most popular, deepfakes havebeen rapidly expanding into other domains, one study de-veloped a method to inject or remove cancer in 3D medicalscans using GANs, manipulating the scans so convincingthat they fooled three radiologists as well as a trained lungcancer screening neural network model that won a $1 mil-lion Kaggle competition [16].1arXiv:2401.13006v1  [cs.AI]  23 Jan 2024In the satellite image domain, a recent paper [26] ex-plored “deepfake geography”, receiving several mentionsthroughout the press [21, 5, 19]. This work utilized Cy-cleGAN [27] to transfer styles of different cities. For ex-ample, a satellite image from Seattle may be stylized tohave similar landscape features as a typical satellite im-age from Beijing. In this paper, we present an extended,generalizable GAN based methodology that can be usedfor object insertion or object removal from an image (asshown in Figure 1). Our method specifically modifies (in-sertion/removal) specific localized regions in a semanticmap, which we then translate to produce a fake image thatagrees with the modified semantic map and resembles theoriginal image in the unaltered regions. This generated im-age is then blended with the pristine image in the samelocalized region that the input map was manipulated, pro-ducing a doctored output image whose pixels are identicalto the pristine image in the unaltered regions. These typesof manipulations find potential use in applications such asdefense, agricultural sector and urban planning. For exam-ple, in urban planning, it is quite common to have urbanblueprints as maps which can undergo numerous changesin the planning stage depending on required design choices,such as swapping the locations of a park and a building tocomply with local zoning ordinances. Using the methodol-ogy presented in this paper, these changes can be easily ren-dered into realistic scenes. In agriculture, the map layout ofan agricultural field can be modified to make way for newcrops, and corresponding visualizations can be previewedin advance. However, the same technique can be used formalicious purposes, such as removing important structuresor landmarks from aerial photographs. Therefore, it is es-sential to have tools for identifying such altered images. Inthis paper, we also discuss the limitations of a variety ofdeep leaning based image forensic techniques, so that thedoctored images created with our proposed method cannotbe flagged.Main contributions. (1) A novel, simple, and effectiveway to edit or manipulate images. (2) Show the limits ofcurrent image forensic techniques so that fake images madewith the proposed method cannot be caught.2. Background2.1. Generative Adversarial NetworksThe GAN framework, as briefly mentioned in Section 1,consists of two neural networks that are jointly trained: agenerative model Gand a discriminative model D. In themost simple setup, the objective of this GAN is to gener-ate images that are visually similar to those in the trainingdata distribution X. However, in image-to-image transla-tion tasks, the objective of the GAN is to learn a mappingbetween source domain Xto the target domain Ysuch thatGpXqis indistinguishable from Y. Some example tasks in-clude translating images from day to night, black and whiteto color, or map to satellite. It can be seen that DandGgen-erally play a zero-sum game where the generator Gis try-ing to synthesize realistic samples to fool the discriminatorD. In the following subsections, we briefly cover two GANframeworks tested with our methodology - CycleGAN [27]and Pix2pixHD [22], while noting that any architecture thatcan perform image-to-image translation is applicable withinour proposed framework.2.1.1 CycleGANA core feature of CycleGAN [27] is its ability to learn imageto image translations without paired examples. The maininnovation that allows unpaired image to image translationis the addition of a cycle consistency loss to the objectivefunction that is being optimized. When training a Cycle-GAN to learn translations between images xandy, two setsof GAN networks are trained. The first network is com-posed of a generator Gthat learns a mapping from xÑy,and a discriminator Dy. The second is composed of a gen-erato\n",
      "----------------------------------------------------------------------------------------------------\n",
      "withemerging new types of nodes and their associated edges. Accord-ingly, models trained incrementally on the new node types mayexperience catastrophic forgetting (severe performance degrada-tion) on the old ones. Targeting this challenge, continual learning onexpanding graphs [ 47,89,92] attracts increasingly more attentionrecently. It exhibits enormous value in various practical applica-tions, especially in the case where graphs are relatively large, andretraining a new model over the entire graph is computationallyinfeasible. For instance, in a social network, a community detectionmodel has to keep adapting its parameters based on nodes fromnewly emerged communities; in a citation network, a document1𝑛: memory budget, 𝑑: average node degree, 𝐿: the radius of the GNN receptive fieldclassifier needs to continuously update its parameters to distinguishthe documents of newly emerged research fields.Memory replay [ 4,48,57,59], which stores representative sam-ples in a buffer to retrain the model and maintain its performanceover existing tasks, exhibits great success in preventing catastrophicforgetting for various continual learning tasks, e.g., computer vi-sion and reinforcement learning [ 3,43,46,58]. Directly applyingmemory replay to graph data with the popular message passingneural networks (MPNNs, the general framework for most GNNs)[34,42,64], however, could give rise to the memory explosionproblem because the necessity to consider the explicit topologicalinformation of target nodes. Specifically, due to the message passingover the topological connections in graphs, retraining an 𝐿-layerGNN (Figure 1, left) with 𝑛buffered nodes would require storingO(𝑛𝑑𝐿)nodes [ 11,15] (the number of edges is not counted yet)in the buffer, where 𝑑is the average node degree. Take the Redditdataset [ 36] as an example, its average node degree is 492, and thebuffer size will easily be intractable even with a 2-layer GNN. Toresolve this issue, Experience Replay based GNN (ER-GNN) [ 92]stores representative input nodes ( i.e., node attributes) in the bufferbut completely ignores the topological information (Figure 1 a).Feature graph network (FGN) [ 65] implicitly encodes node prox-imity with the inner products between the features of the targetnode and its neighbors. However, the explicit topological connec-tions are abandoned and message passing is no longer feasible onthe graph. Sparsified Subgraph Memory (SSM) [ 90] sparsifies thecomputation ego-subgraphs for tractable memory consumption,which still partially sacrifices topological information, especiallywhen the computation ego-subgraphs are large and a majority ofnodes/edges is removed after sparsification (Figure 1 b).To this end, we present a general framework of Parameter De-coupled Graph Neural Networks (PDGNNs) with Topology-awareEmbedding Memory (TEM) to perform continual learning on ex-panding graphs (Figure 1 c). First, with systematic analysis, wedemonstrate that the necessity to store the complete computationego-subgraphs for retraining MPNNs arises from the entanglementbetween the trainable parameters and the individual nodes/edges(Section 3.2). Targeting this problem, we design the ParameterDecoupled Graph Neural Networks (PDGNNs) framework, whichdecouples the trainable parameters from individual nodes/edges.The PDGNNs framework enables us to develop a novel concept,Topology-aware Embedding (TE), which is a vector with a fixed sizearXiv:2401.13200v1  [cs.LG]  24 Jan 2024Figure 1: (a) ER-GNN [ 92] that stores the input attributes of individual nodes. (b) Sparsified Subgraph Memory (SSM) [ 90]that stores sparsified computation ego-subgraphs. (c) Our PDGNNs with TEM. The incoming computation ego-subgraphs areembedded as TEs and then fed into the trainable function. The stored TEs are sampled based on their coverage ratio (Section 3.6).but contains all necessary information for retraining the trainableparameters of PDGNNs. Such TEs are desired surrogates of compu-tation ego-subgraphs to facilitate memory replay. After learningeach task, a subset of TEs is selected with a certain sampling strat-egy and stored in the Topology-aware Embedding Memory (TEM).Because the size of a TE is fixed, the memory space complexityof a buffer (with size 𝑛) can be dramatically reduced from O(𝑛𝑑𝐿)toO(𝑛). Moreover, different from traditional continual learningon Euclidean data without explicit topological connections ( e.g.,images), we theoretically discover that replaying the TE of one sin-gle node incurs a pseudo-training effect on the neighboring nodes,which could also alleviate the forgetting problem for the other nodeswithin the same computation ego-subgraph. This unique phenom-enon in continual learning on expanding graphs takes place dueto the neighborhood aggregation in GNNs. The pseudo-trainingeffect suggests that TEs corresponding to larger computation ego-subgraphs (quantitatively measured by coverage ratio) are morebeneficial to continual learning performance. Based on \n",
      "----------------------------------------------------------------------------------------------------\n",
      "nomics,predictive maintenance, root cause analysis, physics, and ma-chine learning. Conventional data analysis investigates theprobabilistic properties of the data to gain insight into theinvolved probability distributions which can then be used toe.g. predict new data. Causality on the other hand servesto not just learn the data but to learn about the systemthat generates the data. For instance, consider two randomvariables, one is binary and indicates the administration ofa drug that is allegedly reducing blood pressure in patients,and the other is the patient’s blood pressure itself. Then,ordinary data analysis can study the existence and size of astochastic dependency between those two random variables.But if we are interested in the efficiency of the drug inchanging blood pressure, this purely stochastic informationis insufficient, since there can be a correlation between thetwo random variables without causation, i.e. without the drughaving any effect on blood pressure. Causal analysis on theother hand provides techniques to answer questions aboutactual causation. And in this example, it answers the questionof whether the drug is actually the reason for the changein the patient’s blood pressure and also measures the sizeof this causal effect. I.e. causal analysis is concerned withthe discovery and measurement of actual mechanisms in theunderlying system, which in this case would be the patient’sbody.A subfield of causality is causal discovery , which studiesthe existence of causal relations and is not concerned withthe estimation of the size of the causal effects. Often, causaldiscovery is the first step and its results serve as input forthe estimation of the effect size. This paper focuses on causaldiscovery.Most of the research in causal analysis focuses on theacyclic situation, meaning that the considered system is pre-sumed to have no cycles in its causal relations, i.e. there areno feedback loops. This renders the analysis less complex butexcludes many realistic scenarios. An example from econo-metrics would be the study of supply, price, and demand: thedemand is influencing the price but the price is also influencingthe demand.Another assumption in standard causal analysis is causalsufficiency : It is presumed that there are no unobserved vari-ables, so-called hidden confounders , that causally influencemultiple observed variables. Again, this simplifies the analysisbut excludes many relevant use cases. E.g., in the exampleabove of a drug for blood pressure, imagine that the drug isonly given to younger people, which have lower blood pressureanyways, thus causing bias to the results. In this case, age isa hidden confounder.While there are many causal discovery algorithms for theacyclic, causally sufficient situation, very few exist that arealso applicable in the more demanding case of cyclic systemswith hidden confounders. In this paper, we compare theproperties of four of such methods, namely two techniques,ASP-d [11] and ASP-s [4], which are variants of a constraint-based technique using answer set programming, and twovariants, LLC-NF andLLC-F [10], of a method of momentstype estimator.Those four approaches are evaluated on synthetic data fromlinear systems, which means the causal relationships betweenarXiv:2401.13009v1  [cs.LG]  23 Jan 2024the variables are linear.II. R ELATED WORKFor a complete overview of the history of causality see thetreatises [15] and [16]. Both references focus mainly on theacyclic case but do cover, to a certain extent, the situation withhidden confounders.An early technique for cyclic systems, called CCD , isdescribed in [19], but it presumes the absence of latentconfounders. Amongst the few algorithms that allow for bothcycles and hidden confounders are LLC [10], the methoddescribed in [11] which we refer to as ASP-d ,sigmasep [4]which we refer to as ASP-s ,BACKSHIFT [20], CCI [23], andbcause [17, 18].Note that the methods above presume interventional data,that is, not only data from the system itself but also from othersystems that are obtained by changing the original system ina certain way, i.e. intervening on it. If this interventional datais not available, causal inference becomes harder. There are,however, several approaches for this scenario, too, like thefamily of Additive Noise Models (ANM ), see e.g. [8], ICA-based methods for linear systems like LiNGAM [22], LiNG[12], and the Two-Step algorithm [21], or Information Geo-metric Causal Inference (IGCI ), see e.g. [14]. Some of thosemethods can also deal with latent confounders or cyclicity.In recent years, the mathematical foundations of the theoryof cyclic systems with hidden confounders have advancedconsiderably. A comprehensive exposition can be found in [5]and [2].III. D ESCRIPTION OF THE METHODSThis section will present the main features of the LLC andASP algorithms. Note, that this is a high-level overview, pre-senting only as much as is necessary to explain the evaluationbelow. For the details, the re\n",
      "----------------------------------------------------------------------------------------------------\n",
      "an et al. ,2023]. However, the effectiveness of MLLM in person re- identiﬁcation (ReID) tasks remains unexplored. ReID refersto the cross-camera association of target persons [Ye et al. ,∗CorrespondingAuthor2020]. This paper focuses on how to make MLLM effective inReIDtasks. Anintuitiveideaistoﬁne-tuneaMLLM,such as LLaVA [Liuet al. , 2023 ], using ReID image-text pairs,as shown in Figure 1(a). During ﬁne-tuning, a projection layer is used for multimodal alignment of image and text,while indirectly optimizing the visual encoder throughthe LLM’s excellent representational capabilities, thereby enhancing feature extraction for persons and improving task performance. The ﬁne-tuned visual encoder is then used as the backbone network for the ReID model, followed by trainingtheReIDmodel,illustratedinFigure1(b). Although this idea may be simple and effective, how to better adaptMLLMstoReIDtasksstillposestwourgentchallenges.Firstly, when applying MLLMs to ReID tasks, designing instructionsisinevitable. Usinginstructivelearningresultsin the model adapting to the given instruction, leading to over- ﬁtting. Lora [Hu et al. ,2021 ]ﬁne-tuningmaycausetheLLMtolosesomediversity,leadingtopoorergeneralizationonun- seen samples due to overﬁtting to the instruction. To pre- servediversityandenhancegeneralizability,generatingmore comprehensive instructions is intuitive, but this poses sev- eralchallenges: (1)It’sdifﬁculttogeneratehigh-qualityand diverse instructions; (2) Even with an abundance of instruc- tions,appropriatetrainingdatamatchingtheseinstructionsis required;(3)Therichnessofinstructionsleadstoageometric increase in training costs. Therefore, ﬁnding a more com- mon instruction that doesn’t change the nature of the LLM becomes our goal. The essence of an LLM is to naturally generatesubsequentsentencesbasedonprevioustokens. We designasimpleandcommoninstructiontoenableimageand text to produce the same continuation text, thereby solving thisproblem.Secondly, the latent image feature vectors output by the LLMarenotusedtocomputelossininstructlearning [Liuet al.,2023;Zhu et al. ,2023 ],leadingtoindirectoptimizationof multimodal features and insufﬁcient utilization of these fea- tures. Thisapproachisnotsmartandnotconducivetolearn- ing by the visual encoder, thus impairing feature extraction for persons. Therefore, we directly apply the latent image feature vectors outputted by LLMs to the task of ReID, uti- lizing the loss generated in this task to directly optimize the visualencoderorprojectionlayer.To address the aforementioned challenges, this paper pro- poses MLLMReID: Multimodal Large Language Model- (a) MultimodalLargeLanguageModelStructureDiagram.(b) PersonRe-identiﬁcationModelStructurewithFine-TunedVisualEncoder.Figure1: NaiveImplementationofMultimodalLargeLanguageModelforPersonRe-identiﬁcation.based ReID. Firstly, this paper introduces the concept of Common Instruction for leveraging the essence of LLM in continuation writing. It is a simple continuation instruction designed to avoid the issues arising from complex and di- verse instruction designs. Secondly, the DirectReID module proposedinthispapereffectivelyutilizestheimplicitfeature vectorsofimagesoutputbyLLMforReIDtasks.2 Related Work 2.1 Image-Text Multimodal personre-identiﬁcation Existing methods use textual commands or multimodal text- image input to guide the model in learning person features within images. UniHCP [Ciet al. , 2023 ]utilizes a query to focus the model on cloth-agnostic features, such as ”extractcloth-agnosticidentityrepresentations,dim: 1536,”withinan encoder-decoder Transformer architecture. This model em- phasizes features that are independent of clothing. In com- mon ReID tasks, the focus should ideally be on persons’ clothing to distinguish different people. If the model centers oncloth-agnosticfeatures,itmightstruggletolearndiscrim- inative attributes. Moreover, though the query contains ex- plicitcommandinstructions,thereisnocorrespondingsuper- visoryinformationwithintheframework,possiblyrendering the query ineffective. In contrast, our method includes spe- ciﬁctextdescriptionscorrespondingtocommandinstructions as supervisory information, ensuring the practical impact on the model. Bao2023LearningTP introduced VAL-PAT, uti- lizing self-supervised contrastive learning, image-text con- trastive learning, and multi-attribute classiﬁcation for unsu- pervised ReID. However, using attribute-based training can pose two challenges: (1) Some ﬁne-grained attribute infor- mation, suchasglasses, ishardtomanifestinimagesdown- sampled to sizes like 256*128 or 384×128, typically used to increase retrieval efﬁciency, and the model may ﬁnd it chal- lenging to extract this information. (2) Utilizing attributes in feature learning is complex and inﬂexible, as it necessi- tates memorizing numerous labels and may fail to capture diverse variations in human appearance adequately [Chen et al.,2018 ]. SomemethodsemployCLIP’svisualencoderand textencoder [He et\n",
      "----------------------------------------------------------------------------------------------------\n",
      "e sophisticated understandingof human intentions and a greater competency in assistingwith complex tasks. This progression has instigated a tech-nological revolution across a multitude of fields, encom-*Corresponding author.passing software development [36], education [20, 49], so-ciology [33], among others.When examining the realm of generative models, specif-ically Generative Adversarial Networks (GANs) [3, 12, 21,22] and diffusion models [8, 17, 23, 46], we encounter twonotable challenges. The first challenge is the models’ lim-ited ability to process complex, compound tasks. To illus-trate, consider a task that involves “colorizing an old pho-tograph, replacing the depicted individual with the user’simage, and adding a hoe in the user’s hand”. Such a multi-faceted task surpasses the capability of even the most ad-vanced generative models. The second challenge arisesin the update process of a generated result. This processis contingent upon the preservation of the compute graph.However, the sheer volume of results generated by diversealgorithms makes maintaining this compute graph a signifi-cant hurdle. Consequently, this creates a barrier to learningfrom other generative models, given their black-box nature.In this paper, we introduce a novel generative model thatharnesses the capabilities of multiple LLM-based agents,which effectively circumvents these two challenges. Lever-aging the agents’ powerful task decomposition abilities, ourmodel can efficiently manage highly complex tasks. Simul-taneously, during the generation process, we can extract in-sights into how the agents comprehend, dissect, and executethe task, enabling us to modify internal steps and enhancethe results. Crucially, the model’s transparency allows theagent to learn from successful executions by other agents,moving away from the black-box model paradigm. We un-derscore that this transparency is a pivotal factor contribut-ing to the enhanced quality and robustness of the system.Generative Adversarial Networks (GANs) [12] can beviewed as an early endeavor to incorporate a multi-agentsystem into generative models. GANs utilize two agents,namely, a generator and a discriminator. A cleverly de-signed optimization function allows these agents to learnfrom their adversarial interaction, ideally reaching a Nashequilibrium. Similarly, in our multi-agent system, we havediscovered that the establishment of relationships betweendifferent agents is a critical determinant of success.Drawing inspiration from GANs, our system employs1arXiv:2401.13011v1  [cs.CV]  23 Jan 2024two generators and one discriminator. The two genera-tor agents, of equal status, independently process user in-structions and generate results. The discriminator agentthen evaluates these generated results, providing feedbackto each generator and determining which result is superior.The generator agents have dual responsibilities. Firstly,they must reflect on the feedback from the discriminator.Secondly, they should consider the results produced by theother generator agent to enhance their generation process.This process is iteratively carried out until the discriminatordeems the best result to have sufficiently met the user’s re-quirements. We underscore that through this collaborativecompetition, the two generators can continuously augmentthe quality and robustness of the system’s results. Conse-quently, we have named our system Collaborative Compet-itive Agents (CCA).In this paper, we concentrate on image editing, althoughour Collaborative Competitive Agents (CCA) system is aversatile generative model. Conventional image editingmethods [4, 16, 28] fall short when dealing with intricate in-structions, resulting in less robust outcomes. Our proposedgenerative model can considerably enhance this situationthrough the collaborative competition of multiple agents.In summary, our primary contributions are as follows:1. We introduce a new generative model based on mul-tiple agents, which features controllable intermediate stepsand can be iteratively optimized.2. We have meticulously examined the relationshipsamong multiple agents, highlighting that reflection, coop-eration, and competition are integral to the system’s qualityand robustness.3. We have conducted comprehensive experiments onimage editing, demonstrating for the first time the ability torobustly handle complex instructions.2. Related Work2.1. Large Language Model-based AgentsAgents are artificial entities capable of perceiving the en-vironment, making decisions, and taking actions to accom-plish specific goals [48, 54, 55]. Recent advancements inLarge Language Models (LLMs) have demonstrated signif-icant capabilities in Artificial General Intelligence (AGI),offering promising avenues for the evolution of intelligentagents. LLM-based agents possess the ability to memorize,plan, and utilize tools. The “memory” feature allows theseagents to store sequences of past observations, thoughts,and actions for future retrieval. The C\n",
      "----------------------------------------------------------------------------------------------------\n",
      " possible to use empirical data tochoose decoding metrics and code rates that facilitate reliablecommunication over unknown discrete memoryless channels(DMCs). We analyze two algorithms for choosing decodingmetrics: a naive plug-in algorithm and a proposed virtualsample algorithm. The plug-in algorithm is straightforwardand intuitive, but is likely to fail for finite training sets. Onthe contrary, the virtual sample algorithm returns a desireddecoding metric with a high probability as long as the size ofthe training set is no less than a certain finite value which doesnot depend on the channel. Our analysis does not rely on anyassumptions on the statistical characteristics of the channel,much like that in the PAC (probably approximately correct)learning theory [6], [7]. We use the virtual sample algorithm asa building block to construct a learning algorithm that reliablychooses a decoding metric and a code rate using which anencoder and a decoder can communicate reliably at a ratearbitrarily close to the channel mutual information. This leadsto a conclusion that DMCs are PAC learnable.In the language of PAC learning, a chosen decoding metricis a hypothesis and a risk of the hypothesis can be defined us-ing the maximum communication rate supported by the metric.Some other PAC learning problems for communications havebeen studied in [8]–[11]. In [8, Sections II and III] and [9],the hypotheses are constellations and/or their decoders, andthe risks are error probabilities or expectations of a hinge-typeloss. In [8, Section V], the hypothesis is an input distributionof a channel and the risk is the negative of the channelmutual information. In [10], learning-based channel codes aredefined and data-dependent achievability and converse boundsare established. In [11], input-output samples of an unknownDMC are used to construct a compound channel that includesthe DMC with a high probability. Based on the construction,a sampling strategy is proposed to find PAC bounds on thecapacity and the corresponding input distributions.The paper is organized as follows. In the remaining partof Introduction, we introduce our notation and the consideredcommunication model. In Section II we formulate the problemof how to choose decoding metrics and code rates, and showits connection with the PAC learning problem. In Section IIIwe present our theoretical results, which lead to the PAClearnability of DMCs. We conduct some numerical study toshow the results in Section IV. Section V outlines the proofsof the theoretical results and Section VI concludes the paper.A. NotationThe sets of real numbers, integers, non-negative integersand positive integers are denoted by R,Z,Z≥0andZ>0respectively. A finite sequence (x1, x2,···, xn)is written as{xi}ni=1or the boldface letter x. The number |{i∈Z|1≤i≤n, xi=x}|of the occurrences of a symbol xinxis writtenasN(x|x). Throughout the paper, XandYare non-emptyfinite sets. For every probability mass function (PMF) ponXand transition function wfromXtoY,pwis the PMFonYdefined by pw(y) =Px∈Xp(x)w(y|x),p×wis thePMF on X × Y defined by (p×w)(x, y) =p(x)w(y|x)andI(p, w)is the mutual information between XandYwhen(X, Y)∼p×w. All entropies and mutual information are inbits.arXiv:2401.13202v1  [cs.IT]  24 Jan 2024Learning algorithm AEncoder DMC Decoderm ˆmS={(Xi, Yi)}ni=1r k,rFig. 1. A learning algorithm accepts ni.i.d. input-output pairs of the DMCas input and returns a decoding metric kand a code rate r, which are usedby an encoder and a decoder.B. Communication ModelSuppose a DMC has a transition function wfromXtoY. A typical paradigm of communication over the DMC usesa codebook and a decoding metric [12]–[16]. There are Mcodewords in the codebook and positive integers not exceedingMare called messages. If a message mis to be transmitted,the encoder will input the m-th codeword {xm,t}Tt=1∈ XTinthe codebook into the DMC. The code rate of the codebookis defined as log2(M)/T. The decoding metric is a functionk:X × Y → [0,∞). Based on the sequence {yt}Tt=1∈ YToutput by the DMC, the decoder finds the positive integer ˆm≤MmaximizingQTt=1k(xˆm,t, yt)and guesses the transmittedmessage as ˆm. Ifk(x, y) =w(y|x) (1)for all x∈ X andy∈ Y, the decoder is a matched decoderandkis the maximum-likelihood decoding metric. If (1) doesnot hold for all x∈ X andy∈ Y, the guessed message ˆmmay be different from that guessed by a matched decoder. Thedecoder is then said to be mismatched [12]–[16].II. P ROBLEM FORMULATIONWe study how to use empirical data to choose a decodingmetric and a code rate for a DMC with a transition functionwfromXtoYand an input distribution ponX. We assumethatXandYare known, but there is no knowledge about worp. We have a training set Sof independent and identicallydistributed (i.i.d.) input-output pairs (X1, Y1),(X2, Y2),···,(Xn, Yn)of the DMC. The training set is input into a learningalgorithm A, which is a mapping from the training set to (k, r),as shown in Fig. 1. The communication will be at the rate ra\n",
      "----------------------------------------------------------------------------------------------------\n",
      "fy and reasonabout its underlying execution process. This often regards identifying andreasoning about process patterns, bottlenecks, and possibilities for improve-ment. In this paper, to the best of our knowledge, we propose, for the firsttime, the application of Process Mining (PM) techniques to the byproducts∗Corresponding authorEmail addresses: roberto.casaluce@santannapisa.it (Roberto Casaluce),andbur@dtu.dk (Andrea Burattin), francesca.chiaromonte@santannapisa.it(Francesca Chiaromonte), albl@dtu.dk (Alberto Lluch Lafuente),andrea.vandin@santannapisa.it (Andrea Vandin)Preprint submitted to Journal of Systems and Software January 25, 2024of Statistical Model Checking (SMC) simulations. This aims to enhance theutility of SMC analyses.Typically, if SMC gives unexpected results, the modeler has to discoverwhether these come from actual characteristics of the system, or from bugsin the model. This is done in a black-box manner, only based on the obtainednumerical values. We improve on this by using PM to get a white-box per-spective on the dynamics of the system observed by SMC. Roughly speaking,we feed the samples generated by SMC to PM tools, obtaining a compactgraphical representation of the observed dynamics. This mined PM modelis then transformed into a mined QFLan model , making it accessible to PLengineers. Using two well-known PL models, we show that our methodologyis effective (helps in pinpointing issues in models, and in suggesting fixes),and that it scales to complex models. We also show that it is general, byapplying it to the security domain.Keywords: Software product lines, Product line engineering, Probabilisticmodeling, Statistical model checking, Process mining, Attack-defense trees1. IntroductionSoftware product lines (SPL), and feature models in general, as well asProduct Line Engineering (PLE), play a very important role in modern soci-ety, where customization capabilities are expected even for commodity prod-ucts. Very often, these products are equipped with software that is expectedto follow the customization of the product itself. As a consequence, it be-comes necessary to ensure that the product lines are properly designed andthat the models indeed capture the intentions of the modelers. This paperpresents a novel methodology to validate the behavior of SPL models by of-fering simple tools to “see and compare” the actualbehavior of a model withtheexpected one.To validate models that present quantitative aspects in their behavior,we often use exact or statistical analysis techniques. The formal verificationof the dynamics of a system via exact techniques provides precise values ofthe (quantitative) properties being analyzed. These typically require reason-ing upon the whole behavior of the system, which might not be feasible forcomplex models. Indeed, as the possible dynamics of the system increase,these techniques tend to suffer from the well-known state-space explosionproblem, rendering them inapplicable when the state-space becomes infinite2(see, e.g., [1]). On the other hand, statistical analysis techniques, such asStatistical Model Checking (SMC) [2], rely only on limited but statisticallyrelevant samples of executions of a model: simulations. Therefore, statisticalanalysis techniques can be used to analyze complex dynamical systems, po-tentially with infinite state spaces, at the cost that analysis results are notexactanymore but are only statistically reliable estimations, e.g., equippedwith confidence intervals.When the overarching behavior of a system is unknown, and it is im-possible to make assumptions about its transition structure, the system isreferred to as a black-box system. An SMC that analyzes the dynamics ofa black-box system without prior knowledge of the system is referred to asa black-box SMC [3]. These simulation-based approaches return numericalestimates, plots, and occasionally counterexamples of the studied proper-ties. However, they typically do not provide behavioral explanations for theresults obtained. Without clear explanations, the modeler can only makeinformed guesses about how to adjust the model to fix unwanted behaviors.For example, let us assume that we consider an SPL model for a family ofvending machines, a classic PLE model (see, e.g., [4, 5, 6, 7, 8, 9, 10]). Let usfurther assume that we use SMC to study the probability that machines fromthe family contain dispensers for cappuccino and that we get 0. Interestingquestions about this analysis are:•What is the reason behind such an extreme value? ,•Was the model intended to express this dynamic, or is there a bug?In our view, the numeric value 0is a black-box analysis result. Meaningthat we do not know whywe got 0, we do not know if it comes from anissue in the model, nor how to fix it. The core of our proposal is to enrichthe analysis results obtained by SMC to study this query by automaticallyadding explicit visual information pinpointing any misalignment between themodel and the two bullet po\n",
      "----------------------------------------------------------------------------------------------------\n",
      " scenes are crafted in response to various nat-ural language prompts, demonstrating the versatility andadaptability of our model.1. IntroductionThe increasing focus on high-quality indoor 3D scenes isgaining attention in academic and industrial field. Thistrend is particularly beneficial for advancing applicationssuch as filming and AR/VR technologies, offering valu-able insights and inspiration for both designers and con-sumers. Therefore, there is a critical need for an efficientapproach to automatically generate high-quality 3d indoorscenes [4, 6, 9, 10, 24, 25, 28].Indoor scenes could be represented by a 360 panoramaimage. Several text-driven 3D indoor scene generation ap-proaches on a panoramic image have be explored. MVD-iffusion [25] incrementally generated consistent multi-viewimages from text prompts given pixel-to-pixel correspon-dences and reconstructing the 3D mesh of the room fromthese sub-frames, effectively addressing the typical problemof error accumulation was achieved by concurrently gener-ating all images with a global awareness. Ctrl-Room [6]separated the modeling of layouts and appearance produce avivid panoramic image of the room guided by the 3D scenelayout and text prompt generated convincing 3D rooms withdesigner-style layouts and high-fidelity textures from just atext prompt. Text2Room [9] leverage pre-trained 2D text-to-image models to synthesize a sequence of images fromdifferent poses and then monocular depth estimation with atext-conditioned inpainting model to generate complete 3Dscenes with multiple objects and explicit 3D geometry.Implicit functions like NeRF [15] and tri-plane [2] in3D scene generation have also been actively explored.CC3D [1] represents a 2D layout-conditioned 3D genera-tion framework, while DiscoScene [27] conditions scenegeneration on 3D bounding box priors. Text2Room [9]leverage pre-trained 2D text-to-image models to synthe-size a sequence of images from different poses and thenmonocular depth estimation with a text-conditioned inpaint-ing model to generate complete 3D scenes with multipleobjects and explicit 3D geometry.What’s more, some works also model the whole sceneusing a single mesh. DreamSpace [28] proposed a coarse-to-fine panoramic texture generation strategy with dual tex-ture alignment to recovery fine-grain details and authenticspatial coherence. However, these works either suffer fromgenerating correct room layouts or fail to control the indi-vidual room objects.To address these limitations, we propose an novel 3Dindoor scene synthesis pipeline that provides multi-modalcontrollability, such as text prompt or images to control gen-eration and stylization objects. This pipeline aims to syn-thesis 3D indoor scenes with multi-object style consistency.The key insight involves separating diverse room objectsfrom the scene. We adopt meshes as the 3D representa-tion, as they can be seamlessly integrated into downstreamapplications like AR/VR devices. They can be sourcedfrom CAD models or generated through well-trained text-to-mesh or image-to-mesh models. Building on the capa-bilities of SyncDreamer [13], individual mesh can be re-constructed from a single-view image, expanding the rangeof selectable objects significantly.Compared to state-of-the-art 3D style transfer methods,our experiments show an improvement in terms of 3D con-sistent stylization both qualitatively and quantitatively. Ad-ditionally, our mesh objects representation de-couples inter-objects and object to background, allowing more degrees offreedom to manipulate explicitly.To summarize, our contributions are:• We introduce a novel 3D indoor scene synthesis pipelinededicated to generate de-coupled mesh objects using ei-ther text prompt or single-view images.• Objects within the scenes can be stylized using either textinstructions or a style image, ensuring a consistent styleacross multiple objects.• The resulting complete indoor scenes exhibit visual co-herence in both style and spatial arrangement, presentinga unified and aesthetically pleasing composition.2. Related Works2.1. 3D Scene GenerationRecently, several works proposed to use different controlssuch as 3D bounding box, layout abstract or text prompt togenerate 3D scenes. DiscoScene [27] proposed to leveragethe pre-extracted 3D bounding boxes to model all objectsin a scene using a single NeRF [15] using bounding boxcentre and scale as additional condition. CC3D [1] adoptedthe layout abstract generated from the top-down view anddifferent color codes as the object labels to synthesis differ-ent types of objects. However, the Style-GAN [12] basedframework cannot fully disentangle style-code and inputlayouts as the layout change can result in the objects appear-ance change. Ctrl-Room[6] adopted a two-stage method togenerate 3D room from text input, in which the geomet-ric layout and appearance generation were separated. Sincelayout semantic panorama were generated through equirect-angular projection, the generated 3D room still\n",
      "----------------------------------------------------------------------------------------------------\n",
      "r is challeng-ing, because the data generated from agent-environment interaction is nonstationarily distributed,due to the continually changing policy, state visitation, and even environment dynamics. For neuralnetwork (NN) based world models, the nonstationarity could lead to catastrophic forgetting (Mc-Closkey & Cohen, 1989; French, 1999), making models inaccurate at recently under-visited regions(as illustrated in the top row of Figure 1). Planning with inaccurate models is detrimental as themodel errors can compound due to rollouts, resulting in misleading agent updates (Talvitie, 2017;Jafferjee et al., 2020; Wang et al., 2021; Liu et al., 2023). To attain a world model of good accu-racy over the observed data coverage, NN-based methods often maintain all collected experiencesfrom the start of the environment interaction and perform periodic re-training, possibly at every step,resulting in a growing computation cost for lifelong agents.In this paper, we aim to develop a world model, in the Dyna MBRL architecture (Sutton, 1990;1991), that learns incrementally without forgetting prior knowledge about the environment. Wenotice that re-training NN-based world models every step on previous observations till convergenceresembles the concept of Follow-The-Leader (FTL) in online learning (Shalev-Shwartz et al., 2012).While re-training the NN on all previous data is prohibitively expensive, especially under the stream-ing setting in RL, specific types of models studied in online learning can achieve incremental FTLwith only a constant computation cost. To this end, we revisit the classic idea of learning a lin-ear regressor on top of non-linear random features. The loss function of such models is quadraticwith respect to the parameters, satisfying the online learning requirement. It may seem a retrogradechoice given all the success of deep learning, and the findings that a shallow NN needs to be ex-ponentially large to match the capability of a deep one (Eldan & Shamir, 2016; Telgarsky, 2016).1arXiv:2401.13034v2  [cs.LG]  27 Jan 2024Published as a conference paper at ICLR 2024Unvisitedregions under current policyVisitedregions under current policy𝑠!when d𝑠!\"#,𝑓𝑠!,𝑎!>𝛿𝑠!when d𝑠!\"#,𝑓𝑠!,𝑎!≤𝛿Neural NetworksOurs𝜋!𝜋\"𝜋!!Figure 1: This Gridworld environment requires the agent to navigate from the start position (“S”) to the goallocation (“G”) with shortest path. The tabular Q-learning agent starts from a random policy π0and improvesto get better policies πt· · ·πt′, leading to narrower state visitation towards the optimal trajectories ( the yellowregions ). Due to such distributional shift, the NN-based model ( top) may forget recently under-visited regions,even though it has explored there before. The red circles indicate erroneous predictions where the Euclideandistance between the ground truth next state and the prediction is greater than a threshold ( δ= 0.05). Incontrast, our method ( bottom ) learns online, and at each step incrementally computes the optimal solution overall accumulated data, thus is resilient to forgetting.Nevertheless, we believe it is worth exploring under the RL context for three reasons: (1) In RL, datais streamed online and highly non-stationary, advocating for models capable of incremental FTL. (2)Many continuous control problems have a moderate number of dimensions that could fall within thecapability of shallow models (Rajeswaran et al., 2017). (3) Sparse features can be employed tofurther enlarge the model capacity without extra computation cost (Knoll & de Freitas, 2012).Inspired by Knoll & de Freitas (2012), we propose an expressive sparse non-linear feature repre-sentation which we call locality sensitive sparse encoding. Our encoder generates high-dimensionalsparse features with random projection and soft binning. Exploiting the sparsity, we further developan efficient algorithm for online model learning, which only updates a small subset of weightswhile continually tracking a solution to the FTL objective. World models learned online withour method are resilient to forgetting compared to those based on NNs (see the bottom row ofFigure 1 for intuition). We empirically validate the representational advantage of our encoding overother non-linear features, and demonstrate that our method outperforms NNs in online supervisedlearning (Orabona, 2019; Hoi et al., 2021) as well as model-based reinforcement learning (Sutton,1990) with models learned online.2 P RELIMINARIESIn this section, we first recap the protocol of online learning and introduce the Follow-The-Leaderstrategy. Then we revisit Dyna, a classic MBRL architecture, where we apply our method to learnworld models online.2.1 O NLINE LEARNINGOnline learning refers to a learning paradigm where the learner needs to make a sequence ofaccurate predictions given knowledge about the correct answers for all prior questions (Shalev-Shwartz et al., 2012). Formally, at round t, the online learner is given a question xt∈ X andasked to provide \n",
      "----------------------------------------------------------------------------------------------------\n",
      "the adversarial examples can be categorized intowhite-box [6, 15] or black-box attacks [2, 32, 36]. Thewhite-box attacks assume that the adversary has the fullknowledge of the target model to generate the adversar-ial examples. In contrast, the black-box attacks considera more realistic setting, where the adversary cannot get ac-cess to the target model directly. Black-box attacks are ofpractical importance and have attracted broad attention.There are two types of black-box adversarial attacks,i.e.,query-based [21, 26] and transfer-based [2, 14, 27, 32]attacks. 1) Query-based adversarial attacks send queriesto the target model and collect information to craft ad-versarial examples, which may be detected by the serviceprovider. 2) Transfer-based attacks generate adversarial ex-amples from the white-box surrogate models by exploit-ing the cross-model transferability of adversarial examples.Transfer-based attacks assume no a-priori knowledge of thetarget model, and are promising and stealthy to real-worldAI applications.The critical challenge of transfer-based attacks is toimprove the adversarial transferability ( i.e. adversarial suc-cess rate crafted from surrogate models). Various meth-ods have been designed in the literature, including in-put diversity [4, 27, 29, 30, 38], optimization improve-ment [3, 13, 25], ensemble attacks [2, 32] and advancedloss design [12, 37]. Input diversity achieves superior trans-ferability by incorporating image transformations into thesynthesis process, hence alleviating overfitting to surrogatemodels. Existing methods mainly focus on increasing diver-sity by adding global [29, 38] or local [27] transformationcategories.However, existing input-diversity-based works [4, 27,29, 30, 38] adopt an identical step size to craft adversarialexamples. We find that 1) input diversity can be strength-ened by mixing the transformed images; 2) identical stepsize may degrade the adversarial transferability (as differ-ent regions of an image are of different weights for modelinference). Motivated by this, we jointly design enhancedinput diversity and adaptive step size to boost the transfer-ability of black-box adversarial examples.This paper proposes a novel adversarial genera-tive framework, I nput-D iversity-based A daptive A ttackarXiv:2401.13205v1  [cs.CV]  24 Jan 2024(IDAA), by jointly designing enhanced input diversity andadaptive step size. 1) Enhanced input diversity. We exploitdifferent image transformation techniques to reformulate agroup of adversarial examples to obtain input diversity. Tofurther increase the input diversity, we design a local mixupmodule ( i.e. randomly mixing the regions of the group oftransformed images) before feeding to the surrogate model.2) Adaptive step size. We propose to project the perturba-tion optimization into the tanh space to relax the boundaryconstraint. The step sizes can be dynamically adjusted byapplying a second-order momentum.Our main contributions can be summarized as follows.• We propose to design the local mixup step (that randomlymixes a group of image regions) to strengthen the inputdiversity.• For precise adversarial generation, we eliminate the con-straint for image validity and perturbation budget by pro-jecting into the tanh space. We also enable adaptive ad-justment of step sizes for different perturbation regionsduring the update phase via second-order momentum.• By integrating the proposed local mixup and adaptivestep size, we design an adversarial generative framework,IDAA, to craft highly transferable adversarial examples.• Experimental results on ImageNet validate that our pro-posed framework can achieve superior performance incomparison to stat-of-the-art baselines. Our frameworkcan also work in conjunction with other transferablemethods to further improve their transferability.2. Related WorksAdversarial attacks attempt to manipulate AI modelsto deviate from the normal output by carefully crafted in-put data ( i.e., adversarial examples). Based on the deviationdirection, adversarial attacks can be categorized into untar-geted [15, 28] and targeted [9, 12, 37] adversarial attacks.Targeted adversarial attacks attempt to obtain some specificmodel output, while untargeted adversarial attacks aim toconfuse the model to make mistakes.In this paper, we focus on transfer-based black-box ad-versarial attacks, i.e., the adversary exploits the cross-modeltransferability to conduct attacks. Specifically, transfer-based attacks exploit a white-box/open-source surrogatemodel to synthesize adversarial examples and leverage thecrafted adversarial examples to confuse the unknown targetmodels via the transferability of adversarial examples. Thetransferability of adversarial examples is critical to achiev-ing effective attack performance for transfer-based adver-sarial attacks. Several methods have been proposed to boostadversarial transferability.Optimization improvement . Dong et al. [3] proposedto integrate the momentum term into the itera\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tional requirement that exploration mustbecollision-free : in every round at most one agent can be at any node. This requirement, previouslyconsidered in [10, 20], has many applications. If agents are humans circulating in a pharmacy or asupermarket during a pandemic, some areas (such as cash registers or prescription counters) may betoo small to preserve the 6-feet requirement of social distancing between customers. When mobile∗Department of Mathematics, Indian Institute of Technology Jodhpur, India. sbhagat@iitj.ac.in†D´ epartement d’informatique, Universit´ e du Qu´ ebec en Outaouais, Gatineau, Qu´ ebec, Canada. pelc@uqo.ca‡Research supported in part by NSERC Discovery Grant 2018-03899 and by the Research Chair in DistributedComputing of the Universit´ e du Qu´ ebec en Outaouais.1arXiv:2401.13044v1  [cs.DC]  23 Jan 2024entities model software agents, these entities may need exclusive access to the part of a distributeddata base situated at a node. Finally, mobile robots distributing chemicals at nodes of a networkmay need to avoid being at a small distance from each other.The network is modeled as a simple connected undirected graph G= (V, E), called graph in thesequel. Nodes are unlabeled, and all ports at any node of degree dare arbitrarily numbered0, . . . , d −1. This is a standard assumption in many papers on network exploration [2, 9, 18, 24].Each of two identical mobile agents, initially situated at distinct nodes, has to visit all nodes andstop. Agents execute the same deterministic algorithm and move in synchronous rounds: in eachround, an agent can either remain at the same node or move to an adjacent node by taking one ofthe ports. We say that an agent is located at node vin round t, if it is at this node after the aboveaction in round t. When agents cross each other moving simultaneously along an edge in oppositedirections, they do not even notice this fact. Agents are woken up in possibly different rounds,chosen by an adversary. Each agent starts the execution of the algorithm in the round following itswakeup. In every round, at most one agent can be located at any node. For a non-negative integerr, we say that agents have vision of radius r, if in each round t, an awake agent located at a nodevin round t−1 sees the subgraph G(v, r) induced by all nodes at distance at most rfrom v, seesall port numbers in this subgraph, and sees the other agent located at any of these nodes in roundt−1. We call this information the input of the agent in round t. We assume that agents have visionof radius 2. In each round t, an awake agent located at a node vin round t−1, uses the input inround tto determine its action in round t: either moving to an adjacent node choosing one of theports at v, or staying idle at v.An awake agent can compare its inputs in consecutive rounds and deduce a crucial piece of infor-mation (often used in our algorithm), namely that the other agent has moved. We will say thatagent aalready awake in round t−1sees the agent bmoving in round t, if a node uis in the inputofain rounds t−1 and t, and one of the following conditions is satisfied: either bwas not at uinround t−1 but was at uin round t, orbwas at uin round t−1 but was not at uin round t.Agents have no a priori knowledge of the graph but they know an upper bound non its size.Agents are computationally unbounded and cannot mark the visited nodes. They cannot send anymessages. The time of an exploration is the number of rounds since the wakeup of the later agentto the termination by both agents.1.1 Our resultsOur main result is a collision-free exploration algorithm working in time polynomial in n, forarbitrary graphs of size larger than 2 (in the two-node graph, collision-free exploration is impossible,see Section 3). We also show that the assumption of vision of radius 2 cannot be weakened: weprove that collision-free exploration with vision of radius 1 is impossible in any tree of diameter 2.An important building block of our algorithm is a procedure called EXP (n), that, given anypositive integer n, allows an agent to visit all nodes of any graph of size at most n, starting fromany node of this graph, using R(n) edge traversals, where Ris some polynomial. We show thatour collision-free exploration algorithm works in time O(R(n) logn), and thus has only logarithmicslowdown with respect to the time of exploration by a single agent, without any constraints. It is2important to note that, while we use the well-known Reingold’s [24] result as the base of EXP (n),any exploration procedure working in arbitrary anonymous graphs of size at most nwould do,and no changes would be necessary. (We could use, for example, the faster but non-constructiveexploration algorithm from [2]). Hence, our result can be viewed as a generic one: given anyexploration procedure for one agent, working in arbitrary anonymous graphs of size at most n, weobtain a collision-free exploration with only logarithmic slowdown. Of course, if the collision-freerestr\n",
      "----------------------------------------------------------------------------------------------------\n",
      "on optimization th eory,such as the weighted minimum mean squared error (WMMSE) andinterference pricing algorithms [1], [2], [3]. Nonetheles s, the practicalimplementation of these algorithms still encounters many o bstaclesdue to their substantial computational demands [4].To address this challenge, deep learning, like in other doma ins ofwireless communications, has been extensively applied in i nterferencemanagement [4], [5]. Rather than solving the problem direct ly,this approach involves training a deep learning model to pre dictthe optimal solution to the problem speciﬁed by a given chann elrealization. The model can be trained using a dataset consis ting ofchannel realizations and their corresponding optimal solu tions. Oncetrained, the model can efﬁciently predict the optimal solut ion forany given channel realization, offering a cost-effective a lternative tooptimization-based algorithms.However, this data-driven approach based on deep learning m ay notguarantee effective interference management in situation s that deviatesigniﬁcantly from the given dataset. Indeed, this limitati on is inherentto data-driven approaches, since a single dataset cannot en compass allthe diverse scenarios encountered in real-world systems [6 ]. Hence, toensure effective interference management, it is essential to assess theconﬁdence level of the solution predicted by the deep learni ng model.Then, based on this evaluation, optimization-based algori thms can beHyun-Suk Lee is with the Department of Intelligent Mechatro nics En-gineering, Sejong University, Seoul 05006, South Korea (e- mail: hyun-suk@sejong.ac.kr).Do-Yup Kim is with the Department of Information and Telecom municationEngineering, Incheon National University, Incheon 22012, South Korea (e-mail: doyup@inu.ac.kr).Kyungsik Min is with the Department of Information and Telec ommunica-tions Engineering, The University of Suwon, Hwaseong 18323 , South Korea(e-mail: kyungsik@suwon.ac.kr).employed to complement the deep learning model while collec tingadditional data samples to improve model, enhancing its per formance.In this paper, we propose a self-improving interference man age-ment framework based on deep learning with uncertainty quan tiﬁ-cation. Within this framework, we introduce a method to quan tifythe uncertainties associated with solutions made by the dee p learningmodel. Leveraging this quantiﬁed uncertainty, we devise a q ualifyingcriterion to evaluate the trustworthiness of the model’s so lutionsin terms of system performance. Using this criterion, the fr ame-work selectively employs the model’s solutions only when th ey aredeemed trustworthy; otherwise, traditional algorithms ar e employed.Through this iterative process, the framework collects dat a samplesfor situations that the model struggles with, subsequently allowingfor self-improvement using the accumulated data. We demons tratevia experimental results that our proposed framework is eff ective,not only for interference management but also for enhancing thedeep learning model itself. To the best of our knowledge, thi spaper represents the ﬁrst endeavor to design a self-improvi ng deeplearning framework for interference management via uncert aintyquantiﬁcation in the ﬁeld of deep learning.II. D EEPLEARNING -BASED INTERFERENCE MANAGEMENTA. System Model and Problem FormulationWe consider a downlink network comprising /u1D441pairs of single-antenna transceivers, each pair consisting of a base statio n (BS) anda corresponding scheduled user. The set of BSs is deﬁned as N={1,2,...,/u1D441}. Letℎ/u1D45B/u1D45Bdenote the channel gain between BS /u1D45Band itsscheduled user, and ℎ/u1D45B/u1D45Athe interference channel gain from BS /u1D45Ato the scheduled user of BS /u1D45B. The channel gain matrix is deﬁnedasH≔[ℎ/u1D456/u1D457]/u1D456,/u1D457∈N. We assume that the channels main unchangedduring each timeslot. We denote the transmission power of BS /u1D45Bas/u1D45D/u1D45Band deﬁne the vector of transmission powers as p≔[/u1D45D/u1D45B]/u1D45B∈N.Then, the signal to interference-plus-noise ratio (SINR) f or the userof BS/u1D45Bis given bySINR/u1D45B≔|ℎ/u1D45B/u1D45B|2/u1D45D/u1D45B/u1D70E2/u1D45B+/summationtext.1/u1D45A∈N,/u1D45A≠/u1D45B|ℎ/u1D45B/u1D45A|2/u1D45D/u1D45A, (1)where/u1D70E2/u1D45Bis the noise power at that user. The sum-rate of the networkis given by/u1D445(H,p)=/summationdisplay.1/u1D45B∈Nlog(1+SINR/u1D45B). (2)To maximize the weighted sum-rate, a power allocation probl em formanaging downlink interference is formulated asmaxp∈P/u1D445(H,p), (3)whereP≔[0,/u1D443max]/u1D441with/u1D443maxbeing the maximum transmissionpower. The optimal solution for a given His denoted as p∗(H).B. Deep Learning for Interference ManagementIn the literature, a number of algorithms have been develope d toaddress the interference management problem as formulated in (3)with a given channel gain matrix H[1], [2], [3]. Most of these algo-rithms employ an iterative approach, and their effectivene ss has beendemonstrat\n",
      "----------------------------------------------------------------------------------------------------\n",
      "uence and potential advancements in segmentation tasks. Subsequent researches have extendedSAM’s applications across diverse areas [8, 9, 2]. Nevertheless, practical applications have revealedthe limitation of SAM in high-quality segmentation performance, notably characterized by coarsemask boundaries for objects like tennis rackets and chairs, as well as erroneous predictions for detailssuch as kite strings and insect antennae [10].To address the above mentioned issues, HQ-SAM [10] introduces a high-quality token to capturemoredetailsintheimage(seeFig.1(a)),largelyimprovingSAM’ssegmentationqualitybyaddingonlya few parameters. However, the implicit learning approach used in HQ-SAM makes it challenging toimprove SAM’s segmentation capabilities, as it primarily focuses on extracting SAM’s mask decoderfeature for segmentation training, which is isolated from SAM’s overall framework. Some prompt-query-based methods [11] [12] utilize image features to generate fixed sparse prompts (see Fig. 1(b)),which can effectively obtain the location of the target object, but they are difficult to capture thedetailed object information. Additionally, ensemble [13] or augmentation [14] methods reuse theoriginal input sparse prompts, yielding limited gains in challenging areas.Therefore, it is highly desired to develop a network that can directly provide SAM with detailedinformation and improve the mask decoder feature. Intuitively, the most straightforward approachto this end is to provide more detailed annotations, such as additional points or more precise masks.Inspired by this naive intuition, we are wondering if the model could autonomously extract andconvey the details to the SAM, thereby significantly improving SAM’s segmentation quality withoutadditional user input.1arXiv:2401.13051v1  [cs.CV]  23 Jan 2024TrainableEDPEIPoint&boxSparse promptshqtoken   FMEDPEISparse promptsMSparse prompts queriesEDPEIPoint&boxSparse promptsPAMDense promptsDense promptsDense prompts(a) HQ-SAM (c) our PA-SAM (b) RSPrompterFrozenFigure 1: Comparison of different model architectures. ‘E’ means Image Encoder, ‘D’ means MaskDecoder, ‘PE’ means Prompt Encoder, ‘F’ means Feature Fusion Block, and ‘PA’ means PromptAdapter.We make such an attempt in this paper. In specific, we introduce the Prompt Adapter SegmentAnything Model (PA-SAM), a network designed to investigate uncertain areas in images and incor-porate low-level detail information into both dense and sparse prompts to enhance SAM’s learningability for details (see Fig. 1(c)). To capture the details, we propose a prompt-driven adapter toperform adaptive detail enhancement and hard point mining. Unlike conventional adapter [15], theprompt adapter does not optimize image features, but optimize prompt features to extract detailedinformation about the network focal area (contribution 1) . We transform the process of maskrefinement into the learning of a refined token and an uncertain token, enabling the model to be moresensitive to image details in challenging areas (contribution 2) . Additionally, we propose a hardpoint mining method based on Gumbel top-k operation, providing direct detailed guidance to themodel (contribution 3) . During training, PA-SAM freezes the SAM component and only trains theprompt adapter, thereby preserving the powerful object localization capability of the original SAMwhile generating high-quality segmentation maps. Our method achieves leading performance on thehigh-quality dataset HQSeg-44K, with an improvement of 1.7%in mIoU and 2.7%in BmIoU overthe previous state-of-the-art. It also demonstrates promising results on zero-shot segmentation andopen-set segmentation datasets.2 Method2.1 Brief Review of SAMThe segment anything model (SAM) [7] is a foundational model with powerful zero-shot segmentationcapabilities, capable of outputting reasonable masks based on weak annotations. SAM consists of thefollowing components: an image encoder, a mask encoder, a prompt encoder, and a mask decoder.The image encoder transforms input images into 64×64encoded features. The mask encoder encodesmasks to dense prompts, while the prompt encoder encodes points or bounding boxes to sparseprompts. The mask decoder, composed of multiple layers of attention, interacts image featureswith prompt features to output the final segmentation map. Though SAM has demonstrated strongcapability in segmentation tasks, its segmentation quality heavily depends on whether the promptsinput to the mask decoder can carry detailed information. In the absence of detailed guidance, SAMperforms poorly in achieving high-quality segmentation.2.2 Overall Framework of PA-SAMTo capture high-quality detailed information, our idea is to transform the image details into multi-granularity prompt features and pass them to the mask decoder. That is, we fine-tune SAM ina prompt-driven manner. Based on this idea, we propose a trainable prompt-driven adapter andintegrate it into SAM, resulting in our Prompt Adapter SAM \n",
      "----------------------------------------------------------------------------------------------------\n",
      "detection. Our codeis publicly available at: https://github.com/AhaChang/MITIGATE.CCS CONCEPTS•Computing methodologies →Active learning settings ;•Mathematics of computing →Graph algorithms ;•Security andprivacy→Software and application security .Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from permissions@acm.org.Conference’17, July 2017, Washington, DC, USA©2024 Association for Computing Machinery.ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00https://doi.org/XXXXXXX.XXXXXXXKEYWORDSAnomaly Detection, Active Learning, Graph Neural NetworksACM Reference Format:Wenjing Chang, Kay Liu, Kaize Ding, Philip S. Yu, and Jianjun Yu. 2024.Multitask Active Learning for Graph Anomaly Detection. In Proceedingsof ACM Conference (Conference’17). ACM, New York, NY, USA, 11 pages.https://doi.org/XXXXXXX.XXXXXXX1 INTRODUCTIONIn light of the proliferation of the World Wide Web, graph-structureddata has become increasingly pervasive. Concurrently, graph ma-chine learning techniques have been extensively employed in vari-ous web mining tasks, such as recommendation systems [ 41], com-munity detection [ 16], traffic forecasting [ 44], etc. To ensure therobustness and security of such graph learning-based applicationsin web environments, graph anomaly detection serves as an indis-pensable component. Graph anomaly detection aims to identify ab-normal substructures (e.g., nodes) in graphs that exhibit significantdeviations from established norms. It finds extensive applicationsin capturing high-risk entities and behaviors, including but notlimited to spam detection [ 29], financial fraud detection [ 38], andfake news detection [11].In accordance with the insights presented in [ 9,22], unsupervisedmethods heavily rely on the underlying data distribution to deriveoutlier patterns. Consequently, these methods may exhibit unstableperformance when faced with data that contains specific domainknowledge or deviates from the assumed distribution. However,the intricate nature of graph structures, along with the high cost ofmanual annotation for both normal and anomalous nodes, preventsthe collection of abundant ground truth labels, thereby limiting thefeasibility of applying fully supervised learning approaches. Thiscontradiction necessitates the exploration of alternative learningparadigms that can efficiently leverage limited supervision signalswhile also accommodating the complexities inherent in graph data.Given the considerable expense of acquiring ground-truth labelsfor anomaly detection, it is a judicious choice to leverage the exist-ing relatively abundant availability of labels for other graph learn-ing tasks. In the application of graph learning, anomaly detectioncan enhance the stability of various tasks (e.g., node classification)by filtering out anomalies. Conversely, these tasks can serve asauxiliary tasks for anomaly detection and reciprocally provide ex-ternal information (e.g., classification uncertainty) for augmentingarXiv:2401.13210v1  [cs.LG]  24 Jan 2024Conference’17, July 2017, Washington, DC, USA Trovato and Tobin, et al.the efficacy of anomaly detection. Besides, these auxiliary tasksinherently contain general information that can be mutually lever-aged, providing an indirect supervision signals when the anomalydetection task is deficient in annotation [5, 46].Furthermore, to effectively leverage limited direct supervisionsignals for anomaly detection, some semi-supervised methods havebeen proposed [ 10,36,38]. These methods aim to enhance thelearning of anomalous patterns based on the known anomalousnodes. The underlying assumption of these methods is that a subsetof nodes including both normal and anomalous nodes have beenannotated for training, and the labeled data is overall balanced.Nevertheless, it is non-trivial to acquire such an ideal training setfrom an unlabeled graph, one that contains sufficient knowledge fordistinguishing normal and anomalous nodes, especially when con-strained by a limited labeling budget. Active Learning (AL) paves apromising way for addressing the labeling problem, as it enablesmodels to enhance their learning efficiency by actively requestingthe labels in training data [ 1,3,32,45]. It has also been appliedin anomaly detection tasks [ 7,13,14], aiming at discovering moreanomalies based on heuristic query strategies, such as uncertainty-based, diversity-based, and anomaly score-based strategies. In thisway, a selection of samples that is more likely to contain a rela-tively higher proportion of\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ek to refine, so that each entity is encouraged to voluntarily participate?∗Supported by NSF awards CCF-2008688 and CCF-2047288.†Supported in part by NSF grants CCF-1844939 and CCF-2121745.‡Supported by NSF grant CCF-2113798.1arXiv:2401.13053v1  [cs.GT]  23 Jan 2024Towards this end, we assume agents have diverse ML models for decision making that theyseek to refine with data. At the same time, each agent possesses data that may be relevant tothe tasks of other agents. As an example, a retailer may have sales data for certain products incertain geographic locations, but may want data for related products in other markets to make abetter prediction of sales trends. This data could be in the hands of competing retailers. Similarly,a hospital system seeking to build its in-house model for a disease condition based on potentiallyidiosyncratic variables may want patient data from other hospital systems to refine this model.In our paper, we assume the participants in the market have no value for money. We furtherassume that the agents seeking data are the same as those seeking to refine models. Therefore weconsider an exchange economy without money as opposed to a two-sided market with buyers andsellers. This is a reasonable assumption for non-profits such as hospital systems or universities,where student or patient data can be “exchanged” but not sold for profit. Though we seek amarket design without money, the agents in the market still need to be incentivized to voluntarilyparticipate in the market and exchange data, and this is the main focus of our design.In the settings we consider, data is often sensitive and private [3, 16]. As in [3], we addressthis issue by having a trusted central entity (or clearinghouse) with who all agents share their MLtasks and datasets. This entity can refine or retrain the model for one agent using samples of thedata from other agents. For instance, if each agent specifies the gradient of their loss function andtheir in-house model parameters, the central entity can run stochastic gradient descent to updatethe parameters using the other data. This way, the central entity can efficiently compute the lossof the refined model and hence the utility of a collection of datasets to a model. By using a utilitysharing method such as Shapley value that has been well-studied in machine learning [17, 18], theentity can use the same process to attribute this utility gain fairly to the agents that contributeddata to the refinement. The entity then sends the refined models back to the respective agents,preserving data privacy in the process.1.1 Model and ResultsOur approach to market design for data exchange without money is to view it as utility balancing– to encourage voluntary participation, an agent should contribute as much utility to other agentsas they receive from them. In market design terminology, this corresponds to having a commonendogenous price per unit utility bought or sold, so that each agent is revenue-neutral. This canbe viewed as a form of fairness in the exchange. The goal of the central entity is to find the rightamount of data any set of agents should exchange, so that the overall solution is utility balanced.The solution is randomized, where for each agent, we compute a distribution over sets of otheragents. When this agent chooses a set from this distribution to obtain data from, then utilitybalance holds in expectation (or interim ). We motivate interim balance in settings where thesame agents trade over many epochs so that the total utility across these epochs approaches itsexpectation. The objective of the central entity could be to either maximize total utility of agents(social welfare maximization), or core-stability among coalitions of agents.We call this overall problem the Data Exchange Problem . We study computational com-plexity and existence results for the Data Exchange Problem under natural utility functions andhow that utility is shared among contributors. At a high level, our main results are the following.1. We present a formal model for the Data Exchange Problem in Section 2 based on interimutility balancing, codifying the objectives of welfare maximization and stability.22. We show NP-Hardness (Section 3) and polynomial time approximation algorithms for wel-fare maximization (Sections 4 and 5). We present a logarithmic approximation in Theorem 6for submodular utilities and a general class of sharing rules that includes the well-knownShapley value, and a PTAS for concave utilities with proportional sharing in Theorems 6and 7.3. In Section 6, we show that the same solution framework also handles the case where thebalance condition can be relaxed by compensating or extracting payment from agents usinga convex function on the extent of imbalance.4. We show the existence of core stable and strategyproof solutions and the trade-offs achievablebetween these notions and welfare in Section 7. We also show that a specific type of stableand strategyproof solution\n",
      "----------------------------------------------------------------------------------------------------\n",
      "mallchange in the weights w, one can get an equivalent changein the loss by changing the input activations, x, instead.That is, ∆L(x0, w0) = L(x0+δx, w 0)−L(x0, w0) =L(x0, w0+δw)−L(x0, w0). This observation of activity-weight duality leads to the following learning procedure,which we call input space training (IST), based on manipu-lation of the inputs:1. Make a small change in the inputs xthat results in areduction of the loss.2. Use the duality between weights and activations to de-termine a change in the weights that gives a reduction inthe loss for the original inputs.To carry out this procedure, we need to accomplish twotasks - find a change in inputs that reduces the loss, andfind an equivalent change in weights that reduces the loss onthe original inputs. The paper by Feng and Tu [8] providesa method for accomplishing the second task. They notethat there are, in general, more weight parameters than in-puts, and so there are effectively unlimited possible weightchanges that are equivalent to a given change in the inputs.They provide a minimum weight change solution to iden-tify a unique weight update, as a linear combination of thecurrent weight values.Feng and Tu use the activity-weight duality principle forthe purposes of quantifying how networks generalize, butdo not use it to train a network. One could derive a trainingscheme from their equations but it would be slow and com-putationally expensive. In this paper, rather than traininga network from scratch using input space training, we pro-pose a method which takes a classifier network pretrainedusing standard back-propagation methods and then refinesit using a one-shot (non-iterative) IST method. Inspired byactivity-weight duality, our IST refinement method has twostages: first we perturb the training set to reduce the loss,and second, we adjust the weights by performing a domainadaptation step that adapts from the perturbed dataset to theoriginal dataset.1arXiv:2401.13212v1  [cs.CV]  24 Jan 20242. Curriculum LearningThe first approach we propose for altering the training setto reduce loss is based on curriculum learning . Curricu-lum learning, first proposed by Bengio et. al [3], aims toimprove the speed and accuracy of network training, bypresenting data samples from the training set in an orderedfashion. Typically, easier samples are presented before dif-ficult samples as the training progresses.It is not obvious how to properly define the notions of“easy” and “hard”, however, and indeed many different def-initions exist. Some of these definitions are based solely onthe structure of the input examples, without considerationof the network being trained. Table 2 in the survey paper ofWang et. al [28] lists no less than nineteen different typesof pre-defined input difficulty measures that have been usedto guide curriculum learning. But the difficulty of an in-put can also depend on the network being trained. Prob-lems that some networks find difficult may be easy for othernetworks, and vice-versa. So-called Self-Paced-Learning(SPL) methods, such as proposed by Kumar et. al [13] usedynamic measures of problem difficulty that are providedby the network itself as it trains. In the SPL method, easyproblems are defined as those problems for which the net-work’s training loss is less than a (dynamically changing)threshold value.We propose to use the curriculum separation of the train-ing set into easy and hard problems, as defined by the train-ing loss threshold, for our IST approach. We considerthat, over the original training set, our pre-trained networkachieves a particular loss value. If we remove the trainingset samples for which the loss is above a threshold, thenwe are left with a (modified) training set for which the av-erage (and maximum) loss is less than that of the originaltraining set. To avoid having to set a suitable thresholdvalue, we propose using the pre-trained network to defineeasy vs. hard using the simple expedient of consideringeasy problems to be ones the network classifies correctly.This will naturally result in a separation of input samplesbased on loss. We use this procedure to satisfy the first stepof our IST process - altering the inputs to reduce the loss.Even though we are not altering individual samples in thismethod, the collective of the samples on a batch level isbe-ing altered.3. Adversarial CorrectionWe can take the curriculum approach outlined in the previ-ous section a step further, by doing what we call adversarialcorrection to further modify the training set. This results ina larger set of inputs for which the loss is reduced than thecurriculum approach.The concept of adversarial attack is well known in themachine learning community [15]. Given a classifier net-work trained on a particular dataset, an adversary can mod-ify an input slightly in such a way that the network gives adifferent classification output. One thing to keep in mind,however, especially for smaller networks, is that networksfrequently give wro\n",
      "----------------------------------------------------------------------------------------------------\n",
      "dge of a hypergraph may contain an arbitrary num-ber of nodes (see Fig. 5 in Appendix A for an illustration).In the special case when each hyperedge contains just twonodes, the hypergraph reduces to a graph. Each hyper-edge of a hypergraph is considered a clique in a graph.We can therefore convert a hypergraph into a graph byexpanding each hyperedge. However, hypergraphs containmore information than what can be encapsulated into itsexpanded graphs. If we simply expand a hypergraph intoa graph, the explicit information of the cliques is lost.Although the conversion from hypergraphs to graphs isreversible in theory, the NP-completeness of detectingmaximal cliques in a graphs renders it irreversible in prac-tice. Furthermore, the expansion of hyperedges can becomputationally expensive and memory-intensive consid-ering that a hyperedge of Nnodes yields N(N−1)/2undirected edges in a graph. It is hence advantageous todirectly work with hypergraphs whenever possible ratherthan with their expanded graphs.One of the central problems in graph theory is thequantitative determination of graph node distances. The∗lienzhi@amazon.com†bhf@amazon.comliterature has multiple algorithms that aim to achieve this,such as DeepWalk[ 1], graphSAGE[ 2], hitting times of ran-dom walks[ 3] and frustrated random walks[ 4], among oth-ers. We can easily generalize DeepWalk to hypergraphs,yet for the other algorithms, such generalization is highlynon-trivial. In this paper, we generalize frustrated ran-dom walks to hypergraphs, and show that the approachis on par with the performance of DeepWalk even forcomplex hypergraphs. There are four reasons that moti-vate using frustrated random walks (FRW) as opposedto DeepWalk. First, in applications where the goal isto find the nearest neighbors of a few nodes in a largehypergraph, FRW is a preferable and faster option thanDeepWalk. Second, FRW conveniently gives a closed-formand interpretable solution for node distances, a solutionthat is impossible to obtain using any deep-learning basedmethod. Third, FRW does not require any parametertuning, whereas DeepWalk requires heavy investment inparameter tuning. Finally, and unlike in DeepWalk, thenode distances of FRW are asymmetric, rendering it moresuitable to describe real-world relationships which aregenerally asymmetric and non-reflective.More formally, a hypergraph consists of nodes andhyperedges. Each hyperedge is a subset of the node setV. For clarity purpose, we use in this paper Latin lettersto indicate node indices and Greek letters to indicatehyperedge indices. The incidence matrix of a hypergraphis defined as:eiα=(w,if vertex vi∈Eα0,otherwise(1)arXiv:2401.13054v1  [cs.SI]  23 Jan 20242In the above definition, wis the weight of vertex viinhyperedge Eα. If the hypergraph is unweighted, thenw= 1always holds. If we think of vias a memberof a community Eα, then eiαcan be thought of as theloyalty of vitoEα. By definition, the degree of a nodeviisDi=Pαeiα, and the degree of a hyperedge isδα=Pieiα. We can think of δαas the adhesiveness ofEα.Researchers have long used random walks to study hy-pergraphs. In Ref. [ 5], the authors generalized spectralclustering [ 6–8] from graphs to hypergraphs and gave theiralgorithm a random walk interpretation. It is howevernoted that the hypergraph random walks defined in Ref.[5] are no different than the random walks performedon expanded graphs [ 9,10]. To take advantage of thehigher order structure in hypergraphs, we need to takehyperedge degree into account when performing randomwalks. Since a hyperedge in a hypergraph represents anadhesive community, it is argued in [ 11] that a randomwalker roaming on a hypergraph should show preferencetowards hyperedges of higher degrees (stronger adhesive-ness). This is not the only way to generalize random walksfrom graphs to hypergraphs, but it does demonstrate itsadvantages, as shown in Ref. [ 11]. We also note that inRef. [11], the authors assume that all the hypergraphnodes have the same weight, thus restricting their resultsonly to unweighted hypergraphs. Here in this paper, wewill generalize the random walks described in Ref. [ 11]to weighted hypergraphs, and introduce the concept offrustrated random walks on hypergraphs. We show thatfor heavily-weighted and scale-free hypergraphs, the def-inition of which will be given later, frustrated randomwalks are more suitable for computing node distances.II. A UNIFIED FRAMEWORK FORCALCULATING EXPECTED HITTING TIMES OFRANDOM WALKSWith the abundance of research on random walks onhypergraphs, we note that the vast majority of previouswork has focused on the Laplacian matrix. Spectral clus-teringofeigenvectorsofLaplacianmatrices[ 6,8]naturallyleads to image segmentation and community detectionin hypergraphs [ 12,13]. Furthermore, the eigenvectorsof a Laplacian matrix yield node embeddings which en-able us to apply powerful machine learning algorithmsto perform node classification on hypergraphs. Since thestudy of the Laplacian \n",
      "----------------------------------------------------------------------------------------------------\n",
      "encoded representations, based on the representations’ var-ied sensitivity to different auxiliary features [6, 27, 51, 59].However, these methods rely on image-based embeddingsand thus are limited to only identifying certain kinds of biasClassification target: Kite CSBD reasons two feature clusters: 92.4% images with “person” label 7.6% images without “person” label Accuracy: 0.979 Accuracy: 0.947 many kites, kite flying, colorful kites, paper kites, … these people, individuals, guys, so many people, … Correlation: 0.1023 Figure 1. Sensitive features are everywhere: Small objects whichco-occur frequently with the target can affect model prediction, forexample, kites and people in MS-COCO images. Sensitive featureslike this are of multiple types and may cause different downstreambiases. Our method aims to discover comprehensive sensitivecorrelations in a dataset based on common-sense descriptions, andtreat biases which have not been explored in literature.that could be captured in that embedding space. For example,previous studies have shown that visual features that occupysmaller spatial area can lead to worse representations [ 54].Therefore, subtle facial features such as eyeglasses framesor small object features like a keyboard nearby a cat can beoverlooked for bias modeling. These observations suggestthat modeling with additional data modalities, specificallytext descriptions of images, may be beneficial in bridgingthis gap. Such an approach of “common-sense reasoning”by natural language [ 5,13,23,43] allows high-level abstractunderstanding of images and reasoning for subtle imagefeatures, thus can facilitate better dataset diagnosis and biasdiscovery than relying on the image modality alone.There have been some early explorations in this direction.For example, given that text embedding is a good proxyto image embedding in representation space [ 66], auxiliaryfeatures to the target such as ocean and forest for waterbirdrecognition are expressed as text sets. Each text-based fea-ture is encoded and aligned to the model’s inner state to mea-sure the feature’s influence [ 59,66]. However, the use casesof the existing common-sense bias modelings are limited in1arXiv:2401.13213v1  [cs.CV]  24 Jan 2024two major aspects: First, though text-based features can bemore diverse than traditional image-based patterns, they arelimited by the prior knowledge of the humans writing themand cannot expose unlabeled1or subtle features in a dataset.Second, the additional step of embedding space alignmentusing models like CLIP [ 43] or generative models [ 45] lacksthe ability to control fine-grained image regions with text,and may inherit extra bias from the models [8, 46].To bridge the gap, we propose a novel method ofdescription-based reasoning for feature distribution and po-tential model bias called Common Sense Bias Discovery(CSBD), shown in Figure 2. Taking a description corpusof images (for example, descriptive captions), we unpack itinto a hierarchy of “categories” (major subjects in an image)and subordinate “features” (different attributes or states ofa subject) via text embedding clustering. The features areextracted from descriptions’ semantic components so theyrepresent image content comprehensively, not limited byprior knowledge or cross-modal alignment. Then, correla-tions between features are quantified based on their occur-rence across all data samples. It should note that discoveredcorrelated features are not necessarily bias: for example, acorrelation between “ teeth ” and “ smile ” in a dataset offace images is both expected and entirely benign. Therefore,we maintain a human-in-the-loop component in our pipelineto identify sensitive/spurious correlations. However, afterthe identification step, our method does not need a human-in-the-loop to treat the potential bias these correlations mightcause. We summarize our contributions as follows:1.A novel common-sense reasoning approach that discovershuman-interpretable “feature clusters” (beyond the imageembedding level) existing in image datasets.2.Based on the clusters, a formulation to derive pairwiseimage feature correlations, order them by significance,and allow human domain experts to identify sensitivecorrelations for further intervention.3.Empirical evidence that our method discovers subtle sen-sitive features and model biases for classification tasks,which to the best our knowledge has not been previouslyidentified and addressed. Furthermore, we adjust datasampling weights calculated by our method and achievestate-of-the-art results bias mitigation results.2. Related Works2.1. Bias discoveryUnsupervised bias discovery. Many recent studies havefocused on waiving the need for sensitive group annotationto achieve model robustness between groups. One approachis to assume that easy-to-learn data samples lead to learningshortcut attributes, thus resulting in biased classifiers. These1E.g. the MS-COCO dataset is only labeled for 80 objects, but manyother unlabeled\n",
      "----------------------------------------------------------------------------------------------------\n",
      "020). While Qur’an QA 2023 shared task Bisa ranking-based MRC over the Holy Qur’an, whichis the second version of Qur’an QA 2022 sharedtask (Malhas et al., 2022; MALHAS, 2023).This paper presents our approaches to solvethe two tasks AandB. For task A, we exploreboth dual-encoders and cross-encoders for ad hocsearch (Yates et al., 2021). For task B, we in-vestigate LMs for extractive QA using two learn-ing methods (Devlin et al., 2019). For both tasks,we utilize various pre-trained Arabic LM variants.Moreover, we adopt external Arabic resources inour fine-tuning setups (MALHAS, 2023). Finally,we employ an ensemble-based approach to accountfor inconsistencies among multiple runs. We con-tribute to the NLP community by releasing ourexperiment codes and trained LMs to GitHub1.In this work, we address the following researchquestions2:RQ1 : What is the impact of using external re-sources to perform pipelined fine-tuning?RQ2 : How does ensemble learning improve theperformance obtained?RQ3 : What is the effect of thresholding on zero-answer questions?RQ4A: What is the impact of hard negatives on thedual-encoders approach?RQ5B: What is the impact of multi answer lossmethod on multi-answer cases?RQ6B: How is post-processing essential forranking-based extractive question answering?The structure of our paper is as follows: Sec-tions 2 and 3 provide an overview of the datasetsused in our study. In Section 4, we present thesystem design and implementation details for bothtasks. The main results for both tasks are presentedin Section 5. Section 6 focuses on the analysis anddiscussion of our research questions RQs. Finally,Section 7 concludes our work.1https://github.com/mohammed-elkomy/quran-qa2A superscript at the end of a RQ refers to one of the tasks.No superscript means the RQ applies for both tasks.arXiv:2401.13060v1  [cs.CL]  23 Jan 2024Split Training Development# Question-passagerelevance pairs972 160# QuestionsMulti-answer 105 (60%) 15 (60%)Single-answer 43 (25%) 6 (24%)Zero-answer 26 (15%) 4 (16%)Total 174 25Table 1: Task Adataset relevance pairs distributionacross training and development splits. We also includethe distribution of answer types per split.2 Task A Dataset DetailsQur’an QA 2023 shared task Aserves as a test col-lection for the ad hoc retrieval task. The divine textis divided into segments known as the ThematicQur’an Passage Collection (QPC), where logicalsegments are formed based on common themesfound among consecutive Qur’anic verses (Malhaset al., 2023; Swar, 2007). In this task, systemsare required to provide responses to user questionsin MSA by retrieving relevant passages from theQPC when possible. This suggests there is a lan-guage gap between the questions and the passages,as the passages are in CA. Table 1 presents thedistribution of the dataset across the training anddevelopment splits. The majority of questions inthe dataset are multi-answer questions, meaningthat systems can only receive full credit if theyare able to identify all relevant passages for thesequeries. Additionally, Table 1 provides informa-tion on zero-answer questions, which are unan-swerable questions from the entire Qur’an. (Moreinformation about the dataset distribution of topicsin Appendix A.1)Task Ais evaluated as a ranking task using thestandard mean Average Precision (MAP) metric.(Additional information about the evaluation pro-cess including zero-answers cases can be found inAppendix A.2)3 Task B Dataset DetailsQur’an QA 2023 shared task Bis a ranking-based SQuADv2.0-like MRC over the Holy Qur’an,which extends to the Qur’an QA 2022 (Malhaset al., 2022; Rajpurkar et al., 2016). The datasetis also referred to as Qur’an reading comprehen-sion dataset v1.2 (QRCDv1.2). The same questionsfrom task Aare organized as answer span extrac-tion task from relevant passages (Malhas and El-sayed, 2020; Malhas et al., 2022). (See the datasetdistribution of topics in Appendix A.1)Table 2 depicts the distribution of dataset pairsSplit Training Development# Question-passage-answerTriplets1179 220# Question-passagePairsMulti-answer 134 (14%) 29 (18%)Single-answer 806 (81%) 124 (76%)Zero-answer 52 (5%) 10 (6%)Total 992 163Table 2: Task Bdataset pairs and triplets distributionacross training and development splits. For questions-passage pairs, we show the distribution of answer types.and triplets across the training and developmentsplits. In addition, the table presents the distribu-tion of answer types for the dataset pairs.Although zero-answer questions account for 15%of the questions in task Atest collection, they onlycontribute to 5% of the question-passage pairs intask B. Furthermore, task Bhas a limited num-ber of unique questions in comparison to their cor-responding question-passage pairs as seen fromTables 1 and 2, respectively. As a consequence,task Bcan have repeated questions and passagesamong different samples and can be even leakedamong training and development splits (Keleg andMagdy, 2022). Keleg and Magdy (2022) analyze\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AR ship detection datasets demonstrate that our AMANet method is superior to state-of-the-art methods.INDEX TERMS SAR ship detection, adaptive multi-hierarchical attention, deep learning.I. INTRODUCTIONSYNTHETIC aperture radar (SAR) [1]–[3] provides high-resolution imaging capabilities that remain unaffectedby daylight, weather conditions, and other environmentalfactors. This makes SAR an indispensable tool for remotesensing applications. Ship detection in SAR images playsa critical role in various domains such as national defense,maritime management, identification of illicit activities, ma-rine transport monitoring, and coastal security enhancement.However, this task presents significant challenges due to seaclutter, ship size variability, and land clutter interference.Consequently, further research is urgently needed to enhancethe accuracy of offshore vessel detection in SAR images.This research area is both significant and complex, offeringsubstantial practical implications.Convolutional neural networks (CNNs) have been exten-sively employed in visible image object detection [4], deliv-ering remarkable results [5]. When applied to ship detectionin SAR images, these CNN algorithms have proven highlyeffective [6], [7]. Subsequently, the FPN [8] has emerged asa standard solution for detecting ships in multi-scale SARFIGURE 1. The difference between visible and SAR images. The first rowshows visible images, and the second row shows SAR images. The greenrectangles enclose the ground truth.images. Building on the foundation of FPN, later researchhas concentrated on Bi-directional FPN to enhance the rep-resentation of hierarchical features [9], [10]. However, thesemethods require further refinement and enhancement to effec-tively handle extreme-scale changes or scenarios with fewership features. As illustrated in Figure 1, the top row presentsvisible images, while the bottom row features SAR images.SAR images have the distinct advantage of increased sen-sitivity to metallic objects, significantly aiding ship objectVOLUME 11, 2023 1arXiv:2401.13214v1  [cs.CV]  24 Jan 2024X. Ma et al. : AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Networkdetection. However, they offer less color texture and otherdetails when compared to visible images, presenting a uniqueset of challenges.The attention mechanism has gained significant traction inthe field of computer vision. There are three commonly uti-lized attention methods: spatial attention, channel attention,and combined spatial and channel attention. Spatial attentionmethods [11], [12] generate attention masks across spatialdomains, which are employed to select crucial spatial regionsor directly predict the most relevant spatial positions. Channelattention methods [13], [14], on the other hand, generateattention masks across the channel domain, which are usedto select essential channels. Methods that combine spatialand channel attention [15], [16] compute temporal and spatialattention masks separately or produce a joint spatiotemporalattention mask to focus on informative regions. However,these attention methods have shown limited improvement inSAR images, which typically have fewer color and texturefeatures. This limitation is particularly evident in ground clut-ter near the coast, significantly impacting object detection.As illustrated in Figure 1, there is a high similarity betweenground clutter and ships in near-shore scenes. Unlike visibleimages, ships in SAR images cannot be distinguished throughcolor and other features, presenting a unique challenge fordetection algorithms. Further, detecting small and coastalships in coastal environments with limited features and clutteris difficult.In order to meet the above challenges, we propose a novelAMAM designed to learn multi-scale features and adaptivelyaggregate salient features from various feature layers, evenin complex environments. Our method involves several keysteps. First, we fuse information from adjacent feature layersto enhance the detection of smaller targets, achieving multi-scale feature enhancement. Next, to mitigate the adverseeffects of complex backgrounds, we dissect the previouslyfused multi-level features on the channel, individually ex-cavate salient regions, and adaptively amalgamate featuresfrom different channels. Subsequently, we introduce a novelAMANet by embedding the AMAM between the backbonenetwork and the FPN. The AMAM can be readily insertedbetween different frameworks to improve object detection. Fi-nally, extensive experiments on two large-scale SAR ship de-tection datasets demonstrate the superiority of our AMANetmethod compared to the state-of-the-art method, highlight-ing its potential for advancing ship detection in challengingenvironments. The main contributions of this article are asfollows:•This paper presents a plug-and-play AMAM to learnmulti-scale features and adaptively aggregate salient fea-tures from various feature layers.•We propose a novel\n",
      "----------------------------------------------------------------------------------------------------\n",
      " little chance to use multiple traverses to sample the environment systematically and how to find landscape saddles for least -effort transitions to traverse.  One Sentence Summary:   Contact forces sensing allows reconstruction of potential energy landscapes for robot traversal of cluttered large obstacles.   2  INTRODUCTION  Sensing facilitates locomotor planning and control in mobile robots and animals  (Fig. 1A, B ). For example, sensors that enable machine vision (e.g., cameras, radars, LiDAR (1)) to provide a geometric map of the environment (2–6). Based on this map, the robot can construct a navigation function (7, 8) (or an artificial potential field  (9)), with high potential regions representing obstacles and low potential minimum  representing its goal, and plan and follow a gradient descent path to reach a goal while avoiding sparse obstacles (10–13). To help legged robots follow planned paths, studies in animal sensorimotor control a nd bio-inspired robots show that animals and robots use tactile and proprioceptive sensing as feedback signals to controllers that stabilize running and walking around limit cycles (14–20). These advances have greatly facilitated legged robot locomotion on flat ground and terrain with small obstacles (unevenness << 1 leg length) (21). Further enabling legged robots to traverse even larger obstacles (comparable to body size) by physically interacting with them will extend their accessible terrains and facilitate important applications, such as search and rescue in rubble (22, 23), environmental monitoring through natural terrain (24, 25), and planetary exploration through large Martian rocks (26–28). Recent systematic research of the forest floor -dwelling discoid cockroach and its robotic models traversing diverse types of large obstacles presenting distinct locomotor challenges have begun to reveal physical principles. The animal or robot can self -destabilize far away from limit -cycle -like walking and running by physically interacting with the obstacles to transition across different locomotor modes —effectively finding easier pathways —to traverse cluttered large obstacles (29–31). The b ody-obstacle physical interaction results in a potential energy landscape . Locomotor modes emerge as the system was attracted to landscape basins separated by potential energy barriers (21, 30–32). Thus, the locomotor transitions are strenuous barrier -crossing transitions between landscape basins. Some modes can lead to traversal, while others lead to being trapped (21, 30–33). To facilitate transitions across modes to traverse, the animal or robot can generate kinetic energy fluctuation from oscillatory self -propulsion, which helps stochastically overcome the barrier to escape from one basin 3  and reach another (31). They can also actively adjust their bodies and appendages to facilitate locomotor transitions by steering on the landscape, modulating the transition barrier, or even adding/removing basins (32–35). Analogous to the artificial potential fields and navigation functions as a foundation for sparse obstacle avoidance using geometry -based environmental maps, we envision that this potential energy landscape approach will provide mechanics -based environmen tal maps for robots to compose locomotor transitions across modes to traverse heterogeneous cluttered large obstacles (for a review, see (30)).  Fig. 1. Locomotor transitions of animals and robots in complex terrain and active sensing behavior.  (A and B) Illustrative locomotor transitions of (A) a cockroach traversing rugged natural terrain and (B) a robot traversing an earthquake rubble for search and rescue. ( C) Cockroaches traverse d cluttered  grass -like 4  beams with small gaps (< body width) . They often transition from pitching up  against the beams (left, blue) to rolling through the gap (right, red) (31). (D) A minimalist,  feedforward robot can use kinetic energy fluctuation of body oscillation to cross the barrier  to make a transition from pitch (left, blue) to roll mode (right, red), even without planning . (E) A snapshot of potential  energy landscape over body pitch -roll space resulting from body -obstacle physical interaction  (when the body is close to the obstacles), with a pitch basin and a roll basin separated by a potential  energy barrier. The animal/robot’s pitch or roll (A) mode emerges as the system is attracted  to the pitch or roll basin (31). To traverse, the animal/robot must escape entrapment in the pitch  basin/mode, cross the potential energy barrier, and reach the roll basin/mode (31). White arrow shows least -effort transition from pitch (blue) to roll (red) basin via the saddle point (orange) on the potential energy barrier (black dashed curve). ( F) A metaphor of locomotor transition using a mountain climbing example. To climb over a mountain effectively, people go to the saddle point (yellow arrows) instead of climbing up large barriers (red arrow). Similarly, locomotor t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Things)devices, andthe rapid development of communication technology led to a boom of various on-device intelligenceapplications, such as connected autonomous vehicles, smart homes, wearable devices, and mobileAI. It is crucial to securely and efficiently leverage the massively distributed data to succeed inthese burgeoning tasks. Federated Learning (FL), an emerging distributed learning paradigm thatscales on-device learning collaboratively, has gained increasing popularity due to its communicationefficiency, massive decentralized computations, agile personalized service, and privacy preservation[52, 53, 55].Federated Learning is orchestrated by a central server who oversees the clients possessing data,e.g., mobile devices or a group of organizations. A typical FL process involves a series of alternatetraining and communication rounds. During the training round, each client performs local trainingby consuming its local data. The client models are aggregated by the orchestration server during thecommunication round and then broadcast to the clients. We refer to this type of process as the localoptimization method . For example, Federated Averaging ( FedAvg , [90]), also known as Local SGDor Parallel SGD [ 29,86,148,150], applies SGD on local data for local training, and occasionallyaggregate the information by averaging the parameters.One of the reputed advantages of the local optimization methods is the potential to improvecommunication efficiency since the client models may be aggregated infrequently. The communicationprocess is widely acknowledged as the major performance bottleneck of FL applications due to the vastnumber of participants, the relatively large model size, and the unreliable connection of client devices.Unlike the classic datacenter setting where compute nodes and backbone networks are powerful androbust, the devices in FL are usually battery-powered and wirelessly connected. Communication oversuch devices is costly, unstable, and subject to high latency. Hence, understanding and improvingcommunication efficiency have been one of the primary questions since the inception of FL.Despite the simplicity and popularity of local optimization methods, a thorough theoretical un-derstanding has not been established. It is not clear whether, when, and why local optimizationmethods may provably improve communication efficiency. In this dissertation, we aim to advancethe theoretical foundation of local optimization methods by1. Establishing sharp understanding of the existing FL algorithms.12. Improving the efficiency of FL by principled acceleration.3. Extending FL algorithms to more general, regularized settings.1.1Sharp Bounds for Federated Averaging and Continuous Perspec-tiveIn Chapter 2, we establish sharp lower bounds for homogeneous and heterogeneous FedAvg , themost prominent local method in Federated Learning. By solving this open problem, we highlightthe obstacles to FedAvg , and show how FedAvg can converge faster on problems with third-ordersmoothness. This chapter is based on a joint work with Margalit Glasgow and Tengyu Ma, publishedin AISTATS 2022 [48].The characterization of local optimization methods such as FedAvg is one of the most importanttopics in distributed optimization. Numerous existing works have aimed to determine the convergencerate of FedAvg in various settings [ 70,78,119,121,131,132], though early analysis of FedAvgpreceded the proposal of Federated Learning, typically under the name of Local SGD or parallelSGD [64,88,111,113,148,150]. The primary focus of early literature is the special case of one-shotaveraging, in which only one round of averaging (communication) is conducted at the end of theprocedure. Despite the joint efforts, even under the simplest setting (convex, smooth, homogeneous,and bounded covariance; see Assumption 2.1), the state-of-the-art upper bounds for FedAvg due to[70] and [132] do not match the state-of-the-art lower bound due to [ 132]. This gap suggests that atleast one side of the analysis is not sharp. Therefore, a fundamental question remains:Does the current convergence analysis of FedAvg fully capture the capacity of the algorithm?Our first contribution is to answer this question definitively under the aforementioned assumptions.In Section 2.3, we establish a sharp lower bound for FedAvg that matches the existing upper bound(Theorem 2.8), showing that the existing FedAvg analysis is notimprovable. Moreover, we establisha stronger lower bound in the heterogeneous setting, Theorem 2.10, which suggests the best-knownheterogeneous upper bound analysis [131] is also (almost)1not improvable.Our proofs highlight the limitation of FedAvg , yielding these slow convergence rates. In Section 2.2,we show that our lower bound analysis stems from a notion we call iterate bias , which is definedby the deviation of the expectation of the SGD trajectory from the (noiseless) gradient descenttrajectory with the same initialization (see Definition 2.5 for d\n",
      "----------------------------------------------------------------------------------------------------\n",
      "as a technical report in theComputing Science Department of the University of Alberta ( TR77-2, September 1977,now no longer available). The typography in the TR was poor, a s text formatting hadnot come of age yet. In essence the article shows that deﬁniti ons of (non)randomnessfor inﬁnite sequences in terms of computational nonrandomn ess tests, predictability, and“compressibility” through encodings as programs are equiv alent.I conducted the research leading to the report from 1975-197 7, unaware except inthe last months of the work that a 1970 article in a Soviet jour nal had reported many of“my” theorems, without proofs (Zvonkin & Levin, 1970). I acc ordingly annotated thosetheorems with (Leonid) Levin’s name, before submitting the work for publication. Thepreemptedtheorems werelimited tothesemicomputablechar acterization ofrandomness,while my manuscript also covered the recursively computabl e characterization by C.P.Schnorr. However, while the manuscript was under review, a t reatment of the lattercharacterization appeared in an article by that author.∗The reviewer mentioned thepossibility of extending the article to a more complete surv ey, but I found it diﬃcultto contemplate presenting my hard-won results as mostly a su rvey of results by others.Thus, the report languished as a TR, even though all the proof s were new, and a fewunpublishedpropositionsremained. Certain otherresearc hers inthisarealater suggestedto me that the missing proofs in the Zvonkin & Levin survey sho uld really have entitledme to publication and co-discoverer status for at least the s emicomputable results. Inany event, the existence of the arXiv system has made it possi ble to make the originalversion easily accessible.The apparently new results in the submitted article were The orems 2-4 (on theextent to which semicomputable measures actually allow pro babilistic prediction), Th.6(which seems to slightly strengthen the previously known re sult that there is no recursiveuniversal distribution – “probabilities” assigned by “pre dictors” don’t have to add upto 1), Th.7 (about a nearly optimal additive“predictor” – a nontrivial result, Th.11 (akind of law of large numbers, which the reviewer said was impl icit in some of Schnorr’spublished work, a comment that I did not succeed in conﬁrming ), and Th.13, withCorollaries 1 & 2 (though Levin had proved very closely relat ed results).∗∗I include the symbol glossary that prefaced the TR, even thou gh the meanings of thesymbols are mostly clear from the text.∗Claus-Peter Schnorr, & P. Fuchs, “General Random Sequences and Learnable Sequences,” J. Symb.Logic 42(3), pp.329-340 (1977); also,C.P. Schnorr, “A survey of the theory of random sequences’, i n R.E. Butts and J. Hintikka (eds.),Basic Problems in Methodology and Linguistics , Dordrecht: D. Reidel, pp.193–210 (1977).∗∗In 1988 I communicated these points, along with the TR, to Pro fessor Levin, by then at BostonUniversity.2Symbol GlossarySymbol Meaning0,1 unit strings; or numbers (clear from context)N {0,1,2,...}IR the nonnegative realsIR+the positive realsR the real interval [0,1]B the numbers in Rwith ﬁnite radix-2 representationsQ the rational numbers in [0,1]X the 2-element alphabet {0,1}X∗the concatenation closure of XX∞the semi-inﬁnite binary sequencesupper case Latin letters subsets of X∗orX∗×IR;other than B,N,R,Q,X or, procedure variablesdom domainf(S) {f(x)|x∈S}f−1(S) {x|f(x)∈S}log base 2 logarithmp,p′,p′′,pi predictors or conditional predictorsp∗(x) surplus probability of x=dfp(x)−p(x0)−p(x1)pf the Solomonoﬀ predictor determined by a process fpf preﬁx-freere recursively enumerablerp(x) |x|+logp(x)xand other lower caseletters near the end ofthe Latin alphabet binary sequencex(n) preﬁx of length nof binary sequence xx−ﬁnite binary sequence xwith last digit complementedx(n)−x(n) withnth digit complementedδ an element of IR+λ Church’s lambda operatorΛ the null sequenceµ a measure on subsets of X∞σ σS =/summationtextx∈S2−|x|φ partial recursive function from NtoNor fromX∗×NtoQ∅ the empty set× Cartesian product⊑ is a preﬁx of❁ is a proper preﬁx of⊒ is an extension of❂ is a proper extension of3( ) open interval; syntactic delimiters[ ] closed interval; assertion delimiters (numerical value 1 or 0corresponding to true or false when used as arithmetic expre ssion)/an}bracketle{t /an}bracketri}ht ordered pair−> is an encoding of− ≫ is a reduced encoding of41. IntroductionThedecadebeginningin1963sawthedevelopmentoftwotypes ofcomputational theoriesfor inﬁnite sequences. Theories of the ﬁrst type are concern ed with the algorithmicdistinction between random and nonrandom sequences, while theories of the second typeare concerned with prediction of inﬁnite sequences or induc tive discovery of programsfor them.Relatively little attention has been paid to the connection s between these two lines ofdevelopment, even though the existence of such connections has always been apparent.Indeed, vonMises’(1919) original proposal for characteri z\n",
      "----------------------------------------------------------------------------------------------------\n",
      "s an information-rich intermediaterepresentation for downstream tasks such as∗Work done during XFZ’s internship at Bloomberg AI.News title: Drought puts 2.1 million Kenyans at risk of starvationNews body:[0] National disaster declared as crops fail after poor rains and locusts, whileethnic conflicts add to crisis Last modified on Wed 15 Sep 2021 07.02 BST.[1] An estimated 2.1 million Kenyans face starvation due to a drought in halfthe country, which is affecting harvests.[2] The National Drought Management Authority (NDMA) said peopleliving in 23 counties across the arid north, northeastern and coastal parts ofthe country will be in “urgent need” of food aid over the next six months,after poor rains between March and May this year .[3] The crisis has been compounded by Covid-19 and previous poor rains, itsaid, predicting the situation will get worse by the end of the year, as Octoberto December rains are expected to be below normal levels.· · ·[6] In July, the UN Food and Agriculture Organization in Kenya said thecountry needed 9.4bn Kenyan shillings (£62m) to mitigate the effects of thedrought between July and November. · · ·Event type: Droughts Argument type: DateBaseline model outputs:Flan-UL2: Wed 15 Sep 2021ChatGPT: Wed 15 Sep 2021ULTRA outputsLayer-1 only: {March and May, July, Wed 15 Sep 2021}Layer-1 + LEAFER :{between March and May this year , July, Wed 15 Sep2021}Full model: {between March and May this year , Wed 15 Sep 2021}Table 1: Sample example from DocEE (Tong et al.,2022), and outputs of our ULTRA and select baselinemodels. The ground-truth span for this “Date” argumenttype is between March and May this year .ULTRAis able to correct itself with the help of LEAFERmodule, and drops less-pertinent candidate answers like“July”. In contrast, both document-level Flan-UL2 andChatGPT fail to extract since sentence [0] includes astrong distractor, “Wed 15 Sep 2021” . For brevity, weonly show part of this sample article. Numbers like [0]are for illustration purposes and are not part of modelinput.summarization (Filatova and Hatzivassiloglou,2004; Marujo et al., 2017; Li et al., 2021a),recommendation systems (Lu et al., 2016; Li et al.,2020a), and news narrative understanding (Jin et al.,2022; Zhang et al., 2022; Keith Norambuena et al.,2023). Event argument extraction (EAE), a crucialand challenging step in Event Extraction (EE), isthe task of identifying role-specific text spans (i.e.,arguments ) for a given event (Nguyen et al., 2016;Kar et al., 2020; Du and Cardie, 2020a).Existing research mainly focuses on sentencearXiv:2401.13218v1  [cs.CL]  24 Jan 2024level event argument extraction (Chen et al.,2015; Du and Cardie, 2020b; Lu et al.,2021) on the prevalent ACE dataset (Walkeret al., 2005). Yet, in the realm of newsjournalism, events are usually described at thedocument level, and arguments are typicallyscattered across an entire article (Hamborg et al.,2019). Therefore, there is a pressing need tosystematically study the document-level EAE(DocEAE) task, since sentence-level EAE systemscannot accommodate long-distance dependency(Ebner et al., 2020), cross-sentence inference(Li et al., 2021b) and multi-answer (Tonget al., 2022) problems intrinsic to the DocEAEtask. Traditional supervised approaches have toconsume large-scale annotations (e.g., Zheng et al.,2019; Pouran Ben Veyseh et al., 2022, each requiresmore than 30,000 annotated articles) in orderto excel, and the state-of-the-art (SOTA) EAEmodel requires manual design of templates for eachargument type (Hsu et al., 2022). These approachesare not only costly, but also not generalizable, sincethey fail to handle emerging events (Yang et al.,2023).1Recently, there has been a notable surgein applications of Large Language Models (LLMs)for NLP tasks, especially closed models such asPaLM (Chowdhery et al., 2022), Claude (Bai et al.,2022) and GPT-4 (OpenAI, 2023). The mostrelevant work to ours is Li et al. (2023); however,Han et al. (2023) only performed preliminaryanalysis by assessing ChatGPT’s capability ofsolving IE tasks. Meanwhile , there is no priorresearch that has attempted to leverage LLMsto tackle the DocEAE task. In our preliminaryinvestigation, we identified at least three challengesthat arise when employing closed LLMs: 1)hitting endpoints incurs substantial costs andposes scalability challenges during inference; 2)undesirable prompt hacking is needed to ensureperformance (Ouyang et al., 2022); 3) given thenature of news, where information spreads acrossthe content, LLMs suffer from the positional biasissue2(Hou et al., 2023; Liu et al., 2023).To this end, we propose an easy-to-useframework that Unleashes LLMs’ potential forevent argument ex TRA ction through hierarchicalmodeling and pair-wise refinement, dubbed ULTRA .ULTRA , built on Flan-UL2 (Tay et al., 2022), first1COVID-19 became an emerging topic since 2020 (Wanget al., 2020; Zhang et al., 2021), but not covered in traditionalEE corpora (Walker et al., 2005; Ebner et al., 2020).2A\n",
      "----------------------------------------------------------------------------------------------------\n",
      "usinga model to identify the gas in the plume.There are several well established methods for identify-ing gases, such as Step-wise Linear Regression and Bayesian∗The authors acknowledge the Aerospace Corporation for collecting andproviding the historical airborne LWIR data from the Los Angeles basin area.This work is partially funded by NNSA Contract No. 89233218CNA000001,and Los Alamos National Laboratory subcontract No. C3486. LA-UR-24-20093.Model Averaging, which work well for identifying gases froma relatively small library of candidate gases [2]. Machinelearning and deep learning classification models have provento be superior for identification, particularly when there aremany candidate gases and many images to analyze [3, 4, 5].However, applying deep learning classifiers to real world datacan be difficult, thus it is important to properly preprocess thedata before classification.Whitening is a common preprocessing step when workingwith nadir observed gas plumes. Whitening uses the equationz=C−1/2(x−µ), where Cis the scene covariance matrix, µis the scene average spectral signature, and xis the spectrumof interest. Typically a “global” estimate of µandCare used,where every pixel in the scene, except for pixels in the regionof interest (ROI), are included in the calculation. However, ur-ban images often contain many diverse background materialswhich are not represented well by the global µ. This can leadto mischaracterization of important identifying wavelengthsfor the gas, making it more difficult to classify correctly.Since identification with deep learning models is alreadya difficult task on real world plumes, it is crucial to have anaccurate estimate of the whitened gas signature. This paperproposes an iterative background estimation approach withimage segmentation to create local estimates of backgroundspectra for plumes. We demonstrate our approach to be ben-eficial in estimating gas signatures in both simulated and realworld plumes when compared to the global whitening ap-proach.2. METHODA standard approach for whitening is to assume that all spec-tral signatures in the image are normally distributed. The nor-mality assumption is not guaranteed to be satisfied, and inimages with many different background materials, such as inurban scenes, the global background may not sufficiently rep-resent the variety of background signatures [6]. Whiteningwith an incorrect background signature can lead to inaccuratewhitened gas spectra, making it more difficult to classify theplume correctly. For this reason, it is beneficial to whiten eacharXiv:2401.13068v1  [cs.CV]  23 Jan 2024part of a plume according to the distinct background materialsit spans within the scene.One option to distinguish between various backgroundmaterials is to use image segmentation to break the imageinto groups of similar pixels. We use Watershed Segmenta-tion (WS) as it has an appropriate adaption for use with HSI[7]. WS determines segments by finding boundaries between“different colored” regions, thus it is well suited for the pur-pose of distinguishing between various background materials.We choose to use non-marker based WS which results in over-segmentation, reducing the chance that a given segment willcontain more than one distinct background material. Sincesome segments may have a relatively small number of pix-els, we focus on locally estimating the means while using aglobally estimated covariance matrix [8].WS produces segments that are treated independentlywhich can cause problems for segments that are completelymasked by a plume, as whitening with the segment’s meanwill remove important characteristics belonging to the gas.For this reason, we need to be able to estimate the backgroundof a contaminated segment using non-contaminated pixels.Inspired by [9], we represent each spectral signature ywithan additive model, y=b+αt, where bis the background sig-nature, tis the target gas signature, and αis the non-negativesignal strength.Given a set of pixels of the same background material,we want to estimate bandtwhich should be the same for allpixels in the set, and estimate αfor each individual pixel. Oneway to do this is by trying to solve the following optimizationproblem:minb,t,α i≥01NXi||yi−(b+αit)||2. (1)This optimization problem minimizes the mean squared error(MSE) between each pixel and its modeled signature. An is-sue with trying to solve this optimization problem is that b,t,andαiare all unknown. Thus, we opt to use an alternating ap-proach to simplify the problem. Using Lagrange multipliers,the solution at each step for αi,b, and tare:αi= max\u00120,(yi−b)TttTt\u0013, (2)b=1NXyi−αit, (3)t=P(yi−b)αiPα2i. (4)We call this algorithm iBATE (iterative Background Al-pha Target Estimation). Natural initializations for bandtarethe global estimates, and αi= 1. Each step can be repeateduntil the error reaches a limit, or ceases to decrease; in nearlyall of our test cases we observed convergence within 10 iter-ations. Although iteratively so\n",
      "----------------------------------------------------------------------------------------------------\n",
      "afflicted by an arrayof degradations, spanning from noise [5, 20] to environ-mental factors such as rain [9, 14] and atmospheric hazi-ness [1, 24]. The importance of image restoration tasks*∗Corresponding Authoris underscored by their pivotal role in facilitating subse-quent downstream applications, notably encompassing im-age classification [13, 32], object detection [25], and seman-tic image segmentation [26].As deep learning methods have exhibited remarkable ef-ficacy in image restoration tasks, all-in-one image restora-tion methodologies [18, 23] have gained prominence fortheir capacity to address multiple degradations in a sin-gle model. Among these all-in-one methods, corruption-agnostic approaches like AirNet [18] and IDR [36] are gain-ing increased attention to relieve the need for predefineddegradation types. These methods leverage a degradationencoder to autonomously identify and process the corrup-tion features present in images, thereby circumventing therequirement for any prior assumptions about the nature ofthe corruption. Despite achieving commendable perfor-mance, these methods process all input samples, charac-terized by various degradations, within a uniform networkstructure. This seemingly straightforward reconstructionstrategy overlooks the task-wise complexities among thesediverse restoration tasks, potentially leading to the ineffi-cient allocation of computational resources.To better characterize task-wise complexity, we positthat one image restoration task can be effectively trans-formed into another by the deliberate inclusion or removalof corresponding degradation factors. For instance, rainyimages may be perceived as the introduction of an addi-tional layer of rain atop noisy images, while hazy imagescan be generated when raindrops are introduced at eachpixel of the rainy images, influencing the overall bright-ness of the original images. Drawing from this conceptualframework, we can establish a hierarchical ranking of therelative difficulties inherent in each image restoration task;for instance, Deraining ≥Denoising. This ranking allowsus to allocate computational resources tailored to each task.Building upon the aforementioned analysis, we proposea Unified-Width Adaptive Dynamic Network (U-WADN)method as a means to allocate adaptive computational re-sources on a task-specific basis. The U-WADN com-prises two core components: the Width-Adaptive Back-bone (WAB) and the Width Selector (WS). The WAB isarXiv:2401.13221v1  [cs.CV]  24 Jan 2024designed by integrating multiple sub-networks, character-ized by a nested structure where smaller sub-networks areencompassed within larger ones. To be more specific, theparameters in a small network are fully reused when gen-erating the reconstructed images from a larger network.This arrangement mirrors the progression from simpler tomore intricate tasks, where intricate image restoration taskscan be transformed by the incorporation of correspondingdegradation factors ( i.e., extra parameters within larger net-works). Upon receiving a pre-trained WAB, the WS playsa pivotal role in selecting the degradation type for incom-ing input images. It then allocates these images to differentsub-networks based on their task-wise complexities. Fur-thermore, the WS takes into account sample-wise complex-ities, where intricate samples within ostensibly straightfor-ward tasks are also processed by larger sub-networks.The contributions of this paper are summarized as fol-lowing three-folds:• As far as we know, we are the first work to raise the ideathat complicated image restoration tasks can be trans-formed from simple image restoration tasks. For those de-composable image restoration tasks, we process straight-forward image restoration tasks using smaller networks,effectively mitigating the overall computational expenses.• In our study, we introduce a Unified-Width-Adaptive Dy-namic Network (U-WADN) designed for all-in-one im-age restoration tasks. This network comprises a Width-Adaptive Backbone (WAB) and a Width-Selector (WS).The WAB, with its nested network architecture, and theWS, responsible for network selection based on both task-specific and sample-specific complexities, collectivelycontribute to the reduction of computational overhead, allwhile maintaining network parameter efficiency.• We conduct experiments on ’Noise-Rain-Hazy’ restora-tion and dynamically allocate computations based on bothtask-wise and sample-wise difficulties. Despite achievinga 15.7% real-time acceleration and around 32.3% FLOPSreduction, U-WADN continues to deliver better perfor-mance compared with existing methods.2. Related work2.1. Image restorationImage restoration tasks aim to restore clean images fromcorrupted ones. Conventional image restoration tech-niques [6, 12, 27] rely on manually crafted priors for the re-construction of deteriorated images. With the proliferationof learning-based methods, conventional image restorationtechniques have been displaced primarily owin\n",
      "----------------------------------------------------------------------------------------------------\n",
      "itional VSLAM techniques, such as ORBSLAM [16],perform pose estimation by comparing matched keypointsof camera inputs with recent keyframes. The algorithmfirst extracts keypoints, which are image features selectedeither based on predesigned filters [16], [2] or machinelearned models[3], from the camera input and track them inkeyframes by matching the descriptors. The pose estimationis then performed by minimizing the reprojection errorbetween the matched 3D map points in world coordinates and2D keypoints. A considerable large number of matched key-points on consecutive frames is required to reliably performpose estimation, therefore, the scene continuity in adjacentframes is important. The camera images must be capturedand processed frequently to ensure a high level of similarityamong the consecutive frames. However, frequent imageprocessing and keypoint comparison will cause significantcomputation overhead and to record all keyframes of theenvironment will result in a high storage complexity.Rather than memorizing the image features of the visualinput, human navigates in an environment by roughly esti-mating their position based on relative location of surround-ing objects. Neuroscience research shows that the place cell,i.e., the set of neurons associated with locations, located inthe hippocampus and involves in the function of episodicand semantic memory [7], [9]. In this work, we present Se-manticSLAM. The algorithm performs localization and mapconstruction using extracted visual semantic information.The map is a 2D array of neuron clusters, each representing agrid area in the environment. The state of the neuron clusters,which can be written as a vector, represents the semanticinformation of the corresponding grid area. By comparingthe observation and the semantic map, a rough estimationcan be made about the camera pose. With the estimated poseand the observed semantic information of the surroundingarea, the algorithm will update the map to include the newobservations.The pose estimation described above may have large errorat the early phase of a mission when the map has not beenconstructed. Because the robot has no prior knowledge of theenvironment, no matching could be found by comparing theobservation with the map. In addition, the observation is notalways perfect. For example, the most common observationerror is due to obstruction. Using imperfect observation toupdate the map will also introduce errors. In this work, a con-volutional long-short-term-memory (ConvLSTM) is trainedto correct errors during map update such that the errorswill eventually converge instead of being magnified with theiteration. To improve the accuracy of pose estimation at thebeginning of the mission, we will leverage the reading froma low cost Inertial Measurement Unit (IMU) to cross checkthe pose and narrow down the region of the map update.Solely rely on the IMU is not an option for pose estimationas the intrinsic error will accumulate and eventually becomeunbearable. However, using the IMU input to bootstrap thepose estimation at the beginning of the mission is viable.Compared to traditional SLAM, the SemanticSLAM’sadvantage is two folds. Firstly, it does not require highfrequency observation and image processing. While differentdistance, view angle and luminance level may change imagefeatures in the observation, after the semantic extraction,arXiv:2401.13076v1  [cs.RO]  23 Jan 2024Fig. 1: System Overview of SemanticSLAMsuch low level variance will be filtered out. Therefore,continuity in the view point is not a necessary conditionto find a semantic match. Secondly, compared with mapsstoring image features and keyframes, a map with semanticinformation requires much less memory and is more humaninterpretable. The semantic map can be directly used formission and navigation planning and can be easily sharedamong robots as well.We evaluate the effectiveness of SemanticSLAM, on adataset obtained from the Gazebo [13] simulation platformusing RGB-D cameras and IMU data. Our experimentalresults demonstrate that SemanticSLAM outperforms otherrepresentative methods in terms of accuracy and adaptabilityto new environments.II. R ELATED WORKExisting VSLAM techniques, such as ORB-SLAM [16]and LIFT-SLAM [3], employ parallel threads for track-ing, mapping, relocalization, and loop closing. Traditionally,feature points are extracted from images using predefineddescriptors such as SIFT [14]. The map is a collection ofthe frames consists of extracted feature points. Camera poseis estimated by minimizing the reprojection error between thequery frame and the stored frames that have the largest num-ber of matched feature points. To ensure that an abundance ofmap points can be found, large amount of keyframes must bestored in the map, and the observation must have a significantamount of continuity. Hence these methods often requiresignificant computational and memory resources. After poseestimation, some recent works [18], [5] also extract sem\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ge, with textual documents constituting a significant fraction ofits content. Moreover, information changes over time, leading toupdates to existing documents, or the addition of new documents.This leads to multiple versions of information from various timeframes to co-exist and grow over time. A major challenge in in-formation retrieval is ensuring that users get access to the mostrelevant and up-to-date knowledge at any time. This challenge hasrecently been compounded by the increased use of question answer-ing tools powered by large language models (LLMs), which havegained popularity as a result of the release of chatGPT [ 13]. LLMshave been shown to absorb and serve immense quantities of infor-mation from textual data [ 14]. This information is typically derivedfrom a static snapshot of a large number of documents scrapedfrom the web at a specific point in time. However, real-world infor-mation changes continuously, frequently on a daily, hourly or evenreal-time basis. To address the challenge of frequently changingdata, language models must expand or update their memory on aregular basis, which involves significant computational, financialand environmental costs.In recent years, there has been an increasing interest in usingRetrieval Augmented Language Models (RALMs) as a way of ad-dressing the problem of frequently evolving information, and alsoreducing the tendency of LLMs to make up information knownas hallucinations. RALMs use an external document corpus as aknowledge source rather than relying solely on parametric memorylike standard LLMs. This corpus, stored in the form of a documentindex (a format which makes document retrieval efficient), can beaugmented and updated to reflect current versions of documentsstored in it, for e.g., Wikipedia documents, and web pages. Fora given text-based query, RALM uses its retriever component toobtain a ranked list of the most relevant documents from the docu-ment index and gives them to its language model component (alsoknown as a reader), which uses the ranked documents as context togenerates a response to the query. RALMS have been shown to gen-erate more specific and factual responses to queries in knowledgeintensive tasks such as question answering and fact checking thanstand-alone LLMs [ 12]. These models have also shown to performwell in few-shot training scenarios [ 8] using as few as 64 examplesto achieve a good performance.Although RALMs perform well in factual question answering,they typically use a document index, which contains a single ver-sion of each document. However, in many real-world applications,new information continues to be generated, without invalidatingor replacing existing information, which results in multiple ver-sions of documents to be present in the document index. For ex-ample, scientific and medical journals continuously publish newacademic papers which are additions and enhancements to thebody of knowledge that has been published previously, for e.g., newNatural Language Processing (NLP) research papers are posted tothe arxiv platform [ 1] almost daily. This challenge is further com-pounded when trying to build a question answering system thatsupports time-sensitive queries such as \"Which language modelis the state-of-the-art on the latest summarization benchmark?\",because standard RALM models would retrieve numerous papers,each stating it has established a new state of the art in documentsummarization. This is a direct result of the fact that standardLLMs and the LLM components of RALMs do not take into accounttemporal metadata [5].arXiv:2401.13222v2  [cs.IR]  25 Jan 2024Gade and Jetcheva, et al.Figure 1: Overview of TempRALM: In this figure, we show the difference between Atlas and TempRALM. In TempRALM, theretriever fetches documents on semantic relevance with respect to the query as well as temporal relevance relative to thequery-timeIn this paper, we show that RALMs face challenges in handlingtemporality in even simpler and more structured settings. For ex-ample, in the context of frequently changing information such asthe identities of the latest winners of the Wimbledon tennis cham-pionship, we show that Atlas [ 8], a representative state-of-the-artRALM, is generally unable to provide an answer that is meaningfulrelative to the time at which the question is asked. For example, ifthe question \"Who won the Wimbledon Men’s championship?\" isasked on December 31, 2019, current state-of-the-art RALM archi-tectures would retrieve relevant documents by matching the year2019 in the query timestamp with the Wimbledon match date inthe passages. However, if the same question is asked a day later, i.e.on January 1, 2020, the current RALM architecture can no longerretrieve the relevant documents as the year no longer matches, andsince they do not have the ability to understand temporal relation-ships.Prior attempts to address this problem have focused on pre-training the language model by inducing a temporal context as plaintext [ 5]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ased methods continue to be efficient and effective in low-dimensional state spaces. However, mobile robots continueto rely on these infeasible techniques such as Dikjstra’sAlgorithm, Navigation Function, and numerous forms ofgrid-based heuristic search (e.g. A*, D*) [2], [3]. For circulardifferential-drive or holonomic robots, this class of algorithmis still suitable for many uses.However, the sector has evolved away from simple circularrobots and towards new industries outside of warehouses andresearch laboratories. There is a growing use of Ackermann,large non-circular, and quadruped robots in new applicationssuch as last-mile delivery, automated platform lifts, andFig. 1: Large, non-circular industrial robot using Nav2uniquely enabled by this open-source Framework.construction monitoring. These robots cannot utilize single-point holonomic planning techniques previously deployedand require, at minimum, kinematically-feasible paths. Yet,common feasible algorithms have no quality implementationsaccessible for academic use, are not integrated with anymajor research framework (MRPT, ROS, etc), nor havevariants unique to mobile roboticist’s needs [4], [5].Our work was motivated by this gap: to serve these newstyles of robots and its researchers. To fill this, we createdtheSmac Planner : a templated, C++-based search-basedplanning framework designed to make creating search-basedplanning algorithms simple. Within it, we propose threeplanners; 2D-A*, Hybrid-A*, and State Lattice.This paper contains three areas of contribution. It describesthe high-level design of the Smac Planner framework, en-abling performant planners to be added in approximately 200lines of C++. More substantially, this work characterizes sev-eral variations of the kinematically feasible planners (Hybrid-A*, State Lattice) to build upon them for the requirementsarXiv:2401.13078v1  [cs.RO]  23 Jan 2024and conventions in mobile robotics. Finally, we provideperformance benchmarking and analysis of the planners.We provide high-quality implementations in Nav21forrapid benchmarking and evaluation [6]. This is in use by overa dozen organizations worldwide in research, warehouses,outdoors, and in surface marine applications; including theindustrial warehouse robot in Fig 1. Its presence has en-abled Nav2 to be integrated with a broader class of robotsincluding Ackermann, legged, and large non-circular robots,accelerating research on these platforms [7].II. R ELATED WORKSystems that are not able to be modeled as circular or holo-nomic require more developed planning techniques for robustoperation. Kinematically feasible and kinodynamic plannersmodel kinematics and/or dynamics to provide plans forlimited maneuverability drive-trains and arbitrarily shapedrobots [8]. Popular search-based feasible planners includeHybrid-A* and State Lattice. Hybrid-A* makes use of Ack-ermann curvature-constrained models such as Dubins andReeds-Shepp to search grid maps. Meanwhile State Latticeapplies a set of pre-generated motion primitives, known asthe control set, to find its neighbors for arbitrary motionmodels [9], [10]. As such, it is required to generate thecontrol set, usually offline. One such algorithm is describedin [10] and in later detail (Sec. V-C).Sampling-based methods are common for kinodynamicplanning, however they have slow run-time performanceover large distances in the presence of non-trivial obstacles(e.g. long time horizons) [12]. Favorably, hybrid planningused in navigation systems creates a distinction betweenglobal path planning and local trajectory planning suchthat kinodynamic planning is leveraged only in the localtime horizon. Generally, global planning need only applykinematic constraints [13].Many planning frameworks have been proposed, notableamong them with staying power are the Open MotionPlanning Library (OMPL) and the Search-Based PlanningLibrary (SBPL) [14], [15]. OMPL specializes in sampling-based techniques with implementations of common methods,including PRM, RRT and its variants. While OMPL can sam-ple using mobile robot models, in experiments, it providedplans with irregular run-times often an order of magnitude(or more) slower than search-based methods for the low-dimensional and non-trivially occupied state spaces. Whiletechnically drivable, it suffers from significant unnecessarysudden turns - including long segments of reversing nearobstacles even when both are explicitly penalized.SBPL instead focuses on search-based planning with sev-eral heuristic search options such as Anytime Repairing A*and D* Lite [17]. It uses motion primitives to search, but theprimitive generators within SBPL are manually-engineeredand do not create principled minimum control sets, limitingmaneuverability. SBPL also only provides naive distance-based heuristics, resulting in acutely slow planning times in1https://github.com/ros-planning/navigation2structured, realistic environments. The current state of thisframework is more suitable for local traje\n",
      "----------------------------------------------------------------------------------------------------\n",
      "del for Discrete Rea-soning over Tabular and Textual Data. In Proceedings of Make sure to en-ter the correct conference title from your rights confirmation emai (Confer-ence acronym ’XX). ACM, New York, NY, USA, 16 pages. https://doi.org/XXXXXXX.XXXXXXXPermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from permissions@acm.org.Conference acronym ’XX, June 03–05, 2018, Woodstock, NY©2018 Association for Computing Machinery.ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00https://doi.org/XXXXXXX.XXXXXXXYear Ended June 30, 2019 2018 2017Server products and cloud services 32,622 26,129  21,649Office products and cloud services 31,769 28,316 25,573Windows 20,395 19,518 18,593Gaming 11,386 10,353 9,051Search advertising 7,628 7,012 6,219LinkedIn 6,754 5,259 2,271Enterprise Services 6,124 5,846 5,542Devices 6,095 5,134 5,062Other 3,070 2,793 2,611Total 125,843 110,360 96,571Our commercial cloud revenue, which includes Office 365Commercial, Azure, the commercial portion of LinkedIn, Dynamics365, and other comm ercial cloud properties, was $38.1 billion, $26.6billion  and $16.2  billion  in fiscal years 2019, 2018, and 2017,respectively . These amounts are primarily included in Office productsand cloud services, Server products and cloud services, andLinkedIn in the table above.(in millions )Revenue from external customers, classified by significant productand service of ferings, was as follows:Question 1 : What was the percentage change in gaming between2018 and 2019?Discrete Reasoning T ype: Arithmetic CalculationAnswer : (11,386 - 10,353) / 10,353 = 9.98%Question 2 : Did the total revenue in 2019 exceed that of 2018?Discrete Reasoning T ype: ComparisonAnswer : 125,843 > 110,360 = YesQuestion 3 : How many revenue items are between 6,000 million and6,500 million in 2019?Discrete Reasoning T ype: CountingAnswer : Count (Enterprise Services# Devices ) = 2Figure 1: Examples of QA with discrete reasoning over ahybrid of tabular and textual data.1 INTRODUCTIONNowadays the Web inundates its users with vast and intricate con-tent, necessitating content analysis techniques. In this work, wefocus on analyzing a prevalent category of Web content: docu-ments containing tables and text, including but not limited to SECfilings, financial statements, academic papers, and medical reports.These documents often feature extensive numerical data in bothtabular and textual formats, demanding discrete reasoning for in-telligent comprehension. Recent research [ 7,53,54] investigatesthe intelligent comprehension of such documents through questionanswering (QA) tasks, as exemplified in Figure 1. The model, pro-vided with a table and relevant text as the context, needs to performvarious types of discrete reasoning, such as arithmetic calculations,making comparisons, and counting, to answer the question.arXiv:2401.13223v1  [cs.CL]  24 Jan 2024Conference acronym ’XX, June 03–05, 2018, Woodstock, NY Fengbin Zhu, et al.To perform QA over hybrid tabular and textual data, a straight-forward approach [ 21,34] involves taking the table, text, and ques-tion as input and generating the answer directly. However, thisapproach can be ineffective due to the complex reasoning processinvolved [ 42]. To address this, some works [ 7,25,52,55] decom-pose the task into multiple steps, producing intermediate resultsthat serve as references for the final answer. For example, Soar-Graph [ 55] first extracts the relevant information by selecting nodesin a constructed table-text graph structure and then employs a tree-based method to explicitly generate the mathematical expressionof the answer. These multi-step approaches typically require dis-tinct modules for each step and often optimize them concurrentlythrough multi-task learning. However, the problem of how to de-compose and model the answer process remains an open challenge.We identify three key steps in the process of tabular and tex-tual QA, and abstract a Step-wise Pipeline , as illustrated in Figure 2b). In particular, 1) Extractor identifies the relevant informationor evidence to the question from the given context; 2) Reasonergenerates a mathematical equation or logic rule with the obtainedinformation; and 3) Executor derives the final answer by execut-ing the mathematical equation or logic rule with the associatedinformation. These three steps emphasize different abilities for tab-ular and textual QA — understanding of the question and context,knowledge (e.g., logic) of answering the question, and precisionin calculating t\n",
      "----------------------------------------------------------------------------------------------------\n",
      "owledgerepresentationtocontentindexingandmatching[6]torelevancemodelling[3,4].Consequently,thereisalonghistoryofresearchonAI-drivenIRapplications,startingwithrule-basedapproachesinthe1980s[2]andendingwiththeneutralnetwork-basedapproachesdiscussedinthe2020s[4].TheimportanceofAI-drivenIRsystemshasbeenincreasingduetothegrowthintheamountofinformationavailableonline.Oftenreferredtoasaninformationoverload[5],thisphenomenonpromptedtheneedforadvancedIRmechanismsforsatisfyingindividualinformationneeds,whicharecapableofnotonlyprocessingthelargevolumesofavailableinformationbutalsorecognisingthediversespectrumofuserneedsandinsomecases1UniversityofBern,Switzerland3predictingtheseneeds.Suchmechanismsdemonstratedtheirusefulnessinmultipledomainsrangingfromhealthcare[7,8]tojournalism[9,10]toe-commerce[11,12].ThischapterfocusesononeparticulardomaininwhichAI-drivenIRsystemsareincreasinglyemployed,whichisculturalheritage.Byfacilitatingtheorganisationofheritage-relatedcontentbothwithinheritageinstitutions(e.g.archives[13]ormuseums[14]),andcommercialplatforms(e.g.websearchengines[15]orsocialmedianewsfeeds[16]),AI-drivenIRsystemshelptheirusersbecomeinformedaboutabroadrangeofhistoricalphenomena,includinggenocidessuchastheHolocaustorRwandagenocide.Undertheconditionofahighdegreeofautonomy,thesesystemsbecomenon-humancuratorsofgenocide-relatedinformation,whichshapehowindividualsandsocietiesareinformedaboutthepastandpresentatrocities.DespitetheimportanceofIRsystemsforcuratinginformationabouthistoricalandrecentgenocides,therearemultipleconcernsabouttheirpotentialimpactongenocideremembrance.TheusualconcernsaboutthelackoftransparencyofAI-drivenIRsystemsarefurtheramplifiedbythepossibilityofsuchnon-transparencyfacilitatingmanipulationsofIRsystems,whichcanpotentiallyinterferewiththemoralobligationsofsafeguardingthedignityofgenocidevictims[17].Furthermore,suchmanipulationscanfacilitatetheinstrumentalisationofmemoriesaboutpastviolence,whichcanbeusedforjustifyingthepresentstigmatisation,asinthecaseoftheRohingyapersecutioninMyanmar[18]ortheRussian-Ukrainianwar[19].Besidestheabove-mentionedconcernsabouttheuseofIRforcuratinggenocide-relatedinformation,therearealsootherethicalchallengeswhichhaveforlongbeendiscussedinthecontextofhumancurationofhistoricalinformation,suchastheimportanceofprotectingtheprivacyofindividuals[20]orpreventingunfairpracticesofinformationcuration[21].However,despitethegrowingbodyofworkconcerningtheethicsofhumancurationofgenocide-relatedinformation[22–24],thecapabilitiesofIRsystemstodealwithcomplexethicalissuesarisinginthecontextofgenocide-relatedinformationaswellastheperspectivesofbridgingmemoryethicsandIRdesigncurrentlyremainunder-investigated.Toaddressthisgap,thechapteraimstoexaminewhethertheconcernsaboutthehumancurationofgenocide-relatedinformationareapplicabletoAI-drivenIRsystemsandhowtheseconcernscanpotentiallybeaddressed.Forthisaim,itprovidesashortoverviewofthecurrentapplicationsofIRsystemsinthecontextofgenocide-relatedinformation,followedbyadiscussionoftheethicalchallengesofitshumancurationusingathree-partframeworkinspiredbyBelmontcriteria(i.e.respectforindividuals,beneficenceandjustice/fairness).Finally,thechapterdiscussestowhatdegreethesechallengesare4applicabletoAI-drivenIRsystemsandwhatcanbethepotentialwaysofbridgingAIandmemoryethicsinthiscontext.2AI-drivenIRSystemsandGenocide-RelatedInformationThedigitisationofhistoricalcollections,togetherwiththeproductionofnewdigital-bornmaterialsdealingwithinformationaboutgenocides(e.g.audiovisualtributestotheHolocaust[25,26]),promptedthegrowinguseofIRsystemswithinheritageinstitutions.Manyofthesesystemspartiallyreproduceorenhancethetraditionalcurationpracticesusedbyarchivesormuseums,butinsomecases,IRsystemssubstantiallytransformthescaleandfunctionalityofthesepractices.Forinstance,Liew[14]examinedhowIRsystemsfacilitatetheexplorationofcollections,includingtheonesdealingwiththeHolocaust(e.g.byenablingkeyword/phrasesearchandtheuseofwildcardoperators).Schenkolewski-KrollandTractinsky[13]discussedtherelationshipbetweenIRsystemsandauthoritylistsinthecontextofHolocaustmaterialsintheIsraeliarchives.Daelen[27]lookedatthepossibilitiesofusingIRtoenrichtheinventoryofcollectionsrelatedtotheHolocaustandconnectarchivesandusersinthecontextofEuropeanHolocaustResearchInfrastructure;similarly,Carteretal.[28]discussedthepotentialofAI-drivenIRsolutionsforfacilitatingexplorationofprimarysourcesinthecontextoftheHolocaustbyprovingnewpossibilitiesforuserinteractionwiththeMorgenthauDiaries.InadditiontoIRsystemsenhancingtraditionalcurationpractices,therearealsoexamplesofmoreinnovativeapplicationsofthesesystemswithinheritageinstitutions.Oneexampleistheuseofthree-dimensionalvisualisationofHolocaustsurvivorsretrievingaudiorecordingsofthesurvivors’earliercommentsinresponsetotheuserinput.Sometimesreferredtoasholograms[29]orsocialrobots[30],thesesystemsareusedbyseveralHolocaustmemoryinitiatives(e.g.NewDimensionsofTestimonyorForeverProject)andenablenewpossibilitiestoretrievetestimoniesthroughthesimulationofhuman\n",
      "----------------------------------------------------------------------------------------------------\n",
      "dictions. Figure 1 showstwo pipelines for link prediction (Daud et al., 2020;Lichtenwalter et al., 2010) based on Graph NeuralNetworks (GNNs) and LLMs. The former employsGNNs for graph learning, followed by a matcher tocompute similarity to link predict (Zhang and Chen,∗Corresponding author.Figure 1: GNNs and LLMs based pipelines for linkprediction2018; Cai et al., 2021). Meanwhile, the latter gen-erates textual prompts based on sampled subgraphsand utilizes LLMs for prediction.In contrast to the conventional approach ofGNNs that aggregate encoded features via mes-sage passing (Hamilton et al., 2017; Abu-El-Haijaet al., 2019), LLMs exhibit superior learning ca-pabilities and enhanced flexibility (Tamkin et al.,2021; Liang et al., 2022). However, it remainsunder explored on how to effectively learn fromlarger and more complex graphs with LLMs, whichposes high challenges to capturing distant informa-tion and richer semantics. An example is the linkprediction on large-scale graphs: as the number ofcandidate nodes or description nodes for predictiongrows, so does the text fed into LLMs. In this case,extensive inputs become unfeasible due to tokenlength limitations.In this work, we explore the scalable link pre-diction with large language models on large-scaleheterogeneous graphs(LSHGs). LSHGs (Shi et al.,2016; Wang et al., 2022) can be considered as net-works of connections that resemble the real worldmore closely than conventional graph structures,such as social network (Robins et al., 2007) oracademic networks (Kong et al., 2019). The keychallenges can be succinctly described as follows:1) how to fomulate the prompt template for scalablelink prediction task. 2) how to find out crucial in-formation on LSHGs by sampling, enabling LLMsarXiv:2401.13227v1  [cs.CL]  24 Jan 2024Figure 2: The framework of LPNL on heterogeneous graphs. For an input heterogeneous graph with linkprediction tasks, perform two-stage sampling on the source node and each candidate node, resulting in the generationof corresponding anchor nodes. Generate prompts based on anchor nodes, input them into a large language model,reconstruct candidates based on the prediction results, create new prompts for another round of prediction, andrepeat this divide-and-conquer process to obtain a unique link prediction result.to capture it within limited inputs. 3) how to ad-dress lengthy prompts generated by an excess ofcandidate nodes.To tackle the above challenges, we proposeLPNL (LinkPrediction via Natural Language), alarge language model based framework for scalablelink prediction on large-scale graphs. We designnovel prompts for link prediction that articulatinggraph details in natural language. This involvesestablishing a selective query prompt template, fur-nishing a description of the link prediction task, andintegrating heterogeneous information concerningthe source and candidate nodes.In dealing with vast amounts of relevant graphinformation within LSHGs, LPNL’s focus lies onthe crucial segments. This approach helps us avoidthe interference of superfluous contextual infor-mation while ensuring compliance with specifiedtoken limitations. We design a two-stage samplingpipeline that utilizes normalized degree-based het-erogeneous subgraph sampling and personalizedpagerank-based ranking. This pipeline selects morecrucial node information from the graph, ensuringthat the model focuses more on more informativenodes.With a large number of candidate nodes and onlya single link prediction query, the token lengthconstraints make it challenging to fully describe allcandidate node information. For this situation, weutilize a divide-and-conquer method. We partitionthe original node set into multiple equally sizedsmaller sets, sequentially input them into the linkprediction pipeline to obtain partial answers, andrecursively reconstruct the candidate set to obtainthe final answer.We conduct extensive experiments on the OpenAcademic Graph (OAG) (Huang et al., 2020) andfine-tune the language models T5 (Raffel et al.,2020) to serve as the backbone models on the OAGfor LPNL. The results demonstrate that LPNL out-performs various enhanced GNNs-based baselinessignificantly in performance. Furthermore, throughextensive experimentation, we discover that LPNLalso exhibits remarkable few-shot capability. Un-like traditional models, LPNL’s training merely re-quires simple alignment formatting, enabling swiftconvergence in predictions and showcasing supe-rior performance compared to conventional models.Additionally, experiments demonstrate the model’srobust knowledge transferability, maintaining con-sistent performance across various cross-domaintasks. This further underscores the immense poten-tial of large language models in addressing graphlearning.2 The LPNL ArchitectureIn this section, we introduce the details of our pro-posed LinkPrediction via Natural Language, i.e.LPNL , a framework utilizing natural language tosolve link prediction task on large-scale heteroge-neo\n",
      "----------------------------------------------------------------------------------------------------\n",
      "e annotated datasets like VQA (Al-Sadi et al.,2019) exist for general VQA, medical VQA datasets aresmaller, requiring costly expert annotation and specializedmedical knowledge. Synthetically generating question-image pairs is typically inappropriate due to the need forclinical relevance and domain-specific expertise. Addition-ally, generic VQA models struggle to adapt to medicalimages. These models require further specialization and theability to focus on finer details, such as microscopic lesions,crucial for diagnosis. The unrestricted and frequentlyhighly technical nature of the input questions, which maycontain medical terminology not adequately represented bygeneric language models trained on expansive databaseslike Wikipedia, further increases the complexity of medicalVQA.Medical VQA holds immense potential in healthcare, offer-ing valuable support where clinician availability is limited.Given the vast number of queries and the operational scale,it is often challenging for clinicians to address each querypromptly. This can lead to delays in addressing criticalhealth inquiries, potentially slowing down the diagnosis ofsevere conditions with significant consequences. Further-more, search engine responses, while abundant, tend to begeneric, error-prone, irrelevant, and sometimes misleading.This underscores the necessity for an AI system capable ofanalyzing medical images and providing specific answers torelated questions. Such a system could also assist cliniciansby offering a secondary opinion on interpreting compleximages.In our work, we introduce an enhanced radiology datasetused for the pretraining of domain-specific visual encoders.Our experiments with various deep learning models focuson efficient image and text representation learning. Wedemonstrate that intra-domain transfer learning is more ef-fective than inter-domain transfer learning for medical VQAtasks. Our proposed method not only matches benchmarkaccuracy but also has a simpler architectural design.1arXiv:2401.13081v1  [cs.CV]  23 Jan 2024Free Form Medical Visual Question Answering in Radiology2. Literature Survey2.1. Existing DatasetsTo evaluate the performance of VQA models in the medicalfield, various datasets have been created. In this study, wespecifically focus on the radiology sector, thereby concen-trating our review on datasets relevant to radiology imagery.A notable example for benchmarking medical VQA modelsis the VQA-Med dataset(Ben Abacha et al., 2021). Thisdataset is particularly rich in content related to radiologyimages and reports. It comprises 4,500 radiology imagespaired with 4,500 question-and-answer combinations fortraining. Additionally, it includes sets of 500 images and500 corresponding question-answer pairs each for both vali-dation and testing purposes.In addition to the VQA-Med dataset, there are other no-table datasets in the medical VQA field. The VQA-RADdataset(Lau et al., 2018), for instance, includes 315 ra-diology images accompanied by 3,515 question-answerpairs. Another significant resource is the ChestX-ray8dataset(Wang et al., 2017b), which boasts over 100,000chest X-ray images paired with associated textual reports.This dataset has been instrumental not only for VQA butalso for various other medical image analysis tasks. More-over, the SLAKE dataset(Liu et al., 2021d) contributes tothe diversity of resources. It is a bilingual VQA datasetcontaining 642 radiology images from various body parts,along with more than 15,000 question-answer pairs.2.2. Related WorkIn their survey, (Lin et al., 2021) analyzed 46 existing med-ical VQA works, 39 of which are variations of a commonunderlying structure, as shown in Fig 1. This structure isknown as the joint embedding framework, a baseline modelfrequently used for comparison. Based on general VQA,this framework has an image vectorizer, a question vector-izer, a fusion algorithm that combines features from bothmodes, and an answer generator that can be used as either aclassifier or a generative model. The survey shows that a lotof different methods (Gong et al., 2021; Gupta et al., 2021a;Sharma et al., 2021b; Liu et al., 2021b) use CNN modelstrained on ImageNet data (Deng et al., 2009), mainly ResNet(He et al., 2016), to do tasks using datasets like VQA-RADand SLAKE (Liu et al., 2021d; Lau et al., 2018) that areimportant to our study. These models use the pretrainedweights for either initial weight setting or end-to-end fine-tuning. Despite its theoretical viability, using ImageNet,which has a data distribution vastly different from radiology,might not yield optimal results. Nevertheless, this practice iswidespread, primarily due to the scarcity of large annotatedmedical datasets suitable for supervised pretraining of theimage model.Figure 1. Joint embedding framework for Medical VQA (Lin et al.,2021)For the text encoder component, language models oftenemployed include variations of recurrent neural networks,GloVe (Li et al., 2021) , and other word embedding method-\n",
      "----------------------------------------------------------------------------------------------------\n",
      " to rebuild the short- and long-term dependencies that make the riskanalysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% segmentationaccuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vesselsflowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of invasive speciesrisk assessment. It allows policymakers, conservationists, and stakeholders to prioritize managementactions by identifying high-risk invasion pathways. Besides, our model is versatile and can include newdata sources, making it suitable for assessing species invasion risks in a changing global landscape.1arXiv:2401.13098v2  [cs.LG]  29 Jan 2024IntroductionGlobalization has rapidly increased marine shipping activities in the last decades. According to a statisticsreport, container shipping has increased by 24 times in tonnage from 1980 to 20201. During this time, theenvironmental pollution caused by introducing Non-Indigenous Species (NIS) through shipping activitieshas been a subject of study regarding marine preservation. Ballast water, used to keep vessels in balanceduring travels, is listed as a major source of NIS pollution2. The introduction of NIS into differentecological regions due to ballast water discharge has been shown to cause significant damage to the localecosystem. It poses a severe threat to the biodiversity of affected areas. In response to biological invasionissues, many studies about Ballast Water Risk Assessment (BWRA) and tools have been developed overthe last decades to estimate the risk levels of carrying NIS in the ballast water tanks3–13. These works andtools rely on ship self-reports, such as made available by the National Ballast Information Clearinghouse(NBIC)14. Ballast water reporting forms provide information on the water source and destination areas,allowing for an assessment of the environmental similarity between source and target locations of a vesselvoyage, which is considered a significant indicator of invasion risk level2. However, the acquisitionof ballast reports is limited at the global scale due to the various policies across different countries.Additionally, BWRA lacks alternative sources that incorporate comprehensive shipping information.Recent research has revealed a strong correlation between the introduction of non-indigenous speciesand the movement of ships through shipping networks. These studies12, 15have utilized data from theAutomatic Identification System (AIS), a sophisticated location tracking system on ships that allows themto share their positions in real-time16. This technology allows researchers to track individual/collectiveships17–20, predict larger-scale shipping activities21, and assess the risk of introducing NIS through ballastwater12. AIS data has emerged as a promising source of information for studying bioinvasions in marineecosystems. These studies analyze mobility flow by using Origin-Destination (OD) models that combinephysics with statistical mechanics. The gravity model, inspired by Newton’s Law of Universal Gravitation ,measures the attractive force between two objects based on their masses and the distance between them22.The gravity-inspired OD models were introduced in early human mobility and migration studies23, 24.They rely on information about population size and distances between origins and destinations as features.The gravity theory permeates many areas of study that go beyond mobility and migration, such asthe spreading of epidemics25, 26, commercial trading27, communication28and shipping networks15, 29modeling. Although the gravity model has been widely used to model real-world problems, recentstudies have shown that it may not be sufficient for capturing complex patterns in various scenarios30.Relying solely on mass and distance as the critical factors of the model could lead to failures in accuratelyrepresenting patterns31. Nonetheless, the gravity model has been prevalent for many years and remains apopular tool for modeling various phenomena. Beyond gravity models, radiation absorption is anotherphysics-inspired OD model to study mobility patterns32–34. Unlike gravity models, which draw inspirationfrom gravitational forces, radiation models are based on principles seen in radiation and absorption2/26processes, also from physics. While gravity models contain adjustable variables that may be difficult todefine, the radiation-absorption model simplifies this by emphasizing distance as the primary feature whileconsidering the population density. The well-known application of the radiation model is to predict humanmovement toward locations influenced by employment indicators32. Further studies used field theory forabstracting vector fields of daily commuting flows35, while others translated field theory-based mobility todeep learning models for achieving better in\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ealm ofMachine Learning (ML) in Natural Language Pro-cessing (NLP), annotated data is often a scarce andchallenging resource to acquire. In many cases,researchers and practitioners are faced with thedaunting task of developing accurate models withextremely limited or even non-existent annotatedtraining data. To address this challenge, the pro-cess is typically initiated by building a small anno-tated dataset and using it as a basis for training MLmodels using supervised learning methods. Sub-sequently, this process can be iterated by creatingannotated datasets of increasing size through tech-niques commonly referred to as Active Learning(AL) (Ren et al., 2021).As an alternative approach to acquiring anno-tated data, crowdsourcing platforms like AmazonMechanical Turk have been used in recent years.However, relying solely on human annotation ser-vices from these platforms brings its own set ofchallenges (Nowak and Rüger, 2010; Karpinskaet al., 2021). Variability in expertise among annota-tors often results in inconsistent annotation criteriaand, at times, conflicting annotations. Moreover,human annotators may encounter difficulties whendealing with large datasets, leading to errors anddelays in data annotation processes. An additionalconcern lies in the potential introduction of biasthrough annotators’ subjectivity and personal bi-ases, which can negatively affect the performanceof trained models. To mitigate these challenges,numerous research works have attempted to ad-dress these issues, either by selecting high-qualityannotators in multiple-annotated-data setups or byemploying diverse methods to weight each annota-tor’s input (Zhang et al., 2023a; Hsueh et al., 2009;Hovy et al., 2013; Basile et al., 2021).In low-resource settings, a common practice isto randomly sample a subset of the unlabeled datafor the annotation process (Tunstall et al., 2022;Beijbom, 2014). This approach involves selectinga few examples at random, which are then anno-tated to form the initial training dataset. However,arXiv:2401.13229v1  [cs.CL]  24 Jan 2024this methodology may be suboptimal since it ne-glects the specific characteristics of the data andthe requirements of the learning model. In otherwords, randomly sampled data may fail to ade-quately represent the full spectrum of classes orconcepts present within the dataset.The advent of zero-shot methods has providedan intriguing approach to perform initial annota-tion without any annotated training data (Alco-forado et al., 2022). Nonetheless, historical short-comings have often placed zero-shot methods be-hind their few-shot counterparts in terms of per-formance. Recent strides in the field of NLP, par-ticularly the emergence of general-purpose LargeLanguage Models (LLMs), have opened up excit-ing avenues in multi-task learning and zero-shotproblem-solving (Ferraz et al., 2023). These mod-els exhibit remarkable skills across various tasks(Brown et al., 2020; Touvron et al., 2023) but stillencounter difficulties when adapting to specific do-mains where highly specialized knowledge may beentirely absent from their training data (Yang et al.,2023; Zhang et al., 2023b).In the realm of few-shot text classification, thechallenge of acquiring annotated data becomes in-creasingly daunting, particularly when confrontedwith imbalanced datasets (Ferraz et al., 2021).Common benchmark datasets used for few-shottext classification tasks often exhibit a semblanceof balance or slight imbalance. However, suchdatasets represent rare exceptions in the real-worldlandscape, where data distributions are typicallyskewed and imbalanced, mirroring the inherentcomplexity of practical scenarios. The prevalenceof imbalanced data poses a significant challenge,as traditional random sampling strategies becomeincreasingly suboptimal. In scenarios where oneclass overwhelmingly dominates, random samplingtends to favor the majority class, resulting in dataselection that inadequately represents the underrep-resented and rare classes.To address these challenges, in this paper weintroduce an innovative automatic data selectionarchitecture for few-shot learning. Our approachis designed to identify the most informative andrepresentative data points that should be annotatedby humans in low-resource, annotation-scarce sce-narios. It leverages a framework that systemati-cally orders data points based on their likelihood to(i) belong to distinct classes, thereby avoiding un-necessary redundancy in human annotation efforts,and (ii) enhance the overall performance of thelearning model. Our evaluation of this approach en-compasses various low-resource natural languageprocessing datasets, demonstrating its capacity tominimize redundancy in human annotation effortsand improve model performance compared to tra-ditional random sampling or manual data selectionstrategies, particularly in cases with a limited num-ber of annotated examples.In summary, this work presents two primary con-tributions:1.The introduction of an automati\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for text in extracted_texts[:100]:\n",
    "    print(text)\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3910df-8196-4953-906f-f4c3764dd222",
   "metadata": {},
   "source": [
    "## Now evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa431c6-d1cb-4d02-b9cb-c57e963c6eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 1024\n",
    "log_folder_path = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cfa16a-0ace-4aca-b026-63fe0aa107f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_log_sum(logits, target_token_ids):\n",
    "    shifted_logits = logits[:-1, :]\n",
    "    shifted_targets = target_token_ids[1:]\n",
    "    \n",
    "    log_probs = F.log_softmax(shifted_logits, dim=-1)\n",
    "    \n",
    "    target_log_probs = -log_probs.gather(1, shifted_targets.unsqueeze(1)).squeeze()\n",
    "    # print(target_log_probs)\n",
    "    \n",
    "    log_sum = torch.sum(target_log_probs, dim=-1)\n",
    "    # print(perplexity_sum)\n",
    "\n",
    "    return log_sum.item()\n",
    "\n",
    "\n",
    "def print_model_parameters_in_billions(model):\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    total_params_billion = total_params / 1e9\n",
    "    \n",
    "    print(f\"Model parameters: {total_params_billion:.3f} billion\")\n",
    "    \n",
    "    \n",
    "def log(data_dict, folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        try:\n",
    "            os.makedirs(folder_path)\n",
    "            print(f\"Directory created at {folder_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating directory: {e}\")\n",
    "            return\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    file_name = f\"{timestamp}.json\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data_dict, file, indent=4)\n",
    "        print(f\"Dictionary saved successfully to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving dictionary: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c55ca0-30dd-4331-9dbc-531d37a445f3",
   "metadata": {},
   "source": [
    "## Evaluate RWKV(v5/v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56930e55-3876-4a1e-bcf6-798f287caa15",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py38_cu118/wkv_cuda/build.ninja...\n",
      "Building extension module wkv_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module wkv_cuda...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 1 RESCALE_LAYER 6\n",
      "\n",
      "Loading ../models/rwkv_5_3b/RWKV-5-World-3B-v2-20231113-ctx4096.pth ...\n",
      "Model detected: v5.2\n",
      "Strategy: (total 32+1=33 layers)\n",
      "* cuda [float16, float16], store 33 layers\n",
      "0-cuda-float16-float16 1-cuda-float16-float16 2-cuda-float16-float16 3-cuda-float16-float16 4-cuda-float16-float16 5-cuda-float16-float16 6-cuda-float16-float16 7-cuda-float16-float16 8-cuda-float16-float16 9-cuda-float16-float16 10-cuda-float16-float16 11-cuda-float16-float16 12-cuda-float16-float16 13-cuda-float16-float16 14-cuda-float16-float16 15-cuda-float16-float16 16-cuda-float16-float16 17-cuda-float16-float16 18-cuda-float16-float16 19-cuda-float16-float16 20-cuda-float16-float16 21-cuda-float16-float16 22-cuda-float16-float16 23-cuda-float16-float16 24-cuda-float16-float16 25-cuda-float16-float16 26-cuda-float16-float16 27-cuda-float16-float16 28-cuda-float16-float16 29-cuda-float16-float16 30-cuda-float16-float16 31-cuda-float16-float16 32-cuda-float16-float16 \n",
      "emb.weight                        f16      cpu  65536  2560 \n",
      "blocks.0.ln1.weight               f16   cuda:0   2560       \n",
      "blocks.0.ln1.bias                 f16   cuda:0   2560       \n",
      "blocks.0.ln2.weight               f16   cuda:0   2560       \n",
      "blocks.0.ln2.bias                 f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_k           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_v           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_r           f16   cuda:0   2560       \n",
      "blocks.0.att.time_mix_g           f16   cuda:0   2560       \n",
      "blocks.0.att.time_decay           f32   cuda:0     40    64 \n",
      "blocks.0.att.time_first           f32   cuda:0     40    64 \n",
      "blocks.0.att.receptance.weight    f16   cuda:0   2560  2560 \n",
      "blocks.0.att.key.weight           f16   cuda:0   2560  2560 \n",
      "blocks.0.att.value.weight         f16   cuda:0   2560  2560 \n",
      "blocks.0.att.output.weight        f16   cuda:0   2560  2560 \n",
      "blocks.0.att.gate.weight          f16   cuda:0   2560  2560 \n",
      "blocks.0.att.ln_x.weight          f32   cuda:0   2560       \n",
      "blocks.0.att.ln_x.bias            f32   cuda:0   2560       \n",
      "blocks.0.ffn.time_mix_k           f16   cuda:0   2560       \n",
      "blocks.0.ffn.time_mix_r           f16   cuda:0   2560       \n",
      "blocks.0.ffn.key.weight           f16   cuda:0   2560  8960 \n",
      "blocks.0.ffn.receptance.weight    f16   cuda:0   2560  2560 \n",
      "blocks.0.ffn.value.weight         f16   cuda:0   8960  2560 \n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.31.ln1.weight              f16   cuda:0   2560       \n",
      "blocks.31.ln1.bias                f16   cuda:0   2560       \n",
      "blocks.31.ln2.weight              f16   cuda:0   2560       \n",
      "blocks.31.ln2.bias                f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_k          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_v          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_r          f16   cuda:0   2560       \n",
      "blocks.31.att.time_mix_g          f16   cuda:0   2560       \n",
      "blocks.31.att.time_decay          f32   cuda:0     40    64 \n",
      "blocks.31.att.time_first          f32   cuda:0     40    64 \n",
      "blocks.31.att.receptance.weight   f16   cuda:0   2560  2560 \n",
      "blocks.31.att.key.weight          f16   cuda:0   2560  2560 \n",
      "blocks.31.att.value.weight        f16   cuda:0   2560  2560 \n",
      "blocks.31.att.output.weight       f16   cuda:0   2560  2560 \n",
      "blocks.31.att.gate.weight         f16   cuda:0   2560  2560 \n",
      "blocks.31.att.ln_x.weight         f32   cuda:0   2560       \n",
      "blocks.31.att.ln_x.bias           f32   cuda:0   2560       \n",
      "blocks.31.ffn.time_mix_k          f16   cuda:0   2560       \n",
      "blocks.31.ffn.time_mix_r          f16   cuda:0   2560       \n",
      "blocks.31.ffn.key.weight          f16   cuda:0   2560  8960 \n",
      "blocks.31.ffn.receptance.weight   f16   cuda:0   2560  2560 \n",
      "blocks.31.ffn.value.weight        f16   cuda:0   8960  2560 \n",
      "ln_out.weight                     f16   cuda:0   2560       \n",
      "ln_out.bias                       f16   cuda:0   2560       \n",
      "head.weight                       f16   cuda:0   2560 65536 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py38_cu118/rwkv5/build.ninja...\n",
      "Building extension module rwkv5...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module rwkv5...\n"
     ]
    }
   ],
   "source": [
    "# load rwkv model\n",
    "model_name_or_path = r'../models/rwkv_5_3b/RWKV-5-World-3B-v2-20231113-ctx4096.pth'\n",
    "\n",
    "os.environ['RWKV_JIT_ON'] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '1'\n",
    "\n",
    "from rwkv.model import RWKV\n",
    "from rwkv.utils import PIPELINE\n",
    "\n",
    "model = RWKV(model=model_name_or_path, strategy='cuda fp16')\n",
    "pipeline = PIPELINE(model, r\"rwkv_vocab_v20230424\")\n",
    "# pipeline = PIPELINE(model, \"./models/20B_tokenizer.json\")  # v4\n",
    "tokenizer = pipeline.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f0edc1-cfcb-49f8-9118-a1644421ea8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f30370c34ea41eba940eeae50ddf4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/rwkv/model.py:957: UserWarning: operator() profile_node %318 : int = prim::profile_ivalue(%316)\n",
      " does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  r, k, v, g, xxx, ss = self.v5_2_before(x, sx, s, ln_w, ln_b, lx_w, lx_b, k_mix, v_mix, r_mix, g_mix, t_decay, t_first, kw, vw, rw, gw, ow, kmx, krx, kmy, kry, vmx, vrx, vmy, vry, rmx, rrx, rmy, rry, gmx, grx, gmy, gry, omx, orx, omy, ory)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved successfully to ./logs/2024-02-29_23-54-19.json\n",
      "log probability sum: 2900.97\n",
      "avg tokens: 1143\n"
     ]
    }
   ],
   "source": [
    "# eval rwkv\n",
    "rwkv_test_data = []\n",
    "rwkv_token_length_list = []\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_seq = tokenizer.encode(sample)\n",
    "        # input_seq = tokenizer.encode(sample).ids # v4\n",
    "        input_length = len(input_seq)\n",
    "        \n",
    "        neg_log_prob_temp = 0\n",
    "        for begin in range(0, input_length, chunk_size):\n",
    "            input_chunk = input_seq[begin: begin + chunk_size]\n",
    "            \n",
    "\n",
    "            logit = model.forward(input_chunk, None, full_output=True)[0]\n",
    "            \n",
    "            if len(input_chunk) == 1:\n",
    "                logit = logit.unsqueeze(0)\n",
    "\n",
    "            log_sum = calculate_log_sum(logit, torch.tensor(input_chunk).cuda())\n",
    "            \n",
    "            neg_log_prob_temp += log_sum\n",
    "\n",
    "        rwkv_token_length_list.append(input_length)\n",
    "        rwkv_test_data.append(neg_log_prob_temp)\n",
    "        \n",
    "data_dict = {\n",
    "    'model_name_or_path': model_name_or_path,\n",
    "    'data_path': data_path,\n",
    "    'neg_log_prob_sum': sum(rwkv_test_data) / len(rwkv_test_data),\n",
    "    'avg tokens': sum(rwkv_token_length_list) / len(rwkv_token_length_list),\n",
    "       }\n",
    "\n",
    "log(data_dict, log_folder_path)\n",
    "        \n",
    "print(f'log probability sum: {sum(rwkv_test_data) / len(rwkv_test_data):.2f}')\n",
    "print(f'avg tokens: {sum(rwkv_token_length_list) / len(rwkv_token_length_list):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be6fb1dc-f35c-4abc-ac0b-c0b0eba2c3c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model, pipeline, tokenizer, logit\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5180f32-7e40-410a-a492-b44051afca5f",
   "metadata": {},
   "source": [
    "## Evaluate Hugging Face models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b06ba51-0c73-41a5-a2d6-27ea674ab632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 2.795 billion\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "model_name_or_path = r\"stabilityai/stablelm-3b-4e1t\"\n",
    "cache_dir = '../models/temp/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path, \n",
    "                                             device_map=\"cuda\", \n",
    "                                             trust_remote_code=True, \n",
    "                                             cache_dir=cache_dir).eval()\n",
    "\n",
    "print_model_parameters_in_billions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b67253f-59c7-4930-974f-baf5298ddb43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844b1a4d994d429c9da2557d2975ebda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved successfully to ./logs/2024-02-29_23-59-02.json\n",
      "log probability sum: 2894.56\n",
      "avg tokens: 1149\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "data = []\n",
    "token_length_list = []\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        inputs = tokenizer(sample, return_tensors='pt')\n",
    "        inputs = inputs.to(model.device)\n",
    "\n",
    "        seq_length = inputs['input_ids'].shape[-1]\n",
    "        \n",
    "        neg_log_prob_temp = 0\n",
    "        for begin in range(0, seq_length, chunk_size):\n",
    "            \n",
    "            input_chunk = inputs['input_ids'][:, begin: begin + chunk_size]\n",
    "\n",
    "            logit = model.forward(input_ids=input_chunk).logits[0, :, :]\n",
    "\n",
    "            log_sum = calculate_log_sum(logit, input_chunk.squeeze(0))\n",
    "            neg_log_prob_temp += log_sum\n",
    "\n",
    "        token_length_list.append(seq_length)\n",
    "        data.append(neg_log_prob_temp)\n",
    "        \n",
    "data_dict = {\n",
    "    'model_name_or_path': model_name_or_path,\n",
    "    'data_path': data_path,\n",
    "    'neg_log_prob_sum': sum(data) / len(data),\n",
    "    'avg tokens': sum(token_length_list) / len(token_length_list),\n",
    "       }\n",
    "\n",
    "log(data_dict, log_folder_path)\n",
    "\n",
    "print(f'log probability sum: {sum(data) / len(data):.2f}')\n",
    "print(f'avg tokens: {sum(token_length_list) / len(token_length_list):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70e9bce-34bf-4ef7-913c-76252cd0fa97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model, tokenizer, logit, inputs\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b4438-149d-4b2b-9ba1-b037f2d1e558",
   "metadata": {},
   "source": [
    "## Evaluate Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa902d91-01ef-4e91-bc1f-037e425ceb70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 2.768 billion\n"
     ]
    }
   ],
   "source": [
    "from mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel\n",
    "\n",
    "model_name_or_path = \"state-spaces/mamba-2.8b-slimpj\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "model = MambaLMHeadModel.from_pretrained(model_name_or_path, device=\"cuda\", dtype=torch.float16)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print_model_parameters_in_billions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "934009ff-50b7-4cc6-91f6-57d28e110852",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8670ea31be4ae682d41cad9e0b246c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved successfully to ./logs/2024-03-01_00-01-53.json\n",
      "log probability sum: 3165.90\n",
      "avg tokens: 1149\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "data = []\n",
    "token_length_list = []\n",
    "\n",
    "for idx, sample in tqdm(enumerate(extracted_texts), total=len(extracted_texts)):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        inputs = tokenizer(sample, return_tensors='pt')\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        seq_length = inputs['input_ids'].shape[-1]\n",
    "        \n",
    "        neg_log_prob_temp = 0\n",
    "        for begin in range(0, seq_length, chunk_size):\n",
    "            \n",
    "            input_chunk = inputs['input_ids'][:, begin: begin + chunk_size]\n",
    "\n",
    "            logit = model.forward(input_ids=input_chunk).logits[0, :, :]\n",
    "\n",
    "            log_sum = calculate_log_sum(logit, input_chunk.squeeze(0))\n",
    "            neg_log_prob_temp += log_sum\n",
    "\n",
    "        token_length_list.append(seq_length)\n",
    "        data.append(neg_log_prob_temp)\n",
    "        \n",
    "data_dict = {\n",
    "    'model_name_or_path': model_name_or_path,\n",
    "    'data_path': data_path,\n",
    "    'neg_log_prob_sum': sum(data) / len(data),\n",
    "    'avg tokens': sum(token_length_list) / len(token_length_list),\n",
    "       }\n",
    "\n",
    "log(data_dict, log_folder_path)\n",
    "\n",
    "print(f'log probability sum: {sum(data) / len(data):.2f}')\n",
    "print(f'avg tokens: {sum(token_length_list) / len(token_length_list):.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9139aa-a57c-4c06-9214-455fa8a4b2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model, tokenizer, logit, inputs\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663a4f9-3341-48e2-a294-e4a0406b36bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
